{"text":"This is a hot topic : check out Liu & Gildea 's poster for an alternative Bayesian formulation of the same problem and language pair .Galron et al .look at tree - to - tree STSG ( from a Data - Oriented Parsing perspective ) , with an eye towards discriminatively learning STSG rules to optimize for translation accuracy .","label":"CompareOrContrast","metadata":{},"score":"33.677116"}
{"text":"This is a hot topic : check out Liu & Gildea 's poster for an alternative Bayesian formulation of the same problem and language pair .Galron et al .look at tree - to - tree STSG ( from a Data - Oriented Parsing perspective ) , with an eye towards discriminatively learning STSG rules to optimize for translation accuracy .","label":"CompareOrContrast","metadata":{},"score":"33.677116"}
{"text":"We show that our Bayesian model is able to extract minimal set of hierarchical phrase rules without impacting the translation quality as measured by the BLEU score .This paper falls under the latter category and we use a non - parametric Bayesian approach for rule extraction for Hiero - style systems .","label":"CompareOrContrast","metadata":{},"score":"34.889458"}
{"text":"Of these , some concentrate on evaluating word - alignment , directly such as ( Zhang et al . , 2008 ) or indirectly by evaluating a heuristically trained hierarchical translation system from sampled phras ... . by Baskaran Sankaran , Gholamreza Haffari , Anoop Sarkar - In Proceedings of the Sixth Workshop on SMT , 2011 . \" ...","label":"CompareOrContrast","metadata":{},"score":"35.464798"}
{"text":"by Matt Post , Daniel Gildea - In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics ( ACL-09 ) , Suntec . \" ...Tree substitution grammars ( TSGs ) offer many advantages over context - free grammars ( CFGs ) , but are hard to learn .","label":"CompareOrContrast","metadata":{},"score":"36.80913"}
{"text":"This is our fourth yearly submission to the WMT shared translation task .Continuing WMT 's general trend , we worked with more data than in previous years , basing our 2011 system on 13 ... . \" ...A common modeling choice in syntax - based statistical machine translation is the use of synchronous context - free grammars , or SCFGs .","label":"CompareOrContrast","metadata":{},"score":"36.83814"}
{"text":"We begin with structures from standard parsing and alignment tools , then use the EM algorithm to revise these structures in light of the translation task .We report an overall +1.48 BLEU improvement on a standard Chinese - to - English test . by Trevor Cohn , Phil Blunsom - In Proceedings of the Conference on Emprical Methods for Natural Language Processing , 2009 . \" ...","label":"CompareOrContrast","metadata":{},"score":"37.805157"}
{"text":"We begin with structures from standard parsing and alignment tools , then use the EM algorithm to revise these structures in light of the translation task .We report an overall +1.48 BLEU improvement on a standard Chinese - to - English test . by Trevor Cohn , Phil Blunsom - In Proceedings of the Conference on Emprical Methods for Natural Language Processing , 2009 . \" ...","label":"CompareOrContrast","metadata":{},"score":"37.805157"}
{"text":"We propose a linguistically - motivated prior derivation model to score hypothesis derivations on top of the baseline model during the ... \" .This paper presents an improved formally syntax - based SMT model , which is enriched by linguistically syntactic knowledge obtained from statistical constituent parsers .","label":"CompareOrContrast","metadata":{},"score":"38.307266"}
{"text":"While preliminary work , these experiments show promise for semantically - informed machine translation . \" ...We introduce a discriminatively trained , globally normalized , log - linear variant of the lexical translation models proposed by Brown et al .( 1993 ) .","label":"CompareOrContrast","metadata":{},"score":"38.5562"}
{"text":"Analysis and Contrastive Experiments Zollman et al .( 2008 ) compare phrase - base ... . by Ashish Venugopal , Andreas Zollmann , Stephan Vogel - In Proc . of HLT - NAACL , 2007 . \" ...We present an efficient , novel two - pass approach to mitigate the computational impact resulting from online intersection of an n - gram language model ( LM ) and a probabilistic synchronous context - free grammar ( PSCFG ) for statistical machine translation .","label":"CompareOrContrast","metadata":{},"score":"39.15993"}
{"text":"In this paper , we learn a TSG using Gibbs sampling with a nonparametric prior to control subtree size .The learned grammars perform significa ... \" .Tree substitution grammars ( TSGs ) offer many advantages over context - free grammars ( CFGs ) , but are hard to learn .","label":"CompareOrContrast","metadata":{},"score":"39.455658"}
{"text":"First , we can incorporate features on phrase pairs , in addition to word links .Second , we can optimize for an extraction - based loss function that relates directly to the end task of generating translations .Our model gives improvements in alignment quality relative to state - of - the - art unsuper - vised and supervised baselines , as well as providing up to a 1.4 improvement in BLEU score in Chinese - to - English trans - lation experiments . ... he history of phrase - based translation as a method for training translation models ( Marcu and Wong , 2002 ) .","label":"CompareOrContrast","metadata":{},"score":"39.796608"}
{"text":"We also use the algorithm to analyze the maximum SCFG rule length needed to cover hand - aligned data from various language pairs . by Bowen Zhou , Xiaodan Zhu , Bing Xiang , Yuqing Gao - In Proceedings of the ACL'08 : HLT SSST-2 , 2008 . \" ...","label":"CompareOrContrast","metadata":{},"score":"39.90704"}
{"text":"In this paper , we learn a TSG using Gibbs sampling with a nonparametric prior to control subtree size .The learned grammars perform significantly better than heuristically extracted ones on parsing accuracy . ...g tasks that search for a hidden segmentation .","label":"CompareOrContrast","metadata":{},"score":"40.26956"}
{"text":"A common modeling choice in syntax - based statistical machine translation is the use of synchronous context - free grammars , or SCFGs .When training a translation model in a supervised setting , an SCFG is extracted from parallel text that has been statistically word - aligned and parsed by monolingual statistical parsers .","label":"CompareOrContrast","metadata":{},"score":"40.36133"}
{"text":"However , as more parameters are added to the model the idealistic approach has not scaled well , for it is increasingly difficult to incorporate large amounts of training data efficiently over an increasingly large search space .Additionally , the EM procedure has a tendency to overfit its training data when the input units have varying explanatory powers , such as variable - size phrases or variable - height trees . by Trevor Cohn , Phil Blunsom - In Proceedings of the Conference on Emprical Methods for Natural Language Processing , 2009 . \" ...","label":"CompareOrContrast","metadata":{},"score":"40.690033"}
{"text":"A growing body of machine translation research aims to exploit lexical patterns ( e.g. , n - grams and phrase pairs ) with gaps ( Simard et al . , 2005 ; Chiang , 2005 ; Xiong et al . , 2011 ) .","label":"CompareOrContrast","metadata":{},"score":"40.865833"}
{"text":"A growing body of machine translation research aims to exploit lexical patterns ( e.g. , n - grams and phrase pairs ) with gaps ( Simard et al . , 2005 ; Chiang , 2005 ; Xiong et al . , 2011 ) .","label":"CompareOrContrast","metadata":{},"score":"40.865833"}
{"text":"We compare our sampler to a previously proposed Gibbs sampler and demonstrate strong improvements in terms of both training log - likelihood and performance on an end - to - end translation evaluation . ...Koehn et al . , 2003 ) .","label":"CompareOrContrast","metadata":{},"score":"41.20998"}
{"text":"We compare our sampler to a previously proposed Gibbs sampler and demonstrate strong improvements in terms of both training log - likelihood and performance on an end - to - end translation evaluation . ...Koehn et al . , 2003 ) .","label":"CompareOrContrast","metadata":{},"score":"41.20998"}
{"text":"We describe our experiments with training algorithms for tree - to - tree synchronous tree - substitution grammar ( STSG ) for monolingual translation tasks such as sentence compression and paraphrasing .These translation tasks are characterized by the relative ability to commit to parallel parse trees and availability of word alignments , yet the unavailability of large - scale data , calling for a Bayesian tree - to - tree formalism .","label":"CompareOrContrast","metadata":{},"score":"41.328865"}
{"text":"We describe our experiments with training algorithms for tree - to - tree synchronous tree - substitution grammar ( STSG ) for monolingual translation tasks such as sentence compression and paraphrasing .These translation tasks are characterized by the relative ability to commit to parallel parse trees and availability of word alignments , yet the unavailability of large - scale data , calling for a Bayesian tree - to - tree formalism .","label":"CompareOrContrast","metadata":{},"score":"41.328865"}
{"text":"Our approach is designed to extract rules that are licensed by the word alignments and heuristically extracted phras ... \" .We present a novel approach for extracting a minimal synchronous context - free grammar ( SCFG ) for Hiero - style statistical machine translation using a non - parametric Bayesian framework .","label":"CompareOrContrast","metadata":{},"score":"41.4867"}
{"text":", 2004 ) does not prevent all non - ITG permutations , and we demonstrate that the hierarchical reordering model can produce analyses during decoding that are inconsistent with analyses made during training .Experimentally , we verify the utility of hierarchical re - ordering , and compare several theoretically - motivated variants in terms of both translation quality and the syntactic complexity of their output . ... their output .","label":"CompareOrContrast","metadata":{},"score":"41.822624"}
{"text":"They pose this as an optimization problem and give a greedy algorithm ; the resulting grammar is reliably better under a variety of conditions on a Chinese - English task .Meanwhile , Zhang et al .engineer more efficient STSG decoding for the case in which the source is a parse forest and source units are tree fragments .","label":"CompareOrContrast","metadata":{},"score":"41.844215"}
{"text":"They pose this as an optimization problem and give a greedy algorithm ; the resulting grammar is reliably better under a variety of conditions on a Chinese - English task .Meanwhile , Zhang et al .engineer more efficient STSG decoding for the case in which the source is a parse forest and source units are tree fragments .","label":"CompareOrContrast","metadata":{},"score":"41.844215"}
{"text":"We introduce a discriminatively trained , globally normalized , log - linear variant of the lexical translation models proposed by Brown et al .( 1993 ) .In our model , arbitrary , nonindependent features may be freely incorporated , thereby overcoming the inherent limitation of generative models , which require that features be sensitive to the conditional independencies of the generative process .","label":"CompareOrContrast","metadata":{},"score":"42.55806"}
{"text":"In addition to standard hierarchical rule tables , it is capable of extracting syntax augmented machine translation ( SAMT ) grammars ( Zollmann and Venugopal , 2006 ) .Ncode ( Crego et al . , 2011 ) implements the n - gram - based approach to machine translation ( Mariño et al . , 2006 ) .","label":"CompareOrContrast","metadata":{},"score":"42.699028"}
{"text":"Three papers incorporate new feature types into strong baseline translation models , following a recent trend .Shen et al . devise some clever local features using source - side context , derivation span length , and dependency modeling to make impressive improvements on an already impressive baseline system in both Chinese - English and Arabic - English .","label":"CompareOrContrast","metadata":{},"score":"42.81949"}
{"text":"Three papers incorporate new feature types into strong baseline translation models , following a recent trend .Shen et al . devise some clever local features using source - side context , derivation span length , and dependency modeling to make impressive improvements on an already impressive baseline system in both Chinese - English and Arabic - English .","label":"CompareOrContrast","metadata":{},"score":"42.81949"}
{"text":"In the second stage , we instantiate specific alternative derivations from this hypergraph , using the LM to drive this search process , recovering from search errors made in the first pass .Model search errors in our approach are comparable to those made by the state - of - the - art \" Cube Pruning \" approach in ( Chiang , 2007 ) under comparable pruning conditions evaluated on both hierarchical and syntax - based grammars . ...","label":"CompareOrContrast","metadata":{},"score":"43.009155"}
{"text":"Like Hiero , Madnani 's model uses just one nonterminal X instead of linguistic nonterminals .Three additional efforts incorporated linguistic syntax .Callison - Burch ( 2008 ) introduced syntactic const ... . by Bevan Jones , Jacob Andreas , Daniel Bauer , Karl Moritz Hermann , Kevin Knight . \" ...","label":"CompareOrContrast","metadata":{},"score":"43.15002"}
{"text":"We frame the MT problem as a decipherment task , treating the foreign text as a cipher for English and present novel methods for training translation models from nonparallel text . ... annel probabilities ( Knight et al . , 2006 ) .","label":"CompareOrContrast","metadata":{},"score":"43.4915"}
{"text":"We evaluate these models on two cross - lingual document classification tasks , outperforming the prior state of the art .Through qualitative analysis and the study of pivoting effects we demonstrate that our representations are semantically plausible and can capture semantic rela - tionships across languages without paral - lel data . ...","label":"CompareOrContrast","metadata":{},"score":"43.50765"}
{"text":"This is due to the fact that the target side is built inside - out from sub - spans ( Heafield et al . , 2011 , 2013 ) .Watana ... . \" ...Phrase - based translation models usually memorize local translation literally and make independent assumption between phrases which makes it neither generalize well on unseen data nor model sentence - level effects between phrases .","label":"CompareOrContrast","metadata":{},"score":"44.026783"}
{"text":"We present a novel technique for learn - ing semantic representations , which ex - tends the distributional hypothesis to mul - tilingual data and joint - space embeddings .Our models leverage parallel data and learn to strongly align the embeddings of semantically equivalent sentences , while maintaining suf ... \" .","label":"CompareOrContrast","metadata":{},"score":"44.115734"}
{"text":"2008 , Galley et al .2009 , Gimpel & Smith below , and Hassan et al . in the poster session ) .Decoding is NP - complete , and devising efficient beam search is a key point in the paper .","label":"CompareOrContrast","metadata":{},"score":"44.239082"}
{"text":"2008 , Galley et al .2009 , Gimpel & Smith below , and Hassan et al . in the poster session ) .Decoding is NP - complete , and devising efficient beam search is a key point in the paper .","label":"CompareOrContrast","metadata":{},"score":"44.239082"}
{"text":"The addition of a deterministic permutation parser can provide valuable hierarchical information to a phrase - based statistical machine translation ( PBSMT ) system .Permutation parsers have been used to implement hierarchical re - ordering models ( Galley and Manning , 2008 ) and to enforce inversion trans ... \" .","label":"CompareOrContrast","metadata":{},"score":"44.4649"}
{"text":"Since SCFG models have become mainstream , there 's been a greater emphasis on decoding .Following a recent strand of research on grammar transformations for SCFG , Xiao et al .observe that , in the space of possible transformations , many will pair source yields with huge numbers of target yields , which compete during decoding and thus result in more search errors .","label":"CompareOrContrast","metadata":{},"score":"44.485397"}
{"text":"Since SCFG models have become mainstream , there 's been a greater emphasis on decoding .Following a recent strand of research on grammar transformations for SCFG , Xiao et al .observe that , in the space of possible transformations , many will pair source yields with huge numbers of target yields , which compete during decoding and thus result in more search errors .","label":"CompareOrContrast","metadata":{},"score":"44.485397"}
{"text":"We achieve this result by applying phrasal inversion transduction grammar alignment techniques to character strings to train a character - based translation model , and using this in the phrase - based MT framework .We also propose a look - ahead parsing algorithm and substring - informed prior probabilities to achieve more effective and efficient alignment .","label":"CompareOrContrast","metadata":{},"score":"44.518105"}
{"text":"We use a hierarchical Bayesia ... \" .We present a phrasal synchronous gram - mar model of translational equivalence .Unlike previous approaches , we do not resort to heuristics or constraints from a word - alignment model , but instead directly induce a synchronous grammar from parallel sentence - aligned corpora .","label":"CompareOrContrast","metadata":{},"score":"44.551777"}
{"text":"We present a phrasal synchronous gram - mar model of translational equivalence .Unlike previous approaches , we do not resort to heuristics or constraints from a word - alignment model , but instead directly induce a synchronous grammar from parallel sentence - aligned corpora .","label":"CompareOrContrast","metadata":{},"score":"44.74461"}
{"text":"We present a phrasal synchronous gram - mar model of translational equivalence .Unlike previous approaches , we do not resort to heuristics or constraints from a word - alignment model , but instead directly induce a synchronous grammar from parallel sentence - aligned corpora .","label":"CompareOrContrast","metadata":{},"score":"44.74461"}
{"text":"We provide a systematic analysis of the effects of optimizer instability - an extraneous variable that is seldom controlled for - on experimental outcomes , and make recommendations for reporting results more accurately .The second system pair contrasts two German - English Hiero / cdec systems constructed from the WMT11 parallel training data ( 98 M words ) .","label":"CompareOrContrast","metadata":{},"score":"44.761887"}
{"text":"We report an overall 1.48 BLEU improvement on the NIST08 evaluation set over a strong baseline in Chinese / English translation .Background Syntactic methods have recently proven useful in statistical machine translation ( SMT ) .In this article , we explore different ways of exploiting the structure of bilingual material for syntax - based SMT .","label":"CompareOrContrast","metadata":{},"score":"44.87983"}
{"text":"We report an overall 1.48 BLEU improvement on the NIST08 evaluation set over a strong baseline in Chinese / English translation .Background Syntactic methods have recently proven useful in statistical machine translation ( SMT ) .In this article , we explore different ways of exploiting the structure of bilingual material for syntax - based SMT .","label":"CompareOrContrast","metadata":{},"score":"44.87983"}
{"text":"We report an overall 1.48 BLEU improvement on the NIST08 evaluation set over a strong baseline in Chinese / English translation .Background Syntactic methods have recently proven useful in statistical machine translation ( SMT ) .In this article , we explore different ways of exploiting the structure of bilingual material for syntax - based SMT .","label":"CompareOrContrast","metadata":{},"score":"44.87983"}
{"text":"This paper describes an efficient sampler for synchronous grammar induction under a nonparametric Bayesian prior .Inspired by ideas from slice sampling , our sampler is able to draw samples from the posterior distributions of models for which the standard dynamic programing based sampler proves intra ... \" .","label":"CompareOrContrast","metadata":{},"score":"44.958405"}
{"text":"We show that shallow - n grammars , low - level rule catenation , and other search constraints can help to match the power of the translation system to specific language pairs . ... of input lattices following Chappelier et al .","label":"CompareOrContrast","metadata":{},"score":"45.13744"}
{"text":"Learning these hierarchical , probabilistic devices from parallel corpora constitutes a major challenge , because of multiple latent model variables as well as the risk of data overfitting .This paper presents an effective method for learning a family of particular interest to MT , binary Synchronous Context - Free Grammars with inverted / monotone orientation ( a.k.a .","label":"CompareOrContrast","metadata":{},"score":"45.36769"}
{"text":"Tools . by Jonathan H. Clark , Chris Dyer , Alon Lavie , Noah A. Smith - In Proc . of ACL , 2011 . \" ...In statistical machine translation , a researcher seeks to determine whether some innovation ( e.g. , a new feature , model , or inference algorithm ) improves translation quality in comparison to a baseline system .","label":"CompareOrContrast","metadata":{},"score":"45.750233"}
{"text":"The SCFG formulation has a practical benefit : we can take advantage of the heavily - optimized SCFG decoders for machine translation .5 Experiments 5.1 Standard Parsing Experiments We evaluate parsing accuracy of the Stanford and DP - TSG models ( Table 6 ) .","label":"CompareOrContrast","metadata":{},"score":"46.07684"}
{"text":"SCFG models are n't completely forgotten : Zhang & Li offer a new twist on reordering in binary - branching SCFG .Given a source parse , we could train a maximum entropy classifier to decide whether any binary production should be inverted ; this requires a lot of computation over sparse vectors .","label":"CompareOrContrast","metadata":{},"score":"46.257835"}
{"text":"SCFG models are n't completely forgotten : Zhang & Li offer a new twist on reordering in binary - branching SCFG .Given a source parse , we could train a maximum entropy classifier to decide whether any binary production should be inverted ; this requires a lot of computation over sparse vectors .","label":"CompareOrContrast","metadata":{},"score":"46.257835"}
{"text":"In this paper , we develop generative models of monolingual and parallel text that build sentences using gappy patterns of arbitrary length and with arbitrarily many gaps .We exploit Bayesian nonparametrics and collapsed Gibbs sampling to discover salient patterns in a corpus .","label":"CompareOrContrast","metadata":{},"score":"46.259617"}
{"text":"We present the Carnegie Mellon University Stat - XFER group submission to the WMT 2011 shared translation task .We built a hybrid syntactic MT system for French - English using the Joshua decoder and an automatically acquired SCFG .New work for this year includes training data selection and grammar filtering .","label":"CompareOrContrast","metadata":{},"score":"46.424606"}
{"text":"Research to date has focussed primarily on decoding with such models , but less on the difficult problem of inducing the bilingual grammar from data .We propose a generative Bayesian model of tree - to - string translation which induces grammars that are both smaller and pro - duce better translations than the previous heuristic two - stage approach which em - ploys a separate word alignment step . \" ...","label":"CompareOrContrast","metadata":{},"score":"46.543945"}
{"text":"Research to date has focussed primarily on decoding with such models , but less on the difficult problem of inducing the bilingual grammar from data .We propose a generative Bayesian model of tree - to - string translation which induces grammars that are both smaller and pro - duce better translations than the previous heuristic two - stage approach which em - ploys a separate word alignment step . \" ...","label":"CompareOrContrast","metadata":{},"score":"46.543945"}
{"text":"Phrase - based translation models usually memorize local translation literally and make independent assumption between phrases which makes it neither generalize well on unseen data nor model sentence - level effects between phrases .In this pa - per we present a new method to model correlations between phrases as a Markov model and meanwhile employ a robust smoothing strategy to provide better gen - eralization .","label":"CompareOrContrast","metadata":{},"score":"46.794044"}
{"text":"While the former is better able to memorize , the latter provides a more principled model that captures dependencies across phrasal boundaries .Some work has been done to combine insights from these two frameworks .A recent successful attempt showed the advantage of using phrasebased search on top of an N - gram - based model .","label":"CompareOrContrast","metadata":{},"score":"46.814556"}
{"text":"This paper in - troduces two improvements to LR decod - ing that make it comparable in translation quality to CKY - based Hiero . ... t edge of each span , due to the fact that the target side is built inside - out from sub - spans ( Heafield et al . , 2011 ; Heafield et al . , 2013 ) .","label":"CompareOrContrast","metadata":{},"score":"46.845596"}
{"text":"In practice , phrase - based or block - based translation models which ... . \" ...We present a new phrase - based conditional exponential family translation model for statistical machine translation .The model operates on a feature representation in which sentence level translations are represented by enumerating all the known phrase level translations that occur inside them .","label":"CompareOrContrast","metadata":{},"score":"46.865032"}
{"text":"Bai et al .focus on the problem of acquiring multiword expressions ( i.e. idioms ) , showing why typical word alignment methods fail , and using a combination of statistical association measures and heuristics to fix the problem , with small gains in Chinese - English .","label":"CompareOrContrast","metadata":{},"score":"46.896667"}
{"text":"Bai et al .focus on the problem of acquiring multiword expressions ( i.e. idioms ) , showing why typical word alignment methods fail , and using a combination of statistical association measures and heuristics to fix the problem , with small gains in Chinese - English .","label":"CompareOrContrast","metadata":{},"score":"46.896667"}
{"text":"We find that the use of WFSTs rather than k - best lists requires less pruning in translation search , resulting in fewer search errors , better parameter optimization , and improved translation performance .The direct generation of translation lattices in the target language can improve subsequent rescoring procedures , yielding further gains when applying long - span language models and Minimum Bayes Risk decoding .","label":"CompareOrContrast","metadata":{},"score":"46.916534"}
{"text":"Tools . \" ...We present the Carnegie Mellon University Stat - XFER group submission to the WMT 2011 shared translation task .We built a hybrid syntactic MT system for French - English using the Joshua decoder and an automatically acquired SCFG .","label":"CompareOrContrast","metadata":{},"score":"47.00669"}
{"text":"We present experiments on learning on 1.5 million training sentences , and show significant improvements over tuning discriminative models on small development sets . ... pora described in Table 1 .The translation direction is German - to - English .The SMT framework used in our experiments is hierarchical phrase - based translation ( Chiang , 2007 ) .","label":"CompareOrContrast","metadata":{},"score":"47.176495"}
{"text":"Statistical machine translation systems combine the pre - dictions of two directional models , typically using heuristic combination procedures like grow - diag - final .This paper presents a graph - ical model that embeds two directional align - ers into a single model .","label":"CompareOrContrast","metadata":{},"score":"47.217728"}
{"text":"Our evaluation shows an 1.1 - 3.2 % BLEU improvement over competitive baselines for Chinese - English and Arabic - English translation .I really enjoyed Mark Dredze 's talk at EMNLP on multiclass confidence weighted algorithms , where they take their CW binary predictors and extend them in two ( basically equivalent ) ways to a multiclass / structured setting ( warning : I have n't read the paper ! )","label":"CompareOrContrast","metadata":{},"score":"47.254295"}
{"text":"Gimpel & Smith use a relatively new formalism : quasi - synchronous dependency grammar ( QDG ) .In quasi - synchronous grammar , the generation of a target syntax tree is conditioned on ( but not necessarily isomorphic to ) a source syntax tree .","label":"CompareOrContrast","metadata":{},"score":"47.345375"}
{"text":"Gimpel & Smith use a relatively new formalism : quasi - synchronous dependency grammar ( QDG ) .In quasi - synchronous grammar , the generation of a target syntax tree is conditioned on ( but not necessarily isomorphic to ) a source syntax tree .","label":"CompareOrContrast","metadata":{},"score":"47.345375"}
{"text":"In this paper we present a dynamic programming algorithm for GNF rule extraction which efficiently ex - tracts sentence level SCFG rule sets with an arbitrary number of non - terminals .We analyze the performance of the obtained grammar for statistical machine translation on three language pairs . ...","label":"CompareOrContrast","metadata":{},"score":"47.413708"}
{"text":"Tree substitution grammars ( TSGs ) offer many advantages over context - free grammars ( CFGs ) , but are hard to learn .Past approaches have resorted to heuristics .In this paper , we learn a TSG using Gibbs sampling with a nonparametric prior to control subtree size .","label":"CompareOrContrast","metadata":{},"score":"47.45275"}
{"text":"Tree substitution grammars ( TSGs ) offer many advantages over context - free grammars ( CFGs ) , but are hard to learn .Past approaches have resorted to heuristics .In this paper , we learn a TSG using Gibbs sampling with a nonparametric prior to control subtree size .","label":"CompareOrContrast","metadata":{},"score":"47.45275"}
{"text":"Most models define multiple derivations for each translation ; the probability of a translation is thus the sum over all of its derivations .Unfortunately , finding the maximum ... . \" ...We describe our experiments with training algorithms for tree - to - tree synchronous tree - substitution grammar ( STSG ) for monolingual translation tasks such as sentence compression and paraphrasing .","label":"CompareOrContrast","metadata":{},"score":"47.633175"}
{"text":"Most models define multiple derivations for each translation ; the probability of a translation is thus the sum over all of its derivations .Unfortunately , finding the maximum ... . \" ...We describe our experiments with training algorithms for tree - to - tree synchronous tree - substitution grammar ( STSG ) for monolingual translation tasks such as sentence compression and paraphrasing .","label":"CompareOrContrast","metadata":{},"score":"47.633175"}
{"text":"This year there 's a lot of work investigating more expressive formalisms .Two papers model translation with restricted variants of synchronous tree - adjoining grammar ( STAG ) .Carreras & Collins model syntax atop phrase pairs with a parser using sister adjunction ( as in their 2008 parser ) .","label":"CompareOrContrast","metadata":{},"score":"47.71033"}
{"text":"This year there 's a lot of work investigating more expressive formalisms .Two papers model translation with restricted variants of synchronous tree - adjoining grammar ( STAG ) .Carreras & Collins model syntax atop phrase pairs with a parser using sister adjunction ( as in their 2008 parser ) .","label":"CompareOrContrast","metadata":{},"score":"47.71033"}
{"text":"Permutation parsers have been used to implement hierarchical re - ordering models ( Galley and Manning , 2008 ) and to enforce inversion transduction grammar ( ITG ) constraints ( Feng et al . , 2010 ) .We present a number of theoretical results regarding the use of permutation parsers in PBSMT .","label":"CompareOrContrast","metadata":{},"score":"47.865715"}
{"text":"Our models leverage parallel data and learn to strongly align the embeddings of semantically equivalent sentences , while maintaining sufficient distance between those of dissimilar sentences .The mod - els do not rely on word alignments or any syntactic information and are success - fully applied to a number of diverse lan - guages .","label":"CompareOrContrast","metadata":{},"score":"47.919434"}
{"text":"Using a variety of intrinsic and extrinsic measures , including translation performance , we show our model yields better alignments than generative baselines in a number of language pairs . \" ...With a few exceptions , discriminative training in statistical machine translation ( SMT ) has been content with tuning weights for large feature sets on small development data .","label":"CompareOrContrast","metadata":{},"score":"47.954895"}
{"text":"We begin with structures from standard parsing and alignment tools , then use the EM algorithm to revise these structures in light of the translation task .We report an overall +1.48 BLEU improvement on a standard Chinese - to - English test . .","label":"CompareOrContrast","metadata":{},"score":"48.002083"}
{"text":"This paper extends previous work on extracting parallel sentence pairs from comparable data ( Munteanu and Marcu , 2005 ) .For a given source sentence S , a maximum entropy ( ME ) classifier is applied to a large set of candidate target translations .","label":"CompareOrContrast","metadata":{},"score":"48.071102"}
{"text":"This paper extends previous work on extracting parallel sentence pairs from comparable data ( Munteanu and Marcu , 2005 ) .For a given source sentence S , a maximum entropy ( ME ) classifier is applied to a large set of candidate target translations .","label":"CompareOrContrast","metadata":{},"score":"48.071102"}
{"text":"Inspired by ideas from slice sampling , our sampler is able to draw samples from the posterior distributions of models for which the standard dynamic programing based sampler proves intra ... \" .This paper describes an efficient sampler for synchronous grammar induction under a nonparametric Bayesian prior .","label":"CompareOrContrast","metadata":{},"score":"48.31189"}
{"text":"Inspired by ideas from slice sampling , our sampler is able to draw samples from the posterior distributions of models for which the standard dynamic programing based sampler proves intra ... \" .This paper describes an efficient sampler for synchronous grammar induction under a nonparametric Bayesian prior .","label":"CompareOrContrast","metadata":{},"score":"48.31189"}
{"text":"On the algorithmic side , Levenberg & Osborne look at language modeling under the condition that we have unbounded data streams in both source and target language , bounded computation , and the desire to bias our language model towards more recent language use without constantly retraining it .","label":"CompareOrContrast","metadata":{},"score":"48.34419"}
{"text":"On the algorithmic side , Levenberg & Osborne look at language modeling under the condition that we have unbounded data streams in both source and target language , bounded computation , and the desire to bias our language model towards more recent language use without constantly retraining it .","label":"CompareOrContrast","metadata":{},"score":"48.34419"}
{"text":"Finally , we describe a two - pass coarse - to - fine parsing approach that prunes the search space using predictions from a subset of the original grammar .In all , parsing time reduces by 81 % .We also describe a coarse - to - fine pruning scheme for forest - based language model reranking that allows a 100-fold increase in beam size while reducing decoding time .","label":"CompareOrContrast","metadata":{},"score":"48.595406"}
{"text":"We achieve improvements against a number of baselines , including expectation maximization and variational Bayes training , illustrating the merits of nonparametric inference over the space of grammars as opposed to sparse parametric inference with a fixed grammar .Segmentation is achieved by introducing a prior bias towards grammars that are compact representations of the data , namely by enforcing simplicity and ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"48.742027"}
{"text":"We achieve improvements against a number of baselines , including expectation maximization and variational Bayes training , illustrating the merits of nonparametric inference over the space of grammars as opposed to sparse parametric inference with a fixed grammar .Segmentation is achieved by introducing a prior bias towards grammars that are compact representations of the data , namely by enforcing simplicity and ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"48.742027"}
{"text":"Results show that accounting for multiple derivations does indeed improve performance .Additionally , we show that regularisation is essential for maximum conditional likelihood models in order to avoid degenerate solutions .In this paper we directly address the problem of spurious ambiguity in discriminative models .","label":"CompareOrContrast","metadata":{},"score":"49.014473"}
{"text":"We present a new phrase - based conditional exponential family translation model for statistical machine translation .The model operates on a feature representation in which sentence level translations are represented by enumerating all the known phrase level translations that occur inside them .","label":"CompareOrContrast","metadata":{},"score":"49.15718"}
{"text":"As an example application , they perform minimum risk training on a small Chinese - English task , reporting gains in accuracy .For a related paper on minimum risk techniques , see the poster by Pauls et al . .Novel Modeling and Learning Approaches .","label":"CompareOrContrast","metadata":{},"score":"49.4524"}
{"text":"As an example application , they perform minimum risk training on a small Chinese - English task , reporting gains in accuracy .For a related paper on minimum risk techniques , see the poster by Pauls et al . .Novel Modeling and Learning Approaches .","label":"CompareOrContrast","metadata":{},"score":"49.4524"}
{"text":"WORKSHOP FINITE - STATE METHODS AND NATURAL LANGUAGE PROCESSING , 2009 . \" ...We present a determinization construction for weighted tree automata using factorizations .Among others , this result subsumes a previous result for determinization of weighted string automata using factorizations ( Kirsten and Mäurer , 2005 ) and two previous results for weighted tree automata , one of ... \" .","label":"CompareOrContrast","metadata":{},"score":"49.496452"}
{"text":"Word - alignment information can be estimated from alignment models , such as the IBM alignment models ( Brown et al . , 19 ... . by Maryam Siahbani , Anoop Sarkar - In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing , 2014 . \" ...","label":"CompareOrContrast","metadata":{},"score":"49.63585"}
{"text":"The decoder does n't quite beat Moses when used with a language model , but it 's an order of magnitude faster !Three other papers operate on STSG models , with an emphasis on learning techniques .Cohn & Blunsom reformulate tree - to - string STSG induction as a problem in non - parametric Bayesian inference , extending their TSG model for monolingual parsing , and removing the dependence on heuristics over noisy GIZA++ word alignments .","label":"CompareOrContrast","metadata":{},"score":"50.146008"}
{"text":"The decoder does n't quite beat Moses when used with a language model , but it 's an order of magnitude faster !Three other papers operate on STSG models , with an emphasis on learning techniques .Cohn & Blunsom reformulate tree - to - string STSG induction as a problem in non - parametric Bayesian inference , extending their TSG model for monolingual parsing , and removing the dependence on heuristics over noisy GIZA++ word alignments .","label":"CompareOrContrast","metadata":{},"score":"50.146008"}
{"text":"Factoring a Synchronous Context - Free Grammar into an equivalent grammar with a smaller number of nonterminals in each rule enables synchronous parsing algorithms of lower complexity .The problem can be formalized as searching for the tree - decomposition of a given permutation with the minimal branching factor .","label":"CompareOrContrast","metadata":{},"score":"50.338287"}
{"text":"A second contribution concerns devising a lexicalized phrase reordering mechanism that has complimentary strengths to Chiang 's model .The latter conditions reordering decisions on the surrounding lexical context of phrases , whereas our mechanism works with the lexical content of phrase pairs ( akin to standard phrase - based systems ) .","label":"CompareOrContrast","metadata":{},"score":"50.526726"}
{"text":"Probabilistic phrase - based synchronous grammars are now considered promising devices for statistical machine translation because they can express reordering phenomena between pairs of languages .Learning these hierarchical , probabilistic devices from parallel corpora constitutes a major challenge , b ... \" .","label":"CompareOrContrast","metadata":{},"score":"50.70217"}
{"text":"In this thesis , we first demonstrate that the set of category labels used in a machine translation system 's grammar strongly affects three inter - related characteristics of the system : spurious ambiguity , rule sparsity , and reordering precision .","label":"CompareOrContrast","metadata":{},"score":"51.033424"}
{"text":"by Graham Neubig , Taro Watanabe , Eiichiro Sumita , Shinsuke Mori , Tatsuya Kawahara . \" ...We present an unsupervised model for joint phrase alignment and extraction using nonparametric Bayesian methods and inversion transduction grammars ( ITGs ) .The key contribution is that phrases of many granularities are included directly in the model through the use of a novel formulation that memori ... \" .","label":"CompareOrContrast","metadata":{},"score":"51.22264"}
{"text":"Finally , as our main work , we propose three automatic relabeling methods that will create a better set of category labels for a given language pair .Spurious ambiguity can also lead to flattening of distributions conditioned on the left - hand side , as more right- ...","label":"CompareOrContrast","metadata":{},"score":"51.289574"}
{"text":"We present an efficient , novel two - pass approach to mitigate the computational impact resulting from online intersection of an n - gram language model ( LM ) and a probabilistic synchronous context - free grammar ( PSCFG ) for statistical machine translation .","label":"CompareOrContrast","metadata":{},"score":"51.382935"}
{"text":"But the constraine ... \" .Left - to - right ( LR ) decoding Watanabe et al .( 2006 ) is a promising decoding algorithm for hi - erarchical phrase - based translation ( Hiero ) that visits input spans in arbitrary order producing the output translation in left to right order .","label":"CompareOrContrast","metadata":{},"score":"51.44508"}
{"text":"Then they show how to learn the matrix and use it to reorder test sentences prior to translation , improving over the lexicalized reordering model of Moses on German - English .However , most of the new models at EMNLP are syntax - based .","label":"CompareOrContrast","metadata":{},"score":"51.448753"}
{"text":"Then they show how to learn the matrix and use it to reorder test sentences prior to translation , improving over the lexicalized reordering model of Moses on German - English .However , most of the new models at EMNLP are syntax - based .","label":"CompareOrContrast","metadata":{},"score":"51.448753"}
{"text":"Moreover , we devise a fast training algorithm to achieve such improved models based on tree kernel methods .Experiments on an English - to - Chinese task demonstrate that our proposed models outperformed the baseline formally syntaxbased models , while both of them achieved . ... ed 1 The complexity is dominated by synchronous parsing and boundary words keeping .","label":"CompareOrContrast","metadata":{},"score":"51.610424"}
{"text":"Most approaches report problems with overfitting .We describe a novel leavingone - out approach to prevent ov ... \" .Several attempts have been made to learn phrase translation probabilities for phrasebased statistical machine translation that go beyond pure counting of phrases in word - aligned training data .","label":"CompareOrContrast","metadata":{},"score":"51.935226"}
{"text":"Most approaches report problems with overfitting .We describe a novel leavingone - out approach to prevent ov ... \" .Several attempts have been made to learn phrase translation probabilities for phrasebased statistical machine translation that go beyond pure counting of phrases in word - aligned training data .","label":"CompareOrContrast","metadata":{},"score":"51.935226"}
{"text":"The key contribution is that phrases of many granularities are included directly in the model through the use of a novel formulation that memorizes phrases generated not only by terminal , but also non - terminal symbols .This allows for a completely probabilistic model that is able to create a phrase table that achieves competitive accuracy on phrase - based machine translation tasks directly from unaligned sentence pairs .","label":"CompareOrContrast","metadata":{},"score":"51.96827"}
{"text":"The resulting system shows substantial improvements in both alignment quality and translation quality over word - based Hidden Markov Models , while maintaining asymptotically equivalent runtime . ...e free parameters from above were tuned to optimize development set BLEU using grid search . 8 Conclusions and Future Work We have described an algorithm for efficient unsupervised alignment of phrases .","label":"CompareOrContrast","metadata":{},"score":"52.191406"}
{"text":"The approach is built on top of a novel reduction - based weighted synchronous context free grammar formalism , which facilitates the trans ... \" .This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus .","label":"CompareOrContrast","metadata":{},"score":"52.19408"}
{"text":"While the former is better able to memorize , the latter provides a more principled model that captures dependencies across phrasal boundaries .Some work has been done to combine insights from these two frameworks .A recent succe ... \" .","label":"CompareOrContrast","metadata":{},"score":"52.216877"}
{"text":"Kääriäinen makes this idea central .Instead of reasoning over the latent derivations of a generative model , his model directly optimizes a feature - based representation of the target sentence , where the features consist of any biphrase in the training set ( per standard heuristics ) .","label":"CompareOrContrast","metadata":{},"score":"52.221092"}
{"text":"Kääriäinen makes this idea central .Instead of reasoning over the latent derivations of a generative model , his model directly optimizes a feature - based representation of the target sentence , where the features consist of any biphrase in the training set ( per standard heuristics ) .","label":"CompareOrContrast","metadata":{},"score":"52.221092"}
{"text":"These models fundamentally differ from ours in that they stipulat ... . \" ...Recent advances in statistical machine translation have used beam search for approximate NP - complete inference within probabilistic translation models .We present an alternative approach of sampling from the posterior distribution defined by a translation model .","label":"CompareOrContrast","metadata":{},"score":"52.378128"}
{"text":"These models fundamentally differ from ours in that they stipulat ... . \" ...Recent advances in statistical machine translation have used beam search for approximate NP - complete inference within probabilistic translation models .We present an alternative approach of sampling from the posterior distribution defined by a translation model .","label":"CompareOrContrast","metadata":{},"score":"52.378128"}
{"text":"Finally , we employ cube pruning ( Chiang 2007 ) for further efficiency in the search .When scoring translation candidates , we add several smaller models .One model rewards longer translation candidat ... .by Kevin Knight - In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ( EMNLP - CoNLL-2007 , 2007 . \" ...","label":"CompareOrContrast","metadata":{},"score":"52.411285"}
{"text":"However , we can emplo ... . \" ...We present a discriminative model that di - rectly predicts which set of phrasal transla - tion rules should be extracted from a sen - tence pair .Our model scores extraction sets : nested collections of all the overlap - ping phrase pairs consistent with an under - lying word alignment .","label":"CompareOrContrast","metadata":{},"score":"52.422596"}
{"text":"We present an approach to semantics - based statistical machine translation that uses synchronous hyperedge replacement grammars to translate into and from graph - shaped intermediate meaning representations , to our knowledge the first work in NLP to make use of synchronous context free graph grammars .","label":"CompareOrContrast","metadata":{},"score":"52.66433"}
{"text":"This article shows that the structure of bilingual material from standard parsing and alignment tools is not optimal for training syntax - based statistical machine translation ( SMT ) systems .Better structures , labels , and word alignments are learned by the EM algorithm .","label":"CompareOrContrast","metadata":{},"score":"52.74448"}
{"text":"This article shows that the structure of bilingual material from standard parsing and alignment tools is not optimal for training syntax - based statistical machine translation ( SMT ) systems .Better structures , labels , and word alignments are learned by the EM algorithm .","label":"CompareOrContrast","metadata":{},"score":"52.74448"}
{"text":"Since in dependency grammar the nodes are words , their QDG model resembles a word - to - word model .Decoding with QDG was not obvious given past work , and is one of several novel contributions of the paper .","label":"CompareOrContrast","metadata":{},"score":"52.77803"}
{"text":"Since in dependency grammar the nodes are words , their QDG model resembles a word - to - word model .Decoding with QDG was not obvious given past work , and is one of several novel contributions of the paper .","label":"CompareOrContrast","metadata":{},"score":"52.77803"}
{"text":"Our model scores extraction sets : nested collections of all the overlap - ping phrase pairs consistent with an under - lying word alignment .Extraction set mod - els ... \" .We present a discriminative model that di - rectly predicts which set of phrasal transla - tion rules should be extracted from a sen - tence pair .","label":"CompareOrContrast","metadata":{},"score":"52.85273"}
{"text":"Our model scores extraction sets : nested collections of all the overlap - ping phrase pairs consistent with an under - lying word alignment .Extraction set mod - els ... \" .We present a discriminative model that di - rectly predicts which set of phrasal transla - tion rules should be extracted from a sen - tence pair .","label":"CompareOrContrast","metadata":{},"score":"52.85273"}
{"text":"Results are reported on the 2008 NIST Arabic - to - English evaluation task . \" ...Language Weaver , Inc.This article shows that the structure of bilingual material from standard parsing and alignment tools is not optimal for training syntax - based statistical machine translation ( SMT ) systems .","label":"CompareOrContrast","metadata":{},"score":"52.857933"}
{"text":"Li & Eisner show how to compute a huge number of statistics efficiently over a combinatorially large number of hypotheses represented in a hypergraph .The statistics include expected hypothesis length , feature expectation , entropy , cross - entropy , KL divergence , Bayes risk , variance of hypothesis length , gradient of entropy and Bayes risk , covariance and Hessian matrix .","label":"CompareOrContrast","metadata":{},"score":"52.90194"}
{"text":"Li & Eisner show how to compute a huge number of statistics efficiently over a combinatorially large number of hypotheses represented in a hypergraph .The statistics include expected hypothesis length , feature expectation , entropy , cross - entropy , KL divergence , Bayes risk , variance of hypothesis length , gradient of entropy and Bayes risk , covariance and Hessian matrix .","label":"CompareOrContrast","metadata":{},"score":"52.90194"}
{"text":"DeNeefe & Knight model target - side syntax via synchronous tree insertion grammar ( STIG ) .It 's similar to synchronous tree substitution grammar ( STSG ; previously realized in MT as GHKM ) with added left- and right - adjunction operations to model optional arguments .","label":"CompareOrContrast","metadata":{},"score":"53.091866"}
{"text":"DeNeefe & Knight model target - side syntax via synchronous tree insertion grammar ( STIG ) .It 's similar to synchronous tree substitution grammar ( STSG ; previously realized in MT as GHKM ) with added left- and right - adjunction operations to model optional arguments .","label":"CompareOrContrast","metadata":{},"score":"53.091866"}
{"text":"Word class language models can be used to integrate longer context with a reduced vocabulary size .Rule table interpolation is applicable for different tasks , e.g. domain adaptation .The decoder distinguishes between lexical and coverage pruning and applies reordering constraints for efficiency . .","label":"CompareOrContrast","metadata":{},"score":"53.15799"}
{"text":"Our bidirectional model en - forces a one - to - one phrase constraint while ac - counting for the uncertainty in the underlying directional models .The resulting alignments improve upon baseline combination heuristics in word - level and phrase - level evaluations .","label":"CompareOrContrast","metadata":{},"score":"53.382957"}
{"text":"The model 's predictions are properly normalized probabilities .In addition , the model automatically takes into account information provided by phrase overlaps , and does not suffer from reference translation reachability problems .We have implemented an open source translation system Sinuhe based on the proposed translation model .","label":"CompareOrContrast","metadata":{},"score":"53.42058"}
{"text":"take their previous triplet lexicon model ( a probabilistic feature using an outside source word as additional conditioning context ) and move it from a reranking step into the decoding step , with a nice experimental treatment showing improvements in large - scale Chinese - English and Arabic - English .","label":"CompareOrContrast","metadata":{},"score":"53.756332"}
{"text":"take their previous triplet lexicon model ( a probabilistic feature using an outside source word as additional conditioning context ) and move it from a reranking step into the decoding step , with a nice experimental treatment showing improvements in large - scale Chinese - English and Arabic - English .","label":"CompareOrContrast","metadata":{},"score":"53.756332"}
{"text":"Our open - source ( LGPL ) implementation is also available for download as a standalone package with minimal ( POSIX ... . by Juri Ganitkevitch , Chris Callison - burch , Courtney Napoles , Benjamin Van Durme . \" ...Previous work has shown that high quality phrasal paraphrases can be extracted from bilingual parallel corpora .","label":"CompareOrContrast","metadata":{},"score":"53.871666"}
{"text":"The tree - transducer grammars that arise in current syntactic machine translation systems are large , flat , and highly lexicalized .We address the problem of parsing efficiently with such grammars in three ways .First , we present a pair of grammar transformations that admit an efficient cubic - time CKY - style parsing algorithm despite leaving most of the grammar in n - ary form .","label":"CompareOrContrast","metadata":{},"score":"54.033054"}
{"text":"On Chinese - English this improves decoding speed and ultimately translation accuracy , because the decoder can consider larger fragments much more efficiently .Finally , see Finch & Sumita 's comprehensive poster on bidirectional phrase - based decoding for a huge number of language pairs .","label":"CompareOrContrast","metadata":{},"score":"54.326584"}
{"text":"On Chinese - English this improves decoding speed and ultimately translation accuracy , because the decoder can consider larger fragments much more efficiently .Finally , see Finch & Sumita 's comprehensive poster on bidirectional phrase - based decoding for a huge number of language pairs .","label":"CompareOrContrast","metadata":{},"score":"54.326584"}
{"text":"g tasks that search for a hidden segmentation .In this paper we apply these techniques to learn a tree substitution grammar , evaluate it on the Wall Street Journal parsing task , and compare it to previous work .2 Model 2 ... .","label":"CompareOrContrast","metadata":{},"score":"54.414165"}
{"text":"We present a discriminative model that di - rectly predicts which set of phrasal transla - tion rules should be extracted from a sen - tence pair .Our model scores extraction sets : nested collections of all the overlap - ping phrase pairs consistent with an under - lying word alignment .","label":"CompareOrContrast","metadata":{},"score":"54.460335"}
{"text":"d many monolingual source - only and target - only patterns that are similar to those shown in Table 4 .Additionally we noted examples of source words triggering more target - side information than merely one word .There were several examples of patterns that encouraged inclusion of the subject in Engl ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"54.517887"}
{"text":"then extract phrases by relaxing standard heuristic constraints .Given a posterior probability for every alignment point , they simply calculate the probability that a phrase would be extracted , and use this as their count in the typical frequency - based estimate .","label":"CompareOrContrast","metadata":{},"score":"54.65327"}
{"text":"then extract phrases by relaxing standard heuristic constraints .Given a posterior probability for every alignment point , they simply calculate the probability that a phrase would be extracted , and use this as their count in the typical frequency - based estimate .","label":"CompareOrContrast","metadata":{},"score":"54.65327"}
{"text":"Finally , we show that the best way to exploit source - totarget and target - to - source alignment models is to build two separate systems and combine their output translation lattices . ...n ITG to directly align phrases to nodes in a string - to - tree model .","label":"CompareOrContrast","metadata":{},"score":"55.13073"}
{"text":"For each source sentence S , a matching score is computed over al ..The novel decoding algorithm can handle tens of thousands of rules efficiently .An improvement over a standard phrase - based decoder is shown on an Arabic - English translation task with respect to translation accuracy and speed for large re - order window sizes .","label":"CompareOrContrast","metadata":{},"score":"55.24708"}
{"text":"This leads to far fewer language model calls , but while LR decod - i ... \" .Left - to - right ( LR ) decoding ( Watanabe et al . , 2006 ) is promising decoding algorithm for hierarchical phrase - based translation ( Hiero ) that visits input spans in arbitrary order producing the output translation in left to right order .","label":"CompareOrContrast","metadata":{},"score":"55.262394"}
{"text":"This leads to extraction of more useful linguistic patterns and improved B ... \" .We present a method for improving word alignment for statistical syntax - based machine translation that employs a syntactically informed alignment model closer to the translation model than commonly - used word alignment models .","label":"CompareOrContrast","metadata":{},"score":"55.3847"}
{"text":"Therefore , re - ordering must be modeled and constraine ... . \" ...Left - to - right ( LR ) decoding Watanabe et al .( 2006 ) is a promising decoding algorithm for hi - erarchical phrase - based translation ( Hiero ) that visits input spans in arbitrary order producing the output translation in left to right order .","label":"CompareOrContrast","metadata":{},"score":"55.440193"}
{"text":"In traditional ITG models , the branches of a biparse tree are generated from a nonterminal distribution , ... . \" ...In this work , we tackle the task of machine translation ( MT ) without parallel training data .We frame the MT problem as a decipherment task , treating the foreign text as a cipher for English and present novel methods for training translation models from nonparallel text .","label":"CompareOrContrast","metadata":{},"score":"55.57585"}
{"text":"Connecting Theory and Practice .A few papers combine deep theoretical insight with convincing empirical results .Hopkins & Langmead improve on cube pruning , a popular approximate search technique for structured models with non - local features ( i.e. translation with an integrated language model ) .","label":"CompareOrContrast","metadata":{},"score":"55.713524"}
{"text":"Connecting Theory and Practice .A few papers combine deep theoretical insight with convincing empirical results .Hopkins & Langmead improve on cube pruning , a popular approximate search technique for structured models with non - local features ( i.e. translation with an integrated language model ) .","label":"CompareOrContrast","metadata":{},"score":"55.713524"}
{"text":"This way , our novel algorithm avoids any document - level prefiltering step .The algorithm increases the number of extracted parallel sentence pairs significantly , which leads to a BLEU improvement of about 1 % on our Spanish - English data . ... translation in the other sentence , otherwise it is labeled as non - parallel .","label":"CompareOrContrast","metadata":{},"score":"55.766296"}
{"text":"Check out posters by He & Toutanova , Duan et al . , and Feng et al . to learn the latest techniques .Last but not least , if you need a strategy for language pairs with very little parallel data , the poster by Nakov & Ng will interest you .","label":"CompareOrContrast","metadata":{},"score":"55.979843"}
{"text":"Check out posters by He & Toutanova , Duan et al . , and Feng et al . to learn the latest techniques .Last but not least , if you need a strategy for language pairs with very little parallel data , the poster by Nakov & Ng will interest you .","label":"CompareOrContrast","metadata":{},"score":"55.979843"}
{"text":"We report on investigations into hierarchical phrase - based translation grammars based on rules extracted from posterior distributions over alignments of the parallel text .Rather than restrict rule extraction to a single alignment , such as Viterbi , we instead extract rules based on posterior distributions provided by the HMM word - to - word alignment model .","label":"CompareOrContrast","metadata":{},"score":"55.99114"}
{"text":", 2012 ) is developed in C++ and supports phrase - based , hierarchical phrase - based and syntax - based models . \" ...French ne voudrais pas voyager par chemin de fer We propose a principled and efficient phraseto - phrase alignment model , useful in machine translation as well as other related natural language processing problems .","label":"CompareOrContrast","metadata":{},"score":"56.07461"}
{"text":"Language Weaver , Inc.This article shows that the structure of bilingual material from standard parsing and alignment tools is not optimal for training syntax - based statistical machine translation ( SMT ) systems .We present three modifications to the MT training data to improve the accuracy of a stat ... \" .","label":"CompareOrContrast","metadata":{},"score":"56.37764"}
{"text":"Language Weaver , Inc.This article shows that the structure of bilingual material from standard parsing and alignment tools is not optimal for training syntax - based statistical machine translation ( SMT ) systems .We present three modifications to the MT training data to improve the accuracy of a stat ... \" .","label":"CompareOrContrast","metadata":{},"score":"56.37764"}
{"text":"We discuss how our model can be adapted to many text generation tasks by augmenting its feature set , development data , and parameter estimation routine .We illustrate this adaptation by using our paraphrase model for the task of sentence compression and achieve results competitive with state - of - the - art compression systems . .","label":"CompareOrContrast","metadata":{},"score":"56.59278"}
{"text":"Since German is a language that makes productive use of \" closed \" compounds ( compound words written as a single orthographic token ) , we use a CRF segmentation model of to evaluate the probability of ... .by Spence Green , Marie - catherine De Marneffe , John Bauer , Christopher D. Manning . \" ...","label":"CompareOrContrast","metadata":{},"score":"56.746468"}
{"text":"Research to date has focussed primarily on decoding with such models , but less on the difficult problem of inducing the bilingual grammar from data .We propose a generative Bayesian model of tree - to - string translation which induces grammars that are both smaller and pro - duce better translations than the previous heuristic two - stage approach which em - ploys a separate word alignment step . ... nary rule instance with its descendant rule(s ) to create a non - unary rule .","label":"CompareOrContrast","metadata":{},"score":"56.795666"}
{"text":"2 Model 2 ... .by Phil Blunsom , Chris Dyer , Trevor Cohn , Miles Osborne - In Proceedings of the Association for Computational Linguistics , 2009 . \" ...We present a phrasal synchronous gram - mar model of translational equivalence .","label":"CompareOrContrast","metadata":{},"score":"56.862885"}
{"text":"The idealistic path uses an unsupervised learning algorithm such as EM ( Demptser et al . , 1977 ) to learn parameters for some proposed translation model from a bitext training corpus , and then directly translates using the weighted model .","label":"CompareOrContrast","metadata":{},"score":"56.96955"}
{"text":"Inspired by ideas from slice sampling , our sampler is able to draw samples from the posterior distributions of models for which the standard dynamic programing based sampler proves intractable on non - trivial corpora .We compare our sampler to a previously proposed Gibbs sampler and demonstrate strong improvements in terms of both training log - likelihood and performance on an end - to - end translation evaluation .","label":"CompareOrContrast","metadata":{},"score":"57.116974"}
{"text":"To deal with the high degree of ambiguity present in this setting , we present a generative model that simultaneously segments the text into utterances and maps each utterance to a meaning representation grounded in the world state .We show that our model generalizes across three domains of increasing difficulty - Robocup sportscasting , weather forecasts ( a new domain ) , and NFL recaps .","label":"CompareOrContrast","metadata":{},"score":"57.169098"}
{"text":"Rule table interpolation is applicable for different tasks , e.g. domain adaptation .The decoder distinguishes between lexical and coverage pruning and applies reordering constraints for efficiency . ... is an open source machine translation package with a Java implementation of the phrase - based machine translation paradigm .","label":"CompareOrContrast","metadata":{},"score":"57.322193"}
{"text":"As a side effect , the phrase table size is reduced by more than 80 % . ... ning .They observe that due to several constraints and pruning steps , the trained phrase table is much smaller than the heuristically extracted one , while preserving translation quality .","label":"CompareOrContrast","metadata":{},"score":"57.558353"}
{"text":"As a side effect , the phrase table size is reduced by more than 80 % . ... ning .They observe that due to several constraints and pruning steps , the trained phrase table is much smaller than the heuristically extracted one , while preserving translation quality .","label":"CompareOrContrast","metadata":{},"score":"57.558353"}
{"text":"then show how a mixed - genre system can effectively be adapted for a particular target domain , by using a small amount data to tune weights tied to genre and collection types in the training corpus , again with strong results in Arabic - English .","label":"CompareOrContrast","metadata":{},"score":"57.676163"}
{"text":"then show how a mixed - genre system can effectively be adapted for a particular target domain , by using a small amount data to tune weights tied to genre and collection types in the training corpus , again with strong results in Arabic - English .","label":"CompareOrContrast","metadata":{},"score":"57.676163"}
{"text":"Sentences can then be generated based on such grammar rules with a log - linear model .To acquire such grammar rules automatically in an unsupervised manner , we also propose a novel approach with a generative model , which maps from sub - expressions of logical forms to word sequences in natural language sentences .","label":"CompareOrContrast","metadata":{},"score":"57.71142"}
{"text":"( 2009 ) extract rules directly from bilingual chart parses of the parallel corpus without using word alignments .We take a different approach in that we aim to start with ver ... . \" ...Machine transliteration is defined as automatic phonetic translation of names across languages .","label":"CompareOrContrast","metadata":{},"score":"57.752098"}
{"text":"19 Proceedings of the Second ACL Workshop on Syntax and Structure in Statistical Translation ( SSST-2 ) , ...Tools . \" ...A central problem in grounded language acquisition is learning the correspondences between a rich world state and a stream of text which references that world state .","label":"CompareOrContrast","metadata":{},"score":"58.01693"}
{"text":"The goal of t ... \" .With a few exceptions , discriminative training in statistical machine translation ( SMT ) has been content with tuning weights for large feature sets on small development data .Evidence from machine learning indicates that increasing the training sample size results in better prediction .","label":"CompareOrContrast","metadata":{},"score":"58.329285"}
{"text":"The proposed model outperforms the state - of - the - art EM - based model in the English to Chinese transliteration task .Tools . \" ...Statistical machine translation ( SMT ) treats the translation of natural language as a machine learning problem .","label":"CompareOrContrast","metadata":{},"score":"58.371513"}
{"text":"Previous work on MWE identification has relied primarily on surface statistics , which perform poorly for longer MWEs and can not model discontinuous expressions .To address these p ... \" .Multiword expressions ( MWE ) , a known nuisance for both linguistics and NLP , blur the lines between syntax and semantics .","label":"CompareOrContrast","metadata":{},"score":"58.504562"}
{"text":"Inference is per - formed using a novel Gibbs sampler over synchronous derivations .This sam - pler side - steps the intractability issues of previous models which required inference over derivation forests .Instead each sam - pling iteration is highly efficient , allowing the model to be applied to larger transla - tion corpora than previous approaches . \" ...","label":"CompareOrContrast","metadata":{},"score":"58.677094"}
{"text":"Inference is per - formed using a novel Gibbs sampler over synchronous derivations .This sam - pler side - steps the intractability issues of previous models which required inference over derivation forests .Instead each sam - pling iteration is highly efficient , allowing the model to be applied to larger transla - tion corpora than previous approaches . \" ...","label":"CompareOrContrast","metadata":{},"score":"58.677094"}
{"text":"Previous work has shown that high quality phrasal paraphrases can be extracted from bilingual parallel corpora .However , it is not clear whether bitexts are an appropriate resource for extracting more sophisticated sentential paraphrases , which are more obviously learnable from monolingual parallel corpora .","label":"CompareOrContrast","metadata":{},"score":"58.934208"}
{"text":"SMT has made tremendous strides in less than two decades , and many popular tec ... \" .Statistical machine translation ( SMT ) treats the translation of natural language as a machine learning problem .By examining many samples of human - produced translation , SMT algorithms automatically learn how to translate .","label":"CompareOrContrast","metadata":{},"score":"59.076714"}
{"text":"We believe that improvements from a better decoder implementation ... . \" ...The tree - transducer grammars that arise in current syntactic machine translation systems are large , flat , and highly lexicalized .We address the problem of parsing efficiently with such grammars in three ways .","label":"CompareOrContrast","metadata":{},"score":"59.414566"}
{"text":"The PROBING data structure uses linear probing hash tables and is designed for speed .Compared with the widelyused SRILM , our PROBING model is 2.4 times as fast while using 57 % of the memory .The TRIE data structure is a trie with bit - level packing , sorted records , interpolation search , and optional quantization aimed at lower memory consumption .","label":"CompareOrContrast","metadata":{},"score":"59.51356"}
{"text":"I 'd like a single number that I can look at .Here are two concrete proposals for what such a number could be ( note : I 'm assuming you 're also going to provide performance numbers at the best possible selection of hyperparameters from development data or cross validation ...","label":"CompareOrContrast","metadata":{},"score":"59.54249"}
{"text":"But the constrained SCFG grammar used in LR - Hiero ( GNF ) with at most two non - terminals is unable to account for some complex phrasal reordering .Allowing more non - terminals in the rules results in a more expressive grammar .","label":"CompareOrContrast","metadata":{},"score":"59.746742"}
{"text":"The model is like IBM Model 1 , except that the source positions are actually substrings of the source instead of single positions .Reasoning over the substring boundaries makes it resemble an HMM , and they use a sparse prior to avoid overfitting .","label":"CompareOrContrast","metadata":{},"score":"59.819263"}
{"text":"The model is like IBM Model 1 , except that the source positions are actually substrings of the source instead of single positions .Reasoning over the substring boundaries makes it resemble an HMM , and they use a sparse prior to avoid overfitting .","label":"CompareOrContrast","metadata":{},"score":"59.819263"}
{"text":"The align / extract / MERT pipeline popularized by Moses and other NIST - style systems is incredibly hard to improve , but several papers manage just that .Hermjakob 's word aligner starts from lexical translation parameters learned by a statistical alignment model .","label":"CompareOrContrast","metadata":{},"score":"59.90535"}
{"text":"The align / extract / MERT pipeline popularized by Moses and other NIST - style systems is incredibly hard to improve , but several papers manage just that .Hermjakob 's word aligner starts from lexical translation parameters learned by a statistical alignment model .","label":"CompareOrContrast","metadata":{},"score":"59.90535"}
{"text":"I occasionally feel that my colleagues on far reaches of either side of this spectrum are too dismissive of work on the other side ; we need both if we 're going to improve translation .Outside the Box .Before giving you a guided tour through that spectrum , I want to highlight one paper that I found thought - provoking , but hard to classify .","label":"CompareOrContrast","metadata":{},"score":"60.13732"}
{"text":"I occasionally feel that my colleagues on far reaches of either side of this spectrum are too dismissive of work on the other side ; we need both if we 're going to improve translation .Outside the Box .Before giving you a guided tour through that spectrum , I want to highlight one paper that I found thought - provoking , but hard to classify .","label":"CompareOrContrast","metadata":{},"score":"60.13732"}
{"text":"For wor ... . \" ...This paper describes the German - English translation system developed by the ARK research group at Carnegie Mellon University for the Sixth Workshop on Machine Translation ( WMT11 ) .We present the results of several modeling and training improvements to our core hierarchical phrase - based translation s ... \" .","label":"CompareOrContrast","metadata":{},"score":"60.20598"}
{"text":"Syn - tax can inform lexical selection and re - ordering choices and thereby improve translation quality .Research to date has focussed primarily on decoding with such models , but less ... \" .Tree based translation models are a com - pelling means of integrating linguistic in - formation into machine translation .","label":"CompareOrContrast","metadata":{},"score":"60.23291"}
{"text":"Syn - tax can inform lexical selection and re - ordering choices and thereby improve translation quality .Research to date has focussed primarily on decoding with such models , but less ... \" .Tree based translation models are a com - pelling means of integrating linguistic in - formation into machine translation .","label":"CompareOrContrast","metadata":{},"score":"60.23291"}
{"text":"Syn - tax can inform lexical selection and re - ordering choices and thereby improve translation quality .Research to date has focussed primarily on decoding with such models , but less ... \" .Tree based translation models are a com - pelling means of integrating linguistic in - formation into machine translation .","label":"CompareOrContrast","metadata":{},"score":"60.23291"}
{"text":"Extraction set mod - els provide two principle advantages over word - factored alignment models .First , we can incorporate features on phrase pairs , in addition to word links .Second , we can optimize for an extraction - based loss function that relates directly to the end task of generating translations .","label":"CompareOrContrast","metadata":{},"score":"60.371048"}
{"text":"Extraction set mod - els provide two principle advantages over word - factored alignment models .First , we can incorporate features on phrase pairs , in addition to word links .Second , we can optimize for an extraction - based loss function that relates directly to the end task of generating translations .","label":"CompareOrContrast","metadata":{},"score":"60.371048"}
{"text":"We describe a novel leavingone - out approach to prevent over - fitting that allows us to train phrase models that show improved translation performance on the WMT08 Europarl German - English task .In contrast to most previous work where phrase models were trained separately from other models used in translation , we include all components such as single word lexica and reordering models in training .","label":"CompareOrContrast","metadata":{},"score":"60.417397"}
{"text":"We describe a novel leavingone - out approach to prevent over - fitting that allows us to train phrase models that show improved translation performance on the WMT08 Europarl German - English task .In contrast to most previous work where phrase models were trained separately from other models used in translation , we include all components such as single word lexica and reordering models in training .","label":"CompareOrContrast","metadata":{},"score":"60.417397"}
{"text":"Many - to - many methods can be expected to achieve superior results on character - based alignment , as the aligner can use information about substrings , which may correspond to lett ... . \" ...We report on investigations into hierarchical phrase - based translation grammars based on rules extracted from posterior distributions over alignments of the parallel text .","label":"CompareOrContrast","metadata":{},"score":"61.18937"}
{"text":"Language Weaver , Inc.This article shows that the structure of bilingual material from standard parsing and alignment tools is not optimal for training syntax - based statistical machine translation ( SMT ) systems .Better structures , labels , and word alignments are learned by the EM algorithm .","label":"CompareOrContrast","metadata":{},"score":"61.444344"}
{"text":"Recent advances in statistical machine translation have used beam search for approximate NP - complete inference within probabilistic translation models .We present an alternative approach of sampling from the posterior distribution defined by a translation model .We define a novel Gibbs sampler for sampling translations given a source sentence and show that it effectively explores this posterior distribution .","label":"CompareOrContrast","metadata":{},"score":"61.882988"}
{"text":"Recent advances in statistical machine translation have used beam search for approximate NP - complete inference within probabilistic translation models .We present an alternative approach of sampling from the posterior distribution defined by a translation model .We define a novel Gibbs sampler for sampling translations given a source sentence and show that it effectively explores this posterior distribution .","label":"CompareOrContrast","metadata":{},"score":"61.882988"}
{"text":"We assess these grammars in terms of their expressive power , measured by their ability to align the parallel text from which their rules are extracted , and the quality of the translations they yield .In Chinese - to - English translation , we find that rule extraction from posteriors gives translation improvements .","label":"CompareOrContrast","metadata":{},"score":"61.902344"}
{"text":"In statistical machine translation , a researcher seeks to determine whether some innovation ( e.g. , a new feature , model , or inference algorithm ) improves translation quality in comparison to a baseline system .To answer this question , he runs an experiment to evaluate the behavior of the two systems on held - out data .","label":"CompareOrContrast","metadata":{},"score":"62.03631"}
{"text":"The decoder is implemented with standard Weighted Finite - State Transducer ( WFST ) operations as an alternative to the well - known cube pruning procedure .We find that the use of WFSTs ra ... \" .In this article we describe HiFST , a lattice - based decoder for hierarchical phrase - based translation and alignment .","label":"CompareOrContrast","metadata":{},"score":"62.06298"}
{"text":"This survey presents a tutorial overview of state - of - the - art SMT at the beginning of 2007 .We begin with the context of the current research , and then move to a formal problem description and an overview of the four main subproblems : translational equivalence modeling , mathematical modeling , parameter estimation , and decoding .","label":"CompareOrContrast","metadata":{},"score":"62.196518"}
{"text":"In this paper , we demonstrate that accurate machine translation is possible without the concept of \" words , \" treating MT as a problem of transformation between character strings .We achieve this result by applying phrasal inversion transduction grammar alignment techniques to character strings to tr ... \" .","label":"CompareOrContrast","metadata":{},"score":"62.45836"}
{"text":"On NIST MT08 set , our most advanced model brings around +2.0 BLEU and-1.0 TER improvement .","label":"CompareOrContrast","metadata":{},"score":"62.480324"}
{"text":"French ne voudrais pas voyager par chemin de fer We propose a principled and efficient phraseto - phrase alignment model , useful in machine translation as well as other related natural language processing problems .In a hidden semi - Markov model , word - to - phrase and phraseto - word translations are modeled directly by the system .","label":"CompareOrContrast","metadata":{},"score":"62.5179"}
{"text":"Large - scale discriminative machine translation promises to further the state - of - the - art , but has failed to deliver convincing gains over current heuristic frequency count systems .We argue that a principle reason for this failure is not dealing with multiple , equivalent translations .","label":"CompareOrContrast","metadata":{},"score":"62.61422"}
{"text":"Large - scale discriminative machine translation promises to further the state - of - the - art , but has failed to deliver convincing gains over current heuristic frequency count systems .We argue that a principle reason for this failure is not dealing with multiple , equivalent translations .","label":"CompareOrContrast","metadata":{},"score":"62.61422"}
{"text":"\" ...Unsupervised word alignment is most often modeled as a Markov process that generates a sentence f conditioned on its translation e. A similar model generating e from f will make different alignment predictions .Statistical machine translation systems combine the pre - dictions of two directional model ... \" .","label":"CompareOrContrast","metadata":{},"score":"62.926537"}
{"text":"A central problem in grounded language acquisition is learning the correspondences between a rich world state and a stream of text which references that world state .To deal with the high degree of ambiguity present in this setting , we present a generative model that simultaneously segments the text into utterances and maps each utterance to a meaning representation grounded in the world state .","label":"CompareOrContrast","metadata":{},"score":"62.949196"}
{"text":"It 's still globally approximate , but exact for the local prediction problem that cube pruning solves ( i.e. , what are the n - best state splits of an item , given the n - best input states from previous deductions ? )","label":"CompareOrContrast","metadata":{},"score":"62.950253"}
{"text":"It 's still globally approximate , but exact for the local prediction problem that cube pruning solves ( i.e. , what are the n - best state splits of an item , given the n - best input states from previous deductions ? )","label":"CompareOrContrast","metadata":{},"score":"62.950253"}
{"text":"Restrictions to the grammar afford alternative decoding strategies to reduce the runtime cost of synchronous parsing .( Wellington et al . , 2006 ) argue that these restrictions reduce our ability to model ... . by Gonzalo Iglesias , Adrià Gispert - In Proceedings of the EACL , 2009 . \" ...","label":"CompareOrContrast","metadata":{},"score":"63.69024"}
{"text":"Performance at a default setting of the hyperparameter .For instance , SVM - light uses something like average inverse norm of the data vectors as the C parameter .Or you could just us 1 , like I do for logreg .","label":"CompareOrContrast","metadata":{},"score":"63.932835"}
{"text":"To address these problems , we show that even the simplest parsing models can effectively identify MWEs of arbitrary length , and that Tree Substitution Grammars achieve the best results .Our experiments show a 36.4 % F1 absolute improvement for French over ann - gram surface statistics baseline , currently the predominant method for MWE identification .","label":"CompareOrContrast","metadata":{},"score":"64.2478"}
{"text":"Our code is open - source1 , thread - safe , and integrated into the Moses , cdec , and Joshua translation systems .This paper describes the several performance techniques used and presents benchmarks against alternative implementations . ... ion 3 .","label":"CompareOrContrast","metadata":{},"score":"64.33733"}
{"text":"We conclude with an overview of evaluation and notes on future directions . by Adria de Gispert , Gonzalo Iglesias , Graeme Blackwood , Eduardo R. Banga , William Byrne - IN PROCEEDINGS OF HLT / NAACL , 2010 . \" ...","label":"CompareOrContrast","metadata":{},"score":"64.45514"}
{"text":"This model provides a general framework without heuristic or restricti ... \" .Machine transliteration is defined as automatic phonetic translation of names across languages .In this paper , we propose synchronous adaptor grammar , a novel nonparametric Bayesian learning approach , for machine transliteration .","label":"CompareOrContrast","metadata":{},"score":"64.655594"}
{"text":"Tools . \" ...A central problem in grounded language acquisition is learning the correspondences between a rich world state and a stream of text which references that world state .To deal with the high degree of ambiguity present in this setting , we present a generative model that simultaneously segments the text ... \" .","label":"CompareOrContrast","metadata":{},"score":"64.89215"}
{"text":"A large scale evaluation over 8 language pairs shows that performance does significantly improve . ... ases .The discontinuous MTUs that span beyond a phrasal length of 6 words are therefore never hypothesized .Acknowledgments We would like to thank the anonymous reviewers for their helpful feedback and suggestions .","label":"CompareOrContrast","metadata":{},"score":"65.23624"}
{"text":"Moreover , the Maria resulting no daba binary una bofetada rules can not a la ... . by Hao Zhang , Daniel Gildea - In NAACL Workshop on Syntax and Structure in Statistical Translation ( SSST , 2007 . \" ...Factoring a Synchronous Context - Free Grammar into an equivalent grammar with a smaller number of nonterminals in each rule enables synchronous parsing algorithms of lower complexity .","label":"CompareOrContrast","metadata":{},"score":"65.401306"}
{"text":"In this paper , we propose Two - Neighbor Orientation ( TNO ) model that jointly models the orientation decisions between anchors and two neighboring multi - unit chunks which may cross phrase or rule boundaries .We explicitly model the longest span of such chunks , referred to as Maximal Orientation Span , to serve as a global parameter that constrains underlying local decisions .","label":"CompareOrContrast","metadata":{},"score":"65.51055"}
{"text":"Rules are put into syntactic classes based on th ... \" .We describe refinements to hierarchical translation search procedures intended to reduce both search errors and memory usage through modifications to hypothesis expansion in cube pruning and reductions in the size of the rule sets used in translation .","label":"CompareOrContrast","metadata":{},"score":"65.603264"}
{"text":"So , we increase the Moses distortion limit from 6 ( the default ) to 10 and use Moses ' default lexicalized reordering model ( Koehn et al . , 2005 ) .We parsed the Chinese text using the Stanford parser ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"65.96877"}
{"text":"It just runs .What I 'd really like to see in future \" yet another classifier \" papers is an analysis of sensitivity to hyperparameter selection .You could provide graphs and stuff , but these get hard to read .","label":"CompareOrContrast","metadata":{},"score":"66.4284"}
{"text":"In addition to the standard pipeline , including phrase extraction and parameter optimization , Jane 2 contains several state - of - the - art extensions and tools .Forced alignment phrase training can considerably reduce rule table size while learning the translation scores in a more principled manner .","label":"CompareOrContrast","metadata":{},"score":"66.64729"}
{"text":"This work focuses on the description of its phrase - based ... \" .We present Jane 2 , an open source toolkit supporting both the phrase - based and the hierarchical phrase - based paradigm for statistical machine translation .It is implemented in C++ and provides efficient decoding algorithms and data structures .","label":"CompareOrContrast","metadata":{},"score":"66.82909"}
{"text":"It was also very enlightening , but that 's another story .Many thanks to Hal for offering this forum to share the results !151 comments : .One thing that bothers me about MT research is the differing baseline strengths , and the less - than - full additivity of improvements ( or their effectiveness being limited to a certain amount of training data ) .","label":"CompareOrContrast","metadata":{},"score":"67.75427"}
{"text":"We train a machine translation tool on the parallel training data , using the development data of each language pair to optimize the translation system .With this system we translate the test data , and then use a Naı̈ve Bayes classifier7 for the actual experiments . \" ...","label":"CompareOrContrast","metadata":{},"score":"68.67442"}
{"text":"This work focuses on the description of its phrase - based functionality .In addition to the standard pipeline , including phrase extraction and parameter optimization , Jane 2 contains several state - of - the - art extensions and tools .","label":"CompareOrContrast","metadata":{},"score":"68.814606"}
{"text":"It is implemented in C++ and provides efficient decoding algorithms and data structures .This work focuses on the description of its phrase - based ... \" .We present Jane 2 , an open source toolkit supporting both the phrase - based and the hierarchical phrase - based paradigm for statistical machine translation .","label":"CompareOrContrast","metadata":{},"score":"68.867294"}
{"text":"We present KenLM , a library that implements two data structures for efficient language model queries , reducing both time and memory costs .The PROBING data structure uses linear probing hash tables and is designed for speed .Compared with the widelyused SRILM , our PROBING model is 2.4 times as fast ... \" .","label":"CompareOrContrast","metadata":{},"score":"71.05566"}
{"text":"They ask : why not optimize for human judgement ?How hard is this exactly ?I would say , in terms of this scale of loss functions , that their metric is a 2 .Yet , it turns out to be cheap and fast to compute .","label":"CompareOrContrast","metadata":{},"score":"71.34241"}
{"text":"They ask : why not optimize for human judgement ?How hard is this exactly ?I would say , in terms of this scale of loss functions , that their metric is a 2 .Yet , it turns out to be cheap and fast to compute .","label":"CompareOrContrast","metadata":{},"score":"71.34241"}
{"text":"I 'll focus mainly on oral presentations , because unlike poster sessions , the parallel format of the oral sessions entails a hard choice between mutually exclusive options , and part of my motivation is to help you make that choice .","label":"CompareOrContrast","metadata":{},"score":"73.25491"}
{"text":"I 'll focus mainly on oral presentations , because unlike poster sessions , the parallel format of the oral sessions entails a hard choice between mutually exclusive options , and part of my motivation is to help you make that choice .","label":"CompareOrContrast","metadata":{},"score":"73.25491"}
{"text":"Sinuhe is fast and memory efficient , and the BLEU scores obtained by it are only slightly inferior to those of Moses . ... nt reduction in the amount of training data ( 24 % in ( Blunsom et al . , 2008 ) ) .","label":"CompareOrContrast","metadata":{},"score":"73.47656"}
{"text":"Long distance reordering remains one of the greatest challenges in statistical machine translation research as the key contextual information may well be beyond the confine of translation units .In this paper , we propose Two - Neighbor Orientation ( TNO ) model that jointly models the orientation decisi ... \" .","label":"CompareOrContrast","metadata":{},"score":"73.83551"}
{"text":"I love seeing websites that understand the value of providing a quality resource for free .It 's the old what goes around comes around routine . \" ...We present Jane 2 , an open source toolkit supporting both the phrase - based and the hierarchical phrase - based paradigm for statistical machine translation .","label":"CompareOrContrast","metadata":{},"score":"74.54577"}
{"text":"It was a pretty compelling case .Now , I 'm going to pick on basically every \" yet another classifier \" paper I 've read in the past ten years ( read : ever ) .Here 's the deal .","label":"CompareOrContrast","metadata":{},"score":"75.52693"}
{"text":"Whether this is actually true or not , I have this gut feeling that logreg is much less sensitive to hyperparameter selection than are SVMs .This is not at all based on any science , and the experience that it 's based on it somewhat unfair ( comparing megam to libSVM , for instance , which use very different optimization methods , and libSVM does n't do early stopping while megam does ) .","label":"CompareOrContrast","metadata":{},"score":"77.29955"}
{"text":"Pick a single regularization parameter ( or parameter selection scheme , ala SVM - light ) to use for all of them and report results using that value .If this is about the same as the \" I carefully tuned \" setting , I 'm happy .","label":"CompareOrContrast","metadata":{},"score":"78.57895"}
{"text":"( As an aside , Mark , if you 're reading this , I can imagine the whole CW thing getting a bit confused if you 're using feature hashing : have you tried this ?Or has someone else ? )","label":"CompareOrContrast","metadata":{},"score":"79.200714"}
{"text":"That 's a great point to bring up .I offer the thoughts above as general inspiration but clearly there are questions like the one you bring up where the most important thing will be working in honest good faith .This is very interesting information .","label":"CompareOrContrast","metadata":{},"score":"79.572136"}
{"text":"In other words , here 's a caricature of how I believe logreg and SVM behave : .That is , if you really tune the regularizer ( lambda ) well , then SVMs will win out .But for the majority of the settings , they 're either the same or logreg is a bit better .","label":"CompareOrContrast","metadata":{},"score":"80.33006"}
{"text":"That 's it .No tuning , no nothing .( Note that , as I said before , I have n't ever run experiments to verify this .But if it is , then it 's an interesting theoretical question : hinge loss and log loss do n't look that different , despite the fact that John seems to not like how log loss diverges : why should this be true ? )","label":"CompareOrContrast","metadata":{},"score":"82.61833"}
{"text":"The sense of wanting to help , but not knowing how or where , is something a lot of us are going through .Please come visit my site customer relationship when you got time .Nice , I think it could be interesting to add some more entries following this one , and probably it 's not only me having this opinion .","label":"CompareOrContrast","metadata":{},"score":"83.148544"}
{"text":"Performance within a range .Let 's say that if I do careful hyperparameter selection then I get an accuracy of X. I.e. , if I 'm willing to suffer 5 % multiplicative loss , how lazy can I be about hp selection ?","label":"CompareOrContrast","metadata":{},"score":"84.03369"}
{"text":"It must have taken a lot of hours for you to write these yourself .Hats off from me for your hard work .Please come visit my site Sports injuries give me any valuable feedbacks .That is some inspirational stuff ...","label":"CompareOrContrast","metadata":{},"score":"85.31953"}
{"text":"Neither of these is totally ideal , but I think they 'd be a lot better than the current situation of really having no idea !Maybe there are other proposals out there that I do n't know about , or maybe other readers have good ideas .","label":"CompareOrContrast","metadata":{},"score":"86.11749"}
{"text":"This is such a great resource that you are providing and you give it away for free .I love seeing websites that understand the value of providing a quality resource for free .It 's the old what goes around comes around routine .","label":"CompareOrContrast","metadata":{},"score":"87.38071"}
{"text":"It was also very enlightening , but that 's another story .Many thanks to Hal for offering this forum to share the results !Welcome to everyone to ACL !It 's pretty rare for me to end up conferencing in a country I 've been before , largely because I try to avoid it .","label":"CompareOrContrast","metadata":{},"score":"88.30664"}
{"text":"And oh - my - gosh , there 's actually veggie chicken rice , though it does n't seem like it holds up to the same standards as real chicken rice ( if it did , that would be impressive ) .","label":"CompareOrContrast","metadata":{},"score":"93.63297"}
{"text":"This is very interesting information .I am doing some research for a class in school .and i liked the post .do you know where I can find other information regarding this ?I am finding other information on this but nothing that I can use really in my paper for my final .","label":"CompareOrContrast","metadata":{},"score":"93.784256"}
{"text":"I would love some feedback on my site hotel when you got time .I usually do n't leave comments ! ! !Trust me !But I liked your blog ... especially this post !Would you mind terribly if I put up a backlink from my site to your site ?","label":"CompareOrContrast","metadata":{},"score":"94.3654"}
{"text":"and i liked the post .do you know where I can find other information regarding this ?I am finding other information on this but nothing that I can use really in my paper for my final .do you have any suggestions ?","label":"CompareOrContrast","metadata":{},"score":"94.69064"}
{"text":"Cheers ! !Please come visit my site home accent give me any valuable feedbacks .I usually do n't leave comments ! ! !Trust me !But I liked your blog ... especially this post !Would you mind terribly if I put up a backlink from my site to your site ?","label":"CompareOrContrast","metadata":{},"score":"97.73013"}
{"text":"For the vegan minded , there is a good blog about being vegan in Singapore ( first post is about a recent local talk by Campbell , the author of The China Study , which I recommend everyone at least reads ) .","label":"CompareOrContrast","metadata":{},"score":"98.94591"}
{"text":"This is just another reason why I like your website .I like your style of writing you tell your stories without out sending us to 5 other sites to complete the story .Please come visit my site Virginia Beach Yellow Page Business Directory when you got time .","label":"CompareOrContrast","metadata":{},"score":"99.447754"}
{"text":"Thank you for your good humor and for allowing yourself to be convinced that this was the right show for you to work on .Please come visit my site Santa Ana Yellow Page Business Directory when you got time .information will be very useful for me .","label":"CompareOrContrast","metadata":{},"score":"100.63848"}
{"text":"Well , nice article buddy ...Someone will love to read this infor if I tell her about this .She 's really interested in this subject .Thanks again ...Please come visit my site Baltimore Business Directory when you got time .","label":"CompareOrContrast","metadata":{},"score":"100.92049"}
{"text":", indian roti with curry ) .The food court at Vivocity , despite being a food court , is very good .You should have some hand - pressed sugar cane juice -- very sweet , but very tasty ( goes well with some spicy hotpot ) .","label":"CompareOrContrast","metadata":{},"score":"101.33356"}
{"text":"Please come visit my site City Guide Santa Ana when you got time .Awesome !I have read a lot on this topic , but you definitely give it a good vibe .This is a great post .Will be back to read more !","label":"CompareOrContrast","metadata":{},"score":"101.43118"}
{"text":"Yet Kun \" ( or something like that ) is along Purvis street .Especially for dessert , there 's Ah Chew , a Chinese place around Liang Seah street in the Bugis area ( lots of other stuff there too ) .","label":"CompareOrContrast","metadata":{},"score":"102.13516"}
{"text":"Do n't wear a nice shirt unless you plan on doing laundry .Chicken rice .This sounds lame .Sure , chicken is kind of tasty .Rice is kind of tasty .But the key is that the rice is cooked in or with melted chicken fat .","label":"CompareOrContrast","metadata":{},"score":"102.56375"}
{"text":"Now , I realize that most of the above list is not particularly friendly to my happy cow friends .Here 's a list of restaurants that happy cow provides .There are quite a few vegetarian options , probably partially because of the large Muslim population here .","label":"CompareOrContrast","metadata":{},"score":"103.268845"}
{"text":"information will be very useful for me .Thanks for all your help and wishing you all the success in your business Thanks for all your help and wishing you all the success in your business Please come visit my site Find Business Madison when you got time .","label":"CompareOrContrast","metadata":{},"score":"103.48256"}
{"text":"Please come visit my site Santa Ana Web Link when you got time .Excellent article , i just share it with my friend of Italy .I Stumble UP your blog post , you will notice an increase of traffic within 24 hours for targeted people .","label":"CompareOrContrast","metadata":{},"score":"103.74279"}
{"text":", bean stuff ) and frog leg porridge .Okay , so this list is all food .But frankly , what else are you going to do here ?Go to malls ?There 's definitely nice architecture to be seen ; I would recommend the Mosque off of Arab street ; of course you have to go to the Esplanade ( the durian - looking building ) ; etc .","label":"CompareOrContrast","metadata":{},"score":"105.5963"}
{"text":"Thanks for all the enthusiasm to offer such helpful information here .Please come visit my site Apartment living when you got time .Excellent article , i just share it with my friend of Italy .I Stumble UP your blog post , you will notice an increase of traffic within 24 hours for targeted people .","label":"CompareOrContrast","metadata":{},"score":"105.84551"}
{"text":"I am deeply in love with every single piece of information you post here .Will be back often to read more updates !Please come visit my site sexy video 's when you got time .information will be very useful for me .","label":"CompareOrContrast","metadata":{},"score":"107.109634"}
{"text":"Enjoy your time here !Quick update : Totally forgot about coffee .If you need your espresso kick , Highlander coffee ( 49 Kampong Bahru Road ) comes the most recommended , but is a bit of a hike from the conference area .","label":"CompareOrContrast","metadata":{},"score":"109.37503"}
{"text":"For real Chinese tea , here .( Funny aside : when I did this , they first asked \" have you had tea before ? \"Clearly the meaning is \" have you had real Chinese tea prepared traditionally and tasted akin to a wine tasting ? \" But I do n't think I would ever ask someone \" have you had wine before ? \" But I also ca n't really think of a better way to ask this ! )","label":"CompareOrContrast","metadata":{},"score":"113.14564"}
{"text":"I usually do n't leave comments ! ! !Trust me !But I liked your blog ... especially this post !Would you mind terribly if I put up a backlink from my site to your site ?Please come visit my site Business Yellow Pages Indianapolis when you got time .","label":"CompareOrContrast","metadata":{},"score":"123.35722"}
{"text":"As a result , he was an excellent \" tour guide . \"With his help , here 's a list of mostly food related stuff that you should definitely try while here ( see also the ACL blog ): .Pepper crab .","label":"CompareOrContrast","metadata":{},"score":"124.61269"}
