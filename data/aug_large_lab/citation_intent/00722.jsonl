{"text":"While preliminary work , these experiments show promise for semantically - informed machine translation . \" ...We introduce a discriminatively trained , globally normalized , log - linear variant of the lexical translation models proposed by Brown et al .( 1993 ) .","label":"Background","metadata":{},"score":"23.29013"}
{"text":"We review well - known algorithms , arguing that they do not optimize the loss functions they are assumed to optimize wh ... \" .This paper seeks to close the gap between training algorithms used in statistical machine translation and machine learning , specifically the framework of empirical risk minimization .","label":"Background","metadata":{},"score":"27.731995"}
{"text":"Using a variety of intrinsic and extrinsic measures , including translation performance , we show our model yields better alignments than generative baselines in a number of language pairs . \" ...With a few exceptions , discriminative training in statistical machine translation ( SMT ) has been content with tuning weights for large feature sets on small development data .","label":"Background","metadata":{},"score":"27.851208"}
{"text":"We introduce a semi - supervised approach to training for statistical machine translation that alternates the traditional Expectation Maximization step that is applied on a large training corpus with a discriminative step aimed at increasing word - alignment quality on a small , manually word - aligned sub ... \" .","label":"Background","metadata":{},"score":"30.162004"}
{"text":"Callison - Burch et al .( 2005 ) and Zhang and Vogel ( 2005 ) proposed a solution that we call translation by pattern matching , which we bring to fruition in this dissertation .The training data itself serves as a proxy to the model ; rules and parameters are computed on demand .","label":"Background","metadata":{},"score":"30.27154"}
{"text":"They demonstrated its application to a common model based on the translation of contiguous substrings , but leave some open problems .Among these is a question : can this approach match the performance of conventional methods despite unavoidable differences that it induces in the model ?","label":"Background","metadata":{},"score":"30.532913"}
{"text":"Building on this work , we demonstrate substan ... \" .For many years , statistical machine translation relied on generative models to provide bilingual word alignments .In 2005 , several independent efforts showed that discriminative models could be used to enhance or replace the standard generative approach .","label":"Background","metadata":{},"score":"31.366402"}
{"text":"This paper presents a novel training algorithm for a linearly - scored block sequence translation model .The key component is a new procedure to directly optimize the global scoring function used by a SMT decoder .No translation , language , or distortion model probabilities are used as in earlier work on SMT .","label":"Background","metadata":{},"score":"31.421774"}
{"text":"The goal of t ... \" .With a few exceptions , discriminative training in statistical machine translation ( SMT ) has been content with tuning weights for large feature sets on small development data .Evidence from machine learning indicates that increasing the training sample size results in better prediction .","label":"Background","metadata":{},"score":"31.675957"}
{"text":"We also believe that in this particular situation , the presence of the error bars may help to better understand the stability of the system .Using the framework described above , four different settings have been set to produce learning curves , see Table 3 .","label":"Background","metadata":{},"score":"31.913311"}
{"text":"We introduce a discriminatively trained , globally normalized , log - linear variant of the lexical translation models proposed by Brown et al .( 1993 ) .In our model , arbitrary , nonindependent features may be freely incorporated , thereby overcoming the inherent limitation of generative models , which require that features be sensitive to the conditional independencies of the generative process .","label":"Background","metadata":{},"score":"32.128525"}
{"text":"This yields an efficient algorithm for obtaining the exact solution of each line search in Powell 's method and therefore provides a way to iteratively optimize the log - linear weights . using MERT .A number of alternatives have been proposed , such as on - line discriminative training [ 19 , 20 ] .","label":"Background","metadata":{},"score":"32.313095"}
{"text":"With data size and model complexity continually increasing , a scalable solution to this problem is central to future improvement .Callison - Burch et al .( 2005 ) and Zhang and Vogel ( 2005 ) proposed a solution that we call translation by pattern matching , which we bring to fruition in this dissertation .","label":"Background","metadata":{},"score":"32.80036"}
{"text":"We present a unified view of many translation algorithms that synthesizes work on deductive parsing , semiring parsing , and efficient approximate search algorithms .This gives rise to clean analyses and compact descriptions that can serve as the basis for modular implementations .","label":"Background","metadata":{},"score":"32.999557"}
{"text":"We present a unified view of many translation algorithms that synthesizes work on deductive parsing , semiring parsing , and efficient approximate search algorithms .This gives rise to clean analyses and compact descriptions that can serve as the basis for modular implementations .","label":"Background","metadata":{},"score":"32.999557"}
{"text":"The high performance observed in the train - on - test conditions shows that there exists at least one choice of tunable parameters with which the phrase - based translation system can deliver much higher performance .This is useful to bound the space of \" possible performances , ' ' although in ideal situations .","label":"Background","metadata":{},"score":"33.211876"}
{"text":"Although many language pairs would yield different translation performance , in this paper , we are not interested in the translation performance per se : we focus our attention on analyzing the SMT system as a learning system .Since our goal was to obtain high - accuracy learning curves , that can be trusted both for comparing different system settings and to extrapolate performance under unseen conditions , we conducted a large - scale series of tests , to reduce uncertainty in the estimations and to obtain the strongest possible signals .","label":"Background","metadata":{},"score":"33.39919"}
{"text":"We evaluate these models on two cross - lingual document classification tasks , outperforming the prior state of the art .Through qualitative analysis and the study of pivoting effects we demonstrate that our representations are semantically plausible and can capture semantic rela - tionships across languages without paral - lel data . ...","label":"Background","metadata":{},"score":"33.586082"}
{"text":"Work related to our learning curve experiments can also be found in [ 10 ] .It is important to remark that while there are many discussions about automatic evaluation of SMT systems , this work does not consider them .We work within the well - defined setting where a loss function has been agreed upon , that can measure the similarity between two sentences , and a paired training set has been provided .","label":"Background","metadata":{},"score":"33.65307"}
{"text":"We show that shallow - n grammars , low - level rule catenation , and other search constraints can help to match the power of the translation system to specific language pairs . ...i m et al . , 2007 ; Rosti et al . , 2007 ) .","label":"Background","metadata":{},"score":"33.77234"}
{"text":"In practice this trade - off is easily observed , by noticing how the training error can be driven to zero by using a rich hypothesis class , which typically results into overfitting and increased test error .In the context of statistical machine translation ( SMT ) , where large bilingual corpora are used to train adaptive software to translate text , this task is further complicated by the peculiar distribution underlying the data , where the probability of encountering new words or expressions never vanishes .","label":"Background","metadata":{},"score":"34.00604"}
{"text":"The parameters are estimated using an EM - style method .None of these methods try to generalize f .. \" ...This paper presents a novel training algorithm for a linearly - scored block sequence translation model .The key component is a new procedure to directly optimize the global scoring function used by a SMT decoder .","label":"Background","metadata":{},"score":"34.104088"}
{"text":"We show that our algorithm leads not only to improved alignments but also to machine translation outputs of higher quality . ... evious work on discriminative training for wordalignment differed most strongly from our approach in that it generally views word - alignment as a supervised task .","label":"Background","metadata":{},"score":"34.20936"}
{"text":"Model Perturbation : Analysis and Unlearning Curves .Much research has focused on devising improved principles for the statistical estimation of the parameters in language and translation models .The introduction of discriminative graphical models has marked a departure from traditional maximum likelihood estimation principles , and various approaches have been proposed .","label":"Background","metadata":{},"score":"34.52858"}
{"text":"In an age where the creation of intelligent behaviour is increasingly data driven , this is a question of great importance to all of artificial intelligence .In phrase - based approaches to statistical machine translation , translations are generated in response to some input source text .","label":"Background","metadata":{},"score":"34.560204"}
{"text":"We therefore reach the conclusion that estimating entries in the phrase translation tables is the dominant factor in determining performance .What controls the creation of phrase - translation tables ?This is mostly limited by Zipf 's law , since the probability of encountering phrases that have not been seen in the training set does not vanish even after observing very large corpora .","label":"Background","metadata":{},"score":"34.818535"}
{"text":"One of our key findings is that the current performance of phrase - based statistical machine translation systems is not limited by the representation power of the hypothesis class , but rather by model estimation from data .In other words , we demonstrate that parameter choices exist that can deliver significantly higher performance , but that inferring them from finite samples is the problem .","label":"Background","metadata":{},"score":"34.906265"}
{"text":"R. Zens , F.-J. Och , and H. Ney , \" Phrase - based statistical machine translation , \" in Proceedings of the 25th Annual German Conference on AI ( KI ' 02 ) , pp .18 - 32 , Springer , London , UK , 2002 .","label":"Background","metadata":{},"score":"35.16425"}
{"text":"Our experiments confirm existing and mostly unpublished beliefs about the learning capabilities of statistical machine translation systems .We also provide insight into the way statistical machine translation learns from data , including the respective influence of translation and language models , the impact of phrase length on performance , and various unlearning and perturbation analyses .","label":"Background","metadata":{},"score":"35.334305"}
{"text":"Our results show that while both learning algorithms achieve similar results , with the perceptron converging more rapidly , the aggressive update strategy performs significantly worse than the more conservative strategy corroborating Liang et al .( 2006 ) 's findings .","label":"Background","metadata":{},"score":"35.34118"}
{"text":"868 - 876 , 2007 .J. Blatz , E. Fitzgerald , G. Foster , et al . , \" Confidence estimation for machine translation , \" in Proceedings of the 20th international Conference on Computational Linguistics ( COLING ' 04 ) , vol .","label":"Background","metadata":{},"score":"35.3978"}
{"text":"However , these algorithms are only suitable to the case that the new incremental samples belong to old classes .When a new class was added to the classification system , the above methods could not be fully accommodated to this situation and the old models became useless .","label":"Background","metadata":{},"score":"35.467957"}
{"text":"The evaluation of a machine translation system is a lively and hotly debated topic in this field .Ideally , human beings can evaluate the quality of a translated sentence .However , this is unfeasible for rapid development of automatically trained systems with multiple parameter tuning , as human evaluation is expensive , slow , and sometimes inconsistent and subjective .","label":"Background","metadata":{},"score":"35.69924"}
{"text":"The classification speed of MHE - CIL method is faster compared with HE - CIL method , and it is nearly the same as HE - CIL method .Conclusion .A novel class incremental learning algorithm is proposed .In the process of class incremental learning , only the new class samples participate in training and the old models of the classifier can be reused .","label":"Background","metadata":{},"score":"35.793358"}
{"text":"Unfortunately , current estimation procedures are unable to reach such high - performing regions of the parameter space .This was also noted by a recent paper by Wisniewski et al . who note that \" the current bottleneck of translation performances is not the representation power of the [ phrase - based translation systems ] but rather in their scoring functions '' [ 38 ] .","label":"Background","metadata":{},"score":"36.24421"}
{"text":"Training the translation models requires several steps such as aligning words , computing the lexical translation , extracting and scoring the phrases , and creating the reordering model .When the models have been created , the development set is used to run the minimum error rate training ( MERT ) algorithm [ 17 ] to optimize their weights .","label":"Background","metadata":{},"score":"36.279697"}
{"text":"We tackle these issues in the context of algorithmic trading , where sequential decisions need to be made quickly as new data points arrive , and where the data generating process may change continuously with time .We propose a master algorithm that evolves a pool of on - line SVR experts and learns to trade by dynamically weighting the experts ' opinions .","label":"Background","metadata":{},"score":"36.30867"}
{"text":"In addition to standard hierarchical rule tables , it is capable of extracting syntax augmented machine translation ( SAMT ) grammars ( Zollmann and Venugopal , 2006 ) .Ncode ( Crego et al . , 2011 ) implements the n - gram - based approach to machine translation ( Mariño et al . , 2006 ) .","label":"Background","metadata":{},"score":"36.34364"}
{"text":"We present a new generative alignment model which avoids these structural limitations , and show that it is effective when trained using both unsupervised and semi - supervised training methods . ... lar to work using discriminative log - linear models for alignment , which is similar to discriminative log - linear models used for the SMT decoding ( translation ) problem ( Och and Ney , 2002 ; Och , 2003 ) .","label":"Background","metadata":{},"score":"36.40937"}
{"text":"This unrealistic case is not affected by the Zipf 's law , because almost all the words necessary to translate the training material have , by definition , already been observed .The model is therefore able to match long phrases when producing the \" test on training set ' ' translations .","label":"Background","metadata":{},"score":"36.519333"}
{"text":"We begin with the context of the current research , and then move to a formal problem description and an overview of the four main subproblems : translational equivalence modeling , mathematical modeling , parameter estimation , and decoding .Along the way , we present a taxonomy of some different approaches within these areas .","label":"Background","metadata":{},"score":"36.743923"}
{"text":"G. Cauwenberghs and T. Poggio , \" Incremental and decremental support vector machine learning , \" in Advances in Neural Information Processing Systems , pp .409 - 415 , 2001 .View at Google Scholar .J. Zhang , Z. Li , and J. Yang , \" A divisional incremental training algorithm of Support Vector Machine , \" in Proceedings of the IEEE International Conference on Mechatronics and Automation ( ICMA ' 05 ) , pp .","label":"Background","metadata":{},"score":"36.74412"}
{"text":"G. Cauwenberghs and T. Poggio , \" Incremental and decremental support vector machine learning , \" in Advances in Neural Information Processing Systems , pp .409 - 415 , 2001 .View at Google Scholar .J. Zhang , Z. Li , and J. Yang , \" A divisional incremental training algorithm of Support Vector Machine , \" in Proceedings of the IEEE International Conference on Mechatronics and Automation ( ICMA ' 05 ) , pp .","label":"Background","metadata":{},"score":"36.74412"}
{"text":"In this paper we present a novel approach for inducing word alignments from sentence aligned data .We use a Conditional Random Field ( CRF ) , a discriminative model , which is estimated on a small supervised training set .The CRF is conditioned on both the source and target texts , and thus allows for t ... \" .","label":"Background","metadata":{},"score":"36.756054"}
{"text":"We investigate the learning - theoretic implications of this setting , including the interplay between approximation error and estimation error , model selection , and accuracy in parameters estimation .We do not address more general themes about the opportunity for SMT to be evaluated by automatic metrics .","label":"Background","metadata":{},"score":"36.832733"}
{"text":"We analyze a number of these algorithms in terms of their sentencelevel loss functions , which motivates several new approaches , including a Structured SV ... \" .There has been a proliferation of recent work on SMT tuning algorithms capable of handling larger feature sets than the traditional MERT approach .","label":"Background","metadata":{},"score":"36.875134"}
{"text":"Machine Learning and Cybernetics , 2005 .Proceedings of 2005 International Conference on , 3 , 2005 .[ 30 ] Jian - xiong Dong , Krzyzak , A. , Suen , C.Y. Fast SVM training algorithm with decomposition on very large data sets .","label":"Background","metadata":{},"score":"37.07566"}
{"text":"We describe refinements to hierarchical translation search procedures intended to reduce both search errors and memory usage through modifications to hypothesis expansion in cube pruning and reductions in the size of the rule sets used in translation .Rules are put into syntactic classes based on the number of non - terminals and the pattern , and various filtering strategies are then applied to assess the impact on translation speed and quality .","label":"Background","metadata":{},"score":"37.08838"}
{"text":"Incremental learning is an intelligent technology of data mining and knowledge discovery .Among these methods , SVM has a good generalization performance , because it does not depend on all the training data , but a subset named support vector .","label":"Background","metadata":{},"score":"37.240654"}
{"text":"The second concern was to distinguish between the role of the numerical and lexical parts in the language and translation models .Various perturbation experiments show that the accuracy in estimating the numerical parameters is not a crucial aspect of performance , while the estimation of the lexical parts of the tables is a major factor in determining performance .","label":"Background","metadata":{},"score":"37.26805"}
{"text":"In the recent literature the alignment task has frequently been decoupled from the translation task , and assumptions have been made about measuring alignment quality for machine translation which , it turns out , are not justified .In particular , none of the tens of papers published over the last five years has shown that significant decreases in Alignment Error Rate , AER ( Och and Ney , 2003 ) , result in significant increases in translation quality .","label":"Background","metadata":{},"score":"37.384033"}
{"text":"In any case , the addition of massive amounts of data from the same distribution will result in small improvements in the performance .The small error bars that we have obtained also allow us to regard the stability of the SMT when trained on the same training set size .","label":"Background","metadata":{},"score":"37.553596"}
{"text":"This is useful because the language model feature typically favours shorter sentences ( because each additional trigram can only lower the language model probability ) .This is a simple , yet effective feature .The process of training a machine translation system involves estimating the various parameters of the model : the log - linear parameters . as well as the parameters internal to the feature functions , such as the phrase translation probabilities and language model n -gram and backoff probabilities .","label":"Background","metadata":{},"score":"37.991425"}
{"text":"Systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine translation output , but are often very computationally intensive .The complexity is exponential in the size of individual grammar rules due to arbitrary re - orderings between the two langu ... \" .","label":"Background","metadata":{},"score":"38.05031"}
{"text":"We present a novel technique for learn - ing semantic representations , which ex - tends the distributional hypothesis to mul - tilingual data and joint - space embeddings .Our models leverage parallel data and learn to strongly align the embeddings of semantically equivalent sentences , while maintaining suf ... \" .","label":"Background","metadata":{},"score":"38.05413"}
{"text":"We will later analyze the contribution of each component to the overall score .The typical processing pipeline is as follows .Given a parallel training corpus , long sentences are filtered out , and the remaining material is lowercased and tokenized .","label":"Background","metadata":{},"score":"38.122055"}
{"text":"The Journal of Machine Learning Research .[49 ] Bottou , L. and Bousquet , O. The tradeoffs of large scale learning .Advances in neural information processing systems .[50 ] Collobert , R. and Bengio , S. SVMTorch : Support vector machines for large - scale regression problems .","label":"Background","metadata":{},"score":"38.19877"}
{"text":"We also discuss the more general , and computationally more difficult , problem of finding good parsing strategies for non - binarizable rules , and present an approximate polynomial - time algorithm for this problem . \" ...For many years , statistical machine translation relied on generative models to provide bilingual word alignments .","label":"Background","metadata":{},"score":"38.371506"}
{"text":"Cauwenberghs , G. , Poggio , T. : Incremental and decremental support vector machine learning , Cambridge , vol .13 , pp .409 - 123 ( 2001 ) .Cesa - Bianchi , N. , Lugosi , G. : Prediction , learning , and games .","label":"Background","metadata":{},"score":"38.42669"}
{"text":"We present experiments on learning on 1.5 million training sentences , and show significant improvements over tuning discriminative models on small development sets . ... pora described in Table 1 .The translation direction is German - to - English .The SMT framework used in our experiments is hierarchical phrase - based translation ( Chiang , 2007 ) .","label":"Background","metadata":{},"score":"38.511948"}
{"text":"In Proceedings of the 16th International Conference on Pattern Recognition ( ICPR'2002 ) .[ 10 ] Cauwenberghs , G. and Poggio , T. Incremental and decremental support vector machine learning .Advances in neural information processing systems , 2001 .[ 11 ] Fung , G. and Mangasarian , O.L. Incremental support vector machine classification .","label":"Background","metadata":{},"score":"38.576866"}
{"text":"[ 32 ] Ferri , FJ and Pudil , P. and Hatef , M. and Kittler , J. Comparative study of techniques for large - scale feature selection .MACHINE INTELLIGENCE AND PATTERN RECOGNITION .[ 33 ] Lazarevic , A. and Obradovic , Z. Boosting algorithms for parallel and distributed learning .","label":"Background","metadata":{},"score":"38.670776"}
{"text":"Moreover , with a small Lf - Le bilingual corpus available , our method can further improve the translation quality by using the additional Lf - Lp and Lp - Le bilingual corpora . ... n Building and Using Parallel Texts ( Martin et al . , 2005 ) .","label":"Background","metadata":{},"score":"38.775734"}
{"text":"Development and test sets are fixed .One instance of the SMT system has been run for each of all possible combinations of the language and translation training data sizes .BLEU score value has been associated to each pair : language and translation set size .","label":"Background","metadata":{},"score":"38.873333"}
{"text":"Our findings are also consistent with the curves presented by [ 33 ] , although their results are limited to a much lower data set size ( less than . sentences ) and presented on a linear scale .Incidentally , that paper also presents a recent attempt into using active learning for improving MT and meets the challenge of \" diminishing returns ' ' identified in the learning curves : a constant performance improvement requires increasing amounts of data .","label":"Background","metadata":{},"score":"39.016834"}
{"text":"While our model was sensitive to poste - rior thresholds , it also showed a perfor - mance comparable to that of HMM align - ment models . \" ...The best systems for machine translation of natural language are based on statistical models learned from data .","label":"Background","metadata":{},"score":"39.017014"}
{"text":"We describe a novel leavingone - out approach to prevent ov ... \" .Several attempts have been made to learn phrase translation probabilities for phrasebased statistical machine translation that go beyond pure counting of phrases in word - aligned training data .","label":"Background","metadata":{},"score":"39.022236"}
{"text":"Although the framework is drawn from parsing and applied to translation , it is applicable to many dynamic programming problems arising in natural language processing and other areas . by Alexandre Klementiev , Ann Irvine , Chris Callison - burch , David Yarowsky . \" ...","label":"Background","metadata":{},"score":"39.031967"}
{"text":"However , for ease of exposition and to relate our work to pre ... . \" ...The best systems for machine translation of natural language are based on statistical models learned from data .Conventional representation of a statistical translation model requires substantial offline computation and representation in main memory .","label":"Background","metadata":{},"score":"39.055084"}
{"text":"2002 ( Survey ) .[57 ] Collobert , R. and Bengio , S. and Bengio , Y. A parallel mixture of SVMs for very large scale problems .Neural computation .[58 ] Neil , M. and Fenton , N. and Nielson , L. Building large - scale Bayesian networks .","label":"Background","metadata":{},"score":"39.100418"}
{"text":"[ 41 ] Lin , N. and Xi , R. , \" Aggregated estimating equation estimation \" , 2009 .Tools .Miscellaneous .[47 ] Joachims , T. Making large scale SVM learning practical .[ 48 ] S Sonnenburg , G Rätsch .","label":"Background","metadata":{},"score":"39.17231"}
{"text":"268 - 273 , 2000 .B.-F. Zhang , J.-S. Su , and X. Xu , \" A class - incremental learning method for multi - class support vector machines in text classification , \" in Proceedings of the International Conference on Machine Learning and Cybernetics , pp .","label":"Background","metadata":{},"score":"39.19033"}
{"text":"268 - 273 , 2000 .B.-F. Zhang , J.-S. Su , and X. Xu , \" A class - incremental learning method for multi - class support vector machines in text classification , \" in Proceedings of the International Conference on Machine Learning and Cybernetics , pp .","label":"Background","metadata":{},"score":"39.19033"}
{"text":"The impressive capability of current machine translation systems is not only a testament to an incredibly productive and creative research community , but can also be seen as a paradigm for other artificial intelligence tasks .Data - driven approaches to all main areas of AI currently deliver the state - of - the - art performance , from summarization to speech recognition to machine vision to information retrieval .","label":"Background","metadata":{},"score":"39.269547"}
{"text":"We obtain gains in ... \" .Word alignments that violate syntactic correspondences interfere with the extraction of string - to - tree transducer rules for syntaxbased machine translation .We present an algorithm for identifying and deleting incorrect word alignment links , using features of the extracted rules .","label":"Background","metadata":{},"score":"39.522774"}
{"text":"This fundamental limitation seems to be a direct consequence of Zipf law governing textual data .Although the rate of improvement may depend on both the data and the estimation method , it is unlikely that the general shape of the learning curve will change without major changes in the modeling and inference phases .","label":"Background","metadata":{},"score":"39.593666"}
{"text":"The approach yields trainable , probabilistic distortion models that are global : they assign a probability to each possible phrase reordering .These \" segment choice \" models ( SCMs ) can be trained on \" segment - aligned \" sentence pairs ; they can be applied during decoding or rescoring .","label":"Background","metadata":{},"score":"39.620163"}
{"text":"By examining many samples of human - produced translation , SMT algorithms automatically learn how to translate .SMT has made tremendous strides in less than two decades , and many popular techniques have only emerged within the last few years .","label":"Background","metadata":{},"score":"39.91433"}
{"text":"The training part is used to obtain the language model and phrase tables .The development set is used to estimate the log - linear weights . using MERT , and the test set is set aside during the estimation process in order to provide an unbiased estimate of the translation performance .","label":"Background","metadata":{},"score":"39.975746"}
{"text":"Discriminative learning allows easy incorporation of any feature one might have access to during the alignment search .Because the features are handled so easily , ... . \" ...Word alignments that violate syntactic correspondences interfere with the extraction of string - to - tree transducer rules for syntaxbased machine translation .","label":"Background","metadata":{},"score":"40.061455"}
{"text":"In each case , we found the same overall behaviour , of a logarithmic growth in performance with training set size .The question becomes as follows : on which aspect of these systems should we act to achieve better performance ?","label":"Background","metadata":{},"score":"40.35416"}
{"text":"The best systems for machine translation of natural language are based on statistical models learned from data .Conventional representation of a statistical translation model requires substantial offline computation and representation in main memory .Therefore , the principal bottlenecks to the amount of data we can exploit and the complexity of models we can use are available memory and CPU time , and current state of the art already pushes these limits .","label":"Background","metadata":{},"score":"40.3951"}
{"text":"They are automatically filled during the training phase , when a bilingual corpus is used to identify both phrases and their probabilities .Since future translations are produced by maximizing a scoring function estimating translation quality , using the content of the two tables , we see that the contents of the translation and language models tables correspond to the tunable parameters of the learning system .","label":"Background","metadata":{},"score":"40.41031"}
{"text":"Clearly , all measures correlate strongly with each other , such that the choice of the performance measure is fairly arbitrary , as long as one is consistent .For this reason , we have chosen to use BLEU throughout this paper as it is the most widely used automatic score in machine translation .","label":"Background","metadata":{},"score":"40.492218"}
{"text":"5 , pp .2402 - 2411 , 2014 .View at Publisher · View at Google Scholar .S. Rüping , \" Incremental learning with support vector machines , \" in Proceedings of the IEEE International Conference on Data Mining ( ICDM ' 01 ) , pp .","label":"Background","metadata":{},"score":"40.49514"}
{"text":"5 , pp .2402 - 2411 , 2014 .View at Publisher · View at Google Scholar .S. Rüping , \" Incremental learning with support vector machines , \" in Proceedings of the IEEE International Conference on Data Mining ( ICDM ' 01 ) , pp .","label":"Background","metadata":{},"score":"40.49514"}
{"text":"Any way to enforce linguistic constraints might result in a reduced need for data , and ultimately in more complete models , given the same corpus [ 34 ] .Neither approach would change the statistical nature of the system , but they would help it bypass the phrase acquisition bottleneck .","label":"Background","metadata":{},"score":"40.514114"}
{"text":"This line of research shares the insight that HMM models can be improved by imposing well - motivated constraints on them .Toutanova et a .. \" ...We propose a novel unsupervised word alignment model based on the Hidden Markov Tree ( HMT ) model .","label":"Background","metadata":{},"score":"40.546265"}
{"text":"4 The baseline system was trained on unsegmented words , and the ... . by Kenneth Heafield - In Proc . of the Sixth Workshop on Statistical Machine Translation , 2011 . \" ...We present KenLM , a library that implements two data structures for efficient language model queries , reducing both time and memory costs .","label":"Background","metadata":{},"score":"40.75032"}
{"text":"Yaroshinsky , R. , El - Yaniv , R. , Seiden , S. : How to better use expert advice .Machine Learning 55(3 ) , 271 - 309 ( 2004 ) MATH CrossRef Tools . \" ...Many phrase alignment models operate over the combinatorial space of bijective phrase alignments .","label":"Background","metadata":{},"score":"40.81043"}
{"text":"We also propose an approximate EM algorithm and a Gibbs sampling algorithm to estimate model parameters in an unsupervised manner .Experiments on large - scale Chinese - English translation tasks demonstrate that our model achieves improvements in both alignment quality and translation quality .","label":"Background","metadata":{},"score":"40.85131"}
{"text":"Martin , M. : On - line support vector machine regression .In : 13th European Conference on Machine Learning ( 2002 ) .Montana , G. , Triantafyllopoulos , K. , Tsagaris , T. : Data stream mining for market - neutral algorithmic trading .","label":"Background","metadata":{},"score":"41.093964"}
{"text":"Understanding how sophisticated behaviour can be learnt from data is hence not just a concern for machine learning , or to individual applied communities , such as statistical machine translation , but rather a general concern for modern artificial intelligence .The analysis of learning curves and the identification of the various limitations to performance are a crucial part of the machine learning method , and one where statistics and algorithms interact closely .","label":"Background","metadata":{},"score":"41.148445"}
{"text":"Our results suggest that performance , as measured by BLEU , increases by a constant factor for each doubling of the data .Although that factor varies depending on corpus and language pair , this result seems consistent over all experimental conditions we tried .","label":"Background","metadata":{},"score":"41.193268"}
{"text":"As this is an enormous search space , it is no wonder that both algorithmic and statistical challenges are encountered when training these systems .From a statistical learning point of view , this raises interesting questions : How much of the overall error of the translation system is due to representation limitations , and how much to the difficulty of extracting suitable Translation and Language model tables from a finite sample ?","label":"Background","metadata":{},"score":"41.225666"}
{"text":"It achieves our desiderata of minimal offline computation and com - pact representation , but is dependent on fast pattern matching algorithms on text .They demonstrated its application to a common model based on the translation of contiguous substrings , but leave some open problems .","label":"Background","metadata":{},"score":"41.51494"}
{"text":"We find that the use of WFSTs rather than k - best lists requires less pruning in translation search , resulting in fewer search errors , better parameter optimization , and improved translation performance .The direct generation of translation lattices in the target language can improve subsequent rescoring procedures , yielding further gains when applying long - span language models and Minimum Bayes Risk decoding .","label":"Background","metadata":{},"score":"41.63418"}
{"text":"By approximating the intractable space of all candidate translations produced by inter - secting an ngram language model with a synchronous grammar , we are able to train and decode models incorporating millions of sparse , heterogeneous features .Further , we demonstrate the power of the discriminative training paradigm by extracting structured syntactic features , and achieving increases in translation performance . \" ...","label":"Background","metadata":{},"score":"41.89658"}
{"text":"The complexity is exponential in the size of individual grammar rules due to arbitrary re - orderings between the two languages .We develop a theory of binarization for synchronous context - free grammars and present a linear - time algorithm for binarizing synchronous rules when possible .","label":"Background","metadata":{},"score":"41.95228"}
{"text":"Journal of Machine Learning Research , 6:363 - 392 , 2005 .[ 61 ] Golub , G.H. and Von Matt , U. Generalized cross - validation for large - scale problems .Journal of Computational and Graphical Statistics .[62 ] Fan , W. and Stolfo , S.J. and Zhang , J. The application of AdaBoost for distributed , scalable and on - line learning .","label":"Background","metadata":{},"score":"41.974266"}
{"text":"Our first concerns were to distinguish between approximation and estimation error : the performance limitations due to the use of a limited language model versus those due to the need to estimate the parameters of that model from a finite sample .","label":"Background","metadata":{},"score":"42.012543"}
{"text":"Introduction .Traditional approaches to machine translation ( MT ) [ 1 ] relied to a large extent on linguistic analysis .The ( relatively ) recent development of statistical approaches [ 2 ] and especially phrase - based machine translation , or PBMT [ 3 , 4 ] , has put the focus on the intensive use of large parallel corpora .","label":"Background","metadata":{},"score":"42.021233"}
{"text":"Unfortunately the relationship between alignment quality and statistical machine translation performance has not been well understood .In the recent literature the alignment task has frequently been decoupled from the ... \" .Automatic word alignment plays a critical role in statistical machine translation .","label":"Background","metadata":{},"score":"42.108562"}
{"text":"Volume 27 , Issue 4 , Page(s):603 - 618 , April 2005 .[ 31 ] Jian - Xiong Dong , Adam Krzyzak , and Ching Y. Suen .A fast parallel optimization for training support vector machine .In Proceedings of 3rd International Conference on Machine Learning and Data Mining , volume 17 , pages 96 - 105 .","label":"Background","metadata":{},"score":"42.21088"}
{"text":"Does the performance improve with more data because certain parameters are estimated better , or just because the lists are growing ?In the second case , it is likely that more sophisticated statistical algorithms to improve the estimation of probabilities will have limited impact .","label":"Background","metadata":{},"score":"42.322666"}
{"text":"Our models leverage parallel data and learn to strongly align the embeddings of semantically equivalent sentences , while maintaining sufficient distance between those of dissimilar sentences .The mod - els do not rely on word alignments or any syntactic information and are success - fully applied to a number of diverse lan - guages .","label":"Background","metadata":{},"score":"42.336693"}
{"text":"Springer , Heidelberg ( 1995 ) MATH .Wabha , G. : Spline models for observational data .CBMS - NSF Regional Conference Series in Applied Mathematics , vol .SIAM , Philadelphia ( 1990 ) .Wang , W. : An incremental learning strategy for support vector regression .","label":"Background","metadata":{},"score":"42.395805"}
{"text":"Bilingual word alignment forms the foundation of most approaches to statistical machine translation .Current word alignment methods are predominantly based on generative models .In this paper , we demonstrate a discriminative approach to training simple word alignment models that are comparable in accuracy to the more complex generative models normally used .","label":"Background","metadata":{},"score":"42.46187"}
{"text":"22 , no . 9 , pp .1567 - 1581 , 2012 .View at Publisher · View at Google Scholar .S. Yin , H. Luo , and S. Ding , \" Real - time implementation of fault - tolerant control systems with performance optimization , \" IEEE Transactions on Industrial Electronics , vol .","label":"Background","metadata":{},"score":"42.578075"}
{"text":"The approach yields trainable , probabilistic distortion models that are global : they assign a probability to each possible ... \" .This paper presents a new approach to distortion ( phrase reordering ) in phrasebased machine translation ( MT ) .","label":"Background","metadata":{},"score":"42.617203"}
{"text":"35 - 43 , Columbus , Ohio , USA , 2008 . Y. Al - Onaizan , J. Curin , M. Jahr , et al . , \" Statistical machine translation : final report , \" Tech .Rep. , Johns Hopkins University , Summer Workshop on Language Engineering , Center for Speech and Language Processing , Baltimore , Md , USA , 1999 .","label":"Background","metadata":{},"score":"42.630863"}
{"text":"We propose a new perceptron algorithm that can use non - local features .Our algorithm allows the use of all types of non - local features whose values are determined from the sequence and the labels .The weights of local and non - local features are learned together in the training process with guaranteed convergence .","label":"Background","metadata":{},"score":"42.65689"}
{"text":"ICML 2009 .[ 25 ] A. Asuncion , P. Smyth , and M. Welling , \" Distributed Inference for Latent Dirichlet Allocation \" , Neural Information Processing Systems ( NIPS ) , 2007 .[26 ] F. Lozano , and P. Rangel , \" Algorithms for Parallel Boosting \" , ICMLA International Conference on Machine Learning and Applications , 2005 .","label":"Background","metadata":{},"score":"42.65705"}
{"text":"[28 ] L. Zanni , T. Serafini and G. Zanghirati .Parallel Software for Training Large Scale Support Vector Machines on Multiprocessor Systems .Journal of Machine Learning Research 7:14671492 , 2006 .[29 ] J. Zhang , Z. Li , and J. Yang .","label":"Background","metadata":{},"score":"42.68576"}
{"text":"We propose a novel algorithm to estimate reordering probabilities from monolingual data .We report translation results for an end - to - end translation system using these monolingual features alone .Our method only requires monolingual corpora in source and target languages , a small bilingual dictionary , and a small bitext for tuning feature weights .","label":"Background","metadata":{},"score":"42.694973"}
{"text":".. a top - scoring MT system in the Chinese newswire track of the 2008 NIST evaluation .However , except for ( Fraser and Marcu , 2007b ) , none of these advances in alignment quality has improv ... . \" ...","label":"Background","metadata":{},"score":"42.75832"}
{"text":"Among possible methods , two stand out as particularly promising .The first is to generate phrase pairs by using grammatical or various linguistic rules ( e.g. , turning existing entries into new entries , by applying various forms of inflection ) .","label":"Background","metadata":{},"score":"42.77527"}
{"text":"When extracting longer phrases , we expect training set performance to be higher , but test performance to drop ( overfitting ) .Optimizing test performance requires the right trade - off .In this section , we analyze how the phrase length can affect the performance in terms of BLEU score .","label":"Background","metadata":{},"score":"42.848778"}
{"text":"We perform empirical comparisons of eight different tuning strategies , including MERT , in a variety of settings .Among other results , we find that a simple and efficient batch version of MIRA performs at least as well as training online , and consistently outperforms other options . ... oad categories .","label":"Background","metadata":{},"score":"42.85617"}
{"text":"Advances in Neural Information Processing Systems 2007 .[20 ] Graf , H.P. and Cosatto , E. and Bottou , L. and Dourdanovic , I. and Vapnik , V. Parallel support vector machines : The cascade svm .Advances in neural information processing systems .","label":"Background","metadata":{},"score":"42.892807"}
{"text":"Additionally , we show improved translation performance using these reordering models compared to a state - of - the - art baseline system . ...( Koehn et al . , 2005 ) .Here , we use the maximum entropy principle to combine a variety of different features .","label":"Background","metadata":{},"score":"42.94168"}
{"text":"[ 12 ] Chen , R. and Sivakumar , K. and Kargupta , H. An approach to online Bayesian learning from multiple data streams .Workshop on Ubiquitous Data Mining for Mobile and Distributed Environments , Freiburg , Germany , 2001 .","label":"Background","metadata":{},"score":"42.996006"}
{"text":"To answer this question , he runs an experiment to evaluate the behavior of the two systems on held - out data .In this paper , we consider how to make such experiments more statistically reliable .We provide a systematic analysis of the effects of optimizer instability - an extraneous variable that is seldom controlled for - on experimental outcomes , and make recommendations for reporting results more accurately .","label":"Background","metadata":{},"score":"43.042953"}
{"text":"[34 ] Chang , E.Y. and Bai , H. and Zhu , K. Parallel algorithms for mining large - scale rich - media data .Proceedings of the seventeen ACM international conference on Multimedia .[ 35 ] Oei , C. and Friedland , G. and Janin , A. Parallel Training of a Multi - Layer Perceptron on a GPU .","label":"Background","metadata":{},"score":"43.043045"}
{"text":"We also compare two different update strategies , one where we update towards an oracle translation candidate extracted from an N - best list vs a more aggressive approach in which we update towards an oracle extracted prior to training using a minloss decoder .","label":"Background","metadata":{},"score":"43.0892"}
{"text":"The log - linear parameters are then estimated by minimum error rate training ( MERT ) .The weights .is the set of sentence pairs over which MERT is performed .Solving ( 3 ) is difficult because the decoding necessary to produce the hypothesis translation is expensive .","label":"Background","metadata":{},"score":"43.114403"}
{"text":"Res . , 7 , 551 - 585.2006 .[16 ] Kivinen , J. , & M.K.Warmuth . \" Additive versus exponentiated gradient updates for linear prediction \" , Information and Computation , 132 , 1 - 64 .[17 ] Kivinen , J. , Smola , A. J. , & C.Williamson , R. ( 2002 ) .","label":"Background","metadata":{},"score":"43.1317"}
{"text":"Using long phrases will help when the system has to translate sequences of words that match what was encountered in the training corpus , but this becomes increasingly unlikely as the phrases become longer .On the other hand , short sentences are more often reused , but may also be more ambiguous and lead to errors more often .","label":"Background","metadata":{},"score":"43.218315"}
{"text":"In Section 3.4 , we report the correlation coefficient between all the measures .Each correlation coefficient is computed using the results of the 160 experiments described above .Acknowledgments .This work is supported by the EU IST Project SMART ( FP6 - 033917 ) .","label":"Background","metadata":{},"score":"43.27126"}
{"text":"966 - 970 ( 2008 ) .Montana , G. , Triantafyllopoulos , K. , Tsagaris , T. : Flexible least squares for temporal data mining and statistical arbitrage .Expert Systems with Applications ( 2008 ) doi:10.1016/j.eswa.2008.01.062 .Nalbantov , G. , Bauer , R. , Sprinkhuizen - Kuyper , I. : Equity style timing using support vector regressions .","label":"Background","metadata":{},"score":"43.289318"}
{"text":"A decision - tree - based SCM is tested on Chinese - to - English translation , and outperforms a baseline distortion penalty approach at the 99 % confidence level . ... istortion penalty proportional to the difference between the new and the original phrase order ( Koehn , 2004 ) .","label":"Background","metadata":{},"score":"43.29139"}
{"text":"P. Koehn , \" Statistical significance tests for machine translation evaluation , \" in Proceedings of the Conference on Empirical Methods in Natural Language Processing , pp .388 - 395 , Barcelona , Spain , 2004 . A. Stolcke , \" Srilm - an extensible language modeling toolkit , \" in Proceedings of the International Conference on Spoken Language Processing , Denver , Colo , USA , 2002 .","label":"Background","metadata":{},"score":"43.340866"}
{"text":"For each subset , a new instance of the PBSMT system has been created , for a total of 100 models .Each model has been tested on the test set and on a subset of 2,000 pairs the training set .","label":"Background","metadata":{},"score":"43.39173"}
{"text":"The resulting system is used as a preprocessor for both training and test sentences , transforming Chinese sentences to be much closer to English in terms of their word order .We evaluated the reordering approach within the MOSES phrase - based SMT system ( Koehn et al . , 2007 ) .","label":"Background","metadata":{},"score":"43.48195"}
{"text":"F. J. Och and H. Weber , \" Improving statistical natural language translation with categories and rules , \" in Proceedings of the 17th International Conference on Computational Linguistics , vol .2 , pp .985 - 989 , Stroudsburg , Pa , USA , 1998 .","label":"Background","metadata":{},"score":"43.48352"}
{"text":"The influence of alignment quality on parsing improvement is also worth studying .From a linguistics point of view , we would like to see how linguistics distance affects this approach , e.g. , we sus ... . \" ...Several attempts have been made to learn phrase translation probabilities for phrasebased statistical machine translation that go beyond pure counting of phrases in word - aligned training data .","label":"Background","metadata":{},"score":"43.86569"}
{"text":"We use a publicly available structured output SVM to create a max - margin syntactic aligner with a soft cohesion constraint .The resulting aligner is the first , to our knowledge , to use a discriminative learning method to train an ITG bitext parser . ... rence for links to appear near one another ( Vogel et al .","label":"Background","metadata":{},"score":"43.917572"}
{"text":"Therefore , the principal bottlenecks to the amoun ... \" .The best systems for machine translation of natural language are based on statistical models learned from data .Conventional representation of a statistical translation model requires substantial offline computation and representation in main memory .","label":"Background","metadata":{},"score":"43.930893"}
{"text":"[ 63 ] Hall , L. and Bowyer , K. and Kegelmeyer , W. and Moore , T. and Chao , C. Distributed learning on very large data sets .Workshop on Distributed and Parallel Knowledge Discover .[ 64 ] J Beringer , E Hüllermeier .","label":"Background","metadata":{},"score":"44.05117"}
{"text":"The SCFG formulation has a practical benefit : we can take advantage of the heavily - optimized SCFG decoders for machine translation .5 Experiments 5.1 Standard Parsing Experiments We evaluate parsing accuracy of the Stanford and DP - TSG models ( Table 6 ) .","label":"Background","metadata":{},"score":"44.19493"}
{"text":"In ( Tillmann and Zhang , 2006 ) the model is optimized to produce a block orientation and the target sentence is used only for computing a sentence level BLEU .( Liang et al . , 2006 ) demonstrates a dis ... .","label":"Background","metadata":{},"score":"44.201187"}
{"text":"Previous generative word alignment models have made structural assumptions such as the 1-to-1 , 1-to - N , or phrase - based consecutive word assumptions , while previous discriminative models have either made such ... \" .Word alignment is the problem of annotating parallel text with translational correspondence .","label":"Background","metadata":{},"score":"44.209095"}
{"text":"In statistical machine translation , a researcher seeks to determine whether some innovation ( e.g. , a new feature , model , or inference algorithm ) improves translation quality in comparison to a baseline system .To answer this question , he runs an experiment to evaluate the behavior of the two systems ... \" .","label":"Background","metadata":{},"score":"44.39199"}
{"text":"1567 - 1581 , 2012 .View at Publisher · View at Google Scholar .S. Yin , H. Luo , and S. Ding , \" Real - time implementation of fault - tolerant control systems with performance optimization , \" IEEE Transactions on Industrial Electronics , vol .","label":"Background","metadata":{},"score":"44.395676"}
{"text":"We present an approach to semantics - based statistical machine translation that uses synchronous hyperedge replacement grammars to translate into and from graph - shaped intermediate meaning representations , to our knowledge the first work in NLP to make use of synchronous context free graph grammars .","label":"Background","metadata":{},"score":"44.44831"}
{"text":"We present discriminative reordering models for phrase - based statistical machine translation .The models are trained using the maximum entropy principle .We use several types of features : based on words , based on word classes , based on the local context .","label":"Background","metadata":{},"score":"44.466904"}
{"text":"We present discriminative reordering models for phrase - based statistical machine translation .The models are trained using the maximum entropy principle .We use several types of features : based on words , based on word classes , based on the local context .","label":"Background","metadata":{},"score":"44.466904"}
{"text":"Relative Importance of TM and LM .In the previous section , experiments have been run using the same training set size for language and translation models .In general , there is a large difference in terms of cost of retrieving training data for language and translation models ; the former can be trained using monolingual data , while the second needs bilingual texts .","label":"Background","metadata":{},"score":"44.52816"}
{"text":"The first statistical models were word based [ 2 , 11 ] , combining a Markovian language model with a generative word - to - word translation model , in a noisy channel model inspired by speech recognition research .Current state - of - the - art SMT uses phrase - based models , which generalized and superseded word - based models .","label":"Background","metadata":{},"score":"44.534348"}
{"text":"Performance of an SMT system is a function of the dimension of the training data that can be logarithmic as seen in the previous section .We have modelled this relation in the following way : . of the data as increasing set size .","label":"Background","metadata":{},"score":"44.823997"}
{"text":"263 - 311 , 1994 .View at Google Scholar .P. Koehn , F. J. Och , and D. Marcu , \" Statistical phrase - based translation , \" in Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology , pp .","label":"Background","metadata":{},"score":"44.973976"}
{"text":"2142 - 2147 , Genova , Italy , 2006 .N. Draper and H. Smith , Applied Regression Analysis , John Wiley & Sons , New York , NY , USA , 1981 .F. J. Och , \" Statistical machine translation : foundations and recent advances , \" in Proceedings of the Tutorial at MT Summit , 2005 .","label":"Background","metadata":{},"score":"44.974976"}
{"text":"Instead , most have implicit connections to particular forms of ramp loss .We propose to minimize ramp loss directly and present a training algorithm that is easy to implement and that performs comparably to others .Most notably , our structured ramp loss minimization algorithm , RAMPION , is less sensitive to initialization and random seeds than standard approaches . by Taro Watanabe , Jun Suzuki , Hajime Tsukada , Hideki Isozaki - In Proc . of EMNLP , 2007 . \" ...","label":"Background","metadata":{},"score":"45.071175"}
{"text":"Pairwise ranking ( Shen et al ., 2004 ; Hopkins and May , ... . \" ...Jointly parsing two languages has been shown to improve accuracies on either or both sides .However , its search space is much bigger than the monolingual case , forcing existing approaches to employ complicated modeling and crude approximations .","label":"Background","metadata":{},"score":"45.097725"}
{"text":"Small test set sizes produce a big variance in BLEU score .When increasing the test set size , the error bars tend to reduce .using two different test sets of the same size depend on the test set choice and not on different techniques .","label":"Background","metadata":{},"score":"45.32418"}
{"text":"This learning curve reports BLEU score versus the percentage of perturbation applied .These results have been obtained using a fixed training set size equal to 62,995 and 629,957 pairs of sentences and Moses as translation system .Figure 7 : Unlearning curves .","label":"Background","metadata":{},"score":"45.350338"}
{"text":"We propose a novel unsupervised word alignment model based on the Hidden Markov Tree ( HMT ) model .Our model assumes that the alignment variables have a tree structure which is isomorphic to the target dependency tree and models the dis - tortion probability based on the source de - pendency tree , thereby incorporating the syntactic structure from both sides of the parallel sentences .","label":"Background","metadata":{},"score":"45.45549"}
{"text":"Some will be quick to point out that maximizing , for example , BLEU may neither be necessary for , nor guarantee good translation performance .Although we acknowledge that automatic MT metrics may not tell the whole story as far as translation quality is concerned , our systematic study aims at characterizing the behaviour of SMT systems that are built by maximizing such metrics .","label":"Background","metadata":{},"score":"45.561783"}
{"text":"We propose a novel reordering model for phrase - based statistical machine translation ( SMT ) that uses a maximum entropy ( MaxEnt ) model to predicate reorderings of neighbor blocks ( phrase pairs ) .The model provides content - dependent , hierarchical phrasal reordering with generalization based on features automatically learned from a real - world bitext .","label":"Background","metadata":{},"score":"45.59491"}
{"text":"The algorithm reuses the old models of the classifier and trains only one binary subclassifier when a new class comes .But it is not suitable to large data set , because all samples participate in the training in the process of each incremental learning .","label":"Background","metadata":{},"score":"45.61115"}
{"text":"Wen , Y. , Lu , B. : Advances in Knowledge Discovery and Data Mining , chapter Incremental Learning of Support Vector Machines by Classifier Combining , pp .904 - 911 .Springer , Heidelberg ( 2007 ) .Weng , J. , Zhang , Y. , Hwang , W.S. : Candid covariance - free incremental principal component analysis .","label":"Background","metadata":{},"score":"45.770084"}
{"text":"This phrase - based machine translation approach relies on a specific representation of the translation process , such as the choice of contiguous word sequences ( phrases ) as basic units in the language and translation models .How far can this representation take us towards the target of improving translation quality ?","label":"Background","metadata":{},"score":"45.792015"}
{"text":"However , we present a non - trivial O(n3 ) algorithm , based on chart parsing , that at least finds the best reordering within a certain exponentially large neighborhood .We show how to iterate this reordering process within a local search algorithm , which we use in training . ... rst reordering the source language , then translating it , both using different versions of a phrase - based translation system .","label":"Background","metadata":{},"score":"45.948723"}
{"text":"Statistical machine translation ( SMT ) treats the translation of natural language as a machine learning problem .By examining many samples of human - produced translation , SMT algorithms automatically learn how to translate .SMT has made tremendous strides in less than two decades , and many popular tec ... \" .","label":"Background","metadata":{},"score":"46.01329"}
{"text":"IEEE Transactions on Signal Processing , 52 , 2165 - 2176 .[ 18 ] Vijayakumar , S. and D'souza , A. and Schaal , S. Incremental online learning in high dimensions .Neural Computation .[19 ] Chu , Cheng - Tao and Kim , Sang K. and Lin , Yi - An and Yu , Yuanyuan and Bradski , Gary and Ng , Andrew Y. and Olukotun , Kunle .","label":"Background","metadata":{},"score":"46.029232"}
{"text":"We use a Conditional Random Field ( CRF ) , a discriminative model , which is estimated on a small supervised training set .The CRF is conditioned on both the source and target texts , and thus allows for the use of arbitrary and overlapping features over these data .","label":"Background","metadata":{},"score":"46.050587"}
{"text":"In fact , a common belief in SMT is that learning curves follow logarithmic laws ; to analyze this in our experiments , we show all the learning curves in the linear log scale , where we can study if the curve has a linear behaviour .","label":"Background","metadata":{},"score":"46.256283"}
{"text":"[ 55 ] Woodland , PC and Povey , D. Large scale discriminative training for speech recognition .[56 ] RK Ahuja , Ö Ergun , JB Orlin , AP Punnen .A survey of very large - scale neighborhood search techniques .","label":"Background","metadata":{},"score":"46.326412"}
{"text":"This paper presents a maximum entropy machine translation system using a minimal set of translation blocks ( phrase - pairs ) .The new model is a direct translation model ( DTM ) formulation which allows easy integration of additional / alternative views of both source and target sentences such as segmentation for a source language such as Arabic , part - of - speech of both source and target , etc .","label":"Background","metadata":{},"score":"46.543137"}
{"text":"Role of Training Set Size on Performance on New Sentences .In this section , we analyze how training set size affects the performance by creating learning curves ( BLEU score versus training set size ) .The general framework for this set of experiments consists of creating subsets of the complete corpus by subsampling from a uniform distribution without replacement .","label":"Background","metadata":{},"score":"46.61248"}
{"text":"A recent paper ( Collins et al . , 2005 ) shows that major gains can be obtaine ...Learning to Translate : A Statistical and Computational Analysis .Received 15 July 2011 ; Accepted 30 January 2012 .Academic Editor : Peter Tino .","label":"Background","metadata":{},"score":"46.858635"}
{"text":"Statistics on the phrase pair are accumulated over the entire corpus .In our experiments below , we rely on word - to - word IBM models [ 2 ] for alignment .Although more elaborate techniques have appeared more recently [ 13 , 14 ] , their impact on the resulting machine translation quality is still unclear [ 15 ] .","label":"Background","metadata":{},"score":"46.888924"}
{"text":"Cambridge University Press , Cambridge ( 2004 ) .Tay , F. , Cao , L. : ε -descending support vector machines for financial time series forecasting .Neural Processing Letters 15 , 179 - 195 ( 2002 ) MATH CrossRef .","label":"Background","metadata":{},"score":"46.898636"}
{"text":"View at Scopus .C. Domeniconi and D. Gunopulos , \" Incremental support vector machine construction , \" in Proceedings of the IEEE International Conference on Data Mining ( ICDM ' 01 ) , pp .589 - 592 , December 2001 .","label":"Background","metadata":{},"score":"46.921555"}
{"text":"View at Scopus .C. Domeniconi and D. Gunopulos , \" Incremental support vector machine construction , \" in Proceedings of the IEEE International Conference on Data Mining ( ICDM ' 01 ) , pp .589 - 592 , December 2001 .","label":"Background","metadata":{},"score":"46.921555"}
{"text":"Computers & Operations Research ( 2004 ) .Ince , H. , Trafalis , T.B. : A hybrid model for exchange rate prediction .Decision Support Systems 42 , 1054 - 1062 ( 2006 ) CrossRef .Laskov , P. , Gehl , C. , Kruger , S. : Incremental support vector learning : analysis , implementation and applications .","label":"Background","metadata":{},"score":"46.929764"}
{"text":"F. J. Och , \" Minimum error rate training in statistical machine translation , \" in Proceedings of the 41st Annual Meeting on Association for Computational Linguistics , pp .160 - 167 , Sapporo , Japan , 2003 .W. H. Press , S. A. Teukolsky , W. T. Vetterling , and B. P. Flannery , Numerical Recipes in C++ , Cambridge University Press , Cambridge , Mass , USA , 2002 . A. Arun and P. Koehn , \" Online learning methods for discriminative training of phrase based statistical machine translation , \" in Proceedings of 11th the Machine Translation Summit , Copenhagen , Denmark , 2007 .","label":"Background","metadata":{},"score":"46.970566"}
{"text":"L. Specia , M. Turchi , Z. Wang , J. Shawe - Taylor , and C. Saunders , \" Improving the confidence of machine translation quality estimates , \" in Proceedings of 12th the Machine Translation Summit , 2009 . D. Vilar , J. Xu , L. F. D'Haro , and H. Ney , \" Error analysis of statistical machine translation output , \" in Proceedings of the 5th International Conference on Language Resources and Evaluation ( LREC ' 06 ) , Genova , Italy , 2006 .","label":"Background","metadata":{},"score":"47.0223"}
{"text":"He , Y. , Zhu , Y. , Duan , D. : Research on hybrid arima and support vector machine model in short term load forecasting .In : Proceedings of the Sixth International Conference on Intelligent Systems Design and Applications ( 2006 ) .","label":"Background","metadata":{},"score":"47.052773"}
{"text":"However , this hard constraint can also rule out correct alignments , and its utility decreases as alignment models become more ... \" .Word alignment methods can gain valuable guidance by ensuring that their alignments maintain cohesion with respect to the phrases specified by a monolingual dependency tree .","label":"Background","metadata":{},"score":"47.271767"}
{"text":"For each subset , a new instance of the PBSMT system has been created , for a total of 200 models .Two hundred experiments have then been run on an independent test set ( of 2,000 sentences , also not included in any other phase of the experiment ) .","label":"Background","metadata":{},"score":"47.308006"}
{"text":"We demonstrate that even when these models are used as a mere preprocessing step for German - English translation , they significantly outperform Moses ' integrated le ... \" .We apply machine learning to the Linear Ordering Problem in order to learn sentence - specific reordering models for machine translation .","label":"Background","metadata":{},"score":"47.324623"}
{"text":"One way to achieve this could be to either introduce an oracle to which the system can ask for annotation when needed or a process that uses linguistic knowledge to create new table entries based on existing table entries and some grammatical rules .","label":"Background","metadata":{},"score":"47.45079"}
{"text":"For the second set of experiments , data has been randomly sampled in training and test sets one thousand times .Training set has been used to estimate the alphas and the residual , and test set to predict the BLEU score values .","label":"Background","metadata":{},"score":"47.681114"}
{"text":"Estimating a machine translation system is therefore similar to learning the mapping between the source / input and the target / output , a problem which has been extensively studied in statistics and in machine learning .This justifies our view of a typical phrase - based machine translation model as a learning system and motivates our analysis of the performance on that system .","label":"Background","metadata":{},"score":"47.731056"}
{"text":"An automatic score measures the quality of machine - translated sentences by comparing them to a set of human translations , called reference sentences .The score needs to be able to discriminate good translations from bad ones , whilst considering aspects such as adequacy and fluency .","label":"Background","metadata":{},"score":"47.803123"}
{"text":"Word class language models can be used to integrate longer context with a reduced vocabulary size .Rule table interpolation is applicable for different tasks , e.g. domain adaptation .The decoder distinguishes between lexical and coverage pruning and applies reordering constraints for efficiency . .","label":"Background","metadata":{},"score":"47.822433"}
{"text":"The experimental results show that the proposed algorithm not only improves classification accuracy obviously , but also ensures training speed and classification speed .How to use kernel function theory to increase the density of the samples would be our research work in the future .","label":"Background","metadata":{},"score":"47.83823"}
{"text":"Authors in [ 30 ] reported \" almost linear \" improvements in BLEU score by doubling the training set size .In the presentation [ 32 ] , the claim is that BLEU increases with each doubling of the training set size , by 0.5 and 2.5 BLEU points for the language and translation models , respectively , in the context of Arabic - English translation .","label":"Background","metadata":{},"score":"47.86557"}
{"text":"On the other hand , we show that the problem of finding an optimal alignment can be ... \" .Many phrase alignment models operate over the combinatorial space of bijective phrase alignments .We prove that finding an optimal alignment in this space is NP - hard , while computing alignment expectations is # P - hard .","label":"Background","metadata":{},"score":"47.997215"}
{"text":"295 - 302 , Philadelphia , Pa , USA , 2001 .R. C. Moore , W.-T. Yih , and A. Bode , \" Improved discriminative bilingual word alignment , \" in Proceedings of the 21stInternational Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics ( ACL ' 06 ) , pp .","label":"Background","metadata":{},"score":"48.053703"}
{"text":"Role of Test Set Size on Measuring Performance .BLEU score , the metric used in this work to evaluate the quality of the translation , is test set dependent .It means that different test sets regardless of the dimension can produce variation in the value of the BLEU score .","label":"Background","metadata":{},"score":"48.065628"}
{"text":"In Figure 8 , BLEU score as function of the development size is reported .The optimization procedure increases the quality of the translations .This improvement does not seem to be significant after a certain size of the development set .","label":"Background","metadata":{},"score":"48.170082"}
{"text":"We can not use non - local features with current major methods of sequence labeling such as CRFs due to concerns about complexity .We propose a new perceptron algorithm that can use non - local features .Our algorithm allows the use of all types of non - local features whose values are determined from the ... \" .","label":"Background","metadata":{},"score":"48.251846"}
{"text":"[51 ] S Sonnenburg , G Rätsch , K Rieck .Large scale learning with string kernels .Large Scale Kernel Machines .[52 ] Enright , AJ and Van Dongen , S. and Ouzounis , CA .An efficient algorithm for large - scale detection of protein families .","label":"Background","metadata":{},"score":"48.289497"}
{"text":"Small statistical models by random feature mixing .In workshop on Mobile NLP at ACL , 2008 .[ 4 ] Fern , X.Z. and Brodley , C.E. Random projection for high dimensional data clustering : A cluster ensemble approach .Machine learning - international workshop then conference .","label":"Background","metadata":{},"score":"48.372562"}
{"text":"As a side effect , the phrase table size is reduced by more than 80 % . ... ase training with forced alignment .idea can be seen in Figure 1 .Since our initial phrases are extracted from the same training data , that we want to align , very long phrases can be found for segmentation .","label":"Background","metadata":{},"score":"48.521374"}
{"text":"Translation of training sentences allows us to estimate the training error .The learning curves in Figure 4 illustrate how the performance is affected by the phrase length .The \" test on test set ' ' curve is less influenced by the phrase length than the \" test on training set ' ' curve .","label":"Background","metadata":{},"score":"48.631996"}
{"text":"Online learning .[ 8 ] Shalev - Shwartz , S. Online learning : Theory , algorithms , and applications .2007 ( Thesis ) .[ 9 ] Artaˇc , M. , Jogan , M. , and Leonardis , A. ( 2002 ) .","label":"Background","metadata":{},"score":"48.697598"}
{"text":"[59 ] Zhang , Y. Solving large - scale linear programs by interior - point methods under the MATLAB environment .Optimization Methods and Software .[ 60 ] Ivor W. Tsang , James T. Kwok , Pak - Ming Cheung .","label":"Background","metadata":{},"score":"48.716263"}
{"text":"To be consistent and to avoid anomalies due to overfitting or particular data combinations , each set of pairs of sentences has been randomly sampled .The number of pairs is fixed , and a program selects them randomly from the whole original training , development , or test set using a uniform distribution .","label":"Background","metadata":{},"score":"48.75992"}
{"text":"Figure 3 : Chinese - English learning curve obtained using UN corpus and Portage .In all the figures , the curves are increasing linearly or slightly more slowly than that , suggesting a learning curve that is \" at best ' ' logarithmically increasing with the training set size .","label":"Background","metadata":{},"score":"48.858906"}
{"text":"( ii ) Unlearning by Randomization of Parameters .The second kind of noise that we add to the model is based on a swap of a particular quantity inside two entries of language or translation model .This is meant to test how robust the system is to perturbations of the all - important associations between phrases / numbers and to the associations between source / target phrases .","label":"Background","metadata":{},"score":"48.88479"}
{"text":"Nicholas , J.G. : Market - Neutral Investing : Long / Short Hedge Fund Strategies .Bloomberg Professional Library ( 2000 ) .Parrella , F. , Montana , G. : A note on incremental support vector regression .Technical report , Imperial College London ( 2008 ) .","label":"Background","metadata":{},"score":"49.074165"}
{"text":"Conclusion .Data - driven solutions to classic AI problems are now commonplace , ranging from computer vision to information retrieval tasks , and machine translation is one of the main successes of this approach .The idea of putting learning systems at the centre of all AI methodologies introduces however the need to understand the properties and limitations of these learning components .","label":"Background","metadata":{},"score":"49.152214"}
{"text":"5 ] Gionis , A. ; Indyk , P. , Motwani , R. \" Similarity Search in High Dimensions via Hashing \" .Proceedings of the 25th Very Large Database ( VLDB ) Conference .[ 6 ] Q. Shi , J. Petterson , G. Dror , J. Langford , A. Smola , A. Strehl , and V. Vishwanathan . , \" Hash kernels \" , In International Conference on Artificial Intelligence and Statistics , 2009 .","label":"Background","metadata":{},"score":"49.206284"}
{"text":"We extend existing research on bilingual lexicon induction to estimate both lexical and phrasal translation probabilities for MT - scale phrasetables .We ... \" .We estimate the parameters of a phrasebased statistical machine translation system from monolingual corpora instead of a bilingual parallel corpus .","label":"Background","metadata":{},"score":"49.23758"}
{"text":"The parameterization of SCFG models follows a similar pattern of diversity .2.4.2 Discriminative Models Generative models are useful i ..Tools . by Yang Liu , Qun Liu , Shouxun Lin - in Proceedings of COLING - ACL , 2006 . \" ...","label":"Background","metadata":{},"score":"49.34955"}
{"text":"Richer hypothesis classes can fit the training data more accurately but generalize less well than poorer classes , a phenomenon known as overfitting .The choice of the appropriate expressive power , within a parametrized class of models , is called model selection and is one of the most crucial steps in the design of learning systems .","label":"Background","metadata":{},"score":"49.429867"}
{"text":"This is because the rate of improvement of translation performance is at best logarithmic with the training set size .We estimate that bridging the gap between training and test error would require about .paired bilingual sentences , which is larger than the current estimated size of the web .","label":"Background","metadata":{},"score":"49.57881"}
{"text":"Our models are trained on automatically aligned bitext .Their form is simple but novel .They assess , based on features of the input sentence , how strongly each pair of input word tokens wi , wj would like to reverse their relative order .","label":"Background","metadata":{},"score":"50.059677"}
{"text":".. ave important effects on the TATbased model .Acknowledgement This work is supported by National High Technology Research and Development Program contract \" Generally Technical Research and Basic Database Establishment of Chinese Platform\"(Subj ... . by Er Fraser Daniel Marcu - In Technical Report ISI - TR-616 . html , ISI / University of Southern California , 2006 . \" ...","label":"Background","metadata":{},"score":"50.56711"}
{"text":"These are no ... . by Denis Yuen , Michel Simard , Patrick Paul , George Foster , Eric Joanis , Howard Johnson - In HLT - NAACL , 2006 . \" ...This paper presents a new approach to distortion ( phrase reordering ) in phrasebased machine translation ( MT ) .","label":"Background","metadata":{},"score":"50.636246"}
{"text":"Experiments on Arabic - to - English translation indicated that a model trained with sparse binary features outperformed a conventional SMT system with a small number of features . ... ing on a small development set - less than 1 K sentences - was sufficient to achieve improved performance .","label":"Background","metadata":{},"score":"50.70885"}
{"text":"For each percentage value , ten experiments have been run .All the perturbations have been applied on a model trained with 629,957 pairs of sentences randomly selected form the Europal data using Moses as translation system .The unlearning curves are shown in Figure 7 .","label":"Background","metadata":{},"score":"50.746513"}
{"text":"How much space for improvement is there , given new data or new statistical estimation methods or given different models with different complexities ?Before we present experimental results that address these questions , we will describe the setup that was used to obtain these results .","label":"Background","metadata":{},"score":"50.761444"}
{"text":"On the other hand , optimization is really expensive in terms of computational cost .In Figure 9 , it increases roughly linearly with the development set size .It is nice to note how the computational time is strongly related to the number of optimization steps in Figure 10 . A.2 .","label":"Background","metadata":{},"score":"51.0251"}
{"text":"[53 ] Berry , M.W. Large - scale sparse singular value computations .International Journal of Supercomputer Applications .[54 ] Crowder , H. and Johnson , E.L. and Padberg , M. Solving large - scale zero - one linear programming problems .","label":"Background","metadata":{},"score":"51.03816"}
{"text":"While we refer to \" words swap ' ' when , given two entries of the translation model , we swap the target language phrases .Three different sets of experiments have been run applying \" numerical swap ' ' only to the language model , \" numerical swap ' ' only to the translation model and \" words swap ' ' only to the translation model .","label":"Background","metadata":{},"score":"51.04349"}
{"text":"A.1 .Effect of Data Size in Optimization Set .In this section , we study the role of the optimization / development set with regard to the quality of translation .In particular , we analyze how different sizes of the development set affect the performance and the computational cost of the optimization phase .","label":"Background","metadata":{},"score":"51.060432"}
{"text":"The millions of parameters were tuned only on a small development set consisting of less than 1 K sentences .Experiments on Arabic - to - Engli ... \" .We achieved a state of the art performance in statistical machine translation by using a large number of features with an online large - margin training algorithm .","label":"Background","metadata":{},"score":"51.077057"}
{"text":"W. Locke and A. Booth , Machine Translation of Languages , MIT Press , Cambridge , Mass , USA , 1955 .P. F. Brown , S. D. Pietra , V. J. D. Pietra , and R. L. Mercer , \" The mathematic of statistical machine translation : parameter estimation , \" Computational Linguistics , vol .","label":"Background","metadata":{},"score":"51.09822"}
{"text":"What is the best function class to map Spanish documents into English documents ?This is a question of linguistic nature and has been the subject of a long debate .With the growing availability of bilingual parallel corpora , the 1990 s saw the development of statistical machine translation ( SMT ) models .","label":"Background","metadata":{},"score":"51.113132"}
{"text":"MathSciNet .Littlestone , N. , Warmuth , M.K. : The weighted majority algorithm .Information and Computation 108 , 212 - 226 ( 1994 ) MATH CrossRef MathSciNet .Ma , J. , Theiler , J. , Perkins , S. : Accurate on - line support vector regression .","label":"Background","metadata":{},"score":"51.177887"}
{"text":"We also conducted a series of experiments to analyze the accuracy and impact of different types of reordering rules . ... mple reordering model which has a fixed penalty for reordering moves in the decoder .The model of Chiang ( 2005 ) employs a synchronous context - free grammar to allow hierarchical approaches to reordering .","label":"Background","metadata":{},"score":"51.265285"}
{"text":"Both of these ideas of course are being pursued at the moment .It is of course important to remark that these limitations only refer to the current systems , where language is modelled as a Markov chain , and by entirely changing language model , different limitations could be found .","label":"Background","metadata":{},"score":"51.29406"}
{"text":"The ... . by Gonzalo Iglesias , Adrià Gispert - In Proceedings of the EACL , 2009 . \" ...We describe refinements to hierarchical translation search procedures intended to reduce both search errors and memory usage through modifications to hypothesis expansion in cube pruning and reductions in the size of the rule sets used in translation .","label":"Background","metadata":{},"score":"51.528122"}
{"text":"Moreover , the training procedure treats the decoder as a black - box , and thus can be used to optimize any decoding scheme .The training algorithm is evaluated on a standard Arabic - English translation task . ... ttom to top , one block at a time .","label":"Background","metadata":{},"score":"51.6856"}
{"text":"( i ) Unlearning by Adding Noise .A percentage of noise has been added to each probability , . , in the Language model , including conditional probability , and translation model , bidirectional phrase translation probabilities and lexicalized weighting .","label":"Background","metadata":{},"score":"51.910255"}
{"text":"We describe a novel leavingone - out approach to prevent over - fitting that allows us to train phrase models that show improved translation performance on the WMT08 Europarl German - English task .In contrast to most previous work where phrase models were trained separately from other models used in translation , we include all components such as single word lexica and reordering models in training .","label":"Background","metadata":{},"score":"51.933197"}
{"text":"[40 ] Ruibin Xi , Nan Lin , Yixin Chen , \" Compression and Aggregation for Logistic Regression Analysis in Data Cubes , \" IEEE Transactions on Knowledge and Data Engineering , vol .21 , no .4 , pp .","label":"Background","metadata":{},"score":"51.96211"}
{"text":"In our experiments on Chineseto - English translation , this MaxEnt - based reordering model obtains significant improvements in BLEU score on the NIST MT-05 and IWSLT-04 tasks . \" ...Syntactic reordering approaches are an effective method for handling word - order differences between source and target languages in statistical machine translation ( SMT ) systems .","label":"Background","metadata":{},"score":"52.14053"}
{"text":"This is an active area of research in machine translation [ 35 - 37 ] .The results of the perturbation analysis in Section 5 suggest that the limiting factor in the translation tables is not in the numeric part of the model - the parameters being estimated - but in the phrases contained in it , the entries of the phrase table .","label":"Background","metadata":{},"score":"52.310364"}
{"text":"This paper investigates the task of training discriminatively a phrase based SMT system with millions of features using the structured perceptron and the Margin Infused Relax Algorithm ( MIRA ) , two popular online learning algorithms .We also compare two different update strategies , one where we updat ... \" .","label":"Background","metadata":{},"score":"52.393898"}
{"text":"In other words , the essential limiting factor for phrase - based SMT systems seems to be the Zipf law found in natural language .Our large - scale analysis also suggests that the current bottleneck of the phrase - based SMT approach is the lack of sufficient data , not the function class used for the representation of translation systems .","label":"Background","metadata":{},"score":"52.44158"}
{"text":"21 ] Yael Ben - Haim and Elad Yom - Tov .A streaming parallel decision tree algorithm .ICML 2008 workshop on PASCAL Large Scale Learning Challenge .[22 ] Tamir Hazan , Amit Man and Amnon Shashua .A Parallel Decomposition Solver for SVM : Distributed Dual Ascend using Fenchel Duality .","label":"Background","metadata":{},"score":"52.49244"}
{"text":"It is important to notice , however , that introducing a more aggressive type of noise ( Figure 7(b ) ) that essentially replaces entire parameters with random values does lead to a more significant decline in performance .This was obtained by swapping random entries , and so after 100 percent of swaps essentially every entry is a random number ( because the locations to swap are chosen with replacement ) .","label":"Background","metadata":{},"score":"52.547413"}
{"text":"tried by MERT , new hypothesis translations are added to the list .As the number of hypotheses produced by the decoder is finite , this is guaranteed to converge , and in practice , it does fairly quickly .An additional difficulty is that the landscape of the cost , for example , BLEU , is piecewise constant and highly irregular .","label":"Background","metadata":{},"score":"52.667027"}
{"text":"One , containing 1,159,914 pairs of sentences , has been used to train the model .This step has been done only once , and all the experiments use the same translation , language , and reordering models .The second set has 100,000 pairs of sentences , and it is used to randomly select the development sets .","label":"Background","metadata":{},"score":"52.991737"}
{"text":"View at Publisher · View at Google Scholar Abstract .Support vector regression ( SVR ) is an established non - linear regression technique that has been applied successfully to a variety of predictive problems arising in computational finance , such as forecasting asset returns and volatilities .","label":"Background","metadata":{},"score":"53.437294"}
{"text":"However , the mapping between words is stored in a very redundant way within the TM , and this depends on the way the translation table is created , based on sentence alignments .Once an alignment has been found between two sentences , essentially every n -gram ( for every value of n ) is a candidate for insertion in the translation table .","label":"Background","metadata":{},"score":"53.46525"}
{"text":"We train a machine translation tool on the parallel training data , using the development data of each language pair to optimize the translation system .With this system we translate the test data , and then use a Naı̈ve Bayes classifier7 for the actual experiments . \" ...","label":"Background","metadata":{},"score":"53.618294"}
{"text":"The shared task included English -- Inuktitut , Romanian -- English , and English -- Hindi sub - tasks , and drew the participation of ten teams from around the world with a total of 50 systems . \" ...This paper proposes a novel method for phrase - based statistical machine translation by using pivot language .","label":"Background","metadata":{},"score":"53.68615"}
{"text":"In each case , we count the number of phrases of each length that were actually used to produce the translation .The right panel of Figure 5 reports these distribution .It shows that , while the models use a fair amount of longer phrases to translate the training material , these longer phrases are essentially never used for translating the test set : 98 % of the phrases are 5-grams or shorter .","label":"Background","metadata":{},"score":"53.87696"}
{"text":"The gentle decline in performance seems to suggest that fine tuning of parameters is not what controls the performance here , and that perhaps advanced statistical estimation or more observations of the same n -grams would not lead to much better performance .","label":"Background","metadata":{},"score":"53.90815"}
{"text":"Previous work on MWE identification has relied primarily on surface statistics , which perform poorly for longer MWEs and can not model discontinuous expressions .To address these p ... \" .Multiword expressions ( MWE ) , a known nuisance for both linguistics and NLP , blur the lines between syntax and semantics .","label":"Background","metadata":{},"score":"53.993244"}
{"text":"Cambridge University Press , Cambridge ( 2000 ) .Elliott , R.J. , van der Hoek , J. , Malcolm , W.P. : Pairs trading .Quantitative Finance , 271 - 276 ( 2005 ) .Gavrishchaka , V.V. , Banerjee , S. : Support vector machine as an efficient framework for stock market volatility forecasting .","label":"Background","metadata":{},"score":"54.03349"}
{"text":"The underlying log - linear model may be interpreted as a maximum entropy model : . is linear in the log domain , which motivates the description of this framework as \" log - linear model ' ' [ 3 , 4 , 12 ] .","label":"Background","metadata":{},"score":"54.23416"}
{"text":"Chang , B.R. , Tsai , H.F. : Forecast approach using neural network adaptation to support vector regression grey model and generalized auto - regressive conditional heteroscedasticity .Expert Systems with Applications : An International Journal 34 , 925 - 934 ( 2008 ) CrossRef .","label":"Background","metadata":{},"score":"54.365196"}
{"text":"Jointly parsing two languages has been shown to improve accuracies on either or both sides .However , its search space is much bigger than the monolingual case , forcing existing approaches to employ complicated modeling and crude approximations .Here we propose a much simpler alternative , bilingually - constrained monolingual parsing , where a source - language parser learns to exploit reorderings as additional observation , but not bothering to build the target - side tree as well .","label":"Background","metadata":{},"score":"54.568348"}
{"text":"Replacements are not allowed .These choices also depend on the high computational cost of the tuning algorithm .For each size , ten random sets have been selected .For each set , an instance of the system has been run .","label":"Background","metadata":{},"score":"54.633896"}
{"text":"It has been distinguished between truly unknown words ( or stems ) and unseen forms of known stems .The unknown words are the direct effect of Zipf 's law in a language , as new words can come , but the training set is not flexible enough to cover them .","label":"Background","metadata":{},"score":"54.6966"}
{"text":"View at Publisher · View at Google Scholar \" ...We propose a novel reordering model for phrase - based statistical machine translation ( SMT ) that uses a maximum entropy ( MaxEnt ) model to predicate reorderings of neighbor blocks ( phrase pairs ) .","label":"Background","metadata":{},"score":"54.857193"}
{"text":"We describe a set of syntactic reorde ... \" .Syntactic reordering approaches are an effective method for handling word - order differences between source and target languages in statistical machine translation ( SMT ) systems .This paper introduces a reordering approach for translation from Chinese to English .","label":"Background","metadata":{},"score":"54.901535"}
{"text":"We extend bilingual paraphrase extraction to syntactic paraphrases and demonstrate its ability to learn a variety of general paraphrastic transformations , including passivization , dative shift , and topicalization .We discuss how our model can be adapted to many text generation tasks by augmenting its feature set , development data , and parameter estimation routine .","label":"Background","metadata":{},"score":"55.121082"}
{"text":"Dependency cohesion refers to the observation that phrases dominated by disjoint dependency subtrees in the source language generally do not overlap in the target language .It has been verified to be a useful constraint for word alignment .However , previous work either treats this as a hard constraint or uses it as a feature in discriminative models , which is ineffective for large - scale tasks .","label":"Background","metadata":{},"score":"55.227493"}
{"text":"The first unlearning curve ( Figure 6 ) , obtained by adding to each parameter a random number ( sampled from within a range ) proportional to its size , is meant to test the role of detailed tuning of parameters .","label":"Background","metadata":{},"score":"55.314007"}
{"text":"They contain different modules to preprocess data and train the language models and the translation models .These models can be tuned using minimum error rate training [ 17 ] .Both use standard external tools for training the language model , such as SRILM [ 23 ] , and Moses also uses GIZA++ [ 24 ] for word alignments .","label":"Background","metadata":{},"score":"55.46434"}
{"text":"The main . \" ...Dependency cohesion refers to the observation that phrases dominated by disjoint dependency subtrees in the source language generally do not overlap in the target language .It has been verified to be a useful constraint for word alignment .","label":"Background","metadata":{},"score":"55.530647"}
{"text":"This is reflected in the two main components of the typical SMT model : the language model and the translation model .The language model is typically built using a table of n -grams , with associated probabilities , which is sufficient to define a Markov chain .","label":"Background","metadata":{},"score":"55.709595"}
{"text":"7sISI - University of Southern California ISI - TR-616 Acknowledgments This work was supporte ... . \" ...Bilingual word alignment forms the foundation of most approaches to statistical machine translation .Current word alignment methods are predominantly based on generative models .","label":"Background","metadata":{},"score":"55.734516"}
{"text":"This can either represent the effect of insufficient statistics in estimating them , or the use of imperfect parameter estimation biases .These parameters are probabilities , phrases , and associations between source / target phrases contained inside translation and language model tables .","label":"Background","metadata":{},"score":"55.912266"}
{"text":"Note that these are not phrases in the linguistic sense , but simply subsequences of words .For a sentence .referred to as a phrase table .Part of the overall MT training process is to estimate this table and the associated probabilities .","label":"Background","metadata":{},"score":"56.099335"}
{"text":"This setting has been applied to Europarl and Giga corpus datasets using Moses as SMT system . vary across the datasets and correspond to an increase of 1.3 to 1.5 BLEU point for the LM and 1.8 to 1.9 for the TM , for each doubling of the data .","label":"Background","metadata":{},"score":"56.43708"}
{"text":"Database - friendly random projections .In Proc .ACM Symp . on the Principles of Database Systems , pages 274 - 281 , 2001 .[ 2 ] Ella Bingham and Heikki Mannila , Random projection in dimensionality reduction : Applications to image and text data , KDD 2001 .","label":"Background","metadata":{},"score":"56.490906"}
{"text":"Table 5 : Performance obtained training the regressor on 80 % of the data and testing on 20 % .This process has been iterated 1,000 times .Experiments have been performed independently on the Europarl and Giga corpus dataset .Role of Phrase Length in the Translation Table ( Model Selection ) .","label":"Background","metadata":{},"score":"56.606754"}
{"text":"The two effects interact with richer classes being better approximators of the target behaviour but requiring more training data to reliably identify the best hypothesis .The resulting trade - off , equally well known in statistics and in machine learning , can be expressed in terms of bias versus variance , capacity control , or model selection .","label":"Background","metadata":{},"score":"56.73394"}
{"text":"For wor ... . \" ...This paper describes the German - English translation system developed by the ARK research group at Carnegie Mellon University for the Sixth Workshop on Machine Translation ( WMT11 ) .We present the results of several modeling and training improvements to our core hierarchical phrase - based translation s ... \" .","label":"Background","metadata":{},"score":"56.83938"}
{"text":"We examine the degradation in translation performance when bilingually estimated translation probabilities are removed and show that 80%+ of the loss can be recovered with monolingually estimated features alone .We further show that our monolingual features add 1.5 BLEU points when combined with standard bilingually estimated phrase table features .","label":"Background","metadata":{},"score":"56.881966"}
{"text":"Our best model produces the lowest alignment error rate yet reported on Canadian Hansards bilingual data . ...e probabalistic models developed at IBM by Brown et al .( 1993 ) , sometimes augmented by an HMMbased model or Och and Ney 's \" Model 6 \" ( Och and Ney , 2003 ) . \" ...","label":"Background","metadata":{},"score":"56.991188"}
{"text":"EDGE , Workshop on Edge Computing Using New Commodity Architectures .[ 39 ] Kumar , NSL and Satoor , S. and Buck , I. Fast Parallel Expectation Maximization for Gaussian Mixture Models on GPUs Using CUDA .Proceedings of the 2009 11th IEEE International Conference on High Performance Computing and Communications - Volume 00 .","label":"Background","metadata":{},"score":"57.045036"}
{"text":"A briefly discussion about the presence of unknown words when we test on a subset of the training set is given by Section 4.3 .Figure 11 : Number of unknown words translating training and test sets versus training set size .","label":"Background","metadata":{},"score":"57.09152"}
{"text":"36 ] Bertsekas , D.P. and Tsitsiklis , J.N. Parallel and distributed computation : numerical methods .[ 37 ] Fung , J. and Mann , S. OpenVIDIA : parallel GPU computer vision .Proceedings of the 13th annual ACM international conference on Multimedia .","label":"Background","metadata":{},"score":"57.130363"}
{"text":"BLEU and NIST are based on averaging n -gram precisions , combined with a length penalty which penalizes short translations containing only sure words .These metrics differ on the way the precisions are combined and on the length penalty .Meteor evaluates a translation by computing a score based on the word alignment between the translation and a given reference translation .","label":"Background","metadata":{},"score":"57.185543"}
{"text":"For each model , we count the unknown words .Figure 11 shows unknown words as function of the training model .It is clear that small training sets are able to cover a small part of the word space .When increasing the dimension of the training set , the number of unknown words decreases .","label":"Background","metadata":{},"score":"57.3043"}
{"text":"857 In this paper , we address the translation problem fo ... . by Karim Filali , Jeff Bilmes - In IEEE Workshop on Automatic Speech Recognition and Understanding . \" ...We present a new multilingual statistical MT word alignment model based on a simple extension of the IBM and HMM Models and a two - step alignment procedure .","label":"Background","metadata":{},"score":"57.442497"}
{"text":"The set of experiments in Figure 7(a ) is harder to explain without discussing the inner workings of the translation model and Moses .Here , we swapped n -grams in the translation table , essentially breaking the connection between words and their translation .","label":"Background","metadata":{},"score":"57.462257"}
{"text":"We have isolated 4,000 pairs of sentences from the Europarl training set , and we have selected from the remaining part 629,957 pairs .A Moses model is trained using this set .Using the 4,000 sentences pairs , we have created 10 random subsets for each of the 16 chosen sizes , where each size can contain a number of pairs from 250 to 4,000 by a step of 250 pairs .","label":"Background","metadata":{},"score":"57.54846"}
{"text":"The differences of our algorithm from these algorithms are as follows .Daumé III and Marcu ( 2005 ) presented the method called LaSO ( Learning as Search Optimization ) , in which intractable exact infe ...A Mahalanobis Hyperellipsoidal Learning Machine Class Incremental Learning Algorithm .","label":"Background","metadata":{},"score":"57.718697"}
{"text":"The model is linguistically syntax - based because TATs are extracted auto - matically from word - aligned , source side parsed parallel texts .To translate a source sentence , we first employ a parser to pro - duce a source parse tree and then ap - ply TATs to transform the tree into a tar - get string .","label":"Background","metadata":{},"score":"57.83291"}
{"text":"This paper describes the several performance techniques used and presents benchmarks against alternative implementations . ... ion 3 .We substantially outperform all of them on queryspeed and offer lower memory consumption than lossless alternatives .Our open - source ( LGPL ) implementation is also available for download as a standalone package with minimal ( POSIX ... . by Juri Ganitkevitch , Chris Callison - burch , Courtney Napoles , Benjamin Van Durme . \" ...","label":"Background","metadata":{},"score":"58.086494"}
{"text":"Data .We used three different sentence - aligned corpora , covering different language pairs and sizes : ( 1 ) Europarl Release v3 Spanish - English [ 7 ] , ( 2 ) UN Chinese - English corpus provided by the Linguistic Data Consortium , ( 3 ) Giga corpus French - English [ 8 ] .","label":"Background","metadata":{},"score":"58.116226"}
{"text":"In ( a ) , \" words swap TM ' ' has been obtained by swapping the target phrases inside the TM .In ( b ) , two unlearning curves have been compared . \"Numerical swap LM ' ' has been obtained applying numerical swaps only to the LM and \" numerical swap TM ' ' applying numerical swaps only to the LM .","label":"Background","metadata":{},"score":"58.142277"}
{"text":"Burgess , A.N. : Applied quantitative methods for trading and investment , chapter Using Cointegration to Hedge and Trade International EquitiesFinance , pp .41 - 69 .Wiley , Chichester ( 2003 ) CrossRef .Cao , D. , Pang , S. , Bai , Y. : Forecasting exchange rate using support vector machines .","label":"Background","metadata":{},"score":"58.368393"}
{"text":"This paper presents the task definition , resources , participating systems , and comparative results for the shared task on word alignment , which was organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts .The shared task included English -- Inuktitut , Romanian -- English , ... \" .","label":"Background","metadata":{},"score":"58.746017"}
{"text":"Average .and error on the Europarl and Giga corpus datasets are shown in Table 5 .The proposed model is able to approximate well enough the BLEU score using Moses as translation system and in - domain test sets .According to this setting and assuming that we are in the standard case where .","label":"Background","metadata":{},"score":"58.91387"}
{"text":".. hought of as a paraphrase grammar .Like Hiero , Madnani 's model uses just one nonterminal X instead of linguistic nonterminals .Three additional efforts incorporated linguistic syntax .Callison - Burch ( 2008 ) introduced syntactic const ... . by Bevan Jones , Jacob Andreas , Daniel Bauer , Karl Moritz Hermann , Kevin Knight . \" ...","label":"Background","metadata":{},"score":"58.977318"}
{"text":"108 - 118 , Springer , New York , NY , USA , 2013 .View at Google Scholar .F. Porikli and Y. Chi , \" Multi - class classification method , \" US Patent 20 , 130 , 156 , 300 , 2013 .","label":"Background","metadata":{},"score":"59.20098"}
{"text":"108 - 118 , Springer , New York , NY , USA , 2013 .View at Google Scholar .F. Porikli and Y. Chi , \" Multi - class classification method , \" US Patent 20 , 130 , 156 , 300 , 2013 .","label":"Background","metadata":{},"score":"59.20098"}
{"text":"The language pairs cover European as well as non - European languages , and the sizes range from 1.2 M to 22.5 M sentence pairs .We expect that translation between European languages will be easier than from Chinese to English ; however , we are not so much interested in the actual translation performance as in the way this performance evolves with increasing data and under a number of conditions .","label":"Background","metadata":{},"score":"59.21879"}
{"text":"We present a new multilingual statistical MT word alignment model based on a simple extension of the IBM and HMM Models and a two - step alignment procedure .Preliminary results on a small hand - aligned subset of the Europarl corpus show a 7 % relative improvement over a state of the art alignment model .","label":"Background","metadata":{},"score":"59.229633"}
{"text":"Understanding the most important reasons for failure of a PBSMT system is a fundamental task .In [ 39 ] , a classification of different types of error has been proposed .In this section , we focus our attention on a particular type of error : unknown words .","label":"Background","metadata":{},"score":"59.33455"}
{"text":"hrase - based derivation of a particular target sentence .Sentences per hour on a four - core server 20,000 Frequency of optimal solutions found 93.4 % Frequency of ɛ - optimal solutions found 99.2 % Table 1 : The solver , tuned for speed , regularly reports solut ... . \" ...","label":"Background","metadata":{},"score":"59.38296"}
{"text":"Keywords .Incremental support vector regression subspace tracking ensemble learning computational finance algorithmic trading .Other actions .Share .References .Bao , Y. , Liu , Z. , Wang , W. : Forecasting stock composite index by fuzzy support vector machine regression .","label":"Background","metadata":{},"score":"59.38926"}
{"text":"These experiments suggest that the phrase length has a limited impact on actual test performance .Going to larger n- grams seems to bring little benefit in terms of performance as the model continues to prefer short phrases during the decoding phase .","label":"Background","metadata":{},"score":"59.677242"}
{"text":"The computational experiments were done on a Pentium 1.6 G with 512 MB memory .Liner kernel function is used for all the experiments .System parameter .( MAAF ) [ 18 ] are used to evaluate the classification performance of the algorithm .","label":"Background","metadata":{},"score":"59.728188"}
{"text":"There is not much difference between MIRA ... . by Abraham Ittycheriah , Salim Roukos - In HLT - NAACL 2007 : Main Conference , 2007 . \" ...This paper presents a maximum entropy machine translation system using a minimal set of translation blocks ( phrase - pairs ) .","label":"Background","metadata":{},"score":"59.73098"}
{"text":"The distortion feature controls the reordering between phrases .Note that only very short - range reordering may be handled within phrases .Long - range reordering must be handled by target phrase permutations .This feature allows to regulate the amount of reordering depending on , for example , the language pair .","label":"Background","metadata":{},"score":"59.831573"}
{"text":"The search for the optimal translation in ( 2 ) is also referred to as decoding as , in the original analogy of the noisy channel , it corresponds to retrieving the clean message ., we usually assume that the feature functions decompose linearly across basic constituents of the sentences .","label":"Background","metadata":{},"score":"59.85713"}
{"text":"To address these problems , we show that even the simplest parsing models can effectively identify MWEs of arbitrary length , and that Tree Substitution Grammars achieve the best results .Our experiments show a 36.4 % F1 absolute improvement for French over ann - gram surface statistics baseline , currently the predominant method for MWE identification .","label":"Background","metadata":{},"score":"60.065956"}
{"text":"For the disadvantage , [ 14 ] proposed a hyperellipsoidal class incremental learning algorithm ( HE - CIL ) , but the algorithm does not consider the influence of the outlier samples .Therefore , a Mahalanobis hyperellipsoidal learning machine class incremental learning algorithm ( MHE - CIL ) is proposed in this paper .","label":"Background","metadata":{},"score":"60.103462"}
{"text":"The noised probability is obtained as ., ten experiments have been run .In this case , we randomly select two fixed training set sizes equal to 62,995 and 629,957 pairs of sentences form the Europarl corpora and use Moses as translation system .","label":"Background","metadata":{},"score":"60.273636"}
{"text":"A Mahalanobis hyperellipsoidal learning machine class incremental learning algorithm is proposed .To each class sample , the hyperellipsoidal that encloses as many as possible and pushes the outlier samples away is trained in the feature space .In the process of incremental learning , only one subclassifier is trained with the new class samples .","label":"Background","metadata":{},"score":"60.42844"}
{"text":"k. NIPS 2008 .[14 ] Li , Y. , & Long , P. M. , \" The relaxed online maximum margin algorithm \" , Mach .Learn . , 46 , 361 - 387.2002 .[ 15 ] Crammer , K. , Dekel , O. , Keshet , J. , Shalev - Shwartz , S. , & Singer , Y. , \" Online passive - aggressive algorithms \" , J. Mach .","label":"Background","metadata":{},"score":"60.62382"}
{"text":"TMs were limited to a phrase length of 7 words , and LMs were limited to 3 .Hardware .All the experiments have been run on high - performance clusters of machines .Additional information : ClearSpeed accelerator boards on the thick nodes ; SilverStorm Infiniband high - speed connectivity throughout for parallel code message passing ; General Parallel File System ( GPFS ) providing data access from all the nodes with a total of 11 terabytes of storage .","label":"Background","metadata":{},"score":"60.833393"}
{"text":"138 - 145 , Morgan Kaufmann Publishers , San Francisco , Calif , USA , 2002 .S. Banerjee and A. Lavie , \" Meteor : an automatic metric for mt evaluation with improved correlation with human judgments , \" in Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics , Ann Arbor , Mich , USA , 2005 .","label":"Background","metadata":{},"score":"61.083107"}
{"text":"A TAT is capable of generating both terminals and non - terminals and per - forming reordering at both low and high levels .The model is l ... \" .We present a novel translation model based on tree - to - string alignment template ( TAT ) which describes the alignment be - tween a source parse tree and a target string .","label":"Background","metadata":{},"score":"61.158363"}
{"text":"The test set is used to evaluate the quality of models on the data .All experiments using Moses have been run using the default parameter configuration .The training , development , and test set sentences are tokenized and lowercased .","label":"Background","metadata":{},"score":"61.454567"}
{"text":"View at Publisher · View at Google Scholar · View at Scopus . Y. P. Qin , X. N. Li , and C. l. Wang , \" Study on class incremental learning algorithm based on hyper - sphere support vector machines , \" Computer Science , vol . 8 , article 28 , 2008 .","label":"Background","metadata":{},"score":"61.46859"}
{"text":"View at Publisher · View at Google Scholar · View at Scopus . Y. P. Qin , X. N. Li , and C. l. Wang , \" Study on class incremental learning algorithm based on hyper - sphere support vector machines , \" Computer Science , vol . 8 , article 28 , 2008 .","label":"Background","metadata":{},"score":"61.46859"}
{"text":"Experiments are made on Reuters 21578 , in which five categories and 896 texts are used .598 texts are used as training set , and the rest 298 texts are used as testing set ( see Table 1 ) .Information gain is used to reduce feature dimension and the weight of every word is computed according to TF - IDF .","label":"Background","metadata":{},"score":"61.900185"}
{"text":"Both learning curves show a big improvement when moving from the word - to - word translation ( phrase length equal to one ) to the phrase - based model ( higher phrase lengths ) .Figure 4 : BLEU versus n -gram length .","label":"Background","metadata":{},"score":"61.92746"}
{"text":"- 1005 ) .S. Yin , S. X. Ding , A. Haghani , H. Hao , and P. Zhang , \" A comparison study of basic data - driven fault diagnosis and process monitoring methods on the benchmark Tennessee Eastman process , \" Journal of Process Control , vol .","label":"Background","metadata":{},"score":"62.4347"}
{"text":"These sites come from the Canadian government , the European Union , the United Nations , and other international organizations .In addition to covering a wide range of themes , they also contain documents with different styles and genres .We estimate that the rate of misaligned sentence pairs was around 13 % .","label":"Background","metadata":{},"score":"62.659737"}
{"text":"[ 23 ] Catanzaro , Bryan and Sundaram , Narayan and Keutzer , Kurt .Fast Support Vector Machine Training and Classification on Graphics Processors .ICML 2008 .[ 24 ] Rajat Raina , Anand Madhavan , Andrew Y. Ng .","label":"Background","metadata":{},"score":"63.094864"}
{"text":"Relative to the complex movement and translation allowed by Hiero and other models , MJ1 is clearly inferior ( Dreyer et al . , 2007 ) ; MJ1 was developed with efficiency in mind so as to run with a mini ... . \" ...","label":"Background","metadata":{},"score":"63.416973"}
{"text":"Google in [ 30 ] has shown that performance improves logarithmically in the linear scale with the number of tokens in the language model training set when this quantity is huge ( from billions to trillions of tokens ) .In this section , we are interested to understand whether there is a trade - off between the training data size used to build language and translation models and how performances are affected by their differences .","label":"Background","metadata":{},"score":"63.60654"}
{"text":"However , it is not clear whether bitexts are an appropriate resource for extracting more sophisticated sentential paraphrases , which are more obviously learnable from monolingual parallel ... \" .Previous work has shown that high quality phrasal paraphrases can be extracted from bilingual parallel corpora .","label":"Background","metadata":{},"score":"63.662495"}
{"text":"\" Test on training set ' ' is a test set selected by the training set for each training set size and no optimization phase .In the \" test on test set ' ' learning curve , there seems to be no significant advantage to using phrases longer than 4 words .","label":"Background","metadata":{},"score":"63.751366"}
{"text":"The decoder is implemented with standard Weighted Finite - State Transducer ( WFST ) operations as an alternative to the well - known cube pruning procedure .We find that the use of WFSTs ra ... \" .In this article we describe HiFST , a lattice - based decoder for hierarchical phrase - based translation and alignment .","label":"Background","metadata":{},"score":"64.24962"}
{"text":"We advance the state - of - the - art for discrimi - natively trained machine translation systems by presenting novel probabilistic inference and search methods for synchronous gram - mars .By approximating the intractable space of all candidate translations produced by inter - secting an ngram language model w ... \" .","label":"Background","metadata":{},"score":"64.52261"}
{"text":"We apply this alignment model to both French - English and Romanian - English language pairs .An exception is Taskar et al .( 2005 ) who presented a word matching model for discriminative alignment which they they were able to solve optimally .","label":"Background","metadata":{},"score":"65.652664"}
{"text":"Using only Lf - Lp and Lp - Le bilingual corpora , we can build a translation model for Lf - Le .The advantage of this method lies in that we can perform translation between Lf and Le even if there is no bilingual corpus available for this language pair .","label":"Background","metadata":{},"score":"65.904564"}
{"text":"View at Scopus .R. Kong and B. Zhang , \" Fast incremental learning algorithm for support vector machine , \" Control and Decision , vol .20 , no .10 , pp .1129 - 1136 , 2005 .View at Google Scholar · View at Scopus .","label":"Background","metadata":{},"score":"66.19325"}
{"text":"View at Scopus .R. Kong and B. Zhang , \" Fast incremental learning algorithm for support vector machine , \" Control and Decision , vol .20 , no .10 , pp .1129 - 1136 , 2005 .View at Google Scholar · View at Scopus .","label":"Background","metadata":{},"score":"66.19325"}
{"text":"Since German is a language that makes productive use of \" closed \" compounds ( compound words written as a single orthographic token ) , we use a CRF segmentation model of to evaluate the probability of ... .by Spence Green , Marie - catherine De Marneffe , John Bauer , Christopher D. Manning . \" ...","label":"Background","metadata":{},"score":"66.2859"}
{"text":"Figure 5 shows that the number of phrases peaks around 4-grams and 5-grams , then steadily decreases .This means that the phrase extraction algorithm finds it more and more difficult to extract longer phrases .We investigate this further by plotting the distribution of phrases actually used while translating .","label":"Background","metadata":{},"score":"66.45297"}
{"text":"This work focuses on the description of its phrase - based functionality .In addition to the standard pipeline , including phrase extraction and parameter optimization , Jane 2 contains several state - of - the - art extensions and tools .","label":"Background","metadata":{},"score":"66.904465"}
{"text":"The TRIE data structure is a trie with bit - level packing , sorted records , interpolation search , and optional quantization aimed at lower memory consumption .TRIE simultaneously uses less memory than the smallest lossless baseline and less CPU than the fastest baseline .","label":"Background","metadata":{},"score":"67.02309"}
{"text":"Compared with the widelyused SRILM , our PROBING model is 2.4 times as fast ... \" .We present KenLM , a library that implements two data structures for efficient language model queries , reducing both time and memory costs .The PROBING data structure uses linear probing hash tables and is designed for speed .","label":"Background","metadata":{},"score":"67.16805"}
{"text":"We have undertaken a large scale experimental and theoretical investigation of these questions .We use this data to inform a discussion about learning curves .We have also investigated the model - selection properties of n -gram size , where the n -grams are the phrases used as building blocks in the translation process .","label":"Background","metadata":{},"score":"67.21295"}
{"text":"The authors declare that there is no conflict of interests regarding the publication of this paper .Acknowledgments .This study is partly supported by the National Natural Science Foundation of China ( no .61304149 ) , the Natural Science Foundation of Liaoning Province in China ( no .","label":"Background","metadata":{},"score":"67.61438"}
{"text":"So if we remove an n -gram , chances are that other similar ( longer or shorter ) n -grams are present and can take over .In this way , it is not possible to directly compare the unlearning curve for the n -grams part with that for the numeric part of the tables .","label":"Background","metadata":{},"score":"68.78024"}
{"text":"185 - 188 , Prague , Czech Republic , 2007 .P. Koehn , \" Europarl : a parallel corpus for statistical machine translation , \" in Proceedings of the 10 th Machine Translation Summit , pp .79 - 86 , Phuket , Thailand , 2005 .","label":"Background","metadata":{},"score":"69.40172"}
{"text":"Finally , conclusion is outlined in Section 5 . is as small as possible .If there are no remote points , then the hyperellipsoidal will enclose all the mappings of sample .If there are remote points , allowing part of the samples outside of the superellipsoid , and searching for the smallest superellipsoid which can surround the most samples .","label":"Background","metadata":{},"score":"69.44801"}
{"text":"are introduced to allow some of the mappings of sample outside the hyperellipsoidal .Using the method that is similar to finding optimal hyperplane of SVM to obtain the smallest hyperellipsoidal [ 15 - 17 ] , the formulation is as follows : .","label":"Background","metadata":{},"score":"72.473"}
{"text":"During decoding , we maximize the score sw(bn 1 , on1 ) of a block orientation sequence Tong ZhangYahoo !Research New ... . by Adria de Gispert , Gonzalo Iglesias , Graeme Blackwood , Eduardo R. Banga , William Byrne - IN PROCEEDINGS OF HLT / NAACL , 2010 . \" ...","label":"Background","metadata":{},"score":"72.53302"}
{"text":"value of MHE - CIL method which are obviously higher than the other two methods .The key reasons are that MHE - CIL method reduces the space that hyperellipsoidal encloses by pushing the outlier samples away , and the information of sample 's distribution is considered by using Mahalanobis distance .","label":"Background","metadata":{},"score":"73.791626"}
{"text":"The file system is Ibrix and provides data access from all nodes , with a total of 17 TB of storage .Experiments using Portage are distributed over several CPUs , the total number of which depends on the various stages in the estimation process .","label":"Background","metadata":{},"score":"73.88969"}
{"text":"Software .Several software packages are available for training PBSMT systems .In this work , we use both Moses [ 5 ] and Portage [ 6 ] .Moses is a complete open - source phrase - based translation toolkit for academic purposes , while Portage is a similar package available to partners of the National Research Council Canada .","label":"Background","metadata":{},"score":"74.90085"}
{"text":"In the process of classification , considering the information of sample 's distribution in the feature space , the Mahalanobis distances from the sample mapping to the center of each hyperellipsoidal are used to decide the classified sample class .The experimental results show that the proposed method has higher classification precision and classification speed .","label":"Background","metadata":{},"score":"75.06993"}
{"text":"We have created 10 random subsets of the complete Europarl corpus containing 629,957 pairs of sentences .For each subset , ten PBMT systems have been estimated .Each instance of Moses has been trained using a different maximum phrase length , from 1 to 10 .","label":"Background","metadata":{},"score":"76.004166"}
{"text":"Mahalanobis distances are used to confirm the classified sample class .The rest of this paper is organized as follows .In Section 2 , a brief review of Mahalanobis hyperellipsoidal learning machine is given .In Section 3 , a new Mahalanobis hyperellipsoidal learning machine class incremental learning algorithm is discussed in detail .","label":"Background","metadata":{},"score":"76.69473"}
{"text":"This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .Abstract .We present an extensive experimental study of Phrase - based Statistical Machine Translation , from the point of view of its learning capabilities .","label":"Background","metadata":{},"score":"77.14734"}
{"text":"It is implemented in C++ and provides efficient decoding algorithms and data structures .This work focuses on the description of its phrase - based ... \" .We present Jane 2 , an open source toolkit supporting both the phrase - based and the hierarchical phrase - based paradigm for statistical machine translation .","label":"Background","metadata":{},"score":"78.901215"}
{"text":"For Lf - Lp and Lp - Le , there exist large bi ... \" .This paper proposes a novel method for phrase - based statistical machine translation by using pivot language .To conduct translation between languages Lf and Le with a small bilingual corpus , we bring in a third language Lp , which is named the pivot language .","label":"Background","metadata":{},"score":"81.36304"}
{"text":"Data & Knowledge Engineering .","label":"Background","metadata":{},"score":"81.53209"}
{"text":"The Europarl corpus contains material extracted from the proceedings of the European parliament , and the UN data contains material from the United Nations .Both therefore cover a wide range of themes , but are fairly homogeneous in terms of style and genre .","label":"Background","metadata":{},"score":"83.597855"}
{"text":"Three times class incremental learning is done ; the first time increment is the third class sample ( coffee ) , the second time increment is the forth class sample ( soybean ) , and the third time increment is the fifth class sample ( cocoa ) .","label":"Background","metadata":{},"score":"84.53258"}
{"text":"A Mahalanobis Hyperellipsoidal Learning Machine Class Incremental Learning Algorithm .Received 23 December 2013 ; Accepted 31 December 2013 ; Published 11 February 2014 .Academic Editor : Ming Liu .Copyright © 2014 Yuping Qin et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .","label":"Background","metadata":{},"score":"88.71627"}
{"text":"Academic Editor : Ming Liu .Copyright © 2014 Yuping Qin et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .","label":"Background","metadata":{},"score":"105.85888"}
