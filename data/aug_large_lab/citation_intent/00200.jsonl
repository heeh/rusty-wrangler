{"text":"The determined predictive model for discourse functions is then saved and/or used .FIG .2 is an exemplary method for determining predictive models for discourse functions according to this invention .The process begins at step S 100 and immediately continues to step S 200 .","label":"Background","metadata":{},"score":"44.636425"}{"text":"Referring now to FIG .40 , a second embodiment of a speech dialogue system according to the present invention will be described in detail .This second embodiment differs from the first embodiment described above in that the detail of the user detection mechanism is incorporated .","label":"Background","metadata":{},"score":"46.096992"}{"text":"FIG .3 can be implemented as portions of a suitably programmed general - purpose computer .The particular form each of the circuits 10 - 60 of the system for determining predictive models of discourse functions 100 outlined above will take is a design choice and will be obvious and predicable to those skilled in the art .","label":"Background","metadata":{},"score":"46.49965"}{"text":"FIG .3 is an exemplary system for determining predictive discourse models 100 according to this invention .A user of the web - enabled personal computer 300 or the web - enabled personal computer 400 initiates a request to determine a prosodic feature model for the training instances 1000 - 1002 of natural language speech utterances contained in information repository 200 .","label":"Background","metadata":{},"score":"46.804"}{"text":"1 is an overview of an exemplary system for determining predictive models of discourse functions according to this invention ; .FIG .2 is an exemplary method for determining predictive models for discourse functions according to this invention ; .FIG .","label":"Background","metadata":{},"score":"49.78151"}{"text":"The system for determining predictive models of discourse functions 100 retrieves training instance 1000 of the natural language speech utterances from the information repository 200 by activating the input / output circuit 10 .The processor 30 saves the training instance 1000 in memory 20 and activates the prosodic feature determination routine or circuit 40 .","label":"Background","metadata":{},"score":"49.966545"}{"text":"[ 0102 ] .( 3 ) the use of spoken language interfaces and the flexibility of the natural language modality that makes it possible to extract additional information contained in prosody of speech ; .[ 0103 ] .( 4 ) an architecture that is tailored to the special requirements of the tutoring domain ; and .","label":"Background","metadata":{},"score":"50.594402"}{"text":"BRIEF DESCRIPTION OF THE DRAWINGS .[ 0036 ] .FIG .1 is a block diagram of a preferred embodiment of an emotion analyzer distributed across a client / server computing architecture , and can be used as an interactive learning system , an e - commerce system , an e - support system , and the like ; .","label":"Background","metadata":{},"score":"50.7491"}{"text":"10 is a block diagram of an exemplary system for determining predictive models of discourse functions according to this invention ; .FIG .11 is an exemplary data structure for storing speech utterance prosody information according to this invention ; and .","label":"Background","metadata":{},"score":"51.075085"}{"text":"In one of the various exemplary embodiments according to this invention , a user of the web - enabled personal computer 300 initiates a request to determine a predictive model of discourse functions for the training instances 1000 - 1002 .The training instances 1000 - 1002 are associated with of the recorded natural language speech utterances contained in the information repository 200 .","label":"Background","metadata":{},"score":"51.49995"}{"text":"Then , the process according to the flow chart of FIG .13 is carried out in the user state as follows .Then , at the step S112 , the consistency of the additional order made by the semantic utterance representation candidate No . 1 is checked by searching out the inconsistency between the order table shown in FIG .","label":"Background","metadata":{},"score":"51.66012"}{"text":"Then , the process according to the flow chart of FIG .13 is carried out in the user state as follows .Then , at the step S112 , the consistency of the additional order made by the semantic utterance representation candidate No . 1 is checked by searching out the inconsistency between the order table shown in FIG .","label":"Background","metadata":{},"score":"51.66012"}{"text":"Then , the process according to the flow chart of FIG .13 is carried out in the user state as follows .Then , at the step S112 , the consistency of the additional order made by the semantic utterance representation candidate No . 1 is checked by searching out the inconsistency between the order table shown in FIG .","label":"Background","metadata":{},"score":"51.66012"}{"text":"Then , the process according to the flow chart of FIG .13 is carried out in the user state as follows .Then , at the step S112 , the consistency of the additional order made by the semantic utterance representation candidate No . 1 is checked by searching out the inconsistency between the order table shown in FIG .","label":"Background","metadata":{},"score":"51.66012"}{"text":"Not only would this permit more latitude in the recognition process - not requiring all words to conform to existing dictionary databases of word forms - but it would add a great deal to the expression of a written message .Knowing when and how someone releases the rest of their breath after an utterance is a sure clue to the tension with which they said the words . 2.3 MODELS OF PROSODY .","label":"Background","metadata":{},"score":"51.665283"}{"text":"9 described above .Now , in further detail , each one of the elements of the response generation unit 18 shown in FIG .19 operates as follows .In the following , a case of employing the method of sentence generation by the blank filling will be described in detail as an example .","label":"Background","metadata":{},"score":"51.7319"}{"text":"9 described above .Now , in further detail , each one of the elements of the response generation unit 18 shown in FIG .19 operates as follows .In the following , a case of employing the method of sentence generation by the blank filling will be described in detail as an example .","label":"Background","metadata":{},"score":"51.7319"}{"text":"Figure 2 : Frame selections from a Prosodic Font performance of speaker saying angrily , \" I 'm not working for my own education here . \"MOTIVATION .The motivation for creating a prosodic font comes from a number of current disciplinary trends : the too narrowly focused research in speech recognition , design for computational environments , and a growing need for richer and transformational communication mediums in the increasingly casual Internet traffic .","label":"Background","metadata":{},"score":"51.736267"}{"text":"The key focus of this approach is to use the acoustic features extracted from representative speech samples as the mechanism for identifying the prosodic cues in real - time from a speech utterance and which can then be used to detect emotion states .","label":"Background","metadata":{},"score":"52.12442"}{"text":"In this case , system for determining predictive models of discourse functions 100 and/or each of the various circuits discussed above can each be implemented as one or more routines embedded in the communications network , as a resource residing on a server , or the like .","label":"Background","metadata":{},"score":"52.182747"}{"text":"Experiments with using just the highest amplitude achieved , the average amplitude across the vowel event , and the slope of amplitude should be experimented with .People may perceive the underlying rhythmic structure of an utterance , cognitively subtracting the known effects of pronunciation .","label":"Background","metadata":{},"score":"52.18718"}{"text":"This process is repeated for each discourse function identified in the training corpus of speech utterances .In various embodiments , the prosodic feature vector and the determined discourse functions are used to determine a predictive model based on machine learning , statistics and the like .","label":"Background","metadata":{},"score":"52.227737"}{"text":"Referring now to FIG .1 , a first embodiment of a speech dialogue system according to the present invention will be described in detail .Overall System Configuration .In addition , the dialogue management unit 12 achieves the improvement of the speech understanding and the reduction of the processing amount by properly treating the spoken input speech containing elipsis and demonstrative pronouns , so as to enable the natural dialogue between the system and the user .","label":"Background","metadata":{},"score":"52.311882"}{"text":"The desired outcome for this research objective is an algorithm implemented in software that extracts , classifies and verifies in real - time the prosodic structure contained in the spoken dialog .What follows is a description of the research methodology for each of the above sections .","label":"Background","metadata":{},"score":"52.397007"}{"text":"( a ) analyzing the text to extract therefrom a prosodic parameter string based on synthesis - by - rule speech ; .( b ) correcting that one of prosodic parameters of the prosodic parameter string corresponding to the character or character string to be added with the non - verbal information , through the use of modification information based on a prosodic parameter characteristic of the non - verbal information ; .","label":"Background","metadata":{},"score":"52.413147"}{"text":"This alignment essentially serves the same function as Pierrehumbert 's complex accents , by showing if the intonational accent comes late or early within the duration of the accented syllable .Figure 19 : An intonational event is described with a single real number , representing the combined effects of the rise and fall of a pitch accent .","label":"Background","metadata":{},"score":"52.428772"}{"text":"This might involve methods of normalizing the differences in time required to produce certain phonemes as opposed to others , applying rhythmic changes non - linearly such that very fast speech is not as visually fast , or allowing \" hearers \" to control the speed of visual playback . 2.1.2.1","label":"Background","metadata":{},"score":"52.54691"}{"text":"The predictive discourse function model in conjunction with the prosodic information associated with the second portion of the speech utterance 631 is used to predict the likelihood that the second portion of the speech utterance is content information .The sentence or phrase can be segmented into command and content portions or any other hierarchy of contexts and/or or discourse functions recognized by the theory of discourse analysis .","label":"Background","metadata":{},"score":"52.561726"}{"text":"Then , at the step S144 , the variable n is increased by one , and the steps S143 and S144 are repeated until the variable n obtained at the step S144 exceeds the variable M at the step S145 .As a result , for the semantic response representation of FIG .","label":"Background","metadata":{},"score":"52.594887"}{"text":"Then , at the step S144 , the variable n is increased by one , and the steps S143 and S144 are repeated until the variable n obtained at the step S144 exceeds the variable M at the step S145 .As a result , for the semantic response representation of FIG .","label":"Background","metadata":{},"score":"52.594887"}{"text":"Then , at the step S144 , the variable n is increased by one , and the steps S143 and S144 are repeated until the variable n obtained at the step S144 exceeds the variable M at the step S145 .As a result , for the semantic response representation of FIG .","label":"Background","metadata":{},"score":"52.594887"}{"text":"Then , at the step S144 , the variable n is increased by one , and the steps S143 and S144 are repeated until the variable n obtained at the step S144 exceeds the variable M at the step S145 .As a result , for the semantic response representation of FIG .","label":"Background","metadata":{},"score":"52.594887"}{"text":"9 described above .Now , in further detail , each one of the elements of the response generation unit 13 shown in FIG .19 operates as follows .In the following , a case of employing the method of sentence generation by the blank filling will be described in detail as an example .","label":"Background","metadata":{},"score":"52.655323"}{"text":"9 described above .Now , in further detail , each one of the elements of the response generation unit 13 shown in FIG .19 operates as follows .In the following , a case of employing the method of sentence generation by the blank filling will be described in detail as an example .","label":"Background","metadata":{},"score":"52.655323"}{"text":"7 shows exemplary prosodic feature information associated with a second exemplary sentence according to this invention ; .FIG .8 an exemplary visualization of a sentence annotated with prosodic feature information according to this invention ; .FIG .9 is a flow diagram of an exemplary system for determining predictive models of discourse functions according to this invention ; .","label":"Background","metadata":{},"score":"53.015896"}{"text":"0093 ] .For example , after having said , \" Create an appointment with Mark at 3 o'clock tomorrow \" , a user might say \" Change that to 4 o'clock . \" The speech center system 20 establishes that a time attribute of something is changing , but needs to refer back to the conversational record 60 to find the appointment object whose time attribute is changing .","label":"Background","metadata":{},"score":"53.096695"}{"text":"FIG .12 illustrates in block form the functional configuration of a synthetic speech editing apparatus according to the third embodiment of the present invention .MSCL - described data , shown in FIG .10B , for instance , is input via the text / command input part 11 .","label":"Background","metadata":{},"score":"53.279957"}{"text":"2.4 DISCOURSE AND AFFECTIVE FUNCTION . \" ... intonation ...[is] ... a nonarbitrary , sound - symbolic system with intimate ties to facial expression and bodily gesture , and conveying , underneath it all , emotions and attitudes .","label":"Background","metadata":{},"score":"53.350487"}{"text":"Here , the speech response is shorter than the speech response of FIG .34 used in the similar situation before , in order to avoid the tasteless and possibly irritating repetition of the same message .Here , it is important that the display unit 14 continues to display the same content visualizing image indicating the ordered items and the ordered quantities as understood by the system so far , such that the user can continue to inspect the orders taken by the system visually .","label":"Background","metadata":{},"score":"53.499065"}{"text":"Here , the speech response is shorter than the speech response of FIG .34 used in the similar situation before , in order to avoid the tasteless and possibly irritating repetition of the same message .Here , it is important that the display unit 14 continues to display the same content visualizing image indicating the ordered items and the ordered quantities as understood by the system so far , such that the user can continue to inspect the orders taken by the system visually .","label":"Background","metadata":{},"score":"53.499065"}{"text":"Here , the speech response is shorter than the speech response of FIG .34 used in the similar situation before , in order to avoid the tasteless and possibly irritating repetition of the same message .Here , it is important that the display unit 14 continues to display the same content visualizing image indicating the ordered items and the ordered quantities as understood by the system so far , such that the user can continue to inspect the orders taken by the system visually .","label":"Background","metadata":{},"score":"53.499065"}{"text":"Here , the speech response is shorter than the speech response of FIG .34 used in the similar situation before , in order to avoid the tasteless and possibly irritating repetition of the same message .Here , it is important that the display unit 14 continues to display the same content visualizing image indicating the ordered items and the ordered quantities as understood by the system so far , such that the user can continue to inspect the orders taken by the system visually .","label":"Background","metadata":{},"score":"53.499065"}{"text":"[0097 ] .A further important requirement is that the system must not ignore signs of confusion or misconception as the presentation evolves .This means that the interactive training system , like its human counterpart , must detect and understand cues contained in the student 's dialogue and be able to alter or tailor its response and its tutoring strategies .","label":"Background","metadata":{},"score":"53.563614"}{"text":"3 is a block diagram illustrating a synthetic speech editing apparatus according to the first embodiment ; .FIG .4 is a diagram for explaining modifications of a pitch contour in a second embodiment of the present invention ; .FIG .","label":"Background","metadata":{},"score":"53.686226"}{"text":"What is the road map or plan for detecting speech recognition transcription errors , and strategies to compensate for problems that arise from such speech recognition errors ?[ 0113 ] .Questions 1 will be answered fully and Question 2 partially by Objectives 1 and 2 below .","label":"Background","metadata":{},"score":"53.714355"}{"text":"[ 0000 ] .Vision and Research Goals .[ 0098 ] .The vision that guides this research proposal is the goal of creating a spoken language interactive training system that mimics and captures the strategies of a one - on - one human tutor , because learning gains have been shown to be high for students tutored in this fashion .","label":"Background","metadata":{},"score":"53.720253"}{"text":"[ 0000 ] .Key Questions and Technical Objectives .[ 0107 ] .The time required to develop a Version 1.0 of the commercially - ready spoken language ITS is projected to span Phase I and Phase II .In Phase I , exploratory work will confirm or not confirm the technical and commercial feasibility of the system by answering the first three key questions .","label":"Background","metadata":{},"score":"53.798794"}{"text":"Potentially , visual effects would only be applied to the active syllable , making a word a collage constantly in process .The model of making speech events visible yields an opportunity to render artistically events such as inhalations and exhalations .","label":"Background","metadata":{},"score":"53.86978"}{"text":"II .SECOND EMBODIMENT .Referring now to FIG .40 , a second embodiment of a speech dialogue system according to the present invention will be described in detail .This second embodiment differs from the first embodiment described above in that the detail of the user detection mechanism is incorporated .","label":"Background","metadata":{},"score":"53.87097"}{"text":"II .SECOND EMBODIMENT .Referring now to FIG .40 , a second embodiment of a speech dialogue system according to the present invention will be described in detail .This second embodiment differs from the first embodiment described above in that the detail of the user detection mechanism is incorporated .","label":"Background","metadata":{},"score":"53.87097"}{"text":"II .SECOND EMBODIMENT .Referring now to FIG .40 , a second embodiment of a speech dialogue system according to the present invention will be described in detail .This second embodiment differs from the first embodiment described above in that the detail of the user detection mechanism is incorporated .","label":"Background","metadata":{},"score":"53.87097"}{"text":"[ 0117 ] .The expected outcome of this objective at the end of Phase I is the prototype of the front - end of the proposed spoken language ITS architecture - i.e . the Speech Recognition , Emotion Detection and Natural Language modules .","label":"Background","metadata":{},"score":"53.962204"}{"text":"[ 0000 ] .Introduction .[ 0118 ] .The spoken language interactive training system that we propose to build over the course of the SBIR Phase I and Phase II effort serves both a long term objective as well as the immediate Phase I project objective .","label":"Background","metadata":{},"score":"53.978874"}{"text":"[ 0060 ] .The recorded speech data is then played back and each sample is manually annotated preferably using Tone and Break Indices ( ToBI ) [ 13 ] annotation as illustrated in 210 ( .FIG .2 ) using the definitions and criteria for specific emotional states .","label":"Background","metadata":{},"score":"54.09387"}{"text":"[ 0096 ] .When questions or responses to the user are derived by the reasoning facility 54 , they must be translated back into natural language by the language generation module 54 .In a preferred embodiment , the language generation module 54 takes advantage of the knowledge stored in the syntax manager 62 , domain model 70 , lexicon 66 , and conversational record 60 in order to generate natural language output .","label":"Background","metadata":{},"score":"54.121994"}{"text":"Additionally , these modules are important to the planned dialog management schemes for this tutoring domain .The dialog manager and other modules such as the text to speech synthesis agent and the speech error compensation strategies as well as questions 2 and 3 will be addressed in Phase II .","label":"Background","metadata":{},"score":"54.445633"}{"text":"FIG .8 is an illustration of a past order table to be used in a dialogue management unit in the speech dialogue system of FIG .1 .FIG .9 is a state transition diagram for an operation of a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"54.47534"}{"text":"Such an analysis not only represents the sound pattern , but also shows how a pattern in one language relates to typological patterns across languages .In the third part of the course , we will examine phonological patterns from an experimental perspective .","label":"Background","metadata":{},"score":"54.544937"}{"text":"Under the properly controlled circumstances , this method is capable of achieving the high speed understanding of the almost freely uttered speech by using very little restrictions regarding the manner of speech utterance imposed on the user .Thus , in this first embodiment , this method of continuous speech understanding based on the keyword lattice parsing is employed in the speech understanding unit 11 of FIG .","label":"Background","metadata":{},"score":"54.636013"}{"text":"Under the properly controlled circumstances , this method is capable of achieving the high speed understanding of the almost freely uttered speech by using very little restrictions regarding the manner of speech utterance imposed on the user .Thus , in this first embodiment , this method of continuous speech understanding based on the keyword lattice parsing is employed in the speech understanding unit 11 of FIG .","label":"Background","metadata":{},"score":"54.636013"}{"text":"Again this is not intended to be an exhaustive list , and other prosodic parameters could be used in many applications .As in the initialization of the speech recognition process at the client side , there is an analogous calibration procedure used to calibrate the speech and silence components of the speaker 's utterance .","label":"Background","metadata":{},"score":"54.682076"}{"text":"Abstract .A prosody analyzer enhances the interpretation of natural language utterances .The analyzer is distributed over a client / server architecture , so that the scope of emotion recognition processing tasks can be allocated on a dynamic basis based on processing resources , channel conditions , client loads etc .","label":"Background","metadata":{},"score":"54.76079"}{"text":"These operations in the syntactic and semantic analysis unit 22 are to be carried out in a pipeline processing mode , so that the syntactic and semantic analysis unit 22 can obtain a plurality of the semantic utterance representations for a single input speech .","label":"Background","metadata":{},"score":"54.776653"}{"text":"These operations in the syntactic and semantic analysis unit 22 are to be carried out in a pipeline processing mode , so that the syntactic and semantic analysis unit 22 can obtain a plurality of the semantic utterance representations for a single input speech .","label":"Background","metadata":{},"score":"54.776653"}{"text":"These operations in the syntactic and semantic analysis unit 22 are to be carried out in a pipeline processing mode , so that the syntactic and semantic analysis unit 22 can obtain a plurality of the semantic utterance representations for a single input speech .","label":"Background","metadata":{},"score":"54.776653"}{"text":"These operations in the syntactic and semantic analysis unit 22 are to be carried out in a pipeline processing mode , so that the syntactic and semantic analysis unit 22 can obtain a plurality of the semantic utterance representations for a single input speech .","label":"Background","metadata":{},"score":"54.776653"}{"text":"7 and a past order table as shown in FIG .8 .On the other hand , the past order table shown in FIG .8 indicates the order table at a time of an output of the previous system response , i.e. , the content of the order taken up to an output of the previous system response .","label":"Background","metadata":{},"score":"54.814613"}{"text":"7 and a past order table as shown in FIG .8 .On the other hand , the past order table shown in FIG .8 indicates the order table at a time of an output of the previous system response , i.e. , the content of the order taken up to an output of the previous system response .","label":"Background","metadata":{},"score":"54.814613"}{"text":"7 and a past order table as shown in FIG .8 .On the other hand , the past order table shown in FIG .8 indicates the order table at a time of an output of the previous system response , i.e. , the content of the order taken up to an output of the previous system response .","label":"Background","metadata":{},"score":"54.814613"}{"text":"7 and a past order table as shown in FIG .8 .On the other hand , the past order table shown in FIG .8 indicates the order table at a time of an output of the previous system response , i.e. , the content of the order taken up to an output of the previous system response .","label":"Background","metadata":{},"score":"54.814613"}{"text":"Referring now to FIGS . 2 and 3 , an example of speech synthesis will be described below in connection with the case where the control commands to be inserted in a text are the prosodic features control commands of the S layer .","label":"Background","metadata":{},"score":"54.850136"}{"text":"FIG .3 , please see U.S. Pat .No .6,615,172 .[ 0000 ] .Overview of System for Real Time Emotion Detection .[0044 ] .The present invention features and incorporates cooperation between the following components : . a data acquisition component which utilizes speech utterances from test subjects .","label":"Background","metadata":{},"score":"54.970467"}{"text":"The emotion modeler can be transferred in electronic form to a client device or a server device , where it can be used to determine an emotion state of a speaker of an utterance .[ 0030 ] .In this manner an emotion state is determined by evaluating both individual words and an entire sentence of words uttered by the user .","label":"Background","metadata":{},"score":"54.974976"}{"text":"The predictive discourse function model accepts the prosodic features of the speech utterance as input and outputs the likely discourse function of the ambiguous speech utterance within the overall discourse .Other exemplary systems ( not shown ) can use this additional information to rescore the probability of the recognized words appearing within sentences , paragraphs and/or indicate command and/or content boundaries or other segments within the discourse .","label":"Background","metadata":{},"score":"55.08135"}{"text":"However , in various other exemplary embodiments , the systems and methods of this invention may be used to predict subordinations , conversational turn - taking or footing or any other known or later developed discourse function recognized by the determined theory of discourse analysis .","label":"Background","metadata":{},"score":"55.18872"}{"text":"1 will be described .In the following description , a case of employing this speech dialogue system to a task of order taking in a fast food store will be used for the sake of definiteness of the description .Speech Understanding Unit 11 .","label":"Background","metadata":{},"score":"55.252823"}{"text":"1 will be described .In the following description , a case of employing this speech dialogue system to a task of order taking in a fast food store will be used for the sake of definiteness of the description .Speech Understanding Unit 11 .","label":"Background","metadata":{},"score":"55.252823"}{"text":"It is an important aspect of what you know when you know how to speak a language .In this course , students will learn to recognize phonological patterns in language data , state such patterns precisely , and represent them in a formal model .","label":"Background","metadata":{},"score":"55.268127"}{"text":"It is an important aspect of what you know when you know how to speak a language .In this course , students will learn to recognize phonological patterns in language data , state such patterns precisely , and represent them in a formal model .","label":"Background","metadata":{},"score":"55.268127"}{"text":"Furthermore , the speech understanding unit 11 assigns the likelihood for each keyword obtained by the keyword spotting operation , which are subsequently transmitted to the response generation unit 13 in order to determine the speech response pattern as will be described in detail below . 2.2 Dialogue Management Unit 12 .","label":"Background","metadata":{},"score":"55.311646"}{"text":"Furthermore , the speech understanding unit 11 assigns the likelihood for each keyword obtained by the keyword spotting operation , which are subsequently transmitted to the response generation unit 13 in order to determine the speech response pattern as will be described in detail below . 2.2 Dialogue Management Unit 12 .","label":"Background","metadata":{},"score":"55.311646"}{"text":"Furthermore , the speech understanding unit 11 assigns the likelihood for each keyword obtained by the keyword spotting operation , which are subsequently transmitted to the response generation unit 13 in order to determine the speech response pattern as will be described in detail below . 2.2 Dialogue Management Unit 12 .","label":"Background","metadata":{},"score":"55.311646"}{"text":"Furthermore , the speech understanding unit 11 assigns the likelihood for each keyword obtained by the keyword spotting operation , which are subsequently transmitted to the response generation unit 13 in order to determine the speech response pattern as will be described in detail below . 2.2 Dialogue Management Unit 12 .","label":"Background","metadata":{},"score":"55.311646"}{"text":"FIG .9 is a flow diagram of an exemplary system for determining predictive models of discourse functions according to this invention .The speech utterances are recognized and prosodic features are determined as one set of inputs .In various exemplary embodiments according to this invention and as discussed above , a prosodic feature vector is determined based on prosodic features determined in a training corpus of speech utterances .","label":"Background","metadata":{},"score":"55.314503"}{"text":"23 is an illustration of a table used in a human character feature determination unit in the response generation unit of FIG .19 .FIG .24 is an illustration of a table used in a speech characteristic determination unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"55.326645"}{"text":"23 is an illustration of a table used in a human character feature determination unit in the response generation unit of FIG .19 .FIG .24 is an illustration of a table used in a speech characteristic determination unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"55.326645"}{"text":"23 is an illustration of a table used in a human character feature determination unit in the response generation unit of FIG .19 .FIG .24 is an illustration of a table used in a speech characteristic determination unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"55.326645"}{"text":"23 is an illustration of a table used in a human character feature determination unit in the response generation unit of FIG .19 .FIG .24 is an illustration of a table used in a speech characteristic determination unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"55.326645"}{"text":"5 shows exemplary prosodic feature information for prosodic features J.sub.1-J. sub.8 associated with the first exemplary sentence according to this invention .The prosody information associated with a statistically significant number of training sentences is used to determine predictive models of discourse functions .","label":"Background","metadata":{},"score":"55.38086"}{"text":"In various exemplary embodiments according to this invention , prosody information associated with the discourse function is stored in the initial frequency portion 1130 ; the pitch variation portion 1140 ; the preceding silence portion 1150 and the boundary tone portion 1160 .","label":"Background","metadata":{},"score":"55.449814"}{"text":"In various other exemplary embodiments according to this invention , additional information provided by the predictive model for discourse functions facilitates the segmentation of natural language speech utterances into the discourse functions necessary to determine mode changes and the like .BRIEF DESCRIPTION OF THE DRAWINGS .","label":"Background","metadata":{},"score":"55.465225"}{"text":"During the second part of the course the only regular assignments will be reading assignments , and students will work on a small - scale research project in the phonetics and/or phonology of tone and intonation .A short paper reporting the results of this research project will be the basis for the grade for the second part of the course .","label":"Background","metadata":{},"score":"55.537872"}{"text":"FIG .2 is a detailed block diagram of a speech understanding unit in the speech dialogue system of FIG .1 , .FIG .3 is an illustration of an example of a keyword lattice obtained from a continuous input speech in the speech understanding unit of FIG .","label":"Background","metadata":{},"score":"55.542892"}{"text":"Black , A. ( 1997 ) .\" Predicting the intonation of discourse segments from examples in dialogue speech \" , ATR Workshop on Computational modeling of prosody for spontaneous speech processing .ATR , Japan .Republished in \" Computing Prosody , \" Eds . Y. Sagisaka , N. Campbell and N. Higuchi , Springer Verlag .","label":"Background","metadata":{},"score":"55.674675"}{"text":"38 , the exemplary multimodal response output in this first embodiment of the speech dialogue system in the practical order taking task in a fast food store will be described in detail .First , FIG .32 shows an initial display on the display unit 14 in the absence of the user .","label":"Background","metadata":{},"score":"55.683422"}{"text":"38 , the exemplary multimodal response output in this first embodiment of the speech dialogue system in the practical order taking task in a fast food store will be described in detail .First , FIG .32 shows an initial display on the display unit 14 in the absence of the user .","label":"Background","metadata":{},"score":"55.683422"}{"text":"38 , the exemplary multimodal response output in this first embodiment of the speech dialogue system in the practical order taking task in a fast food store will be described in detail .First , FIG .32 shows an initial display on the display unit 14 in the absence of the user .","label":"Background","metadata":{},"score":"55.683422"}{"text":"38 , the exemplary multimodal response output in this first embodiment of the speech dialogue system in the practical order taking task in a fast food store will be described in detail .First , FIG .32 shows an initial display on the display unit 14 in the absence of the user .","label":"Background","metadata":{},"score":"55.683422"}{"text":"FIG .1 is an illustration of a preferred embodiment in a computer system 10 .Generally , the computer system 10 includes a digital processor 12 which hosts and executes a speech center system 20 , conversation manager 28 , and speech engine 22 in working memory .","label":"Background","metadata":{},"score":"55.705616"}{"text":"Finally , when the dialogue management unit 234 is not in the state # 3 at the step S295 , the dialogue management unit remains in the state # 0 and the operation proceeds to a next operation timing .Referring now to FIG .","label":"Background","metadata":{},"score":"55.804626"}{"text":"FIG .2 illustrates a preferred embodiment of an emotion modeler and classifier of the present invention ; . [ 0038 ] .FIG .3 is a block diagram of a prior art natural language query system ( NLQS ) ; .","label":"Background","metadata":{},"score":"55.82402"}{"text":"[ 0050 ] .An emotion modeler comprising the above implements the extraction of the speaker 's emotion state , and uses the benefits from the optimization of the machine learning algorithms derived from the training session .[ 0000 ] .","label":"Background","metadata":{},"score":"55.85651"}{"text":"The predictive discourse function model routine or circuit 60 associates the prosodic features with the determined discourse functions .The predictive model determination routine or circuit 60 may use using machine learning , statistics , induced decision trees , model lookup or any known or later developed method of determining a predictive model without departing from the scope of this invention .","label":"Background","metadata":{},"score":"55.90862"}{"text":"[0070 ] .The conversation manager 28 converts the utterance 15 into an intermediate form that is more amenable to processing .The translation process initially converts recognized utterances 15 into sequences of script calls to frame - building functions via a recursive substitution translation facility .","label":"Background","metadata":{},"score":"55.91916"}{"text":"The value \" 150 \" indicates the initial frequency information for the training speech utterance .The pitch variation portion 1040 contains the value \" 0.10 \" for the training instance speech utterance .This value indicates a pitch variation value that may be useful in determining or identifying discourse functions of type \" COORDINATION \" .","label":"Background","metadata":{},"score":"55.95422"}{"text":"The prosodic features J 3 822 may be a change in the initial pitch , or any other prosodic feature or set of features associated with the start of the content portion 820 .In various exemplary embodiments according to this invention , the association between the prosodic features and the discourse function can also be personalized for a specific user .","label":"Background","metadata":{},"score":"55.99537"}{"text":"3 .A second task will be to prepare a road - map and plan for Phase II .The integration of this front - end of the system will serve as an important step in proving the feasibility of interfacing the spoken language interface with real - time emotion detection and would be critical to the strategy for the dialog management for this tutoring domain .","label":"Background","metadata":{},"score":"56.013954"}{"text":"[ 0100 ] .( 1 ) prosody - based modeling of the student 's dialog , and its use in managing the dialog so as to recognize misconceptions and clarify issues the student has with the lesson ; .[ 0101 ] .","label":"Background","metadata":{},"score":"56.397232"}{"text":"FIG .13 is a flow chart for an operation in a user state in an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .1 using the examples shown in FIGS .","label":"Background","metadata":{},"score":"56.411945"}{"text":"FIG .13 is a flow chart for an operation in a user state in an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .1 using the examples shown in FIGS .","label":"Background","metadata":{},"score":"56.411945"}{"text":"FIG .13 is a flow chart for an operation in a user state in an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .1 using the examples shown in FIGS .","label":"Background","metadata":{},"score":"56.411945"}{"text":"In this way , user specific methods of prosodically denoting discourse functions may be incorporated into the predictive discourse function model over time and/or over multiple sessions .In still other exemplary embodiments according to this invention , the prosodic features J 1 , J 2 and J 3 , 831 - 833 may be comprised of single prosodic features or may reflect sets of prosodic features .","label":"Background","metadata":{},"score":"56.418232"}{"text":"How do we extract the acoustic - prosodic cues embedded in the utterances of a typical tutoring speech corpora ?What reference architecture can be defined for the interactive training system to make it suitable for the tutoring domain , and combines spoken language interfaces , real - time prosody modeler , dialog manager and cognitive - based reasoning agents ?","label":"Background","metadata":{},"score":"56.427063"}{"text":"11 is a flowchart showing editing and display procedures according to the third embodiment ; and .FIG .12 is block diagram illustrating a synthetic speech editing apparatus according to the third embodiment .DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT .","label":"Background","metadata":{},"score":"56.448307"}{"text":"However , the use of discrete input modes can impede the fluency with which a user interacts with the natural language interface .Thus , rather than directly conversing with systems incorporating these conventional natural language interfaces , users are forced to track the current input mode and/or status of the system .","label":"Background","metadata":{},"score":"56.58105"}{"text":"11 as follows .Namely , first at the step S91 , the order table is updated according to the semantic utterance representation supplied from the speech understanding unit 11 , and at the step S92 , th semantic response representation is generated according to the current system state .","label":"Background","metadata":{},"score":"56.633766"}{"text":"11 as follows .Namely , first at the step S91 , the order table is updated according to the semantic utterance representation supplied from the speech understanding unit 11 , and at the step S92 , th semantic response representation is generated according to the current system state .","label":"Background","metadata":{},"score":"56.633766"}{"text":"[ 0000 ] .Overview of the Reference Architecture .[0120 ] .The spoken language interactive training system uses traditional components required for implementing a spoken dialogue system .Spoken language systems are in general , complex frameworks involving the integration of several components such as speech recognition , speech synthesis , natural language understanding and dialog management as in an information retrieval application using spoken language interfaces .","label":"Background","metadata":{},"score":"56.64804"}{"text":"[ 0000 ] .Objective 2 : To Implement the Front End of the Spoken Language ITS ( Comprised of the Speech Recognition , Natural Language and the Prosody Modeler ( Developed in Objective 1 ) Using the Rapid Prototyping Open Agent Architecture ( OAA ) Environment .","label":"Background","metadata":{},"score":"56.696472"}{"text":"FIG .1 is a diagram for explaining an MSCL ( Multi - Layered Speech / Sound Synthesis Control Language ) description scheme in a first embodiment of the present invention ; .FIG .2 is a flowchart showing a synthetic speech editing procedure involved in the first embodiment ; .","label":"Background","metadata":{},"score":"56.76204"}{"text":"This is an advanced phonetics seminar in bilingualism and second language acquisition with a focus on speech production and perception .The course is used primarily for discussion of course readings , in which students will be actively involved by giving presentations .","label":"Background","metadata":{},"score":"56.77578"}{"text":"The method of claim 33 , wherein at the outputting step , the visual response is outputted before the speech response is outputted .A speech response system , comprising : . speech analyzing means for analyzing an input speech from a user ; . response output means for outputting a speech response and a visual response according to the input speech analyzed by the speech analyzing means ; and .","label":"Background","metadata":{},"score":"56.81219"}{"text":"The method of claim 33 , wherein at the outputting step , the visual response is outputted before the speech response is outputted .A speech response system , comprising : . speech analyzing means for analyzing an input speech from a user ; . response output means for outputting a speech response and a visual response according to the input speech analyzed by the speech analyzing means ; and .","label":"Background","metadata":{},"score":"56.81219"}{"text":"The following Table 3 shows examples of description in such a case .Table 3 shows examples of five S - layer commands prepared based on the experimental results on the second embodiment and their interpretations by the corresponding I - layer commands .","label":"Background","metadata":{},"score":"57.1772"}{"text":"While the second embodiment has been described above to use the MSCL method to describe prosody control of the text , other description methods may also be used .The second embodiment is based on the assumption that combinations of specific prosodic features are prosody control rules .","label":"Background","metadata":{},"score":"57.19699"}{"text":"The prosodic features J 1 -J 2 831 - 833 may be a silence of a specific duration , relative pitch changes or any other prosodic feature associated with the predictive models of discourse functions .It will be apparent that the prosodic features may be used alone or in combination to determine the start and end of the command portion 810 without departing from the scope of this invention .","label":"Background","metadata":{},"score":"57.240868"}{"text":"Here , the new text data as well as the content visualizing image are continued to be displayed even after the timing t2 until the next system response output stage .In this case , the change of the system response output content and its output order is determined at the response generation unit 13 according to the response act and the number of ordered items indicated by the semantic response representation supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"57.336765"}{"text":"Here , the new text data as well as the content visualizing image are continued to be displayed even after the timing t2 until the next system response output stage .In this case , the change of the system response output content and its output order is determined at the response generation unit 13 according to the response act and the number of ordered items indicated by the semantic response representation supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"57.336765"}{"text":"Here , the new text data as well as the content visualizing image are continued to be displayed even after the timing t2 until the next system response output stage .In this case , the change of the system response output content and its output order is determined at the response generation unit 13 according to the response act and the number of ordered items indicated by the semantic response representation supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"57.336765"}{"text":"Here , the new text data as well as the content visualizing image are continued to be displayed even after the timing t2 until the next system response output stage .In this case , the change of the system response output content and its output order is determined at the response generation unit 13 according to the response act and the number of ordered items indicated by the semantic response representation supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"57.336765"}{"text":"Thus , it is quite significant to continuously display the sequentially updated content of the order taken by the system throughout the dialogue with the user .For this reason , in this example , the confirmation for the partial change of the order such as addition , replacement , deletion is carried out by using only the speech response and the text data of the speech response .","label":"Background","metadata":{},"score":"57.34114"}{"text":"Thus , it is quite significant to continuously display the sequentially updated content of the order taken by the system throughout the dialogue with the user .For this reason , in this example , the confirmation for the partial change of the order such as addition , replacement , deletion is carried out by using only the speech response and the text data of the speech response .","label":"Background","metadata":{},"score":"57.34114"}{"text":"Thus , it is quite significant to continuously display the sequentially updated content of the order taken by the system throughout the dialogue with the user .For this reason , in this example , the confirmation for the partial change of the order such as addition , replacement , deletion is carried out by using only the speech response and the text data of the speech response .","label":"Background","metadata":{},"score":"57.34114"}{"text":"Thus , it is quite significant to continuously display the sequentially updated content of the order taken by the system throughout the dialogue with the user .For this reason , in this example , the confirmation for the partial change of the order such as addition , replacement , deletion is carried out by using only the speech response and the text data of the speech response .","label":"Background","metadata":{},"score":"57.34114"}{"text":"The system for determining predictive models of discourse functions 100 mediates the request by retrieving the first training instance 1000 .The prosodic features of the speech utterance are determined .Prosodic features may include but are not limited to the fundamental frequency , intonational phrase tones , boundary tones , inter utterance silence duration , rate of speech and the like .","label":"Background","metadata":{},"score":"57.418854"}{"text":"5 is an illustration of an exemplary list of keywords to be used in the speech understanding unit of FIG .2 .FIG .6 is an illustration of an example of a semantic response representation to be obtained by a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"57.478386"}{"text":"5 is an illustration of an exemplary list of keywords to be used in the speech understanding unit of FIG .2 .FIG .6 is an illustration of an example of a semantic response representation to be obtained by a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"57.478386"}{"text":"BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 is a schematic block diagram of a first embodiment of a speech dialogue system according to the present invention .FIG .2 is a detailed block diagram of a speech understanding unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"57.525867"}{"text":"BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 is a schematic block diagram of a first embodiment of a speech dialogue system according to the present invention .FIG .2 is a detailed block diagram of a speech understanding unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"57.525867"}{"text":"BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 is a schematic block diagram of a first embodiment of a speech dialogue system according to the present invention .FIG .2 is a detailed block diagram of a speech understanding unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"57.525867"}{"text":"FIG .4 is a diagram illustrating an activation - evaluation relationship implemented in preferred embodiments of the present invention .DETAILED DESCRIPTION OF THE INVENTION .[ 0040 ] .Brief Overview of Natural Language Query Systems As alluded to above , the present inventions are intended to be integrated as part of a Natural Language Query System ( NLQS ) such as that shown in .","label":"Background","metadata":{},"score":"57.56414"}{"text":"As discussed above , individual features may be used to determine discourse functions .However , in still other exemplary embodiments , multiple prosodic features associated with a discourse function are combined into a single prosodic feature vector .A predictive model of discourse functions is then determined .","label":"Background","metadata":{},"score":"57.61576"}{"text":"[ 0022]FIG .5 is a flow chart of a procedure for processing a spoken utterance and providing an output in response to the spoken utterance according to a preferred embodiment .DETAILED DESCRIPTION OF THE INVENTION .[ 0023 ] .","label":"Background","metadata":{},"score":"57.65799"}{"text":"Categorization above the low - level signal allows intonational phonologists to do work on the similarity of meaning and function across speakers , as well as understand which portions of continuous signals hold conventionalized linguistic and structural meanings .They categorize continuous prosodic variables into segmented events .","label":"Background","metadata":{},"score":"57.739227"}{"text":"By optimizing the interaction and relationship of the SR engines 155 and 182 , the NLP routines 190 , and the dictionaries and grammars , an extremely fast and accurate match can be made , so that a unique and responsive answer can be provided to the user .","label":"Background","metadata":{},"score":"57.7604"}{"text":"These data - driven values corresponding to these states will then be used to assist in formulating the dialog strategies for the ITS .The long term objective of the research is to build a spoken language - based ITS system that incorporates dialog control strategies that also incorporate emotional cues contained in the utterances of the student 's dialogue .","label":"Background","metadata":{},"score":"57.827682"}{"text":"In step 116 , the dialog manger 56 places the response output in a queue of response outputs .For example , the queue contains response outputs accumulated over time , particularly if the user has been away from the computer for a time .","label":"Background","metadata":{},"score":"57.852715"}{"text":"The main goal of this part of the experiment is in using machine learning algorithms to automatically determine which acoustic - prosodic features are the most informative in identifying and mapping the two stress levels from these features .Machine learning has been established to be a valuable tool for data exploration for a number of data classification problems in fields such as linguistics .","label":"Background","metadata":{},"score":"57.861935"}{"text":"In this dynamic context , word presentation adopts some of the temporal quality of speech , adopting a temporal word by word presentation rather than having them appear as beads on a visual string .Text has long been considered one of the least rich mediums of communication , face to face conversation the richest because it involves speech , facial expression , gesture and temporal forms ( Daft and Lengel , 1987 ) .","label":"Background","metadata":{},"score":"57.90161"}{"text":"FIG .4 shows an exemplary sentence annotated according to this invention ; .FIG .5 shows exemplary prosodic feature information associated with a first exemplary training sentence according to this invention ; .FIG .6 shows a second exemplary sentence annotated according to this invention ; .","label":"Background","metadata":{},"score":"57.91512"}{"text":"FIG .1b shows a high - level view of specific software agents that comprise the speech - enabled ITS .Although each agent is connected to a central hub or Facilitator , there is a functional hierarchy which describes each agent and the flow of messages between them as shown in .","label":"Background","metadata":{},"score":"57.93553"}{"text":"[ 0024 ] .In other embodiments the operations are distributed across the client device and server device on a case - by - case basis .A parts - of - speech analyzer is also preferably included for identifying a first set of emotion cues based on evaluating a syntax structure of the utterance .","label":"Background","metadata":{},"score":"57.99726"}{"text":"[ 0000 ] .Data Acquisition .[ 0057 ] .An emotion modeler and classifier system 200 of the present invention is shown in .FIG .2 .This system is trained with actual examples from test subjects to improve performance .","label":"Background","metadata":{},"score":"58.019287"}{"text":"Rules in the rule base will decide which template 72 is appropriate for the language generation task at hand .[0097 ] .[ 0097]FIG .5 is a flow chart of a procedure 100 for processing a spoken utterance 14 and providing audio output to the user in response to the utterance 14 .","label":"Background","metadata":{},"score":"58.040504"}{"text":"Other examples will be apparent from the present teachings .Thus this additional POS analysis can be used to supplement a prosodic analysis .Those skilled in the art will appreciate that other POS features may be exploited to further determine syntax structures correlative with emotion states .","label":"Background","metadata":{},"score":"58.042324"}{"text":"It will be apparent that the categorization into \" SUBORDINATION \" and \" COORDINATION \" discourse functions is merely exemplary and that any known or later developed discourse functions recognizable by the selected theory of discourse analysis may be used in the practice of this invention .","label":"Background","metadata":{},"score":"58.04527"}{"text":"For example , the long duration of a syllable , may infer an emotional state corresponding to doubt - DOUBT compared to alternate emotional state of certainty - CERTAINTY which in turn may be represented by a shorter time duration of the same syllable .","label":"Background","metadata":{},"score":"58.048725"}{"text":"8 is an exemplary visualization of a sentence annotated with prosodic feature information according to one aspect of this invention .The prosodic feature J 1 831 is a feature associated with the beginning of the command portion 810 of the recognized speech utterance .","label":"Background","metadata":{},"score":"58.129135"}{"text":"Once a matching rule has been found , the rule 's conditions must be satisfied .These become new goals for the inference engine of the reasoning facility 52 to achieve , based on the content of the memory and the conversational record .","label":"Background","metadata":{},"score":"58.169685"}{"text":"In the case of executing the commands in the order in which they are obtained , the information about the order of their execution becomes unnecessary .Then , the Japanese text separated in step S 4 is subjected to a Japanese syntactic structure analysis to obtain prosodic parameters based on the conventional by - rule - synthesis method ( S 6 ) .","label":"Background","metadata":{},"score":"58.181374"}{"text":"1 will be described .In the following description , a case of employing this speech dialogue system to a task of order taking in a fast food store will be used for the sake of definiteness of the description . 2.1","label":"Background","metadata":{},"score":"58.200653"}{"text":"1 will be described .In the following description , a case of employing this speech dialogue system to a task of order taking in a fast food store will be used for the sake of definiteness of the description . 2.1","label":"Background","metadata":{},"score":"58.200653"}{"text":"In a problem set , students are given a set of data from some language , and they determine the pattern and give an analysis .There will be 2 - 3 reading assignments using journal articles available in electronic form through the University Library .","label":"Background","metadata":{},"score":"58.223686"}{"text":"[ 0025 ] .A calibration routine can be stored and used on the client side or server side depending on the particular hardware and system configuration , performance requirements , etc . .[ 0026 ] .The extracted prosodic features can be varied according to the particular application , and can include data values which are related to one or more acoustic measures including one of PITCH , DURATION & ENERGY .","label":"Background","metadata":{},"score":"58.227875"}{"text":"We will begin with an introduction to the basics of this domain : the autosegmental representation of tone , the typology of tone systems , the metrical - autosegmental representation of intonation , and the many factors that affect fundamental frequency in speech .","label":"Background","metadata":{},"score":"58.279594"}{"text":"Next , consider a case in which the user somewhat hesitatingly uttered the input speech of \" Uhm . . .well , that 's right . \" in response to the message shown in FIG .35 .In this case , the system fails to understand the input speech as there is no output from the speech understanding unit 11 , since this input speech is considered as the unexpected utterance .","label":"Background","metadata":{},"score":"58.281124"}{"text":"Next , consider a case in which the user somewhat hesitatingly uttered the input speech of \" Uhm . . .well , that 's right . \" in response to the message shown in FIG .35 .In this case , the system fails to understand the input speech as there is no output from the speech understanding unit 11 , since this input speech is considered as the unexpected utterance .","label":"Background","metadata":{},"score":"58.281124"}{"text":"Next , consider a case in which the user somewhat hesitatingly uttered the input speech of \" Uhm . . .well , that 's right . \" in response to the message shown in FIG .35 .In this case , the system fails to understand the input speech as there is no output from the speech understanding unit 11 , since this input speech is considered as the unexpected utterance .","label":"Background","metadata":{},"score":"58.281124"}{"text":"Next , consider a case in which the user somewhat hesitatingly uttered the input speech of \" Uhm . . .well , that 's right . \" in response to the message shown in FIG .35 .In this case , the system fails to understand the input speech as there is no output from the speech understanding unit 11 , since this input speech is considered as the unexpected utterance .","label":"Background","metadata":{},"score":"58.281124"}{"text":"This design stands in contrast to currently existing dialog management strategies for an information - type domain which have discourse plans that are either elaborate or based on form - filling or finite state machine approaches .The dialog manager for the proposed ITS must combine low - level responsive dialogue activities with its high level educational plan .","label":"Background","metadata":{},"score":"58.334217"}{"text":"Question and statement intonational contours , as well as pitch accent placement , often associated with speaker intention and grammatical function , may have an emotional derivation .If prosodic intonation and accent derive from an emotional core common in all normal humans , why do n't we all speak in exactly the same manner ?","label":"Background","metadata":{},"score":"58.338108"}{"text":"Next , speech recognition will recognize not just the word itself but how the word was said , and how long it lasted , and how quickly the next word followed .Even vocal events like inhaling and exhaling , sounds which are particularly explosive , and speech errors like words left only half - begun can have visual correlates .","label":"Background","metadata":{},"score":"58.368156"}{"text":"S 7 : A synthetic speech generation part 18 generates synthetic speech based on the controlled prosodic parameters .Turning next to FIG .3 , an embodiment of the synthetic speech editing unit will be described in concrete terms .A Japanese text containing prosodic feature control commands is input into a text / command input part 11 via a keyboard or some other editor .","label":"Background","metadata":{},"score":"58.38905"}{"text":"2.4.2 Syntax , Information Structure , and Mutual Belief .Prosody serves many syntactical and discourse functions within speech .Much attention has been focused on the syntactical and discursive functions of prosodic variation .This set of research aims to uncover a discrete set of rules governing the universal use of song and rhythm .","label":"Background","metadata":{},"score":"58.43735"}{"text":"When the user state act is not \" user present \" at the step S282 , the dialogue management unit remains in the state # 0 and the operation proceeds to a next operation timing to repeat this flow chart of FIG .","label":"Background","metadata":{},"score":"58.44992"}{"text":"When the user state act is not \" user present \" at the step S282 , the dialogue management unit remains in the state # 0 and the operation proceeds to a next operation timing to repeat this flow chart of FIG .","label":"Background","metadata":{},"score":"58.44992"}{"text":"The following paragraphs describe the brief background of each agent : . [ 0000 ] .Objective 1 : To Develop a Real - Time Algorithm that Builds a Dialog Prosody Model .[ 0132 ] .This objective has two goals : . [ 0133 ] .","label":"Background","metadata":{},"score":"58.45116"}{"text":"[ 0000 ] .Challenges .[ 0106 ] .A key goal of the proposed research is to develop indicators of speech recognition errors that lead to these misunderstanding and non - understanding events , and to develop strategies for handling errors of this kind so that the resulting system performance is as robust as possible .","label":"Background","metadata":{},"score":"58.53152"}{"text":"When the speech act is \" order \" at the step S285 , next at the step S286 , the semantic response representation for the confirmation of the ordered content is generated .Then , the dialogue management unit maintains the state # 0 and the operation proceeds to a next operation timing .","label":"Background","metadata":{},"score":"58.570755"}{"text":"When the speech act is \" order \" at the step S285 , next at the step S286 , the semantic response representation for the confirmation of the ordered content is generated .Then , the dialogue management unit maintains the state # 0 and the operation proceeds to a next operation timing .","label":"Background","metadata":{},"score":"58.570755"}{"text":"DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS .I. FIRST EMBODIMENT .Referring now to FIG .1 , a first embodiment of a speech dialogue system according to the present invention will be described in detail .Overall System Configuration .In addition , the dialogue management unit 12 achieves the improvement of the speech understanding and the reduction of the processing amount by properly treating the spoken input speech containing elipsis and demonstrative pronouns , so as to enable the natural dialogue between the system and the user .","label":"Background","metadata":{},"score":"58.79843"}{"text":"DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS .I. FIRST EMBODIMENT .Referring now to FIG .1 , a first embodiment of a speech dialogue system according to the present invention will be described in detail .Overall System Configuration .In addition , the dialogue management unit 12 achieves the improvement of the speech understanding and the reduction of the processing amount by properly treating the spoken input speech containing elipsis and demonstrative pronouns , so as to enable the natural dialogue between the system and the user .","label":"Background","metadata":{},"score":"58.79843"}{"text":"DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS .I. FIRST EMBODIMENT .Referring now to FIG .1 , a first embodiment of a speech dialogue system according to the present invention will be described in detail .Overall System Configuration .In addition , the dialogue management unit 12 achieves the improvement of the speech understanding and the reduction of the processing amount by properly treating the spoken input speech containing elipsis and demonstrative pronouns , so as to enable the natural dialogue between the system and the user .","label":"Background","metadata":{},"score":"58.79843"}{"text":"S 4 : The prosodic feature control commands are then analyzed in a prosodic feature control command analysis part 15 to extract therefrom the control sequence of the commands .S 5 : In a sentence structure analysis part 13 the character string of the text is decomposed into a significant word string having a meaning , by referring to a speech synthesis rule database 14 .","label":"Background","metadata":{},"score":"58.852394"}{"text":"10 as follows .Namely , first at the step S81 , a plurality of the semantic utterance representation candidates are entered from the speech understanding unit 11 .Then , at the step S82 , the inference of the unspecified parts in the semantic utterance representation candidates entered at the seep S81 is carried out by using the previously obtained semantic response representation .","label":"Background","metadata":{},"score":"58.891838"}{"text":"10 as follows .Namely , first at the step S81 , a plurality of the semantic utterance representation candidates are entered from the speech understanding unit 11 .Then , at the step S82 , the inference of the unspecified parts in the semantic utterance representation candidates entered at the seep S81 is carried out by using the previously obtained semantic response representation .","label":"Background","metadata":{},"score":"58.891838"}{"text":"For example , in one of the exemplary embodiments according to this invention , a theory of discourse analysis is applied to the verified recognized speech utterances associated with the training corpus to determine the discourse functions .After the discourse functions in the training corpus of speech utterances have been determined , control continues to step S 600 .","label":"Background","metadata":{},"score":"58.943405"}{"text":"85 - 96 , 2000 .[ 0284 ] .While the preferred embodiment is directed specifically to integrating the prosody analyzer with embodiments of a NLQS system of the type noted above , it will be understood that it could be incorporated within a variety of statistical based NLQS systems .","label":"Background","metadata":{},"score":"58.951996"}{"text":"We will learn how children acquire the sounds system of their language and how language experience shapes that acquisition .Finally , we will address topics , such as second language acquisition and current speech technology as it applies to computerized speech synthesis and speech recognition .","label":"Background","metadata":{},"score":"58.965717"}{"text":"Each row of the data structure for storing exemplary discourse function prosody information 1170 reflects an exemplar of a type of discourse function .That is , the training instances are clustered based on the determined discourse functions .Machine learning methods , statistics or any other method of determining a model based on the prosody information are then used to determine a predictive model for discourse functions .","label":"Background","metadata":{},"score":"58.982544"}{"text":"The theory of discourse analysis may be previously determined and stored in a memory .In various other exemplary embodiments according to this invention , the theory of discourse analysis is selected based on user input , features associated with the user , a selected application , a usage environment and the like .","label":"Background","metadata":{},"score":"59.002438"}{"text":"FIG .6 is a table showing the results of hearing tests on synthetic speech messages with scaled utterance durations in the second embodiment ; .FIG .7 is a table showing the results of hearing tests on synthetic speech messages having , in combination , modified pitch contours and scaled utterance durations in the second embodiment ; .","label":"Background","metadata":{},"score":"59.026127"}{"text":"Interesting visual effects may occur by freezing each syllable at the moment activity transfers to the next syllable .Prosodic Font words would then appear as collages in process .Even though a word is presented as a totality , many visual state changes occur at the syllable level .","label":"Background","metadata":{},"score":"59.060783"}{"text":"response output means for outputting a system response according to the detected keywords , the system response being generated in accordance with a prescribed rule corresponding to each of the keywords .The present invention relates to a speech dialogue system for realizing an interaction between a computer based system and a human speaker by utilizing various input and output techniques such as speech recognition and speech synthesis .","label":"Background","metadata":{},"score":"59.162014"}{"text":"The discourse functions may include context information , mode indicators or any known or later developed discourse level information useful in segmenting and/or disambiguating speech utterances .For example , prosodic features associated with a first portion of a speech utterance are used to predict the likelihood that the first portion of the speech utterance is associated with a command directed at the current application .","label":"Background","metadata":{},"score":"59.164543"}{"text":"Generating Expression in Synthesized Speech .Thesis at the Massachusetts Institute of Technology , Media Lab , Cambridge , MA ._ _ _ _ .An Investigation into the Correlation of Cue Phrases , Unfilled Pauses and the Structuring of Spoken Discourse , Proceedings of the IRCS Workshop on Prosody in Natural Speech , Technical Report IRCS-92 - 37 .","label":"Background","metadata":{},"score":"59.166237"}{"text":"18 . 2.3 Response Generation Unit 13 .In addition , the content visualizing image visualizing the essential content of the speech response is provided for supporting the smooth comprehension of the system response by the user .In further detail , this response generation unit 13 has a configuration as shown in FIG .","label":"Background","metadata":{},"score":"59.187634"}{"text":"18 . 2.3 Response Generation Unit 13 .In addition , the content visualizing image visualizing the essential content of the speech response is provided for supporting the smooth comprehension of the system response by the user .In further detail , this response generation unit 13 has a configuration as shown in FIG .","label":"Background","metadata":{},"score":"59.187634"}{"text":"18 . 2.3 Response Generation Unit 13 .In addition , the content visualizing image visualizing the essential content of the speech response is provided for supporting the smooth comprehension of the system response by the user .In further detail , this response generation unit 13 has a configuration as shown in FIG .","label":"Background","metadata":{},"score":"59.187634"}{"text":"The prosodic parameters corresponding to characters or character string to be corrected are corrected by the prosodic feature control commands of the I layer , and speech is synthesized from a parameter string containing the corrected prosodic parameters .A method for editing non - verbal information of a speech message synthesized by rules in correspondence to a text , said method comprising the steps of : .","label":"Background","metadata":{},"score":"59.30848"}{"text":"[0058 ] .These questions are designed so that the expected elicited answers aided by visual cues exhibit emotions of CERTAINTY , UNCERTAINTY and DOUBT .The formulation of the questions can be performed using any of a variety of known techniques .","label":"Background","metadata":{},"score":"59.336006"}{"text":"Finally , when the dialogue management unit 234 is not in the state # 3 at the step S295 , the dialogue management unit remains in the state # 0 and the operation proceeds to a next operation timing .III .","label":"Background","metadata":{},"score":"59.35357"}{"text":"22A as follows .First , at the step S141 , a variable n for indicating a number of execution of the process is initially set to zero , and at the step S142 , a number of items involved in the semantic response representation is set to a variable M. When the semantic response representation shown in FIG .","label":"Background","metadata":{},"score":"59.35633"}{"text":"22A as follows .First , at the step S141 , a variable n for indicating a number of execution of the process is initially set to zero , and at the step S142 , a number of items involved in the semantic response representation is set to a variable M. When the semantic response representation shown in FIG .","label":"Background","metadata":{},"score":"59.35633"}{"text":"22A as follows .First , at the step S141 , a variable n for indicating a number of execution of the process is initially set to zero , and at the step S142 , a number of items involved in the semantic response representation is set to a variable M. When the semantic response representation shown in FIG .","label":"Background","metadata":{},"score":"59.35633"}{"text":"22A as follows .First , at the step S141 , a variable n for indicating a number of execution of the process is initially set to zero , and at the step S142 , a number of items involved in the semantic response representation is set to a variable M. When the semantic response representation shown in FIG .","label":"Background","metadata":{},"score":"59.35633"}{"text":"FIG .6 is an illustration of an example of a semantic response representation to be obtained by a dialogue management unit in the speech dialogue system of FIG .1 .FIG .7 is an illustration of an order table to be used in a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"59.35796"}{"text":"0114 ] .Objective 1 : To implement an algorithm for real time prosody modeling based on the prosodic characteristics of speech in order to extract and classify acoustic - prosodic characteristics contained in the student 's speech .[0115 ] .","label":"Background","metadata":{},"score":"59.367325"}{"text":"FIG 5 is an illustration of an exemplary list of keywords to be used in the speech understanding unit of FIG .2 .FIG .6 is an illustration of an example of a semantic response representation to be obtained by a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"59.42501"}{"text":"Eventually , when the order taking procedure is finished as the user 's utterance for the confirmation of the entire orders is received , the transition from the dialogue in progress user state UP to the finish system state S9 is made and the dialogue is terminated .","label":"Background","metadata":{},"score":"59.436737"}{"text":"Eventually , when the order taking procedure is finished as the user 's utterance for the confirmation of the entire orders is received , the transition from the dialogue in progress user state UP to the finish system state S9 is made and the dialogue is terminated .","label":"Background","metadata":{},"score":"59.436737"}{"text":"Also , it is important to determine what should be displayed in the speech dialogue system utilizing various other media .It is therefore an object of the present invention to provide a speech dialogue system capable of realizing natural and smooth dialogue between the system and a human user , and easy maneuverability of the system .","label":"Background","metadata":{},"score":"59.464592"}{"text":"Prosodic features identified after the utterance of the discourse function may also be used to predict the discourse function .Thus , it should be apparent that any prosodic feature helpful in predicting a discourse function , which presents before , during and/or following the utterance of a discourse function may be used in the practice of this invention .","label":"Background","metadata":{},"score":"59.469894"}{"text":"12 is a data structure for storing prosody information for each of the exemplary discourse functions according this invention ; .DETAILED DESCRIPTION OF EXEMPLARY EMBODIMENTS .FIG .1 is an overview of an exemplary system for determining predictive models of discourse functions 100 according to this invention .","label":"Background","metadata":{},"score":"59.471024"}{"text":"[ 0000 ] .Decision Tree Classifier Training .[0065 ] .Decision tree classifiers , such as shown in .FIG .2 , are probabilistic classifiers that transform data inputted to it into a binary question based on the attributes of the data that is supplied .","label":"Background","metadata":{},"score":"59.52163"}{"text":"FIG .1 , the emotion detector is preferably implemented in distributed configuration in which some functions reside at a client 110 , and other functions are at a server side 120 .As noted above , a speech recognition process is also distributed , so that a portion of speech operations is performed by hardware / software routines 115 .","label":"Background","metadata":{},"score":"59.539402"}{"text":"The environmental interface module 32 enables the speech center 20 to keep in touch with what is happening on the user 's computer .Changes in window focus , such as dialogs popping up and being dismissed , and applications 26 launching and exiting , must all be monitored in order to interpret the meaning of voice commands .","label":"Background","metadata":{},"score":"59.57856"}{"text":"[0010 ] .In one aspect of the present invention , a method and system is provided for analyzing spoken utterances comprising common language words in a speech - enabled environment .The system includes a syntax manager and a semantics analysis module .","label":"Background","metadata":{},"score":"59.583103"}{"text":"It includes the whole class of variations in voice pitch and intensity that have linguistic functions .3 Ward and Tsukahara , \" A Study in Responsiveness in Spoken Dialog \" , International Journal of Human - Computer Studies , March 2003 .","label":"Background","metadata":{},"score":"59.61759"}{"text":"The method of claim 21 , wherein said outputting step also outputs a visual indication for informing said user as to whether said speech dialogue system is ready to receive said input speech .The method of claim 21 , wherein said generating step generates said visual response which includes a content visualizing image formed by pictures of objects mentioned in said speech response and a numerical figure indicating a quantity of each of said objects .","label":"Background","metadata":{},"score":"59.683334"}{"text":"The method of claim 21 , wherein said outputting step also outputs a visual indication for informing said user as to whether said speech dialogue system is ready to receive said input speech .The method of claim 21 , wherein said generating step generates said visual response which includes a content visualizing image formed by pictures of objects mentioned in said speech response and a numerical figure indicating a quantity of each of said objects .","label":"Background","metadata":{},"score":"59.683334"}{"text":"10A is a diagram showing an example of an input Japanese sentence in the third embodiment ; .FIG .10B is a diagram showing an example of its MSCL description ; .FIG .10C is a diagram showing an example of a display of the effect by the commands according to the third embodiment ; .","label":"Background","metadata":{},"score":"59.685204"}{"text":"It may be necessary to further distort the duration scale of the Prosodic Font to account for the minimal duration needed for visual processing .Figure 39 : As a timing counter proceeds through the speech data , the syllable currently considered active is highlighted .","label":"Background","metadata":{},"score":"59.729782"}{"text":"In order to provide more robustness for the experimental task , each of two subsets of files will be annotated by a manual transcriber .In addition , we will use a Jack - knifing training and testing procedure .With this procedure , two thirds of the files used as the training set and one third of the files used as the test set will be cyclically exchanged so that three different pairs of training and test sets are created for the entire research measurements .","label":"Background","metadata":{},"score":"59.76242"}{"text":"2.4.1The Emotional Speaker .Prosody demonstrates a continuity of meaning ( unlike the segmental phonetic system ) , and a complexity and subtlety .The question of whether prosody is emotional is really one of kind and degree .Prior to the effects of culture , language , different social display rule requirements , gender , and physiology , human beings are fundamentally emotional creatures .","label":"Background","metadata":{},"score":"59.782684"}{"text":"Ishizaki provides a taxonomy of form using basic units of phrase of some formal dimension , like a specific instance of color ( 1996 ) .Each phrase has a particular temporal duration .Phrases combine together to make temporal forms .","label":"Background","metadata":{},"score":"59.795116"}{"text":"As shown in .FIG .1 , the result is an evidence variable that represents the combination of the above correlates that leads to a local maximum for stress level classification accuracy .Additionally , receiver operator characteristic curves will be plotted using the key acoustic parameters to ascertain which acoustic parameter or combination of parameters play the dominant role in recognizing the stress level .","label":"Background","metadata":{},"score":"59.841545"}{"text":"In such a case , the display of the content visualizing image indicating the entire order may be interrupted temporarily , if desired .Next , consider a case in which the user uttered the input speech of \" That 's right . \" more clearly , in response to the message shown in FIG .","label":"Background","metadata":{},"score":"59.85144"}{"text":"In such a case , the display of the content visualizing image indicating the entire order may be interrupted temporarily , if desired .Next , consider a case in which the user uttered the input speech of \" That 's right . \" more clearly , in response to the message shown in FIG .","label":"Background","metadata":{},"score":"59.85144"}{"text":"In such a case , the display of the content visualizing image indicating the entire order may be interrupted temporarily , if desired .Next , consider a case in which the user uttered the input speech of \" That 's right . \" more clearly , in response to the message shown in FIG .","label":"Background","metadata":{},"score":"59.85144"}{"text":"In such a case , the display of the content visualizing image indicating the entire order may be interrupted temporarily , if desired .Next , consider a case in which the user uttered the input speech of \" That 's right . \" more clearly , in response to the message shown in FIG .","label":"Background","metadata":{},"score":"59.85144"}{"text":"Here , the semantic response representation supplied from the dialogue management unit 12 contains the \" Act \" frame indicating the type of the response to be generated at the response generation unit 13 , as described above .In FIG .","label":"Background","metadata":{},"score":"59.864376"}{"text":"Here , the semantic response representation supplied from the dialogue management unit 12 contains the \" Act \" frame indicating the type of the response to be generated at the response generation unit 13 , as described above .In FIG .","label":"Background","metadata":{},"score":"59.864376"}{"text":"Here , the semantic response representation supplied from the dialogue management unit 12 contains the \" Act \" frame indicating the type of the response to be generated at the response generation unit 13 , as described above .In FIG .","label":"Background","metadata":{},"score":"59.864376"}{"text":"Here , the semantic response representation supplied from the dialogue management unit 12 contains the \" Act \" frame indicating the type of the response to be generated at the response generation unit 13 , as described above .In FIG .","label":"Background","metadata":{},"score":"59.864376"}{"text":"Furthermore , this embodiment employs a Parameter level layer ( hereinafter referred to as a P layer ) composed of prosodic parameters that are placed under the control of the control commands of the I layer .The first embodiment inserts the prosodic feature control commands in a text through the use of a prosody control system that has the three layers in multi - layered form as depicted in FIG .","label":"Background","metadata":{},"score":"59.89769"}{"text":"This indicates the boundary tone associated with the training instance speech utterance .The N th row of the exemplary data structure for storing speech utterance prosody information 1070 contains a value of \" N \" in the identifier portion 1010 .","label":"Background","metadata":{},"score":"59.904724"}{"text":"Participants in the course will present their own research in phonetics and phonology to the group ; provide specific feedback to other participants on their presentations ; and will read from the published research literature .The reading component will focus on current research trends and practical readings that develop specific methodological points ( e.g. techniques for statistical analysis , or experimental paradigms ) .","label":"Background","metadata":{},"score":"59.933872"}{"text":"Recognition feedback , dictation correction , and preference setting are all cases where traditional GUI interface elements may be desirable .The GUI manager 40 abstracts the details of exactly how these services are implemented , and provides an abstract interface to the rest of the speech center 20 .","label":"Background","metadata":{},"score":"59.96347"}{"text":"On the other hand , the operation in the system state 71 is carried out according to the flow chart of FIG .11 as follows .Namely , first at the step S91 , the order table is updated according to the semantic utterance representation supplied from the speech understanding unit 11 , and at the step S92 , the semantic response representation is generated according to the current system state .","label":"Background","metadata":{},"score":"59.97846"}{"text":"On the other hand , the operation in the system state 71 is carried out according to the flow chart of FIG .11 as follows .Namely , first at the step S91 , the order table is updated according to the semantic utterance representation supplied from the speech understanding unit 11 , and at the step S92 , the semantic response representation is generated according to the current system state .","label":"Background","metadata":{},"score":"59.97846"}{"text":"Any discourse function identifiable by a theory of discourse analysis and associated with identifiable prosodic features may be used in the practice of this invention .After the exemplary sentence has been segmented into constituent discourse function units , the prosodic features J.sub.1-J. sub.3 831 - 833 in the speech utterances associated with the exemplary training sentence are determined .","label":"Background","metadata":{},"score":"60.025764"}{"text":"If a font has no scale , no one could read it .There are many mapping potentials between parameters that have the same inherent continual permanence or discrete staccato .In the figure below , I list the mapping relationships used in Prosodic Font .","label":"Background","metadata":{},"score":"60.031734"}{"text":"6 shows response rates with respect to the above - mentioned mental states ( 7 ) to ( 10 ) that the examinees understood from the voices they heard .In this case , too , the experimental results reveal that the lengthened duration present the speaker 's intention of clearly speaking , whereas the shortened duration presents that speaker is speaking in a flurry .","label":"Background","metadata":{},"score":"60.051216"}{"text":"output means for outputting the speech response and the visual response generated by the response generation means to the user .The speech dialogue system of claim 1 , wherein the output means outputs the speech response and the visual response by controlling at least one of an output order , an output timing , and a visual response output position .","label":"Background","metadata":{},"score":"60.052437"}{"text":"19 .FIG .39 is a diagram summarizing an overall operation in the speech dialogue system of FIG .1 .FIG .40 is a schematic block diagram of a second embodiment of a speech dialogue system according to the present invention .","label":"Background","metadata":{},"score":"60.068245"}{"text":"19 .FIG .39 is a diagram summarizing an overall operation in the speech dialogue system of FIG .1 .FIG .40 is a schematic block diagram of a second embodiment of a speech dialogue system according to the present invention .","label":"Background","metadata":{},"score":"60.068245"}{"text":"19 .FIG .39 is a diagram summarizing an overall operation in the speech dialogue system of FIG .1 .FIG .40 is a schematic block diagram of a second embodiment of a speech dialogue system according to the present invention .","label":"Background","metadata":{},"score":"60.068245"}{"text":"19 .FIG .39 is a diagram summarizing an overall operation in the speech dialogue system of FIG .1 .FIG .40 is a schematic block diagram of a second embodiment of a speech dialogue system according to the present invention .","label":"Background","metadata":{},"score":"60.068245"}{"text":"In further detail , the operation in the user state 72 is carried out according to the flow chart of FIG .10 as follows .Namely , first at the step S81 , a plurality of the semantic utterance representation candidates are entered from the speech understanding unit 11 .","label":"Background","metadata":{},"score":"60.125183"}{"text":"In further detail , the operation in the user state 72 is carried out according to the flow chart of FIG .10 as follows .Namely , first at the step S81 , a plurality of the semantic utterance representation candidates are entered from the speech understanding unit 11 .","label":"Background","metadata":{},"score":"60.125183"}{"text":"Furthermore to improve performance , a prosodic analyzer should be trained / calibrated in advance .SUMMARY OF THE INVENTION .[ 0018 ] .An object of the present invention , therefore , is to provide an improved system and method for overcoming the limitations of the prior art noted above ; . [ 0019 ] .","label":"Background","metadata":{},"score":"60.178944"}{"text":"The speech dialogue system of claim 1 , wherein the response generation means generates the visual response including a content visualizing image formed by pictures of objects mentioned in the speech response and a numerical figure indicating a quantity of each of the objects .","label":"Background","metadata":{},"score":"60.211273"}{"text":"Speech , as a rich medium of communication , contains acoustic correlates such as pitch , duration , amplitude which are related to the speaker 's emotion .The anticipated outcome of this objective will be a software algorithm which analyzes the student 's dialog in real - time , and outputs data values corresponding to the prosody characteristics embedded in the student 's speech .","label":"Background","metadata":{},"score":"60.228355"}{"text":"FIG .9 is a state transition diagram for an operation of a dialogue management unit in the speech dialogue system of FIG .1 .FIG .10 is a flow chart for an operation in a user state in the state transition diagram of FIG .","label":"Background","metadata":{},"score":"60.262924"}{"text":"FIG .9 is a state transition diagram for an operation of a dialogue management unit in the speech dialogue system of FIG .1 .FIG .10 is a flow chart for an operation in a user state in the state transition diagram of FIG .","label":"Background","metadata":{},"score":"60.262924"}{"text":"FIG .9 is a state transition diagram for an operation of a dialogue management unit in the speech dialogue system of FIG .1 .FIG .10 is a flow chart for an operation in a user state in the state transition diagram of FIG .","label":"Background","metadata":{},"score":"60.262924"}{"text":"We will work through the principles of phonological analysis : the process of inferring the distribution and its implication from a dataset .We will also consider explanations for why some patterns occur again and again in the world 's languages .","label":"Background","metadata":{},"score":"60.281162"}{"text":"2.2.2Pitch Range How does one represent pitch range computationally ?Does pitch range start from the bottom of a speaker 's range and go higher , or does it start from the middle and deviate to higher or lower pitches ?","label":"Background","metadata":{},"score":"60.28854"}{"text":"The \" 175 \" value indicates the initial frequency information for the training instance speech utterance .The exemplary data structure for storing speech utterance prosody information 1070 contains the value \" 0.15 \" in the pitch variation portion 1040 .The \" 0.15 \" value indicates the variation in the pitch associated with the subordination discourse function .","label":"Background","metadata":{},"score":"60.299362"}{"text":"14 is a flow chart for an operation in a system state in an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .1 .FIGS .15A , 15B and 15E are illustrations of examples of a semantic utterance representation , a response act list , and a semantic response representation for an exemplary case of the operation in a dialogue management unit in the operation shown in the flow chart of FIG .","label":"Background","metadata":{},"score":"60.29964"}{"text":"14 is a flow chart for an operation in a system state in an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .1 .FIGS .15A , 15B and 15E are illustrations of examples of a semantic utterance representation , a response act list , and a semantic response representation for an exemplary case of the operation in a dialogue management unit in the operation shown in the flow chart of FIG .","label":"Background","metadata":{},"score":"60.29964"}{"text":"It is an important aspect of what you know when you know how to speak a language .Such an analysis not only represents the sound pattern , but also shows how a pattern in one language relates to typological patterns across languages .","label":"Background","metadata":{},"score":"60.302216"}{"text":"FIG .3 is an illustration of an example of a keyword lattice obtained from a continuous input speech in the speech understanding unit of FIG .2 . FIG .4 is an illustration of an example of a semantic utterance representation to be obtained by the speech understanding unit of FIG .","label":"Background","metadata":{},"score":"60.30649"}{"text":"FIG .3 is an illustration of an example of a keyword lattice obtained from a continuous input speech in the speech understanding unit of FIG .2 . FIG .4 is an illustration of an example of a semantic utterance representation to be obtained by the speech understanding unit of FIG .","label":"Background","metadata":{},"score":"60.30649"}{"text":"FIG .3 is an illustration of an example of a keyword lattice obtained from a continuous input speech in the speech understanding unit of FIG .2 . FIG .4 is an illustration of an example of a semantic utterance representation to be obtained by the speech understanding unit of FIG .","label":"Background","metadata":{},"score":"60.30649"}{"text":"4 is an illustration of an example of a semantic utterance representation to be obtained by the speech understanding unit of FIG .2 .FIG 5 is an illustration of an exemplary list of keywords to be used in the speech understanding unit of FIG .","label":"Background","metadata":{},"score":"60.34438"}{"text":"( b ) extracting from the text a prosodic parameter string of speech synthesized by rules ; .( c ) controlling that one of the prosodic parameters of the prosodic parameter string corresponding to the character or character string to be added with the non - verbal information , by referring to the prosody control rules stored in the prosody control rule database ; and .","label":"Background","metadata":{},"score":"60.37847"}{"text":"This semantic response representation of FIG .6 is for the confirmation of the order made by the user , so that the ACT frame indicates this \" confirmation \" operation while the ORDER TABLE frame indicates the content of the order made by the input speech .","label":"Background","metadata":{},"score":"60.44912"}{"text":"This semantic response representation of FIG .6 is for the confirmation of the order made by the user , so that the ACT frame indicates this \" confirmation \" operation while the ORDER TABLE frame indicates the content of the order made by the input speech .","label":"Background","metadata":{},"score":"60.44912"}{"text":"This semantic response representation of FIG .6 is for the confirmation of the order made by the user , so that the ACT frame indicates this \" confirmation \" operation while the ORDER TABLE frame indicates the content of the order made by the input speech .","label":"Background","metadata":{},"score":"60.44912"}{"text":"This semantic response representation of FIG .6 is for the confirmation of the order made by the user , so that the ACT frame indicates this \" confirmation \" operation while the ORDER TABLE frame indicates the content of the order made by the input speech .","label":"Background","metadata":{},"score":"60.44912"}{"text":"Input speech analysis part for analyzing input speech containing non - verbal information to obtain prosodic parameters ; .a prosodic feature / prosodic feature control command conversion part for converting said prosodic parameters in said input speech to a set of prosodic feature control commands ; and .","label":"Background","metadata":{},"score":"60.451157"}{"text":"In step S 500 , discourse functions are determined based on the speech utterances and the selected theory of discourse analysis .Discourse functions refer to intra - sentential and inter - sentential phenomena used to accomplish task , text and interaction level discourse activities .","label":"Background","metadata":{},"score":"60.45357"}{"text":"For example , in an educational application , the content would include tutoring materials ; in other commercial applications the content will vary of course depending on the designs , objectives and nature of a vendor / operator 's business .[ 0000 ] .","label":"Background","metadata":{},"score":"60.499706"}{"text":"A combination of phonetic and orthographic linguistic forms would be used during speech recognition , inherently opening up opportunities for dialect representations of speech .Automating the Prosodic Font speech parameter collection is obviously one of the largest future work agenda items .","label":"Background","metadata":{},"score":"60.543015"}{"text":"This section reviews the many conventions that have been proposed .Identifying the structure of talk and writing has been a focus of natural language generation and understanding efforts .Discourse theorists always appoint a central role for prosody in the segmentation of spoken discourse , yet the models differ substantially .","label":"Background","metadata":{},"score":"60.547043"}{"text":"Pierrehumbert 's work on characterizing the fundamental frequency in a linear , relative manner is still the phonological state - of - the - art ( 1980 ) .2.3.2 Phonetic Models of Prosody .On the continuous , speaker dependent side are the researchers who attempt to describe the physical signals themselves in succinct manners .","label":"Background","metadata":{},"score":"60.557335"}{"text":"Still another object of the present invention is to provide a synthetic speech message editing / creating method and apparatus that allow ease in visually recognizing the effect of prosodic parameter control in editing non - verbal information of a synthetic speech message .","label":"Background","metadata":{},"score":"60.650497"}{"text":"Affective versus Syntactic Ontology : those who hold that intonation and patterns of prominence developed as an extension of grammar and discourse structure versus those that believe prosody has non - linguistic roots in affect and emotion that develop in conventionally understood ways , dependent upon sociological and linguistic factors .","label":"Background","metadata":{},"score":"60.652763"}{"text":"The expected outcome of this objective at the end of Phase I is a prototype of the front - end of the ITS architecture defined in Objective 2-i.e . the speech recognition , natural language and prosody modeler modules as shown in .","label":"Background","metadata":{},"score":"60.66839"}{"text":"8 is a table depicting examples of commands used in hearing tests concerning prosodic features of the pitch and the power in a third embodiment of the present invention ; .FIG .9 is a table depicting examples of commands used in hearing tests concerning the dynamic range of the pitch in the third embodiment ; .","label":"Background","metadata":{},"score":"60.67675"}{"text":"For example the latter may not include a prosody capability , and therefore emotion detection may need to be facilitated by a separate server device .[0085 ] .Moreover in some instances the prosodic data and acoustic feature data can be transmitted using different priorities .","label":"Background","metadata":{},"score":"60.766937"}{"text":"A speaker model would initialize all Prosodic Font parameters such that unreadable visualizations would not occur .Using an individual 's Speaker Model , a look - up table of phonetic duration distributions across speakers , and speech / prosody recognizers , a Prosodic Font could identify the routine from the excited or depressed phonetic sounds .","label":"Background","metadata":{},"score":"60.79841"}{"text":"Institute for Research in Cognitive Science , Philadelphia , PA . , 19 - 30 ._ _ _ _ .The Effect of Pitch Accenting on Pronoun Referent Resolution .Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics .","label":"Background","metadata":{},"score":"60.823215"}{"text":"Abstract .A conversation manager processes spoken utterances from a user of a computer .The conversation manager includes a semantics analysis module and a syntax manager .A domain model that is used in processing the spoken utterances includes an ontology ( i.e. , world view for the relevant domain of the spoken utterances ) , lexicon , and syntax definitions .","label":"Background","metadata":{},"score":"60.82554"}{"text":"5 shows response rates with respect to the above - mentioned mental states ( 1 ) to ( 6 ) that the examinees understood from the voices they heard .The experimental results suggest that the six kinds of modifications ( a ) to ( f ) of the pitch contour depicted in FIG .","label":"Background","metadata":{},"score":"60.861423"}{"text":"12A to 12E. FIG .14 is a flow chart for an operation in a system state in an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .1 .FIGS .15A , 15B and 15C are illustrations of examples of a semantic utterance representation , a response act list , and a semantic response representation for an exemplary case of the operation in a dialogue management unit in the operation shown in the flow chart of FIG .","label":"Background","metadata":{},"score":"60.86503"}{"text":"( a ) extracting from said text a prosodic parameter string of speech synthesized by rules ; .( c ) synthesizing speech from said prosodic parameter string containing said corrected prosodic parameter and outputting a synthetic speech message ; .A method for editing non - verbal information by adding information of mental states to a speech message synthesized by rules in correspondence to a text , said method comprising the steps of : .","label":"Background","metadata":{},"score":"60.87288"}{"text":"14 is a flow chart for an operation in a system state in an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .1 .FIGS .15A , 15B and 15C are illustrations of examples of a semantic utterance representation , a response act list , and a semantic response representation for an exemplary case of the operation in a dialogue management unit in the operation shown in the flow chart of FIG .","label":"Background","metadata":{},"score":"60.879368"}{"text":"Second , it is ease of usage intended for skilled users which permits description of close control .The above - mentioned method can not change the character shape and writing direction .Even as for the character string , for instance , there arises a need for varying it in many ways when it is desired to prepare an attention - seeking home page .","label":"Background","metadata":{},"score":"60.887516"}{"text":"Hence , if there were a correspondingly flexible medium , such as computational fonts , there could be many mapping relationships established between the parameters sets that would be expressively meaningful to readers .This assumes a competency on the part of readers , that they can and will be able to read and understand the prosodic relationships conveyed via fonts .","label":"Background","metadata":{},"score":"60.9162"}{"text":"The prosodic parameters obtained in step S 6 are controlled by referring to the prosodic feature control commands and the positional information both obtained in step S 5 ( S 10 ) .Based on the controlled prosodic parameters , a speech synthesis signal for the Japanese text separated in step S 4 is generated ( S 11 ) , and then the speech synthesis signal is output as speech ( S 12 ) .","label":"Background","metadata":{},"score":"60.91709"}{"text":"The speech understanding unit 11 is required to achieve the understanding of the input speech uttered by the user by extracting a semantic content intended to be expressed in the input speech .Under the properly controlled circumstances , this method is capable of achieving the high speed understanding of the almost freely uttered speech by using very little restrictions regarding the manner of speech utterance imposed on the user .","label":"Background","metadata":{},"score":"60.918114"}{"text":"The speech understanding unit 11 is required to achieve the understanding of the input speech uttered by the user by extracting a semantic content intended to be expressed in the input speech .Under the properly controlled circumstances , this method is capable of achieving the high speed understanding of the almost freely uttered speech by using very little restrictions regarding the manner of speech utterance imposed on the user .","label":"Background","metadata":{},"score":"60.918114"}{"text":"Eds .Feldman and Rime .Cambridge : Cambridge University Press .Kiesling A. , Kompe , R. , Niemann , H. , Noth , E. , & Batliner , A. ( 1995 ) .Voice Source State as a Source of Information in Speech Recognition : Detection of Laryngealizations .","label":"Background","metadata":{},"score":"60.94017"}{"text":"45 is a schematic block diagram of a third embodiment of a speech dialogue system according to the present invention .FIGS .46A and 46B are block diagrams of two alternative configurations for an A / D and D / A conversion units in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"60.96903"}{"text":"45 is a schematic block diagram of a third embodiment of a speech dialogue system according to the present invention .FIGS .46A and 46B are block diagrams of two alternative configurations for an A / D and D / A conversion units in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"60.96903"}{"text":"45 is a schematic block diagram of a third embodiment of a speech dialogue system according to the present invention .FIGS .46A and 46B are block diagrams of two alternative configurations for an A / D and D / A conversion units in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"60.96903"}{"text":"45 is a schematic block diagram of a third embodiment of a speech dialogue system according to the present invention .FIGS .46A and 46B are block diagrams of two alternative configurations for an A / D and D / A conversion units in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"60.96903"}{"text":"In the second part of the course , we will explore patterns of distribution of speech sound categories , i.e. restrictions on what sounds go where .Students will learn to discover such patterns in data and analyze them within a formal model .","label":"Background","metadata":{},"score":"60.972935"}{"text":"In one conventional approach , the user speaks ( makes audible utterance of ) a specific command from a limited menu of phrases recognized by a speech - enabled software application .The user must speak the command or phrase in exactly the proper manner without departing from the predefined menu .","label":"Background","metadata":{},"score":"60.97924"}{"text":"No .09/342,937 , filed Jun. 29 , 1999 , entitled \" Method and Apparatus for Translation of Common Language Utterances into Computer Application Program Commands , \" the entire teachings of which are incorporated herein by reference .When these functions are executed , they build frames within the semantic analysis module 50 which serve as an initial semantic representation of the utterance 15 .","label":"Background","metadata":{},"score":"61.003014"}{"text":"FIG .11 is a flow chart for an operation in a system state in the state transition diagram of FIG .9 .FIGS .12A and 12B are illustrations of examples of a semantic response representation and an order table for an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"61.054268"}{"text":"FIG .11 is a flow chart for an operation in a system state in the state transition diagram of FIG .9 .FIGS .12A and 12B are illustrations of examples of a semantic response representation and an order table for an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"61.054268"}{"text":"FIG .11 is a flow chart for an operation in a system state in the state transition diagram of FIG .9 .FIGS .12A and 12B are illustrations of examples of a semantic response representation and an order table for an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"61.054268"}{"text":"Second Embodiment .Since the apparatus depicted in FIG .3 can be used for a synthetic speech editing method according to a second embodiment of the present invention , this embodiment will hereinbelow be described with reference to FIG .3 .","label":"Background","metadata":{},"score":"61.098686"}{"text":"1 .FIGS .12D and 12E are illustrations of examples of two semantic utterance representation candidates for an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .1 .FIG .13 is a flow chart for an operation in a user state in an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"61.111145"}{"text":"Every command of the S layer is converted to a set of I - layer commands - this permits closer prosody control .Shown below in Table 1 are examples of the I - layer commands , prosodic parameters to be controlled and the contents of control .","label":"Background","metadata":{},"score":"61.111977"}{"text":"3 which is configured to interact on a real - time basis to give a human - like dialog capability / experience for e - commerce , e - support , and e - learning applications .As seen in .FIG .","label":"Background","metadata":{},"score":"61.152203"}{"text":"Each speech event has an ending time and a peak amplitude .Syllables , in addition , have pointers to a TILT accent event , if they fall within the accent 's duration .In this way , a syllable can represent parameters reserved for accented information .","label":"Background","metadata":{},"score":"61.180996"}{"text":"Here , the human character image to be displayed on the display unit 14 incorporates the movement and the facial expression of the human character which are determined according to the response output content information and the human character image information supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"61.18578"}{"text":"Here , the human character image to be displayed on the display unit 14 incorporates the movement and the facial expression of the human character which are determined according to the response output content information and the human character image information supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"61.18578"}{"text":"Here , the human character image to be displayed on the display unit 14 incorporates the movement and the facial expression of the human character which are determined according to the response output content information and the human character image information supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"61.18578"}{"text":"Here , the human character image to be displayed on the display unit 14 incorporates the movement and the facial expression of the human character which are determined according to the response output content information and the human character image information supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"61.18578"}{"text":"The exemplary data structure for storing speech utterance prosody information 1070 contains the value \" 0.10 \" in the preceding silence portion 1050 .The \" 0.10 \" value indicates the duration of any silence preceding the training instance speech utterance .","label":"Background","metadata":{},"score":"61.187664"}{"text":"Disturbances in prosody : a right - hemisphere contribution to language .Archives of Neurology 38 , 742 - 744 .Wong , YinYin .Temporal Typography : Characterization of time - varying typographic forms .M.S. Thesis , Massachusetts Institute of Technology , Media Laboratory .","label":"Background","metadata":{},"score":"61.202797"}{"text":"Finally , at the step S124 , the transition to the addition confirmation user state UA is made .The examples of other system speech responses for confirmation operation in cases of the other response acts are enlisted in FIG .16 .","label":"Background","metadata":{},"score":"61.316284"}{"text":"Finally , at the step S124 , the transition to the addition confirmation user state UA is made .The examples of other system speech responses for confirmation operation in cases of the other response acts are enlisted in FIG .16 .","label":"Background","metadata":{},"score":"61.316284"}{"text":"Finally , at the step S124 , the transition to the addition confirmation user state UA is made .The examples of other system speech responses for confirmation operation in cases of the other response acts are enlisted in FIG .16 .","label":"Background","metadata":{},"score":"61.316284"}{"text":"Finally , at the step S124 , the transition to the addition confirmation user state UA is made .The examples of other system speech responses for confirmation operation in cases of the other response acts are enlisted in FIG .16 .","label":"Background","metadata":{},"score":"61.316284"}{"text":"The three tiers of the figure allow cross - analysis of the [ 1 ] amplitude , [ 2 ] orthography , and the [ 3 ] fundamental frequency tracking results .Note how there is no fundamental frequency during the phoneme /t / events .","label":"Background","metadata":{},"score":"61.329437"}{"text":"Finally , we will address topics , such as second language acquisition and current speech technology as it applies to computerized speech synthesis and speech recognition .This course will provide an introduction to the problems , methods , and tools of linguistics in the areas of phonetics and phonology .","label":"Background","metadata":{},"score":"61.373108"}{"text":"Then , on the system side , the above described operation in the initial user state U0 in the state transition diagram of FIG .9 is carried out .Here , however , suppose that the input speech was uttered by the user so fast that the system failed to understand the input speech as there is no output from the speech understanding unit 11 .","label":"Background","metadata":{},"score":"61.432983"}{"text":"Then , on the system side , the above described operation in the initial user state U0 in the state transition diagram of FIG .9 is carried out .Here , however , suppose that the input speech was uttered by the user so fast that the system failed to understand the input speech as there is no output from the speech understanding unit 11 .","label":"Background","metadata":{},"score":"61.432983"}{"text":"Then , on the system side , the above described operation in the initial user state U0 in the state transition diagram of FIG .9 is carried out .Here , however , suppose that the input speech was uttered by the user so fast that the system failed to understand the input speech as there is no output from the speech understanding unit 11 .","label":"Background","metadata":{},"score":"61.432983"}{"text":"Then , on the system side , the above described operation in the initial user state U0 in the state transition diagram of FIG .9 is carried out .Here , however , suppose that the input speech was uttered by the user so fast that the system failed to understand the input speech as there is no output from the speech understanding unit 11 .","label":"Background","metadata":{},"score":"61.432983"}{"text":"Kagan et al .correlated wider variation in pitch with extroverted as opposed to introverted personalities ( 1994 ) .Lastly , emotion - or more broadly - affect , lifts or depresses a person 's entire speech range .Therefore , the range evident in one person during one intonational phrase may not be the range of an intonational phrase that follows ; likewise , differences in pitch range across people is vast .","label":"Background","metadata":{},"score":"61.475834"}{"text":"There may be a need for a rhythm equalizer to ease sudden rhythmic transitions , and some persistence of image during very fast segments to give the eye slightly more time to read .USER TEST .I designed a user test for Prosodic Font to see if people , exposed minimally to a file from the Prosodic Font corpus , could choose an audio file that most closely resembled the intonation , rhythm and emphasis evident in the Prosodic Font .","label":"Background","metadata":{},"score":"61.478016"}{"text":"Data values that are extracted at the client side are transmitted to the server for incorporation in the SQL construct for the database query process , or incorporated in higher level logic of the dialog manager .In this way the turn - taking and control of the dialogue is significantly shaped by the emotion states extracted from the speaker 's utterance .","label":"Background","metadata":{},"score":"61.49485"}{"text":"31A , when the number of items ordered becomes numerous , the text data can be quite lengthy and the output of the entire speech response can take a considerable amount of time .In such a case , the display of the text data is useless and the speech response can be rather irritating to the user .","label":"Background","metadata":{},"score":"61.501465"}{"text":"31A , when the number of items ordered becomes numerous , the text data can be quite lengthy and the output of the entire speech response can take a considerable amount of time .In such a case , the display of the text data is useless and the speech response can be rather irritating to the user .","label":"Background","metadata":{},"score":"61.501465"}{"text":"31A , when the number of items ordered becomes numerous , the text data can be quite lengthy and the output of the entire speech response can take a considerable amount of time .In such a case , the display of the text data is useless and the speech response can be rather irritating to the user .","label":"Background","metadata":{},"score":"61.501465"}{"text":"31A , when the number of items ordered becomes numerous , the text data can be quite lengthy and the output of the entire speech response can take a considerable amount of time .In such a case , the display of the text data is useless and the speech response can be rather irritating to the user .","label":"Background","metadata":{},"score":"61.501465"}{"text":"etc . , required in the speech understanding operation , the dialogue management operation , and the response generation operation .Here , the processor unit 291 carries out the multi - task execution of the programs for realizing the understanding operation , the dialogue management operation , and the response generation operation as in the first and second embodiment described above .","label":"Background","metadata":{},"score":"61.506042"}{"text":"It is preferable to carry out this speech speed control such that the utterance duration is made shorter when the dialogue is progressing smoothly , while the utterance duration is made longer when the dialogue is not progressing smoothly .Here , the change of the utterance duration can be controlled properly by selecting the appropriate length of the response sentence pattern .","label":"Background","metadata":{},"score":"61.549507"}{"text":"It is preferable to carry out this speech speed control such that the utterance duration is made shorter when the dialogue is progressing smoothly , while the utterance duration is made longer when the dialogue is not progressing smoothly .Here , the change of the utterance duration can be controlled properly by selecting the appropriate length of the response sentence pattern .","label":"Background","metadata":{},"score":"61.549507"}{"text":"In some applications , of course , it may not be necessary or desirable to compute all such variables , and in other instances it may be useful to use additional frequency , energy and/or duration components ( or derivatives thereof ) .","label":"Background","metadata":{},"score":"61.553024"}{"text":"It consists of two major parts .In the first part , we will survey the sounds of the world 's languages : how they are made , what they sound like , and how they differ from each other in acoustic properties .","label":"Background","metadata":{},"score":"61.575684"}{"text":"What additional information can a font convey when the font represents a speaking voice rather than a hand - manipulated pen ? \"Trends in speech recognition and synthesis have been narrowly focused upon recognizing semantic word units only .The influence of prosody upon the interpretation of semantics and speaker intention has been neglected .","label":"Background","metadata":{},"score":"61.58892"}{"text":"When the keyword is determined as capable of being the start point of a sentence , this keyword is registered into the sentence candidate table 22d as a new sentence part candidate .Then , the sentence candidate end point detector 22c determines whether each connected sentence part candidate processed by the sentence candidate analyzer can be regarded as a complete sentence according to the prescribed syntactic and semantic rules .","label":"Background","metadata":{},"score":"61.602623"}{"text":"When the keyword is determined as capable of being the start point of a sentence , this keyword is registered into the sentence candidate table 22d as a new sentence part candidate .Then , the sentence candidate end point detector 22c determines whether each connected sentence part candidate processed by the sentence candidate analyzer can be regarded as a complete sentence according to the prescribed syntactic and semantic rules .","label":"Background","metadata":{},"score":"61.602623"}{"text":"When the keyword is determined as capable of being the start point of a sentence , this keyword is registered into the sentence candidate table 22d as a new sentence part candidate .Then , the sentence candidate end point detector 22c determines whether each connected sentence part candidate processed by the sentence candidate analyzer can be regarded as a complete sentence according to the prescribed syntactic and semantic rules .","label":"Background","metadata":{},"score":"61.602623"}{"text":"When the keyword is determined as capable of being the start point of a sentence , this keyword is registered into the sentence candidate table 22d as a new sentence part candidate .Then , the sentence candidate end point detector 22c determines whether each connected sentence part candidate processed by the sentence candidate analyzer can be regarded as a complete sentence according to the prescribed syntactic and semantic rules .","label":"Background","metadata":{},"score":"61.602623"}{"text":"As described above , a wide variety of non - verbal information can be added to synthetic speech by combinations of the modifications of the pitch contour ( modifications of the dynamic range and envelope ) with the lengthening and shortening of the duration .","label":"Background","metadata":{},"score":"61.663063"}{"text":"A display 1 \" - \" provided at the beginning of each line indicates the position of the pitch frequency of the synthesized result prior to the editing operation .That is , when no editing operation is performed concerning the pitch frequency , the characters in each line are arranged with the position of the display [ - ] held at the same height as that of the center of each character .","label":"Background","metadata":{},"score":"61.682274"}{"text":"Hence , in the second embodiment of the invention it is determined that these modified versions of the pitch contour correspond to the mental states ( 1 ) to ( 6 ) , and they are used as basic prosody control rules .","label":"Background","metadata":{},"score":"61.73066"}{"text":"Voice is an act of expression that moves what is internal , private and undifferentiated into an external , public and particular environment .Unlike a static font , a prosodic font does not forget the instant of emergence from the body .","label":"Background","metadata":{},"score":"61.737442"}{"text":"Shriberg , 1998].Prosody is a general term for those aspects of speech that span groups of syllables [ Par 86 ] , and we incorporate in the concept dialog prosody : characteristics spanning not just one but multiple conversational turns .","label":"Background","metadata":{},"score":"61.75335"}{"text":"Similar discourse constituents are clustered and machine learning , statistics or other techniques are applied to select the prosodic features for the predictive model of discourse functions .The predictive model of discourse functions is then saved to memory .The predictive models of discourse functions can then be used alone or in combination with newly recognized speech utterances to determine the discourse functions .","label":"Background","metadata":{},"score":"61.776505"}{"text":"8 is utilized as the dialogue history indicative of the change of the order table in the course of the order taking operation .This dialogue management unit 12 also manages the progress of the dialogue between the system and the user according to the state transition diagram shown in FIG .","label":"Background","metadata":{},"score":"61.800594"}{"text":"8 is utilized as the dialogue history indicative of the change of the order table in the course of the order taking operation .This dialogue management unit 12 also manages the progress of the dialogue between the system and the user according to the state transition diagram shown in FIG .","label":"Background","metadata":{},"score":"61.800594"}{"text":"8 is utilized as the dialogue history indicative of the change of the order table in the course of the order taking operation .This dialogue management unit 12 also manages the progress of the dialogue between the system and the user according to the state transition diagram shown in FIG .","label":"Background","metadata":{},"score":"61.800594"}{"text":"8 is utilized as the dialogue history indicative of the change of the order table in the course of the order taking operation .This dialogue management unit 12 also manages the progress of the dialogue between the system and the user according to the state transition diagram shown in FIG .","label":"Background","metadata":{},"score":"61.800594"}{"text":"In various other exemplary embodiments according to this invention , the prosodic feature determination routine or circuit 40 may be a digital signal processor embedded within the automatic speech recognition system .The prosodic feature determination circuit or routine 40 determines the prosodic features of the speech utterances and encodes them as annotations within the recognized speech utterances .","label":"Background","metadata":{},"score":"61.80382"}{"text":"For example , callers who are confused or express doubt may be routed to another dialog module , or to a live operator .[ 0033 ] .In some preferred embodiments an emotion state can be used to control visual feedback presented to a user of the real - time speech recognition system .","label":"Background","metadata":{},"score":"61.830093"}{"text":"FIG .7 is an illustration of an order table to be used in a dialogue management unit in the speech dialogue system of FIG .1 .FIG .8 is an illustration of a past order table to be used in a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"61.83464"}{"text":"FIG .7 is an illustration of an order table to be used in a dialogue management unit in the speech dialogue system of FIG .1 .FIG .8 is an illustration of a past order table to be used in a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"61.83464"}{"text":"FIG .7 is an illustration of an order table to be used in a dialogue management unit in the speech dialogue system of FIG .1 .FIG .8 is an illustration of a past order table to be used in a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"61.83464"}{"text":"Then , the dialogue management unit maintains the state # 0 and the operation proceeds to a next operation timing .When the speech act is not \" no \" at the step S289 , next at the step S291 , whether the user state act in the semantic user state representation supplied from the user state detection unit 233 is \" user absent \" or not is determined .","label":"Background","metadata":{},"score":"61.866943"}{"text":"Then , the dialogue management unit maintains the state # 0 and the operation proceeds to a next operation timing .When the speech act is not \" no \" at the step S289 , next at the step S291 , whether the user state act in the semantic user state representation supplied from the user state detection unit 233 is \" user absent \" or not is determined .","label":"Background","metadata":{},"score":"61.866943"}{"text":"In the synthesis - by - rule speech from a text , too , attempts are being made to additionally provide desired non - verbal information .Since these attempts each insert in the text a command for controlling phonological information of a specific kind , a user is required to have knowledge about verbal information .","label":"Background","metadata":{},"score":"61.909622"}{"text":"FIG .31B is a timing chart for another example of a display timing control to be made in a response output control unit in the response generation unit of FIG .19 .FIG .32 to FIG .38 are illustrations of various examples of display images to be used in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"61.92305"}{"text":"FIG .31B is a timing chart for another example of a display timing control to be made in a response output control unit in the response generation unit of FIG .19 .FIG .32 to FIG .38 are illustrations of various examples of display images to be used in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"61.92305"}{"text":"FIG .31B is a timing chart for another example of a display timing control to be made in a response output control unit in the response generation unit of FIG .19 .FIG .32 to FIG .38 are illustrations of various examples of display images to be used in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"61.92305"}{"text":"FIG .31B is a timing chart for another example of a display timing control to be made in a response output control unit in the response generation unit of FIG .19 .FIG .32 to FIG .38 are illustrations of various examples of display images to be used in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"61.92305"}{"text":"Each utterance is indexed in the conversational record 60 , along with the results of its semantic analysis .The information is eventually purged from the conversational record when it is no longer relevant to active goals and after some predefined period of time has elapsed .","label":"Background","metadata":{},"score":"61.931557"}{"text":"I placed no limit on the number of times subjects might replay the audio or Prosodic Font files due to short term memory constraints on temporally based material .They were also to circle the emotion that most closely describes the emotion expressed within the Prosodic Font file .","label":"Background","metadata":{},"score":"61.933823"}{"text":"This indicates pitch variation that is typically associated with discourse functions of type \" COORDINATION \" .The preceding silence portion 1150 contains the value \" 0.14 \" .This indicates that discourse functions of type \" COORDINATION \" are typically associated with a preceding silence of \" 0.14 \" units .","label":"Background","metadata":{},"score":"61.95154"}{"text":"0140 ] .Before the extraction can begin , we will acquire a speech corpus in the form of a database or a corpus containing a set of files from one of several recognized linguistic repositories 7 .The corpus sourced from the Oregon Graduate Institute is supplied with a phonetic transcription file with each speech file .","label":"Background","metadata":{},"score":"61.97352"}{"text":"[ 0102 ] .[ 0103 ] .For example , the invention can incorporate knowledge of the user 's domain , such as knowledge about the user 's goals , plans , tasks , and processes .Techniques are provided for determining predictive models of discourse functions based on prosodic features of natural language speech .","label":"Background","metadata":{},"score":"61.98338"}{"text":"The tree is structured as a sequence of simple questions , and the answers to these questions trace a path down the tree .The end point reached determines the classification or prediction made by the model .[ 0083 ] .","label":"Background","metadata":{},"score":"62.001984"}{"text":"The output 16 is a command or other output based on the recognized spoken utterance 15 and which is directed to the speech enabled external application 26 ( see .FIG .2 ) selected by the conversation manager 28 .[ 0024 ] .","label":"Background","metadata":{},"score":"62.05321"}{"text":"Prosodic features spanning several speech units that are larger than phonemes - i.e . syllables , words and turns - can be built up incrementally from characteristics of smaller units .We will proceed incrementally from bottom up in this work , keeping in mind the higher level modeling structures which are to be developed .","label":"Background","metadata":{},"score":"62.07229"}{"text":"Computational Linguistics 28:3 , 245 - 288 .Graesser , A. , Wiemer - Hastings , K. , Wiemer - Hastings , P. , Kreuz , R. , & the Tutoring Research Group ( 2000 ) .AutoTutor :A simulation of a human tutor , Journal of Cognitive Systems Research , 1,35 - 51 .","label":"Background","metadata":{},"score":"62.082863"}{"text":"Gibson and Levin , from the Psychology of Reading ( 1975 ) .This thesis is about writing .Or rather , what writing might become when one is writing by speaking .What does the introduction of software that can translate speech into written symbols do to the nature of writing , of reading ?","label":"Background","metadata":{},"score":"62.104084"}{"text":"In the second part of the course , we will survey the sounds of the world 's languages .Students will learn to identify sounds from many different languages .Grading Policy .The grade will be based on homework assignments ( roughly on a week ) , and two quizzes ( one at the end of each section of the course ) .","label":"Background","metadata":{},"score":"62.126995"}{"text":"The prosodic feature patterns once stored in the prosodic feature rule database 16 are selectively read out therefrom into the prosodic feature - to - control command conversion part 23 by designating a required one of the S - layer commands .","label":"Background","metadata":{},"score":"62.13221"}{"text":"The \" SUBORDINATION \" value indicates that the training speech utterance has been classified as a subordination type of discourse function under the selected theory of discourse analysis .Typically the classification is verified by multiple automatics and/or human verifiers .It will be apparent that the terms \" SUBORDINATION \" and \" COORDINATION \" are merely exemplary and that in various other exemplary embodiments according to this invention , different naming conventions may be used without departing from the scope of this invention .","label":"Background","metadata":{},"score":"62.133484"}{"text":"[ 0090 ] .It is widely accepted that students achieve large gains in learning when they receive good one - on - one human tutoring .[ Cohen et al , 1982].One of the success factors of human tutors is their ability to use prosodic information embedded in a students ' unconstrained speech in order to draw inferences about the student 's understanding of the lesson as it progresses , and to structure the tutor / student dialog accordingly .","label":"Background","metadata":{},"score":"62.156567"}{"text":"867 - 870 ., Language and Speech 41(3 - 4 ) , 439 - 487 .Grosz , B. & Hirshberg , J. ( 1992 ) , Some intonational characteristics of discourse structure , in ' Proceedings of the International Conference on Spoken Language Processing ' , Banff , Canada , pp .","label":"Background","metadata":{},"score":"62.188995"}{"text":"For example , \" Tell me a story about when you were really angry , furious or livid about something that happened to you , or perhaps to another person ... \" .From two hours of original recording , I chose two speakers from the original seven , one male and one female , from whom to develop an emotional corpus with speaker consistency .","label":"Background","metadata":{},"score":"62.199257"}{"text":"4 , pp .329 - 353,1989 .Zachary , W. Santarelli , T. , Lyons , D. , Bergondy , M. and Johnston , J. ( 2001 ) .Using a Community of Intelligent Synthetic Entities to Support Operational Team Training .","label":"Background","metadata":{},"score":"62.200985"}{"text":"Gibson & Levin .Cambridge , MA : MIT Press .A speech dialogue system capable of realizing natural and smooth dialogue between the system and a human user , and easy maneuverability of the system .In the system , a semantic content of input speech from a user is understood and a semantic content determination of a response output is made according to the understood semantic content of the input speech .","label":"Background","metadata":{},"score":"62.20644"}{"text":"The predictive discourse model may be determined using machine learning , statistics , and support vector machines , Nave Bayes , decision tree induction or any known or later developed method of determining a predictive model .In various other exemplary embodiments , the predictive discourse model may be an incremental predictive model that refines the current predictive model based on new training instances .","label":"Background","metadata":{},"score":"62.211693"}{"text":"[ 0005 ] .A conventional grammar are limited in that is typically difficult to consistently specify and maintain large grammars .The present invention applies more general syntactic templates to an ontological model thus allowing more consistent generation across the grammar .","label":"Background","metadata":{},"score":"62.245625"}{"text":"Motion latencies between independent strokes are thus possible to introduce .I introduced three new strokes into the system .Figure 27 : The two ' j ' glyphs above demonstrate the two potential glyph variations by merely attaching different dependent glyphs .","label":"Background","metadata":{},"score":"62.260086"}{"text":"Zachary , W. W. , Ryder , J. M. , & Hicinbothom , J. H. ( 2000 ) .Building cognitive task analyses and models of a decision - making team in a complex real - time environment .In J. M. Schraagen , S. F. Chipman , & V. L. Shalin ( Eds . ) , Cognitive Task Analysis .","label":"Background","metadata":{},"score":"62.2862"}{"text":"When an utterance 15 is recognized , the conversation manager 28 combines an analysis of the utterance 15 with information on the state of the desktop and remembered context from previous recognitions to determine the intended target of the utterance 15 .","label":"Background","metadata":{},"score":"62.320526"}{"text":"Then , at the step S83 , the scoring for evaluating the likelihood of each of the semantic utterance representation candidates is made , and at the step S84 , one of the semantic utterance representation candidates with the highest score is selected as the semantic utterance representation .","label":"Background","metadata":{},"score":"62.417313"}{"text":"Then , at the step S83 , the scoring for evaluating the likelihood of each of the semantic utterance representation candidates is made , and at the step S84 , one of the semantic utterance representation candidates with the highest score is selected as the semantic utterance representation .","label":"Background","metadata":{},"score":"62.417313"}{"text":"Most importantly , tutors give and receive additional linguistic cues during the lesson about how the dialogue is progressing .The cues received by the one - on - one tutor give the tutor information about the student 's understanding of the material and allow the tutor to determine when a tutoring strategy is working or is not working .","label":"Background","metadata":{},"score":"62.44087"}{"text":"The next wave of innovation in the space is improving the process for the content creation and improving the ease and effectiveness of student interaction .The critical need to improve content is to provide the right kinds of tools for building learning environments that are easier to deploy and easier to use .","label":"Background","metadata":{},"score":"62.453743"}{"text":"Similarly , for the semantic utterance representation candidate No . 2 , first at the step S113 , the inference of the unspecified parts is made .In this example , however , there is no unspecified parts in the semantic utterance representation candidate No . 2 , so that the inference is actually not made and the process proceeds to the next step S114 .","label":"Background","metadata":{},"score":"62.46535"}{"text":"Similarly , for the semantic utterance representation candidate No . 2 , first at the step S113 , the inference of the unspecified parts is made .In this example , however , there is no unspecified parts in the semantic utterance representation candidate No . 2 , so that the inference is actually not made and the process proceeds to the next step S114 .","label":"Background","metadata":{},"score":"62.46535"}{"text":"Similarly , for the semantic utterance representation candidate No . 2 , first at the step S113 , the inference of the unspecified parts is made .In this example , however , there is no unspecified parts in the semantic utterance representation candidate No . 2 , so that the inference is actually not made and the process proceeds to the next step S114 .","label":"Background","metadata":{},"score":"62.46535"}{"text":"Similarly , for the semantic utterance representation candidate No . 2 , first at the step S113 , the inference of the unspecified parts is made .In this example , however , there is no unspecified parts in the semantic utterance representation candidate No . 2 , so that the inference is actually not made and the process proceeds to the next step S114 .","label":"Background","metadata":{},"score":"62.46535"}{"text":"We will compare patterns of syllabification , stress and tone placement across languages .We will also consider psycholinguistic findings about the role of prosody in speech processing and language acquisition .Grading Policy .The grade will be based on homework assignments ( roughly one a week ) , and a test at the end of each of the two sections .","label":"Background","metadata":{},"score":"62.47877"}{"text":"Now , in order to realize a natural and efficient dialogue with a human speaker , it is important for the speech dialogue system to be capable of conveying as much information on the state of the computer as possible to the human speaker .","label":"Background","metadata":{},"score":"62.50781"}{"text":"Now , in order to realize a natural and efficient dialogue with a human speaker , it is important for the speech dialogue system to be capable of conveying as much information on the state of the computer as possible to the human speaker .","label":"Background","metadata":{},"score":"62.50781"}{"text":"Now , in order to realize a natural and efficient dialogue with a human speaker , it is important for the speech dialogue system to be capable of conveying as much information on the state of the computer as possible to the human speaker .","label":"Background","metadata":{},"score":"62.50781"}{"text":"Now , in order to realize a natural and efficient dialogue with a human speaker , it is important for the speech dialogue system to be capable of conveying as much information on the state of the computer as possible to the human speaker .","label":"Background","metadata":{},"score":"62.50781"}{"text":"Routine events such as declination , different phonetic duration , amplitudes and energy levels would be regularized ; the affective and discursive functions of prosodic variation would be foreground visuals .Prosodic Font would encode only the novel aspects of speech , the pure paralinguistic song and rhythm .","label":"Background","metadata":{},"score":"62.52099"}{"text":"899 - 916 .Ortiz , C. L. and Grosz , B. , Interpreting Information Requests in Context : A Collaborative Web Interface for Distance Learning .To appear , Autonomous Agents and Multi - Agent Systems , 2002 .Pfundt , H. & Duit , R. ( 1991 ) .","label":"Background","metadata":{},"score":"62.539505"}{"text":"This enables the speech center 20 to easily compose calls to respective application operations and invoke them .The script engine 38 environment also allows the definition of new subroutines and functions that combine the primitive functionality provided by applications 26 into actions that more closely correspond to those that a user might talk about .","label":"Background","metadata":{},"score":"62.569206"}{"text":"The method of claim 21 , wherein said outputting step outputs said speech response and said visual response by controlling at least one of an output order , an output timing , and a visual response output position .The method of claim 21 , further comprising the step of detecting a physical state of said user , and wherein said making step makes said semantic content determination of said response output by taking said physical state of said user detected at said detecting step into account .","label":"Background","metadata":{},"score":"62.62607"}{"text":"The method of claim 21 , wherein said outputting step outputs said speech response and said visual response by controlling at least one of an output order , an output timing , and a visual response output position .The method of claim 21 , further comprising the step of detecting a physical state of said user , and wherein said making step makes said semantic content determination of said response output by taking said physical state of said user detected at said detecting step into account .","label":"Background","metadata":{},"score":"62.62607"}{"text":"New operations can be added to the speech center 20 by providing a definition of the function , and a set of domain model rules that describe the prerequisites and effects of the operation .[0058 ] .By providing the speech center system 20 with what is in effect \" machine readable documentation \" on its functions , the speech center 20 can choose which functions to call in order to achieve its goals .","label":"Background","metadata":{},"score":"62.634983"}{"text":"output means for outputting to said user said speech response and said visual response generated by said response generation means .The speech dialogue system of claim 1 , wherein said response generation means generates said visual response which includes an image of a human character delivering said speech response , text data of said speech response , and a content visualizing image of a content of said speech response .","label":"Background","metadata":{},"score":"62.645393"}{"text":"Plutchik , R. , The Psychology and Biology of Emotion , Harper Collins , New York 1994 .Russell , J. A. , How shall an Emotion be called , in R. Plutchik & H. Conte ( editors ) , Circumplex Models of Personality and Emotion , Washington , APA , 1997 .","label":"Background","metadata":{},"score":"62.647133"}{"text":"In step 106 , semantics analysis module 50 processes the recognized spoken utterance 15 using a grammatic specification 90 based on the domain model 70 to produce an initial semantic representation based on the recognized spoken utterance 15 .For example , the semantics analysis module 50 produces a frame structure based on the recognized spoken utterance 15 .","label":"Background","metadata":{},"score":"62.671165"}{"text":"The semantically segmented and prosodically annotated text 1500 is used to determine predictive models of discourse .The predictive models of discourse are used to generate output information 1600 including updated automatic speech recognition models 1610 and/or text to speech models 1620 that associate the prosodic features at the discourse function level .","label":"Background","metadata":{},"score":"62.685795"}{"text":"Example One : \" Oh wow she placed wow that 's amazing .\" 3 seconds .Example Two : \" I 'm not working for my own education here .\" 4 seconds .The study showed that people can correctly match Prosodic Font systematic graphical variation with speech audio that demonstrates similar variation .","label":"Background","metadata":{},"score":"62.823883"}{"text":"If the processing approach is based on a statistical approach , then the speech - enabled application will not recognize words that are not included in the sample of phrases that was used for the statistical analysis .In general , many conventional approaches are based on lists of words or phrases that are limited because no interpretation or meaning ( i.e. , semantics ) is associated with them .","label":"Background","metadata":{},"score":"62.87586"}{"text":"Because the feature sets are identical , prosody and affect are at least intimately related , if not dependent ; and many have suggested that prosody is primarily an instrument of affect ( e.g. , Bolinger , 1989 ) .It remains a mystery whether people recognize emotions categorically or in dimensional vector space .","label":"Background","metadata":{},"score":"62.89559"}{"text":"Then , the dialogue management unit maintains the state # 0 and the operation proceeds to a next operation timing .When the speech act is \" yes \" at the step S287 , next at the step S288 , the ordered content is registered into the order table a he transition he state # 2 is made and the operation proceeds to a next operation timing .","label":"Background","metadata":{},"score":"62.911095"}{"text":"Then , the dialogue management unit maintains the state # 0 and the operation proceeds to a next operation timing .When the speech act is \" yes \" at the step S287 , next at the step S288 , the ordered content is registered into the order table a he transition he state # 2 is made and the operation proceeds to a next operation timing .","label":"Background","metadata":{},"score":"62.911095"}{"text":"FIG .18 is an illustration of an example of a semantic response representation supplied from the dialogue management unit to the response generation unit in the speech dialogue system of FIG .1 .FIG .19 is a detailed block diagram of a response generation unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"62.94236"}{"text":"FIG .18 is an illustration of an example of a semantic response representation supplied from the dialogue management unit to the response generation unit in the speech dialogue system of FIG .1 .FIG .19 is a detailed block diagram of a response generation unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"62.94236"}{"text":"FIG .18 is an illustration of an example of a semantic response representation supplied from the dialogue management unit to the response generation unit in the speech dialogue system of FIG .1 .FIG .19 is a detailed block diagram of a response generation unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"62.94236"}{"text":"FIG .18 is an illustration of an example of a semantic response representation supplied from the dialogue management unit to the response generation unit in the speech dialogue system of FIG .1 .FIG .19 is a detailed block diagram of a response generation unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"62.94236"}{"text":"[ 0032 ] .Systems employing the present invention can also use the emotion state to formulate a response by an interactive agent in a real - time natural language processing system .These interactive agents are found online , as well as in advanced interactive voice response systems which communicate over conventional phone lines with assistance from voice browsers , VXML formatted documents , etc .","label":"Background","metadata":{},"score":"62.943707"}{"text":"This content visualizing image generation unit 136 can generates the desired content visualizing image similarly to the human character image generation unit 132 by incorporating the appropriate control of the display time and the temporal change of the visual image .Thus , in a case of using the still pictures , a plurality of content visualizing images to be displayed successively are prepared in advance , while in a case of using the animated picture , the animated picture realizing the appropriate content visualizing image is prepared in advance .","label":"Background","metadata":{},"score":"62.977196"}{"text":"This content visualizing image generation unit 136 can generates the desired content visualizing image similarly to the human character image generation unit 132 by incorporating the appropriate control of the display time and the temporal change of the visual image .Thus , in a case of using the still pictures , a plurality of content visualizing images to be displayed successively are prepared in advance , while in a case of using the animated picture , the animated picture realizing the appropriate content visualizing image is prepared in advance .","label":"Background","metadata":{},"score":"62.977196"}{"text":"This content visualizing image generation unit 136 can generates the desired content visualizing image similarly to the human character image generation unit 132 by incorporating the appropriate control of the display time and the temporal change of the visual image .Thus , in a case of using the still pictures , a plurality of content visualizing images to be displayed successively are prepared in advance , while in a case of using the animated picture , the animated picture realizing the appropriate content visualizing image is prepared in advance .","label":"Background","metadata":{},"score":"62.977196"}{"text":"This content visualizing image generation unit 136 can generates the desired content visualizing image similarly to the human character image generation unit 132 by incorporating the appropriate control of the display time and the temporal change of the visual image .Thus , in a case of using the still pictures , a plurality of content visualizing images to be displayed successively are prepared in advance , while in a case of using the animated picture , the animated picture realizing the appropriate content visualizing image is prepared in advance .","label":"Background","metadata":{},"score":"62.977196"}{"text":"In this regard , the joyful smiling facial expression of the human character image is very important to relax the tension on the user side , and it is further preferable to use the synthesized voice with the cheerful intonation for the initial greeting speech response .","label":"Background","metadata":{},"score":"63.053093"}{"text":"In this regard , the joyful smiling facial expression of the human character image is very important to relax the tension on the user side , and it is further preferable to use the synthesized voice with the cheerful intonation for the initial greeting speech response .","label":"Background","metadata":{},"score":"63.053093"}{"text":"In this regard , the joyful smiling facial expression of the human character image is very important to relax the tension on the user side , and it is further preferable to use the synthesized voice with the cheerful intonation for the initial greeting speech response .","label":"Background","metadata":{},"score":"63.053093"}{"text":"In this regard , the joyful smiling facial expression of the human character image is very important to relax the tension on the user side , and it is further preferable to use the synthesized voice with the cheerful intonation for the initial greeting speech response .","label":"Background","metadata":{},"score":"63.053093"}{"text":"On the other hand , the order table registered in the ORDER TABLE frame indicates the content of the order in a form of an order list having slots for ordered items , ordered sizes , and ordered quantities .In addition , at the keyword spotter 21b , the user 's speech speed is measured according to the spotted keywords and their start and end points .","label":"Background","metadata":{},"score":"63.06524"}{"text":"On the other hand , the order table registered in the ORDER TABLE frame indicates the content of the order in a form of an order list having slots for ordered items , ordered sizes , and ordered quantities .In addition , at the keyword spotter 21b , the user 's speech speed is measured according to the spotted keywords and their start and end points .","label":"Background","metadata":{},"score":"63.06524"}{"text":"On the other hand , the order table registered in the ORDER TABLE frame indicates the content of the order in a form of an order list having slots for ordered items , ordered sizes , and ordered quantities .In addition , at the keyword spotter 21b , the user 's speech speed is measured according to the spotted keywords and their start and end points .","label":"Background","metadata":{},"score":"63.06524"}{"text":"On the other hand , the order table registered in the ORDER TABLE frame indicates the content of the order in a form of an order list having slots for ordered items , ordered sizes , and ordered quantities .In addition , at the keyword spotter 21b , the user 's speech speed is measured according to the spotted keywords and their start and end points .","label":"Background","metadata":{},"score":"63.06524"}{"text":"All students will be evaluated on their oral presentation skills and contributions to the group .For junior students , a primary goal of the course is to help them develop their research as soon as possible .Students in this group who are taking the course for the first time will work on a research project tailored to their specific needs ( for example , a study design , an IRB proposal ) .","label":"Background","metadata":{},"score":"63.071117"}{"text":"[0099 ] .The architecture will be tailored for the special requirements of the tutoring domain with a dialog manager that enables smooth and robust conversational dialogs between the student and tutor , while allowing for better understanding of the student during the student - system dialog .","label":"Background","metadata":{},"score":"63.073334"}{"text":"12C in response to this confirmation message , the speech understanding unit 11 obtains two semantic utterance representation candidates No . 1 and No . 2 shown in FIG .12D and FIG .12E by carrying out the keyword detection and the keyword lattice parsing as described above .","label":"Background","metadata":{},"score":"63.082508"}{"text":"12C in response to this confirmation message , the speech understanding unit 11 obtains two semantic utterance representation candidates No . 1 and No . 2 shown in FIG .12D and FIG .12E by carrying out the keyword detection and the keyword lattice parsing as described above .","label":"Background","metadata":{},"score":"63.082508"}{"text":"12C in response to this confirmation message , the speech understanding unit 11 obtains two semantic utterance representation candidates No . 1 and No . 2 shown in FIG .12D and FIG .12E by carrying out the keyword detection and the keyword lattice parsing as described above .","label":"Background","metadata":{},"score":"63.082508"}{"text":"12C in response to this confirmation message , the speech understanding unit 11 obtains two semantic utterance representation candidates No . 1 and No . 2 shown in FIG .12D and FIG .12E by carrying out the keyword detection and the keyword lattice parsing as described above .","label":"Background","metadata":{},"score":"63.082508"}{"text":"0166 ] .The following describes the steps that will be followed as we assemble and run the community of OAA agents for speech recognition , emotion detection and natural language functions : . [ 0167 ] .We expect that by fully achieving the goals in the objectives as described above , we will have laid a solid foundation going into Phase 2 .","label":"Background","metadata":{},"score":"63.092308"}{"text":"By using the ToBI annotation , one is able to derive the intonational events in speech from the human perception of speech intonation .Kappa statistics are then used to evaluate the consistency between the annotators .Again any number of statistical approaches may be employed instead .","label":"Background","metadata":{},"score":"63.127674"}{"text":"It serves the purpose of permitting the reconstruction of a stylized F0 track , while eliminating the F0 anomalies associated with many phonetic events .Prosodic Font is then free to define average font size , starting positions , weighting , etc . based upon F0 averages .","label":"Background","metadata":{},"score":"63.133247"}{"text":"Response Generator - produces the appropriate system replies using the information from the database .Speech Synthesis - constructs the acoustic form of the system replies produced by the response generator .[0126 ] .The dialogue manager is the key component in dialog systems .","label":"Background","metadata":{},"score":"63.1368"}{"text":"ABSTRACT .The advent of automated speech recognition opens up new possibilities for design of new typographic forms .Graphic designers have long been designing text to evoke the sound of a voice saying the words .Some have even used sound to animate word units within a computational environment .","label":"Background","metadata":{},"score":"63.148132"}{"text":"This model would allow any prosodic font message sent by the speaker to have a visual context created for the message , enabling readers to see what the speaker 's voice \" looks \" like normally .This would also enable a prosody recognizer to detect affective changes in the voice and change color schemes , font styles , and background .","label":"Background","metadata":{},"score":"63.15354"}{"text":"It is to be noted that the Fundamental frequency pattern may be controlled differently from that shown in FIG .26 by using other known methods such as a method using a linear approximation or a method using a pitch level for expressing the fundamental frequency pattern .","label":"Background","metadata":{},"score":"63.183296"}{"text":"It is to be noted that the fundamental frequency pattern may be controlled differently from that shown in FIG .26 by using other known methods such as a method using a linear approximation or a method using a pitch level for expressing the fundamental frequency pattern .","label":"Background","metadata":{},"score":"63.183296"}{"text":"It is to be noted that the fundamental frequency pattern may be controlled differently from that shown in FIG .26 by using other known methods such as a method using a linear approximation or a method using a pitch level for expressing the fundamental frequency pattern .","label":"Background","metadata":{},"score":"63.183296"}{"text":"It is to be noted that the Fundamental frequency pattern may be controlled differently from that shown in FIG .26 by using other known methods such as a method using a linear approximation or a method using a pitch level for expressing the fundamental frequency pattern .","label":"Background","metadata":{},"score":"63.183296"}{"text":"For example , the prosodic features associated with discourse functions in a training corpus are determined .The discourse functions may be determined based on a theory of discourse analysis .A predictive model of discourse functions is then determined .The prosodic features are accepted by the predictive model of discourse functions which outputs a prediction of the discourse function likely associated with the speech utterance .","label":"Background","metadata":{},"score":"63.2044"}{"text":"[ 0000 ] .Extraction of Acoustic Features .[ 0142 ] .In addition to the segmentally time - stamped transcript of the dialog provided with the corpus or provided in live usage by the speech recognizer , we will extract the following primary acoustic features - pitch , duration and energy .","label":"Background","metadata":{},"score":"63.233994"}{"text":"Training of the prosody analyzer with real world expected responses improves emotion modeling and the real - time identification of potential features such as emphasis , intent , attitude and semantic meaning in the speaker 's utterances .extracting prosodic features from the utterance to generate extracted prosodic data ; transferring said extracted prosodic data with said extracted acoustic feature data to the server device ; . recognizing an emotion state of a speaker of the utterance based on at least said extracted prosodic data ; . wherein operations associated with recognition of prosodic features in the utterance are also distributed across the client device and server device .","label":"Background","metadata":{},"score":"63.24245"}{"text":"S 2 : The characters or character strings desired to correct their prosodic features are specified and the corresponding prosodic feature control commands are input and inserted in the text .S 3 : The text and the prosodic feature control commands are both input into a text / command separating part 12 , wherein they are separated from each other .","label":"Background","metadata":{},"score":"63.252563"}{"text":"The emotion states described in the table above can be extended to include other emotion states .[ 0000 ] .Feature Extraction .[ 0064 ] .Acoustic features are extracted by a routine shown as 220 .Before the initiation of the feature extraction process , the speech samples are preferably re - sampled at a 44 kHz sampling rate to ensure higher fidelity speech sample and higher quality source data for the speech feature extraction tools .","label":"Background","metadata":{},"score":"63.254147"}{"text":"The method of claim 25 , wherein said generating step generates said speech response incorporating a speech characteristic corresponding to said movement and said facial expression of said human character .The method of claim 26 , wherein said speech characteristic of said speech response includes at least one of an emotional expression and an intonation .","label":"Background","metadata":{},"score":"63.26094"}{"text":"The method of claim 25 , wherein said generating step generates said speech response incorporating a speech characteristic corresponding to said movement and said facial expression of said human character .The method of claim 26 , wherein said speech characteristic of said speech response includes at least one of an emotional expression and an intonation .","label":"Background","metadata":{},"score":"63.26094"}{"text":"Experimenting with different levels of visual persistence within RSVP , movement of the word emanation point on the screen , spatially linear layout and three dimension presentations would begin to address the variety of design potentials .Designing with a time - based medium adds an entirely new repertoire to the field of design .","label":"Background","metadata":{},"score":"63.283463"}{"text":"No .6,165,172 .[ 0084 ] .In a distributed environment , the prosodic data is also preferably sent in a packet stream , which may or may not also include the extracted acoustic feature data for a speech recognition process , i.e. , such as cepstral coefficients .","label":"Background","metadata":{},"score":"63.29052"}{"text":"In a further aspect , the grammatic specification is a Backus Naur Form grammar .[ 0016 ] .The initial semantic representation , in another aspect is based on a frame structure representing the recognized spoken utterance .BRIEF DESCRIPTION OF THE DRAWINGS .","label":"Background","metadata":{},"score":"63.32688"}{"text":"[ 0088 ] .If the next generation of computer - based training systems with spoken language interfaces is going to be successful , they must also provide a comfortable , satisfying and user - friendly environment .This project helps to approach the important goal of improving user experience so that the student experiences a satisfying , effective and enjoyable tutoring session comparable to that offered by one - on - one human tutors .","label":"Background","metadata":{},"score":"63.376648"}{"text":"It is to be noted that the other known types of the speech waveform generator may be used instead of that shown in FIG .29 .The content visualizing image generation unit 136 generates the content visualizing image visualizing the essential content of the speech response is provided for supporting the smooth comprehension of the system response by the user .","label":"Background","metadata":{},"score":"63.411545"}{"text":"It is to be noted that the other known types of the speech waveform generator may be used instead of that shown in FIG .29 .The content visualizing image generation unit 136 generates the content visualizing image visualizing the essential content of the speech response is provided for supporting the smooth comprehension of the system response by the user .","label":"Background","metadata":{},"score":"63.411545"}{"text":"It is to be noted that the other known types of the speech waveform generator may be used instead of that shown in FIG .29 .The content visualizing image generation unit 136 generates the content visualizing image visualizing the essential content of the speech response is provided for supporting the smooth comprehension of the system response by the user .","label":"Background","metadata":{},"score":"63.411545"}{"text":"It is to be noted that the other known types of the speech waveform generator may be used instead of that shown in FIG .29 .The content visualizing image generation unit 136 generates the content visualizing image visualizing the essential content of the speech response is provided for supporting the smooth comprehension of the system response by the user .","label":"Background","metadata":{},"score":"63.411545"}{"text":"To facilitate the successful outcome of the objective , the research will be broken out into the following four key sections : .Preparation of the corpus .Extraction of the acoustic correlates from which prosodic cues can be derived .Classification of the acoustic correlates using machine learning algorithms & verification with the manually annotated corpus .","label":"Background","metadata":{},"score":"63.42857"}{"text":"Scherer believes this confusion would be mitigated with contextual features ( 1981 ) .Because the voice is a vehicle of emotional expression with measurable - and often continuous - vocal characteristics , a prosodic font can use these continuous vocal measurements in the design of temporal typographic forms .","label":"Background","metadata":{},"score":"63.445793"}{"text":"The exemplary prosodic features associated with each type of discourse function are determined .Machine learning , observation and the like are used to determine a subset of prosodic features associated with each type of discourse function useful in predicting the likelihood of each type of discourse function .","label":"Background","metadata":{},"score":"63.44819"}{"text":"Pitch frequency fluctuations can be represented by the character size .The symbols \" . \" and \" - \" can be changed or modified at user 's request .Incidentally , when the Japanese text is fed intact into the character conversion part 26 , such a display as depicted in FIG .","label":"Background","metadata":{},"score":"63.45662"}{"text":"The \" 80 \" value indicates the boundary tone associated with the training instance speech utterance .The second row of the exemplary data structure for storing speech utterance prosody information 1070 contains a value of \" 2 \" in the identifier portion 1010 .","label":"Background","metadata":{},"score":"63.46444"}{"text":"Here , the information on the ordered quantities may be incorporated into the pictures of the ordered items such that the content visualizing image contains as many number of each ordered item as the ordered quantity .Also , for this reason , each numerical figure is displayed at the same level as the pictures of the corresponding ordered item .","label":"Background","metadata":{},"score":"63.48523"}{"text":"Here , the information on the ordered quantities may be incorporated into the pictures of the ordered items such that the content visualizing image contains as many number of each ordered item as the ordered quantity .Also , for this reason , each numerical figure is displayed at the same level as the pictures of the corresponding ordered item .","label":"Background","metadata":{},"score":"63.48523"}{"text":"Here , the information on the ordered quantities may be incorporated into the pictures of the ordered items such that the content visualizing image contains as many number of each ordered item as the ordered quantity .Also , for this reason , each numerical figure is displayed at the same level as the pictures of the corresponding ordered item .","label":"Background","metadata":{},"score":"63.48523"}{"text":"Here , the information on the ordered quantities may be incorporated into the pictures of the ordered items such that the content visualizing image contains as many number of each ordered item as the ordered quantity .Also , for this reason , each numerical figure is displayed at the same level as the pictures of the corresponding ordered item .","label":"Background","metadata":{},"score":"63.48523"}{"text":"[ 0018 ] .[ 0018]FIG .1 is a block diagram of a preferred embodiment in a computer system .[ 0019 ] .[ 0019]FIG .2 is a block diagram of the components of the speech center system illustrated in FIG .","label":"Background","metadata":{},"score":"63.503742"}{"text":"FIG .16 is an illustration of a table summarizing system responses for various cases in the speech dialogue system of FIG .1 . FIG .17 is an illustration of an input speech signal for explaining a determination of an input speech speed in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"63.50675"}{"text":"FIG .16 is an illustration of a table summarizing system responses for various cases in the speech dialogue system of FIG .1 . FIG .17 is an illustration of an input speech signal for explaining a determination of an input speech speed in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"63.50675"}{"text":"Recently , researchers have demonstrated that spoken language interfaces , with semantic understanding , can be implemented with computer - based tutoring systems .Furthermore , the prosodic information contained in speech can be extracted automatically and used to assist the computer in guiding the tutoring dialog .","label":"Background","metadata":{},"score":"63.513435"}{"text":"The method of claim 21 , wherein the outputting step also outputs a visual indication for informing the user as to whether the speech dialogue system is ready to receive the input speech .The method of claim 21 , wherein the generating step generates the visual response which includes a content visualizing image formed by pictures of objects mentioned in the speech response and a numerical figure indicating a quantity of each of the objects .","label":"Background","metadata":{},"score":"63.54465"}{"text":"The method of claim 21 , wherein the outputting step also outputs a visual indication for informing the user as to whether the speech dialogue system is ready to receive the input speech .The method of claim 21 , wherein the generating step generates the visual response which includes a content visualizing image formed by pictures of objects mentioned in the speech response and a numerical figure indicating a quantity of each of the objects .","label":"Background","metadata":{},"score":"63.54465"}{"text":"FIG .20 is an illustration of an example of a human character image information to be used in the response generation unit of FIG .19 .FIG .21 is an illustration of examples of a response sentence structure to be used in a response sentence generation unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"63.561325"}{"text":"FIG .20 is an illustration of an example of a human character image information to be used in the response generation unit of FIG .19 .FIG .21 is an illustration of examples of a response sentence structure to be used in a response sentence generation unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"63.561325"}{"text":"FIG .20 is an illustration of an example of a human character image information to be used in the response generation unit of FIG .19 .FIG .21 is an illustration of examples of a response sentence structure to be used in a response sentence generation unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"63.561325"}{"text":"FIG .20 is an illustration of an example of a human character image information to be used in the response generation unit of FIG .19 .FIG .21 is an illustration of examples of a response sentence structure to be used in a response sentence generation unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"63.561325"}{"text":"Clearly there is a substantial opportunity for a company focused on speech recognition and intelligent learning in both the corporate and wider educational e - Learning business .[ 0000 ] .The Product .[0181 ] .The focus of our investigation is to implement an ITS architecture which addresses the issue of student understanding , so as to raise the level of performance by 1 to 2 standard deviation units .","label":"Background","metadata":{},"score":"63.580727"}{"text":"Third Embodiment .Now , a description will be given below of an example of a display of the prosodic feature pattern of the text controlled by the commands , and a configuration for producing the display .First , experimental results concerning the prosodic feature of the utterance duration will be described .","label":"Background","metadata":{},"score":"63.58613"}{"text":"Compared to the richness of speech , writing is a meager system .A speaker uses stress , pitch , rate , pauses , voice qualities , and a host of other sound patterns not even vaguely defined to communicate a message as well as attitudes and feelings about what he is saying .","label":"Background","metadata":{},"score":"63.626884"}{"text":"However , based on the additional prosodic information , the predictive discourse function model predicts the likelihood that the recognized speech reflects a command discourse function .Thus , additional systems ( not shown ) may be used to determine that the recognized speech reflects a request to record subsequent information into the body of an email message .","label":"Background","metadata":{},"score":"63.646267"}{"text":"0017 ] .The foregoing and other objects , features and advantages of the invention will be apparent from the following more particular description of preferred embodiments of the invention , as illustrated in the accompanying drawings in which like reference characters refer to the same parts throughout the different views .","label":"Background","metadata":{},"score":"63.649635"}{"text":"Other well - known approaches can also be used of course , and may vary from application to application .Referring to .FIG .2 , the extracted acoustic features ( as described in a following section Prosody Analysis , are extracted in 220 .","label":"Background","metadata":{},"score":"63.67537"}{"text":"Ishizaki articulated a descriptive theory of temporal form - how the interaction of visual elements over time may be conceptualized- and demonstrated this theory with a multi - agent system that designs continuous visual solutions ( 1996 ) .Ishizaki and his students at Carnegie Mellon University designed temporal typography with the stated intent of representing affective vocal prosody ( 1997 ) .","label":"Background","metadata":{},"score":"63.697266"}{"text":"[ 0020]FIG .3 is a block diagram of the components of the conversation manager illustrated in FIG .2 . [ 0021 ] .[ 0021]FIG .4 is a block diagram of a domain model and grammatic specification for a preferred embodiment .","label":"Background","metadata":{},"score":"63.702515"}{"text":"The method of claim 37 , wherein said simplified speech response contains a demonstrative pronoun to refer to said visual response .The method of claim 33 , wherein at said outputting step , said visual response is outputted at an earlier timing than a timing for outputting said visual response when said speech response is said full speech response .","label":"Background","metadata":{},"score":"63.715508"}{"text":"The method of claim 37 , wherein said simplified speech response contains a demonstrative pronoun to refer to said visual response .The method of claim 33 , wherein at said outputting step , said visual response is outputted at an earlier timing than a timing for outputting said visual response when said speech response is said full speech response .","label":"Background","metadata":{},"score":"63.715508"}{"text":"Prosodic Font would play on top of this graphical box .Graphically , it appears that the voice emanates from the alignment parameter given the Prosodic Font .For example , the examples made for the user tests were left aligned on the screen ; hence , it appeared that the voice was speaking from the point of left alignment .","label":"Background","metadata":{},"score":"63.725765"}{"text":"In this second embodiment , the user detection mechanism using a floor mat will be described as an example .These semantic user state representations No . 1 and No . 2 are supplied to the dialogue management unit 234 .Now , the operation of this speech dialogue system of the second embodiment proceeds as follows .","label":"Background","metadata":{},"score":"63.731495"}{"text":"In this second embodiment , the user detection mechanism using a floor mat will be described as an example .These semantic user state representations No . 1 and No . 2 are supplied to the dialogue management unit 234 .Now , the operation of this speech dialogue system of the second embodiment proceeds as follows .","label":"Background","metadata":{},"score":"63.731495"}{"text":"In this second embodiment , the user detection mechanism using a floor mat will be described as an example .These semantic user state representations No . 1 and No . 2 are supplied to the dialogue management unit 234 .Now , the operation of this speech dialogue system of the second embodiment proceeds as follows .","label":"Background","metadata":{},"score":"63.731495"}{"text":"In this second embodiment , the user detection mechanism using a floor mat will be described as an example .These semantic user state representations No . 1 and No . 2 are supplied to the dialogue management unit 234 .Now , the operation of this speech dialogue system of the second embodiment proceeds as follows .","label":"Background","metadata":{},"score":"63.731495"}{"text":"It is also to be noted that such an indication may also incorporate any other visual features related to the aspects of colors , luminances , and concentrations , which can be utilized in catching the user 's attention .As a consequence , the problem of the incomplete speech recognition due to the errors and ambiguity associated with the speech recognition in the speech dialogue system can be compensated effectively by the smooth dialogue between the system and the user .","label":"Background","metadata":{},"score":"63.749718"}{"text":"The reasoning facility 52 is primarily concerned with the determination of how to achieve the goals derived from the user 's questions and commands .[ 0092 ] .Conversational speech is full of implicit and explicit references back to people and objects that were mentioned earlier .","label":"Background","metadata":{},"score":"63.757576"}{"text":"Please make your order . \" , while the same speech response is outputted from the loudspeaker unit 15 in the synthesized voice .This state corresponds to the initial system state S0 in the state transition diagram of FIG .9 described above .","label":"Background","metadata":{},"score":"63.79042"}{"text":"Please make your order . \" , while the same speech response is outputted from the loudspeaker unit 15 in the synthesized voice .This state corresponds to the initial system state S0 in the state transition diagram of FIG .9 described above .","label":"Background","metadata":{},"score":"63.79042"}{"text":"Please make your order . \" , while the same speech response is outputted from the loudspeaker unit 15 in the synthesized voice .This state corresponds to the initial system state S0 in the state transition diagram of FIG .9 described above .","label":"Background","metadata":{},"score":"63.79042"}{"text":"Please make your order . \" , while the same speech response is outputted from the loudspeaker unit 15 in the synthesized voice .This state corresponds to the initial system state S0 in the state transition diagram of FIG .9 described above .","label":"Background","metadata":{},"score":"63.79042"}{"text":"On the other hand , it is impossible for the user to guess how the pitch or duration will affect the communication of information or nuances of speech unless he has knowledge about speech synthesis or a text - to - speech synthesizer .","label":"Background","metadata":{},"score":"63.796093"}{"text":"( Another way of describing this difference is low to mid - level descriptions versus high - level descriptions . )Linear versus Layered Descriptions : those who believe that prosody is constructed of a linear sequence of events versus those who believe that prosody consists of layers of signals of greater or lesser range which interact to produce a composite effect .","label":"Background","metadata":{},"score":"63.824364"}{"text":"The attached Appendix is taken from Applicant 's provisional application referenced above .APPENDIX .[ 0000 ] .Part 1 : Identification and Significance of the Innovation .[ 0000 ] .Introduction .[ 0087 ] .This project will yield a computer - based spoken language training system that will begin to approximate the benefits provided by a one - on - one tutor - student session .","label":"Background","metadata":{},"score":"63.8377"}{"text":"[ 0038 ] .In a conventional approach , all applications 26 have an implicit model of the world that they represent .This implicit model guides the design of the user interface and the functionality of the program .The problem with an implicit model is that it is all in the mind of the designers and developers , and so is often not thoroughly or consistently implemented in the product .","label":"Background","metadata":{},"score":"63.89041"}{"text":"3 .This diagram illustrates the functional dependencies between the various blocks and the message interfaces between them .[0130 ] .This community of agents will be required for the full implementation of the ITS ( Version 1.0 ) to be completed in Phase II .","label":"Background","metadata":{},"score":"63.9748"}{"text":"In step 108 , the syntax manager 62 provides an utterance representation that represents the recognized spoken utterance 15 based on the initial semantic representation and the domain model 70 .For example , the syntax manager 62 provides a set of propositions based on the frame structure produced by the semantics analysis module 50 from the recognized spoken utterance 15 .","label":"Background","metadata":{},"score":"64.01987"}{"text":"They identify a simple two - way ( emotion / non - emotion ) and three - way classification schemes ( negative / neutral / positive ) .Additionally , other researchers [ Holzapfel et al , 2002 ] have also explored the use of emotions for dialog management strategies that assist in minimizing the misunderstanding of the user and thus improve user acceptance .","label":"Background","metadata":{},"score":"64.04414"}{"text":"Then , at the step S122 , the semantic response representation for outputting a confirmation message for this addition is obtained by selecting an appropriate response act to be registered in the ACT frame from the response act list shown in FIG . 15B.","label":"Background","metadata":{},"score":"64.045204"}{"text":"Then , at the step S122 , the semantic response representation for outputting a confirmation message for this addition is obtained by selecting an appropriate response act to be registered in the ACT frame from the response act list shown in FIG . 15B.","label":"Background","metadata":{},"score":"64.045204"}{"text":"Then , at the step S122 , the semantic response representation for outputting a confirmation message for this addition is obtained by selecting an appropriate response act to be registered in the ACT frame from the response act list shown in FIG . 15B.","label":"Background","metadata":{},"score":"64.045204"}{"text":"Then , at the step S122 , the semantic response representation for outputting a confirmation message for this addition is obtained by selecting an appropriate response act to be registered in the ACT frame from the response act list shown in FIG . 15B.","label":"Background","metadata":{},"score":"64.045204"}{"text":"response output means for outputting a system response according to the detected keywords , the system response being generated in accordance with a prescribed rule corresponding to each of the keywords .Description .This is a continuation of application Ser .","label":"Background","metadata":{},"score":"64.047"}{"text":"The present invention may be used in a speech center system that is further empowered by this model by explicitly representing the available script functions , their parameters , prerequisites , and effects .Rather than translating directly between utterance and action , the system then translates the spoken utterance into an internal representation that captures the meaning of the utterance , and then further processes the internal representation by matching and automated inference procedures .","label":"Background","metadata":{},"score":"64.07209"}{"text":"When the speech act is \" no \" at the step S289 , next at the step S290 , the semantic response representation for the reconfirmation of the ordered content is generated .Then , the dialogue management unit maintains the state # 0 and the operation proceeds to a next operation timing .","label":"Background","metadata":{},"score":"64.08179"}{"text":"When the speech act is \" no \" at the step S289 , next at the step S290 , the semantic response representation for the reconfirmation of the ordered content is generated .Then , the dialogue management unit maintains the state # 0 and the operation proceeds to a next operation timing .","label":"Background","metadata":{},"score":"64.08179"}{"text":"European Chapter Meeting of the ACL .Association for Computational Linguistics , Mo. .Shriberg , Elizabeth et al . , Can Prosody Aid the Automatic Classification of Dialog Acts in Conversational Speech , Language and Speech 41 ( 3 - 4 ) : 439 - 487 .","label":"Background","metadata":{},"score":"64.09509"}{"text":"Because the speech processing is broken up in this fashion , it is possible to achieve real - time , interactive , human - like dialog consisting of a large , controllable set of questions / answers .The assistance of the animated agent 157 further enhances the experience , making it mote natural and comfortable for even novice users .","label":"Background","metadata":{},"score":"64.1193"}{"text":"[ 0134 ] .To assess the effectiveness of the selected acoustic features for prosodic cue detection .[ 0135 ] .Para - linguistic states including emotion , attention , motivation , interest level , degree of comprehension , degree of interactivity , and responsiveness are integral determinants of prosodic aspects of human speech , and prosody is the important mechanism through which the speaker 's emotional and other states are expressed .","label":"Background","metadata":{},"score":"64.126656"}{"text":"Although there has been must research on reading perception ( Vygotsky , 1975 ; Gibson and Levin , 1975 ) , there has been no research on perception of glyphs that change shape over time .3.1.1 Perception of Glyph Balance and Proportion .","label":"Background","metadata":{},"score":"64.148636"}{"text":"Most people watched the Prosodic Font file two or three times consecutively , listened to each of the audio files , listened to each audio file again and watched the Prosodic Font file each time .After this procedure they would make a decision .","label":"Background","metadata":{},"score":"64.149315"}{"text":"On the other hand , [ @naki ] is an S - layer command for generating an utterance with a feeling of sorrow .A description will be given , with reference to FIG .10C , of an example of a display in the case where the description scheme or notation based on the above - mentioned experiments is applied to the description shown in FIG .","label":"Background","metadata":{},"score":"64.174774"}{"text":"A speech dialogue system capable of realizing natural and smooth dialogue between the system and a human user , and easy maneuverability of the system .Speech dialogue system for facilitating improved human - computer interaction US 5357596 A .Rsum .","label":"Background","metadata":{},"score":"64.18365"}{"text":"Also , the syntactic templates of the present invention are more abstract in nature , and thus changes to the syntactic templates propagate throughout the generated grammar .[ 0006 ] .To address these issues , the present invention provides a model of the domains that a speech center system is dealing with .","label":"Background","metadata":{},"score":"64.19494"}{"text":"The speech dialogue system of claim 1 , wherein the response generation means generates the visual response which includes an image of a human character delivering the speech response , where the image incorporates movement and facial expression of the human character .","label":"Background","metadata":{},"score":"64.208466"}{"text":"Further , more expressions could be added to synthetic speech by combining , as basic prosody control rules , modifications of the amplitude pattern ( the power pattern ) as well as the modifications of the pitch pattern and duration .By this , the desired expression ( non - verbal information ) can be added to the synthetic speech .","label":"Background","metadata":{},"score":"64.26258"}{"text":"FIG .16B is an illustration of a table summarizing system responses for various cases in the speech dialogue system of FIG .1 . FIG .17 is an illustration of an input speech signal for explaining a determination of an input speech speed in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"64.2861"}{"text":"FIG .16B is an illustration of a table summarizing system responses for various cases in the speech dialogue system of FIG .1 . FIG .17 is an illustration of an input speech signal for explaining a determination of an input speech speed in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"64.2861"}{"text":"Prosodic Font uses a combination of machine and human recognition techniques to create text descriptions of prosodic parameters from a sound corpus developed expressly for this thesis .The sound corpus is excerpted from two speakers - one male and one female - who are telling stories about four different emotional experiences .","label":"Background","metadata":{},"score":"64.33767"}{"text":"The TILT model is a refinement of the earlier RFC model ; as such , I will focus upon it alone .TILT is a phonetic model of intonation that classifies continuous signals as two types of events , a TILT event ( a numerical description of the closest Euclidean shape of the pitch accent curve ) , or a Connection event ( the period in between pitch accents ) .","label":"Background","metadata":{},"score":"64.37082"}{"text":"Attention , Intention , and the structure of discourse .Journal fo Computational Linguistics 12 , 175 - 204 .Grosz , B. & Hirschberg , J. ( 1992 ) .Some intonational characteristics of discourse structure .In Proceedings of the 1992 International Conference on Spoken Language Processing , Banff , Canada , 429 - 432 .","label":"Background","metadata":{},"score":"64.406235"}{"text":"And , in fact as we shall see later , vocal disturbances and so - called speech \" errors \" can be revealing of the speaker 's affective state .Hence , Prosodic Font should seek to convey these non - linguistic vocal sounds as well as the linguistic .","label":"Background","metadata":{},"score":"64.41321"}{"text":"According to the synthetic speech message editing / creating method and apparatus of the third embodiment of the present invention , the contents of manipulation ( editing ) can visually checked depending on how characters subjected to prosodic feature control operation ( editing ) are arranged - this permits more effective correcting operations .","label":"Background","metadata":{},"score":"64.41627"}{"text":"A speech dialogue system , comprising : . speech understanding means for understanding a semantic content of an input speech from a user by detecting keywords of said input speech ; . dialogue management means for limiting said keywords to be detected in said input speech in advance , according to a state of a dialogue between said user and said speech dialogue system ; and .","label":"Background","metadata":{},"score":"64.417244"}{"text":"A speech dialogue system , comprising : . speech understanding means for understanding a semantic content of an input speech from a user by detecting keywords of said input speech ; . dialogue management means for limiting said keywords to be detected in said input speech in advance , according to a state of a dialogue between said user and said speech dialogue system ; and .","label":"Background","metadata":{},"score":"64.417244"}{"text":"It is to be noted that the selective use of the different response sentence patterns may be made for the other aspects of the speech response such as the selective use of the polite response sentence pattern and the intimate response sentence pattern .","label":"Background","metadata":{},"score":"64.46562"}{"text":"It is to be noted that the selective use of the different response sentence patterns may be made for the other aspects of the speech response such as the selective use of the polite response sentence pattern and the intimate response sentence pattern .","label":"Background","metadata":{},"score":"64.46562"}{"text":"It is to be noted that the selective use of the different response sentence patterns may be made for the other aspects of the speech response such as the selective use of the polite response sentence pattern and the intimate response sentence pattern .","label":"Background","metadata":{},"score":"64.46562"}{"text":"It is to be noted that the selective use of the different response sentence patterns may be made for the other aspects of the speech response such as the selective use of the polite response sentence pattern and the intimate response sentence pattern .","label":"Background","metadata":{},"score":"64.46562"}{"text":"Additionally during Phase II , other tasks such as integrating an interface to the widely - used authoring tools , Authorware and Director , and testing the system using live subjects in real situations will be completed .[ 0000 ] .","label":"Background","metadata":{},"score":"64.52191"}{"text":"When the dialogue management unit 234 is in the state # 3 at the step S295 , next at the step S296 , the semantic response representation for the final salutation No . 2 of \" Thank you for coming .\" is generated and the transition to the state # 0 is made and the operation proceeds to a next operation timing .","label":"Background","metadata":{},"score":"64.52559"}{"text":"When the dialogue management unit 234 is in the state # 3 at the step S295 , next at the step S296 , the semantic response representation for the final salutation No . 2 of \" Thank you for coming .\" is generated and the transition to the state # 0 is made and the operation proceeds to a next operation timing .","label":"Background","metadata":{},"score":"64.52559"}{"text":"Are We Identifying Emotional Categories or Dimensions ?The feature sets for prosody and vocal emotion are largely identical .Picard identifies the physical signals that convey emotion vocally as \" ... frequency and timing , with secondary effects in its loudness and enunciation .","label":"Background","metadata":{},"score":"64.550186"}{"text":"Then the speech engine 22 outputs a recognized spoken utterance 15 as output to the speech center system 20 .In step 104 , the context manager 58 determines the context of the recognized utterance 15 .For example , the context manager 58 determines that the recognized utterance 15 is associated with the context of a specific external application 26 that the user has recently been accessing .","label":"Background","metadata":{},"score":"64.56088"}{"text":"Speech dialogue system for facilitating improved human - computer interaction US 5357596 A .Abstract .A speech dialogue system capable of realizing natural and smooth dialogue between the system and a human user , and easy maneuverability of the system .","label":"Background","metadata":{},"score":"64.576294"}{"text":"[ 0116 ] .Obective 2 : To implement the front end of the ITS comprised of the Speech Recognition , Natural Language and the real - time prosody modeling module ( developed in Objective 1 ) , so that the emotional state detection algorithm can be tested in a system setting .","label":"Background","metadata":{},"score":"64.61731"}{"text":"Controlling by hand the sixty plus continuous parameters in METAFONT can become tedious .There is a need for applications that automate state changes of font parameters .Since speech also represents continuous , sinuous change , we might map the signal characteristics of one onto the shape parameters of the other .","label":"Background","metadata":{},"score":"64.63789"}{"text":"This file is representative of a speaker reminiscing about a satisfying evening spent eating dinner , overlooking the ocean .The font is small and pulsates in rhythm with the ebb and flow of the voice .By exposing them first to this file , subjects can associate the smallness of the type with a calm emotion .","label":"Background","metadata":{},"score":"64.67249"}{"text":"Please repeat it again .\" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the regretful facial expression as shown in FIG .","label":"Background","metadata":{},"score":"64.67917"}{"text":"Please repeat it again .\" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the regretful facial expression as shown in FIG .","label":"Background","metadata":{},"score":"64.67917"}{"text":"Please repeat it again .\" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the regretful facial expression as shown in FIG .","label":"Background","metadata":{},"score":"64.67917"}{"text":"Please repeat it again .\" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the regretful facial expression as shown in FIG .","label":"Background","metadata":{},"score":"64.67917"}{"text":"Also , it is important to determine what should be displayed in the speech dialogue system utilizing various other media .SUMMARY OF THE INVENTION .It is therefore an object of the present invention to provide a speech dialogue system capable of realizing natural and smooth dialogue between the system and a human user , and easy maneuverability of the system .","label":"Background","metadata":{},"score":"64.68383"}{"text":"Also , it is important to determine what should be displayed in the speech dialogue system utilizing various other media .SUMMARY OF THE INVENTION .It is therefore an object of the present invention to provide a speech dialogue system capable of realizing natural and smooth dialogue between the system and a human user , and easy maneuverability of the system .","label":"Background","metadata":{},"score":"64.68383"}{"text":"Also , it is important to determine what should be displayed in the speech dialogue system utilizing various other media .SUMMARY OF THE INVENTION .It is therefore an object of the present invention to provide a speech dialogue system capable of realizing natural and smooth dialogue between the system and a human user , and easy maneuverability of the system .","label":"Background","metadata":{},"score":"64.68383"}{"text":"Artificial intelligence and tutoring systems , Los Altos , Morgan Kaufmann , 1987 .WordNet , A Lexical Database for English .Cognitive Science Laboratory , Princeton University .Young , S. J. , and C E Proctor , C. E. , The design and implementation of dialogue control in voice operated database inquiry systems , Computer Speech and Language , vol .","label":"Background","metadata":{},"score":"64.70929"}{"text":"Here , it is important to control the relationships between the audio information and the visual information by appropriate output timing control .It is also important to control the output timings of these audio information and visual information to manipulate the order of presentation of the information to be given to the user .","label":"Background","metadata":{},"score":"64.715744"}{"text":"Here , it is important to control the relationships between the audio information and the visual information by appropriate output timing control .It is also important to control the output timings of these audio information and visual information to manipulate the order of presentation of the information to be given to the user .","label":"Background","metadata":{},"score":"64.715744"}{"text":"Here , it is important to control the relationships between the audio information and the visual information by appropriate output timing control .It is also important to control the output timings of these audio information and visual information to manipulate the order of presentation of the information to be given to the user .","label":"Background","metadata":{},"score":"64.715744"}{"text":"Here , it is important to control the relationships between the audio information and the visual information by appropriate output timing control .It is also important to control the output timings of these audio information and visual information to manipulate the order of presentation of the information to be given to the user .","label":"Background","metadata":{},"score":"64.715744"}{"text":"The discourse functions in the natural language speech utterance 1000 are determined .In various exemplary embodiments according to this invention , the discourse functions are determined by recognizing the natural language speech to form a recognized text .The recognized text is then optionally verified .","label":"Background","metadata":{},"score":"64.76505"}{"text":"Capturing the intonational contour from F0 is a process of smoothing the F0 curve to remove small perturbations , and using interpolation to fill in the gaps of silence during unvoiced events .Intonation must be understood as an abstraction from the phonemic effects of pronunciation .","label":"Background","metadata":{},"score":"64.81904"}{"text":"In some applications , of course , it may not be necessary or desirable to compute all such variables , and in other instances it may be useful to use additional frequency components ( or derivatives thereof ) .[0054 ] .","label":"Background","metadata":{},"score":"64.81933"}{"text":"5.2.3 Phonemic Realization .A single word is seldom pronounced in exactly the same way during conversation .This often has to do with different phonemes substituting for like sounding phonemes , phonemes added in for reasons of emphasis , elongated phonemes , unusually forceful phonemes that involve some hold and release of air , and many more reasons .","label":"Background","metadata":{},"score":"64.828865"}{"text":"Figure 5 : The intonation of \" You might have told me \" can imply indignation [ left ] to doubt [ right].Example after Bolinger ( 1989 ) .Figure 6 : The common greeting \" Hello \" can convey speaker mood and intentions in a very short linguistic sound - unit .","label":"Background","metadata":{},"score":"64.84042"}{"text":"41 is a diagram for explaining an operation of a user state detection unit in the speech dialogue system of FIG .40 .FIG .42 is a timing chart for one example of an operation in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"64.860176"}{"text":"41 is a diagram for explaining an operation of a user state detection unit in the speech dialogue system of FIG .40 .FIG .42 is a timing chart for one example of an operation in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"64.860176"}{"text":"41 is a diagram for explaining an operation of a user state detection unit in the speech dialogue system of FIG .40 .FIG .42 is a timing chart for one example of an operation in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"64.860176"}{"text":"41 is a diagram for explaining an operation of a user state detection unit in the speech dialogue system of FIG .40 .FIG .42 is a timing chart for one example of an operation in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"64.860176"}{"text":"Referring now to FIG .45 , a third embodiment of a speech dialogue system according to the present invention will be described in detail .This third embodiment differs from the first and second embodiments described above in that the further detail of the practical implementation of the speech dialogue system configuration is incorporated .","label":"Background","metadata":{},"score":"64.8684"}{"text":"In a third conventional approach , a computer uses a grammar to specify the class of utterances by the user that are acceptable .SUMMARY OF THE INVENTION .[ 0004 ] .Conventional approaches to processing spoken utterances directed to speech enabled applications have limitations .","label":"Background","metadata":{},"score":"64.888596"}{"text":"( a )Lengthened : ( 7 ) Intention of clearly speaking .( 8) Intention of suggestively speaking .( b ) Shortened : ( 9 ) Hurried .( 10 ) Urgent .Seven examinees were made to hear synthesized voices generated by ( g ) lengthening and ( h ) shortening the duration of a prosodic pattern of a Japanese word utterance \" Aoi \" ( which means \" Blue \" ) .","label":"Background","metadata":{},"score":"64.89993"}{"text":"3 ) .The computer program product 80 may be installed by any suitable software installation procedure , as is well known in the art .In another embodiment , the software instructions may also be downloaded over a wireless connection .","label":"Background","metadata":{},"score":"64.90547"}{"text":"Often the Prosodic Font would slow down after repeated playing due to Java 1.2 vagaries .Correspondingly , three of the eleven subjects in example one chose the bored audio file which demonstrates a slower , more lethargic rhythm .Rhythmic correspondence of the Prosodic Font to vocal prosody is a key , if not primary , feature in peoples ' perception of sound to image relationship .","label":"Background","metadata":{},"score":"64.90591"}{"text":"That knowledge is provided individually on an application 26 by application 26 basis , and is incorporated into the speech center 20 through the application model interface 42 . [ 0032 ] .The GUI manager 40 provides an interface to the speech center 20 .","label":"Background","metadata":{},"score":"64.9332"}{"text":"For example , high energy in a speech utterance is associated with high activation of the emotion state .Conversely , low energy levels of the speech utterance are associated with emotion states with low activation values .[ 0055 ] .","label":"Background","metadata":{},"score":"64.95051"}{"text":"Zachary , W. W. , Ryder , J. M. , Ross , L. , & Weiland , M. Z. ( 1992 ) .Intelligent computer - human interaction in real - time multi - tasking process control and monitoring systems .In M. Helander and M. Nagamachi ( Eds . ) , Design for Manufacturability .","label":"Background","metadata":{},"score":"64.95651"}{"text":"In Proceedings of ICSLP92 , v. 2 , 867 - 870 .Small , D. ( 1996 ) .Perception of Temporal Typography .Paper written for Ph.D. Comprehensive Exams .Sparacino , F. ( 1996 ) . DirectIVE: Choreographing Media for Interactive Virtual Environments .","label":"Background","metadata":{},"score":"64.96593"}{"text":"The method of claim 25 , wherein the generating step generates the speech response incorporating a speech characteristic corresponding to the movement and the facial expression of the human character .The method of claim 26 , wherein the speech characteristic of the speech response includes at least one of an emotional expression , an intentional expression , and an intonation .","label":"Background","metadata":{},"score":"64.99075"}{"text":"The method of claim 25 , wherein the generating step generates the speech response incorporating a speech characteristic corresponding to the movement and the facial expression of the human character .The method of claim 26 , wherein the speech characteristic of the speech response includes at least one of an emotional expression , an intentional expression , and an intonation .","label":"Background","metadata":{},"score":"64.99075"}{"text":"12C is an illustration indicating an exemplary dialogue between the system and the user in an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .1 .FIGS .12D and 12E are illustrations of examples of two semantic utterance representation candidates for an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"65.017876"}{"text":"12C is an illustration indicating an exemplary dialogue between the system and the user in an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .1 .FIGS .12D and 12E are illustrations of examples of two semantic utterance representation candidates for an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"65.017876"}{"text":"12C is an illustration indicating an exemplary dialogue between the system and the user in an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .1 .FIGS .12D and 12E are illustrations of examples of two semantic utterance representation candidates for an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"65.017876"}{"text":"Interactive Discourse as an Emergent Register .Written Communication .Vol . 8 , No . 1 , January , 8 - 34 .Fujisaki , H. ( 1983 ) .Dynamic characteristics of voice fundamental frequency in speech and singing .","label":"Background","metadata":{},"score":"65.034386"}{"text":"On the other hand , as for speech synthesis , the development has been made From a simple text - to - speech system toward a speech synthesis system suitable for a speech dialogue system in which a greater weight is given to the intonation .","label":"Background","metadata":{},"score":"65.13258"}{"text":"On the other hand , as for speech synthesis , the development has been made From a simple text - to - speech system toward a speech synthesis system suitable for a speech dialogue system in which a greater weight is given to the intonation .","label":"Background","metadata":{},"score":"65.13258"}{"text":"Using these commands , it is possible to describe time - variation of parameters .[ # ] indicates the insertion of a silent period in the synthetic speech .The silent period in this case is 1 mora , where \" mora \" is an average length of one syllable .","label":"Background","metadata":{},"score":"65.13366"}{"text":"Accordingly , it is difficult to obtain a speech message with desired prosodic features by arbitrarily correcting prosodic or phonological parameters of that portion in the synthesized speech which sounds monotonous and hence recitative .Since this method visually corrects the prosodic parameters , however , the actual parameter correcting operation requires experience and knowledge of phonetics , and hence is difficult for an ordinary operator .","label":"Background","metadata":{},"score":"65.14238"}{"text":"Comparison of cognitive model uses in intelligent training systems .In Proceedings of IEA2000/HFES2000 ( pp .2 - 374 to 2 - 377 ) .Santa Monica , Calif. : Human Factors Society .Ryder , J. M. , Graesser , A. C. , McNamara , J. , Karnavat , A. , & Popp , E. ( 2002 ) .","label":"Background","metadata":{},"score":"65.178474"}{"text":"In the prosodic feature rule database 16 there are stored rules that provide information as to how to change and correct the prosodic parameters in correspondence to each prosodic feature control command .The prosodic parameters of the text , controlled in the prosodic feature control part 17 , are provided to the synthetic speech generation part 18 , wherein they are rendered into a synthetic speech signal , which is applied to a loudspeaker 19 .","label":"Background","metadata":{},"score":"65.1806"}{"text":"Syllables punctuate the screen boldly , and the scale changes from very small to very large within a single syllable .Overall , the effect is engaging , and has even aroused some empathetic laughter identifying with the speaker .The fonts appear to have a life of their own .","label":"Background","metadata":{},"score":"65.27654"}{"text":"Method and apparatus for editing / creating synthetic speech message and recording medium with the method recorded thereon US 6226614 B1 .Abstract .A three - layered prosody control description language is used to insert prosodic feature control commands in a text at the positions of characters or a character string to be added with non - verbal information .","label":"Background","metadata":{},"score":"65.32092"}{"text":"Brown , G. and Kenworthy , J. 1980 Questions of Intonation , Baltimore , University Park Press , p. 21 - 122 .Dahlbck , N. and Jnsson , A. 1989 .Empirical studies of discourse representations for natural language interfaces .","label":"Background","metadata":{},"score":"65.429535"}{"text":"I admire the simple , independent feature exaggeration ( i.e. visual scaling of paralinguistically salient features , or time scaling by feature importance ) that a phonological approach would enable , yet am interested in the individualistic characterization that a phonetic approach enables .","label":"Background","metadata":{},"score":"65.43169"}{"text":"Does it encode just the words that we write now by hand ?Or does it also encode the emotional overtones , the lyric melody , the subtle rhythms of our speech into the written symbology ?What , then , does typography become ?","label":"Background","metadata":{},"score":"65.4464"}{"text":"I argue for a productive combination of the auto - segmental metrical school of phonology ( Bruce , 1977 ; Pierrehumbert , 1980 ; Beckman , 1986 ; Ladd , 1996 ) and the more phonetic TILT model ( Taylor , 1998 ) .","label":"Background","metadata":{},"score":"65.45807"}{"text":"Normal , everyday spoken prosody is an emotional expression .Psychologists and anthropologists have studied children 's acquirement of diverse intonational contours .Usually they have relied only upon their ear to make intonational distinctions .The use of intonation by a Mandarin Chinese newborn was studied over a two year period ( Clumeck , 1977 ) .","label":"Background","metadata":{},"score":"65.470535"}{"text":"FIG .29 is a detailed block diagram of a speech waveform generation unit in the speech response generation unit of FIG .25 .FIG .30A is a timing chart for one example of a display timing control to be made in a response output control unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"65.49409"}{"text":"FIG .29 is a detailed block diagram of a speech waveform generation unit in the speech response generation unit of FIG .25 .FIG .30A is a timing chart for one example of a display timing control to be made in a response output control unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"65.49409"}{"text":"FIG .29 is a detailed block diagram of a speech waveform generation unit in the speech response generation unit of FIG .25 .FIG .30A is a timing chart for one example of a display timing control to be made in a response output control unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"65.49409"}{"text":"FIG .29 is a detailed block diagram of a speech waveform generation unit in the speech response generation unit of FIG .25 .FIG .30A is a timing chart for one example of a display timing control to be made in a response output control unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"65.49409"}{"text":"\" The Perception of Tone . \"In Tone : a Linguistic Survey .Ed .Victoria Fromkin .New York : Academic Press .Gumperz , J. J. ( 1982 ) .Discourse Strategies .Cambridge : Cambridge University Press .","label":"Background","metadata":{},"score":"65.54369"}{"text":"It is preferable to carry out this speech speed control such that the utterance duration is made shorter when the dialogue is progressing smoothly , while the utterance duration is made longer when the dialogue is not progressing smoothly .Here , the change of the utterance duration can be controlled properly by selecting the appropriate length of the response sentence pattern , for example , the shorter response sentence pattern may be used when the user 's speech speed is faster than 9 mora / sec . , while the longer and more polite response sentence pattern may be used otherwise .","label":"Background","metadata":{},"score":"65.557175"}{"text":"It is preferable to carry out this speech speed control such that the utterance duration is made shorter when the dialogue is progressing smoothly , while the utterance duration is made longer when the dialogue is not progressing smoothly .Here , the change of the utterance duration can be controlled properly by selecting the appropriate length of the response sentence pattern , for example , the shorter response sentence pattern may be used when the user 's speech speed is faster than 9 mora / sec . , while the longer and more polite response sentence pattern may be used otherwise .","label":"Background","metadata":{},"score":"65.557175"}{"text":"In face - to - face conversation , prosody is central among human communication tools for conveying psychological - emotional state , intentions , and the point of information focus .When writing provides little context for the hapless reader , such as in email , there is a need for speaker 's intention and emotional state cues to be provided along with the semantics of the message .","label":"Background","metadata":{},"score":"65.56725"}{"text":"Shape also varies at the extreme ends of the continuum .Figure 31 : A single static instance of the Prosodic Font abstract letterform glyphs .PROSODIC FEATURES .Although automatic prosody recognizers are currently in research and development , no off - the - shelf commercial system exists , nor has any system been developed to work in conjunction with a speech recognizer .","label":"Background","metadata":{},"score":"65.596146"}{"text":"[ 0076 ] .Specifically , the calibration routine 130 uses a test utterance from which a baseline is computed for one or more acoustic features that are extracted by the prosody analysis block 118 .For example , the test utterance includes a set of phrases , one of which contains significant stress or accent or other emotion indicator from which a large shift in the fundamental frequency ( FO ) , or pitch can be calculated .","label":"Background","metadata":{},"score":"65.61891"}{"text":"The S layer permits intuition - dependent control descriptions , such as speaker 's mental states and sentence structures , without requiring knowledge about the prosody and other phonetic matters .It is also possible to establish correspondence between the commands of the S layer and HTML , LaTeX and other commands .","label":"Background","metadata":{},"score":"65.65119"}{"text":"Timing of syllables is accurate to the hundredths of a second from the speech data .We know that the timing of any syllable is dependent upon the physical motion necessary to form the phonemes .These phonetic dependencies do not appear to make a large difference in the relative changes of timing between words .","label":"Background","metadata":{},"score":"65.66476"}{"text":"The prosodic feature pattern can be updated by correcting the corresponding prosodic parameter on the display screen through GUI and then writing the corrected parameter into the prosodic feature rule database 16 from the conversion part 23 .This registration function avoids the need for obtaining synthetic speech containing non - verbal information through the use of many prosodic feature control commands of the I layer whenever the user requires the non - verbal information unobtainable with the prosodic feature control commands of the S layer .","label":"Background","metadata":{},"score":"65.67093"}{"text":"A recording medium having recorded thereon a procedure for editing / creating non - verbal information of a synthetic speech message by rules , said procedure comprising the steps of : .( b ) extracting from said text a prosodic parameter string of speech synthesized by rules ; .","label":"Background","metadata":{},"score":"65.6858"}{"text":"In the system , a semantic content of input speech from a user is understood and a semantic content determination of a response output is made according to the understood semantic content of the input speech .Then , a speech response and a visual response according to the determined response output are generated and outputted to the user .","label":"Background","metadata":{},"score":"65.6987"}{"text":"[ 0000 ] .Real - Time Classifier .[0081 ] .The parts - of - speech analysis from routine(s ) 121 yields syntactic elements from which emotion cues can be derived .The acoustic analyzer routine(s ) 118 in turn yields separate data values for the prosodic acoustic correlates which are also related to emotion cues .","label":"Background","metadata":{},"score":"65.73296"}{"text":"Here , the new text data and content visualizing image are continued to be displayed even after the timing t3 until the next system response output stage .FIG .31A is a timing chart for a situation of making a confirmation of all orders after the orders for two hamburgers , one cheese burger , and three coffees are received .","label":"Background","metadata":{},"score":"65.75905"}{"text":"Here , the new text data and content visualizing image are continued to be displayed even after the timing t3 until the next system response output stage .FIG .31A is a timing chart for a situation of making a confirmation of all orders after the orders for two hamburgers , one cheese burger , and three coffees are received .","label":"Background","metadata":{},"score":"65.75905"}{"text":"Here , the new text data and content visualizing image are continued to be displayed even after the timing t3 until the next system response output stage .FIG .31A is a timing chart for a situation of making a confirmation of all orders after the orders for two hamburgers , one cheese burger , and three coffees are received .","label":"Background","metadata":{},"score":"65.75905"}{"text":"Here , the new text data and content visualizing image are continued to be displayed even after the timing t3 until the next system response output stage .FIG .31A is a timing chart for a situation of making a confirmation of all orders after the orders for two hamburgers , one cheese burger , and three coffees are received .","label":"Background","metadata":{},"score":"65.75905"}{"text":"As content creators are able to more intuitively gauge student understanding and concern through a voice interface , it will ease their conceptual workload in creating more engaging content that will not have to create exhaustive cases to gauge user feedback on content that has been presented .","label":"Background","metadata":{},"score":"65.801956"}{"text":"Confusion matrices will then be used to represent and compare the recognition accuracy as a percentage of stress levels and the two - way classifications generated by the different classifiers .[ 0000 ] .Development of the Real - Time Prosodic Modeling Algorithm .","label":"Background","metadata":{},"score":"65.82492"}{"text":"In the dictation mode , the input signal information is matched against signal information templates associated with candidate recognized text .The recognized text then serves as the input to the underlying application .For example , recognized text may be placed into an application such as an editor , word - processor , email editor and the like in lieu of , or in addition to , keyboard input .","label":"Background","metadata":{},"score":"65.84936"}{"text":"Thus , the prosodic information associated with the first portion of the speech utterance may indicate the speech utterance should be considered a command to the addressing function of an email system .Similarly , prosodic information associated with the second portion of the speech utterance may be used to indicate that the second portion of the speech utterance contains the content portion or addressee information associated with the email message .","label":"Background","metadata":{},"score":"65.88638"}{"text":"[ 0025]FIG .2 shows the components of a speech center system 20 configured according to the present invention .FIG .2 also illustrates external applications 26 that communicate with the speech center 20 , a speech engine 22 , and an active accessability module 24 .","label":"Background","metadata":{},"score":"65.89313"}{"text":"The semantics analysis module processes a recognition message based on one of the spoken utterances recognized by a speech engine to produce an initial semantic representation of the recognized spoken utterance based on the grammatic specification and the domain model .The semantic analysis module provides a set of propositions that represent the recognized spoken utterance , the set of propositions based on the initial semantic representation and the domain model .","label":"Background","metadata":{},"score":"65.92799"}{"text":"( c ) synthesizing speech by said corrected prosodic parameter ; .( e ) converting the characters of said text based on said character conversion information and displaying them accordingly ; .A synthetic speech message editing / creating apparatus comprising : . a text / prosodic feature control command separating part for separating said prosodic feature control command from said text ; . a speech synthesis information converting part for generating a prosodic parameter string from said separated text based on a \" synthesis - by - rule \" method ; .","label":"Background","metadata":{},"score":"65.93413"}{"text":"[ 0034 ] .The both prosodic data and acoustic feature data may or may not be packaged within a common data stream as received at the server device , depending on the nature of the data , the content of the data streams , available bandwidth , prioritizations required , etc .","label":"Background","metadata":{},"score":"65.954765"}{"text":"It is a non - arbitrary use of vocal features to convey the way we feel about what we are saying , as well as how we are feeling when we say anything .A number of primitive features interact within any spoken utterance to create a uniquely phrased and emphasized utterance .","label":"Background","metadata":{},"score":"65.99283"}{"text":"[ 0095 ] .The goal of computer - based tutoring environments has been to create an optimum educational tool which emulates the methods of good human tutors .One - on - one human tutoring has repeatedly been shown to be more effective than other types of instruction .","label":"Background","metadata":{},"score":"65.99384"}{"text":"Across the field of linguistics , more and more scholars are using experiments to investigate linguistics issues , and to provide evidence that stands up to skeptical scrutiny .This course is a hands - on introduction to how to do this .","label":"Background","metadata":{},"score":"65.99662"}{"text":"The speech dialogue system of claim 1 , wherein said response generation means generates said visual response which includes an image of a human character delivering said speech response , wherein said image incorporates movement and facial expression of said human character .","label":"Background","metadata":{},"score":"66.0026"}{"text":"The speech dialogue system of claim 1 , wherein said response generation means generates said visual response which includes an image of a human character delivering said speech response , wherein said image incorporates movement and facial expression of said human character .","label":"Background","metadata":{},"score":"66.0026"}{"text":"The goal of finding the date will result in the location of another rule which invokes a function that can calculate a date based on the relative date \" tomorrow \" information .The goal of finding a person results in the location of a rule that will invoke a function which will attempt to disambiguate a person 's full name from their first name .","label":"Background","metadata":{},"score":"66.01427"}{"text":"The method of .claim 1 , wherein said prosodic features include data values which are related to one or more acoustic measures including one of PITCH , DURATION & ENERGY .The method of .claim 1 , wherein said emotion state includes at least one of STRESS & NON - STRESS .","label":"Background","metadata":{},"score":"66.019394"}{"text":"They will investigate their own speech of people they know by means of small - scale acoustic and perception experiments .They will learn about how such differences emerge over time , and how one ends up speaking the way one does .","label":"Background","metadata":{},"score":"66.03447"}{"text":"FIGS .12A and 12B are illustrations of examples of a semantic response representation and an order table for an exemplary case of the operation in a dialogue management unit in the speech dialogue system of FIG .1 . FIG .","label":"Background","metadata":{},"score":"66.07998"}{"text":"Yet , each stroke 's weighting ( line thickness ) , curvature , rotation , even hue or transparency could be separately controlled .Figure 26 : Early sketch of the four stroke system .Kerning between glyphs was automatically built into the system through the left , center and right alignment practice .","label":"Background","metadata":{},"score":"66.08861"}{"text":"[ # ] is a pause inserting command , by which a silent duration of about 1 mora is inserted .[A ] is an amplitude value control command , by which the amplitude value is made 1.8 times larger than before , that is , than \" konotori \" ( which means \" the bird \" ) .","label":"Background","metadata":{},"score":"66.09169"}{"text":"For example , if the Unified Linguistic Discourse Model is used , the verified recognized texts associated with the training corpus of speech utterances are segmented into discourse constituents .Segmentation in the Unified Linguistic Discourse Model is comprised of co - ordinations , subordinations and binaries or n - aries .","label":"Background","metadata":{},"score":"66.154755"}{"text":"In the domain of ritual exchanges and adjacency pairs , such as greetings , farewells , introductions , et cetera , the emotional exchange value becomes particularly evident .Picard postulates that ( 1 ) the fact that you make the greeting , and ( 2 ) how the greeting is said , is more important than what is said ( 1997 ) .","label":"Background","metadata":{},"score":"66.16165"}{"text":"Finally , at the step S117 , the transition to the addition confirmation system state SA is made .In the addition confirmation system state SA , the process according to the flow chart of FIG .14 is carried out as follows .","label":"Background","metadata":{},"score":"66.17665"}{"text":"Finally , at the step S117 , the transition to the addition confirmation system state SA is made .In the addition confirmation system state SA , the process according to the flow chart of FIG .14 is carried out as follows .","label":"Background","metadata":{},"score":"66.17665"}{"text":"Finally , at the step S117 , the transition to the addition confirmation system state SA is made .In the addition confirmation system state SA , the process according to the flow chart of FIG .14 is carried out as follows .","label":"Background","metadata":{},"score":"66.17665"}{"text":"Finally , at the step S117 , the transition to the addition confirmation system state SA is made .In the addition confirmation system state SA , the process according to the flow chart of FIG .14 is carried out as follows .","label":"Background","metadata":{},"score":"66.17665"}{"text":"Modelling Intonational Structure using Hidden Markov Models , ESCA Workshop on Intonation , Athens , September .Vygotsky , ( 1975 ) .On the Perception of Words : An Application of Some Basic Concepts .In The Psychology of Reading .","label":"Background","metadata":{},"score":"66.17923"}{"text":"In Grosz and Sidner 's discourse model of attentional and intentional state ( 1986 ) , prosodic accents mark the attentional status of discourse entities ( Cahn , 1995 ; Grosz and Hirschberg , 1992 ; Nakatani , 1995 ) , the intended syntactical focus of attention .","label":"Background","metadata":{},"score":"66.18232"}{"text":"Build data sets for standalone speech recognition tests .[ The option of investigating the use of the UNIANCE compiler with the EduSpeak speech engine for providing a semantic output representation is not required in Phase I , but is a valuable option during Phase II when interfacing with the dialog manager . ]","label":"Background","metadata":{},"score":"66.187126"}{"text":"Namely , as indicated in FIG .43 , the user gets off the floor mat after the response No . 2 of \" Your orders are two hamburgers and two coffees , right ? \" for confirmation is outputted , the semantic user state representation No . 2 is supplied from the user state detection unit 233 to the dialogue management unit 234 . is outputted as a visual response from the display unit 236 and as a speech response from the loudspeaker unit 237 .","label":"Background","metadata":{},"score":"66.19042"}{"text":"Namely , as indicated in FIG .43 , the user gets off the floor mat after the response No . 2 of \" Your orders are two hamburgers and two coffees , right ? \" for confirmation is outputted , the semantic user state representation No . 2 is supplied from the user state detection unit 233 to the dialogue management unit 234 . is outputted as a visual response from the display unit 236 and as a speech response from the loudspeaker unit 237 .","label":"Background","metadata":{},"score":"66.19042"}{"text":"Namely , as indicated in FIG .43 , the user gets off the floor mat after the response No . 2 of \" Your orders are two hamburgers and two coffees , right ? \" for confirmation is outputted , the semantic user state representation No . 2 is supplied from the user state detection unit 233 to the dialogue management unit 234 . is outputted as a visual response from the display unit 236 and as a speech response from the loudspeaker unit 237 .","label":"Background","metadata":{},"score":"66.19042"}{"text":"Namely , as indicated in FIG .43 , the user gets off the floor mat after the response No . 2 of \" Your orders are two hamburgers and two coffees , right ? \" for confirmation is outputted , the semantic user state representation No . 2 is supplied from the user state detection unit 233 to the dialogue management unit 234 . is outputted as a visual response from the display unit 236 and as a speech response from the loudspeaker unit 237 .","label":"Background","metadata":{},"score":"66.19042"}{"text":"Larger numbers of enterprises recognize that e - Learning is an obvious benefit in their technology infrastructure .Just as most e - mail projects were never cost justified , e - Learning will become a standard way of deploying knowledge transfer programs 20 .","label":"Background","metadata":{},"score":"66.19411"}{"text":"Conversely , real - time speech and natural language recognition systems are also known in the art , as depicted in Applicant 's prior patents , including U.S. Pat .No .6,615,172 which is also incorporated by reference herein .Because of the significant benefits offered by prosodic elements in identifying a meaning of speech utterances ( as well as other human input ) , it would be clearly desirable to integrate such features within the aforementioned Bennett et al . speech recognition / natural language processing architectures .","label":"Background","metadata":{},"score":"66.21155"}{"text":"In addition , the content visualizing image visualizing the essential content of the speech response is provided for supporting the smooth comprehension of the system response by the user .In further detail , this response generation unit 13 has a configuration as shown in FIG .","label":"Background","metadata":{},"score":"66.22067"}{"text":"0151 ] .Speaktomi will implement the front end of the speech - based ITS within the reference architecture discussed previously and based on a configuration of modular components functioning as software agents that adhere to a software framework called the Open Agent Architecture ( OAA ) 15 .","label":"Background","metadata":{},"score":"66.2263"}{"text":"This case corresponds to a case of making transition to the final system state S9 in the state transition diagram of FIG .9 described above .At this point , the other necessary response output such as that for requesting the user to pay the total charge can be made .","label":"Background","metadata":{},"score":"66.240326"}{"text":"This case corresponds to a case of making transition to the final system state S9 in the state transition diagram of FIG .9 described above .At this point , the other necessary response output such as that for requesting the user to pay the total charge can be made .","label":"Background","metadata":{},"score":"66.240326"}{"text":"This case corresponds to a case of making transition to the final system state S9 in the state transition diagram of FIG .9 described above .At this point , the other necessary response output such as that for requesting the user to pay the total charge can be made .","label":"Background","metadata":{},"score":"66.240326"}{"text":"This case corresponds to a case of making transition to the final system state S9 in the state transition diagram of FIG .9 described above .At this point , the other necessary response output such as that for requesting the user to pay the total charge can be made .","label":"Background","metadata":{},"score":"66.240326"}{"text":"5.2.2 Linguistic Labeling .I acted as the speech recognizer for the emotional corpus .The basic linguistic unit is a speech event .A speech event can be either a syllable , a silence , an inhalation or exhalation .I did not encounter any coughing , sighing or the like within the small excerpts I chose for the Emotional Corpus .","label":"Background","metadata":{},"score":"66.25775"}{"text":"\" The role of the right hemisphere in the control of speech prosody in propositional and affective contexts .\" Brain and Language 25 , 19 - 36 .Silverman , K. Beckman , M. , Pitrelli , J. , Ostendorf , M. , Wightman , C. , Price , P. , Pierrehumbert , J. , & Hirschberg , J. ( 1992 ) .","label":"Background","metadata":{},"score":"66.26662"}{"text":"7 shows the experimental results , which suggest that various mental states could be expressed by varied combinations of basic prosody control rules , and the response rates on the respective mental states indicate that their recognition is quite common to the examinees .","label":"Background","metadata":{},"score":"66.26698"}{"text":"Alternatively , the prosodic features may be determined in a batch mode or the like .It will also be apparent that combinations of prosodic features may be associated with discourse functions at various levels of discourse structure .Thus , the prosodic features may be used to indicate the segmentation boundaries between words , to indicate intra - sentential and inter - sentential subordinations , paragraphs segments , turn taking segments or any known or later developed discourse structure identifiable by the selected theory of discourse analysis .","label":"Background","metadata":{},"score":"66.26741"}{"text":"Some conventional automatic speech recognition systems constrain this matching process based on probability models such as co - occurrence , lattice rescoring and the like .Idiosyncratic variations in the input speech information are handled by refinement or personalization of the information associated with the signal information templates .","label":"Background","metadata":{},"score":"66.28049"}{"text":"[ 0035 ] .It will be understood from the Detailed Description that the inventions can be implemented in a multitude of different embodiments .Furthermore , it will be readily appreciated by skilled artisans that such different embodiments will likely include only one or more of the aforementioned objects of the present inventions .","label":"Background","metadata":{},"score":"66.31789"}{"text":"0099 ] .In step 110 , the reasoning facility 52 generates a goal based on the utterance representation ( e.g. , set of propositions ) received from the syntax manager 62 .As part of step 110 , the reasoning facility 52 may generate further subgoals if necessary to achieve the goal .","label":"Background","metadata":{},"score":"66.32132"}{"text":"Figure 24 : The difference between glyph forms drawn through means of equations of lines and curves , and glyph forms constructed through the association of smaller graphic primitives with each other .Illustration taken from Drucker ( 1995 , p. 283 ) .","label":"Background","metadata":{},"score":"66.34411"}{"text":"March 18 .Anderson , M. , Pierrehumbert , J. , & Liberman , M. ( 1984 ) .Synthesis by rule of English intonation patterns .Proceedings of the IEEE International Conference on Acoustics , Speech , and Signal Processing , 2.8.2 - 2.8.4 .","label":"Background","metadata":{},"score":"66.394485"}{"text":"Further , there were no existing speech corpus predicated on expressive and emotional conversational data that were not taped from phone lines - a notoriously unclean medium from which to record .My approach to developing a theory on prosody 's function , parameters , range and description thereof is bottom up .","label":"Background","metadata":{},"score":"66.396996"}{"text":"The speech dialogue system of claim 6 , wherein the speech characteristic of the speech response includes at least one of an emotional expression , an intentional expression , and an intonation .The speech dialogue system of claim 1 , wherein the speech understanding means supplies a plurality of candidates for the input speech , and the dialogue management means determines the response output by evaluating said plurality of candidates in accordance with a dialogue history / state .","label":"Background","metadata":{},"score":"66.40738"}{"text":"FIG .10 is a flow chart for an operation in a user state in the state transition diagram of FIG .9 .FIG .11 is a flow chart for an operation in a system state in the state transition diagram of FIG .","label":"Background","metadata":{},"score":"66.433655"}{"text":"Much research has attempted to correlate accent type with particular discourse functions .In Artificial Intelligence , researchers theorize that prosody factors into the model of the speaker .Accent is hypothesized to mark the speaker 's model of uncertainty ( Ward and Hirschberg , 1985 ) and mutual belief developed between the speaker and hearer through discourse ( Pierrehumbert and Hirschberg , 1990 ) .","label":"Background","metadata":{},"score":"66.44582"}{"text":"The system has particular applicability to such applications as remote learning , e - commerce , technical e - support services , Internet searching , etc . .BACKGROUND OF THE INVENTION .[ 0003 ] .Emotion is an integral component of human speech and prosody is the principal way it is communicated .","label":"Background","metadata":{},"score":"66.448395"}{"text":"Then , a speech response and a visual response according to the determined response output are generated and outputted to the user .The dialogue between the system and the user is managed by controlling transitions between user states during which the input speech is to be entered and system states during which the system response is to be outputted .","label":"Background","metadata":{},"score":"66.459"}{"text":"Then , a speech response and a visual response according to the determined response output are generated and outputted to the user .The dialogue between the system and the user is managed by controlling transitions between user states during which the input speech is to be entered and system states during which the system response is to be outputted .","label":"Background","metadata":{},"score":"66.459"}{"text":"LgSp .Ward & Hirschberg , J. ( 1985 ) .Implicating uncertainty .Language .Wieman , L. ( 1975 ) .The stress pattern of early child language .PhD. Dissertation , University of Washington .Eric document 111 201 .","label":"Background","metadata":{},"score":"66.462456"}{"text":"A detailed implementation of the speech understanding unit 11 for realizing this method will now be described .The keyword detection unit 21 carries out the keyword spotting operation as follows .First , at the speech analyzer 21a , the input speech is passed through a low pass filter ( not shown ) and A / D converted by using the sampling frequency of 12 KHz and the 12 bits quantization .","label":"Background","metadata":{},"score":"66.467926"}{"text":"A detailed implementation of the speech understanding unit 11 for realizing this method will now be described .The keyword detection unit 21 carries out the keyword spotting operation as follows .First , at the speech analyzer 21a , the input speech is passed through a low pass filter ( not shown ) and A / D converted by using the sampling frequency of 12 KHz and the 12 bits quantization .","label":"Background","metadata":{},"score":"66.467926"}{"text":"On the other hand , as For the speech synthesis , development has been made from a simple text - to - speech system toward a speech synthesis system suitable for a speech dialogue system in which a greater weight is given to the intonation .","label":"Background","metadata":{},"score":"66.495476"}{"text":"On the other hand , as For the speech synthesis , development has been made from a simple text - to - speech system toward a speech synthesis system suitable for a speech dialogue system in which a greater weight is given to the intonation .","label":"Background","metadata":{},"score":"66.495476"}{"text":"In another embodiment , one or more of the external applications may be hosted and executed by a different digital processor 12 than the digital processor 12 that hosts the speech center 20 .Generally , the speech center 20 ( and its individual components ) may be implemented as hardware or software .","label":"Background","metadata":{},"score":"66.511444"}{"text":"In a conventional command mode , a language model is determined for the automatic speech recognition system based on the target application for the speech .That is , if an operating system is the target of the speech utterance , the set of valid operating system commands forms a set of signal information templates against which the speech utterance signal information is compared .","label":"Background","metadata":{},"score":"66.51666"}{"text":"A synthetic speech message editing apparatus according to the first aspect of the present invention comprises : . a text / prosodic feature control command separating part for separating the prosodic feature control command from the text ; . a speech synthesis information converting part for generating a prosodic parameter string from the separated text based on a \" synthesis - by - rule \" method ; .","label":"Background","metadata":{},"score":"66.52164"}{"text":"The speech center 20 has at its disposal a set of actions that it can perform itself .These are a subclass of the class of all actions that the speech center 20 knows about , and are known as operations .","label":"Background","metadata":{},"score":"66.52449"}{"text":"One is an amateur story - teller with a well - honed sense of rhythm and cadence ; the other seemed to actually experience the emotion talked about in a fresh way , allowing emotion to dominate the vocal expression .From their stories , I created a speech corpus one minute and forty seconds long ( see figure 32 ) .","label":"Background","metadata":{},"score":"66.54749"}{"text":"Grosz , B. & Sidner , C. ( 1986 ) , ' Attention , intentions , and the structure of discourse ' , Computational Linguistics 12 , 175 - 204 .Beckman , M. E. & G. Ayers Elam , ( 1997 ) : Guidelines for ToBI labelling , version 3 . [","label":"Background","metadata":{},"score":"66.54866"}{"text":"It is common to all of the languages that prosodic features of voices vary with the speaker 's mental states , intentions and so forth .Accordingly , it is evident that the MSCL according to the present invention is applicable to the editing of synthetic speech in any kind of language .","label":"Background","metadata":{},"score":"66.564285"}{"text":"a display for displaying thereon the converted text .Recording media , on which procedures of performing the editing methods according to the first , second and third aspects of the present invention are recorded , respectively , are also covered by the invention .","label":"Background","metadata":{},"score":"66.61099"}{"text":"Here , it is to be noted that the above described operation of the keyword detection unit 21 can be realized in real time processing by using the DSP boards proposed by the present inventors .The keyword lattice obtained by the keyword detection unit 21 as described above is then supplied to the syntactic and semantic analysis unit 22 in which each keyword in the keyword lattice is analyzed from left to right , as follows .","label":"Background","metadata":{},"score":"66.612564"}{"text":"Here , it is to be noted that the above described operation of the keyword detection unit 21 can be realized in real time processing by using the DSP boards proposed by the present inventors .The keyword lattice obtained by the keyword detection unit 21 as described above is then supplied to the syntactic and semantic analysis unit 22 in which each keyword in the keyword lattice is analyzed from left to right , as follows .","label":"Background","metadata":{},"score":"66.612564"}{"text":"Here , it is to be noted that the above described operation of the keyword detection unit 21 can be realized in real time processing by using the DSP boards proposed by the present inventors .The keyword lattice obtained by the keyword detection unit 21 as described above is then supplied to the syntactic and semantic analysis unit 22 in which each keyword in the keyword lattice is analyzed from left to right , as follows .","label":"Background","metadata":{},"score":"66.612564"}{"text":"Here , it is to be noted that the above described operation of the keyword detection unit 21 can be realized in real time processing by using the DSP boards proposed by the present inventors .The keyword lattice obtained by the keyword detection unit 21 as described above is then supplied to the syntactic and semantic analysis unit 22 in which each keyword in the keyword lattice is analyzed from left to right , as follows .","label":"Background","metadata":{},"score":"66.612564"}{"text":"[ 0061 ] .Referring to FIGS . 3 and 4 , the syntax manager 62 uses the grammatical specifications 90 to define the language that the speech center 20 understands .The foundation domain model 70 contains a set of grammatical specifications that defines base classes such as numbers , dates , assertions , commands and questions .","label":"Background","metadata":{},"score":"66.612946"}{"text":"After the training corpus of speech utterances has been determined , control continues to step S 400 .Prosodic features associated with the speech utterances are determined in step S 400 .The prosodic features may be determined using any known or later developed signal processing technique applied to the training corpus .","label":"Background","metadata":{},"score":"66.65101"}{"text":"This course is a continuation of Phonology I ( LIN 380 K ) .The sequence of the two courses forms a one - year introduction to phonology .This course will focus on prosody : the organization of speech sounds into larger units , such as syllables , feet and phonological words .","label":"Background","metadata":{},"score":"66.67818"}{"text":"Several examples of control of the pitch contour and duration of word utterances will be described first , then followed by an example of the creation of the S - layer commands through examination of mental tendencies of synthetic speech in each example of such control .","label":"Background","metadata":{},"score":"66.70372"}{"text":"This test utterance , as in the analogous case of the signal - to - noise ratio calibration of speech recognition routines , allows the system to automatically compute a calibration baseline for the emotion detector / modeler while taking into account other environmental variables .","label":"Background","metadata":{},"score":"66.709366"}{"text":"In one exemplary embodiment , the determined discourse functions are added as annotations within the recognized text .It should be apparent that the prosodic features associated with discourse functions may precede the specific discourse function to be identified , occur during the discourse function or may follow the discourse function depending on the language , speaker , genre and/or other factors .","label":"Background","metadata":{},"score":"66.74245"}{"text":"Litman D. and Silliman S. , ITSPOKE : An Intelligent Tutoring Spoken Dialogue System .In Proceedings of the Human Language Technology Conference : 4th Meeting of the North American Chapter of the Association for Computational Linguistics ( HLT / NAACL ) ( Companion Proceedings ) , Boston , Mass. , May 2004 .","label":"Background","metadata":{},"score":"66.80012"}{"text":"The speech dialogue system of claim 43 , wherein said dialogue management means also limits syntactic and semantic rules to be used by said speech understanding means in advance , according to a state of a dialogue between said user and said speech dialogue system .","label":"Background","metadata":{},"score":"66.81561"}{"text":"The speech dialogue system of claim 43 , wherein said dialogue management means also limits syntactic and semantic rules to be used by said speech understanding means in advance , according to a state of a dialogue between said user and said speech dialogue system .","label":"Background","metadata":{},"score":"66.81561"}{"text":"2.1 FEATURE SET .2.1.1 Song .Song designates those prosodic features that are centrally involved in the production and perception of tone and pitch .These features are the intonational contour , pitch accents and final phrasal tones , as well as pitch range . 2.1.1.1","label":"Background","metadata":{},"score":"66.87969"}{"text":"The discourse function portion 1020 of the exemplary data structure for storing speech utterance prosody information 1070 contains the value \" COORDINATION \" indicating that the speech utterance has been classified as a \" COORDINATION \" type of discourse function under the selected theory of discourse analysis .","label":"Background","metadata":{},"score":"66.89191"}{"text":"The speech dialogue system of claim 6 , wherein said speech characteristic of said speech response includes at least one of an emotional expression and an intonation .The speech dialogue system of claim 1 , wherein said output means also outputs a visual indication for informing said user as to whether said speech dialogue system is ready to receive said input speech .","label":"Background","metadata":{},"score":"66.91431"}{"text":"The speech dialogue system of claim 6 , wherein said speech characteristic of said speech response includes at least one of an emotional expression and an intonation .The speech dialogue system of claim 1 , wherein said output means also outputs a visual indication for informing said user as to whether said speech dialogue system is ready to receive said input speech .","label":"Background","metadata":{},"score":"66.91431"}{"text":"Even though the proportions of each stroke - both horizontally and vertically - may be adjusted separately , this may render the glyphs more unreadable even as it increases expressiveness .Perception tests can begin to chart the outward limits of glyph expressiveness .","label":"Background","metadata":{},"score":"66.940605"}{"text":"0189 ] .Our focus on a license - based , embedded technology is important as our first point of entry .As the company grows , Speaktomi will focus on enhancing its relationship with content creators and providing services to these creators so that they may better use speech technologies in their learning / tutoring applications .","label":"Background","metadata":{},"score":"66.94676"}{"text":"When the dialogue management unit 234 is not in the state # 0 at the step S281 , next at the step S284 , whether the dialogue management unit 234 is in the state # 1 or not is determined .When the dialogue management unit 234 is in the state # 1 at the step S284 , next at the step S285 , whether the speech act in the semantic utterance representation supplied from the speech understanding unit 232 is \" order \" or not is determined .","label":"Background","metadata":{},"score":"66.950516"}{"text":"When the dialogue management unit 234 is not in the state # 0 at the step S281 , next at the step S284 , whether the dialogue management unit 234 is in the state # 1 or not is determined .When the dialogue management unit 234 is in the state # 1 at the step S284 , next at the step S285 , whether the speech act in the semantic utterance representation supplied from the speech understanding unit 232 is \" order \" or not is determined .","label":"Background","metadata":{},"score":"66.950516"}{"text":"Finally , it will be further appreciated that server system 180 may be a single , large - scale system , or a collection of smaller systems interlinked to support a number of potential network users .[ 0041 ] .Initially speech input is provided in the form of a question or query articulated by the speaker at the client 's machine or personal accessory as a speech utterance .","label":"Background","metadata":{},"score":"66.959694"}{"text":"The \" SUBORDINATION \" value indicates that the speech utterance is classified as a subordination type of discourse function under the selected theory of discourse analysis .The exemplary data structure for storing speech utterance prosody information 1070 contains the value \" 174 \" in the initial frequency portion 1030 indicating the initial frequency information associated with the training speech utterance .","label":"Background","metadata":{},"score":"66.98857"}{"text":"Yet , men lower and women often heighten the normal range in which they speak in a manner that is not accounted for by mere physiological differences in order to accentuate their gender identity ( Olsen , 1975 ; Sachs , 1975 ) .","label":"Background","metadata":{},"score":"67.067055"}{"text":"Hambrecht , W. R. & Company , A Vision for E - Learning for America 's Workforce , American Society for Trainers and Development ( ASTD ) , referencing Corporate E - Learning : Exploring a New Frontier , 2000 .Henton , C. ( 2002 ) , Fiction and reality of TTS , Speech Technology Magazine , January - February , pp .","label":"Background","metadata":{},"score":"67.11531"}{"text":"43 , No . 9 , pp .63 - 65 .Shriberg E. and Stolcke A. , Direct Modeling of Prosody : An Overview of Applications in Automatic Speech Processing , Proc .International Conference on Speech Prosody , Nara , Japan , March 2004 .","label":"Background","metadata":{},"score":"67.14743"}{"text":"Although this state of affairs is a testament to the difficulty of prosody recognition and interpretation , this may also be attributed to the fact that there are few compelling applications that use prosody and vocal expression in conjunction with semantic speech recognition .","label":"Background","metadata":{},"score":"67.151596"}{"text":"Speech dialogue system for facilitating improved human - computer interaction US 5577165 A .Rsum .A speech dialogue system capable of realizing natural and smooth dialogue between the system and a human user , and easy maneuverability of the system .","label":"Background","metadata":{},"score":"67.15259"}{"text":"It is also to be noted that such an indication may also incorporate any other visual features related to the aspects of colors , luminances , and concentrations , which can be utilized in catching the user 's attention .IV .","label":"Background","metadata":{},"score":"67.15797"}{"text":"It is also to be noted that such an indication may also incorporate any other visual features related to the aspects of colors , luminances , and concentrations , which can be utilized in catching the user 's attention .IV .","label":"Background","metadata":{},"score":"67.15797"}{"text":"It is also to be noted that such an indication may also incorporate any other visual features related to the aspects of colors , luminances , and concentrations , which can be utilized in catching the user 's attention .IV .","label":"Background","metadata":{},"score":"67.15797"}{"text":"In one embodiment , the input 14 is not necessarily spoken , but is based on some other type of suitable input , such as phrases or sentences typed into a computer keyboard .The recognized spoken utterance 15 is a spoken utterance 14 , recognized as a valid utterance by the speech engine 22 .","label":"Background","metadata":{},"score":"67.166374"}{"text":"Research into spoken rhythm has been handicapped by too close an attention to word citation form , ignoring the study of rhythmic structure within natural language .As such , the tools for prosodic rhythmic description are similar to those from formally structured music ( Lerdahl and Jackendoff , 1983 ) in which a strict metrical division is observed .","label":"Background","metadata":{},"score":"67.20233"}{"text":"Affective use of prosody precedes the acquisition of linguistic tone .Children naturally and easily put accents on what is most interesting and exciting ; their subjective reaction involves no necessary intention .Hence , the prosodic accents that adults often place on \" new \" rather than \" given \" lexical items can be traced back to an emotional , not grammatical , interest .","label":"Background","metadata":{},"score":"67.23528"}{"text":"The data structure for storing exemplary discourse function prosody information 1170 contains the value \" 0.10 \" in the preceding silence portion 1050 .The \" 0.10 \" value indicates the average duration of the silence preceding the exemplary discourse functions of type \" SUBORDINATION \" .","label":"Background","metadata":{},"score":"67.243645"}{"text":"To avoid this , I built Prosodic Font with an implicit understanding that prosody functions primarily as an instrument of emotional communication , but the best way to represent affect is to use interpretations of low- to mid - level voice signals .","label":"Background","metadata":{},"score":"67.25772"}{"text":"A Prosodic Font picks up at the point they left off to begin to describe a design method for treating a glyph as an architectural structure , with each part free to transform and move .Furthermore , Prosodic Font provides a compelling method of automating the animation of these low level graphic elements by mapping the temporal - spatial form of speech to the spatial - temporal form of typography .","label":"Background","metadata":{},"score":"67.27611"}{"text":"In addition , while the generated speech and visual responses are outputted from the response generation unit 13 , the response generation unit 13 notifies the dialogue management system 12 that the output of the responses is in progress .Individual System Elements .","label":"Background","metadata":{},"score":"67.34874"}{"text":"In addition , while the generated speech and visual responses are outputted from the response generation unit 13 , the response generation unit 13 notifies the dialogue management system 12 that the output of the responses is in progress .Individual System Elements .","label":"Background","metadata":{},"score":"67.34874"}{"text":"In addition , while the generated speech and visual responses are outputted from the response generation unit 13 , the response generation unit 13 notifies the dialogue management system 12 that the output of the responses is in progress .Individual System Elements .","label":"Background","metadata":{},"score":"67.34874"}{"text":"In addition , while the generated speech and visual responses are outputted from the response generation unit 13 , the response generation unit 13 notifies the dialogue management system 12 that the output of the responses is in progress .Individual System Elements .","label":"Background","metadata":{},"score":"67.34874"}{"text":"FIG .39 summarizes the overall operation of this first embodiment of the speech dialogue system .In short , the keywords in the input speech uttered by the user are detected by the keyword spotting operation at the keyword detection unit 21 to obtain the keyword candidates 222 .","label":"Background","metadata":{},"score":"67.361015"}{"text":"FIG .39 summarizes the overall operation of this first embodiment of the speech dialogue system .In short , the keywords in the input speech uttered by the user are detected by the keyword spotting operation at the keyword detection unit 21 to obtain the keyword candidates 222 .","label":"Background","metadata":{},"score":"67.361015"}{"text":"FIG .39 summarizes the overall operation of this first embodiment of the speech dialogue system .In short , the keywords in the input speech uttered by the user are detected by the keyword spotting operation at the keyword detection unit 21 to obtain the keyword candidates 222 .","label":"Background","metadata":{},"score":"67.361015"}{"text":"FIG .39 summarizes the overall operation of this first embodiment of the speech dialogue system .In short , the keywords in the input speech uttered by the user are detected by the keyword spotting operation at the keyword detection unit 21 to obtain the keyword candidates 222 .","label":"Background","metadata":{},"score":"67.361015"}{"text":"This research proposal builds on the considerable work in the area of detecting emotion states in natural human - computer dialog .Silipo & Greenberg [ Sillipo , Greenberg , 2000 ] found that amplitude and duration are the primary acoustic parameters associated with patterns of stress - related cues .","label":"Background","metadata":{},"score":"67.36787"}{"text":"5.2.4 Voice Quality .Voice quality events color entire syllables , even entire segments .They are features of vocal personality and are affected strongly by emotional state .Although this is not used visually within Prosodic Font , I labeled voice quality events at the syllabic level of granularity .","label":"Background","metadata":{},"score":"67.39392"}{"text":"7 shows exemplary prosodic features associated with the second exemplary sentence according to one aspect of this invention .The exemplary prosodic features include prosodic features J 1 -J 3 831 - 833 .As discussed above , the prosodic feature information is used alone or in combination with other prosodic features to determine the context information .","label":"Background","metadata":{},"score":"67.39733"}{"text":"Similarly the OAA 5 environment allows flexible and more rapid prototyping and debugging than alternate schemes .This proposal anticipates that the approach taken will save time and will allow us to focus on issues such as the ' tutoring domain'-specific architectural issues , speech recognition imperfections and other key system integration issues .","label":"Background","metadata":{},"score":"67.40602"}{"text":"FIG .43 is a timing chart for another example of an operation in the speech dialogue system of FIG .40 .FIG .44 is a flow chart for an operation in the speech dialogue system of FIG .40 .","label":"Background","metadata":{},"score":"67.43215"}{"text":"FIG .43 is a timing chart for another example of an operation in the speech dialogue system of FIG .40 .FIG .44 is a flow chart for an operation in the speech dialogue system of FIG .40 .","label":"Background","metadata":{},"score":"67.43215"}{"text":"FIG .43 is a timing chart for another example of an operation in the speech dialogue system of FIG .40 .FIG .44 is a flow chart for an operation in the speech dialogue system of FIG .40 .","label":"Background","metadata":{},"score":"67.43215"}{"text":"FIG .43 is a timing chart for another example of an operation in the speech dialogue system of FIG .40 .FIG .44 is a flow chart for an operation in the speech dialogue system of FIG .40 .","label":"Background","metadata":{},"score":"67.43215"}{"text":"They also found that the interfoot intervals \" were no more isochronous than in ' normal ' readings \" ( Beckman , 1986 , p. 93 ) .Prosodic Font requires a higher level understanding of rhythmic performance in order to represent the rhythmic intention rather than side - effects of phonetic pronunciation requirements .","label":"Background","metadata":{},"score":"67.439476"}{"text":"The system of .claim 14 wherein said emotion cue data value is in the form of a data variable suitable for inclusion within a SQL construct .a first routine executing on the client device configured to extract prosodic features from the utterance and to generate extracted prosodic data ; . a second routine executing on the client device configured to transfer said extracted prosodic data with said extracted acoustic feature data to the server device ; . a third routine executing on the server device configured to recognize an emotion state of a speaker of the utterance based on at least said extracted prosodic data ; . wherein operations associated with recognition of prosodic features in the utterance are also distributed across the client device and server device .","label":"Background","metadata":{},"score":"67.44024"}{"text":"10 is a block diagram of an exemplary system for determining predictive models of discourse functions according to this invention .The system for determining predictive models for discourse functions includes input 1200 from text 1220 and speech 1210 and an automatic speech recognition system 1300 which recognizes the input speech information .","label":"Background","metadata":{},"score":"67.468925"}{"text":"The conversation manager 28 is the central component of the speech center 20 that integrates the information from all the other modules 30 , 32 , 34 , 36 , 38 , 40 , 42 .In a preferred embodiment , the conversation manager 28 is not a separate component , but is the internals of the speech center 20 .","label":"Background","metadata":{},"score":"67.47136"}{"text":"The understanding of a semantic content of input speech from a user is made by detecting keywords in the input speech , with the keywords to be detected in the input speech limited in advance , according to a state of a dialogue between the user and the system . speech understanding means for understanding a semantic content of an input speech from a user ; . dialogue management means for making a semantic content determination of a response output according to said semantic content of said input speech understood by said speech understanding means ; . response generation means for generating a speech response and a visual response according to said semantic content of said response output determined by said dialogue management means ; and .","label":"Background","metadata":{},"score":"67.50742"}{"text":"For this objective , in addition to dictionary entries for syllabification and lexical stress levels we will measure the three key speech signal acoustic features - pitch , duration and energy .Duration of segments , syllables , and phrases , fundamental frequency - F o -the acoustic correlate of pitch , and to a lesser degree , energy or amplitude , the correlate of loudness , are the observational basis of prosody in human speech .","label":"Background","metadata":{},"score":"67.52205"}{"text":"The exemplary data structure for storing speech utterance prosody information 1070 contains the value \" SUBORDINATION \" in the discourse function portion 1020 .The \" SUBORDINATION \" value indicates that the speech utterance is classified as a subordination type of discourse function based on the selected theory of discourse analysis .","label":"Background","metadata":{},"score":"67.5654"}{"text":"In recent years , it has become possible to realize a so called human - computer interaction in various forms by inputting , outputting and processing multi - media such as characters , speech , graphics , and images .In particular , in conjunction with a significant improvement in the capacities of a computer and a memory device , various applications of a work station and a personal computer which can handle the multi - media have been developed .","label":"Background","metadata":{},"score":"67.59158"}{"text":"In recent years , it has become possible to realize a so called human - computer interaction in various forms by inputting , outputting and processing multi - media such as characters , speech , graphics , and images .In particular , in conjunction with a significant improvement in the capacities of a computer and a memory device , various applications of a work station and a personal computer which can handle the multi - media have been developed .","label":"Background","metadata":{},"score":"67.59158"}{"text":"In recent years , it has become possible to realize a so called human - computer interaction in various forms by inputting , outputting and processing multi - media such as characters , speech , graphics , and images .In particular , in conjunction with a significant improvement in the capacities of a computer and a memory device , various applications of a work station and a personal computer which can handle the multi - media have been developed .","label":"Background","metadata":{},"score":"67.59158"}{"text":"In recent years , it has become possible to realize a so called human - computer interaction in various forms by inputting , outputting and processing multi - media such as characters , speech , graphics , and images .In particular , in conjunction with a significant improvement in the capacities of a computer and a memory device , various applications of a work station and a personal computer which can handle the multi - media have been developed .","label":"Background","metadata":{},"score":"67.59158"}{"text":"I review the typographical history we have inherited : stylistic differences , clues to creating a perceptually elegant font , and systems of measurement to ensure balance and harmony . 3.1 TYPOGRAPHIC STYLE .In the figure below , the first two typefaces represent the broadest divisions in typographic design , the orientation of the letter weighting .","label":"Background","metadata":{},"score":"67.61267"}{"text":"The reasoning facility 52 still must determine which column to operate upon , for example .[ 0091 ] .The reasoning facility 52 performs the reasoning process for the conversation manager 28 .The reasoning facility 52 is a goal - directed rule based system composed of an inference engine , memory , rule base and agenda .","label":"Background","metadata":{},"score":"67.662186"}{"text":"With few exceptions , the silences are the product of an unvoiced phoneme , or an utterance spoken with a breathy quality .When I used parameters from all Tilt event types , the words would disappear at strange intervals during a phrase .","label":"Background","metadata":{},"score":"67.6848"}{"text":"There are some key problems that must be solved before computer - based learning systems are fully accepted and able to penetrate the training and tutoring market .The first and most important is to provide a more user friendly way to access this training and learning content .","label":"Background","metadata":{},"score":"67.72882"}{"text":"The discourse functions are clustered .Systems and methods for determining predictive models of discourse functions US 7542903 B2 .Abstract .Techniques are provided for determining predictive models of discourse functions based on prosodic features of natural language speech .Inter and intra sentential discourse functions in a training corpus of natural language speech utterances are determined .","label":"Background","metadata":{},"score":"67.73134"}{"text":"Using a phonological and discourse interpretation of prosody in conjunction with speaker specific phonetics , Prosodic Font can communicate the syntactical , informational functions of prosody .Word pairs that are given contrastive prosody could index into a contrastive visual form .","label":"Background","metadata":{},"score":"67.73582"}{"text":"1 .A detailed implementation of the speech understanding unit 11 for realizing this method will now be described .The keyword detection unit 21 carries out the keyword spotting operation as follows .First , at the speech analyzer 21a , the input speech is passed through a low pass filter ( not shown ) and A / D converted by using the sampling Frequency of 12 KHz and the 12 bits quantization .","label":"Background","metadata":{},"score":"67.75481"}{"text":"1 .A detailed implementation of the speech understanding unit 11 for realizing this method will now be described .The keyword detection unit 21 carries out the keyword spotting operation as follows .First , at the speech analyzer 21a , the input speech is passed through a low pass filter ( not shown ) and A / D converted by using the sampling Frequency of 12 KHz and the 12 bits quantization .","label":"Background","metadata":{},"score":"67.75481"}{"text":"The modified prosodic parameters are used to generate the synthetic speech signal for the separated Japanese text in the synthetic speech generating part 18 , and the synthetic speech signal is output as speech via the loudspeaker 19 .On the other hand , the prosodic parameters modified in the prosodic feature control part 17 and rules for converting the position and size of each character of the Japanese text to character conversion information are prestored in a database 24 .","label":"Background","metadata":{},"score":"67.76051"}{"text":"To the extent that these objects and classes fit into the built - in domain model hierarchy , the existing grammatical constructs apply to them as well .So , if an application 26 provides an operation for , say , printing it could specify : . [ 0053 ] .","label":"Background","metadata":{},"score":"67.82422"}{"text":"No .XX / XXX , XXX , entitled \" SYSTEMS AND METHODS FOR HYBRID TEXT SUMMARIZATION \" , filed Oct. 15 , 2003 , herein incorporated by reference in its entirety .After the theory of discourse analysis has been selected , control then continues to step S 300 .","label":"Background","metadata":{},"score":"67.86788"}{"text":"Maeireizo B. , Litman D. , and Hwa R. , Co - training for Predicting Emotions with Spoken Dialogue Data .In Companion Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ( ACL ) , Barcelona , Spain , July 2004 .","label":"Background","metadata":{},"score":"67.87428"}{"text":"Also , by using the computer graphics technique , the human character image in any predetermined movement and facial expression can be obtained by specifying the desired movement and facial expression .The speech characteristic determination unit 134 determines the emotional expression and the intonation of the speech response in correspondence to the movement and the facial expression of the human character image .","label":"Background","metadata":{},"score":"67.96144"}{"text":"Also , by using the computer graphics technique , the human character image in any predetermined movement and facial expression can be obtained by specifying the desired movement and facial expression .The speech characteristic determination unit 134 determines the emotional expression and the intonation of the speech response in correspondence to the movement and the facial expression of the human character image .","label":"Background","metadata":{},"score":"67.96144"}{"text":"Also , by using the computer graphics technique , the human character image in any predetermined movement and facial expression can be obtained by specifying the desired movement and facial expression .The speech characteristic determination unit 134 determines the emotional expression and the intonation of the speech response in correspondence to the movement and the facial expression of the human character image .","label":"Background","metadata":{},"score":"67.96144"}{"text":"Also , by using the computer graphics technique , the human character image in any predetermined movement and facial expression can be obtained by specifying the desired movement and facial expression .The speech characteristic determination unit 134 determines the emotional expression and the intonation of the speech response in correspondence to the movement and the facial expression of the human character image .","label":"Background","metadata":{},"score":"67.96144"}{"text":"To specify the prosodic parameter value takes two forms : relative control for changing or correcting the prosodic parameter resulting from the \" synthesis - by - rule \" and absolute control form making an absolute correction to the parameter .Further , prosodic feature control commands in frequent use are combined for easy access thereto when they are stored in the prosody control rule database 16 , and they are used as new prosodic feature control commands to specify prosodic parameters .","label":"Background","metadata":{},"score":"67.98498"}{"text":"The preceding silence portion 1050 contains the value \" 0.11 \" .The \" 0.11 \" value indicates the duration of any silence preceding the training instance speech utterance .The boundary tone portion 1060 contains the value \" 80 \" .","label":"Background","metadata":{},"score":"68.023605"}{"text":"568 - 575 .Lea , W. A. ( ed . ) , Trends in speech recognition , Englewood Cliffs , N.J. , Prentice Hall , 1980 .Litman D. and Forbes - Riley K. , Predicting Student Emotions in Computer - Human Tutoring Dialogues .","label":"Background","metadata":{},"score":"68.031845"}{"text":"After the face , vocal inflection is the second - most modality expressive of emotion we possess ( Picard , 1997 ) .Research into emotion and speech has found that people can recognize affect with 60 % reliability when context and meaning are obscured ( Scherer , 1981 ) .","label":"Background","metadata":{},"score":"68.07433"}{"text":"In this course , students will learn to recognize phonological patterns in language data , state such patterns precisely , and represent them in a formal model .We will explore prosodic patterns , which are how sounds are organized into larger units such as syllables , stress feet , phonological words , and phonological phrases .","label":"Background","metadata":{},"score":"68.08148"}{"text":"Once all the required information is assembled , the appointment creation function is called and the appointment scheduled .[ 0059 ] .One of the most important aspects of the domain model 70 is that it is explicitly represented and accessible to the speech center system 20 .","label":"Background","metadata":{},"score":"68.08792"}{"text":"These typographic forms would inherently assume a temporal , dynamic form .Prosody in this thesis represents the melody and rhythm people use in natural speech .Even unintentionally , prosody expresses the emotional state of the speaker , her attitude towards whom she 's talking with and what she 's talking about , resolves linguistic ambiguity , and points towards any new focus of linguistic information .","label":"Background","metadata":{},"score":"68.08856"}{"text":"Figure 36 : Schematic of the current implemented Prosodic Font system .The Letterform design system transfers its font to the Prosodic Font Performance interface .The performance interface loads the text files that describe one of the corpus audio files and plays the sound file in a Prosodic Font . 6.2 PARAMETER MATCH APPROPRIATENESS .","label":"Background","metadata":{},"score":"68.1263"}{"text":"The semantics module uses the grammatic specification and the domain model to develop a set of frames ( i.e. , internal representation of the spoken utterance ) .The semantics module then develops a set of propositions from the set of frames .","label":"Background","metadata":{},"score":"68.13165"}{"text":"First , I define the prosodic feature set , in terms of song and rhythm .Secondly , I describe the perceptual and computational techniques for finding these features within spontaneous speech .Next , I describe methods of describing prosodic features according to relevant theories within the phonetic and phonological fields , and specify which ones are most productive in a Prosodic Font context .","label":"Background","metadata":{},"score":"68.15068"}{"text":"There has heretofore been researched and developed , as what is called a TTE ( Text - To - Speech ) message synthesis method , a \" speech synthesis - by - rule \" that converts a text to speech form .","label":"Background","metadata":{},"score":"68.16371"}{"text":"[ 0069 ] .Referring to FIG .3 , the 66 implements a dictionary of all the words known to the speech center system 20 .The lexicon provides synonyms and parts of speech information for elements of the ontological description for the domain model .","label":"Background","metadata":{},"score":"68.19234"}{"text":"Prosodic Font could be visual , temporal tool to help researchers identify the success or failure of the algorithms they develop to extract prosody and affective features from speech .Prosodic fonts are becoming a social need .Writing has seldom been used as a communication medium in environments in which people are spatially co - located , sometimes even in neighboring offices .","label":"Background","metadata":{},"score":"68.229675"}{"text":"some vocal event ) during an F0 silence , nor does it allow any font parameters to slip to zero unless a silent event is of a certain minimum duration .This gives the font a visual continuity across phrases , smoothing out the abrupt scalar effect of introducing a very short - lived zero into the font parameters .","label":"Background","metadata":{},"score":"68.239426"}{"text":"I share these without qualification .Just as in speech generation , it is difficult to know what is normal .Recognizing a font as belonging within the domain of normality allows one to recognize when a font is angry or excited .","label":"Background","metadata":{},"score":"68.29727"}{"text":"The speech dialogue system of claim 13 , wherein said output means outputs said visual response before said speech response is outputted .A method of speech dialogue between a human user and a speech dialogue system , comprising the steps of : . understanding a semantic content of an input speech from a user ; . making a semantic content determination of a response output according to said semantic content of said input speech ; . generating a speech response and a visual response according to said response output ; and . outputting to said user said speech response and said visual response .","label":"Background","metadata":{},"score":"68.31853"}{"text":"The speech dialogue system of claim 13 , wherein said output means outputs said visual response before said speech response is outputted .A method of speech dialogue between a human user and a speech dialogue system , comprising the steps of : . understanding a semantic content of an input speech from a user ; . making a semantic content determination of a response output according to said semantic content of said input speech ; . generating a speech response and a visual response according to said response output ; and . outputting to said user said speech response and said visual response .","label":"Background","metadata":{},"score":"68.31853"}{"text":"Rhythm in speech is focused upon duration patterns .Finding duration patterns implicitly involves knowing the onset and offset of any given physical feature .Determining the onset and offset of speech is difficult due to uncontrollable recording conditions and the continuity of the breath involved in producing sound .","label":"Background","metadata":{},"score":"68.33271"}{"text":"The speech dialogue system of claim 13 , wherein the output means outputs the visual response before the speech response is outputted .A method of speech dialogue between a human user and a speech dialogue system , comprising the steps of : . determining a response output according to the input speech ; . generating a speech response and a visual response according to the response output ; and . outputting the speech response and the visual response generated to the user .","label":"Background","metadata":{},"score":"68.33384"}{"text":"claim 9 , further including a step : transferring said emotion modeler in electronic form to a client device or a server device .The method of .claim 9 further including a step : determining an emotion state of a speaker of an utterance based on said emotion modeler .","label":"Background","metadata":{},"score":"68.34553"}{"text":"As a consequence , the problem of the incomplete speech recognition due to the errors and ambiguity associated with the speech recognition in the speech dialogue system can be compensated effectively by the smooth dialogue between the system and the user .","label":"Background","metadata":{},"score":"68.38724"}{"text":"As a consequence , the problem of the incomplete speech recognition due to the errors and ambiguity associated with the speech recognition in the speech dialogue system can be compensated effectively by the smooth dialogue between the system and the user .","label":"Background","metadata":{},"score":"68.38724"}{"text":"As a consequence , the problem of the incomplete speech recognition due to the errors and ambiguity associated with the speech recognition in the speech dialogue system can be compensated effectively by the smooth dialogue between the system and the user .","label":"Background","metadata":{},"score":"68.38724"}{"text":"( d ) synthesizing speech from said prosodic parameter string containing said controlled prosodic parameter and outputting a synthetic speech message .Description .BACKGROUND OF THE INVENTION .The present invention relates to a method and apparatus for editing / creating synthetic speech messages and a recording medium with the method recorded thereon .","label":"Background","metadata":{},"score":"68.39034"}{"text":"FSM technology is usually found in limited domain environments .This DM must be an agent that monitors the execution of dialogue strategies and is able to change plans as unplanned events occur .In general , the dialog manager for a tutorial type domain must interweave high - level tutorial planning with adaptive on - the - fly plans .","label":"Background","metadata":{},"score":"68.392525"}{"text":"In various other exemplary embodiments according to this invention , the predictive models of discourse functions model are used to refine the discourse level segmentation of the natural language speech .For example , as shown in .FIG .5 , the first exemplary training phrase \" Here 's a new email .","label":"Background","metadata":{},"score":"68.445526"}{"text":"A speech dialogue system , comprising : . speech understanding means for understanding a semantic content of an input speech from a user ; . response output means for outputting a system response according to said semantic content of said input speech understood by said speech understanding means ; and .","label":"Background","metadata":{},"score":"68.48929"}{"text":"A speech dialogue system , comprising : . speech understanding means for understanding a semantic content of an input speech from a user ; . response output means for outputting a system response according to said semantic content of said input speech understood by said speech understanding means ; and .","label":"Background","metadata":{},"score":"68.48929"}{"text":"Boyce , S. ( 2000 ) .Natural Spoken Dialogue Systems for Telephony Applications .Communications of the ACM ., Vol .43 , No . 9 , pp .29 - 34 .Business Week On - line , Web Training Explodes , May 22 , 2000 .","label":"Background","metadata":{},"score":"68.48987"}{"text":"[ 0037 ] .The domain model 70 is a model of the \" world \" ( e.g. , concepts , or more grammatic specification , semantic specification ) of one or more speech - enabled applications 26 .In one embodiment , the domain model 70 is a foundation model including base knowledge common to many applications 26 .","label":"Background","metadata":{},"score":"68.49179"}{"text":"15A , so as to obtain the semantic response representation shown in FIG .15C. Then , at the step S123 , the appropriate response output is outputted from the response generation unit 18 .In this case , the speech response of \" Let me confirm .","label":"Background","metadata":{},"score":"68.50575"}{"text":"15A , so as to obtain the semantic response representation shown in FIG .15C. Then , at the step S123 , the appropriate response output is outputted from the response generation unit 18 .In this case , the speech response of \" Let me confirm .","label":"Background","metadata":{},"score":"68.50575"}{"text":"a processor for : . determining prosodic features associated with speech utterances in the training corpus , . determining discourse functions associated with the speech utterances in the training corpus , the discourse functions being determined automatically based on a theory of discourse analysis , and . determining a predictive model for discourse functions by associating the prosodic features determined from the speech utterances in the training corpus with the discourse functions determined from the speech utterances in the training corpus , . wherein the predictive model of discourse functions is used to predict from prosodic features of a specific recognized speech , a likelihood that speech utterances of the specific recognized speech reflect a specific discourse function , and .","label":"Background","metadata":{},"score":"68.522995"}{"text":"As such , I am not solely interested in judging Prosodic Font on aesthetic criteria reserved for static font forms .Rather , I see Prosodic Font as beginning to ask the questions that designers of future fonts - abstractly defined glyphs with algorithms of motion , transformation and interaction - will ask .","label":"Background","metadata":{},"score":"68.534546"}{"text":"Jordan , P. , Makatchev , M. , and VanLehn , K. , 2003 .Abductive Theorem Proving for Analyzing Student Explanations .In Proceedings of Artificial Intelligence in Education Conference .Karat , C. , Halverson , C. , and Karat , J. ( 1999 ) , Patterns of Entry and Correction in Large Vocabulary Continuous Speech Recognition Systems .","label":"Background","metadata":{},"score":"68.59589"}{"text":"07/978,521 , filed on Nov. 18 , 1992 , U.S. Pat .No . 5,357,596 .BACKGROUND OF THE INVENTION .Field of the Invention .The present invention relates to a speech dialogue system for realizing an interaction between a computer based system and a human speaker by utilizing various input and output techniques such as speech recognition and speech synthesis .","label":"Background","metadata":{},"score":"68.6017"}{"text":"Any prosodic coding schema must attend to the details of accentual prominence .And any application using prosody would be wise to keep the communication within context . 2.1.1.3Pitch Range .The normal speech pitch range for both male and female speakers falls between 70Hz and 450Hz , approximately .","label":"Background","metadata":{},"score":"68.61859"}{"text":"Higher level abstractions of amplitude , duration and F0 signals need to be created while maintaining the speaker dependency of the voice signal .Removing the physical pronunciation effects upon phone duration and vowel spectra from the signal would yield a more phonological understanding of speaker intent .","label":"Background","metadata":{},"score":"68.61966"}{"text":"Futura served as the aesthetic model for the Prosodic Font I designed and animated .Illustration is from Bringhurst ( 1992 , p. 241 ) .I believe that again a simplification of form based upon communication necessity is required to migrate typographic forms from static paper representations to computationally animated forms .","label":"Background","metadata":{},"score":"68.6295"}{"text":"In this way , the speech recognition engine can provide an output that is a syntactic or semantic representation of the student 's utterance and be directly used with the dialog manager .16 Bos , J. , Compilation of Unification Grammars with Compositional Semantics to Speech Recognition Packages , COLING 2002 .","label":"Background","metadata":{},"score":"68.631065"}{"text":"[ 0095 ] .The dialog manager 56 has the responsibility for deciding whether a speech center - generated response should be visible or audible .It also decides whether the response can be presented immediately , or whether it must ask permission first .","label":"Background","metadata":{},"score":"68.64366"}{"text":"Since the prosody generation rules used are based on prosodic features of speech made in a recitation tone , however , it is inevitable that the synthesized speech becomes recitation - type and hence is monotonous .In natural conversations the prosodic features of dialogue speech often significantly vary with the speaker 's mental states and intentions .","label":"Background","metadata":{},"score":"68.64795"}{"text":"Hence , it is apparent that the third embodiment of the present invention can equally be applied to various natural languages other than Japanese .EFFECT OF THE INVENTION .With the use of the relative control scheme , the entire synthetic speech need not be corrected and only required corrections are made to the result by the \" synthesis - by - rule \" only at required places - this achieves a large saving of work involved in the speech message synthesis .","label":"Background","metadata":{},"score":"68.675896"}{"text":"[ 0082 ] .Again , the real - time classifier is preferably based on the Classification and Regression Tree ( CART ) procedure , a widely used decision tree - based approach for extracting and mining patterns from raw data .","label":"Background","metadata":{},"score":"68.67665"}{"text":"Developing an architecture for Speaktomi 's Spoken Language Interactive Training System that combines spoken language interfaces , and real - time prosody modeling together with a dialog manager implemented with cognitive reasoning agents .The spoken language interface is a stable , widely deployed speech recognition engine , designed and targeted for educational applications .","label":"Background","metadata":{},"score":"68.690956"}{"text":"a prosodic feature control part for controlling and correcting the prosodic parameter string based on the extracted position information and the separated prosodic feature control command ; and . speech synthesis part for generating synthetic speech based on the corrected prosodic parameter string from the prosodic feature control part .","label":"Background","metadata":{},"score":"68.697586"}{"text":"In J. Ohala , Y. Hasegawa , M. Ohala , D. Granville and A. Bailey ( eds . ) , Proceedings of the XIVth International Congress of Phonetic Sciences .Linguistics Department , University of California , Berkeley .Phonology 15 .","label":"Background","metadata":{},"score":"68.70716"}{"text":"In a preferred embodiment , each supported application 26 has its own domain model 70 included in its associated \" application module description \" file ( with extension \" apm \" ) .[ 0057 ] .The speech center 20 has a rudimentary built - in notion of what an \" action \" is .","label":"Background","metadata":{},"score":"68.7086"}{"text":"[ 0051 ] .The function of emotion detector 100 ( .FIG .1 ) is to model the emotion state of the speaker .This model is derived preferably using the acoustic and syntactic properties of the speech utterance .","label":"Background","metadata":{},"score":"68.735794"}{"text":"Each syllable is understood as either weak or strong .Figure 17 : The linguistic description of phrasal beat and metrical duration is a direct musical analogy .The dots represent the beat , a duration - less concept .The bars represent the duration of time that occurs between each beat .","label":"Background","metadata":{},"score":"68.75271"}{"text":"The conversation manager includes a semantics analysis module and a syntax manager .004289 , 10004289 , US 2002/0095286 A1 , US 2002/095286 A1 , US 20020095286 A1 , US 20020095286A1 , US 2002095286 A1 , US 2002095286A1 , US - A1 - 20020095286 , US - A1 - 2002095286 , US2002/0095286A1 , US2002/095286A1 , US20020095286 A1 , US20020095286A1 , US2002095286 A1 , US2002095286A1 .","label":"Background","metadata":{},"score":"68.75372"}{"text":"For instance the sentences : .[ 0078 ] .\" This shape has a larger number of .\" [ 0079 ] .\" This shape has a larger number of sides than the slot .\" [ 0080 ] .","label":"Background","metadata":{},"score":"68.76515"}{"text":"The Japanese text is provided to the sentence structure analysis part 13 , wherein prosodic parameters are created by referring to the speech synthesis rule database 14 .On the other hand , in the prosodic feature control command analysis part ( or parsing part ) 15 the separated prosodic feature control commands are analyzed to extract their contents and information about their positions on the character string ( the text ) .","label":"Background","metadata":{},"score":"68.76699"}{"text":"Figure 7 : Intonation is independent enough from linguistic structure to imply distinct affective meanings even when accompanied by a non - linguistic sound - unit \" mmmhmm \" .Non - linguistic sound - units are often used as a backchannel comment from hearer to speaker , to give feedback while the other holds the conversational floor .","label":"Background","metadata":{},"score":"68.79516"}{"text":"FIG .25 is a detailed block diagram of a speech response generation unit in the response generation unit of FIG .19 .FIG .26 is a diagram for a fundamental frequency pattern model used in the speech response generation unit of FIG .","label":"Background","metadata":{},"score":"68.798325"}{"text":"FIG .25 is a detailed block diagram of a speech response generation unit in the response generation unit of FIG .19 .FIG .26 is a diagram for a fundamental frequency pattern model used in the speech response generation unit of FIG .","label":"Background","metadata":{},"score":"68.798325"}{"text":"FIG .25 is a detailed block diagram of a speech response generation unit in the response generation unit of FIG .19 .FIG .26 is a diagram for a fundamental frequency pattern model used in the speech response generation unit of FIG .","label":"Background","metadata":{},"score":"68.798325"}{"text":"FIG .25 is a detailed block diagram of a speech response generation unit in the response generation unit of FIG .19 .FIG .26 is a diagram for a fundamental frequency pattern model used in the speech response generation unit of FIG .","label":"Background","metadata":{},"score":"68.798325"}{"text":"The conversation manager 28 is also responsible for controlling when dictation functionality is active , based on the context determined by the environmental interface 32 .[ 0034 ] .[ 0034]FIG .3 represents the structure of the conversation manager 28 in a preferred embodiment .","label":"Background","metadata":{},"score":"68.802"}{"text":"The written message is individual , contextual and expressive .WHY DO THIS AT THE MEDIA LABORATORY ?Arriving at the concept of prosodic typography is a product of having been at the Media Laboratory and stepping into the midst of many streams of research that flow within the same channel here .","label":"Background","metadata":{},"score":"68.829666"}{"text":"183 - 186 , Hiroshi Matsu'ura , et al , \" A Large Vocabulary Word Recognition System Based on Syllable Recognition and non Linear Word Matching \" .ICASSP-92 , Mar. 1992 , pp .85 - 88 , Yoichi Takebayashi , et al , \" Key word Spotting in Noisy Continuous Speech Using Word Pattern Vector Subabstraction and Noise Immunity Learning . \"","label":"Background","metadata":{},"score":"68.85728"}{"text":"The speech dialogue system of claim 13 , wherein the output means outputs the visual response before the speech response is outputted .A method of speech dialogue between a human user and a speech dialogue system , comprising the steps of : . understanding an input speech from a user ; . determining a response output according to the input speech ; . generating a speech response and a visual response according to the response output ; and . outputting the speech response and the visual response generated to the user .","label":"Background","metadata":{},"score":"68.874695"}{"text":"A speech dialogue system , comprising : . speech understanding means for understanding an input speech from a user ; . dialogue management means for determining a response output content according to the input speech understood by the speech understanding means ; . response generation means for generating a speech response and a visual response according to the response output determined by the dialogue management means ; and .","label":"Background","metadata":{},"score":"68.89691"}{"text":"While this invention has been described in conjunction with the exemplary embodiments outlined above , it is evident that many alternatives , modifications and variations will be apparent to those skilled in the art .Accordingly , the exemplary embodiments of the invention , as set forth above , are intended to be illustrative , not limiting .","label":"Background","metadata":{},"score":"68.89726"}{"text":"No disfluencies ; fluent answer ; high energy .UNCERTAINTY .Disfluencies present ; additional questions .asked by the user re clarification - what is . meant etc . .DOUBT .Slower response ; heavily disfluent ; lower .energy .","label":"Background","metadata":{},"score":"68.89765"}{"text":"Creating Prosodic Font required pursuing two separate research vectors , namely , prosody and font design , and then merging these two streams together in a way that the meaning in prosody can be visualized through a temporal font design .I describe in the following section the necessary work done in prosody and in typographic design to prepare them to be merged together .","label":"Background","metadata":{},"score":"68.91562"}{"text":"However , a letterform that can internally transform its shape , weighting , width , height , curvature , color , et cetera through time is not going to have the same design technique as fonts designed for paper .The reader 's ability to feel the emotional thrust of the speaker through the Prosodic Font is not to be forgotten either .","label":"Background","metadata":{},"score":"68.954094"}{"text":"The speech dialogue system of claim 1 , wherein said response generation means generates said visual response which includes an image of a human character delivering said speech response , text data of said speech response , and a content visualizing image of a content of said speech response .","label":"Background","metadata":{},"score":"68.97571"}{"text":"BACKGROUND OF THE INVENTION .Field of the Invention .The present invention relates to a speech dialogue system for realizing an interaction between a computer based system and a human speaker by utilizing various input and output techniques such as speech recognition and speech synthesis .","label":"Background","metadata":{},"score":"68.99391"}{"text":"BACKGROUND OF THE INVENTION .Field of the Invention .The present invention relates to a speech dialogue system for realizing an interaction between a computer based system and a human speaker by utilizing various input and output techniques such as speech recognition and speech synthesis .","label":"Background","metadata":{},"score":"68.99391"}{"text":"The speech dialogue system of claim 1 , wherein the output means also outputs a visual indication for informing the user as to whether the speech dialogue system is ready to receive the input speech .The speech dialogue system of claim 1 , wherein the response generation means generates the visual response including a content visualizing image formed by pictures of objects mentioned in the speech response and a numerical figure indicating a quantity of each of the objects .","label":"Background","metadata":{},"score":"68.998825"}{"text":"BACKGROUND OF THE INVENTION .Field of Invention .This invention relates to the determination and use of prosodic information .Description of Related Art .Conventional automatic speech recognition systems compare incoming speech signal information against templates of speech signal information .","label":"Background","metadata":{},"score":"69.01137"}{"text":"The first tests I designed did not incorporate any such introduction and often the subjects expressed confusion at the lack of context they were given in the three and four second Prosodic Font files .After the training file , subjects see the three second angry file .","label":"Background","metadata":{},"score":"69.0143"}{"text":"The speech center system 20 has an explicit model of the world ( e.g. , domain model 70 ) which will serve as a foundation for language understanding and reasoning .Some of the basic concepts that the speech center system 20 models using the domain model 70 are : .","label":"Background","metadata":{},"score":"69.01973"}{"text":"It is quite likely that some of these companies will offer competitive voice - enabled e - Learning products .Clearly our proposed technology will substantially differentiate us in the tutoring and learning environments where the interactive process with students is extremely important .","label":"Background","metadata":{},"score":"69.06698"}{"text":"The I layer is used also as a layer that interprets the prosodic feature control commands of the S layer and indicates a control scheme to the P layer .The I - layer commands have a set of symbols for specifying control of one or more prosodic parameters that are control objects in the P layer .","label":"Background","metadata":{},"score":"69.110916"}{"text":"The P layer is composed mainly of prosodic parameters that are selected and controlled by the prosodic feature control commands of the I layer described next .These prosodic parameters are those of prosodic features which are used in a speech synthesis system , such as the pitch , power , duration and phoneme information for each phoneme .","label":"Background","metadata":{},"score":"69.1216"}{"text":"An accent selects out a particular word over other words , revealing the speaker 's communication intention through the relative selection , as well as the relative forcefulness of the accent .Any word , irrespective of syntactical class , can bear an accent , depending on the speaker 's intention .","label":"Background","metadata":{},"score":"69.164505"}{"text":"[0165 ] .We will source the software for the CARMEL framework and follow the procedure to convert it to an OAA agent .Similarly , we will convert the CARMEL deep language understanding framework to a software agent running within the OAA environment .","label":"Background","metadata":{},"score":"69.3125"}{"text":"( a ) extracting from the text a prosodic parameter string of speech synthesized by rules ; .( c ) synthesizing speech from the prosodic parameter string containing the corrected prosodic parameter and for outputting a synthetic speech message .A synthetic speech message editing apparatus according to the second aspect of the present invention comprises : . syntactic structure analysis means for extracting from the text a prosodic parameter string of speech synthesized by rules ; . synthetic speech generating means for synthesizing speech from the prosodic parameter string containing the corrected prosodic parameter and for outputting a synthetic speech message .","label":"Background","metadata":{},"score":"69.34645"}{"text":"6.1 SYSTEM DESIGN .The Prosodic Font uses computationally generated and manually provided textual descriptions of parameters that would appear in a real - time Prosodic Font system .In this way , it sidesteps the lack of existing real - time prosody recognition .","label":"Background","metadata":{},"score":"69.43358"}{"text":"If the response is a question or answer , or other message , to the user , then the procedure 100 proceeds to step 114 .[ 0100 ] .The text string , for example , may be a question for the user , answer to a user 's question , an announcement for the user ( e.g. , completion of some event ) , or other message for the user .","label":"Background","metadata":{},"score":"69.46163"}{"text":"@Asking ] is a prosodic feature control command of the S layer ; in this instance , it has a combination of prosodic feature control commands as prosodic parameter of speech as in the case of \" praying \" .The prosodic feature control command information fed to the command analysis part 15 is processed to extract therefrom the prosodic feature control commands and the information about their positions in the text .","label":"Background","metadata":{},"score":"69.4628"}{"text":"It is this market for improved tools and software that Speaktomi will seek to penetrate .[ 0180 ] .While speech technology may be considered a small component of a training solution , it is a critical user interface and interaction component that is extremely valuable .","label":"Background","metadata":{},"score":"69.46711"}{"text":"Computer readable storage medium comprising : computer readable program code embodied on the computer readable storage medium , the computer readable program code usable to program a computer to determine a predictive model for discourse functions comprising the steps of : . determining a training corpus of speech utterances ; . determining discourse functions associated with speech utterances in the training corpus of speech utterances , the discourse functions being determined automatically based on a theory of discourse analysis ; . determining prosodic features associated with the speech utterances in the training corpus of speech utterances ; and . determining at least one predictive model of discourse functions by associating the prosodic features with the discourse functions , . wherein the predictive model of discourse functions is used to predict from prosodic features of a specific recognized speech , a likelihood that speech utterances of the specific recognized speech reflect a specific discourse function , and .","label":"Background","metadata":{},"score":"69.592636"}{"text":"The input information is processed by separating means to separate it into the Japanese text and the prosodic feature control commands ( S 4 ) .This separation is performed by determining whether respective codes belong to the prosodic feature control commands or the Japanese text through the use of the MSCL description scheme and a wording analysis scheme .","label":"Background","metadata":{},"score":"69.651276"}{"text":"[ 0060 ] .[ 0060]FIG .4 is an illustration of a domain model 70 and a process for generating a grammatic specification 90 .In a preferred embodiment , the domain model 70 also includes an ontology 64 ( i.e. , ontological description ) , lexicon 66 , and syntax definitions 72 ( e.g. , templates ) .","label":"Background","metadata":{},"score":"69.66849"}{"text":"Declination : construct or intrinsic feature of speech pitch ?Phonetica 39 , 254 - 273 .Cutler , A. & Swinney , D. ( 1987 ) .Prosody and the development of comprehension .Journal of Child Language 14 , 145 - 167 .","label":"Background","metadata":{},"score":"69.67886"}{"text":"The \" 0.15 \" value indicates the duration of the silence preceding the speech utterance .The boundary tone portion 1060 contains the value \" 95 \" .The \" 95 \" value indicates the boundary tone associated with the speech utterance .","label":"Background","metadata":{},"score":"69.68942"}{"text":"Prosodic Font uses low- to mid - level signal characterizations of voice in order to represent individual differences between speakers .However , these events are understood as linear sequences of meaningful events in order to capture the emotional intention of the song and rhythm apart from the pronunciation requirements of particular words .","label":"Background","metadata":{},"score":"69.69206"}{"text":"Steven Abney , Partial Parsing via Finite - State Cascades .J. of Natural Language Engineering , 2(4 ) : 337 - 344 .Thomas K. Landauer , Peter W. Foltz , and Darrell Laham .An introduction to latent semantic analysis , .","label":"Background","metadata":{},"score":"69.69368"}{"text":"In the second section of the course , we will examine how sounds are organized into larger rhythmic units such as syllables , stress feet , and prosodic phrases .We will analyze these grouping patterns within the formal framework of Optimality Theory , and explore their bases and effects as revealed in experimental studies .","label":"Background","metadata":{},"score":"69.72667"}{"text":"The fine - lined font indicates the introduction of the S - layer commands .The heights of the characters indicate the results of variations in height according to the S - layer commands .FIG .11 depicts an example of the procedure described above .","label":"Background","metadata":{},"score":"69.728516"}{"text":"When patients with right - hemisphere damage , the brain location theorized to be the center of emotion responses , were asked to form questions and statements , and happy and sad speech , they produced monotone speech in all cases ( B. Shapiro and Danly , 1985 ) .","label":"Background","metadata":{},"score":"69.73005"}{"text":"Ploetzner , R. & VanLehn , K. ( 1997 ) .The acquisition of informal physics knowledge during formal physics .Poison , M. , & Richardson , J. ( Eds . )Foundations of intelligent tutoring systems .Hillsdale , N.J. : Erlbaum Press .","label":"Background","metadata":{},"score":"69.7303"}{"text":"With this control method , it is possible to make six kinds of modifications ( a ) to ( f ) as listed below , the modifications being indicated by the broken - line patterns a , b , c , d , e and f in FIG .","label":"Background","metadata":{},"score":"69.75137"}{"text":"A Natural Language Engine 190 facilitates structuring the query to database 188 .After a matching answer to the user 's question is found , the former is transmitted in text form across data link 160 B , where it is converted into speech by text to speech engine 159 , and thus expressed as oral feedback by animated character agent 157 .","label":"Background","metadata":{},"score":"69.75925"}{"text":"Each application agent as shown can be interfaced to an existing legacy application such as a speech recognition engine or a library via a wrapper that calls a pre - existing application programming interface ( API ) .Meta - agents assist the facilitator agent in coordinating their activities .","label":"Background","metadata":{},"score":"69.80185"}{"text":"Among the questions we will address will be the following : .Grading :The grade will be based on homework assignments ( roughly on a week ) , and two tests ( one at the end of each section of the course ) .","label":"Background","metadata":{},"score":"69.86536"}{"text":"Listening closely to musical structure and how different instruments interact within a short musical piece is not a common intellectual exercise .Few people have experience in listening for musical relationships and how to make judgments about them .RELATED WORK .","label":"Background","metadata":{},"score":"69.867935"}{"text":"30A , 30B , 31A , and 31B. FIG .30A is a timing chart for an initial greeting situation .In this case , as there is no order taken yet , there is no content visualizing image display .At a timing t0 , the text data for the initial greeting words are displayed .","label":"Background","metadata":{},"score":"69.885315"}{"text":"30A , 30B , 31A , and 31B. FIG .30A is a timing chart for an initial greeting situation .In this case , as there is no order taken yet , there is no content visualizing image display .At a timing t0 , the text data for the initial greeting words are displayed .","label":"Background","metadata":{},"score":"69.885315"}{"text":"30A , 30B , 31A , and 31B. FIG .30A is a timing chart for an initial greeting situation .In this case , as there is no order taken yet , there is no content visualizing image display .At a timing t0 , the text data for the initial greeting words are displayed .","label":"Background","metadata":{},"score":"69.885315"}{"text":"30A , 30B , 31A , and 31B. FIG .30A is a timing chart for an initial greeting situation .In this case , as there is no order taken yet , there is no content visualizing image display .At a timing t0 , the text data for the initial greeting words are displayed .","label":"Background","metadata":{},"score":"69.885315"}{"text":"11 is an exemplary data structure for storing speech utterance prosody information according to this invention .The exemplary data structure for storing prosody information 1070 is comprised of an identifier portion 1010 ; a discourse function portion 1020 ; an initial frequency portion 1030 , a pitch variation portion 1040 ; a preceding silence portion 1050 and a boundary tone portion 1060 .","label":"Background","metadata":{},"score":"69.90765"}{"text":"F0 serves as an indicator of emphasis , motion , emotion , and focus , but not presence .If the Tilt system were to be of more help in corresponding to actual phonological linguistic events , it would have to couple with , at the very least , a measure of amplitude during the syllable 's vowel sound .","label":"Background","metadata":{},"score":"69.9547"}{"text":"The method of claim 21 , further comprising the step of detecting a state of the user , and wherein the determining step determines the response output by taking the state of the user detected at the detecting step into account .","label":"Background","metadata":{},"score":"69.97579"}{"text":"The method of claim 21 , further comprising the step of detecting a state of the user , and wherein the determining step determines the response output by taking the state of the user detected at the detecting step into account .","label":"Background","metadata":{},"score":"69.97579"}{"text":"The speech dialogue system of claim 5 , wherein the response generation means generates the speech response incorporating a speech characteristic corresponding to the movement and the facial expression of the human character .The speech dialogue system of claim 6 , wherein the speech characteristic of the speech response includes at least one of an emotional expression , an intentional expression , and an intonation .","label":"Background","metadata":{},"score":"69.976105"}{"text":"[ 0035 ] .The message hub 68 includes message queue and message dispatcher submodules .The message hub 68 provides a way for the various modules 30 , 32 , 34 , 36 , 40 , 42 , and 50 through 64 to communicate asynchronous results .","label":"Background","metadata":{},"score":"69.998566"}{"text":"15A , so as to obtain the semantic response representation shown in FIG .15C. Then , at the step S123 , the appropriate response output is outputted from the response generation unit 13 .In this case , the speech response of \" Let me confirm .","label":"Background","metadata":{},"score":"70.02701"}{"text":"15A , so as to obtain the semantic response representation shown in FIG .15C. Then , at the step S123 , the appropriate response output is outputted from the response generation unit 13 .In this case , the speech response of \" Let me confirm .","label":"Background","metadata":{},"score":"70.02701"}{"text":"a prosodic feature control part for controlling and correcting said prosodic parameter string based on said extracted position information and said separated prosodic feature control command ; and . speech synthesis part for generating synthetic speech based on said corrected prosodic parameter string from said prosodic feature control part .","label":"Background","metadata":{},"score":"70.02774"}{"text":"Assignments will be problem sets and lab assignments .Grading PolicyThe grade will be based on homework assignments ( roughly one a week ) , and a test at the end of each of the two sections .TextsThere is no textbook for this course .","label":"Background","metadata":{},"score":"70.03046"}{"text":"A computer method for analyzing spoken utterances comprin model .A computer program propagated signal product comprising : . a computer usable propagated medium for analyzing spoken utterances comprising common language words in a speech - enabled environment ; and .a set of computer program instructions embodied on the computer usable propagated medium , including instructions to : . define a grammatic specification suitable for processing the spoken utterances based on a domain model for a speech - enabled application ; . process a recognition message , based on one of the spoken utterances recognized by a speech engine , to produce an initial semantic representation of the recognized spoken utterance based on the grammatic specification and the domain model ; and . provide a set of propositions that represent the recognized spoken utterance , the set of propositions based on the initial semantic representation and the domain model .","label":"Background","metadata":{},"score":"70.04836"}{"text":"What rules of optical proportion will govern glyphs that change their form and proportion over time ?At this point in Prosodic Font development , this question may only be asked , but not answered .A sophisticated grid system for proportioning the vertical space of a font is well understood ( see figure 23 below ) .","label":"Background","metadata":{},"score":"70.13095"}{"text":"Training of emotion modelers is also known as set out for example in the following also incorporated by reference herein : . L. Breiman , J. H. Friedman , R. A. Olshen , and C. J. Stone .Classification and Regression Trees , Chapman & Hall , New York , 1984 .","label":"Background","metadata":{},"score":"70.14064"}{"text":"Here , the user 's speech speed is obtained as an average number of moras per second as follows .Thus , the semantic response representation obtained in the dialogue management unit 12 is outputted to the response generation unit 13 along with the user 's speech speed and the likelihood of each keyword used in the semantic response representation in a form as shown in FIG .","label":"Background","metadata":{},"score":"70.16766"}{"text":"[0054 ] .file is a patient of print .[ 0055 ] .and commands such as \" print this file \" would be available with no further syntax specification required .[ 0056 ] .The description of a speech - enabled application 26 can also introduce additional grammatical constructs that provide more specialized sentence forms for the new classes introduced .","label":"Background","metadata":{},"score":"70.171776"}{"text":"Forbes , Special E - Learning Section , referencing Corporate E - Learning : Exploring a New Frontier by Hambrecht , W.R. & Company , March 2000 .FrameNet : Theory and Practice .FRG : Institute for Science Education .Gildea D and Jurafsky D. , 2002 .","label":"Background","metadata":{},"score":"70.17397"}{"text":"At server 180 , the partially processed speech signal data is handled by a server - side SRE 182 , which then outputs recognized speech text corresponding to the user 's question .Based on this user question related text , a text - to - query converter 184 formulates a suitable query that is used as input to a database processor 186 .","label":"Background","metadata":{},"score":"70.18394"}{"text":"Each mark , each letter would be signed by the author 's current emotional tone of voice .The concept of voice has been used to symbolize the externalization of one 's internal state .To have voice within feminist and psychoanalytic literature is to have power , agency and character .","label":"Background","metadata":{},"score":"70.20985"}{"text":"The results of investigations on mental influences by each control method will be described .Listed below are mental attitudes ( non - verbal information ) that listeners took in from synthesized voices obtained by modifying a Japanese word utterance according to the above - mentioned control methods ( a ) to ( f ) .","label":"Background","metadata":{},"score":"70.21942"}{"text":"Prosodic Font contributes to the field of speech generation by developing discrete textual descriptions of emotionally charged segments of speech .This work points to prosodic features of interest , and how one might describe them in text .Prosodic Font could also be useful to researchers in prosody and speech as a tool to help recognize and identify prosodic and voice quality variation .","label":"Background","metadata":{},"score":"70.223"}{"text":"Portrayal of voice quality is an important issue to identity and recognition of an individual , although the current implementation of Prosodic Font did not incorporate a visual interpretation .Figure 15 : The analysis of this phrase shows the kind of uneven , and \" spattered \" F0 results the tracker yields during creaky voice events .","label":"Background","metadata":{},"score":"70.22304"}{"text":"( d ) converting the modification information of the prosodic parameter to character conversion information such as the position , size , typeface and display color of each character in the text ; and .( e ) converting the characters of the text based on the character conversion information and displaying them accordingly .","label":"Background","metadata":{},"score":"70.24617"}{"text":"The typography is surprisingly effective at allowing a reader to hear a distinctive , unique voice and character while reading the autobiography .This work was no small inspiration to me in thinking about Prosodic Font .FUTURE WORK .Since Prosodic Font work has just begun , there is little but future work .","label":"Background","metadata":{},"score":"70.25186"}{"text":"In F. Katamba ( ed . )Bantu Phonology and Morphology .LINCOM EUROPA , Munich , 69 - 92 .Studies in African Linguistics 23 .Linguistic Inquiry 22 .Linguistic Inquiry 22 .1990 : Tone and the Structure of Words in Shona ( Outstanding Dissertations in Linguistics ) .","label":"Background","metadata":{},"score":"70.25601"}{"text":"Furthermore the emotion detection / prosodic analysis operations can be distributed across the client device and server device on a case - by - case basis to achieve a real - time performance , and configured during an initialization procedure ( i.e. , such as within an MRCP type protocol ) .","label":"Background","metadata":{},"score":"70.25896"}{"text":"FIGS . 27A-27F are diagrams of a fundamental frequency pattern used in the speech response generation unit of FIG .25 , without and with a modification for generating a speech response with a joyful expression .FIGS .28A-28F are diagrams of a fundamental frequency pattern used in the speech response generation unit of FIG .","label":"Background","metadata":{},"score":"70.26929"}{"text":"FIGS . 27A-27F are diagrams of a fundamental frequency pattern used in the speech response generation unit of FIG .25 , without and with a modification for generating a speech response with a joyful expression .FIGS .28A-28F are diagrams of a fundamental frequency pattern used in the speech response generation unit of FIG .","label":"Background","metadata":{},"score":"70.26929"}{"text":"The dialogue between the system and the user is managed by controlling transitions between user states during which the input speech is to be entered and system states during which the system response is to be outputted .The understanding of a semantic content of input speech from a user is made by detecting keywords in the input speech , with the keywords to be detected in the input speech limited in advance , according to a state of a dialogue between the user and the system .","label":"Background","metadata":{},"score":"70.27956"}{"text":"0105 ] .One of the overarching goals behind this research is embodied in our design approach which emphasizes the use of rapid and flexible prototyping natural language tools and environments such as the CARMEL 4 language understanding framework and the Open Agent Architecture environment .","label":"Background","metadata":{},"score":"70.28156"}{"text":"This indicates the variation in the pitch for the speech utterance .The exemplary data structure for storing speech utterance prosody information 1070 contains the value \" 0.10 \" in the preceding silence portion 1050 .The \" 0.10 \" value indicates the duration of any silence preceding the speech utterance .","label":"Background","metadata":{},"score":"70.28352"}{"text":"Meanwhile , it has become popular to use linguistic data of characters instead of the numerical data ordinarily used in a conventional computer .As for the visual data , a capacity to handle the monochromatic image data ordinarily used in a conventional computer is expanded to deal with color images , animated images , three dimensional graphic images , and dynamic images .","label":"Background","metadata":{},"score":"70.292946"}{"text":"Meanwhile , it has become popular to use linguistic data of characters instead of the numerical data ordinarily used in a conventional computer .As for the visual data , a capacity to handle the monochromatic image data ordinarily used in a conventional computer is expanded to deal with color images , animated images , three dimensional graphic images , and dynamic images .","label":"Background","metadata":{},"score":"70.292946"}{"text":"Meanwhile , it has become popular to use linguistic data of characters instead of the numerical data ordinarily used in a conventional computer .As for the visual data , a capacity to handle the monochromatic image data ordinarily used in a conventional computer is expanded to deal with color images , animated images , three dimensional graphic images , and dynamic images .","label":"Background","metadata":{},"score":"70.292946"}{"text":"Meanwhile , it has become popular to use linguistic data of characters instead of the numerical data ordinarily used in a conventional computer .As for the visual data , a capacity to handle the monochromatic image data ordinarily used in a conventional computer is expanded to deal with color images , animated images , three dimensional graphic images , and dynamic images .","label":"Background","metadata":{},"score":"70.292946"}{"text":"A speaker model would also help in converting vocal sound to proportions within the available graphical space .Understanding the limits of vocal parameters is important to making the font visible and well - placed within a display system .Prosodic Font is unable to predict a speaker 's pitch range prior to the speaker talking , or even across different emotions .","label":"Background","metadata":{},"score":"70.309814"}{"text":"3.1 Typographic Style 3.1.1 Perception of Glyph Balance and Proportion .Prosodic Font Design .Typographic Design System .4.1 Four Stroke System 4.2 Expanded Stroke System : Consecutiveness / Simultaneity and Dependence / Independence .Prosodic Features . 5.1 Speech Corpus Development 5.2 Labeling Prosody in Speech 5.2.1 Tilt Phonological - Phonetic System 5.2.2 Linguistic Labeling 5.2.3 Phonemic Realization 5.2.4 Voice Quality .","label":"Background","metadata":{},"score":"70.33758"}{"text":"2.3.2.1The TILT Model .Figure 18 : The Tilt model is based upon a stream of phonological events that are themselves stylized interpretations of the actual F0 curve .TILT generates a single number that represents the rise and fall of a pitch accent .","label":"Background","metadata":{},"score":"70.347725"}{"text":"[ 0027 ] .[ 0028 ] .In this fashion , an emotion modeler is adapted to be used in an emotion detector distributed between a client device and a server device .[ 0029 ] .In certain preferred embodiments visual cues are also used to elicit the distinct emotion states .","label":"Background","metadata":{},"score":"70.36246"}{"text":"As an accompaniment to discourse structure , pitch range expands and contracts , raises and depresses .When speakers begin a new topic , their pitch range expands ; conversely , when speakers are drawing to the end of an intonational phrase , their pitch range compresses .","label":"Background","metadata":{},"score":"70.380066"}{"text":"Typographic History describes the historical features of typographic space and perceptual issues of font design .I discuss the migration of some of these historical graphic features to temporal design , and introduce new features .PROSODY AND AFFECT .The current task of speech recognition is only to decode the orthographic representation of phonetic sound units .","label":"Background","metadata":{},"score":"70.42401"}{"text":"Advances in role and reference grammar .Amsterdam John Benjamins . P166 A34 .Viennot , L. ( 1979 ) , Spontaneous reasoning in elementary dynamics , European Journal of Science .Walker , M. , et al . , DARPA Communicator Evaluation : Progress from 2000 to 2001 , ICSLP-2002 Proceedings , 7th International Conference On Spoken Language Processing , September 2002 , Denver , Colo. , USA .","label":"Background","metadata":{},"score":"70.44954"}{"text":"Figure 3 : The intonation , or tune , of the utterance \" He wo n't be going will he \" is represented here as a continuously curved line .Intonation occurs in units called intonational phrases .The intonational phrase can be distinguished by the presence of an ending tone that signals its closure and by a duration of silence that follows the utterance .","label":"Background","metadata":{},"score":"70.471756"}{"text":"The course will be divided into three parts : the first on syllables , the second on stress , and the third on tone and intonation .The grade for the course will be based on quasi - weekly homework assignments , and three small research projects ( one for each section of the course ) .","label":"Background","metadata":{},"score":"70.4818"}{"text":"Tilt events are joined into an fundamental frequency curve by Connection events , and straight line F0 interpolations between Accents and Silences .To synthesize an F0 contour from tilt parameters , first the rise and fall parameters of both amplitude ( A ) and duration ( D ) must be calculated , and then the F0 curve for each rise and fall portion can be reconstructed .","label":"Background","metadata":{},"score":"70.48952"}{"text":"In contrast , phonology believes that prosody can be extracted from any particular pitch as a system of pitch contrasts .It is doubtful that pitch target levels are the sole , or even central , point of prosodic meaning .Therefore , Prosodic Font might use prosodic variation systematically within a visual spatial medium to convey prosodic meaning .","label":"Background","metadata":{},"score":"70.53051"}{"text":"But in terms of speaking Prosodic Font , syntax emerges as a by - product of a speaker using proper grammatical forms .Syntax , per se , does not affect the visuals .Prosodic Font assumes that people intuitively understand intonation as a relative system of contrasts and similarities , and that people will still understood the semantic intention of prosody if the parameters that comprise its system are mapped onto a completely alternative medium .","label":"Background","metadata":{},"score":"70.53523"}{"text":"[ 0087 ] .Class Thing-1 Column .[ 0088 ] .Patient Action-1 Thing-1 .[ 0089 ] .Destination Action-1 Green .[ 0090 ] .The set of triples generated from the sentence serve as input to the reasoning facility 52 , which is described below .","label":"Background","metadata":{},"score":"70.573166"}{"text":"Each rule represents a valid inference step that the reasoning facility 52 can take in the associated domain 70 .A rule states that when the condition propositions are satisfied , then the action propositions can be concluded .Both condition and action propositions can contain embedded script function calls , allowing the rules to interact with both external applications 26 and other speech center 20 components .","label":"Background","metadata":{},"score":"70.57646"}{"text":"Based on the above experimental results , the speaker 's mental states that examinees took in were investigated in the case where the modifications of the pitch contour and the lengthening and shortening of the duration were used in combination .Seven examinees were asked to freely write the speaker 's mental states that they associated with the afore - mentioned Japanese word utterance \" shikatanai . \"","label":"Background","metadata":{},"score":"70.580765"}{"text":"After the recognized text has been optionally verified , a theory of discourse analysis is applied to the verified recognized text to determine the discourse functions .For example , in various exemplary embodiments according to this invention , subordinations , speech repairs , data , commands and/or other discourse functions within the recognized text are determined .","label":"Background","metadata":{},"score":"70.59099"}{"text":"Yet there is reason to preserve some of the exactitude of phonetics in order to preserve varying voice ranges , unusual forceful phonetic noises , and temporal meter .In large , Prosodic Font is in search of a marriage of phonetics and phonology .","label":"Background","metadata":{},"score":"70.621735"}{"text":"Yet , writing email is done differently than writing on paper has been done ( Ferrara , Brunner , and Whittemore , 1991 ) .The email register ( i.e. \" tone of voice \" ) is decidedly more informal , even shorthand - ish , than writing that is used in other written contexts .","label":"Background","metadata":{},"score":"70.62261"}{"text":"Now , the above described operation of the dialogue management unit 12 will be illustrated by using a concrete example .Here , an example to be used is a case in which the dialogue management unit 12 obtained the semantic response representation as shown in FIG .","label":"Background","metadata":{},"score":"70.635605"}{"text":"Now , the above described operation of the dialogue management unit 12 will be illustrated by using a concrete example .Here , an example to be used is a case in which the dialogue management unit 12 obtained the semantic response representation as shown in FIG .","label":"Background","metadata":{},"score":"70.635605"}{"text":"Now , the above described operation of the dialogue management unit 12 will be illustrated by using a concrete example .Here , an example to be used is a case in which the dialogue management unit 12 obtained the semantic response representation as shown in FIG .","label":"Background","metadata":{},"score":"70.635605"}{"text":"Now , the above described operation of the dialogue management unit 12 will be illustrated by using a concrete example .Here , an example to be used is a case in which the dialogue management unit 12 obtained the semantic response representation as shown in FIG .","label":"Background","metadata":{},"score":"70.635605"}{"text":"Please say it again .\" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the regretful facial expression as shown in FIG .","label":"Background","metadata":{},"score":"70.63762"}{"text":"Please say it again .\" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the regretful facial expression as shown in FIG .","label":"Background","metadata":{},"score":"70.63762"}{"text":"Please say it again .\" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the regretful facial expression as shown in FIG .","label":"Background","metadata":{},"score":"70.63762"}{"text":"Please say it again .\" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the regretful facial expression as shown in FIG .","label":"Background","metadata":{},"score":"70.63762"}{"text":"Meanwhile , the human character image starts the lip motion along the output of the speech response of \" Your orders are two hamburgers , one cheese burger , and three coffees , right ? \" between the timings t0 and t4 .","label":"Background","metadata":{},"score":"70.685646"}{"text":"Meanwhile , the human character image starts the lip motion along the output of the speech response of \" Your orders are two hamburgers , one cheese burger , and three coffees , right ? \" between the timings t0 and t4 .","label":"Background","metadata":{},"score":"70.685646"}{"text":"Meanwhile , the human character image starts the lip motion along the output of the speech response of \" Your orders are two hamburgers , one cheese burger , and three coffees , right ? \" between the timings t0 and t4 .","label":"Background","metadata":{},"score":"70.685646"}{"text":"Meanwhile , the human character image starts the lip motion along the output of the speech response of \" Your orders are two hamburgers , one cheese burger , and three coffees , right ? \" between the timings t0 and t4 .","label":"Background","metadata":{},"score":"70.685646"}{"text":"Pitch - Based Emphasis Detection for Segmenting Speech Recordings .In Proceedings of the International Conference on Spoken Language Processing , 1931 - 1934 .Beckman , M. ( 1986 ) .Stress and Non - Stress Accent .Dordrecht , Holland / Riverton : Foris Publications .","label":"Background","metadata":{},"score":"70.711"}{"text":"From left to right the numbers are : exact ending time in the speech file , a color specification used for viewing this file in Entropic 's xwaves software , event type , and the absolute F0 that begins the event .","label":"Background","metadata":{},"score":"70.77149"}{"text":"The method of claim 34 , wherein said full speech response mentions all of said information items to be confirmed while said simplified speech response does not directly mention said information items to be confirmed .The method of claim 35 , wherein said simplified speech response contains a demonstrative pronoun to refer to said visual response .","label":"Background","metadata":{},"score":"70.778244"}{"text":"The method of claim 34 , wherein said full speech response mentions all of said information items to be confirmed while said simplified speech response does not directly mention said information items to be confirmed .The method of claim 35 , wherein said simplified speech response contains a demonstrative pronoun to refer to said visual response .","label":"Background","metadata":{},"score":"70.778244"}{"text":"Some problems for case grammar ' .In : O'Brien , R. J. ( ed . )Report of the 22 nd Annual Round Table Meeting on Linguistics and Language Studies .Washington : Georgetown UP .Fillmore , Charles J. ( 1976 ) : Frame semantics and the nature of language ; Annals of the New York Academy of Sciences : Conference on the Origin and Development of Language and Speech , Volume 280 ( pp .","label":"Background","metadata":{},"score":"70.842476"}{"text":"For example , the recorded speech concerns an evening of great satisfaction , and the voice is breathy , low , soft and slow .The Prosodic Font produced undulates through the words like the ocean mentioned in the speech .In this satisfied speech , exhalations and inhalations rise up often and gently in between intonational phrases .","label":"Background","metadata":{},"score":"70.84363"}{"text":"The base classes of the domain model have built - in meaning , in that the system can have a model about what kinds of entities populate the different built - in classes , and what kinds of operations can be performed upon them .","label":"Background","metadata":{},"score":"70.859665"}{"text":"Additionally , by interfacing our system to Macromedia 's widely - used authoring tools - Authorware and Director - our spoken language ITS will provide a direct and effective mechanism whereby the technology could be rapidly adopted by the existing educational customer base .","label":"Background","metadata":{},"score":"70.96016"}{"text":"claim 1 , wherein said operations are distributed across the client device and server device on a case - by - case basis .The method of . claim 1 further including a parts - of - speech analyzer for identifying a first set of emotion cues based on evaluating a syntax structure of the utterance .","label":"Background","metadata":{},"score":"70.97062"}{"text":"Typographic Performance : Continuous Design Solutions as Emergent Behaviors of Active Agents .PhD Dissertation , Massachusetts Institute of Technology , Media Laboratory , February .Ishizaki , S. ( 1997 ) .Kinetic Typography : Prologue .In Digital Communication Design Forum at Tokyo Design Center .","label":"Background","metadata":{},"score":"70.97548"}{"text":"claim 1 , in which the prosodic features occur in at least one of a location : preceding , within and following the associated discourse function .The method of .claim 1 , in which the prosodic features are encoded within a prosodic feature vector .","label":"Background","metadata":{},"score":"70.99086"}{"text":"The initial plan for Speaktomi is to work with e - Learning educational authoring tools providers to integrate its technology into their platforms .License revenue will be focused on between 2 - 5 % of the ASP of the finished product or tool - client based tools and support , and server - based products for the corporate environment with competitive pricing . A.8.4 .","label":"Background","metadata":{},"score":"71.06413"}{"text":"The topic of the research can be in any area of linguistics , and involved any particular language .This is an introduction to the study of speech sounds - how they are produced , what they sound like , what their physical properties are , and how listeners identify them .","label":"Background","metadata":{},"score":"71.08011"}{"text":"The response sentence generation unit 131 generates the response sentence text data and the response sentence structure data for the speech response according to the semantic response representation and the human character image information supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"71.10113"}{"text":"The response sentence generation unit 131 generates the response sentence text data and the response sentence structure data for the speech response according to the semantic response representation and the human character image information supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"71.10113"}{"text":"The response sentence generation unit 131 generates the response sentence text data and the response sentence structure data for the speech response according to the semantic response representation and the human character image information supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"71.10113"}{"text":"The response sentence generation unit 131 generates the response sentence text data and the response sentence structure data for the speech response according to the semantic response representation and the human character image information supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"71.10113"}{"text":"By introducing prosodic expression indications into textual written form , text as a medium may develop greater communicative richness .A prosodic font would be situated in the continuum of rich mediums between telephony ( voice alone ) and textual communication as we currently understand it .","label":"Background","metadata":{},"score":"71.107315"}{"text":"6 shows a second exemplary sentence 600 annotated according to this invention .The second exemplary sentence 600 is comprised of a command portion 610 and a content portion 620 .The command portion 610 includes the recognized speech utterance 611 \" And the body is \" .","label":"Background","metadata":{},"score":"71.14306"}{"text":"Similarly , exhalation can be quick and forceful or it can be a gentle ( or exasperated ! ) sigh .These non - linguistic vocal events are revealing of emotional state and should not be eliminated from representation within a prosodic font .","label":"Background","metadata":{},"score":"71.147705"}{"text":"[ 0094 ] .The dialog manager 56 serves as a traffic cop for information flowing back and forth between the reasoning facility 52 and the user .Questions generated by the reasoning facility 52 as well as answers derived to user questions and unsolicited announcements by the speech center system 20 are all processed by the dialog manager 56 .","label":"Background","metadata":{},"score":"71.1702"}{"text":"Continuous measurement of these and more phonetic qualities would be possible through a Speaker Model and normalization against a standard distribution of phonemic realizations .The gestalt achieved is an elastic squash and stretch animation effect .When F0 is higher , the glyphs become skinnier , taller and lighter in weight ; when F0 is lower , the glyphs become wider , shorter and heavier ( see figure 38 below ) .","label":"Background","metadata":{},"score":"71.233765"}{"text":"Since editing method is common to a character printing method , no particular printing method is necessary .Hence , the synthetic speech editing system is very simple .By equipping the display means with a function for accepting a pointing device to change or modify the character position information or the like , it is possible to produce the same effect as in the editing operation using GUI .","label":"Background","metadata":{},"score":"71.23929"}{"text":"Ohala , J. J. ( 1983 ) .Cross - language use of pitch : an ethological view .Phonetica 40 , 1 - 18 .Olsen , C. L. ( 1975 ) .Grave vs. Agudo in two dialects of Spanish : a study in voice register and intonation .","label":"Background","metadata":{},"score":"71.31198"}{"text":"We will also consider how phonological patterns arise out of variation in production and perception , how knowledge of phonological patterns influences speech production and perception .Grading Policy The grade will be based on homework assignments ( roughly one a week ) , and two tests .","label":"Background","metadata":{},"score":"71.4043"}{"text":"We will also consider how phonological patterns arise out of variation in production and perception , how knowledge of phonological patterns influences speech production and perception .Grading Policy The grade will be based on homework assignments ( roughly one a week ) , and two tests .","label":"Background","metadata":{},"score":"71.4043"}{"text":"This value indicates the average value of the boundary tone frequency associated with a discourse function of type \" SUBORDINATION \" .The second row of the data structure for storing exemplary discourse function prosody information 1170 contains the value \" 2 \" in the identifier portion 1110 .","label":"Background","metadata":{},"score":"71.409775"}{"text":"7 Linguistic Data Consortium , Univ . of Pennsylvania ; Oregon Graduate Institute ( OGI ) ; and the Berkeley International Computer Science Institute ( ICSI ) .8 ToBI - tone and break indices - is a method used in linguistics to annotate English utterances with intonation patterns & other aspects of the prosody . 9 Although many levels of prosodic stress are claimed to exist by some phonologists , at most three levels of stress can be detected in speech recordings by trained linguists with even moderate reliability - primary stress , absence of stress and weak stress .","label":"Background","metadata":{},"score":"71.44812"}{"text":"The method of .claim 1 , in which the theory of discourse analysis is at least one of : the Linguistic Discourse Model , the Unified Linguistic Discourse Model , Rhetorical Structure Theory , Discourse Structure Theory and Structured Discourse Representation Theory .","label":"Background","metadata":{},"score":"71.47487"}{"text":"Yoroshiku Onegaishimasu . \"( meaning \" My name is Nakajima .How do you do . \" ) by a description scheme using the I and S layers of MSCL .[ /-\\ ] shows a local change of the pitch .","label":"Background","metadata":{},"score":"71.48017"}{"text":"0070 ] .Accordingly emotion detector 100 as shown works in parallel with the speech recognition processes .It consists of three main sections : .A prosody analyzer 118 which operates based on extracted acoustic features of the utterance .A parts - of - speech analyzer 121 which yields syntactic cues relating to the emotion state .","label":"Background","metadata":{},"score":"71.50981"}{"text":"Intonational phonology 's primary goal is to discover the universal functions of prosody .On the other hand , linguists often subjugate prosody to the status of a linguistic amplifier , believing that prosody is used by speakers to foreground certain linguistic items introduced into the conversation , amongst other things .","label":"Background","metadata":{},"score":"71.51249"}{"text":"Next , experimental results concerning the intonational variation will be described .The intonation represents the value ( the dynamic range ) of a pitch variation within a word .When the intonation is large , the utterance sounds \" strong , positive \" , and with a small intonation , the utterance sounds \" weak , passive \" .","label":"Background","metadata":{},"score":"71.542404"}{"text":"In Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop ( ASRU ) , St. Thomas , Virgin Islands , November - December , 2003 .Litman , D. , and Allen , J. F. , A plan recognition model for sub dialogues in conversation , Cognitive Science , 11(2 ) : 163 - 200 .","label":"Background","metadata":{},"score":"71.56653"}{"text":"105 - 114 , Springer - Verlag .Shute , V. J. , & Psotka , J. ( 1995 ) .Intelligent tutoring systems : Past , present , and future .In D. Janassen ( Ed . ) , Handbook of Research on Educational Communications and Technology , Scholastic Publications .","label":"Background","metadata":{},"score":"71.575134"}{"text":"For example , the propagated signal may be a digitized signal propagated over the Internet or other network .In one embodiment , the propagated signal is a signal that is transmitted over the propagation medium over a period of time , such as the instructions for a software application sent in packets over a network over a period of milliseconds , seconds , minutes , or longer .","label":"Background","metadata":{},"score":"71.58984"}{"text":"The response output control unit 137 also controls the display positions of the text data , the human character image , and the content visualizing image on the display unit 14 .Exemplary Multimodal Response Output .Referring now to FIG .","label":"Background","metadata":{},"score":"71.60639"}{"text":"The response output control unit 137 also controls the display positions of the text data , the human character image , and the content visualizing image on the display unit 14 .Exemplary Multimodal Response Output .Referring now to FIG .","label":"Background","metadata":{},"score":"71.60639"}{"text":"The response output control unit 137 also controls the display positions of the text data , the human character image , and the content visualizing image on the display unit 14 .Exemplary Multimodal Response Output .Referring now to FIG .","label":"Background","metadata":{},"score":"71.60639"}{"text":"The response output control unit 137 also controls the display positions of the text data , the human character image , and the content visualizing image on the display unit 14 .Exemplary Multimodal Response Output .Referring now to FIG .","label":"Background","metadata":{},"score":"71.60639"}{"text":"MAPPING RELATIONSHIPS .Creating systematic matches between spoken prosody and an object - oriented glyph system involves a combination of science , art , and trial - and - error practices .I created a system of mappings ; however , this current work is intended to act as a prototype for later extension , refinement and expansion .","label":"Background","metadata":{},"score":"71.636444"}{"text":"Further , each discipline places different vocal features into the prosodic feature set .Computational linguists and speech communication researchers identify intonation and prominence as the major prosodic feature set items , while poets and poetry critics associate prosody with rate of speaking and metrical rhythm .","label":"Background","metadata":{},"score":"71.67465"}{"text":"12 is a data structure for storing exemplary discourse function prosody information according this invention .The data structure for storing exemplary discourse function prosody information 1170 is comprised of an identifier portion 1110 ; a discourse function portion 1120 ; an initial frequency portion 1130 , a pitch variation portion 1140 ; a preceding silence portion 1150 and a boundary tone portion 1160 .","label":"Background","metadata":{},"score":"71.67595"}{"text":"Guinn , C. , & Montoya , R. ( 1997 ) , Natural Language Processing in Virtual Reality Training Environments , Proceedings of the 19th Interservice / Industry Training Systems and Education Conference ( I / ITSEC ' 97 ) , Orlando , Fla. .","label":"Background","metadata":{},"score":"71.67824"}{"text":"The prosodic parameters of the P layer are basic parameters of speech and have an interface - like property that permits application of the synthetic speech editing technique of the present invention to various other speech synthesis or speech coding systems that employ similar prosodic parameters .","label":"Background","metadata":{},"score":"71.69609"}{"text":"The lexicon of the tribe and the letters of the alphabet -- which are the chromosomes and genes of literate culture -- are in the typographer 's care ....Yet , like poetry and painting , storytelling and weaving , typography itself has not improved .","label":"Background","metadata":{},"score":"71.710724"}{"text":"Here , the user 's speech speed is obtained as an average number of moras per second as follows .Then , from these mora numbers the user 's speech speed can be determined as an average number of mora per second for these three keywords given by : .","label":"Background","metadata":{},"score":"71.74383"}{"text":"Here , the user 's speech speed is obtained as an average number of moras per second as follows .Then , from these mora numbers the user 's speech speed can be determined as an average number of mora per second for these three keywords given by : .","label":"Background","metadata":{},"score":"71.74383"}{"text":"Here , the user 's speech speed is obtained as an average number of moras per second as follows .Then , from these mora numbers the user 's speech speed can be determined as an average number of mora per second for these three keywords given by : .","label":"Background","metadata":{},"score":"71.74383"}{"text":"The speech dialogue system of claim 1 , wherein the output means outputs the speech response and the visual response by controlling at least one of an output order , an output timing , and a visual response output position .The speech dialogue system of claim 1 , further comprising user state detection means for detecting a state of the user , wherein the state of the user detected by the user state detection means is taken into account by the dialogue management means in determining the response output .","label":"Background","metadata":{},"score":"71.74472"}{"text":"Prosodic typography uses the active recognition of speech and prosody - the song and rhythm of ordinary talk - in the design of a font .Further , the temporal and dynamic characteristics of speech are to some extent transferred to font representation , lending written representations some of talk 's transitory , dynamic qualities .","label":"Background","metadata":{},"score":"71.745834"}{"text":"We will also consider how phonological patterns arise out of variation in production and perception , how knowledge of phonological patterns influences speech production and perception .This course will explore prosody above the level of the syllable ( stress , accent , tone and intonation ) , from the perspective of laboratory phonology . ","label":"Background","metadata":{},"score":"71.75703"}{"text":"And even more recently , fonts are being designed solely for use in electronic media , never requiring the glyph to assume a tangible form on paper or stone .These glyphs are drawn in light , ephemeral and fleeting .In this exodus from tangible lead type to mathematical description , much has been inherited from previous ages .","label":"Background","metadata":{},"score":"71.79086"}{"text":"There were four problems with this approach .Using the text alignment scheme for horizontal stroke alignment proved to be messy .To draw a glyph , each stroke would have to be tested for its alignment , the array searched for how the other strokes were aligned , and then an arrangement constructed between them .","label":"Background","metadata":{},"score":"71.796524"}{"text":"A prosodic font provides such an interface that does not compromise an audio message to the extent that semantic speech recognition would .Further , a prosodic font 's design potential for emerging through time might be easily adapted to very small displays .","label":"Background","metadata":{},"score":"71.81247"}{"text":"Training , Cognition and Instruction , 15(2 ) , 169 - 206 .Tversky , A. & Kahneman , D. ( 1974 ) , Judgments under uncertainty : Heuristics and biases , Science , 185 , .U.S. Bancorp Piper Jaffray , 20001 .","label":"Background","metadata":{},"score":"71.84142"}{"text":"Moreover , the likelihood of each keyword supplied from the dialogue management unit 12 along the semantic response representation can be reflected in the determination of the response speech pattern as follows .Namely , in a case of making a confirmation for example , the response sentence pattern in a form of a positive confirmation such as \" Your orders are two hamburgers , right ? \" and the response sentence pattern in a form of a question such as \" Are your orders two hamburgers ? \" can be used selectively .","label":"Background","metadata":{},"score":"71.85649"}{"text":"Moreover , the likelihood of each keyword supplied from the dialogue management unit 12 along the semantic response representation can be reflected in the determination of the response speech pattern as follows .Namely , in a case of making a confirmation for example , the response sentence pattern in a form of a positive confirmation such as \" Your orders are two hamburgers , right ? \" and the response sentence pattern in a form of a question such as \" Are your orders two hamburgers ? \" can be used selectively .","label":"Background","metadata":{},"score":"71.85649"}{"text":"When most words are written , they become , of course , a part of the visual world .Like most of the elements of the visual world , they become static things and lose , as such , the dynamism which is so characteristic of the auditory world in general , and of the spoken word in particular .","label":"Background","metadata":{},"score":"71.87384"}{"text":"Phonology is the study of the distribution of speech sound categories , i.e. what sounds can go where in an utterance .It is an important aspect of what you know when you know how to speak a language .In the first section of the course , we will learn how to do a phonological analysis : including how to determine the distribution of a sound class on the basis of a dataset , and formulate a formal model of the pattern .","label":"Background","metadata":{},"score":"71.87561"}{"text":"The I layer is composed of commands that are used to control the value , time - varying pattern ( a prosodic feature ) and accent of each prosodic parameter of the P layer .To this end , descriptions by symbols , which control patterns of the corresponding prosodic parameters of the P layer , are used as prosodic feature control commands of the I layer .","label":"Background","metadata":{},"score":"71.90053"}{"text":"Fundamental frequency by its very nature yields a discontinuous signal because it only tracks voiced phonetic events .Hence , every instance of an unvoiced phoneme ( eg ./t/ , /p/ , /q/ , /th/ , /f/ , et cetera ) will result in a gap in the F0 contour ( see figure 14 below ) .","label":"Background","metadata":{},"score":"71.93253"}{"text":"And even musical performance involves stretching and compressing of the specified rhythm .Although the theory of rhythm has been well documented in circles from poetry to linguistics , the performance of rhythm has not .Bruce and Liberman conducted informal experiments into rhythmic performance in 1984 ( as reported in Beckman , 1986 ) .","label":"Background","metadata":{},"score":"71.95177"}{"text":"Finally , we will address topics , such as second language acquisition and current speech technology as it applies to computerized speech synthesis and speech recognition .Phonology is the study of the distribution of speech sound categories , i.e. what sounds can go where in an utterance .","label":"Background","metadata":{},"score":"71.98761"}{"text":"FIGS . 27A-27F are diagrams of a fundamental frequency pattern used in the speech response generation unit of FIG .25 , without and with a modification for generating a such response with a joyful expression .FIGS .28A-28F are diagrams of a fundamental Frequency pattern used in the speech response generation unit of FIG .","label":"Background","metadata":{},"score":"72.0238"}{"text":"FIGS . 27A-27F are diagrams of a fundamental frequency pattern used in the speech response generation unit of FIG .25 , without and with a modification for generating a such response with a joyful expression .FIGS .28A-28F are diagrams of a fundamental Frequency pattern used in the speech response generation unit of FIG .","label":"Background","metadata":{},"score":"72.0238"}{"text":"A speech recognizer paired with prosody recognizer feeds descriptions of the voice signal and words uttered into a Prosodic Font .A Prosodic Font is an abstract description of letter forms with algorithms for motion .It uses a descriptive vocal model of the particular speaker , developed over time .","label":"Background","metadata":{},"score":"72.03849"}{"text":"9 .As a result , the following conclusion is reached .Weak intonation The character positions at the beginning and ending of the word are raised ( 43 % ) .The input Japanese sentence of FIG .10A means \" I 'm asking you , please let the bird go far away from your hands .","label":"Background","metadata":{},"score":"72.05353"}{"text":"To facilitate and enhance the human - like aspects of the interaction , the question is presented in the presence of an animated character 157 visible to the user who assists the user as a personal information retriever / agent .The agent can also interact with the user using both visible text output on a monitor / display ( not shown ) and/or in audible form using a text to speech engine 159 .","label":"Background","metadata":{},"score":"72.08879"}{"text":"Therefore , my methodology in creating the speech was to interview native English speaking friends of mine , asking them to tell me a story about four emotional experiences they had experienced .The friendship we shared enabled greater emotional disclosure and expressiveness .","label":"Background","metadata":{},"score":"72.10327"}{"text":"Not only is the definition and what constitutes the prosodic feature in question , but the basic function of prosody within and across languages is in dispute .Prosody may have universal import to humans , irrespective of which language is spoken .","label":"Background","metadata":{},"score":"72.135025"}{"text":"FIG .26 shows the fundamental Frequency pattern for a Japanese sentence of \" Tsuikawa potetodesu \" meaning \" Addition is a potato . \" , and a dashed line indicates the model without the emphasis while the solid line indicates the model with the emphasis .","label":"Background","metadata":{},"score":"72.13852"}{"text":"FIG .26 shows the fundamental frequency pattern for a Japanese sentence of \" Tsuikawa potetodesu \" meaning \" Addition is a potato . \" , and a dashed line indicates the model without the emphasis while the solid line indicates the model with the emphasis .","label":"Background","metadata":{},"score":"72.13852"}{"text":"FIG .26 shows the fundamental frequency pattern for a Japanese sentence of \" Tsuikawa potetodesu \" meaning \" Addition is a potato . \" , and a dashed line indicates the model without the emphasis while the solid line indicates the model with the emphasis .","label":"Background","metadata":{},"score":"72.13852"}{"text":"FIG .26 shows the fundamental Frequency pattern for a Japanese sentence of \" Tsuikawa potetodesu \" meaning \" Addition is a potato . \" , and a dashed line indicates the model without the emphasis while the solid line indicates the model with the emphasis .","label":"Background","metadata":{},"score":"72.13852"}{"text":"A statistically significant training corpus of speech utterances is selected .Prosodic features associated with the speech utterances in the training corpus are determined .The training texts are analyzed using a theory of discourse analysis to determine discourse functions within the text .","label":"Background","metadata":{},"score":"72.14259"}{"text":"The first \" own \" was captured at the height of a High pitch accent , and the second \" own \" was captured after the pitch fell .Prosodic Font displays the visual speech data word by word , using timing constraints of the speech file .","label":"Background","metadata":{},"score":"72.14532"}{"text":"The system of . claim 19 , wherein said emotion state is determined by evaluating both individual words and an entire sentence of words uttered by the user .The system of . claim 19 , further including a calibration routine .","label":"Background","metadata":{},"score":"72.16272"}{"text":"44 as follows .When the user state act is \" user present \" at the step S282 , next at the step S283 , the semantic response representation for the initial greeting is generated and the transition to the state # 1 is made .","label":"Background","metadata":{},"score":"72.16899"}{"text":"44 as follows .When the user state act is \" user present \" at the step S282 , next at the step S283 , the semantic response representation for the initial greeting is generated and the transition to the state # 1 is made .","label":"Background","metadata":{},"score":"72.16899"}{"text":"Some findings go so far as to integrate prosodic parameters of voice quality , range , and speaking duration differences along axes of emotion ; however , there are fundamental disagreements about how emotional space is defined .Some anthropologists have looked at how vocal timbre changes across context , building upon the work of linguistic anthropologist John Gumperz in contextualized vocal prosody ( 1982 ) .","label":"Background","metadata":{},"score":"72.19814"}{"text":"Prosodic Font requires some method that enables individualized playback speed control .During some Prosodic Font files , there are points at which the spoken rhythm used is too fast or slow , or too precipitously sudden , for the Prosodic Font to convey in a manner that could be read .","label":"Background","metadata":{},"score":"72.23287"}{"text":"Casual speech is not often used as an object of analysis .As such , speech errors such as false starts and mispronunciations , non - linguistic exclamations and the like are not described as significant events in syntactic research ; whereas , Prosodic Font would find these meaningful , expressive vocal events .","label":"Background","metadata":{},"score":"72.24379"}{"text":"Please make your order . \" between the timings t0 and t2 , so as to urge the user to make the order .FIG .30B is a timing chart for a situation in which one hamburger and one cola has already been ordered and two hamburgers and two coffees are ordered additionally .","label":"Background","metadata":{},"score":"72.244736"}{"text":"Please make your order . \" between the timings t0 and t2 , so as to urge the user to make the order .FIG .30B is a timing chart for a situation in which one hamburger and one cola has already been ordered and two hamburgers and two coffees are ordered additionally .","label":"Background","metadata":{},"score":"72.244736"}{"text":"Please make your order . \" between the timings t0 and t2 , so as to urge the user to make the order .FIG .30B is a timing chart for a situation in which one hamburger and one cola has already been ordered and two hamburgers and two coffees are ordered additionally .","label":"Background","metadata":{},"score":"72.244736"}{"text":"Please make your order . \" between the timings t0 and t2 , so as to urge the user to make the order .FIG .30B is a timing chart for a situation in which one hamburger and one cola has already been ordered and two hamburgers and two coffees are ordered additionally .","label":"Background","metadata":{},"score":"72.244736"}{"text":"Intonational contour targets and the continuum between them must be considered in a relative manner .Currently , intonation and pitch range are more an art form than a science .Developing a description of a speaker 's use of their voice over time would supply more appropriate graphic initialization and switching parameters for a Prosodic Font .","label":"Background","metadata":{},"score":"72.25578"}{"text":"44 as follows .Here , the dialogue management unit 234 at each moment of the operation is in one of the following four states # 0 , # 2 , and # 3 .The dialogue management unit 234 is in the state # 0 initially , and the transitions to the other states # 1 , # 2 , and # 3 are made according to the user state .","label":"Background","metadata":{},"score":"72.26657"}{"text":"44 as follows .Here , the dialogue management unit 234 at each moment of the operation is in one of the following four states # 0 , # 2 , and # 3 .The dialogue management unit 234 is in the state # 0 initially , and the transitions to the other states # 1 , # 2 , and # 3 are made according to the user state .","label":"Background","metadata":{},"score":"72.26657"}{"text":"As a result of this keyword spotting procedure at the keyword spotter 21b , the keyword detection unit 21 obtains the keyword lattice enumerating all the keyword candidates from the continuous input speech .In other words , the keyword lattice shown in FIG .","label":"Background","metadata":{},"score":"72.31721"}{"text":"As a result of this keyword spotting procedure at the keyword spotter 21b , the keyword detection unit 21 obtains the keyword lattice enumerating all the keyword candidates from the continuous input speech .In other words , the keyword lattice shown in FIG .","label":"Background","metadata":{},"score":"72.31721"}{"text":"As a result of this keyword spotting procedure at the keyword spotter 21b , the keyword detection unit 21 obtains the keyword lattice enumerating all the keyword candidates from the continuous input speech .In other words , the keyword lattice shown in FIG .","label":"Background","metadata":{},"score":"72.31721"}{"text":"As a result of this keyword spotting procedure at the keyword spotter 21b , the keyword detection unit 21 obtains the keyword lattice enumerating all the keyword candidates from the continuous input speech .In other words , the keyword lattice shown in FIG .","label":"Background","metadata":{},"score":"72.31721"}{"text":"Configure agent to be part of the community of OAA agents .Emotion Detector Agent .[ 0164 ] .We will implement the algorithm of the emotional state detector developed in Objective 1 in C++ Software code .[ 0000 ] .","label":"Background","metadata":{},"score":"72.35031"}{"text":"The first row of the data structure for storing exemplary discourse function prosody information 1170 contains a value of \" 1 \" in the identifier portion 1110 .The identifier portion is used as an index into the information contained in the data structure for storing exemplary discourse function prosody information .","label":"Background","metadata":{},"score":"72.43702"}{"text":"Since Prosodic Font is inherently a font of motion and transformation , there is more of a need to maintain simplicity of construction rather than static visual harmony .Some glyphs use exactly the same primitive strokes , but in a different consecutive order .","label":"Background","metadata":{},"score":"72.43765"}{"text":"Data abstraction modules , such as the context manager 58 , the conversational record 60 , the syntax manager 62 , the ontology module 64 , and the lexicon module 66 are indicated by boxes with a bar across the top .","label":"Background","metadata":{},"score":"72.449875"}{"text":"Smith , J. P. , diSessa , A. A. , & Roschelle , J. ( 1993 ) , Misconceptions reconceived : A constructivist analysis of knowledge in transition , Journal of the Learning Sciences , 2(2 ) , 115 - 164 .","label":"Background","metadata":{},"score":"72.468185"}{"text":"Phonology is the study of the distribution of speech sound categories , i.e. what sounds can go where in an utterance .It is an important aspect of what you know when you know how to speak a language .In this course , students will learn to recognize phonological patterns in language data , state such patterns precisely , and represent them in a formal model .","label":"Background","metadata":{},"score":"72.50616"}{"text":"Speaktomi aims to enhance this user system interaction so as to be more intuitive for less experienced workers .[ 0000 ] .The Opportunity .[0176 ] .Speaktomi 's unique technology is critical to the next stage of e - Learning and computer based training tools .","label":"Background","metadata":{},"score":"72.51136"}{"text":"[ 0012 ] .In another aspect , the domain model includes a lexicon of words associated with the speech - enabled application .The lexicon provides synonyms and parts of speech information for elements of an ontological description of the domain model , and the grammatic specification along with the ontological description and the syntax templates is based on the lexicon .","label":"Background","metadata":{},"score":"72.52817"}{"text":"A NLQS system typically includes a parts - of - speech module 121 to extract parts - of - speech from the utterance .In the present invention this same speech module is also used in a prosodic analysis .Further processing results in tagging and grouping of the different parts - of - speech .","label":"Background","metadata":{},"score":"72.64008"}{"text":"The triples derived from the above frame representation are shown in the example below .The words with numbers appended to them in the example represent anonymous objects introduced by the speech center system 20 .Class Action-1 Action .[ 0086 ] .","label":"Background","metadata":{},"score":"72.644806"}{"text":"Greater collaboration between businesses and their partners requires that increased knowledge and learning be brought to not only an internal audience but to external audiences as well .The acceptance of e - Learning systems which have been effective in providing training but have not yet achieved the improvement in performance provided by human tutors .","label":"Background","metadata":{},"score":"72.655266"}{"text":"I am interested in the connection between vocal expression and type design .I 've designed a font that uses the voice signal to determine its own shape and motion .There are two examples of this font on the large computer .","label":"Background","metadata":{},"score":"72.68496"}{"text":"Phonology is the study of the distribution of speech sound categories , i.e. what sounds can go where in an utterance .It is an important aspect of what you know when you know how to speak a language .In the first section of the course , students will become familiar with phonological patterns through problem sets , in which they determine the distributional restrictions on particular classes of sounds in a dataset .","label":"Background","metadata":{},"score":"72.69284"}{"text":"At this point in the analysis , we will discover by experiment which combination of acoustic features - amplitude , pitch , pitch range or others derived from the base set , will most accurately classify syllables into STRESS or NON - STRESS categories .","label":"Background","metadata":{},"score":"72.73263"}{"text":"Choice 1A Choice 1B Choice 1C .Circle the word that best describes the emotion the font is expressing : .Anger Excitement Satisfaction Sadness .EXAMPLE TWO : \" I 'm not working for my own education here \" .","label":"Background","metadata":{},"score":"72.74436"}{"text":"Improvement in tools and effectiveness of e - Learning results are critical to continue to drive the market .Speaktomi will provide the core technology for human interaction to make this possible .19 \" Academic E - Learning Must Confront Content Development Costs \" , Gartner study April 2003 .","label":"Background","metadata":{},"score":"72.75668"}{"text":"This is not dissimilar to vocal prosody .Often we need time to acquaint ourselves with someone 's manner of speaking before understanding how they use intonational gestures .By establishing some visual markings - such as a visual \" reference line \" - to give any particular Prosodic Font a vocal context would aid in the interpretation of the speaker 's emotional state .","label":"Background","metadata":{},"score":"72.76048"}{"text":"Each of these strokes were given similar constraints : [ 1 ] whether they were to be measured on a horizontal or vertical measure , [ 2 ] a top and bottom constraint on that measure , and [ 3 ] a rotation value .","label":"Background","metadata":{},"score":"72.84034"}{"text":"In the first part we will focus on the sounds of English .Students will be engaged in this section in defining how particular speech sounds are produced , identifying sounds in English words , and identifying sounds in acoustic spectrograms .","label":"Background","metadata":{},"score":"72.88342"}{"text":"An intonational phrase does not imply any degree of well - formedness .For example , if a person stops suddenly during an utterance - even half - way through a word - and begins again on a different subject , or coughs or burps , the presence of silence should be sufficient reason to mark the end of an intonational phrase .","label":"Background","metadata":{},"score":"72.9021"}{"text":"In spontaneous conversations the speaker changes the stress , speed and pitch of his utterances so as to express various information which are not contained in verbal information , such as his mental states , attitudes and understanding , and his intended nuances .","label":"Background","metadata":{},"score":"72.937836"}{"text":"I went back to study the alphabet and emerged with a more elegant system . 4.2 EXPANDED STROKE SYSTEM : CONSECUTIVENESS / SIMULTANEITY AND DEPENDENCE / INDEPENDENCE .Two principles of stroke positioning enable the construction of any letterform glyph : consecutiveness or simultaneity , and dependence or independence .","label":"Background","metadata":{},"score":"72.9725"}{"text":"According to preliminary user testing results , people are able to identify systems of graphic transforms as representative of systems of prosodic variation .I found that rhythmic variation and variations in vocal stress are extremely important in peoples ' ability to match Prosodic Font files to speech audio files .","label":"Background","metadata":{},"score":"72.99444"}{"text":"In Prosodic Font , the orthography of the syllable speech event contains phonetic markings that apply to the succeeding letter .For example , if a person says \" Argh ! \" with an initial glottalization and a forceful /g/ plosive phone , I would represent it as \" & Ar#g_h \" ( the underscore represents a phonetic ligature ) .","label":"Background","metadata":{},"score":"73.04974"}{"text":"[ 0023 ] .A first aspect of the invention concerns a system and method for incorporating prosodic features while performing real - time speech recognition distributed across a client device and a server device .The SR process typically transfers speech data from an utterance to be recognized using a packet stream of extracted acoustic feature data including at least some cepstral coefficients .","label":"Background","metadata":{},"score":"73.06751"}{"text":"[ 0043 ] .Time Includes dates , as well as time of day .[0044 ] .Actions Things that agents can do to alter the state of the world .[ 0045 ] .Attributes Characteristics of things , such as color , author , etc . .","label":"Background","metadata":{},"score":"73.07443"}{"text":"The ease of usage by the user is roughly divided into two .First , it is ease of usage intended for beginners which enables them to easily describe a text input into the text - to - speech synthesizer even if they have no expert knowledge .","label":"Background","metadata":{},"score":"73.09088"}{"text":"Combining phonetic normalization with a specific Speaker Model of their voice characteristics over time would refine this method , making the Prosodic Font highly expressive of an individual 's use of prosody .Currently , only a few levels of visual effects have been applied using the speech parameters .","label":"Background","metadata":{},"score":"73.12267"}{"text":"[ 0000 ] .Structure / Operation of Real - Time , Client Server Emotion Detector .[ 0069 ] .The emotion detector 100 is integrated with the NLQS system of the prior art ( .FIG .3 ) .","label":"Background","metadata":{},"score":"73.12904"}{"text":"Searching through its available rules the speech center 20 finds one that states that it can create an appointment .Examining the rule description , the speech center 20 finds that it calls a function which has the following parameters : a person , date , time , and place .","label":"Background","metadata":{},"score":"73.129234"}{"text":"Excited Angry Sad Satisfied .Male Speaker : She places 4sec .Not working for my own 3sec .Painful 9sec .Sunset 28sec .Upset 7sec .Couch 19sec .Should Have 3sec .Figure 32 : I selected short portions of speech which demonstrated emotional characteristics specific to anger , excitement , sadness , and satisfaction .","label":"Background","metadata":{},"score":"73.14132"}{"text":"Prosodic variation is found within all languages .In a few languages , such as Cantonese or Yoruba , prosodic intonation takes on a highly formalized function , using distinct tone structures on the same morphemic item to indicate a different word item .","label":"Background","metadata":{},"score":"73.19293"}{"text":"Prominence levels are hypothesized to indicate the relative salience of a word within an utterance .Ladd defines accent as an independent linguistic element , treating fundamental frequency as \" the manifestation of an overarching structure in which elements of a tune are associated with elements of a text in ways that reflect the prominence relations in the text .","label":"Background","metadata":{},"score":"73.20108"}{"text":"Silverman , K. ; Beckman , M. ; Pierrehumbert , J. ; Ostendorf , M. ; Wightman , C. ; Price , P. ; and Hirschberg , J. 1992 .\" ToBI : A standard scheme for labeling prosody . \"In Proceedings of ICSLP .","label":"Background","metadata":{},"score":"73.202995"}{"text":"Events An action that has occurred , will occur , or is occurring over a span of time .[ 0047 ] .These concepts are described in the portion of the domain model 70 known as the ontology 64 ( i.e. , based on an ontological description ) .","label":"Background","metadata":{},"score":"73.21103"}{"text":"Speech samples from these representative test subjects are recorded in a controlled environment - i.e . in a localized environment with low background noise .The speech as articulated by speakers speaking in different styles but with emphasis on the styles that represent the intended emotion modes that each sample requires .","label":"Background","metadata":{},"score":"73.22835"}{"text":"[ 0020 ] .Another object of the present invention , therefore , is to provide an improved system and method for formulating SQL queries that includes parameters based on user emotional content ; . [ 0021 ] .[ 0022 ] .","label":"Background","metadata":{},"score":"73.24379"}{"text":"This indicates that the prosodic features are associated with a \" COORDINATION \" discourse function .The initial frequency portion 1130 contains the value \" 150 \" .This indicates the initial frequency typically associated with \" COORDINATION \" discourse functions .","label":"Background","metadata":{},"score":"73.279655"}{"text":"Describing a propensity towards a particular pitch differential is not an intentional target , but an observed effect .The debate about pitch target levels is very important for a system such as Prosodic Font .If pitch target levels themselves are more meaningful than the difference between specified tonal points - and the slopes of change between them , then prosody is inherently a vocal , auditory system .","label":"Background","metadata":{},"score":"73.3109"}{"text":"Currently , additional phonemes , such as flap or glottal , are labeled as discrete events because there is no good way of determining a phonetic pronunciation continuum .Creating an automatic phonetic classifier that identifies full and reduced vowel forms , plus unusually energetic consonantal sounds , on a continuous measurement scale would add a great deal of small detail and interest to each Prosodic Font glyph .","label":"Background","metadata":{},"score":"73.31566"}{"text":"When the user state act is \" user absent \" at the step S291 , next at the step S292 , the transition to the state # 3 is made and the operation proceeds to a next operation timing .When the user state act is not \" user absent \" at the step S291 , the dialogue management unit remains in the state # 0 and the operation proceeds to a next operation timing .","label":"Background","metadata":{},"score":"73.3354"}{"text":"When the user state act is \" user absent \" at the step S291 , next at the step S292 , the transition to the state # 3 is made and the operation proceeds to a next operation timing .When the user state act is not \" user absent \" at the step S291 , the dialogue management unit remains in the state # 0 and the operation proceeds to a next operation timing .","label":"Background","metadata":{},"score":"73.3354"}{"text":"( c ) controlling that one of said prosodic parameters of said prosodic parameter string corresponding to said character or character string to be added with said non - verbal information , by referring to said prosody control rules stored in said prosody control rule database ; and .","label":"Background","metadata":{},"score":"73.40195"}{"text":"Prosodic Font simply represents an inhalation as a circle that grows from the center of the screen outwards ; an exhalation is a large circle that shrinks .RESULTS .Figure 40 : Frame capture selections from the excited voice file , \" Wow she placed wow that 's amazing .","label":"Background","metadata":{},"score":"73.45048"}{"text":"Like all the arts , it is basically immune to progress , though it is not immune to change .Robert Bringhurst , The Elements of Typographic Style .( 1992 , p. 196 ) .Typography is the design of graphic forms characters that comprise a language 's words .","label":"Background","metadata":{},"score":"73.46097"}{"text":"Note that proportions of each glyph are continuously adjustable erstwhile maintaining glyph distinction .Changes in weighting , transforms and color can be made on a per - stroke basis ( see figures 29 and 30 ) .Figure 28 : Above glyphs are possible variations upon the letter possible with the Prosodic Font Object Oriented glyph - building system .","label":"Background","metadata":{},"score":"73.46721"}{"text":"No .4,907,279 and Japanese Patent Application Laid - Open Nos .5 - 307396 , 3 - 189697 and 5 - 19780 there is disclosed a method that inserts phonological parameter control commands such as accents and pauses in a text and edits synthesized speech through the use of such control commands .","label":"Background","metadata":{},"score":"73.48944"}{"text":"Currently these providers have focused on the software for creating and managing learning content rather than featured technologies for improving the experience of students in a training environment .The main competitive thrust will come from companies already entrenched in the embedded speech technology for telephony .","label":"Background","metadata":{},"score":"73.534805"}{"text":"[ 0000 ] .American Society for Trainers and Development ( ASTD ) , A Vision for E - Learning for America 's Workforce , referencing Moe , Michael , and Henry Blodgett , The Knowledge Web , Merrill Lynch & Co. , Global Securities Research & Economics Group , 2000 .","label":"Background","metadata":{},"score":"73.558365"}{"text":"Rabiner , H. R. , and Juang , B. H. , Fundamentals of Speech Recognition , Prentice Hall , 1993 .Rabiner , H. R. , Digital Processing of Speech Signals , Prentice Hall , 1978 .Ros C. , Litman D. , Bhembe D. , Silliman S. , Srivastava R. , and Van Lehn K. , A Comparison of Tutor and Student Behavior in Speech versus Text - Based Tutoring , Proceedings of the HLT / NAACL Workshop : Building Educational Applications Using NLP , June , 2003 .","label":"Background","metadata":{},"score":"73.58509"}{"text":"In various other exemplary embodiments according to this invention , the recognized text is verified by using different speech recognition methods and deciding the correct , verified text by majority voting between the different recognition methods .Alternatively , the recognized speech utterances are verified by human verifiers .","label":"Background","metadata":{},"score":"73.625435"}{"text":"We will read survey the current literature in these areas , and practice experimental methods for finding out about these topics .Students will apply these skills and concepts to a language of their choice in a short research paper .Linguistics 344 is an introduction to the sound structure of language .","label":"Background","metadata":{},"score":"73.65192"}{"text":"When the user state act is not \" user absent \" at the step S291 , the dialogue management unit remains in the state # 0 and the operation proceeds to a next operation timing .When The dialogue management unit 234 is not in the state # 1 at the step S284 , next at the step S293 , whether the dialogue management unit 234 is in the state # 2 or not is determined .","label":"Background","metadata":{},"score":"73.666214"}{"text":"When the user state act is not \" user absent \" at the step S291 , the dialogue management unit remains in the state # 0 and the operation proceeds to a next operation timing .When The dialogue management unit 234 is not in the state # 1 at the step S284 , next at the step S293 , whether the dialogue management unit 234 is in the state # 2 or not is determined .","label":"Background","metadata":{},"score":"73.666214"}{"text":"SUMMARY OF THE INVENTION .Thus , systems and methods for segmenting natural language into relevant discourse functions or contexts would be useful .Various exemplary embodiments according to the systems and methods of this invention provide for training a system to segment speech into discourse function units .","label":"Background","metadata":{},"score":"73.68916"}{"text":"The dots \" . \" indicated by reference numeral 2 under the character string of each line represent an average duration T m ( which indicates one - syllable length , that is , 1 mora in the case of Japanese ) of each character by their spacing .","label":"Background","metadata":{},"score":"73.707634"}{"text":"1 The mnemonic ITS is used in the literature to signify an Intelligent Tutoring System .In the context of this proposal , ITS is used to refer to our proposed system - an Interactive Training System .We also wish to clarify that training involves tutoring on a one - on - one basis or in a classroom setting .","label":"Background","metadata":{},"score":"73.73775"}{"text":"Ron gave me freedom to learn and research .Stephanie Shattuck - Hufnagel and Samuel J. Keyser placed me on my feet initially in the vast and overwhelming field of prosody , rhythm and intonation .Stephanie Seneff was instrumental in helping me focus the work and understand arcane technicalities involved in speech recognition .","label":"Background","metadata":{},"score":"73.75911"}{"text":"Whatever curvature exists within tonal perceptual space would need to mapped onto visual space as well .In this way , high and low tones are both more unusual than medium tones , and need to be non - linearly more prominent than medium tones .","label":"Background","metadata":{},"score":"73.85356"}{"text":"[0075 ] .The prosody analysis as noted above is preferably based on three key acoustic features - Fundamental Frequency ( FO ) , Amplitude ( RMS ) and Duration ( DUR ) , extracted in real - time from the utterance .","label":"Background","metadata":{},"score":"73.87064"}{"text":"Stifleman , L. ( 1995 ) .A Discourse Analysis Approach to Structured Speech .Presented at the AAAI 1995 Spring Symposium Series : Empirical Methods in Discourse Interpretation and Generation .Stanford University , March 27 - 29 .Sun Systems Incorporated .","label":"Background","metadata":{},"score":"73.88965"}{"text":"An electronic abstract display driven by their vocal expression is generated between them .In this way , only the paralinguistic functions of language is communicated , the linguistic functions removed .This is also an example of temporal vocal parameters driving a visual spatial display .","label":"Background","metadata":{},"score":"73.982895"}{"text":"5.2.1 Tilt Phonological - Phonetic System .The Tilt system is an outgrowth from Taylor 's earlier Rise - Fall - Connection System ( RFC ) ( 1995 ) .In the RFC model , F0 curves are smoothed and then fitted to three types of events : Accents , Connections or Silences .","label":"Background","metadata":{},"score":"73.99594"}{"text":"The method of claim 33 , wherein the full speech response recites the response output explicitly while the simplified speech response does not recite the response output explicitly .The method of claim 37 , wherein the simplified speech response contains a pronoun to refer to the visual response .","label":"Background","metadata":{},"score":"74.07472"}{"text":"The method of claim 33 , wherein the full speech response recites the response output explicitly while the simplified speech response does not recite the response output explicitly .The method of claim 37 , wherein the simplified speech response contains a pronoun to refer to the visual response .","label":"Background","metadata":{},"score":"74.07472"}{"text":"What We Will Do .[ 0091 ] .In the course of Phase I and Phase II the proposed research will focus on three key strategies to investigate the hypothesis that a pure text - based computer - based training can be improved to levels approaching the best one - on - one human tutors by : .","label":"Background","metadata":{},"score":"74.07951"}{"text":"The third row of the exemplary data structure for storing speech utterance prosody information 1070 contains a \" 3 \" in the identifier portion 1010 .The identifier portion 1070 is used as an index into the information contained in the exemplary data structure for storing speech utterance prosody information .","label":"Background","metadata":{},"score":"74.1678"}{"text":"The second principle is one of dependency .Dependent strokes use the same graphic characteristics as their parent stroke .In this way , a dependent stroke has the same weighting and motion as its parent stroke , making the parent and dependent strokes appear visually homogenous .","label":"Background","metadata":{},"score":"74.17493"}{"text":"From things to processes : A theory of conceptual change for learning science concepts , Learning and Instruction , 4 , 27 - 43 .Classroom Lessons : Integrating Cognitive Theory and Classroom Practice ( pp .51 - 74 ) .","label":"Background","metadata":{},"score":"74.17536"}{"text":"The difference can be understood from the following joke .A Reporter and a notorious Bank Robber have the following exchange as described in Ladd ( 1996 ) : .Reporter :\" Why do you rob BANKS ? \"Bank Robber : \" Because THAT 's where the real MONey is . \" The reporter wanted the robber to interpret the accent on banks as a phrasal accent , or broad accent .","label":"Background","metadata":{},"score":"74.19683"}{"text":"Individual applications can extend the foundation domain model to create an application domain model by adding their own elements to the base classes , or defining new subclasses of these classes and new sentence forms to work with them .[0008 ] .","label":"Background","metadata":{},"score":"74.198586"}{"text":"Ang J. , Prosodic Cues For Emotion Recognition In Communicator Dialogs , M.S. Thesis , University of California at Berkeley , December 2002 .Bahl , L. R. , Jeninek , F. , Mercer , R. L. , A maximum likelihood approach to continuous speech recognition , IEEE Trans .","label":"Background","metadata":{},"score":"74.20789"}{"text":"The domain model , in a further aspect , includes an ontological data structure based on entities , classes , and attributes .[ 0014 ] .In another aspect , the domain model includes a syntax specification and the grammatic specification is based on the syntax specification .","label":"Background","metadata":{},"score":"74.297775"}{"text":"Organizational Information Requirements , Media Richness , and Structural Design .Management Science , Vol .32 , No . 5 , May.Drucker , J. ( 1995 ) .The Alphabetic Labyrinth : The Letters in History and Imagination .London : Thames and Hudson Ltd. .","label":"Background","metadata":{},"score":"74.338776"}{"text":"20 received by the speech characteristic determination unit 134 is also transmitted to the speech response generation unit 135 , in order to generate the speech response with the emphasizing term emphasized .The speech response generation unit 135 generates the desired speech response in a synthesized voice to be outputted from the loudspeaker unit 15 .","label":"Background","metadata":{},"score":"74.35738"}{"text":"20 received by the speech characteristic determination unit 134 is also transmitted to the speech response generation unit 135 , in order to generate the speech response with the emphasizing term emphasized .The speech response generation unit 135 generates the desired speech response in a synthesized voice to be outputted from the loudspeaker unit 15 .","label":"Background","metadata":{},"score":"74.35738"}{"text":"20 received by the speech characteristic determination unit 134 is also transmitted to the speech response generation unit 135 , in order to generate the speech response with the emphasizing term emphasized .The speech response generation unit 135 generates the desired speech response in a synthesized voice to be outputted from the loudspeaker unit 15 .","label":"Background","metadata":{},"score":"74.35738"}{"text":"20 received by the speech characteristic determination unit 134 is also transmitted to the speech response generation unit 135 , in order to generate the speech response with the emphasizing term emphasized .The speech response generation unit 135 generates the desired speech response in a synthesized voice to be outputted from the loudspeaker unit 15 .","label":"Background","metadata":{},"score":"74.35738"}{"text":"197 - 200 , Hiroyuki Tsuboi , et al . , \" A Real - Time Task - Oriented Speech Understanding System Using Keyword - Spotting \" .IEEE , Jul. 1991 , pp .905 - 908 , Yoichi Takebayashi , et al . , \" A Robust Speech Recognition System Using Work - Spotting with Noise Immunity Learning \" .","label":"Background","metadata":{},"score":"74.38469"}{"text":"The method of claim 33 , wherein the length of the speech response for making the confirmation is determined from information items to be confirmed by the confirmation .The method of claim 34 , wherein the full speech responses mentions all of the information items to be confirmed while the simplified speech response does not directly mention the information items to be confirmed .","label":"Background","metadata":{},"score":"74.39728"}{"text":"The method of claim 33 , wherein the length of the speech response for making the confirmation is determined from information items to be confirmed by the confirmation .The method of claim 34 , wherein the full speech responses mentions all of the information items to be confirmed while the simplified speech response does not directly mention the information items to be confirmed .","label":"Background","metadata":{},"score":"74.39728"}{"text":"The system of . claim 19 wherein said emotion state is used to control non - verbal audio feedback presented to a user of the real - time speech recognition system .The system of .claim 24 wherein said non - verbal audio feedback is one of a selected set of audio recordings associated with different user emotion states .","label":"Background","metadata":{},"score":"74.425606"}{"text":"SUMMARY OF THE INVENTION .It is therefore an object of the present invention to provide a synthetic speech editing / creating method and apparatus with which it is possible for an operator to easily synthesize a speech message with desired prosodic parameters .","label":"Background","metadata":{},"score":"74.431465"}{"text":"42 , when the user gets on the Floor mat , the semantic user state representation No . 1 is supplied from the user state detection unit 233 to the dialogue management unit 234 .In response , the dialogue management unit 234 automatically supplies the semantic response representation No . 1 to the response generation unit 23S such that the response No . 1 of \" Welcome to Tos Burger .","label":"Background","metadata":{},"score":"74.47076"}{"text":"42 , when the user gets on the Floor mat , the semantic user state representation No . 1 is supplied from the user state detection unit 233 to the dialogue management unit 234 .In response , the dialogue management unit 234 automatically supplies the semantic response representation No . 1 to the response generation unit 23S such that the response No . 1 of \" Welcome to Tos Burger .","label":"Background","metadata":{},"score":"74.47076"}{"text":"0002 ] .Speech enabling mechanisms have been developed that allow a user of a computer system to verbally communicate with software applications executing on the system .Examples of speech recognition products that convert spoken utterances into text strings that can be utilized by the applications include the ViaVoice  product from IB  , Armonk , N.Y. , and NaturallySpeaking Professional from Dragon Systems , Newton , Mass. .","label":"Background","metadata":{},"score":"74.47708"}{"text":"The context manager module 58 keeps track of the targets of previous commands , factors in changes in the desktop environment , and uses this information to determine the target of new commands .One example of a context manager 58 suitable for use with the invention is described in copending , commonly assigned U.S. patent application Ser .","label":"Background","metadata":{},"score":"74.48364"}{"text":"0177 ] .Speaktomi 's platform for improving user interaction will allow educational content tool developers such as Macromedia to offer a wider array of modes of interaction to content developers and reduce the cost of creating engaging content which is one of the major concerns in the emerging e - Learning space .","label":"Background","metadata":{},"score":"74.51139"}{"text":"In this case , the system understand this input speech as the user 's confirmation of the entire order , such that the speech response for the final salutation such as \" Thank you very much .\" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the bowing gesture as shown in FIG .","label":"Background","metadata":{},"score":"74.5358"}{"text":"In this case , the system understand this input speech as the user 's confirmation of the entire order , such that the speech response for the final salutation such as \" Thank you very much .\" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the bowing gesture as shown in FIG .","label":"Background","metadata":{},"score":"74.5358"}{"text":"In this case , the system understand this input speech as the user 's confirmation of the entire order , such that the speech response for the final salutation such as \" Thank you very much .\" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the bowing gesture as shown in FIG .","label":"Background","metadata":{},"score":"74.5358"}{"text":"In this case , the system understand this input speech as the user 's confirmation of the entire order , such that the speech response for the final salutation such as \" Thank you very much .\" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the bowing gesture as shown in FIG .","label":"Background","metadata":{},"score":"74.5358"}{"text":"They are free to call upon services provided by other modules ( such as 30 , 32 , 34 , 36 , 40 , 42 , 52 , 54 , 56 , 58 , 60 , 62 , 64 or 66 ) when appropriate .","label":"Background","metadata":{},"score":"74.54492"}{"text":"Terken , J. ( 1984 ) .The distribution of pitch accents in structures as a function of discourse structure .Language and Speech , 27 , 269 - 289 .Terken , J. & Hirschberg , J. ( 1994 ) .","label":"Background","metadata":{},"score":"74.56476"}{"text":"Chicago Linguistics Society , Chicago .1984 : Zero - Derivation and Inflection .In M. Speas and R. Sproat ( eds . )MIT Working Papers in Linguistics .MIT , Cambridge .PROSODIC FONT . the Space between the Spoken and the Written .","label":"Background","metadata":{},"score":"74.59243"}{"text":"tara michelle graber rosenberger M.S. Rensselaer Polytechnic Institute 1995 B.A. University of Waterloo 1993 .CONTENTS .Abstract .Masters Thesis Committee .Contents .Acknowledgements .Introduction .Motivation .Why do this at the Media Laboratory ?Background .Prosody and Affect .","label":"Background","metadata":{},"score":"74.59421"}{"text":"42 , when the user gets on the floor mat , the semantic user state representation No . 1 is supplied from the user state detection unit 233 to the dialogue management unit 234 .In response , the dialogue management unit 234 automatically supplies the semantic response representation No . 1 to the response generation unit 235 such that the response No . 1 of \" Welcome to Tos Burger .","label":"Background","metadata":{},"score":"74.62613"}{"text":"42 , when the user gets on the floor mat , the semantic user state representation No . 1 is supplied from the user state detection unit 233 to the dialogue management unit 234 .In response , the dialogue management unit 234 automatically supplies the semantic response representation No . 1 to the response generation unit 235 such that the response No . 1 of \" Welcome to Tos Burger .","label":"Background","metadata":{},"score":"74.62613"}{"text":"In the user state 72 , the transition to the system state 71 is made according to the semantic utterance representation obtained from the input speech uttered by the user .In this manner of managing the progress of the dialogue as the transitions between two states , it becomes possible for the dialogue management unit 12 to realize the flexible management of the dialogue between the system and the user .","label":"Background","metadata":{},"score":"74.64996"}{"text":"In the user state 72 , the transition to the system state 71 is made according to the semantic utterance representation obtained from the input speech uttered by the user .In this manner of managing the progress of the dialogue as the transitions between two states , it becomes possible for the dialogue management unit 12 to realize the flexible management of the dialogue between the system and the user .","label":"Background","metadata":{},"score":"74.64996"}{"text":"In the user state 72 , the transition to the system state 71 is made according to the semantic utterance representation obtained from the input speech uttered by the user .In this manner of managing the progress of the dialogue as the transitions between two states , it becomes possible for the dialogue management unit 12 to realize the flexible management of the dialogue between the system and the user .","label":"Background","metadata":{},"score":"74.64996"}{"text":"In the user state 72 , the transition to the system state 71 is made according to the semantic utterance representation obtained from the input speech uttered by the user .In this manner of managing the progress of the dialogue as the transitions between two states , it becomes possible for the dialogue management unit 12 to realize the flexible management of the dialogue between the system and the user .","label":"Background","metadata":{},"score":"74.64996"}{"text":"This key objective ensures that the dialog remains robust , stable and stays on track so that the user experience is productive , engaging and enjoyable .[ 0000 ] .Specific Aims .[ 0119 ] .[ 0000 ] .","label":"Background","metadata":{},"score":"74.71374"}{"text":"If raising the voice can be used to signal anger or surprise , raising the voice a lot can signal violent anger or great surprise .Paralinguistic signals that are phonetically similar generally mean similar things ....The difference between language and paralanguage is a matter of the way the sound - meaning relation is structured \" ( 1996 , p. 36 ) .","label":"Background","metadata":{},"score":"74.72557"}{"text":"44 from the beginning .When the dialogue management unit 234 is not in the state # 0 at the step S281 , next at the step S284 , whether the dialogue management unit 234 is in the state # 1 or not is determined .","label":"Background","metadata":{},"score":"74.76224"}{"text":"44 from the beginning .When the dialogue management unit 234 is not in the state # 0 at the step S281 , next at the step S284 , whether the dialogue management unit 234 is in the state # 1 or not is determined .","label":"Background","metadata":{},"score":"74.76224"}{"text":"However , they did not formalize their observations and visual studies into a systematic theory , nor did they begin from the point of computational and algorithmic typographic design .Sparacino designed a program called Media Creatures using real - time fundamental frequency and energy trackers to animate words ( 1996 ) .","label":"Background","metadata":{},"score":"74.813965"}{"text":"FIG .22A is a flow chart for an operation of the response sentence generation unit in the response generation unit of FIG .19 .FIGS .22B , 22C and 22D are illustrations of exemplary semantic response representation , response sentence structure , and generated response sentence to be used in the response sentence generation unit in the operation shown in the flow chart of FIG .","label":"Background","metadata":{},"score":"74.81675"}{"text":"FIG .22A is a flow chart for an operation of the response sentence generation unit in the response generation unit of FIG .19 .FIGS .22B , 22C and 22D are illustrations of exemplary semantic response representation , response sentence structure , and generated response sentence to be used in the response sentence generation unit in the operation shown in the flow chart of FIG .","label":"Background","metadata":{},"score":"74.81675"}{"text":"FIG .22A is a flow chart for an operation of the response sentence generation unit in the response generation unit of FIG .19 .FIGS .22B , 22C and 22D are illustrations of exemplary semantic response representation , response sentence structure , and generated response sentence to be used in the response sentence generation unit in the operation shown in the flow chart of FIG .","label":"Background","metadata":{},"score":"74.81675"}{"text":"FIG .22A is a flow chart for an operation of the response sentence generation unit in the response generation unit of FIG .19 .FIGS .22B , 22C and 22D are illustrations of exemplary semantic response representation , response sentence structure , and generated response sentence to be used in the response sentence generation unit in the operation shown in the flow chart of FIG .","label":"Background","metadata":{},"score":"74.81675"}{"text":"Humans can perceive tonal changes as small as .3Hz to .5Hz , and rates of linear rising or falling slopes near 0 ( Grandour , 1978 ) .However , Bruce found evidence that it is pitch target level , and not amount of pitch displacement , that is perceptually most important ( 1977 ) .","label":"Background","metadata":{},"score":"74.856285"}{"text":"[ 0128 ] .Speaktomi 's proposed architecture for its spoken language ITS is based on a configuration of modular components functioning as software agents and adhering to the SRI Open Agent Architecture ( OM ) 6 framework as shown in .","label":"Background","metadata":{},"score":"74.931595"}{"text":"Defining glyphs to function in a temporal , transformational capacity might require a simplification and independence of shape parameters .Prosodic Font chose to represent letterforms as arrangements of very simple marks ; each mark has tremendous transformational capacity by itself and in relationship to the entire glyph .","label":"Background","metadata":{},"score":"74.975815"}{"text":"For Prosodic Font work , I am most interested in the paralinguistic use of prosodic variation ; that is , all uses of prosody not associated with tones that function linguistically .This argument has raged since , and many papers have been published continuing to account for prosody in terms of syntax and information structure .","label":"Background","metadata":{},"score":"75.04358"}{"text":"Secondly , the stories were often very long , involving multiple digressions and asides which had different emotional coloring independently of the larger story .I picked the corpus selections from the \" heart \" of the story that would appear to the careful listener to exhibit the particular emotional vocal characteristics .","label":"Background","metadata":{},"score":"75.052444"}{"text":"Ladd points out that a unique feature in the description of a pitch accent is the rhythmic offset of the onset of the vowel from the pitch target achieved ( 1996 ) .This temporal delay is used to dramatic effect . 2.2 TECHNIQUES IN FEATURE IDENTIFICATION .","label":"Background","metadata":{},"score":"75.07036"}{"text":"Prosody is \" something else , \" he said .Why is it important to know the origins and use of prosody ?Prosody may be an innate function of song that we share with our avian sisters and brothers , that gains an understood , communicative function as we learn to participate within a certain language , community , and contexts .","label":"Background","metadata":{},"score":"75.09029"}{"text":"When the dialogue management unit 234 is not in the state # 2 at the step S293 , next at the step S295 , whether the dialogue management unit 234 is in the state # 3 or not is determined .When the dialogue management unit 234 is in the state # 3 at the step S295 , next at the step S296 , the semantic response representation for the final salutation No . 2 of \" Thank you for coming .","label":"Background","metadata":{},"score":"75.09291"}{"text":"When the dialogue management unit 234 is not in the state # 2 at the step S293 , next at the step S295 , whether the dialogue management unit 234 is in the state # 3 or not is determined .When the dialogue management unit 234 is in the state # 3 at the step S295 , next at the step S296 , the semantic response representation for the final salutation No . 2 of \" Thank you for coming .","label":"Background","metadata":{},"score":"75.09291"}{"text":"The first row of the exemplary data structure for storing speech utterance prosody information 1070 contains a value of \" 1 \" in the identifier portion 1010 .The identifier portion is used as an index into the information contained in the exemplary data structure for storing speech utterance prosody information .","label":"Background","metadata":{},"score":"75.14812"}{"text":"Strong emotions such as those with high activation and very positive evaluation are represented on the periphery of the circle .An example of a strong emotion is exhilaration , an emotional state which is associated with very positive evaluation and high activation .","label":"Background","metadata":{},"score":"75.15045"}{"text":"Cambridge : MIT Press .Nakatani , C. ( 1995 ) . \"Discourse Structural Constraints on Accent in Narrative . \" In Progress in Speech Synthesis .Eds .Jan P.H. van Santen , Richard Sproat , Joseph Olive , and Julia Hirschberg .","label":"Background","metadata":{},"score":"75.1543"}{"text":"The training corpus of speech utterances may be a previously determined training corpus such as the Switchboard corpus of the Linguistic Data Consortium .In various other exemplary embodiments , the training corpus may be a user specific training corpus , a training corpus that combines speech utterances from different users into a combined training corpus of speech utterances .","label":"Background","metadata":{},"score":"75.21113"}{"text":"For example , the command for the \" Angry \" utterance enlarges the dynamic ranges of the pitch and power and the command for the \" Crying \" utterance shakes or sways the pitch pattern of each phoneme , providing a characteristic sentence - final pitch pattern .","label":"Background","metadata":{},"score":"75.29026"}{"text":"The exemplary data structure for storing speech utterance prosody information 1070 contains the value \" 173 \" in the initial frequency portion 1030 .The \" 173 \" value indicates the initial frequency information for a training speech utterance .The exemplary data structure for storing speech utterance prosody information 1070 contains the value \" 0.12 \" in the pitch variation portion 1040 .","label":"Background","metadata":{},"score":"75.329895"}{"text":"[ 0179 ] .The realities of an explosive growth in e - Learning within companies has put more pressure on companies to provide content that is more accessible to a wider array of their staff members .Some 63 percent of all training in corporations from external providers ( none e - Learning ) is for new software applications that are critical for job functions .","label":"Background","metadata":{},"score":"75.348724"}{"text":"The raw data , 290 for the Wagon CART is provided to the input of the Wagon CART .Then the output of the CART is sent to 250 .The optimization of the CART tree output results is done in 280 by comparing the CART results 270 with the ToBI labeled speech utterances of 210 .","label":"Background","metadata":{},"score":"75.40489"}{"text":"Word duration standard deviation .( F 0 _ RANGE )  .Combination of above .( DUR ) .( F 0 _ RANGE )  .Combination of above .( RMS )  ( DUR ) .Parts of Speech ( POS ) Analysis .","label":"Background","metadata":{},"score":"75.41591"}{"text":"FIG .47 is an illustration of one example of a display image to be used in the speech dialogue system of FIG .45 .FIG .48 is an illustration of another example of a display image to be used in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"75.440315"}{"text":"FIG .47 is an illustration of one example of a display image to be used in the speech dialogue system of FIG .45 .FIG .48 is an illustration of another example of a display image to be used in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"75.440315"}{"text":"Natural Language Processing in Virtual Reality Training Environments , Proceedings of the 19th Interservice / Industry Training Systems and Education Conference ( I / ITSEC ' 97 ) , Orlando , Fla. .Hake , R. R. ( under review ) , Interactive - engagement vs. traditional methods : A six - thousand student survey of mechanics test data for introductory physics courses .","label":"Background","metadata":{},"score":"75.49695"}{"text":"These components are well known in the art , and in a preferred embodiment include a personal computer system 150 , an INTERNET connection 160 A , 160 B , and a larger scale computing system 180 .It will be understood by those skilled in the art that these are merely exemplary components , and that the present invention is by no means limited to any particular implementation or combination of such systems .","label":"Background","metadata":{},"score":"75.53102"}{"text":"Yet , the excitement in adhering more closely to phonemic rather than orthographic realization is that written language would gain a color , individualism and novelistic appeal that it only currently realizes in places such as a Mark Twain novel .In a commercial release of Prosodic Font , a switch which would allow greater to lessor phonemic representation would be essential .","label":"Background","metadata":{},"score":"75.543015"}{"text":"The determined emotional expression and intonation of the response speech are supplied to the speech response generation unit 135 .The generated speech response is supplied to the response output control unit 137 .The content visualizing image generation unit 136 generates the content visualizing image according to the content visualizing image information supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"75.61298"}{"text":"The determined emotional expression and intonation of the response speech are supplied to the speech response generation unit 135 .The generated speech response is supplied to the response output control unit 137 .The content visualizing image generation unit 136 generates the content visualizing image according to the content visualizing image information supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"75.61298"}{"text":"The determined emotional expression and intonation of the response speech are supplied to the speech response generation unit 135 .The generated speech response is supplied to the response output control unit 137 .The content visualizing image generation unit 136 generates the content visualizing image according to the content visualizing image information supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"75.61298"}{"text":"The determined emotional expression and intonation of the response speech are supplied to the speech response generation unit 135 .The generated speech response is supplied to the response output control unit 137 .The content visualizing image generation unit 136 generates the content visualizing image according to the content visualizing image information supplied from the dialogue management unit 12 .","label":"Background","metadata":{},"score":"75.61298"}{"text":"Syllabification is even more difficult because people often eliminate entire syllables from their pronunciation of a word , especially when it is in an unaccented position .For example , in the Sunset audio file I encountered the word \" ev - en - ing , \" pronounced \" eve - ning \" .","label":"Background","metadata":{},"score":"75.62752"}{"text":"Equinox Publishing , London .Journal of the International Phonetic Association 40 .Natural Language and Linguistic Theory 25 .2005 : ( with Benjamin Hansen )The origin of vowel length neutralization in vocoid sequences : Evidence from Finnish speakers .","label":"Background","metadata":{},"score":"75.63408"}{"text":"P MacNeilage .The Production of Speech , New York : Springer - Verlag , 39 - 55 .Gibson , E.J. & Levin , H. ( 1975 ) .The Psychology of Reading .Cambridge , MA : MIT Press .","label":"Background","metadata":{},"score":"75.68991"}{"text":"( 2 ) Weakness or passive attitude .( 3 ) Understanding attitude .( 4 )Questioning attitude .( 5 ) Relief or calmness .( 6 ) Uneasiness or reluctance .Seven examinees were made to hear synthesized voices generated by modifying a Japanese word utterance \" shikatanai \" ( which means \" It ca n't be helped . \" ) according to the above methods ( a ) to ( f ) .","label":"Background","metadata":{},"score":"75.702774"}{"text":"Declination is falling into disfavor as an account of pitch depression during any utterance .The Prosodic Font does not use any inherent notion of declination since no theory can aid with identification .More productively , I use target accent , duration , and syllable offsets that I introduce in the following Rhythm section to account for the pitch range instability .","label":"Background","metadata":{},"score":"75.78198"}{"text":"[ 0000 ] .Business Model .[ 0183 ] .The business model for marketing and selling Speaktomi 's technology will be based on the following : .Focus on generating revenue through technology licensing .The development of an interface with Macromedia .","label":"Background","metadata":{},"score":"75.814476"}{"text":"The power of the speech center 20 derives from the fact that it has significant knowledge about the applications 26 it controls .Without this knowledge , it would be limited to providing little more than simplistic menu based command and control services .","label":"Background","metadata":{},"score":"75.831085"}{"text":"[ Excerpted from Myers ( 1997 ) ] .In N. Burton - Roberts , P. Carr , and G. Docherty ( eds . ) , Phonological Knowledge : conceptual and empirical issues .Oxford University Press , Oxford .Studies in African Linguistics 28 .","label":"Background","metadata":{},"score":"75.86722"}{"text":"These changes can be classified as either High or Low .A number of prosodic features often coincide with an accent , such as increased duration , increased loudness , and vowel fullness ( i.e. not reduced phonetic form ) .Figure 8 : This utterance contains three high pitch accents .","label":"Background","metadata":{},"score":"75.884125"}{"text":"Prosodic Font draws upon work done in phonetic and phonological linguistics research .In particular , I use the work of auto - segmental metrical phonologists who believe that intonation and prosody are not linguistic systems per se , but that the stream of prosody can be understood in linear segments .","label":"Background","metadata":{},"score":"75.90997"}{"text":"The prosodic feature control part 17 refers to a prosodic feature rule database 16 and gets instructions specifying which and how prosodic parameters in the text are controlled ; the prosodic parameter control part 17 varies and corrects the prosodic parameters accordingly .","label":"Background","metadata":{},"score":"75.946045"}{"text":"It is not clear how one derives the underlying phrasal representation and pitch accent model from spontaneous speech ( 1983 ) .The Rise Fall Connection ( RFC ) and the more generalized TILT model fit Euclidean curves to intonational F0 changes .","label":"Background","metadata":{},"score":"75.95948"}{"text":"Wong defined Temporal Typography using Rapid Visual Serial Presentation ( RSVP ) to remove the necessity of eye movement during the reading event ( 1995 ) .Rather , words are presented in rapid succession .In both Ishizaki 's and Wong 's design work , choice of typeface is included within possible formal dimensions of temporal design .","label":"Background","metadata":{},"score":"75.9787"}{"text":"Speech recognition programs should consider recognizing the complete paralinguistic to linguistic vocal continuity of a speaker 's utterances - not just discrete linguistic events .This would broaden the conception of speech recognition to include affective sounds such as sighs , breaths , laughs - sounds that are usually ignored .","label":"Background","metadata":{},"score":"75.998474"}{"text":"It contains two halves of unequal proportions , the rise portion and the fall portion , either of which may be of zero duration .Taylor combined these two parameters into one numerical descriptor called the tilt parameter , itself an abstract description of the Euclidean shape of an F0 accent event .","label":"Background","metadata":{},"score":"76.00521"}{"text":"Collins M. , Three generative , lexicalised models for statistical parsing .In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics , Madrid , Spain , July 1997 .de Kleer , J. & Brown , J. S. ( 1984 ) , A qualititative physics based on confluences , Artificial Intelligence , 24 , 7 - 83 .","label":"Background","metadata":{},"score":"76.02779"}{"text":"FIG .47 is an illustration of one example of a display image to be used in the speech dialogue system of FIG .45 .FIG 48 is an illustration of another example of a display , image to be used in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"76.046295"}{"text":"FIG .47 is an illustration of one example of a display image to be used in the speech dialogue system of FIG .45 .FIG 48 is an illustration of another example of a display , image to be used in the speech dialogue system of FIG .","label":"Background","metadata":{},"score":"76.046295"}{"text":"Prosodic Font has an internal timer that moves the program state through the linear list of words , which are , in turn , linear lists of syllables .Within a word , the active syllable 's hue is tinted , while the inactive syllables are shaded ( see figure 39 above ) .","label":"Background","metadata":{},"score":"76.10902"}{"text":"A goal is a proposition that may contain a variable for one or more of its elements .The speech center system 20 then attempts to find or derive a match for that proposition , and find values for any variables .","label":"Background","metadata":{},"score":"76.14064"}{"text":"Using scripts the PRAAT tool automatically extracts and archives of a large number of speech and spectrographic features from each speech sample .The EST library also contains a number of speech analysis tools from which other speech features such as linear predictive coefficients ( LPC ) , cepstrum coefficients , mel - frequency cepstrum coefficients ( MFCC ) , area , energy and power can be extracted .","label":"Background","metadata":{},"score":"76.15298"}{"text":"We will initially aim to annotate syllables into two categories - STRESS and UNSTRESSED 9 .Once we develop and confirm experimental procedures for classifying these two levels , we can proceed to prosodic modeling of larger units .At the level of turn - taking our experimental procedures will be provide information that would enable a tutoring system to infer paralinguistic characteristics of the dialog participants .","label":"Background","metadata":{},"score":"76.1726"}{"text":"III .THIRD EMBODIMENT .Referring now to FIG .45 , a third embodiment of a speech dialogue system according to the present invention will be described in detail .This third embodiment differs from the first and second embodiments described above in that the further detail of the practical implementation of the speech dialogue system configuration is incorporated .","label":"Background","metadata":{},"score":"76.211975"}{"text":"III .THIRD EMBODIMENT .Referring now to FIG .45 , a third embodiment of a speech dialogue system according to the present invention will be described in detail .This third embodiment differs from the first and second embodiments described above in that the further detail of the practical implementation of the speech dialogue system configuration is incorporated .","label":"Background","metadata":{},"score":"76.211975"}{"text":"It is to be noted that , besides these already mentioned above , many modifications and variations of the above embodiments may be made without departing from the novel and advantageous features of the present invention .Accordingly , all such modifications and variations are intended to be included within the scope of the appended claims .","label":"Background","metadata":{},"score":"76.21474"}{"text":"It is to be noted that , besides these already mentioned above , many modifications and variations of the above embodiments may be made without departing from the novel and advantageous features of the present invention .Accordingly , all such modifications and variations are intended to be included within the scope of the appended claims .","label":"Background","metadata":{},"score":"76.21474"}{"text":"It is to be noted that , besides these already mentioned above , many modifications and variations of the above embodiments may be made without departing from the novel and advantageous features of the present invention .Accordingly , all such modifications and variations are intended to be included within the scope of the appended claims .","label":"Background","metadata":{},"score":"76.21474"}{"text":"It is to be noted that , besides these already mentioned above , many modifications and variations of the above embodiments may be made without departing from the novel and advantageous features of the present invention .Accordingly , all such modifications and variations are intended to be included within the scope of the appended claims .","label":"Background","metadata":{},"score":"76.21474"}{"text":"Journal of Phonetics 33 .2004 :The effects of boundary tones on the f0 scaling of lexical tones .In B. Bel and I. Marlien ( ed . ) , TAL 2004 : International Symposium on Tonal Aspects of Languag e. Institute of Linguistics , Chinese Academy of Social Sciences , Beijing .","label":"Background","metadata":{},"score":"76.21732"}{"text":"Some parameters , such as amplitude , are always present in the spoken signal , whereas others are less omnipresent , such as fundamental frequency ( F0 ) .There is no F0 signal in a whisper , an unvoiced phoneme , and even in a breathy voice .","label":"Background","metadata":{},"score":"76.2656"}{"text":"The ontology 64 provides meaning to the grammatical specifications 90 , and the grammatical specifications 90 determine what form statements about the objects defined in the ontology 64 may take .[0068 ] .Given a syntax specification 72 , an ontology 64 , and a lexicon 66 , the syntax manager 62 generates a grammatic specification 90 ( e.g. , BNF grammar ) which can be used by the speech engine 22 to guide recognition of a spoken utterance .","label":"Background","metadata":{},"score":"76.26781"}{"text":"Science , 210(5 ) , 1139 - 1141 .Meng , H. , et al , ISIS : A Multi - Modal , Trilingual , Distributed Spoken Dialog System developed with CORBA , Java , XML and KQML , ICSLP 2002 Proceedings , Denver , Colo. , USA .","label":"Background","metadata":{},"score":"76.27597"}{"text":"It was difficult for all speakers to recreate vocally .I would like to clarify that the speech corpus I developed is not necessarily an \" emotional \" speech corpus .The people I spoke with were re - telling emotional experiences they had had ; they were not experiencing them for the first time .","label":"Background","metadata":{},"score":"76.285416"}{"text":"Here , the display controller 2992 controls the display 2993 to display the visual response given in terms of images , texts , figures , animated images , colors , luminances , and concentrations , under the control of the processor unit 291 .","label":"Background","metadata":{},"score":"76.337"}{"text":"Here , the display controller 2992 controls the display 2993 to display the visual response given in terms of images , texts , figures , animated images , colors , luminances , and concentrations , under the control of the processor unit 291 .","label":"Background","metadata":{},"score":"76.337"}{"text":"Here , the display controller 2992 controls the display 2993 to display the visual response given in terms of images , texts , figures , animated images , colors , luminances , and concentrations , under the control of the processor unit 291 .","label":"Background","metadata":{},"score":"76.337"}{"text":"Prerequisite : Phonology I ( LIN 380 K ) .In this course , we will explore how pitch is used in languages , both in lexical tone languages ( where pitch can distinguish two words ) and in intonation ( where pitch distinguishes between two sentence types ) .","label":"Background","metadata":{},"score":"76.343475"}{"text":"The ending tone , or boundary tone , forms a tonal tail on the utterance that is high , equal , or low relative to the utterance .Figure 4 : The ending tone , or boundary tone , of the intonational phrase falls approximately within the circled region .","label":"Background","metadata":{},"score":"76.3709"}{"text":"You receive notice through one of your portables that someone important to you has sent you a message .You want to hear it , but you do n't want to risk interrupting the meeting , nor do you want others around you to hear your message .","label":"Background","metadata":{},"score":"76.38884"}{"text":"The EduSpeak SR engine works for adult and child voices as well as native and non - native speakers .The key performance enablers of this SR engine are : high speech recognition accuracy , speaker - independent recognition , requires no user training , has a small , scalable footprint dependent on vocabulary requirements , supports unlimited - size dynamically loadable grammars , and supports statistical language models ( SLM ) .","label":"Background","metadata":{},"score":"76.3968"}{"text":"The emotion detector will be the software application as described under Objective 1 .For the Natural Language module we will use the CARMEL Workbench for language understanding .[ 0000 ] .Speech Recognition Agent .[ 0153 ] .The OAA - based speech recognition agent will be created by writing a software wrapper for the SRI EduSpeak speech recognition engine .","label":"Background","metadata":{},"score":"76.39694"}{"text":"Since we do not know the structure of the data and the relevance or irrelevance of some of the features , it behooves us to attempt to classify the extracted data with more than a few learning schemes .We will use a representative number of these data - driven algorithms such as boosting ( AdaBoost ) , classification and regression trees ( CART ) , artificial neural networks ( ANN ) , support vector machines ( SVM ) and nearest neighbor methods .","label":"Background","metadata":{},"score":"76.40318"}{"text":"The storage unit 293 stores the data , control parameters , programs , etc . , required in the speech understanding operation , the dialogue management operation , and the response generation operation .Here , the processor unit 291 carries out the multi - task execution of the programs for realizing the understanding operation , the dialogue management operation , and the response generation operation as in the first and second embodiment described above .","label":"Background","metadata":{},"score":"76.40414"}{"text":"The storage unit 293 stores the data , control parameters , programs , etc . , required in the speech understanding operation , the dialogue management operation , and the response generation operation .Here , the processor unit 291 carries out the multi - task execution of the programs for realizing the understanding operation , the dialogue management operation , and the response generation operation as in the first and second embodiment described above .","label":"Background","metadata":{},"score":"76.40414"}{"text":"Hestenes , D. , Wells , M. , & Swackhamer , G. ( 1992 ) , Force concept inventory , Physics Teacher , 30 , 141- .Holzmann , G. J. , Design and Validation of Computer Protocols , Prentice Hall , New Jersey , 1991 , ISBN 0 - 13 - 539925 - 4 .","label":"Background","metadata":{},"score":"76.40906"}{"text":"Journal of Linguistics 20 .Phonetica 60 .2003 : ( ed . )Comparative Markedness .Special issue of Theoretical Linguistics 29 .2003 : OCP Effects in Optimality Theory .In J. McCarthy ( ed . )Optimality Theory in Phonology : A Reader .","label":"Background","metadata":{},"score":"76.41458"}{"text":"[ 0141 ] .The KAPPA Coefficient K 10 will be used as the metric that measures the pair wise agreement between the two transcribers .This metric represents the ratio of the proportion of times that the transcribers agreed to the maximum proportion of times that the transcribers could have agreed .","label":"Background","metadata":{},"score":"76.43173"}{"text":"Figure 33 : An excerpt from a typical Tilt text file developed from an audio speech file .Using the textual output from the Tilt system , one can re - create a stylized version of the F0 curve found in the audio speech file .","label":"Background","metadata":{},"score":"76.432205"}{"text":"Frame to attribute - object - value triple translation is mostly a matter of filling in references to containing frames .These triples are stored in memory , and provide the raw material upon which the reasoning facility 52 operates .A sentence such as \" make this column green \" would be translated to a frame structure by a series of calls like these : .","label":"Background","metadata":{},"score":"76.464005"}{"text":"In this configuration of FIG .45 , the A / D conversion unit 295 and the D / A conversion unit 298 are provided separately such that they can be operated independently from each other .For this purpose , it is preferable to use the indication combining the notification text and the notification sign image .","label":"Background","metadata":{},"score":"76.46437"}{"text":"In this configuration of FIG .45 , the A / D conversion unit 295 and the D / A conversion unit 298 are provided separately such that they can be operated independently from each other .For this purpose , it is preferable to use the indication combining the notification text and the notification sign image .","label":"Background","metadata":{},"score":"76.46437"}{"text":"In this configuration of FIG .45 , the A / D conversion unit 295 and the D / A conversion unit 298 are provided separately such that they can be operated independently from each other .For this purpose , it is preferable to use the indication combining the notification text and the notification sign image .","label":"Background","metadata":{},"score":"76.46437"}{"text":"In this configuration of FIG .45 , the A / D conversion unit 295 and the D / A conversion unit 298 are provided separately such that they can be operated independently from each other .For this purpose , it is preferable to use the indication combining the notification text and the notification sign image .","label":"Background","metadata":{},"score":"76.46437"}{"text":"Further , the MSCL system enables input of a sound data file of music , background noise , a natural voice and so forth .This is because more effective contents generation inevitably requires music , natural voice and similar sound information in addition to speech .","label":"Background","metadata":{},"score":"76.506485"}{"text":"34 .In this case , the above described operations in the speech understanding unit 11 and the dialogue management unit 12 to produce the appropriate semantic response representation are carried out on a basis of this input speech .Here , the response act registered in the ACT frame of the semantic response representation is \" overall confirmation \" , such that the speech response For the overall confirmation such as \" Your orders are two hamburgers and two coffees , right ? \" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the normal facial expression as shown in FIG .","label":"Background","metadata":{},"score":"76.52814"}{"text":"34 .In this case , the above described operations in the speech understanding unit 11 and the dialogue management unit 12 to produce the appropriate semantic response representation are carried out on a basis of this input speech .Here , the response act registered in the ACT frame of the semantic response representation is \" overall confirmation \" , such that the speech response For the overall confirmation such as \" Your orders are two hamburgers and two coffees , right ? \" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the normal facial expression as shown in FIG .","label":"Background","metadata":{},"score":"76.52814"}{"text":"34 .In this case , the above described operations in the speech understanding unit 11 and the dialogue management unit 12 to produce the appropriate semantic response representation are carried out on a basis of this input speech .Here , the response act registered in the ACT frame of the semantic response representation is \" overall confirmation \" , such that the speech response for the overall confirmation such as \" Your orders are two hamburgers and two coffees , right ? \" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the normal facial expression as shown in FIG .","label":"Background","metadata":{},"score":"76.52814"}{"text":"34 .In this case , the above described operations in the speech understanding unit 11 and the dialogue management unit 12 to produce the appropriate semantic response representation are carried out on a basis of this input speech .Here , the response act registered in the ACT frame of the semantic response representation is \" overall confirmation \" , such that the speech response for the overall confirmation such as \" Your orders are two hamburgers and two coffees , right ? \" is outputted from the loudspeaker unit 15 while the text data of this speech response is displayed on the display unit 14 along with the human character image with the normal facial expression as shown in FIG .","label":"Background","metadata":{},"score":"76.52814"}{"text":"Then , the semantic utterance representation No . 2 for the next user utterance of \" Right . \" uttered in reply , the dialogue is terminated as the final salutation of \" Thank you very much .\" is outputted according to the semantic response representation No . 3 .","label":"Background","metadata":{},"score":"76.56419"}{"text":"Then , the semantic utterance representation No . 2 for the next user utterance of \" Right . \" uttered in reply , the dialogue is terminated as the final salutation of \" Thank you very much .\" is outputted according to the semantic response representation No . 3 .","label":"Background","metadata":{},"score":"76.56419"}{"text":"Then , the semantic utterance representation No . 2 for the next user utterance of \" Right . \" uttered in reply , the dialogue is terminated as the final salutation of \" Thank you very much .\" is outputted according to the semantic response representation No . 3 .","label":"Background","metadata":{},"score":"76.56419"}{"text":"Then , the semantic utterance representation No . 2 for the next user utterance of \" Right . \" uttered in reply , the dialogue is terminated as the final salutation of \" Thank you very much .\" is outputted according to the semantic response representation No . 3 .","label":"Background","metadata":{},"score":"76.56419"}{"text":"Other studies report that the average student tutored by a ' good ' one - on - one tutor scored 2.0 standard deviation units above average students receiving standard class instruction [ Bloom , 1984].[ 0096 ] .The challenge then for a computer - based tutoring system such as the one proposed is to emulate the desirable human one - on - one tutoring environment .","label":"Background","metadata":{},"score":"76.635254"}{"text":"For example , Prosodic Font does not represent the spectral differences between an /a/ phoneme and an /i/ phoneme , but it would represent a general increase in volume and fall in pitch .Prosodic Font does not require that speech be labeled as an instance of any categorical emotion or syntactical construction .","label":"Background","metadata":{},"score":"76.68761"}{"text":"FIG .3 , memory 20 can be implemented using any appropriate combination of alterable , volatile or non - volatile memory or non - alterable , or fixed memory .The alterable memory , whether volatile or non - volatile , can be implemented using any one or more of static or dynamic RAM , a floppy disk and disk drive , a write - able or rewrite - able optical disk and disk drive , a hard drive , flash memory or the like .","label":"Background","metadata":{},"score":"76.72543"}{"text":"6.1 System Design 6.2 Parameter Match Appropriateness .Results .User Test .Related Work .Future work .Appendix A : Tilt file example .Appendix B : Word file Example .Appendix C : Font file .Appendix D : Questionnaire .","label":"Background","metadata":{},"score":"76.74083"}{"text":"The resulting benefits that would accrue include the features of an advanced intelligent training system that significantly raise the students ' performance .[ 0000 ] .Competition .[0182 ] .The market for e - Learning software is just evolving and is currently led by six major companies : Docent and Click2learn ( now SumTotal ) , Saba Software , IBM , Pathlore and WBT systems .","label":"Background","metadata":{},"score":"76.825134"}{"text":"The storage unit 293 stores the data , control parameters , programs .etc . , required in the speech understanding operation , the dialogue management operation , and the response generation operation .Here , the processor unit 291 carries out the multi - task execution of the programs for realizing the understanding operation , the dialogue management operation , and the response generation operation as in the first and second embodiment described above .","label":"Background","metadata":{},"score":"76.861694"}{"text":"31B , in order to simplify the dialogue for making the confirmation of the orders .Namely , in FIG .31B , after the orders are received , at a timing t0 , the text data is erased once , while the content visualizing image showing two hamburgers , one cheese burger , and three coffees is displayed immediately at the timing t0 .","label":"Background","metadata":{},"score":"76.8633"}{"text":"31B , in order to simplify the dialogue for making the confirmation of the orders .Namely , in FIG .31B , after the orders are received , at a timing t0 , the text data is erased once , while the content visualizing image showing two hamburgers , one cheese burger , and three coffees is displayed immediately at the timing t0 .","label":"Background","metadata":{},"score":"76.8633"}{"text":"31B , in order to simplify the dialogue for making the confirmation of the orders .Namely , in FIG .31B , after the orders are received , at a timing t0 , the text data is erased once , while the content visualizing image showing two hamburgers , one cheese burger , and three coffees is displayed immediately at the timing t0 .","label":"Background","metadata":{},"score":"76.8633"}{"text":"31B , in order to simplify the dialogue for making the confirmation of the orders .Namely , in FIG .31B , after the orders are received , at a timing t0 , the text data is erased once , while the content visualizing image showing two hamburgers , one cheese burger , and three coffees is displayed immediately at the timing t0 .","label":"Background","metadata":{},"score":"76.8633"}{"text":"Orlando : Institute for Simulation and Training .Zachary , W. , Le Mentec , J - C. , & Ryder , J. ( 1996 ) .Interface agents in complex systems .In C. Ntuen & E. H. Park ( Eds . ) , Human interaction with complex systems : Conceptual Principles and Design Practice .","label":"Background","metadata":{},"score":"76.8793"}{"text":"Picard , R. ( 1997 ) .Affective Computing .Cambridge , MA : MIT Press .Pierrehumbert , J. ( 1980 ) .The Phonology and Phonetics of English Intonation .PhD thesis at the Massachusetts Institute of Technology .Pierrehumbert , J. & Hirschberg , J. ( 1990 ) .","label":"Background","metadata":{},"score":"76.892166"}{"text":"28A and FIGS .28D-28F show the exemplary fundamental frequency patterns for a Japanese sentence of \" Sumimasen Mouichido Onegaishimasu \" meaning \" I 'm sorry .Please say it again \" for the normal case and a case with the regretful emotional expression .","label":"Background","metadata":{},"score":"77.06101"}{"text":"28A and FIGS .28D-28F show the exemplary fundamental frequency patterns for a Japanese sentence of \" Sumimasen Mouichido Onegaishimasu \" meaning \" I 'm sorry .Please say it again \" for the normal case and a case with the regretful emotional expression .","label":"Background","metadata":{},"score":"77.06101"}{"text":"Choose the sound file that sounds most like the Prosodic Font example looked .Circle your choice below .Circle the emotion that you think best describes the font 's expression .Repeat this for the second font example .EXAMPLE ONE : \" Oh wow she placed wow that 's amazing \" .","label":"Background","metadata":{},"score":"77.092834"}{"text":"4 , Academic Press , New York 1959 .FEELTRACE ' : An Instrument for Recording Perceived Emotion in Real Time , Ellen Douglas - Cowie , Roddy Cowie , Marc Schrder : Proceedings of the ISCA Workshop on Speech and Emotion : A Conceptual Framework for Research Pages 19 - 24 , Textflow , Belfast , 2000 .","label":"Background","metadata":{},"score":"77.21745"}{"text":"The method of claim 1 , wherein said prosodic parameter control in said step ( c ) is to change values of said parameters relative to said prosodic parameter string obtained in said step ( b ) .The method of claim 1 , wherein said prosodic parameter control in said step ( c ) is to change specified absolute values of said parameters with respect to said prosodic parameter string obtained in said step ( b ) .","label":"Background","metadata":{},"score":"77.245026"}{"text":"Dialogue speech conveys speaker 's mental states , intentions and the like as well as the linguistic meaning of spoken dialogue .Such information contained in the speaker 's voices , except their linguistic meaning , is commonly referred to as non - verbal information .","label":"Background","metadata":{},"score":"77.274994"}{"text":"Phonology is the study of the distribution of speech sound categories , i.e. the restrictions on what sounds can go where in an utterance .It is an important aspect of what you know when you know how to speak a language .","label":"Background","metadata":{},"score":"77.30369"}{"text":"TYPOGRAPHIC DESIGN SYSTEM .My design goal is twofold : [ 1 ] to create a font which clearly differentiates one glyph from another , and [ 2 ] to create glyphs that are architectural composites of smaller shapes to enable independent movement and transformation .","label":"Background","metadata":{},"score":"77.31764"}{"text":"When the utterance duration is changed , the character display spacing of the character string changes correspondingly .Similarly , the four characters identified by reference numeral 5 indicate a flat pitch contour , and the two character identified by reference numeral 6 a declining pitch contour .","label":"Background","metadata":{},"score":"77.37306"}{"text":"In another aspect of the invention , the syntax manager receives an ontological description of the domain model based on entities , classes , and attributes , and receives syntax templates for the domain model specifying legal word sequences based on the ontological description .","label":"Background","metadata":{},"score":"77.43553"}{"text":"Taylor , P. A. ( 1995 ) .The Rise / Fall / connection Model of Intonation .Speech Communication , 15 , 169 - 186 ._ _ _ _ .Analysis and Synthesis of Intonation using the Tilt Model .","label":"Background","metadata":{},"score":"77.435875"}{"text":"Proceedings of 1992 International Conference on Acoustics , Speech , and Signal Processing ( ICASSP 92 ) , I-197 to I-200 , San Francisco .U.S.A. ( March 1992 for further detail concerning the above described operations of the speech understanding unit 11 . )","label":"Background","metadata":{},"score":"77.484146"}{"text":"Proceedings of 1992 International Conference on Acoustics , Speech , and Signal Processing ( ICASSP 92 ) , I-197 to I-200 , San Francisco .U.S.A. ( March 1992 for further detail concerning the above described operations of the speech understanding unit 11 . )","label":"Background","metadata":{},"score":"77.484146"}{"text":"For example , when the sampling frequency of the A / D conversion is 12 KHz , the cut - off frequency will be 5.4 KHz .The mat unit 296 further comprises : a floor mat 2961 to be stepped on by the user ; a floor mat controller 2962 connected to the floor mat 2961 ; and a floor mat controller interface 2963 connected to the floor mat controller 2962 .","label":"Background","metadata":{},"score":"77.494995"}{"text":"I suspect that the vocal quality aspect would be a wonderful rendering style applied to the prosodic glyphs .Breathy vocal quality would have a degree of blur to the font edges ; creaky voice would have lines running through the font like an old cinematic film .","label":"Background","metadata":{},"score":"77.53265"}{"text":"Duration is the amount of time from the onset of the syllable to the onset of silence , or the onset of another syllable .Loudness , although a perceptual quality , is treated here as the direct measurement of speech amplitude .","label":"Background","metadata":{},"score":"77.643135"}{"text":"The speech dialogue system of claim 13 , wherein the length of the speech response for making the confirmation is determined from information items to be confirmed by the confirmation .The speech dialogue system of claim 14 , wherein the full speech response mentions all of the information items to be confirmed while the simplified speech response does directly not mention the information items to be confirmed .","label":"Background","metadata":{},"score":"77.678894"}{"text":"The speech dialogue system of claim 13 , wherein the length of the speech response for making the confirmation is determined from information items to be confirmed by the confirmation .The speech dialogue system of claim 14 , wherein the full speech response mentions all of the information items to be confirmed while the simplified speech response does directly not mention the information items to be confirmed .","label":"Background","metadata":{},"score":"77.678894"}{"text":"[ FOd ] designates the dynamic range of the pitch contour and its numerical value indicates the range scaling factor .[/V ] designates the downward projecting modification of the pitch contour from the beginning to the peak and its numerical value indicates the degree of such modification .","label":"Background","metadata":{},"score":"77.733635"}{"text":"Or is it an arrangement of primitive marks , each uniquely rendered ?Most recently , Adobe made a set of Multiple Master fonts which proportions designers can adjust , moving the point instance of the font through a graphic space of fifteen dimensions .","label":"Background","metadata":{},"score":"77.76923"}{"text":"A set of glyphs that represent the alphabet is called a font .A font usually has a unifying visual style that distinguishes it from glyphs belonging to other fonts .In the age of electronic production , a glyph has become as abstract a concept as a letter .","label":"Background","metadata":{},"score":"77.805084"}{"text":"The command \" Weak \" narrows the dynamic ranges of the pitch and power , the command \" Doubt \" raises the word - final pitch .These examples of control are in the case where these commands are applied to the editing of Japanese speech .","label":"Background","metadata":{},"score":"77.82016"}{"text":"The selection is based on the particular attribute and question about it so that it gives the best predictive value for the classification or bin .When the tree reaches the leaf nodes , the probability about the distribution of all instances in the branch is calculated , which is then used as predictors for the new raw data .","label":"Background","metadata":{},"score":"77.87073"}{"text":"Written language represents the linguistic channel .Prosodic Font goes further to represent the paralinguistic channel on top of the visual linguistic representations .Dr. Robert Ladd describes the coordination of the paralinguistic and linguistic : . \" The central difference between paralinguistic and linguistic messages resides in the quantal or categorical structure of linguistic signalling and the scalar or gradient nature of paralanguage .","label":"Background","metadata":{},"score":"77.95804"}{"text":"Consecutive relationships always move from left to right , similar to the linear order of reading .In the b , first the line stroke and then the circle stroke ; vice - versa for the d. If four strokes are related through a consecutive relationship , they are drawn side - by - side , overlapping by the value of the current glyph weighting ( or thickness ) .","label":"Background","metadata":{},"score":"77.96816"}{"text":"If a low stop value is used , the over trained tree can be pruned using the hold out option , where a subset is removed from the training set and then used for pruning to build a smaller CART .The Wagon Cart requires a special structure of input - a prosodic feature vector ( PFV)-i.e a vector that contains prosodic features in both predictor and predictees .","label":"Background","metadata":{},"score":"77.97266"}{"text":"22C , the response sentence of \" Let me confirm .Your orders are one large cola and three small potatoes , right ? \" as shown in FIG .22D can be obtained .The human character feature determination unit 132 determines the movement and the facial expression of the human character image to deliver the speech response .","label":"Background","metadata":{},"score":"78.0245"}{"text":"22C , the response sentence of \" Let me confirm .Your orders are one large cola and three small potatoes , right ? \" as shown in FIG .22D can be obtained .The human character feature determination unit 132 determines the movement and the facial expression of the human character image to deliver the speech response .","label":"Background","metadata":{},"score":"78.0245"}{"text":"22C , the response sentence of \" Let me confirm .Your orders are one large cola and three small potatoes , right ? \" as shown in FIG .22D can be obtained .The human character feature determination unit 132 determines the movement and the facial expression of the human character image to deliver the speech response .","label":"Background","metadata":{},"score":"78.0245"}{"text":"22C , the response sentence of \" Let me confirm .Your orders are one large cola and three small potatoes , right ? \" as shown in FIG .22D can be obtained .The human character feature determination unit 132 determines the movement and the facial expression of the human character image to deliver the speech response .","label":"Background","metadata":{},"score":"78.0245"}{"text":"By the time the baby becomes an adult , she will have developed a vast repertoire numbering in the thousands of subtle intonational tunes that communicate the way she feels about what she 's saying - or the way she 's feeling when she 's talking ( Bolinger , 1989 ) .","label":"Background","metadata":{},"score":"78.03357"}{"text":"Education , 1 , 205 - 221 .Ferandez and Garcia - Mateo , Distributed Speech Recognition over IP networks on the Aurora 3 Database , ICSLP -2002 Proceedings , Denver , Colo. , USA .Ferguson , J. D. , Hidden Markov Analysis : An Introduction , in Hidden Markov Models for Speech , Institute of Defense Analyses , Princeton , N.J. 1980 .","label":"Background","metadata":{},"score":"78.051056"}{"text":"The system of . claim 10 , in which the prosodic features are encoded within a prosodic feature vector .The system of . claim 15 , in which the prosodic feature vector is a multimodal feature vector .The system of . claim 10 , in which the discourse function is an intra - sentential discourse function .","label":"Background","metadata":{},"score":"78.07938"}{"text":"Speakers use high and low ranges to different semantic effect .In Ohala 's ethology - inspired \" universal frequency code , \" high pitches convey smallness and attitudes of defenselessness while low tones convey dominance and power ( 1983 ) .","label":"Background","metadata":{},"score":"78.13783"}{"text":"The dynamic range of the pitch contour is narrowed .( c )The pattern of the vowel at the ending of the word utterance is made a monotonically declining pattern .( d )The pattern of the vowel at the ending of the word utterance is made a monotonously rising pattern .","label":"Background","metadata":{},"score":"78.23666"}{"text":"The system of .claim 29 , wherein said prosodic data is transmitted with a higher priority than said acoustic feature data .The system of .claim 30 , wherein said prosodic data is selected and configured to have a data content which is significantly less than said acoustic feature data .","label":"Background","metadata":{},"score":"78.29649"}{"text":"The above embodiment has been described mainly in connection with Japanese and some examples of application to English .In general , when a Japanese text is expressed using Japanese alphabetical letters , almost all letters are one - syllabled - this allows comparative ease in establishing correspondence between the character positions and the syllables in the text .","label":"Background","metadata":{},"score":"78.31177"}{"text":"Natural Language and Linguistic Theory 15 .In I. Roca ( ed . )Constraints and Derivations in Phonology .Oxford University Press , Oxford , 125 - 152 .Studies in African Linguistics 25 , 29 - 60 .Phonology 13 .","label":"Background","metadata":{},"score":"78.37021"}{"text":"The speech dialogue system of claim 13 , wherein said length of said speech response for making said confirmation is determined from information items to be confirmed by said confirmation .The speech dialogue system of claim 14 , wherein said full speech response mentions all of said information items to be confirmed while said simplified speech response does not directly mention said information items to be confirmed .","label":"Background","metadata":{},"score":"78.39671"}{"text":"The speech dialogue system of claim 13 , wherein said length of said speech response for making said confirmation is determined from information items to be confirmed by said confirmation .The speech dialogue system of claim 14 , wherein said full speech response mentions all of said information items to be confirmed while said simplified speech response does not directly mention said information items to be confirmed .","label":"Background","metadata":{},"score":"78.39671"}{"text":"However , this kind of automatic informational prosodic processing may prove unnecessary since speakers naturally perform these accents and rhythmic expansions , and Prosodic Font will mirror any evident vocal emphasis .TYPOGRAPHY .Typography is an ancient craft and an old profession as well as a constant technological frontier .","label":"Background","metadata":{},"score":"78.47299"}{"text":"a comparator component which applies machine learning to the datasets - i.e . the dataset corresponding to the features extracted from the speech samples are fed to a decision tree - based machine learning algorithm .Decision trees implemented using algorithms learned from the dataset effectuate the decision tree used in the real - time emotion detector .","label":"Background","metadata":{},"score":"78.52183"}{"text":"FIG .4 shows an exemplary sentence 400 annotated according to this invention .The exemplary sentence is temporally annotated with discourse function information .The exemplary sentence 400 is comprised of a command portion 410 and a content portion 420 .","label":"Background","metadata":{},"score":"78.55705"}{"text":"Combinations of the above primary features such as [ F 0- RANGEDUR ] or [ F 0- RANGERMSDUR ] will be calculated and used in the analysis .[ 0000 ] .Classification of Acoustic Features for Prosodic Modeling .[ 0147 ] .","label":"Background","metadata":{},"score":"78.59867"}{"text":"A key concept in emotion theory is the representation of emotion as a two - dimensional activation - evaluation space .As seen in .FIG .4 , the activation of the emotion state - the vertical axis , represents the activity of the emotion state , e.g. exhilaration represents a high level of activation , whereas boredom involves a small amount of activation .","label":"Background","metadata":{},"score":"78.602844"}{"text":"Yet the medium has changed so radically that heuristics that formerly defined typography - differences between abstract letters and tangible letterforms - are not sufficient .Beauty , style , form and measurement of font design requires re - evaluation in light of this new computational , temporal medium .","label":"Background","metadata":{},"score":"78.62042"}{"text":"The three characters denoted by reference numeral 8 are larger in size than the characters preceding and following them - this indicates that the amplitude value is on the increase .The five characters indicated by reference numeral 10 on the last line differ in font from the other characters .","label":"Background","metadata":{},"score":"78.67304"}{"text":"For example , given that classes are defined as basic concepts , a simple form of a command is as follows : .[ 0049 ] .template command(action ) .[ 0050 ] .[ 0051 ] .[ 0052 ] .","label":"Background","metadata":{},"score":"78.74173"}{"text":"No physical evidence has been found to confirm this , and in fact , there is more evidence that the pitch range should be understood as emanating from the bottom of the speaker 's range .The F0 movements can roughly be described as positive deviations ... from this base level ...","label":"Background","metadata":{},"score":"78.75432"}{"text":"Demand for knowledge sharing and learning in the U.S. has increased due to several factors including : .Competition from an increasingly skilled global workforce .Virtualization and outsourcing of highly skilled projects and services to more cost competitive - i.e . lower cost , human resources in areas outside the U.S. .","label":"Background","metadata":{},"score":"78.790726"}{"text":"The size of the CART tree is optimized by means of the stopping criteria , which define the point when splitting of the nodes stops , i.e. when the purity of the node is highest .Another approach is to prune the tree - i.e .","label":"Background","metadata":{},"score":"78.83899"}{"text":"[ 0000 ] .Representative Prosodic Features .[ 0053 ] .Pitch - the fundamental frequency , FO of a speech utterance is the acoustic correlate of pitch .It is considered to be one of the most important attributes in expressing and detecting emotion .","label":"Background","metadata":{},"score":"78.892395"}{"text":"The message plays in a prosodic font , reflecting the sender 's tone of voice , rhythm , loudness , and forcefulness in the systematic movement of the syllables over time .You can see in the words how the sender expresses emotion vocally , and you understand more deeply what she meant to convey to you by seeing how the words change relative to each other .","label":"Background","metadata":{},"score":"78.90071"}{"text":"Proceedings of the 2002 Interservice / Industry Training Simulation , and Education Conference [ CD - ROM].Arlington , Va. : National Defense Industrial Association .Shneiderman , B. ( 2000 ) , The Limits of Speech Recognition .Communications of the ACM .","label":"Background","metadata":{},"score":"78.948845"}{"text":"The solid line indicates an unmodified original pitch contour ( a standard pitch contour obtained from the speech synthesis rule database 14 by a sentence structure analysis , for instance ) .( a )The dynamic range of the pitch contour is enlarged .","label":"Background","metadata":{},"score":"79.006645"}{"text":"Notes on transitivity and theme in English , Part 2 .Journal of Linguistics , 3 , 199 - 244 .Hawley , M. ( 1993 ) .Structure out of Sound .Ph.D. Thesis at the Massachusetts Institute of Technology , Media Lab , Cambridge , MA .","label":"Background","metadata":{},"score":"79.03052"}{"text":"In languages other than Japanese , however , there are many cases where the position of the syllable in a word does not simply correspond to the position of the word in the character string as in the case of English .","label":"Background","metadata":{},"score":"79.03881"}{"text":"Fundamental frequency is a product of voiced sounds , of vibrating the glottal folds during vocalization .Fundamental frequency trackers approach unvoiced phonemes differently , including leaving an empty duration , or using straight line interpolation between the preceding and succeeding voiced phonemes .","label":"Background","metadata":{},"score":"79.19517"}{"text":"This interface 34 allows applications 26 to load custom grammars , or define task specific vocabulary .The external application interface 34 also allows applications 26 to explicitly tap into the speech center 20 for speech recognition and synthesis services .[ 0031 ] .","label":"Background","metadata":{},"score":"79.21455"}{"text":"The data structure for storing exemplary discourse function prosody information 1170 contains the value \" 175 \" in the initial frequency portion 1030 .This value indicates the average initial frequency information for discourse functions of type \" SUBORDINATION \" .The data structure for storing exemplary discourse function prosody information 1170 contains the value \" 0.15 \" in the pitch variation portion 1040 .","label":"Background","metadata":{},"score":"79.24082"}{"text":"claim 1 , wherein said emotion state includes at least one of CERTAINTY , UNCERTAINTY and/or DOUBT .A method for performing real - time emotion detection comprising : . extracting selected acoustic features of a speech utterance ; . extracting syntactic cues relating to an emotion state of a speaker of said speech utterance ; . classifying inputs from said prosody analyzer and said parts - of - speech analyzer and processing the same to output an emotion cue data value corresponding to said emotion state .","label":"Background","metadata":{},"score":"79.269"}{"text":"Finscheidt , T. , Aalburg , S. , Stan , S. , Beaugeant , C. , Network - Based vs .Distributed Speech Recognition in Adaptive Multi - Rate Wireless Systems , ICSLP -2002 Proceedings , 7 th International Conference On Spoken Language Processing , September 2002 , Denver , Colo. , USA .","label":"Background","metadata":{},"score":"79.326355"}{"text":"The speech dialogue system of claim 13 , wherein said full speech response recites said response output explicitly while said simplified speech response does not recite said response output explicitly .The speech dialogue system of claim 17 , wherein said simplified speech response contains a demonstrative pronoun to refer to said visual response .","label":"Background","metadata":{},"score":"79.36357"}{"text":"The speech dialogue system of claim 13 , wherein said full speech response recites said response output explicitly while said simplified speech response does not recite said response output explicitly .The speech dialogue system of claim 17 , wherein said simplified speech response contains a demonstrative pronoun to refer to said visual response .","label":"Background","metadata":{},"score":"79.36357"}{"text":"The determined theory of discourse may include , the Unified Linguistic Discourse Model ( ULDM ) , the Rhetorical Structure Theory ( RST ) , the Discourse Structure Theory , the Structured Discourse Representation Theory ( SDRT ) or any known or later developed theory of discourse analysis .","label":"Background","metadata":{},"score":"79.370605"}{"text":"Choice 1A Choice 1B Choice 1C .Circle the word that best describes the emotion the font is expressing : .Anger Excitement Satisfaction Sadness .BIBLIOGRAPHY .Adobe Systems Incorporated .The Compact Font Format Specification .Technical Note # 5176 .","label":"Background","metadata":{},"score":"79.38837"}{"text":"The Market .[ 0178 ] .The e - Learning market is poised for explosive growth through 2005 .The global e - Learning market was projected to grow to approximately $ 4.2 billion .By 2005 , it will hit approximately $ 33.6 billion .","label":"Background","metadata":{},"score":"79.42001"}{"text":"In some instances because of the nature of the data communicated , it may be desirable to format a prosodic data packet with different payload than a corresponding speech recognition data packet ( i.e. , such as an MFCC packet sent via an RTP protocol for example ) .","label":"Background","metadata":{},"score":"79.491936"}{"text":"The method of .claim 9 , wherein visual cues are also used to elicit said distinct emotion states .The method of .claim 9 , wherein said annotations are derived from Kappa statistics associated with a second group of reviewers .","label":"Background","metadata":{},"score":"79.601654"}{"text":"This high speed processor 2971 is used in executing a large scale processing required in the speech understanding operation and the response generation operation .In a case of using the user detection mechanism using monitoring camera , this high speed processor 2971 may also be used in the large scale processing required in the image processing in conjunction with the monitoring camera .","label":"Background","metadata":{},"score":"79.64978"}{"text":"I describe this process below . 5.1 SPEECH CORPUS DEVELOPMENT .Emotional speech , such as anger , sadness , satisfaction , and excitement , engender very different physiological - thus changing phonetic qualities - and prosodic responses ( Kappas , Hess and Scherer , 1991 ) .","label":"Background","metadata":{},"score":"79.668396"}{"text":"A description will be given of an example of application of the - layer prosodic feature control commands to English text .The command [ FOd ] sets the dynamic range of pitch at a value double designated by ( 2.0 ) subsequent to the command .","label":"Background","metadata":{},"score":"79.72223"}{"text":"He found that humans can on average recognize vocal affect with about 60 % reliability : people can distinguish arousal ( angry versus sad ) but frequently confuse valence ( angry versus enthusiastic ) ( 1981 ) .Prosodic Font does not seek to label speech as any particular type of emotion due to the inability in all but the simplest cases to infer emotional categories based upon vocal characteristics .","label":"Background","metadata":{},"score":"79.744675"}{"text":"For example , the word \" actually \" is often pronounced as \" akshly . \"Which form of the word should a Prosodic Font serve ?The danger in adhering to phonemic realization is that written language may become difficult to read , or even unreadable .","label":"Background","metadata":{},"score":"79.83985"}{"text":"OM agents employ ICL via solvables to perform queries , execute actions , exchange information , set triggers and manipulate data in the agent community .6 The SRI Open Agent Architecture ( OAA ) is a framework for integrating the various components that comprise a spoken dialogue system such as the FASTER ITS .","label":"Background","metadata":{},"score":"79.89629"}{"text":"All but one correctly identified the predominate emotion in the Prosodic Font as excitement .Higher success was achieved in the second example .Nine out of eleven subjects chose the correct audio file , and identified anger as the predominate emotion .","label":"Background","metadata":{},"score":"79.904305"}{"text":"In Plans and Intentions in Communication and Discourse , Eds .P. R. Cohen , J. Morgan , and M. E. Pollack , Cambridge : MIT Press , 271 - 311 .Prevost , S. & Steedman , M. ( 1994 ) .","label":"Background","metadata":{},"score":"79.995995"}{"text":"Figure is after Ladd ( 1996 ) .Grandour and Harshman conducted studies on tone and range perception and found that for English speakers , average pitch and extreme endpoints were the most salient perceptual features ; while for speakers of tone languages ( e.g. Thai and Yoruba ) direction and slope proved most salient .","label":"Background","metadata":{},"score":"80.04636"}{"text":"Prosody - the rhythmic and melodic qualities of speech that are used to convey emphasis , intent , attitude and semantic meaning , is a key component in the recovery of the speaker 's communication and expression embedded in a speech utterance .","label":"Background","metadata":{},"score":"80.165695"}{"text":"Speech Communication 15 , 139 - 153 .Scherer , K. R. ( 1981 ) . \"Speech and emotional states . \"In Speech Evaluation in Psychiatry .Ed . , J. K. Darby , Grune and Stratton , Inc. , 189 - 220 .","label":"Background","metadata":{},"score":"80.226425"}{"text":"Prosodic Font 's focus continues beyond to that of prosody - the paralinguistic features of speech that convey a multiplicity of emotional , informational and situated meanings .Prosody is a paralinguistic category that can describe the song - or intonation , rhythm , and vocal timbre ( or voice quality ) found in all spoken utterances of all languages .","label":"Background","metadata":{},"score":"80.23422"}{"text":"To handle words in which a number of letters are pronounced as a single phoneme , I invented the notion of phonetic ligature .The most common phonetic ligature is the ' ng ' in any gerund verb form , such as \" painting \" .","label":"Background","metadata":{},"score":"80.272"}{"text":"In the experiments , a Japanese word \" Urayamashii \" ( which means \" envious \" ) was used .A plurality of length - varied versions of this word , obtained by changing its character spacing variously , were written side by side .","label":"Background","metadata":{},"score":"80.29341"}{"text":"Intonation researcher Dwight Bolinger defines intonation as , \" all uses of fundamental pitch that reflect inner states ... \" ( 1989 , p. 3 ) .There is evidence that speakers intone with a high degree of precision .Subtle intonational changes can radically affect the hearer 's interpretation of the words , as well as provide a window onto the speaker 's affective state .","label":"Background","metadata":{},"score":"80.39871"}{"text":"For example , it is important that a Prosodic Font sign screaming , \" FIRE ! \" remain readable during events when prosodic variation and voice quality is extreme .Figure 29 : The lowercase glyph ' b ' letterform can change proportions continuously .","label":"Background","metadata":{},"score":"80.458115"}{"text":"With the above - described MSCL system , it is possible to designate some voice qualities of high to low pitches , in addition to male and female voices .This is not only to simply change the value of the pitch or fundamental frequency of synthetic speech but also to change the entire spectrum thereof in accordance with the frequency spectrum of the high- or low - pitched voice .","label":"Background","metadata":{},"score":"80.61865"}{"text":"Kagan , J. , Sindman , N. , Arcus , D. , & Reznick , J.S. ( 1994 ) .Galen 's Prophecy : Temperament in Human Nature .New York : Basic Books , Division of HarperCollins .Kappas , A. , Hess , U. , & Scherer , K.R. ( 1991 ) . \"","label":"Background","metadata":{},"score":"80.73046"}{"text":"Prosodic Font GUI could include emotional templates that users could apply to certain messages , sentences , phrases and words .APPENDIX A : TILT FILE EXAMPLE . tilt .Format of file is as follows : End Time ; SPSS color ; Event Number ; Event Type ; tilt : Start F0 ; .","label":"Background","metadata":{},"score":"80.77363"}{"text":"Now , consider a case in which the user uttered the input speech of \" Eh , two hamburgers , and . . .well . . .two coffees , please . \" in haste , in response to the message shown in FIG .","label":"Background","metadata":{},"score":"80.821365"}{"text":"Now , consider a case in which the user uttered the input speech of \" Eh , two hamburgers , and . . .well . . .two coffees , please . \" in haste , in response to the message shown in FIG .","label":"Background","metadata":{},"score":"80.821365"}{"text":"Now , consider a case in which the user uttered the input speech of \" Eh , two hamburgers , and . . .well . . .two coffees , please . \" in haste , in response to the message shown in FIG .","label":"Background","metadata":{},"score":"80.821365"}{"text":"Now , consider a case in which the user uttered the input speech of \" Eh , two hamburgers , and . . .well . . .two coffees , please . \" in haste , in response to the message shown in FIG .","label":"Background","metadata":{},"score":"80.821365"}{"text":"Gender identification causes exaggerated prosodic effects that are not justified by the physiological difference between the average man and woman .Men tend to do the opposite , to which we can add ( 1 ) that they are more apt to drop into the lower register change , namely creak \" ( 1989 , p. 24 ) .","label":"Background","metadata":{},"score":"80.832146"}{"text":"I describe two major iterations of my work below and the system I have accepted .I call the shapes that serve as architectural units within a single glyph , strokes .One or more strokes together can form a glyph .","label":"Background","metadata":{},"score":"80.89053"}{"text":"VocalEvent Types : .Vocal Quality Types : .Key to Phonetic Constants within Syllable Vocal Events : .File : K - S - sunset29s . words .APPENDIX C : FONT FILE .Note :In this implementation , Simultaneity is not defined in the font specification , but rather in the code .","label":"Background","metadata":{},"score":"80.995094"}{"text":"The system of .claim 14 wherein the classifier is a trained Classification and Regression Tree classifier .The system of .claim 14 wherein said classifier is trained with data obtained during an off - line training phase .The system of .","label":"Background","metadata":{},"score":"80.99663"}{"text":"FIG .30B is a timing chart for another example of a display timing control to be made in a response output control unit in the response generation unit of FIG .19 .FIG .31A is a timing chart for another example of a display timing control to be made in a response output control unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"81.03105"}{"text":"FIG .30B is a timing chart for another example of a display timing control to be made in a response output control unit in the response generation unit of FIG .19 .FIG .31A is a timing chart for another example of a display timing control to be made in a response output control unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"81.03105"}{"text":"FIG .30B is a timing chart for another example of a display timing control to be made in a response output control unit in the response generation unit of FIG .19 .FIG .31A is a timing chart for another example of a display timing control to be made in a response output control unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"81.03105"}{"text":"FIG .30B is a timing chart for another example of a display timing control to be made in a response output control unit in the response generation unit of FIG .19 .FIG .31A is a timing chart for another example of a display timing control to be made in a response output control unit in the response generation unit of FIG .","label":"Background","metadata":{},"score":"81.03105"}{"text":"Wang , K. , SALT : A Spoken Language Interface for Web - Based Multimodal Dialog Systems , 7th International Conference On Spoken Language Processing , September 2002 , Denver , Colo. , USA .Weld , D. & de Kleer , J. ( 1990 ) , Readings in Qualitative Reasoning about Physical Systems , Menlo Park , Calif. : Morgan Kaufmann .","label":"Background","metadata":{},"score":"81.07726"}{"text":"Stat . , 37 : 1554 - 1563 , 1966 .Bennett , C. et al , Building VoiceXML - based Applications , ICSLP -2002 Proceedings , 7 th International Conference On Spoken Language Processing , September 2002 , Denver , Colo. , USA .","label":"Background","metadata":{},"score":"81.201706"}{"text":"The x uses two slanted line strokes simultaneously while the v uses them consecutively .In historical typographic practice , the x glyph is not actually constructed of two crossing lines , but rather four lines that do n't meet precisely .","label":"Background","metadata":{},"score":"81.23103"}{"text":"The cut - off frequency of this low pass filtering function is determined according to the sampling frequency used in the A / D conversion .For example , when the sampling frequency of the A / D conversion is 12 KHz , the cut - off frequency will be 5.4 KHz .","label":"Background","metadata":{},"score":"81.23717"}{"text":"The cut - off frequency of this low pass filtering function is determined according to the sampling frequency used in the A / D conversion .For example , when the sampling frequency of the A / D conversion is 12 KHz , the cut - off frequency will be 5.4 KHz .","label":"Background","metadata":{},"score":"81.23717"}{"text":"The cut - off frequency of this low pass filtering function is determined according to the sampling frequency used in the A / D conversion .For example , when the sampling frequency of the A / D conversion is 12 KHz , the cut - off frequency will be 5.4 KHz .","label":"Background","metadata":{},"score":"81.23717"}{"text":"In preferred embodiments the classifier is a trained Classification and Regression Tree classifier , which is trained with data obtained during an off - line training phase .The classifier uses a history file containing data values for emotion cues derived from a sample population of test subjects and using a set of sample utterances common to content associated with the real - time recognition system .","label":"Background","metadata":{},"score":"81.310074"}{"text":"We will read and critique current articles , focusing on detailed case studies of particular languages , such as Swedish , Japanese , Chichewa , Thai , Chatino , and Serbian - Croatian .We will assess the implications of these systems for issues such as the representation of tone and tone patterns , the production and perception of fundamental frequency contours , and the organization of speech into intonational phrases .","label":"Background","metadata":{},"score":"81.38103"}{"text":"Cho , Peter .( 1997 )Pliant Type : Experiments in Expressive and Malleable Typography .Massachusetts Institute of Technology , S.B. Thesis .Clumeck , Harold .Topics in the acquisition of Mandarin phonology : A case study .Papers and Reports on Child Language Development , Stanford University .","label":"Background","metadata":{},"score":"81.44115"}{"text":"Following , the humanist rationalist movement formed letters with the weight of the letter distributed around a perfect vertical from the horizon .Lastly , what might be considered a sub - division of the humanist rationalist movement because of its perfect vertical orientation , sans serif letterforms lost the beginnings and endings nostalgic of the broad - nibbed pen .","label":"Background","metadata":{},"score":"81.45708"}{"text":"This third embodiment differs from the first and second embodiments described above in that the further detail of the practical implementation of the speech dialogue system configuration is incorporated .Here , the filter and amplifier 2952 has functions of an amplification of the input speech received by the microphone 2951 and of a low pass filtering for the sake of the A / D conversion at the A / D converter 2953 .","label":"Background","metadata":{},"score":"81.50578"}{"text":"Small studied different visual techniques of differentiating one voice from another in conversation using RSVP techniques ( 1996 ) .He found that most people find prosodic representation within RSVP harder to read than a steady , rhythmic presentation of words .","label":"Background","metadata":{},"score":"81.559"}{"text":"Reading , MA : Addison Wesley Publishing Company ._ _ _ _ .( 1986b ) .METAFONT : The Program .Reading , MA : Addison Wesley Publishing Company .Ladd , D. R. ( 1980 ) .The Structure of Intonational Meaning .","label":"Background","metadata":{},"score":"81.566216"}{"text":"Visual effects are cumulative , and as such , somewhat unpredictable .The phonetic speech labels , such as \" emphatic plosive \" , \" flap \" , \" glottal \" and \" lengthened phone \" were all identified and labeled by hand .","label":"Background","metadata":{},"score":"81.59303"}{"text":"For example , a goal is to support a grammatic specification 90 for asserting a property for an object in the base grammar .In conventional Backus Naur Form ( BNF ) , the grammatic specification 90 might take the form : . [","label":"Background","metadata":{},"score":"81.607445"}{"text":"[0048 ] .Although the ontology 64 represents the semantic structure of the domain model 70 , the ontology 64 says nothing about the language used to speak about the domain model 70 .That information is contained within the syntax specification .","label":"Background","metadata":{},"score":"81.619675"}{"text":"Grading Policy The grade will be based on homework assignments ( roughly one a week ) , and two tests .Texts There is no textbook for this course .Publications .In T. Borowsky , S. Kawahara , T. Shinya , and M. Sugahara ( eds . )","label":"Background","metadata":{},"score":"81.62952"}{"text":"The following results , substantially as predicted , were obtained .Short duration : Narrow character spacing ( 88 % ) .Long duration : Wide character spacing ( 100 % ) .Next , a description will be given of experimental results obtained concerning the prosodic features of the fundamental frequency ( pitch ) and amplitude value ( power ) .","label":"Background","metadata":{},"score":"81.663475"}{"text":"The speech dialogue system of claim 13 , wherein the full speech response recites the response output explicitly while the simplified speech response does not recite the response output explicitly .The speech dialogue system of claim 17 , wherein the simplified speech response contains a pronoun to refer to the visual response .","label":"Background","metadata":{},"score":"81.69717"}{"text":"The speech dialogue system of claim 13 , wherein the full speech response recites the response output explicitly while the simplified speech response does not recite the response output explicitly .The speech dialogue system of claim 17 , wherein the simplified speech response contains a pronoun to refer to the visual response .","label":"Background","metadata":{},"score":"81.69717"}{"text":"Then , at the timing t1 , the content visualizing image showing two hamburgers , one cheese burger , and three coffees is displayed .Here , the new text data as well as the content visualizing image are continued to be displayed even after the timing t4 until the next system response output stage .","label":"Background","metadata":{},"score":"81.70787"}{"text":"Then , at the timing t1 , the content visualizing image showing two hamburgers , one cheese burger , and three coffees is displayed .Here , the new text data as well as the content visualizing image are continued to be displayed even after the timing t4 until the next system response output stage .","label":"Background","metadata":{},"score":"81.70787"}{"text":"Then , at the timing t1 , the content visualizing image showing two hamburgers , one cheese burger , and three coffees is displayed .Here , the new text data as well as the content visualizing image are continued to be displayed even after the timing t4 until the next system response output stage .","label":"Background","metadata":{},"score":"81.70787"}{"text":"Then , at the timing t1 , the content visualizing image showing two hamburgers , one cheese burger , and three coffees is displayed .Here , the new text data as well as the content visualizing image are continued to be displayed even after the timing t4 until the next system response output stage .","label":"Background","metadata":{},"score":"81.70787"}{"text":"claim 6 , in which the prosodic feature vector is a multimodal feature vector .The method of .claim 1 , in which the discourse function is an intra - sentential discourse function .The method of .claim 1 , in which the discourse function is an inter - sentential discourse function .","label":"Background","metadata":{},"score":"81.70855"}{"text":"Prosodic typography is the electronic intervention between speech and text .It represents the contextual , individual aspects of speech that printed typography does not capture .Prosodic Font is a project that explores what becomes possible when speech recognition merges with dynamic forms of typography .","label":"Background","metadata":{},"score":"81.7399"}{"text":"Graphic interface design work can be done on how to allow a user to design a Prosodic Font message using a standard GUI approach .The user would type a message and then add prosodic contours and accents to the orthographic message that would automatically transform it into a Prosodic Font message .","label":"Background","metadata":{},"score":"81.74869"}{"text":"The content portion 420 is comprised of a single text portion 421 .Prosodic features are used to segment the speech utterance into a command portion 410 and a content portion 420 .However , it should be apparent that the predictive discourse function models may also be used to determine any type of discourse function recognizable by the theory of discourse analysis .","label":"Background","metadata":{},"score":"82.04414"}{"text":"The point at which breath becomes an identifiable phoneme is unclear .The intrinsic formation of a phoneme allows for easier or more difficult on- or off - set detection .For example , a non - glottalized vowel onset , /u/ , will be more difficult to detect than the onset of a consonantal plosive , /p/. These problems are not solvable by technology , but rather through re - definition of the problem .","label":"Background","metadata":{},"score":"82.12356"}{"text":"Papers from the 1998 AAAI Spring Symposium , Technical Report SS-98 - 01 ( J. Chu - Carroll et al , eds . )Stanford CA pp .98 - 105 , AAAI Press , Menlo Park CA . 1998 .Free format text : ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS : AZARA , MISTY;POLANYI , LIVIA;THIONE , GIOVANNI L.;AND OTHERS;REEL / FRAME:015005/0383;SIGNING DATES FROM 20040210 TO 20040211 .","label":"Background","metadata":{},"score":"82.17597"}{"text":"Prosodic prominence is created through intonational contours ; hence , it is an accent conveyed as an aspect of the utterance 's tune .It is also called intonational accent , pitch accent , or just accent .Accent is placed upon syllables that are often , but not exclusively , found within the class of lexically prominent syllables .","label":"Background","metadata":{},"score":"82.207085"}{"text":"The METAFONT and Multiple Master glyphs are designed as a series of lines and curves and thickness , similar historical glyph lead carvings .Because they are not complex architectures of independent elements , it is extremely difficult to map speech parameters onto noticeably independent graphic parameters .","label":"Background","metadata":{},"score":"82.26654"}{"text":"ASSP -23(1 ) : 24 - 29 , February 1975 .Baum L. E. , An inequality and associated maximization technique in statistical estimation for probabilistic functions of Markov processes , Inequalities 3 : 1- 8 , 1972 .Baum , L. E. , Petrie , T. , Statistical inference for probabilistic functions for finite state Markov chains , Ann .","label":"Background","metadata":{},"score":"82.27916"}{"text":"The system of . claim 19 , wherein said emotion state is used to formulate a response by an interactive agent in a real - time natural language processing system .The system of . claim 19 , wherein said emotion state is used by an interactive agent to control dialog content and/or a dialog sequence with a user of a speech recognition system .","label":"Background","metadata":{},"score":"82.34274"}{"text":"30A , 30B , 31A , and 31B , the output timings are determined according to the speech duration of each part of the speech response .Thus , in FIG .30A , the period between the timings t0 and t1 is determined by the speech duration required for outputting the speech response of \" Welcome to Tos Burger . \" , and so on .","label":"Background","metadata":{},"score":"82.43536"}{"text":"30A , 30B , 31A , and 31B , the output timings are determined according to the speech duration of each part of the speech response .Thus , in FIG .30A , the period between the timings t0 and t1 is determined by the speech duration required for outputting the speech response of \" Welcome to Tos Burger . \" , and so on .","label":"Background","metadata":{},"score":"82.43536"}{"text":"30A , 30B , 31A , and 31B , the output timings are determined according to the speech duration of each part of the speech response .Thus , in FIG .30A , the period between the timings t0 and t1 is determined by the speech duration required for outputting the speech response of \" Welcome to Tos Burger . \" , and so on .","label":"Background","metadata":{},"score":"82.43536"}{"text":"30A , 30B , 31A , and 31B , the output timings are determined according to the speech duration of each part of the speech response .Thus , in FIG .30A , the period between the timings t0 and t1 is determined by the speech duration required for outputting the speech response of \" Welcome to Tos Burger . \" , and so on .","label":"Background","metadata":{},"score":"82.43536"}{"text":"I required one punctuation mark - the apostrophe - for the numerous contracted forms of words I encountered in the speech corpus .The final Prosodic Glyph specification actually turned out to be much more flexible as a creative design system than I would have suspected .","label":"Background","metadata":{},"score":"82.58849"}{"text":"Replicate strategy and build relationships with other key software vendors , schools , training institutions such as Kaplan , Educational Testing Service ( ETS ) , Thomson and other training companies - key business strategy will be licensing .Collaborate with key technical partners such as SRI International and CHI Systems to leverage advanced technology for driving the development of sophisticated interactive training systems .","label":"Background","metadata":{},"score":"82.6045"}{"text":"28B show the exemplary fundamental frequency patterns for a Japanese sentence of \" Sumimasen Mouichido Onegaishimasu \" meaning \" I 'm sorry .Please say it again \" for the normal case and a case with the regretful emotional expression .","label":"Background","metadata":{},"score":"82.6057"}{"text":"28B show the exemplary fundamental frequency patterns for a Japanese sentence of \" Sumimasen Mouichido Onegaishimasu \" meaning \" I 'm sorry .Please say it again \" for the normal case and a case with the regretful emotional expression .","label":"Background","metadata":{},"score":"82.6057"}{"text":"There is an inherent difficulty in a Prosodic Font in the difference between phonetic and phonology .Broadly speaking , phonology seeks to understand the universal meaning of speech sounds , whereas phonetics seek to understand the mapping of speech sounds to overt expression .","label":"Background","metadata":{},"score":"82.74793"}{"text":"Specifically it is a piece of middleware that supports C++ , Java , Lisp and Prolog and enables one to rapidly prototype components into a system .[ 0152 ] .Research Plan : The front end for the ITS will be implemented by creating software agents for each of the Speech Recognition , Emotion Detector and Natural Language software modules .","label":"Background","metadata":{},"score":"82.77053"}{"text":"[0007 ] .The domain models of the invention include foundation models and application models .The application independent foundation domain model consists of common classes in the speech center system that can be shared and extended by the speech - enabled applications .","label":"Background","metadata":{},"score":"82.89959"}{"text":"The implementation of the machine learning classifier - based experiments will be performed within the WEKA 13 machine learning software environment and with the Stuttgart Neural Network Simulator ( SNNS ) 14 .All of the software that will be used in this objective - PRAAT , WEKA and SNNS is already installed and working on our workstations .","label":"Background","metadata":{},"score":"82.94569"}{"text":"A Theory of Pitch Accent in English .Word 14:2 - 3 , 109 - 149 ._ _ _ _ .Accent is predictable ( if you 're a mind reader ) .Language 48 , 633 - 644 ._ _ _ _ .","label":"Background","metadata":{},"score":"82.95037"}{"text":"Training Example : \" This evening had the touch of someone 's hand which was wonderful , the ... the ... sight of this huge beautiful red sun setting over the Pacific ocean , and this constant wonderful sound of the surf coming in , just washing up constantly .","label":"Background","metadata":{},"score":"83.189545"}{"text":"The microcode and software routines executed to effectuate the inventive methods may be embodied in various forms , including in a permanent magnetic media , a non - volatile ROM , a CD - ROM , or any other suitable machine - readable format .","label":"Background","metadata":{},"score":"83.244026"}{"text":"This rule did not extend to words in which certain letters were not pronounced .I never eliminated letters in order to preserve legibility .However , eliminating certain letters or using colloquial orthography should be experimented with since the color of more casual conversation would be more evident if letters could be eliminated if not spoken .","label":"Background","metadata":{},"score":"83.30148"}{"text":"Prerequisite : Introduction to Phonetics course , or permission of the instructor .Linguistics 344 is an introduction to the sound structure of language .We will explore how the sounds differ across various dialects of English and across the world 's languages .","label":"Background","metadata":{},"score":"83.439285"}{"text":"\" is outputted as a visual response from the display unit 236 and as a speech response From the loudspeaker unit 237 .Next , when the user utters the input speech of \" Hamburgers and coffees , two for each . \" , the speech understanding unit 232 supplies the semantic utterance representation No . 1 based on this input speech to the dialogue management unit 234 .","label":"Background","metadata":{},"score":"83.51247"}{"text":"\" is outputted as a visual response from the display unit 236 and as a speech response From the loudspeaker unit 237 .Next , when the user utters the input speech of \" Hamburgers and coffees , two for each . \" , the speech understanding unit 232 supplies the semantic utterance representation No . 1 based on this input speech to the dialogue management unit 234 .","label":"Background","metadata":{},"score":"83.51247"}{"text":"\" is outputted as a visual response from the display unit 236 and as a speech response from the loudspeaker unit 237 .Next , when the user utters the input speech of \" Hamburgers and coffees , two for each . \" , the speech understanding unit 232 supplies the semantic utterance representation No . 1 based on this input speech to the dialogue management unit 234 .","label":"Background","metadata":{},"score":"83.51247"}{"text":"\" is outputted as a visual response from the display unit 236 and as a speech response from the loudspeaker unit 237 .Next , when the user utters the input speech of \" Hamburgers and coffees , two for each . \" , the speech understanding unit 232 supplies the semantic utterance representation No . 1 based on this input speech to the dialogue management unit 234 .","label":"Background","metadata":{},"score":"83.51247"}{"text":"The present invention enables an ordinary user to effectively create a desired speech message .It is evident that the present invention is applicable not only to Japanese but also other natural languages , for example , German , French , Italian , Spanish and Korean .","label":"Background","metadata":{},"score":"83.53964"}{"text":"Proportions of letterforms from x height to the base line in height and width have been 5:4 .Rounded letters such as ' o ' , ' p ' , ' e ' and ' c ' exceed the x height line and fall equally below the base line to appear as large as the other letters .","label":"Background","metadata":{},"score":"83.62775"}{"text":"Detection of prosody and emotional content in speech is known in the art , and is discussed for example in the following representative references which are incorporated by reference herein : U.S. Pat .No .6,173,260 to Slaney ; U.S. Pat .","label":"Background","metadata":{},"score":"83.716415"}{"text":"This is an introduction to the study of speech sounds - how they are produced , what they sound like , what their physical properties are , and how listeners identify them .The course will have two parts .In the first we will examine closely the pronunciation of English in various dialects .","label":"Background","metadata":{},"score":"83.74837"}{"text":"[ 0074 ] .The outputs of the prosody analyzer 118 and the parts - of - speech analyzer 121 are fed preferably to a trained CART classifier 125 .This classifier 125 is trained with data obtained during the off - line training phase described previously .","label":"Background","metadata":{},"score":"83.828285"}{"text":"Namely , in a case of making a confirmation for example , the response sentence pattern in a form of a positive confirmation such as \" Your orders are two hamburgers , right ? \" and the response sentence pattern in a form of a question such as \" Are your orders two hamburgers ? \" can be used selectively .","label":"Background","metadata":{},"score":"83.93855"}{"text":"Namely , in a case of making a confirmation for example , the response sentence pattern in a form of a positive confirmation such as \" Your orders are two hamburgers , right ? \" and the response sentence pattern in a form of a question such as \" Are your orders two hamburgers ? \" can be used selectively .","label":"Background","metadata":{},"score":"83.93855"}{"text":"The system of . claim 19 , wherein both prosodic data and acoustic feature data are packaged within a common data stream as received at the server device .The system of . claim 19 , wherein prosodic data and acoustic feature data are packaged within different data streams as received at the server device .","label":"Background","metadata":{},"score":"84.07814"}{"text":"The best predictions based on the training data are stored in the leaf nodes of the CART .[0067 ] .[0068 ] .The specific and preferred CART used in the present invention is the Wagon CART of the Edinburgh Speech Tools library .","label":"Background","metadata":{},"score":"84.07896"}{"text":"6,496,799 to Pickering ; U.S. Pat .No . 6,873,953 to Lenning ; U.S. Publication No .2005/0060158 to Endo et al . ; 2004/0148172 to Cohen et al ; U.S. Publication No .2002/0147581 to Shriberg et al . ; and U.S. Publication No .","label":"Background","metadata":{},"score":"84.31842"}{"text":"New Advances and Trends , Eds .Antonio J. Rubio Ayuso and Juan M. Lopez Soler .NATO ASI Series .Series F : Computer and Systems Sciences , v. 147 :p. 329 .Berlin : Springer - Verlag .Knuth , D. ( 1986a ) .","label":"Background","metadata":{},"score":"84.43375"}{"text":"The determined movement and facial expression of the human character image are supplied to the human character image generation unit 133 .The human character image generation unit 133 generates the human character image to be displayed on the display unit 14 according to the movement and the facial expression of the human character image determined at the human character feature determination unit 132 .","label":"Background","metadata":{},"score":"84.4846"}{"text":"The determined movement and facial expression of the human character image are supplied to the human character image generation unit 133 .The human character image generation unit 133 generates the human character image to be displayed on the display unit 14 according to the movement and the facial expression of the human character image determined at the human character feature determination unit 132 .","label":"Background","metadata":{},"score":"84.4846"}{"text":"The determined movement and facial expression of the human character image are supplied to the human character image generation unit 133 .The human character image generation unit 133 generates the human character image to be displayed on the display unit 14 according to the movement and the facial expression of the human character image determined at the human character feature determination unit 132 .","label":"Background","metadata":{},"score":"84.4846"}{"text":"The determined movement and facial expression of the human character image are supplied to the human character image generation unit 133 .The human character image generation unit 133 generates the human character image to be displayed on the display unit 14 according to the movement and the facial expression of the human character image determined at the human character feature determination unit 132 .","label":"Background","metadata":{},"score":"84.4846"}{"text":"The system of . claim 10 , in which the predictive models are determined based on at least one of : machine learning , rules .The system of .claim 12 , in which the machine learning based predictive models are determined based on at least one of : statistics , decision trees , Nave Bayes .","label":"Background","metadata":{},"score":"84.742134"}{"text":"In A. Cutler and D.R.Ladd , editors , Prosody : Models and Measurements , Springer - Verlag , Berlin Germany .Bruce , G. ( 1977 ) .Swedish Word Accents in Sentence Perspective .PhD Thesis , Lund : CWK Gleerup .","label":"Background","metadata":{},"score":"84.79692"}{"text":"Build statistical - based grammars so as to improve accuracy and compatibility with the dialog manager ; Create statistical grammar models ( SLM ) using SRILM ( publicly available from SRI ) from a dialog training corpus .Train SLM using SLM.EXE or other tools .","label":"Background","metadata":{},"score":"84.801674"}{"text":"Figure 22 : Typical examples of a broad - nibbed pen letterform design in textura , fraktur , bastarda , and rotunda .Unlike more modern sans serif forms , pen designed fonts appear to be constructed as an architecture of simpler strokes , drawn in time .","label":"Background","metadata":{},"score":"84.964325"}{"text":"Likewise , the grammatic specification 90 disallows sentences that specify attributes of objects that do not possess those attributes .To capture this distinction in BNF format in the grammatic specification 90 would require separate definitions for each type of attribute , and separate sets of attributes for each type of object .","label":"Background","metadata":{},"score":"85.171036"}{"text":"The task manager 36 controls script execution through the script engine 38 .The task manager 36 provides the capability to proceed with multiple execution requests simultaneously , to queue up additional script commands for busy applications 26 , and to track the progress of the execution , informing the clients when execution of a script is in progress or has completed .","label":"Background","metadata":{},"score":"85.241394"}{"text":"The first system I designed had four stroke elements : a line stroke , a circle stroke , an open circle stroke , and an s. One or a number of these strokes were placed within a grid space to form every letter of the alphabet .","label":"Background","metadata":{},"score":"85.37854"}{"text":"Each glyph - the visual form of an alphabetic letter - is comprised of one or more font primitives called strokes .These strokes are placed within a grid space using two of four possible basic constraints : independence or dependence , and simultaneity or consecutiveness .","label":"Background","metadata":{},"score":"85.38241"}{"text":"1989 : Review of M. Guthrie and J. Carrington , Lingala : Grammar and Dictionary , Bulletin of the School of Oriental and African Studies .Natural Language and Linguistic Theory 5 , 485 - 518 .1985 : The long and the short of it : a metrical theory of English vowel quantity .","label":"Background","metadata":{},"score":"85.42775"}{"text":"To calculate Amplitude and Duration for the Rising portion of the Accent : .To calculate Amplitude and Duration for the Falling portion of the Accent : .To calculate a specific F0 point in time using either Rise or Fall Amplitude and Duration : .","label":"Background","metadata":{},"score":"85.699295"}{"text":"1a .OM allows rapid and flexible integration of software agents in a prototyping development environment .Because these components can be coded in different languages , and run on different platforms , the OAA framework is an ideal environment for rapid software prototyping and facilitates ease in adding or removing software components .","label":"Background","metadata":{},"score":"85.88922"}{"text":"In the preferred embodiment , the script engine 38 is a LotusScript engine from IBM , and so long as an application 26 provides an OLE automation or DLL interface , it will be controllable by the speech center 20 .In other embodiments , the script engine 38 is a Visual Basic , Javascript , or any other suitable scripting engine .","label":"Background","metadata":{},"score":"85.89255"}{"text":"Next to the phonemes are the English words that , in spoken form , use the phoneme .In reduced form , a citation form phoneme effectively becomes another phoneme .After Moriarty 's Table of Vowel Sounds ( 1975 ) .","label":"Background","metadata":{},"score":"86.11407"}{"text":",1984 referenced above ) .[ 0066 ] .The CART decision tree algorithm 260 extends the decision tree method to handle numerical values and is particularly less susceptible to noisy or missing data .CART ( Classification and Regression Tree ) introduced by Breiman , Freidman , Olshen , Stone referenced above is a widely used decision tree - based procedure for data mining .","label":"Background","metadata":{},"score":"86.12777"}{"text":"3 are straightforward translations of the Japanese keywords .Consequently , for the continuous input speech of \" Three hamburgers , coffees , and potatoes , please \" uttered in English , the keyword lattice expressed in English will take the appearance substantially different from that shown in FIG .","label":"Background","metadata":{},"score":"86.26578"}{"text":"3 are straightforward translations of the Japanese keywords .Consequently , for the continuous input speech of \" Three hamburgers , coffees , and potatoes , please \" uttered in English , the keyword lattice expressed in English will take the appearance substantially different from that shown in FIG .","label":"Background","metadata":{},"score":"86.26578"}{"text":"3 are straightforward translations of the Japanese keywords .Consequently , for the continuous input speech of \" Three hamburgers , coffees , and potatoes , please \" uttered in English , the keyword lattice expressed in English will take the appearance substantially different from that shown in FIG .","label":"Background","metadata":{},"score":"86.26578"}{"text":"3 are straightforward translations of the Japanese keywords .Consequently , for the continuous input speech of \" Three hamburgers , coffees , and potatoes , please \" uttered in English , the keyword lattice expressed in English will take the appearance substantially different from that shown in FIG .","label":"Background","metadata":{},"score":"86.26578"}{"text":"The pattern of the section from the beginning of the vowel of the first syllable to the pattern peak is made upwardly projecting .( f )The pattern of the section from the beginning of the vowel of the first syllable to the pattern peak is made downwardly projecting .","label":"Background","metadata":{},"score":"86.278366"}{"text":"[ 0028 ] .The script engine 38 enables the speech center 20 to control applications 26 by executing scripts against them .The script engine 38 provides the following capabilities : The script engine 38 supports cross - application scripting via OLE ( Object Linking and Embedding ) automation or through imported DLL 's ( Dynamic Link Libraries ) .","label":"Background","metadata":{},"score":"86.37053"}{"text":"Speech Recognizer ( SR)-receives the acoustic signal from the user and generates a text string or other representation containing the utterances most likely to have been pronounced .Natural Language Understanding - generates a particular natural language representation of the syntax and semantics of the text received from the speech recognizer .","label":"Background","metadata":{},"score":"86.60078"}{"text":"A presentation at the International Conference on Advances in Infrastructure for 3-busines , e - Education , e - Science , and e - Medicine on the Internet , SSGRR 2002W .Mazur , E. ( 1993 ) .Peer Instruction : A User 's Manual , Cambridge , Mass. : Harvard University Press .","label":"Background","metadata":{},"score":"86.631424"}{"text":"The Robber chose instead to interpret the accent on \" banks \" as an emphatic rather than broad accent , which instead means something like \" why banks and not clothing stores ?\" There is little evidence as of yet that the differences in these accents are evident physically , or whether they are a product of some shared discourse plan .","label":"Background","metadata":{},"score":"86.6747"}{"text":"Stanford University Press , Stanford .Bringhurst , R. ( 1992 ) .The Elements of Typographic Style .Second Edition ( 1996 ) .Point Roberts , WA : Hartley & Marks , Publishers .Brown , G. ( 1983 ) .","label":"Background","metadata":{},"score":"86.71295"}{"text":"wav files and analysis performed using a speech tool such as the Sony Sound Forge and open source speech tools such as PRAAT [ 11 ] speech analyzer and the Edinburgh Speech Tools [ 12].Other similar tools for achieving a similar result are clearly useable within the present invention .","label":"Background","metadata":{},"score":"86.7485"}{"text":"In a character conversion part 26 the character conversion information is used to convert each character of the Japanese text , and the thus converted Japanese text is displayed on a display 27 .The rules for converting the MSCL control commands to character information referred to above can be changed or modified by a user .","label":"Background","metadata":{},"score":"86.85166"}{"text":"[0079 ] .AssociateValue(\"destination \" ) .[ 0080 ] .AssociateParameter(\"green \" ) .[0081 ] .End(\"action \" ) .[ 0082 ] .End(\"command \" ) .[ 0083 ] .After the frame representation of the sentence is constructed , it is converted into a series of propositions , which are primarily attribute - object - value triples .","label":"Background","metadata":{},"score":"86.96269"}{"text":"Differences in voice quality can greatly affect the success of F0 tracking .The glottal phoneme found in English speech - the difference between \" she eats \" as opposed to \" sheets \" - can occur as a vocal characteristic .","label":"Background","metadata":{},"score":"86.96291"}{"text":"Stress is a sub - category of prominence , and is the rhythmic counterpart to intonational prominence , the pitch accent .Stress is created through effects of duration , loudness ( the perception of the physical property of amplitude ) , and the full or reduced perception of vowel quality .","label":"Background","metadata":{},"score":"87.076675"}{"text":"Horizontal proportions have not really developed , except as proportions related to the distance between the X height and Base Line of a glyph , usually 5:4 , height to width .Changing any one of the grid proportions changes the way a font looks drastically .","label":"Background","metadata":{},"score":"87.08562"}{"text":"[ 0064 ] .template statement(object ) .[0065 ] .[ 0066 ] .[0067 ] .This template tells the syntax manager 62 how to take this more general syntax specification and turn it into BNF based on the ontological description or information ( i.e. , ontology 64 ) in the domain model 70 .","label":"Background","metadata":{},"score":"87.21444"}{"text":"Computers allow the exploration of forms and mediums that have heretofore not existed .I consider prosodic font work to contribute to this exploratory design .I ask , \" How can the letters of the English alphabet be represented , differentiated and animated ?","label":"Background","metadata":{},"score":"87.21542"}{"text":"The letterforms were often rendered in a two - dimensions with a single flat hue .Figure 20 : The Futura typeface was designed by Paul Renner in 1924 - 26 and issued by the Bauer foundry in 1927 , Frankfurt .","label":"Background","metadata":{},"score":"87.33495"}{"text":"51 - 74 ) .Cambridge : MIT Press .Jeninek , F. , et al , Continuous Speech Recognition : Statistical methods in Handbook of Statistics , II , P. R. Kristnaiad , Ed .Amsterdam , The Netherlands , North - Holland , 1982 .","label":"Background","metadata":{},"score":"87.40016"}{"text":"Free format text : CORRECTIVE ASSIGNMENT TO CORRECT THE ASSIGNEE NAME PREVIOUSLY RECORDED ON REEL 015005FRAME 0383;ASSIGNORS : AZARA , MISTY;POLANYI , LIVIA;THIONE , GIOVANNI L.;AND OTHERS;REEL / FRAME:022229/0834;SIGNING DATES FROM 20040210 TO 20040211","label":"Background","metadata":{},"score":"87.501434"}{"text":"This did not allow enough detail to create the mixed characters such as t , f , g , nor the unfilled dot in i or j. Each stroke also requires additional specification unique to itself .For example , the open circle stroke , in order to form either a u or a c , needs to specify the degrees to be left open .","label":"Background","metadata":{},"score":"87.5242"}{"text":"On a computer , shapely lines such as pen would produce require far more parameters than the geometric simplicity of the sans serif moderns .Furthermore , the fine portions of the strokes often do not show to best advantage on the rough resolution of a computer monitor .","label":"Background","metadata":{},"score":"87.56065"}{"text":"Plosive phonemes are created by stopping the emission of air completely with the tongue or lips and then releasing it explosively .Plosive phonemes such as /p/ and /t/ often cause a high - pitched , scattering effect on the fundamental frequency .","label":"Background","metadata":{},"score":"87.845566"}{"text":"Measures of vocal quality need to be compiled and normalized for real - time look - up purposes .I envision vocal quality measures to map well to font rasterization techniques and texture mapping , as well as color .For example , a breathy voice would blur the edges of the prosodic font to a greater or lessor degree , whereas a creaky voice would be illustrated through striations through the font texture .","label":"Background","metadata":{},"score":"88.26895"}{"text":"Are your orders two hamburgers and two coffees ?Please answer yes or no . \" as shown in FIG .38 .The use of such a response sentence may also be controlled according to the information such as a number of questions or corrections made during the same dialogue .","label":"Background","metadata":{},"score":"88.30438"}{"text":"Are your orders two hamburgers and two coffees ?Please answer yes or no . \" as shown in FIG .38 .The use of such a response sentence may also be controlled according to the information such as a number of questions or corrections made during the same dialogue .","label":"Background","metadata":{},"score":"88.30438"}{"text":"Are your orders two hamburgers and two coffees ?Please answer yes or no . \" as shown in FIG .38 .The use of such a response sentence may also be controlled according to the information such as a number of questions or corrections made during the same dialogue .","label":"Background","metadata":{},"score":"88.30438"}{"text":"Are your orders two hamburgers and two coffees ?Please answer yes or no . \" as shown in FIG .38 .The use of such a response sentence may also be controlled according to the information such as a number of questions or corrections made during the same dialogue .","label":"Background","metadata":{},"score":"88.30438"}{"text":"For example , one can not change the vertical stem of a glyph ( such as in the glyph t ) independently of its cross bar , because the two are dependent upon a single weight value .Nor can one continuously change the curvature of line in non - circular shape elements , such as the glyph l or i. .","label":"Background","metadata":{},"score":"88.31102"}{"text":"Cho 's innovative and lovely typographic work has been an inspiration to my own Object - Oriented font design .I would hope that artists such as Cho would be intrigued to create fonts for a prosodic font system .For the San Francisco Exploratorium museum , artist Paul Demarinus created an exhibit that demonstrated how communicative the paralinguistic expression of prosody alone can be .","label":"Background","metadata":{},"score":"88.332565"}{"text":"The high speed processor unit 297 further comprises : a high speed processor 2971 and the high speed processor interface 2972 connected to the high speed processor 2971 .This high speed processor 2971 is used in executing a large scale processing required in the speech understanding operation and the response generation operation .","label":"Background","metadata":{},"score":"88.592545"}{"text":"The high speed processor unit 297 further comprises : a high speed processor 2971 and the high speed processor interface 2972 connected to the high speed processor 2971 .This high speed processor 2971 is used in executing a large scale processing required in the speech understanding operation and the response generation operation .","label":"Background","metadata":{},"score":"88.592545"}{"text":"The high speed processor unit 297 further comprises : a high speed processor 2971 and the high speed processor interface 2972 connected to the high speed processor 2971 .This high speed processor 2971 is used in executing a large scale processing required in the speech understanding operation and the response generation operation .","label":"Background","metadata":{},"score":"88.592545"}{"text":"For example , happiness is a very positive , whereas despair is very negative .Psychologists [ see references 1 , 2 , 3 , 4 , 5 above ] have long used this two dimensional circle to represent emotion states .","label":"Background","metadata":{},"score":"88.61998"}{"text":"Then , at a timing t0 , the text data is changed to a new text data of \" You want to add two hamburgers and two coffees , right ? \" for making the confirmation for the additional order .Also , at the same timing t0 , the content visualizing image is changed to a new content visualizing image showing three hamburgers , two coffees , and one cola by combining the additional order with the previous order .","label":"Background","metadata":{},"score":"88.654175"}{"text":"Then , at a timing t0 , the text data is changed to a new text data of \" You want to add two hamburgers and two coffees , right ? \" for making the confirmation for the additional order .Also , at the same timing t0 , the content visualizing image is changed to a new content visualizing image showing three hamburgers , two coffees , and one cola by combining the additional order with the previous order .","label":"Background","metadata":{},"score":"88.654175"}{"text":"Then , at a timing t0 , the text data is changed to a new text data of \" You want to add two hamburgers and two coffees , right ? \" for making the confirmation for the additional order .Also , at the same timing t0 , the content visualizing image is changed to a new content visualizing image showing three hamburgers , two coffees , and one cola by combining the additional order with the previous order .","label":"Background","metadata":{},"score":"88.654175"}{"text":"Then , at a timing t0 , the text data is changed to a new text data of \" You want to add two hamburgers and two coffees , right ? \" for making the confirmation for the additional order .Also , at the same timing t0 , the content visualizing image is changed to a new content visualizing image showing three hamburgers , two coffees , and one cola by combining the additional order with the previous order .","label":"Background","metadata":{},"score":"88.654175"}{"text":"_ _ _ _ .Intonational Phonology .Cambridge Studies in Linguistics 79 .Cambridge : Cambridge University Press .Lehrer , W. ( 1995 ) .Brother Blue - The Portrait Series .Seattle , Washington : Bay Press .Lerdahl , F. & Jackendoff , R. ( 1983 ) .","label":"Background","metadata":{},"score":"88.67038"}{"text":"In 1978 , Professor Don Knuth began work on the METAFONT in conjunction with typographers Charles Bigelow and Kris Holmes .Matthew Carter , Zapf and Richard Southall also contributed .METAFONT is a program to render any font style , shape , and proportion by specifying brush shape , proportion and angle parameters ( Knuth , 1986 ) .","label":"Background","metadata":{},"score":"88.7683"}{"text":"I also had difficulty transforming the rotation of the strokes and keeping them within the grid space .Note that I wrote Prosodic Font in a beta version of Java 1.2 to benefit from the vastly improved drawing model - an improvement upon PostScript - created through a partnership with Adobe ( Sun , 1998 ) .","label":"Background","metadata":{},"score":"88.78969"}{"text":"The attention to detail possible in these parameterized fonts is brilliant .Yet , neither METAFONT nor Multiple Master fonts have taken the design world by storm .Why ?No one yet knows how to use the immense design freedom implicit in these fonts .","label":"Background","metadata":{},"score":"88.908356"}{"text":"[0127 ] .The AutoTutor ( domain : computer literacy ) , CIRCSIM ( domain : Newtonian mechanics ) and the ATLAS - ANDES ( domain : circulatory system ) are representative examples of ITS that have been implemented .Each of these systems utilize DM models that implement a combination of different strategies : for example , AutoTutor 's DM is an adaptation of the form - filling approach to tutorial dialogue .","label":"Background","metadata":{},"score":"89.200386"}{"text":"Apparatus and method for converting an audio signal into a parameterized representation using band pass filters , apparatus and method for modifying a parameterized representation using band pass filter , apparatus and method for synthesizing a parameterized of an audio signal using band pass filters .","label":"Background","metadata":{},"score":"89.308426"}{"text":"Things A basic category that includes all others .[ 0040 ] .Agents Animate objects , people , organizations , computer programs .[ 0041 ] .Objects Inanimate objects , including documents and their sub - objects .[ 0042 ] .","label":"Background","metadata":{},"score":"89.567215"}{"text":"Primary Examiner : .Macdonald , Allen R. .Assistant Examiner : .Chowdhury , Indranil .Attorney , Agent or Firm : .Parent Case Data : .This is a continuation of application Ser .No .07/978,521 , filed on Nov. 18 , 1992 , U.S. Pat .","label":"Background","metadata":{},"score":"89.63986"}{"text":"[ 0026 ] .The speech engine interface module 30 encapsulates the details of communicating with the speech engine 22 , isolating the speech center 20 from the speech engine 22 specifics .In a preferred embodiment , the speech engine 22 is ViaVoice  from IBM  .","label":"Background","metadata":{},"score":"89.80511"}{"text":"RELATED APPLICATIONS .[ 0001 ] .The present application claims priority to provisional application Ser .No .60/633,239 filed Dec. 3 , 2004 which is hereby incorporated by reference herein .FIELD OF THE INVENTION .[0002 ] .","label":"Background","metadata":{},"score":"89.86429"}{"text":"In the decision tree , entropy can be measured by looking at the purity of the resulting subsets of a split .For example , if a subset contains only one class it is purest ; conversely , the largest impurity is defined as when all classes are equally mixed in the subset .","label":"Background","metadata":{},"score":"89.879684"}{"text":"This method of demonstrating citation form stress patterns shows the difference between one of the very few rhythmically differentiated word pairs in English .Linguist Mary Beckman specifies three forms of lexical stress patterns in English : primary accent ( full stress ) , secondary accent ( an ' unstressed ' full vowel ) , and tertiary accent ( a reduced vowel ) ( 1986 ) .","label":"Background","metadata":{},"score":"89.90121"}{"text":"The HIGH pitch level [ i.e. H tone ] can be specified as F0-level 2 , 3 , or 4 , depending on the context .This means the F0-level 2 can represent both a HIGH and a LOW pitch level , which may seem paradoxical .","label":"Background","metadata":{},"score":"89.91176"}{"text":"Scott P Myers .Contact .Interests .Biography .Scott Myers received a PhD in Linguistics in 1987 from the University of Massachusetts at Amherst .He taught at Temple University and the School of Oriental and African Studies before coming to the University of Texas in 1990 .","label":"Background","metadata":{},"score":"90.01846"}{"text":"Classes may be defined as being subclasses of existing classes , for example .Attributes can be defined for particular classes , which associate entities that are members of these classes with other entities in other classes .For example , a person class might support a height attribute whose value is a member of the number class .","label":"Background","metadata":{},"score":"90.24165"}{"text":"Linguistics 344 is an introduction to the sound structure of language .We will explore how the sounds differ across various dialects of English and across the world 's languages .We will learn how children acquire the sounds system of their language and how language experience shapes that acquisition .","label":"Background","metadata":{},"score":"90.79294"}{"text":"Figure 35 : The first two lines are ligatures for an italic font cut by Christoffel van Dijck , 1650s .The second two lines are ligatures from Adobe Caslon roman and italic by Carol Twomby , after William Caslon , 1750s .","label":"Background","metadata":{},"score":"91.150764"}{"text":"Mistakes and misrepresentations are , of course , my own responsibility .Certain colleagues at the Media Lab were collaborators and innovators in the course of my study .Thanks to Bill Keyes , Fernanda Viegas , and Tim McNerney , for the camaraderie during our short - lived internship in IG .","label":"Background","metadata":{},"score":"91.34773"}{"text":"For example , one downward stroke and one rounded stroke form the letter ' b ' .4.1 FOUR STROKE SYSTEM .The letters in the Roman alphabet fall clearly within visual similarity groups .There are also those letters which represent combinations of these two systems .","label":"Background","metadata":{},"score":"91.37439"}{"text":"claim 1 , in which the predictive models are determined based on at least one of : machine learning , rules .The method of .claim 3 , in which the machine learning based predictive models are determined based on at least one of : statistics , decision trees , Nave Bayes .","label":"Background","metadata":{},"score":"91.758255"}{"text":"Suguru Ishizaki 's own design work and feedback at nascent points in Prosodic Font work focused and motivated me .Glorianna Davenport and Justine Cassell welcomed me into their respective research groups at various points and gave me the benefits of their creative and scientific perspectives .","label":"Background","metadata":{},"score":"92.052055"}{"text":"[ 0063 ] .This would allow the user to create sentences like \" The color of A1 is red \" or \" The age of Tom is 35 \" .The sample conventional BNF does not quite capture the desired meaning , however , because it does n't relate the set of legal attributes to specific type of the object , and it does n't relate the set of legal values to the particular attribute in question .","label":"Background","metadata":{},"score":"92.12116"}{"text":"The class of phonetic sounds marked include : glottals , lengthened phones , flaps , rigorous unvoiced and voiced plosives .Although these phonetic marks are discrete rather than continuous variables , they should include a notion of forcefulness .This would allow any and every letter to experience an amount of phonetic influence .","label":"Background","metadata":{},"score":"92.29875"}{"text":"The offset between the vowel and target pitch may be reversed ( not shown ) , when the vowel onset occurs well after the pitch target is achieved .Furthermore , the offset between vowel onset and pitch accent is still interesting when the pitch accent is low ( not shown ) as opposed to the high accent shown .","label":"Background","metadata":{},"score":"92.49022"}{"text":"This high speed processor 2971 are operated under the control from the processor unit 291 with the input transferred from the memory unit 292 and the output transmitted through the high speed processor interface 2972 to the memory unit 292 .The display unit 299 further comprises : a display 2993 for displaying the visual response ; a display controller 2992 connected to the display 2993 ; and a display controller interface 2991 connected to the display controller 2992 .","label":"Background","metadata":{},"score":"92.80078"}{"text":"Secondary and tertiary stressed forms are differentiated only on the basis of vowel quality , full or reduced .Full vowel form is based upon the phonetic understanding of the citation form of the word .Reduced vowel form is a result of the vowel in citation form changing toward a more central , neutral vowel .","label":"Background","metadata":{},"score":"92.98781"}{"text":"12B in response to the input speech from the user .In this case , the multimodal response output is generated such that the speech response for the confirmation message of \" Your orders are one hamburger , two coffees , and four large colas , right ? \"","label":"Background","metadata":{},"score":"93.0896"}{"text":"12B in response to the input speech from the user .In this case , the multimodal response output is generated such that the speech response for the confirmation message of \" Your orders are one hamburger , two coffees , and four large colas , right ? \"","label":"Background","metadata":{},"score":"93.0896"}{"text":"12B in response to the input speech from the user .In this case , the multimodal response output is generated such that the speech response for the confirmation message of \" Your orders are one hamburger , two coffees , and four large colas , right ? \"","label":"Background","metadata":{},"score":"93.0896"}{"text":"12B in response to the input speech from the user .In this case , the multimodal response output is generated such that the speech response for the confirmation message of \" Your orders are one hamburger , two coffees , and four large colas , right ? \"","label":"Background","metadata":{},"score":"93.0896"}{"text":"Intonation is the psychological perception of the change in pitch during a spoken utterance .It can also be called the tune of an utterance .Intonation is the perception of the physical signal , fundamental frequency ( F0 ) .F0 is a measurable signal produced of voiced speech , a glottal vibration such as evident in the phone /v/ as opposed to the unvoiced phone /f/. The excitation for voiced speech sounds is produced through periodic vibration at the glottis , which in turn produces a pulse train spaced at regular intervals .","label":"Background","metadata":{},"score":"93.11069"}{"text":"For example , the sound - unit /dog/ means the word - unit dog , and the sound - unit /bog/ means the word - unit bog , but there is no semantic meaning halfway between the phonetic sound - units /dog/ and /bog .","label":"Background","metadata":{},"score":"93.242035"}{"text":"This work was performed at the MIT Media Laboratory .Support for this work was provided by the National Endowment for the Arts , the Digital Life and News in the Future corporate sponsor consortiums .The views expressed herein do not necessarily reflect the views of the supporting sponsors .","label":"Background","metadata":{},"score":"93.34949"}{"text":"Pitch Accent .During the course of any utterance , a speaker speaks certain syllables with greater prominence than others .There are two kinds of prominence within English , lexical prominence and prosodic prominence .Lexical prominence is the preferred placement of accentuation within any given word item , as in the citation form of /LEX - i - cal/. Lexical prominence is often called syllabic stress , or just stress .","label":"Background","metadata":{},"score":"93.36197"}{"text":"Simplifying for analytic purposes , pitch in English can be defined at four levels - low , mid , high or extra high ; and having three terminal contours - fading , rising , or sustained .Fundamental frequency measurements will be used to characterize syllable or sub - syllable level pitch contours with this vocabulary .","label":"Background","metadata":{},"score":"93.46845"}{"text":"The external application interface 34 enables communications from external applications 26 to the speech center 20 .For the most part , the speech center 20 can operate without any modifications to the applications 26 it controls , but in some circumstances , it may be desirable to allow the applications 26 to communicate information directly back to the speech center 20 .","label":"Background","metadata":{},"score":"93.51358"}{"text":"Intonation is only present during voiced events .Voiced phonemes are created by vibrating the glottal folds while air is moving out through them .Unvoiced phonemes are created without glottal vibration .The difference between a voiced and an unvoiced phoneme , respectively , is the one of the differences evident between the minimal pair , /f/ and /v/. Unvoiced consonants and whispers have no tune and no intonational contour .","label":"Background","metadata":{},"score":"93.52418"}{"text":"The last letterform , an example of sans serif Helvetica , has little evidence of pen production .It reflects the evenness and potential perfection of machine production standards in its geometric simplicity .so so so .Figure 21 : The typefaces used above , Palatino , Garamond and Helvetica can represent the three broadest movements in typeface design .","label":"Background","metadata":{},"score":"93.73064"}{"text":"Mach .Intell . , PAMI- 5 : 179 - 190 , 1983 .Baker , Collin F. , Fillmore , Charles J. , and Lowe , John B. ( 1998 ) : The Berkeley FrameNet project .In Proceedings of the COLING - ACL , Montreal , Canada .","label":"Background","metadata":{},"score":"93.93956"}{"text":"More recently , he has focused on experimental approaches to linguistic issues , in phonetics and phonology .Courses .Linguistics 344 is an introduction to the sound structure of language .We will explore how the sounds differ across various dialects of English and across the world 's languages .","label":"Background","metadata":{},"score":"94.00257"}{"text":"RELATED APPLICATION(S ) .[ 0001 ] .This application claims the benefit of U.S. Provisional Application No .60/261,372 , filed on Jan. 12 , 2001 .The entire teachings of the above application are incorporated herein by reference .BACKGROUND OF THE INVENTION .","label":"Background","metadata":{},"score":"94.06064"}{"text":"Bauhaus designers valued communication of the message by using the simplest of elements .Programmers and mathematicians today call the method of achieving this kind of goal \" elegant .\" Bauhaus designers simplified typographic design from the previous decorative letterforms of the Victorian era and the complex organic movement of Art Nouveau design .","label":"Background","metadata":{},"score":"94.59973"}{"text":"My love and appreciation to Mom and Dad , for continuously putting my life into perspective during the most difficult and busiest of times .Your gifts to me are more than I can ever realize .And to Samarjit , who transformed my thesis experience and my life , my love .","label":"Background","metadata":{},"score":"94.92961"}{"text":"Commercially available speech recognition packages do not even consider that third party developers might be interested in something aside from semantic content .IBM 's Via Voice and DragonSpeak 's Naturally Speaking do not include external code libraries to permit third party developers to further process the raw speech signals .","label":"Background","metadata":{},"score":"95.15278"}{"text":"Older speakers have a different pronunciation than younger speakers .Different social and ethnic groups have their own ways of saying things , as do people in different regions .In this class , students will learn about different accents in English : British vs. American , Southern , North - Eastern , Afriican American .","label":"Background","metadata":{},"score":"95.23164"}{"text":"11294918 , 294918 , US 2006/0122834 A1 , US 2006/122834 A1 , US 20060122834 A1 , US 20060122834A1 , US 2006122834 A1 , US 2006122834A1 , US - A1 - 20060122834 , US - A1 - 2006122834 , US2006/0122834A1 , US2006/122834A1 , US20060122834 A1 , US20060122834A1 , US2006122834 A1 , US2006122834A1 .","label":"Background","metadata":{},"score":"95.67359"}{"text":"Here , FIGS .27A-27C and FIGS .27D-27F show the exemplary fundamental frequency patterns for a Japanese sentence of \" Gochumonwa hanbagawo hitotsudesune \" meaning \" Your order is one hamburger , right ? \" for the normal case and a case with the joyful emotional expression .","label":"Background","metadata":{},"score":"95.89966"}{"text":"Here , FIGS .27A-27C and FIGS .27D-27F show the exemplary fundamental frequency patterns for a Japanese sentence of \" Gochumonwa hanbagawo hitotsudesune \" meaning \" Your order is one hamburger , right ? \" for the normal case and a case with the joyful emotional expression .","label":"Background","metadata":{},"score":"95.89966"}{"text":"Here , FIGS .27A-27C and FIGS .27D-27F show the exemplary fundamental frequency patterns for a Japanese sentence of \" Gochumonwa hanbagawo hitotsudesune \" meaning \" Your order is one hamburger , right ? \" for the normal case and a case with the joyful emotional expression .","label":"Background","metadata":{},"score":"95.89966"}{"text":"Here , FIGS .27A-27C and FIGS .27D-27F show the exemplary fundamental frequency patterns for a Japanese sentence of \" Gochumonwa hanbagawo hitotsudesune \" meaning \" Your order is one hamburger , right ? \" for the normal case and a case with the joyful emotional expression .","label":"Background","metadata":{},"score":"95.89966"}{"text":"Thesis Advisor Ronald L. MacNeil Principal Research Associate MIT Media Laboratory .Thesis Reader Stephanie Seneff Principal Research Scientist Laboratory for Computer Science , MIT .Thesis Reader Maribeth Back Creative Documents Initiative Sound Designer Xerox Corporation @ PARC .ACKNOWLEDGEMENTS .","label":"Background","metadata":{},"score":"95.91"}{"text":"Here , the system completely failed to understand the input speech so that the order table remains empty and consequently there is no content visualizing image involved in the visual response .Next , consider a case in which the user uttered the input speech of \" Two hamburgers and two coffees , please .","label":"Background","metadata":{},"score":"96.310684"}{"text":"Here , the system completely failed to understand the input speech so that the order table remains empty and consequently there is no content visualizing image involved in the visual response .Next , consider a case in which the user uttered the input speech of \" Two hamburgers and two coffees , please .","label":"Background","metadata":{},"score":"96.310684"}{"text":"Here , the system completely failed to understand the input speech so that the order table remains empty and consequently there is no content visualizing image involved in the visual response .Next , consider a case in which the user uttered the input speech of \" Two hamburgers and two coffees , please .","label":"Background","metadata":{},"score":"96.310684"}{"text":"Here , the system completely failed to understand the input speech so that the order table remains empty and consequently there is no content visualizing image involved in the visual response .Next , consider a case in which the user uttered the input speech of \" Two hamburgers and two coffees , please .","label":"Background","metadata":{},"score":"96.310684"}{"text":"Vertical dimensions are highly specified through a number of common specifications .X height , ascender and descender heights , added or subtracted from the base line , are the most frequently used proportions used in letterform design .There are no common specifications for horizontal proportions in letterforms .","label":"Background","metadata":{},"score":"96.41592"}{"text":"This work builds upon work completed in the Visual Language Workshop ( VLW ) .Researchers and students designed computer interfaces to textual information that involve many notions of time .It is VLW students , particularly Yin Yin Wong , who transferred the idea of Rapid Serial Visual Presentation ( RSVP ) to message design .","label":"Background","metadata":{},"score":"96.58841"}{"text":"Janet Cahn 's work in emotive , intonational speech generation - and Janet Cahn herself - have provided me with direction into an amorphous and distributed body of prosody and emotion literature .And , lastly , the spirit of curiosity and art that envelopes even the most scientific of inquiries here has allowed me to learn the technical skills I needed to accomplish this work .","label":"Background","metadata":{},"score":"98.18236"}{"text":"Rises and falls could be understood as smooth transitions from one \" highly specified \" peak accent to another .Ladd writes that for the same utterance , speakers control pitch accent targets with low standard deviation .Therefore , exact pitch levels achieved may be perceptually meaningful to hearers ( Ladd , 1996 ) .","label":"Background","metadata":{},"score":"98.51289"}{"text":"Imagine that a good friend is telling you a story she is very excited about .She gets to the part when she imitates a large explosion , \" BOOM ! \"she says with a wild wave of her hand .","label":"Background","metadata":{},"score":"98.56537"}{"text":"Here , these operations are need to be executed in parallel , so that the high speed processor 2971 contains a plurality of parallel processing elements .This high speed processor 2971 are operated under the control from the processor unit 291 with the input transferred from the memory unit 292 and the output transmitted through the high speed processor interface 2972 to the memory unit 292 .","label":"Background","metadata":{},"score":"98.99448"}{"text":"Here , these operations are need to be executed in parallel , so that the high speed processor 2971 contains a plurality of parallel processing elements .This high speed processor 2971 are operated under the control from the processor unit 291 with the input transferred from the memory unit 292 and the output transmitted through the high speed processor interface 2972 to the memory unit 292 .","label":"Background","metadata":{},"score":"98.99448"}{"text":"Here , these operations are need to be executed in parallel , so that the high speed processor 2971 contains a plurality of parallel processing elements .This high speed processor 2971 are operated under the control from the processor unit 291 with the input transferred from the memory unit 292 and the output transmitted through the high speed processor interface 2972 to the memory unit 292 .","label":"Background","metadata":{},"score":"98.99448"}{"text":"Taipei , Taiwan .[ 0154 ] .The research methodology and representative sub - tasks required to build and test the speech recognition interface and associated grammar development for the ITS are to : .Acquire speech recognition engine license from SRI .","label":"Background","metadata":{},"score":"99.3772"}{"text":"The data transmission unit 294 makes a data transmission with respect to the system to the external devices such as computers , data processors , etc . , through the data transmission unit interface 2941 under the control of the processor unit 291 .","label":"Background","metadata":{},"score":"99.827194"}{"text":"If a speaker uses creaky voice over an extended part of an utterance , a.k.a .Dorothy Parker voice , automatic tracing of intonational tune breaks down , as seen in figure 15 below ( Beckman and Ayers , 1994 ) .","label":"Background","metadata":{},"score":"100.09983"}{"text":"Duration and related correlates : duration ( DUR ) , maximum duration ( DUR_MAX ) , minimum duration ( DUR_MIN ) , mean duration ( DUR_MEAN ) , standard deviation from duration mean ( DUR_STDV ) .Amplitude and related correlates : Amplitude ( RMS ) , Minimum amplitude ( RMS_MIN ) , Maximum amplitude ( RMS_MAX ) , mean amplitude ( RMS_MEAN ) , difference between the highest and lowest amplitudes ( RMS_RANGE ) , standard deviation from amplitude mean ( RMS_STDV ) .","label":"Background","metadata":{},"score":"103.22974"}{"text":"The communication links 99 shown in .In general , the communication links 99 can be any known or later developed connection system or structure usable to connect devices and facilitate communication .Further , it should be appreciated that the communication links 99 can be wired or wireless links to a network .","label":"Background","metadata":{},"score":"109.70238"}