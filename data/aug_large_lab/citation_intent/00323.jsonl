{"text":"This paper explores a parsimonious approach to Data - Oriented Parsing .While allowing , in principle , all possible subtrees of trees in the treebank to be productive elements , our approach aims at finding a manageable subset of these trees that can accurately describe empirical distributions over phrase - structure trees .","label":"CompareOrContrast","metadata":{},"score":"26.866869"}
{"text":"In this paper , we propose a machine learning algorithm for shallow semantic parsing , extending the work of Gildea and Jurafsky ( 2002 ) , Surdeanu et al .( 2003 ) and others .Our algorithm is based on Support Vector Machines which we show give an improvement in performance over earlier classifiers .","label":"CompareOrContrast","metadata":{},"score":"27.221054"}
{"text":"In this paper , we propose a machine learning algorithm for shallow semantic parsing , extending the work of Gildea and Jurafsky ( 2002 ) , Surdeanu et al .( 2003 ) and others .Our algorithm is based on Support Vector Machines which we show give an improvement in performance over earlier classifiers .","label":"CompareOrContrast","metadata":{},"score":"27.221054"}
{"text":"We address the problem of training the free parameters of a statistical machine translation system .We show significant improvements over a state - of - the - art minimum error rate training baseline on a large Chinese - English translation task .","label":"CompareOrContrast","metadata":{},"score":"27.300875"}
{"text":"We describe new lookup algorithms for hierarchical phrase - based translation that reduce the empirical computation time by nearly two orders of magnitude , making on - the - fly lookup feasible for source phrases with gaps .This paper presents an empirical study on how different selections of input translation systems affect translation quality in system combination .","label":"CompareOrContrast","metadata":{},"score":"27.92878"}
{"text":"In this paper , we present a three - step multi - lingual dependency parser based on a deterministic shift - reduce parsing algorithm .Different from last year , we separate the root - parsing strategy as sequential labeling task and try to link the neighbor word dependences via a near neighbor parsing .","label":"CompareOrContrast","metadata":{},"score":"28.379694"}
{"text":"This paper presents a syntax - driven approach to question answering , specifically the answer - sentence selection problem for short - answer questions .Rather than using syntactic features to augment existing statistical classifiers ( as in previous work ) , we build on the idea that questions and their ( correct ) answers relate to each other via loose but predictable syntactic transformations .","label":"CompareOrContrast","metadata":{},"score":"28.768097"}
{"text":"In this paper we present a discourse informed model which is capable of producing document compressions that are coherent and informative .Our model is inspired by theories of local coherence and formulated within the framework of Integer Linear Programming .Experimental results show significant improvements over a state - of - the - art discourse agnostic approach .","label":"CompareOrContrast","metadata":{},"score":"29.328333"}
{"text":"We present a method for improving word alignment for statistical syntax - based machine translation that employs a syntactically informed alignment model closer to the translation model than commonly - used word alignment models .This leads to extraction of more useful linguistic patterns and improved BLEU scores on translation experiments in Chinese and Arabic .","label":"CompareOrContrast","metadata":{},"score":"29.477343"}
{"text":"In particular , this paper further introduces a variational Bayesian inference algorithm that is applicable to a wide class of tree transducers , producing state - of - the - art semantic parsing results while remaining applicable to any domain employing probabilistic tree transducers . ... pled handling of data sparsity andprior knowledge .","label":"CompareOrContrast","metadata":{},"score":"30.067646"}
{"text":"We describe an approach to improve Statistical Machine Translation ( SMT ) performance using multi - lingual , parallel , sentence - aligned corpora in several bridge languages .Our approach consists of a simple method for utilizing a bridge language to create a word alignment system and a procedure for combining word alignment systems from multiple bridge languages .","label":"CompareOrContrast","metadata":{},"score":"30.454002"}
{"text":"This paper proposes a method for learning a discriminative parser for machine translation reordering using only aligned parallel text .This is done by treating the parser 's derivation tree as a latent variable in a model that is trained to maximize reordering accuracy .","label":"CompareOrContrast","metadata":{},"score":"30.530268"}
{"text":"This paper proposes a method for learning a discriminative parser for machine translation reordering using only aligned parallel text .This is done by treating the parser 's derivation tree as a latent variable in a model that is trained to maximize reordering accuracy .","label":"CompareOrContrast","metadata":{},"score":"30.530268"}
{"text":"Our results provide the first known empirical evidence that lexical semantics are indeed useful for SMT , despite claims to the contrary .This paper presents a tree - to - tree transduction method for text rewriting .Our model is based on synchronous tree substitution grammar , a formalism that allows local distortion of the tree topology and can thus naturally capture structural mismatches .","label":"CompareOrContrast","metadata":{},"score":"30.601255"}
{"text":"( 1993 ) .In our model , arbitrary , nonindependent features may be freely incorporated , thereby overcoming the inherent limitation of generative models , which requ ... \" .We introduce a discriminatively trained , globally normalized , log - linear variant of the lexical translation models proposed by Brown et al .","label":"CompareOrContrast","metadata":{},"score":"30.613432"}
{"text":"We present the idea of estimating semantic distance in one , possibly resource - poor , language using a knowledge source in another , possibly resource - rich , language .We do so by creating cross - lingual distributional profiles of concepts , using a bilingual lexicon and a bootstrapping algorithm , but without the use of any sense - annotated data or word - aligned corpora .","label":"CompareOrContrast","metadata":{},"score":"30.663097"}
{"text":"We introduce an approximate inference method using Tree - based Reparameterization ( TRP ) to reduce computational cost .In experiments , our proposed model obtained significant improvements compare to baseline models that use Support Vector Machines .We introduce a technique for identifying the most salient participants in a discussion .","label":"CompareOrContrast","metadata":{},"score":"31.49656"}
{"text":"They demonstrated its application to a common model based on the translation of contiguous substrings , but leave some open problems .Among these is a question : can this approach match the performance of conventional methods despite unavoidable differences that it induces in the model ?","label":"CompareOrContrast","metadata":{},"score":"31.632973"}
{"text":"We describe a set of syntactic reordering rules that exploit systematic differences between Chinese and English word order .The resulting system is used as a preprocessor for both training and test sentences , transforming Chinese sentences to be much closer to English in terms of their word order .","label":"CompareOrContrast","metadata":{},"score":"31.896223"}
{"text":"In this paper we present new experiments to test this claim .We use the PARSEVAL metric , the Leaf - Ancestor metric as well as a dependency - based evaluation , and present novel approaches measuring the effect of controlled error insertion on treebank trees and parser output .","label":"CompareOrContrast","metadata":{},"score":"31.916245"}
{"text":"We present a new generative alignment model which avoids these structural limitations , and show that it is effective when trained using both unsupervised and semi - supervised training methods .Experiments show strong improvements in word alignment accuracy and usage of the generated alignments in hierarchical and phrasal SMT systems increases the BLEU score .","label":"CompareOrContrast","metadata":{},"score":"32.24029"}
{"text":"We also propose an approximate EM algorithm and a Gibbs sampling algorithm to estimate model parameters in an unsupervised manner .Experiments on large - scale Chinese - English translation tasks demonstrate that our model achieves improvements in both alignment quality and translation quality .","label":"CompareOrContrast","metadata":{},"score":"32.28489"}
{"text":"Our formulation uses a factorization analogous to the standard dynamic programs for parsing .In particular , it allows one to efficiently learn a model which discriminates among the entire space of parse trees , as opposed to reranking the top few candidates .","label":"CompareOrContrast","metadata":{},"score":"32.634018"}
{"text":"Moreover , with a small Lf - Le bilingual corpus available , our method can further improve the translation quality by using the additional Lf - Lp and Lp - Le bilingual corpora . ... n Building and Using Parallel Texts ( Martin et al . , 2005 ) .","label":"CompareOrContrast","metadata":{},"score":"32.64718"}
{"text":"We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative improvement over the baseline approach that uses a fixed context window of adjacent words .","label":"CompareOrContrast","metadata":{},"score":"32.75219"}
{"text":"We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative improvement over the baseline approach that uses a fixed context window of adjacent words .","label":"CompareOrContrast","metadata":{},"score":"32.75219"}
{"text":"Our results suggest that our bootstrapping methods have considerable potential , and could be used to semi - automate an approach based on incremental manual annotation .In this paper , we consider the computational modelling of human plausibility judgements for verb - relation - argument triples , a task equivalent to the computation of selectional preferences .","label":"CompareOrContrast","metadata":{},"score":"32.85881"}
{"text":"This paper makes the connection ... \" .Many semantic parsing models use tree transformations to map between natural language and meaning representation .However , while tree transformations are central to several state - of - the - art approaches , little use has been made of the rich literature on tree automata .","label":"CompareOrContrast","metadata":{},"score":"32.886627"}
{"text":"We describe a robust accurate domain - independent approach to statistical parsing incorporated into the new release of the ANLT toolkit , and publicly available as a research tool .The system has been used to parse many well known corpora in order to produce data for lexical acquisition efforts ; it has also been used as a component in an open - domain question answering project .","label":"CompareOrContrast","metadata":{},"score":"32.99784"}
{"text":"This paper describes a corpus - based study of plural descriptions , and proposes a psycholinguistically - motivated algorithm for plural reference generation .The descriptive strategy is based on partitioning , and incorporates corpus - derived heuristics .An exhaustive evaluation shows that the output closely matches human data .","label":"CompareOrContrast","metadata":{},"score":"33.01515"}
{"text":"We complement that method with supervised prediction of possible tags for out - of - vocabulary words and study the impact of both semi - supervision and starting dictionary size on three representative downstream tasks ( named entity tagging , semantic role labeling , ASR output postprocessing ) that use POS tags as features .","label":"CompareOrContrast","metadata":{},"score":"33.055656"}
{"text":"In this paper we address the problem of multiple citation concept alignment by combining and modifying the CRF based pairwise word alignment system of Blunsom & Cohn ( 2006 ) and a posterior decoding based multiple sequence alignment algorithm of Schwartz & Pachter ( 2007 ) .","label":"CompareOrContrast","metadata":{},"score":"33.24568"}
{"text":"Similar head - finding rules were used for Chinese experiments .The ... . \" ...We discuss the relevance of k - best parsing to recent applications in natural language processing , and develop efficient algorithms for k - best trees in the framework of hypergraph parsing .","label":"CompareOrContrast","metadata":{},"score":"33.273216"}
{"text":"This paper presents novel improvements to the induction of translation lexicons from monolingual corpora using multilingual dependency parses .We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative ... \" .","label":"CompareOrContrast","metadata":{},"score":"33.57293"}
{"text":"This paper presents novel improvements to the induction of translation lexicons from monolingual corpora using multilingual dependency parses .We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative ... \" .","label":"CompareOrContrast","metadata":{},"score":"33.57293"}
{"text":"We also compare the translation accuracy for all variations .We achieved a state of the art performance in statistical machine translation by using a large number of features with an online large - margin training algorithm .The millions of parameters were tuned only on a small development set consisting of less than 1 K sentences .","label":"CompareOrContrast","metadata":{},"score":"33.81355"}
{"text":"( 2005 ) , obtain very high accuracy on standard dependency parsing tasks and can be trained and applied without marginalization , ' ' summing trees ' ' permits some alternative techniques of interest .Using the summing algorithm , we present experimental results on four nonprojective languages , for maximum conditional likelihood estimation , minimum Bayes - risk parsing , and hidden variable training .","label":"CompareOrContrast","metadata":{},"score":"33.945595"}
{"text":"We present several improvements to unlexicalized parsing with hierarchically state - split PCFGs .First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar without a treebank .","label":"CompareOrContrast","metadata":{},"score":"33.976353"}
{"text":"Our approach combines the strengths of lexical reordering and syntactic preordering models by pe ... \" .We present a simple and novel classifier - based preordering approach .Unlike existing preordering models , we train feature - rich discriminative classifiers that directly predict the target - side word order .","label":"CompareOrContrast","metadata":{},"score":"34.0219"}
{"text":"With data size and model complexity continually increasing , a scalable solution to this problem is central to future improvement .Callison - Burch et al .( 2005 ) and Zhang and Vogel ( 2005 ) proposed a solution that we call translation by pattern matching , which we bring to fruition in this dissertation .","label":"CompareOrContrast","metadata":{},"score":"34.07541"}
{"text":"We describe an incremental parser that was trained to minimize cost over sentences rather than over individual parsing actions .This is an attempt to use the advantages of the two top - scoring systems in the CoNLL - X shared task .","label":"CompareOrContrast","metadata":{},"score":"34.18472"}
{"text":"Thus while human judgement is not straightforward and it is difficult to create a Pan - Chinese lexicon manually , it is observed that combining simple clustering methods with the appropriate data sources appears to be a promising approach toward its automatic construction .","label":"CompareOrContrast","metadata":{},"score":"34.231583"}
{"text":"The increasing use of large open - domain document sources is exacerbating the problem of ambiguity in named entities .This paper explores the use of a range of syntactic and semantic features in unsupervised clustering of documents that result from ad hoc queries containing names .","label":"CompareOrContrast","metadata":{},"score":"34.321205"}
{"text":"We present an information extraction system that decouples the tasks of finding relevant regions of text and applying extraction patterns .We create a self - trained relevant sentence classifier to identify relevant regions , and use a semantic affinity measure to automatically learn domain - relevant extraction patterns .","label":"CompareOrContrast","metadata":{},"score":"34.33425"}
{"text":"While our model was sensitive to poste - rior thresholds , it also showed a perfor - mance comparable to that of HMM align - ment models . \" ...The best systems for machine translation of natural language are based on statistical models learned from data .","label":"CompareOrContrast","metadata":{},"score":"34.524536"}
{"text":"We expect that our method could be further improved via well - tuned parameter validations for different languages .Tools . by Kuzman Ganchev , Jennifer Gillenwater , Ben Taskar - In ACL - IJCNLP , 2009 . \" ...Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .","label":"CompareOrContrast","metadata":{},"score":"34.972076"}
{"text":"Our best result , 91.44 % accuracy , reflects a 25 % reduction in error rate compared with the previous state of the art .We present a new approach to automatic summarization based on neural nets , called NetSum .We extract a set of features from each sentence that helps identify its importance in the document .","label":"CompareOrContrast","metadata":{},"score":"35.09025"}
{"text":"However , this previous work relied on translation grammars constructed using standard generative word alignment processes .7 Future Work While we have demonstrated that this ... . \" ...Syntax - based translation models should in principle be efficient with polynomially - sized search space , but in practice they are often embarassingly slow , partly due to the cost of language model integration .","label":"CompareOrContrast","metadata":{},"score":"35.181667"}
{"text":"We show how it can efficiently handle problems with ( possibly global ) structural constraints via simple sort operations .Experiments on synthetic and real - world data show that our approach compares favorably with the state - of - the - art .","label":"CompareOrContrast","metadata":{},"score":"35.26658"}
{"text":"Finally , we show a qualitative evaluation of the results of automatically adding extracted MWEs to existing linguistic resources .We argue that such a process improves qualitatively , if a more compositional approach to grammar / lexicon automated extension is adopted .","label":"CompareOrContrast","metadata":{},"score":"35.282974"}
{"text":"In addition , we present work on experiments with named entities and other multi - word units , showing a statistically significant improvement of generation accuracy .Given multiple translations of the same source sentence , how to combine them to produce a translation that is better than any single system output ?","label":"CompareOrContrast","metadata":{},"score":"35.286633"}
{"text":"However , we plan to extend the system to improve parse coverage , depth and accuracy . ... realistic texts .Evaluation of such systems has been primarily in terms of the PARSEVAL scheme tree similarity measures of ( labelled ) precision and recall and crossing bracket rate .","label":"CompareOrContrast","metadata":{},"score":"35.410862"}
{"text":"By extending a recent model , we obtain a completely corpus - driven model for this task which achieves significant correlations with human judgements .It rivals or exceeds deeper , resource - driven models while exhibiting higher coverage .Moreover , we show that our model can be combined with deeper models to obtain better predictions than from either model alone .","label":"CompareOrContrast","metadata":{},"score":"35.47357"}
{"text":"We consistently observed significant improvements on several test sets in multiple languages covering different genres .This paper proposes a method using the existing Rule - based Machine Translation ( RBMT ) system as a black box to produce synthetic bilingual corpus , which will be used as training data for the Statistical Machine Translation ( SMT ) system .","label":"CompareOrContrast","metadata":{},"score":"35.772766"}
{"text":"A key idea is to introduce non - standard CCG combinators that relax certain parts of the grammar --- for example allowing flexible word order , or insertion of lexical items --- with learned costs .We also present a new , online algorithm for inducing a weighted CCG .","label":"CompareOrContrast","metadata":{},"score":"35.847507"}
{"text":"This line of research shares the insight that HMM models can be improved by imposing well - motivated constraints on them .Toutanova et a .. \" ...We propose a novel unsupervised word alignment model based on the Hidden Markov Tree ( HMT ) model .","label":"CompareOrContrast","metadata":{},"score":"35.875698"}
{"text":"In this study , we present a system that generates lexical analogies automatically from text data .Our system discovers semantically related pairs of words by using dependency relations , and applies novel machine learning algorithms to match these word - pairs to form lexical analogies .","label":"CompareOrContrast","metadata":{},"score":"35.969994"}
{"text":"In this study we show that analogical learning offers as well an elegant and effective solution to the problem of identifying potential translations of unknown words .We present a probabilistic model of diachronic phonology in which individual word forms undergo stochastic edits along the branches of a phylogenetic tree .","label":"CompareOrContrast","metadata":{},"score":"35.989502"}
{"text":"Furthermore , the combination of parse trees can compensate for the reordering errors caused by single parse tree .Finally , experimental results show that the performance of our system is superior to that of the state - of - the - art phrase - based SMT system .","label":"CompareOrContrast","metadata":{},"score":"36.010696"}
{"text":"In this paper , we try to address this gap and explore the problem of book summarization .We introduce a new data set specifically designed for the evaluation of systems for book summarization , and describe summarization techniques that explicitly account for the length of the documents .","label":"CompareOrContrast","metadata":{},"score":"36.193428"}
{"text":"We present techniques using latent topic models to automatically predict the quality of questions based on their content .Our best system achieves a prediction accuracy of 72 % , beating out strong baselines by a significant amount .We also examine the effect of question quality on the dy - namics of user behavior and the longevity of questions . .","label":"CompareOrContrast","metadata":{},"score":"36.25943"}
{"text":"In our approach , proper nouns are expanded into new queries aimed at maximizing the probability of retrieving transliterations from existing search engines .The method involves learning the sublexical relationships between names and their transliterations .At run - time , a given name is automatically extended into queries with relevant morphemes , and transliterations in the returned search snippets are extracted and ranked .","label":"CompareOrContrast","metadata":{},"score":"36.268127"}
{"text":"We give experimental results showing significant improvements on two tasks : parsing Wall Street Journal text , and named - entity extraction from web data . \" ...We present several improvements to unlexicalized parsing with hierarchically state - split PCFGs .","label":"CompareOrContrast","metadata":{},"score":"36.27439"}
{"text":"Our model learns soft alignments as a hidden variable in discriminative training .Experimental results using the TREC dataset are shown to significantly outperform strong state - of - the - art baselines .Previous machine learning techniques for answer selection in question answering ( QA ) have required question - answer training pairs .","label":"CompareOrContrast","metadata":{},"score":"36.411343"}
{"text":"We present results that show that incorporating lexical and structural semantic information is effective for word sense disambiguation .We evaluated the method by using precise information from a large treebank and an ontology automatically created from dictionary sentences .Exploiting these information improves precision 2 - 3 % , especially 5.7 % for verb , over a model using only bag of words and n - gram features .","label":"CompareOrContrast","metadata":{},"score":"36.553032"}
{"text":"These methods are attractive for their ability to manage uncertainty about model parameters and allow one to incorporate prior knowledge during inference .Here , we propose a no ... . \" ...Many semantic parsing models use tree transformations to map between natural language and meaning representation .","label":"CompareOrContrast","metadata":{},"score":"36.609245"}
{"text":"We evaluate the proposed algorithms on the 2007 CONLL Shared Task , and report errors analysis .Experimental results show that the system score is better than the average score among the participating systems .In the paper we describe a dependency parser that uses exact search and global learning ( Crammer et al . , 2006 ) to produce labelled dependency trees .","label":"CompareOrContrast","metadata":{},"score":"36.70991"}
{"text":"Our work examines whether semantic role information is beneficial to question answering .We introduce a general framework for answer extraction which exploits semantic role annotations in the FrameNet paradigm .We view semantic role assignment as an optimization problem in a bipartite graph and answer extraction as an instance of graph matching .","label":"CompareOrContrast","metadata":{},"score":"36.73295"}
{"text":"In this paper , we define the tasks of the different tracks and describe how the data sets were created from existing treebanks for ten languages .In addition , we characterize the different approaches of the participating systems , report the test results , and provide a first analysis of these results .","label":"CompareOrContrast","metadata":{},"score":"36.82226"}
{"text":"We discuss the relevance of k - best parsing to recent applications in natural language processing , and develop efficient algorithms for k - best trees in the framework of hypergraph parsing .To demonstrate the efficiency , scalability and accuracy of these algorithms , we present experiments on Bikel 's implementation of Collins ' lexicalized PCFG model , and on Chiang 's CFG - based decoder for hierarchical phrase - based translation .","label":"CompareOrContrast","metadata":{},"score":"37.209076"}
{"text":"Experimental results are presented for composite translations computed from large numbers of different research systems as well as a set of translation systems derived from one of the best - ranked machine translation engines in the 2006 NIST machine translation evaluation .","label":"CompareOrContrast","metadata":{},"score":"37.234516"}
{"text":"We show how the algorithms can be efficiently applied to exponential sized representations of parse trees , such as the \" all subtrees \" ( DOP ) representation described by ( Bod 9 ... \" .This paper introduces new learning algorithms for natural language processing based on the perceptron algorithm .","label":"CompareOrContrast","metadata":{},"score":"37.29706"}
{"text":"We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .We apply the framework to word segmentation , joint segmentation and POStagging , dependency parsing , and phrase - structure parsing .","label":"CompareOrContrast","metadata":{},"score":"37.32144"}
{"text":"We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .We apply the framework to word segmentation , joint segmentation and POStagging , dependency parsing , and phrase - structure parsing .","label":"CompareOrContrast","metadata":{},"score":"37.32144"}
{"text":"We demonstrate significant gains using features derived from a dependency parse representation over those derived from a constituency - based tree parse .By also capturing inter - argument dependencies using a log - linear re - ranking model we achieve very promising results on this difficult task identifying both arguments correctly for over 74 % of the connectives on held - out test data using gold - standard parses .","label":"CompareOrContrast","metadata":{},"score":"37.32462"}
{"text":"Second , we compare various inference procedures for state - split PCFGs from the standpoint of risk minimization , paying particular attention to their practical tradeoffs .Finally , we present multilingual experiments which show that parsing with hierarchical state - splitting is fast and accurate in multiple languages and domains , even without any language - specific tuning . .","label":"CompareOrContrast","metadata":{},"score":"37.405434"}
{"text":"We briefly describe each model , highlighting points where they differ .We include a quantitative comparison of the phrase pairs that each model has to work with , as well as the reasons why some phrase pairs are not learned by the syntax - based model .","label":"CompareOrContrast","metadata":{},"score":"37.509567"}
{"text":"We integrate these probabilities into the framework of fully - lexicalized parsing based on large - scale case frames .This approach simultaneously addresses two tasks of coordination disambiguation : the detection of coordinate conjunctions and the scope disambiguation of coordinate structures .","label":"CompareOrContrast","metadata":{},"score":"37.521782"}
{"text":"A typical approach in graph - based dependency parsing has been to assume a factorized model , where local features are used but a global function is optimized ( McDonald et al ., 2005b ) .Recently ... \" .We explore a stacked framework for learning to predict dependency structures for natural language sentences .","label":"CompareOrContrast","metadata":{},"score":"37.660892"}
{"text":"We find that the use of a decision tree improves on the basic approach only for the deep parser - based approach .We also show that combining both the shallow and deep decision tree features is effective .Our evaluation is carried out using a large test set of grammatical and ungrammatical sentences .","label":"CompareOrContrast","metadata":{},"score":"38.051796"}
{"text":"Recent efforts have tried to overcome this issue by using statistics from speech lattices instead of only the 1-best transcripts ; however , these efforts have invariably used the classical vector space retrieval model .This paper presents a novel approach to lattice - based spoken document retrieval using statistical language models : a statistical model is estimated for each document , and probabilities derived from the document models are directly used to measure relevance .","label":"CompareOrContrast","metadata":{},"score":"38.10308"}
{"text":"Therefore , we use ancestor - descendant relation in addition to parent - child relation , so that the added redundancy helps errors be corrected .Experimental results show that the proposed method achieves higher accuracy .We propose a sequence - alignment based method for detecting and disambiguating coordinate conjunctions .","label":"CompareOrContrast","metadata":{},"score":"38.2285"}
{"text":"To resolve conflicts in shift - reduce parsing , we propose a maximum entropy model trained on the derivation graph of training data .As our approach combines the merits of phrase - based and string - todependency models , it achieves significant improvements over the two baselines on the NIST Chinese - English datasets .","label":"CompareOrContrast","metadata":{},"score":"38.533596"}
{"text":"The appropriate output transformation for a given task can be selected by applying a hill - climbing approach to held - out data .On the NP Chunking task , our hill - climbing system finds a model structure that outperforms both first - order and second - order models with the same input feature set .","label":"CompareOrContrast","metadata":{},"score":"38.596153"}
{"text":"Our error analysis for this task suggests that the primary source of error are differences in annotation guidelines among treebanks .Our suspicions are supported by the observation that no team was able to improve target domain performance substantially over a state of the art baseline .","label":"CompareOrContrast","metadata":{},"score":"38.680794"}
{"text":"We present experimental results from the CoNLL 2003 named entity recognition ( NER ) task to demonstrate the performance of the proposed algorithm .In this paper , we address a unique problem in Chinese language processing and report on our study on extending a Chinese thesaurus with region - specific words , mostly from the financial domain , from various Chinese speech communities .","label":"CompareOrContrast","metadata":{},"score":"38.70215"}
{"text":"There have been many proposed techniques to reduce the storage requirements for language models .A technique based upon pointer - free compact storage of ordinal trees shows compression competitive with the best proposed systems , while retaining the full finite state structure , and without using computationally expensive block compression schemes or lossy quantization techniques .","label":"CompareOrContrast","metadata":{},"score":"38.770653"}
{"text":"There have been many proposed techniques to reduce the storage requirements for language models .A technique based upon pointer - free compact storage of ordinal trees shows compression competitive with the best proposed systems , while retaining the full finite state structure , and without using computationally expensive block compression schemes or lossy quantization techniques .","label":"CompareOrContrast","metadata":{},"score":"38.770653"}
{"text":"However , increasing a model 's order can lead to an increase in the number of model parameters , making the model more susceptible to sparse data problems .This paper shows how the notion of output transformation can be used to explore a variety of alternative model structures .","label":"CompareOrContrast","metadata":{},"score":"39.031578"}
{"text":"It achieves our desiderata of minimal offline computation and com - pact representation , but is dependent on fast pattern matching algorithms on text .They demonstrated its application to a common model based on the translation of contiguous substrings , but leave some open problems .","label":"CompareOrContrast","metadata":{},"score":"39.102478"}
{"text":"When tested on a corpus of Wikipedia articles , our hierarchically informed model predicts the correct insertion paragraph more accurately than baseline methods .In this paper we consider the problem of automatically identifying the arguments of discourse connectives ( e.g. and , because , nevertheless ) in the Penn Discourse TreeBank(PDTB ) .","label":"CompareOrContrast","metadata":{},"score":"39.1128"}
{"text":"While discriminative methods , such as those presented in McDonald et al .( 2005b ) , obtain very high accuracy on standard dependency parsing tasks and can be trained and applied without marginalization , \" summing trees \" permits some alternative techniques of interest .","label":"CompareOrContrast","metadata":{},"score":"39.2495"}
{"text":"We present a holistic data - driven technique that generates natural - language descriptions for videos .We combine the output of state - of - the - art object and activity detectors with \" real - world \" knowledge to select the most probable subject - verb - object triplet for describing a video .","label":"CompareOrContrast","metadata":{},"score":"39.454845"}
{"text":"We present a holistic data - driven technique that generates natural - language descriptions for videos .We combine the output of state - of - the - art object and activity detectors with \" real - world \" knowledge to select the most probable subject - verb - object triplet for describing a video .","label":"CompareOrContrast","metadata":{},"score":"39.454845"}
{"text":"\" ...We present a novel generative model for natural language tree structures in which semantic ( lexical dependency ) and syntactic ( PCFG ) structures are scored with separate models .This factorization provides conceptual simplicity , straightforward opportunities for separately improving the component mod ... \" .","label":"CompareOrContrast","metadata":{},"score":"39.47457"}
{"text":"We show that the proposed model performs at least as well as an approach based on statistical machine translation on two problems of name transliteration , and provide evidence that the combination of the two approaches promises further improvement .In this paper we propose an instance based method for lexical entailment and apply it to automatic ontology population from text .","label":"CompareOrContrast","metadata":{},"score":"39.508804"}
{"text":"However , for ease of exposition and to relate our work to pre ... . \" ...The best systems for machine translation of natural language are based on statistical models learned from data .Conventional representation of a statistical translation model requires substantial offline computation and representation in main memory .","label":"CompareOrContrast","metadata":{},"score":"39.536053"}
{"text":"This framework integrates multiple MT systems ' output at the word- , phrase- and sentence- levels .By boosting common word and phrase translation pairs , pruning unused phrases , and exploring decoding paths adopted by other MT systems , this framework achieves better translation quality with much less re - decoding time .","label":"CompareOrContrast","metadata":{},"score":"39.56366"}
{"text":"In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .","label":"CompareOrContrast","metadata":{},"score":"39.709194"}
{"text":"In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .","label":"CompareOrContrast","metadata":{},"score":"39.709194"}
{"text":"We begin with the context of the current research , and then move to a formal problem description and an overview of the four main subproblems : translational equivalence modeling , mathematical modeling , parameter estimation , and decoding .Along the way , we present a taxonomy of some different approaches within these areas .","label":"CompareOrContrast","metadata":{},"score":"39.72757"}
{"text":"We also point out the high variance in all of these estimators , and that they require many more iterations to approach convergence than usually thought .This paper describes a probabilistic model for coordination disambiguation integrated into syntactic and case structure analysis .","label":"CompareOrContrast","metadata":{},"score":"39.86116"}
{"text":"We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .","label":"CompareOrContrast","metadata":{},"score":"39.931023"}
{"text":"We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .","label":"CompareOrContrast","metadata":{},"score":"39.931023"}
{"text":"We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .","label":"CompareOrContrast","metadata":{},"score":"39.931023"}
{"text":"We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .","label":"CompareOrContrast","metadata":{},"score":"39.931023"}
{"text":"We can not use non - local features due to concerns about complexity with current major methods of sequence labeling such as CRFs .We propose a new perceptron algorithm that can use non - local features .Our algorithm allows the use of all types of non - local features whose values are determined from the sequence and the labels .","label":"CompareOrContrast","metadata":{},"score":"39.93293"}
{"text":"We also address the issue whether a corpus annotated by means of AL -- using a particular classifier and a particular feature set -- can be re - used to train classifiers different from the ones employed by AL , supplying alternative feature sets as well .","label":"CompareOrContrast","metadata":{},"score":"40.02955"}
{"text":"Finally , we demonstrate the efficacy of a semi - supervised extension .The key idea that enables this is an application of the predict - self idea for unsupervised learning . \" ...This paper describes an empirical study of high - performance dependency parsers based on a semi - supervised learning approach .","label":"CompareOrContrast","metadata":{},"score":"40.04171"}
{"text":"Unlike previous approaches , our framework does not require full projected parses , allowing partial , approximate transfer through linear expectation constraints on the space of distributions over trees .We consider several types of constraints that range from generic dependency conservation to language - specific annotation rules for auxiliary verb analysis .","label":"CompareOrContrast","metadata":{},"score":"40.041855"}
{"text":"Unlike previous approaches , our framework does not require full projected parses , allowing partial , approximate transfer through linear expectation constraints on the space of distributions over trees .We consider several types of constraints that range from generic dependency conservation to language - specific annotation rules for auxiliary verb analysis .","label":"CompareOrContrast","metadata":{},"score":"40.041855"}
{"text":"In this paper , a novel method is proposed for use of web search results to improve the existing query spelling correction models solely based on query logs by leveraging the rich information on the web related to the query and its top - ranked candidate .","label":"CompareOrContrast","metadata":{},"score":"40.08213"}
{"text":"Word lexicon models extracted from the alignment have been proposed by Koehn , Och and Marcu [ 1 ] and Zens and Ney [5 ] ... . \" ...The IBM translation models have been hugely influential in statistical machine translation ; they are the basis of the alignment models used in modern translation systems .","label":"CompareOrContrast","metadata":{},"score":"40.287216"}
{"text":"We apply the proposed approach to enhance opinion sum - marization in a two - stage framework .Experimental results show that the proposed approach effectively ( 1 ) discriminates low - quality reviews from high - quality ones and ( 2 ) enhances the task of opinion summarization by detecting and filtering low - quality reviews .","label":"CompareOrContrast","metadata":{},"score":"40.32881"}
{"text":"This paper focuses on the domain estimation problem in statistical machine translations .In the proposed method , a training corpus , which is a bilingual corpus , is automatically clustered to sub - corpuses .Each sub - corpus is regarded as a domain .","label":"CompareOrContrast","metadata":{},"score":"40.40994"}
{"text":"The system consists of two components : an unlabeled dependency parser using Gibbs sampling which can incorporate sentence - level ( global ) features as well as token - leve ... \" .In this paper , we describe a two - stage multilingual dependency parser used for the multilingual track of the CoNLL 2007 shared task .","label":"CompareOrContrast","metadata":{},"score":"40.46763"}
{"text":"The system consists of two components : an unlabeled dependency parser using Gibbs sampling which can incorporate sentence - level ( global ) features as well as token - leve ... \" .In this paper , we describe a two - stage multilingual dependency parser used for the multilingual track of the CoNLL 2007 shared task .","label":"CompareOrContrast","metadata":{},"score":"40.46763"}
{"text":"Experimental results show that the global features are useful in all the languages . ... mines unlabeled dependency structures only , and we attach dependency relation labels using Support Vector Machines afterwards . \" ...We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .","label":"CompareOrContrast","metadata":{},"score":"40.48331"}
{"text":"Experimental results show that the global features are useful in all the languages . ... mines unlabeled dependency structures only , and we attach dependency relation labels using Support Vector Machines afterwards . \" ...We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .","label":"CompareOrContrast","metadata":{},"score":"40.48331"}
{"text":"We achieve average results , which is partly due to difficulties in mapping to the dependency representation used for the shared task .Following ( Blitzer et al . , 2006 ) , we present an application of structural correspondence learning to non - projective dependency parsing ( McDonald et al . , 2005 ) .","label":"CompareOrContrast","metadata":{},"score":"40.59606"}
{"text":"Current phrase - based SMT technologies are good at capturing local reordering but not global reordering .This paper introduces syntactic knowledge to improve global reordering capability of SMT system .Syntactic knowledge such as boundary words , POS information and dependencies is used to guide phrase reordering .","label":"CompareOrContrast","metadata":{},"score":"40.830467"}
{"text":"The second approach combines unsupervised hidden markov modelling with language models .Empirical evaluation of both systems pointed out that the hidden markov model managed best to learn the task of segmenting and labelling biological field book entries from a derived database only .","label":"CompareOrContrast","metadata":{},"score":"40.83381"}
{"text":"This paper describes an empirical study of high - performance dependency parsers based on a semi - supervised learning approach .We describe an extension of semisupervised structured conditional models ( SS - SCMs ) to the dependency parsing problem , whose framework is originally proposed in ( Suzuki and Isozaki , 2008 ) .","label":"CompareOrContrast","metadata":{},"score":"40.901974"}
{"text":"After a brief introduction to infant testing methods and an overview of experiments demonstrating infants ' statistical prowess , I will describe two new lines of research from our lab that are consistent with Bayesian approaches to linguistic generalization .One line of research focuses on the amount of evidence that infants need to generalize principles that are either found or not found among human languages .","label":"CompareOrContrast","metadata":{},"score":"40.9089"}
{"text":"This factorization provides conceptual simplicity , straightforward opportunities for separately improving the component models , and a level of performance comparable to similar , non - factored models . ... known to be very effective .Additionally , methods based only on key lexical dependencies have been shown to be very effective in choosing between valid syntactic forms [ 1]. \" ...","label":"CompareOrContrast","metadata":{},"score":"40.93195"}
{"text":"We perform both identification and resolution automatically , with two sets of easily computable features .Experimental results show that our proposed learning approach achieves anaphoric zero pronoun resolution accuracy comparable to a previous state - of - the - art , heuristic rule - based approach .","label":"CompareOrContrast","metadata":{},"score":"40.95508"}
{"text":"The model parameters are learned in a max - margin framework by employing a linear programming relaxation .We evaluate the performance of our parser on data in several natural languages , achieving improvements over existing state - of - the - art methods . \" ...","label":"CompareOrContrast","metadata":{},"score":"41.05073"}
{"text":"In our model , arbitrary , nonindependent features may be freely incorporated , thereby overcoming the inherent limitation of generative models , which require that features be sensitive to the conditional independencies of the generative process .However , unlike previous work on discriminative modeling of word alignment ( which also permits the use of arbitrary features ) , the parameters in our models are learned from unannotated parallel sentences , rather than from supervised word alignments .","label":"CompareOrContrast","metadata":{},"score":"41.102997"}
{"text":"Using the WordNet hierarchy , we embed the construction of Abney and Light in the topic model and show that automatically learned domains improve WSD accuracy compared to alternative contexts .This paper focuses on the evaluation of methods for the automatic acquisition of Multiword Expressions ( MWEs ) for robust grammar engineering .","label":"CompareOrContrast","metadata":{},"score":"41.223022"}
{"text":"In this paper , we describe a two - stage multilingual dependency parser used for the multilingual track of the CoNLL 2007 shared task .The system consists of two components : an unlabeled dependency parser using Gibbs sampling which can incorporate sentence - level ( global ) features as well as token - level ( local ) features , and a dependency relation labeling module based on Support Vector Machines .","label":"CompareOrContrast","metadata":{},"score":"41.26266"}
{"text":"Finally , it shows that feature - based and tree kernel - based methods much complement each other and the composite kernel can well integrate both flat and structured features .Syntactic reordering approaches are an effective method for handling word - order differences between source and target languages in statistical machine translation ( SMT ) systems .","label":"CompareOrContrast","metadata":{},"score":"41.424297"}
{"text":"This paper presents a novel unsupervised support vector machine ( U - SVM ) classifier for answer selection , which is independent of language and does not require hand - tagged training pairs .The key ideas are the following : 1 . unsupervised learning of training data for the classifier by clustering web search results ; and 2 . selecting the answer from the candidates by classifying the question .","label":"CompareOrContrast","metadata":{},"score":"41.66144"}
{"text":"Standard thesaurus - based measures of word pair similarity are based on only a single path between those words in the thesaurus graph .By contrast , we propose a new model of lexical semantic relatedness that incorporates information from every explicit or implicit path connecting the two words in the entire graph .","label":"CompareOrContrast","metadata":{},"score":"41.710808"}
{"text":"We explore sourceto - target models with phrase - level as well as sentence - level scoring and target - to - source models with scoring on phrase level only .For the first two types of lexicon models , we compare several scoring variants .","label":"CompareOrContrast","metadata":{},"score":"41.73848"}
{"text":"We exploit the Matrix Tree Theorem ( Tutte , 1984 ) to derive an algorithm that efficiently sums the scores of all nonprojective trees i ... \" .A notable gap in research on statistical dependency parsing is a proper conditional probability distribution over nonprojective dependency trees for a given sentence .","label":"CompareOrContrast","metadata":{},"score":"41.842583"}
{"text":"However , many questions about inference with such split PCFGs remain open .In this work , we present 1 . an effective method for pruning in split PCFGs 2 . a comparison of ... . \" ...We describe a robust accurate domain - independent approach to statistical parsing incorporated into the new release of the ANLT toolkit , and publicly available as a research tool .","label":"CompareOrContrast","metadata":{},"score":"41.885303"}
{"text":"Callison - Burch et al .( 2005 ) and Zhang and Vogel ( 2005 ) proposed a solution that we call translation by pattern matching , which we bring to fruition in this dissertation .The training data itself serves as a proxy to the model ; rules and parameters are computed on demand .","label":"CompareOrContrast","metadata":{},"score":"41.90297"}
{"text":"Our model even competes with state - of - the - art discriminative models hand - designed for the grammaticality tasks , despite training on positive data alone .We also show fluency improvements in a preliminary machine translation experiment .At the same time , because n - gram language models only condition on a local window of linear word - level context , they are p .. \" ...","label":"CompareOrContrast","metadata":{},"score":"41.903545"}
{"text":", 2004 ) and HPSG trees / forests ( Wu et al . , 2010 ) . ... on result extracting .The weights of multiple language models are tuned under minimum error rate training ( MERT )( Och , 2003 ) . \" ...","label":"CompareOrContrast","metadata":{},"score":"41.93613"}
{"text":"Significant improvement over the previous results in the literature is reported as well as a new benchmark dataset is introduced .Semi - supervised algorithms perform better than their supervised version by a wide margin especially when the amount of labeled data is limited .","label":"CompareOrContrast","metadata":{},"score":"42.104813"}
{"text":"Using a single unified internal representation for translat ... \" .We present cdec , an open source framework for decoding , aligning with , and training a number of statistical machine translation models , including word - based models , phrase - based models , and models based on synchronous context - free grammars .","label":"CompareOrContrast","metadata":{},"score":"42.119766"}
{"text":"We present a nonparametric Bayesian model of tree structures based on the hierarchical Dirichlet process ( HDP ) .Our HDP - PCFG model allows the complexity of the grammar to grow as more training data is available .In addition to presenting a fully Bayesian model for the PCFG , we also develop an efficient variational inference procedure .","label":"CompareOrContrast","metadata":{},"score":"42.18251"}
{"text":"For our models and training sets , more peaked measures of confidence , measured by Renyi entropy , outperformed smoother ones .We discuss how our feature set could be extended with cross - lingual or cross - domain features , to incorporate knowledge from parallel or comparable corpora during bootstrapping .","label":"CompareOrContrast","metadata":{},"score":"42.350067"}
{"text":"We propose a novel unsupervised word alignment model based on the Hidden Markov Tree ( HMT ) model .Our model assumes that the alignment variables have a tree structure which is isomorphic to the target dependency tree and models the dis - tortion probability based on the source de - pendency tree , thereby incorporating the syntactic structure from both sides of the parallel sentences .","label":"CompareOrContrast","metadata":{},"score":"42.551613"}
{"text":"We study five types of lexicon models : a model which is extracted from word - aligned training data and - given the word alignment matrix - relies on pure relative frequencies [ 1 ] ; the IBM model 1 l ... \" .","label":"CompareOrContrast","metadata":{},"score":"42.704285"}
{"text":"Our approach recovers non - local dependencies at the level of Lexical - Functional Grammar f - structures , using automatically acquired subcategorisation frames and f - structure paths linking antecedents and traces in NLDs .Currently our algorithm achieves 92.2 % f - score for trace insertion and 84.3 % for antecedent recovery evaluating on gold - standard CTB trees , and 64.7 % and 54.7 % , respectively , on CTBtrained state - of - the - art parser output trees .","label":"CompareOrContrast","metadata":{},"score":"42.750675"}
{"text":"Based on an extension to Harris 's distributional hypothesis , we use selectional preferences to gather evidence of inference directionality and plausibility .Experiments show empirical evidence that our approach can classify inference rules significantly better than several baselines .This paper assesses the role of multi - label classification in modelling polysemy for language acquisition tasks .","label":"CompareOrContrast","metadata":{},"score":"42.755898"}
{"text":"We ... \" .We introduce a novel Bayesian approach for deciphering complex substitution ciphers .Our method uses a decipherment model which combines information from letter n - gram language models as well as word dictionaries .Bayesian inference is performed on our model using an efficient sampling technique .","label":"CompareOrContrast","metadata":{},"score":"42.783463"}
{"text":"We describe our submission to the domain adaptation track of the CoNLL07 shared task in the open class for systems using external resources .Our main finding was that it was very difficult to map from the annotation scheme used to prepare training and development data to one that could be used to effectively train and adapt the RASP system unlexicalised parse ranking model .","label":"CompareOrContrast","metadata":{},"score":"42.834843"}
{"text":"In particular , we wish to determine the best location in a text for a given piece of new information .For this process to succeed , the insertion algorithm should be informed by the existing document structure .Lengthy real - world texts are often hierarchically organized into chapters , sections , and paragraphs .","label":"CompareOrContrast","metadata":{},"score":"43.17943"}
{"text":"These features include scores from discriminative classifiers for sp ... \" .We present a novel beam - search decoder for grammatical error correction .The decoder iteratively generates new hypothesis corrections from current hypotheses and scores them based on features of grammatical correctness and fluency .","label":"CompareOrContrast","metadata":{},"score":"43.213623"}
{"text":"Experimental results on sentence compression bring significant improvements over a state - of - the - art model .Many emerging applications require documents to be repeatedly updated .Such documents include newsfeeds , webpages , and shared community resources such as Wikipedia .","label":"CompareOrContrast","metadata":{},"score":"43.22738"}
{"text":"Our code is open - source1 , thread - safe , and integrated into the Moses , cdec , and Joshua translation systems .This paper describes the several performance techniques used and presents benchmarks against alternative implementations . ...r accurate model estimation , but can also compute perplexity . RandLM 0.2 ( Talbot and Osborne , 2007 ) stores large - scale models in less memory using randomized data structures .","label":"CompareOrContrast","metadata":{},"score":"43.39186"}
{"text":"We present and evaluate here several methods that integrate LSA - based information with a standard language model : a semantic cache , partial reranking , and different forms of interpolation .We found that all methods show significant improvements , compared to the 4-gram baseline , and most of them to a simple cache model as well .","label":"CompareOrContrast","metadata":{},"score":"43.4106"}
{"text":"First , it automatically determines a dy - namic context - sensitive tree span for relation extraction by extending the widely - used Shortest Path - enclosed Tree ( SPT ) to include necessary context information outside SPT .Second , it proposes a context - sensitive convolution tree kernel , which enumerates both context - free and context - sensitive sub - trees by considering their ancestor node paths as their contexts .","label":"CompareOrContrast","metadata":{},"score":"43.567516"}
{"text":"There has been little effort reported on this in the research community .We argue that semantics is important for record extraction or finer - grained language processing tasks .We derive a data record template including semantic language models from unstructured text and represent them with a discourse level Conditional Random Fields ( CRF ) model .","label":"CompareOrContrast","metadata":{},"score":"43.664436"}
{"text":"The best systems for machine translation of natural language are based on statistical models learned from data .Conventional representation of a statistical translation model requires substantial offline computation and representation in main memory .Therefore , the principal bottlenecks to the amount of data we can exploit and the complexity of models we can use are available memory and CPU time , and current state of the art already pushes these limits .","label":"CompareOrContrast","metadata":{},"score":"43.66649"}
{"text":"State - of - the - art performance on Hebrew Treebank parsing is demonstrated using the new method .The benefits of joint inference are modest with the current component models , but appear to increase as components themselves improve .This paper proposes a new bootstrapping approach to unsupervised part - of - speech induction for resource - scarce languages .","label":"CompareOrContrast","metadata":{},"score":"43.666817"}
{"text":"In the domain adaptation track , we use two models to parse unlabeled data in the target domain to supplement the labeled out - of - domain training set , in a scheme similar to one iteration of co - training .","label":"CompareOrContrast","metadata":{},"score":"43.768448"}
{"text":"We propose a simple generative , syntactic language model that conditions on overlapping windows of tree context ( or treelets ) in the same way that n - gram language models condition on overlapping windows of linear context .We estimate the parameters of our model by collecting counts from automaticall ... \" .","label":"CompareOrContrast","metadata":{},"score":"43.91842"}
{"text":"In addition , we utilize the RankBoost - based reranking algorithm to rerank the N - best outputs of the HMM - based tagger using various $ n$-gram , morphological , and dependency features .Two methods are proposed to improve the generalization performance of the reranking algorithm .","label":"CompareOrContrast","metadata":{},"score":"43.96318"}
{"text":"Instead of collecting more and more parallel training corpora , this paper aims to improve SMT performance by exploiting full potential of the existing parallel corpora .Two kinds of methods are proposed : offline data optimization and online model optimization .","label":"CompareOrContrast","metadata":{},"score":"43.994743"}
{"text":"We remove this bottleneck by predicting the final verb in advance .We use reinforcement learn - ing to learn when to trust predictions about unseen , future portions of the sentence .We also introduce an evalua - tion metric to measure expeditiousness and quality .","label":"CompareOrContrast","metadata":{},"score":"44.009453"}
{"text":"Our preordering approach has several advantages .First , be - nsubj ROOT attr det amod It was a real whirlwind .NN VBD ...The 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ( EMNLP - CoNLL 2007 ) .","label":"CompareOrContrast","metadata":{},"score":"44.015675"}
{"text":"We discuss how the general framework is applied to each of the problems studied in this article , making comparisons with alternative learning and decoding algorithms .We also show how the comparability of candidates considered by the beam is an important factor in the performance .","label":"CompareOrContrast","metadata":{},"score":"44.165222"}
{"text":"We discuss how the general framework is applied to each of the problems studied in this article , making comparisons with alternative learning and decoding algorithms .We also show how the comparability of candidates considered by the beam is an important factor in the performance .","label":"CompareOrContrast","metadata":{},"score":"44.165222"}
{"text":"We demonstrate the effectiveness of our technique largely surpassing both the random and most frequent baselines and outperforming current state - of - the - art unsupervised approaches on a benchmark ontology available in the literature .To date , work on Non - Local Dependencies ( NLDs ) has focused almost exclusively on English and it is an open research question how well these approaches migrate to other languages .","label":"CompareOrContrast","metadata":{},"score":"44.253067"}
{"text":"A notable gap in research on statistical dependency parsing is a proper conditional probability distribution over nonprojective dependency trees for a given sentence .We exploit the Matrix Tree Theorem ( Tutte , 1984 ) to derive an algorithm that efficiently sums the scores of all nonprojective trees in a sentence , permitting the definition of a conditional log - linear model over trees .","label":"CompareOrContrast","metadata":{},"score":"44.272816"}
{"text":"We exploit a series of binarization methods to restructure the Penn Treebank style trees such that syntactified phrases smaller than Penn Treebank constituents can be acquired and exploited in translation .We find that by employing the EM algorithm for determining the binarization of a parse tree among a set of alternative binarizations gives us the best translation result .","label":"CompareOrContrast","metadata":{},"score":"44.291183"}
{"text":"Semantic inference is a core component of many natural language applications .In response , several researchers have developed algorithms for automatically learning inference rules from textual corpora .However , these rules are often either imprecise or underspecified in directionality .","label":"CompareOrContrast","metadata":{},"score":"44.339916"}
{"text":"The toolkit supports several state - of - the - art models developed in statistical machine translation , including the phrase - based model , the hierachical phrase - based model , and various syntaxbased models .The key ... \" .","label":"CompareOrContrast","metadata":{},"score":"44.356476"}
{"text":"We present a novel discriminative approach to parsing inspired by the large - margin criterion underlying support vector machines .Our formulation uses a factorization analogous to the standard dynamic programs for parsing .In particular , it allows one to efficiently learn a model which discriminates ... \" .","label":"CompareOrContrast","metadata":{},"score":"44.46483"}
{"text":"Via an oracle experiment , we show that the upper bound on accuracy of a CCG parser is significantly lowered when its search space is pruned using a supertagger , though the supertagger also prunes many bad parses .Inspired by this analysis , we design a single model with both supertagging and parsing features , rather than separating them into distinct models chained together in a pipeline .","label":"CompareOrContrast","metadata":{},"score":"44.50431"}
{"text":"We call this the \" SVO Language Model \" approach ( SVO LM ) .This simple model does not consider synonyms , verb conjugations , or SVO dependencies but only looks at word sequences .... . \" ...We present a novel beam - search decoder for grammatical error correction .","label":"CompareOrContrast","metadata":{},"score":"44.598522"}
{"text":"In scientific literature , sentences that cite related work can be a valuable resource for applications such as summarization , synonym identification , and entity extraction .In order to determine which equivalent entities are discussed in the various citation sentences , we propose aligning the words within these sentences according to semantic similarity .","label":"CompareOrContrast","metadata":{},"score":"44.938427"}
{"text":"This lexicon provides the initial lexical probabilities for EM training of a HMM model .We evaluate the method by applying it in the Biology domain and show that we achieve results that are comparable with some taggers developed for this domain .","label":"CompareOrContrast","metadata":{},"score":"45.004868"}
{"text":"Left - to - right decoding , which generates the target string in order , can improve decoding efficiency by simplifying the language model evaluation .This paper presents a novel left to right decoding algorithm for tree - to - string translation , using a bottom - up parsing strategy and dynamic future cost estimation for each partial translation .","label":"CompareOrContrast","metadata":{},"score":"45.02881"}
{"text":"..METU - Sabanc treebank ( Atalay et al . , 2003 ; Oflazer et al . , 2003 ) from the CoNLL shared task in 2006 .Whenever using CoNLL shared task data , we used the first 80 % of the data d .. \" ...","label":"CompareOrContrast","metadata":{},"score":"45.055157"}
{"text":"..METU - Sabanc treebank ( Atalay et al . , 2003 ; Oflazer et al . , 2003 ) from the CoNLL shared task in 2006 .Whenever using CoNLL shared task data , we used the first 80 % of the data d .. \" ...","label":"CompareOrContrast","metadata":{},"score":"45.055157"}
{"text":"Key enablers of this high performance are features derived from previous natural language processing work in noun compound bracketing .For example , token association features beyond simple N - gram counts provide powerful indicators of segmentation .We present two machine learning approaches to information extraction from semi - structured documents that can be used if no annotated training data are available , but there does exist a database filled with information derived from the type of documents to be processed .","label":"CompareOrContrast","metadata":{},"score":"45.07804"}
{"text":"We present experiments with a dependency parsing model defined on rich factors .Our model represents dependency trees with factors that include three types of relations between the tokens of a dependency and their children .We extend the projective parsing algorithm of Eisner ( 1996 ) for our case , and train models using the averaged perceptron .","label":"CompareOrContrast","metadata":{},"score":"45.149647"}
{"text":"We present a comparative error analysis of the two dominant approaches in data - driven dependency parsing : global , exhaustive , graph - based models , and local , greedy , transition - based models .We show that , in spite of similar performance overall , the two models produce different types of errors , in a way that can be explained by theoretical properties of the two models .","label":"CompareOrContrast","metadata":{},"score":"45.16851"}
{"text":"However , parsing accuracies for Arabic usually lag behind non - semitic languages .Moreover , whil ...Tools . by Kuzman Ganchev , Jennifer Gillenwater , Ben Taskar - In ACL - IJCNLP , 2009 . \" ...Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .","label":"CompareOrContrast","metadata":{},"score":"45.54545"}
{"text":"We generalize the evaluation to other word - types , and show that the performance can be increased to 18 % relative by preserving part - of - speech equivalencies during translation .We further differentiate ourselves from previous work by conducting a second evaluation which examines the accuracy of translating all word types , rather than just nouns .","label":"CompareOrContrast","metadata":{},"score":"45.57343"}
{"text":"We generalize the evaluation to other word - types , and show that the performance can be increased to 18 % relative by preserving part - of - speech equivalencies during translation .We further differentiate ourselves from previous work by conducting a second evaluation which examines the accuracy of translating all word types , rather than just nouns .","label":"CompareOrContrast","metadata":{},"score":"45.57343"}
{"text":"Therefore , the principal bottlenecks to the amoun ... \" .The best systems for machine translation of natural language are based on statistical models learned from data .Conventional representation of a statistical translation model requires substantial offline computation and representation in main memory .","label":"CompareOrContrast","metadata":{},"score":"45.6875"}
{"text":"We analyze the effect of resampling techniques , including under - sampling and over - sampling used in active learning .Experimental results show that under - sampling causes negative effects on active learning , but over - sampling is a relatively good choice .","label":"CompareOrContrast","metadata":{},"score":"45.798973"}
{"text":"Morphological analysis and disambiguation are crucial stages in a variety of natural language processing applications , especially when languages with complex morphology are concerned .We present a system which disambiguates the output of a morphological analyzer for Hebrew .It consists of several simple classifiers and a module which combines them under linguistically motivated constraints .","label":"CompareOrContrast","metadata":{},"score":"45.88982"}
{"text":"Unlike all previous approaches , our method is able to perform correction of whole sentences with multiple and interacting errors while still taking advantage of powerful existing classifier approaches .Our decoder achieves an F1 correction score significantly higher than all previous published scores on the Helping Our Own ( HOO ) shared task data set . ... ults directly comparable to the pipeline , the decoder uses the same resources as the pipeline .","label":"CompareOrContrast","metadata":{},"score":"45.897663"}
{"text":"Experiments on twelve languages show that stacking transition - based and graphbased parsers improves performance over existing state - of - the - art dependency parsers . by Terry Koo , Amir Globerson , Xavier Carreras , Michael Collins - In EMNLP - CoNLL , 2007 . \" ...","label":"CompareOrContrast","metadata":{},"score":"46.033443"}
{"text":"Dependency parsing is a central NLP task .In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .","label":"CompareOrContrast","metadata":{},"score":"46.063255"}
{"text":"Dependency parsing is a central NLP task .In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .","label":"CompareOrContrast","metadata":{},"score":"46.063255"}
{"text":"We treat the graph as a Markov chain and compute a word - specific stationary distribution via a generalized PageRank algorithm .Semantic relatedness of a word pair is scored by a novel divergence measure , ZKL , that outperforms existing measures on certain classes of distributions .","label":"CompareOrContrast","metadata":{},"score":"46.08717"}
{"text":"We present experiments showing that multilingual , parallel text in Spanish , French , Russian , and Chinese can be utilized in this framework to improve translation performance on an Arabic - to - English task .Automatic word alignment is the problem of automatically annotating parallel text with translational correspondence .","label":"CompareOrContrast","metadata":{},"score":"46.13823"}
{"text":"Syntax - based translation models should in principle be efficient with polynomially - sized search space , but in practice they are often embarassingly slow , partly due to the cost of language model integration .Experiments show that , with comparable translation quality , our tree - to - string system ( in Python ) can run more than 30 times faster than the phrase - based system Moses ( in C++ ) . ... ld potentially be combined to further speed up decoding .","label":"CompareOrContrast","metadata":{},"score":"46.173615"}
{"text":"We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .","label":"CompareOrContrast","metadata":{},"score":"46.24588"}
{"text":"We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .","label":"CompareOrContrast","metadata":{},"score":"46.24588"}
{"text":"We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .","label":"CompareOrContrast","metadata":{},"score":"46.24588"}
{"text":"We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .","label":"CompareOrContrast","metadata":{},"score":"46.24588"}
{"text":"We also describe the multiplicative combination of this dependency model with a model of linear constituency .The product model outperforms both components on their respective evaluation metrics , giving the best published figures for unsupervised dependency parsing and unsupervised constituency parsing .","label":"CompareOrContrast","metadata":{},"score":"46.26806"}
{"text":"It is well - known that domain specific language models perform well in automatic speech recognition .Domain specific language and translation models in statistical machine translations perform well .However , there are two problems with using domain specific models .","label":"CompareOrContrast","metadata":{},"score":"46.282997"}
{"text":"The paper reports a hybridization experiment , where an existing ML dependency parser ( LingPars ) , was allowed access to Constraint Grammar analyses provided by a rule - based parser ( EngGram ) for the same data .Descriptive compatibility issues and their influence on performance are discussed , such as tokenization problems , category bundling and dependency head conventions .","label":"CompareOrContrast","metadata":{},"score":"46.345795"}
{"text":"We train a discriminative classifier over a wide variety of features derived from WordNet structure , corpus - based evidence , and evidence from other lexical resources .Our learned similarity measure outperforms previously proposed automatic methods for sense clustering on the task of predicting human sense merging judgments , yielding an absolute F - score improvement of 4.1 % on nouns , 13.6 % on verbs , and 4.0 % on adjectives .","label":"CompareOrContrast","metadata":{},"score":"46.363697"}
{"text":"This paper addresses the problem of detecting low - quality product reviews .Three types of biases in the existing evaluation standard of product reviews are discovered .To assess the quality of product reviews , a set of specifications for judging the quality of reviews is first defined .","label":"CompareOrContrast","metadata":{},"score":"46.666172"}
{"text":"We describe an adaptation and application of a search - based structured prediction algorithm \" Searn \" to unsupervised learning problems .We show that it is possible to reduce unsupervised learning to supervised learning and demonstrate a high - quality unsupervised shift - reduce parsing model .","label":"CompareOrContrast","metadata":{},"score":"46.70243"}
{"text":"We describe an adaptation and application of a search - based structured prediction algorithm \" Searn \" to unsupervised learning problems .We show that it is possible to reduce unsupervised learning to supervised learning and demonstrate a high - quality unsupervised shift - reduce parsing model .","label":"CompareOrContrast","metadata":{},"score":"46.70243"}
{"text":"The resulting IE system achieves good performance on the MUC-4 terrorism corpus and ProMed disease outbreak stories .This approach requires only a few seed extraction patterns and a collection of relevant and irrelevant documents for training .This paper proposes a tree kernel with context - sensitive structured parse tree information for re - lation extraction .","label":"CompareOrContrast","metadata":{},"score":"46.750347"}
{"text":"We frame the MT problem as a decipherment task , treating the foreign text as a cipher for English and present novel methods for training translation models from nonparallel text .In this work , we tackle the task of machine translation ( MT ) without parallel training data .","label":"CompareOrContrast","metadata":{},"score":"46.75361"}
{"text":", 2005b ) .Recently Nivre and McDonald ( 2008 ) used the output of one dependency parser to provide features for another .We show that this is an example of stacked learning , in which a second predictor is trained to improve the performance of the first .","label":"CompareOrContrast","metadata":{},"score":"46.776657"}
{"text":"We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word - to - word alignments from an MT system , and syntactic structure from parse - trees of source and target language sentences .","label":"CompareOrContrast","metadata":{},"score":"46.821697"}
{"text":"We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .","label":"CompareOrContrast","metadata":{},"score":"46.83139"}
{"text":"We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .","label":"CompareOrContrast","metadata":{},"score":"46.83139"}
{"text":"We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .","label":"CompareOrContrast","metadata":{},"score":"46.83139"}
{"text":"We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .","label":"CompareOrContrast","metadata":{},"score":"46.83139"}
{"text":"We describe Akamon , an open source toolkit for tree and forest - based statistical machine translation ( Liu et al . , 2006 ; Mi et al . , 2008 ; Mi and Huang , 2008 ) .Akamon implements all of the algorithms required for tree / forestto - string decoding using tree - to - string translation rules : multiple - thread for ... \" .","label":"CompareOrContrast","metadata":{},"score":"46.849762"}
{"text":"We formulate the problem of nonprojective dependency parsing as a polynomial - sized integer linear program .Our formulation is able to handle non - local output features in an efficient manner ; not only is it compatible with prior knowledge encoded as hard constraints , it can also learn soft constraints from data .","label":"CompareOrContrast","metadata":{},"score":"46.889572"}
{"text":"We extract effective expressions from the important segments to define various viewpoints .In text mining a viewpoint defines the important associations between key entities and it is crucial that the correct viewpoints are identified .We show the effectiveness of the method by using real datasets from a car rental service center .","label":"CompareOrContrast","metadata":{},"score":"46.893898"}
{"text":"We show how partition functions and marginals for directed spanning trees can be computed by an adaptation of Kirchhoff 's Matrix - Tree ... \" .This paper provides an algorithmic framework for learning statistical models involving directed spanning trees , or equivalently non - projective dependency structures .","label":"CompareOrContrast","metadata":{},"score":"46.941795"}
{"text":"This simple framework performs surprisingly well , giving accuracy results competitive with the state - of - the - art on all the tasks we consider .The computational simplicity of the decoder and training algorithm leads to significantly higher test speeds and lower training times than their main alternatives , including log - linear and large - margin training algorithms and dynamic - programming for decoding .","label":"CompareOrContrast","metadata":{},"score":"46.971878"}
{"text":"This simple framework performs surprisingly well , giving accuracy results competitive with the state - of - the - art on all the tasks we consider .The computational simplicity of the decoder and training algorithm leads to significantly higher test speeds and lower training times than their main alternatives , including log - linear and large - margin training algorithms and dynamic - programming for decoding .","label":"CompareOrContrast","metadata":{},"score":"46.971878"}
{"text":"Using the RankNet learning algorithm , we train a pair - based sentence ranker to score every sentence in the document and identify the most important sentences .We apply our system to documents gathered from CNN.com , where each document includes highlights and an article .","label":"CompareOrContrast","metadata":{},"score":"46.984734"}
{"text":"However , previous approaches ignore this dependency .We propose a novel approach for this task , namely training Semi Markov models discriminatively using a Max - Margin method .This method allows us to model the sequence dependency of the problem and to incorporate properties of a whole paragraph , such as coherence , which can not be used in previous methods .","label":"CompareOrContrast","metadata":{},"score":"47.017952"}
{"text":"To demonstrate an application of the method , we perform experiments which use the algorithm in training both log - linear and max - margin dependency parsers .The new training methods give improvements in accuracy over perceptron - trained models . ... linear and max - margin training to be applied via the framework developed in this paper .","label":"CompareOrContrast","metadata":{},"score":"47.039314"}
{"text":"Three binary linear classifiers were trained to predict the existence of a preposition , etc , on unlabeled data and we used singular value decomposition to induce new features .During the training , the parser was trained with these additional features in addition to these described in ( McDonald et al . , 2005 ) .","label":"CompareOrContrast","metadata":{},"score":"47.198563"}
{"text":"We also show that our techniques can be applied to full - scale parsing applications by demonstrating its effectiveness in learning state - split grammars .We explore the use of Wikipedia as external knowledge to improve named entity recognition ( NER ) .","label":"CompareOrContrast","metadata":{},"score":"47.223007"}
{"text":"Generalizing possible tags for new words A drawback of the semi - supervised approach is that the dictionary has to include a set of possible tags for all words being tagged .Tagging new corpora ...Tools . by Chris Dyer , Adam Lopez , Juri Ganitkevitch , Jonathan Weese , Hendra Setiawan , Ferhan Ture , Vladimir Eidelman , Phil Blunsom , Philip Resnik - In Proceedings of ACL System Demonstrations , 2010 . \" ...","label":"CompareOrContrast","metadata":{},"score":"47.264843"}
{"text":"In phrase - based models , this problem can be addressed by storing the training data in memory and using a suffix array as an efficient index to quickly lookup and extract rules on the fly .Hierarchical phrase - based translation introduces the added wrinkle of source phrases with gaps .","label":"CompareOrContrast","metadata":{},"score":"47.56483"}
{"text":"Furthermore , we explore the performance of information drawn from different levels of linguistic description , using feature sets based on morphology , syntax , semantics , and n -gram distribution .Finally , we demonstrate that ensemble classifiers are a powerful and adequate way to combine different types of linguistic evidence : a simple , majority voting ensemble classifier improves the accuracy from 62.5 % ( best single classifier ) to 84 % .","label":"CompareOrContrast","metadata":{},"score":"47.799313"}
{"text":"We provide an efficient algorithm for learning such models and show experimental evidence of the model 's improved performance over a natural baseline model and a lexicalized probabilistic context - free grammar . by Shankar Kumar , William Byrne , Speech Processing - In Proceedings of HLT - NAACL , 2004 . \" ...","label":"CompareOrContrast","metadata":{},"score":"47.92914"}
{"text":"Our approach combines a set of hand - written patterns together with a probabilistic model .Because the patterns heavily utilize regular expressions , the pertinent tree structures are covered using a limited number of patterns .The probabilistic model is essentially a probabilistic context - free grammar ( PCFG ) approach with the patterns acting as the terminals in production rules .","label":"CompareOrContrast","metadata":{},"score":"47.96698"}
{"text":"These category labels are used as features in a CRF - based NE tagger .We demonstrate using the CoNLL 2003 dataset that the Wikipedia category labels extracted by such a simple method actually improve the accuracy of NER .This paper presents a large - scale system for the recognition and semantic disambiguation of named entities based on information extracted automatically from a large encyclopedic collection and Web search results , over a space of more than 1.4 million entities .","label":"CompareOrContrast","metadata":{},"score":"48.013336"}
{"text":"Deterministic parsing has emerged as an effective alternative for complex parsing algorithms which search the entire search space to get the best probable parse tree .In this paper , we present an online large margin based training framework for deterministic parsing using Nivre 's Shift - Reduce parsing algorithm .","label":"CompareOrContrast","metadata":{},"score":"48.05552"}
{"text":"Unlike previous methods , our approach can annotate arbitrary videos without requiring the expensive collection and annotation of a similar training video corpus .We evaluate our technique against a baseline that does not use text - mined knowledge and show that humans prefer our descriptions 61 % of the time . .","label":"CompareOrContrast","metadata":{},"score":"48.199455"}
{"text":"The online method adapts the translation model by redistributing the weight of each predefined submodels .Information retrieval model is used for the weighting scheme in both methods .Experimental results show that without using any additional resource , both methods can improve SMT performance significantly .","label":"CompareOrContrast","metadata":{},"score":"48.22654"}
{"text":"In common with other approaches to sequence modeling using perceptrons , and in contrast with comparable generative models , this model permits and transparently exploits arbitrary features of input strings .The simplicity of perceptron training lends more versatility than comparable approaches , allowing the model to be applied to a variety of problem types for which a learned edit model might be useful .","label":"CompareOrContrast","metadata":{},"score":"48.41752"}
{"text":"We introduce a reinforcement learning - based approach to simultaneous ma - chine translation - producing a trans - lation while receiving input words- between languages with drastically dif - ferent word orders : from verb - final lan - guages ( e.g. , German ) to verb - medial languages ( English ) .","label":"CompareOrContrast","metadata":{},"score":"48.42635"}
{"text":"The experiments are carried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser .We use a generative history - based model to predict the most likely derivation of a dependency parse .","label":"CompareOrContrast","metadata":{},"score":"48.426437"}
{"text":"Our method compares favorably with state - of - the - art algorithms that recover WH - traces .Recent studies focussed on the question whether less - configurational languages like German are harder to parse than English , or whether the lower parsing scores are an artifact of treebank encoding schemes and data structures , as claimed by Kbler et al .","label":"CompareOrContrast","metadata":{},"score":"48.504593"}
{"text":"Despite their simplicity , we find that initializing the dependency model with valence using our concave models can approach state of the art grammar induction results for English and Chinese .For other applications , such as unsupervised part - of - speech tagging and grammar induction , and indeed for more sophisticated word alignment models , the log - likelihood function optimized by EM is n .. \" ...","label":"CompareOrContrast","metadata":{},"score":"48.52847"}
{"text":"From this unified representation , the decoder can extract not only the 1- or k - best translations , but also alignments to a reference , or the quantities necessary to drive discriminative training using gradient - based or gradient - free optimization techniques .","label":"CompareOrContrast","metadata":{},"score":"48.646008"}
{"text":"We argue that bootstrapping a parser is most promising when the model uses a rich set of redundant features , as in recent models for scoring dependency parses ( McDonald et al . , 2005 ) .Drawing on Abney 's ( 2004 ) analysis of the Yarowsky algorithm , we perform bootstrapping by entropy regularization : we maximize a linear combination of conditional likelihood on labeled data and confidence ( negative Renyi entropy ) on unlabeled data .","label":"CompareOrContrast","metadata":{},"score":"48.77011"}
{"text":"The first stage consists in tuning a single - parser system for each language by optimizing parameters of the parsing algorithm , the feature model , and the learning algorithm .The second stage consists in building an ensemble system that combines six different parsing strategies , extrapolating from the optimal parameters settings for each language .","label":"CompareOrContrast","metadata":{},"score":"48.873993"}
{"text":"Our approach is based on the analysis of the paths between two protein names in the dependency parse trees of the sentences .Given two dependency trees , we define two separate similarity functions ( kernels ) based on cosine similarity and edit distance among the paths between the protein names .","label":"CompareOrContrast","metadata":{},"score":"48.90342"}
{"text":"We define the objective function of our hybrid model , which is written in log - linear form , by discriminatively combining discriminative structured predictor(s ) with generative model(s ) that incorporate unlabeled data .Then , unlabeled data is used in a generative manner to increase the sum of the discriminant functions for all outputs during the parameter estimation .","label":"CompareOrContrast","metadata":{},"score":"49.113613"}
{"text":"y and goal of this work is different from ours .Building topic models .A prominent use of Bayesian inference is in topic modeling , which has found applications in information retrieval and NLP for a broad variety of tasks such as summarization ( Daume ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"49.12623"}
{"text":"Unfortunately the sentence in Figure 1(b ) is highly unusual in its amount of dependency conservation .To get a feel for the typical case , we used off - the - shelf parsers ( McDonald et al . , 2005 ) for E .. by Ivan Titov , James Henderson - IN PROCEEDINGS OF CONLL-2007 SHARED TASK .","label":"CompareOrContrast","metadata":{},"score":"49.155697"}
{"text":"Unfortunately the sentence in Figure 1(b ) is highly unusual in its amount of dependency conservation .To get a feel for the typical case , we used off - the - shelf parsers ( McDonald et al . , 2005 ) for E .. by Ivan Titov , James Henderson - IN PROCEEDINGS OF CONLL-2007 SHARED TASK .","label":"CompareOrContrast","metadata":{},"score":"49.155697"}
{"text":"We show how partition functions and marginals for directed spanning trees can be computed by an adaptation of Kirchhoff 's Matrix - Tree Theorem .To demonstrate an application of the method , we perform experiments which use the algorithm in training both log - linear and max - margin dependency parsers .","label":"CompareOrContrast","metadata":{},"score":"49.169136"}
{"text":"Statistical machine translation ( SMT ) treats the translation of natural language as a machine learning problem .By examining many samples of human - produced translation , SMT algorithms automatically learn how to translate .SMT has made tremendous strides in less than two decades , and many popular techniques have only emerged within the last few years .","label":"CompareOrContrast","metadata":{},"score":"49.368732"}
{"text":"This paper presents a novel approach for exploiting the global context for the task of word sense disambiguation ( WSD ) .This is done by using topic features constructed using the latent dirichlet allocation ( LDA ) algorithm on unlabeled data .","label":"CompareOrContrast","metadata":{},"score":"49.447224"}
{"text":"Evaluation on the ACE RDC corpora shows that our dynamic context - sensitive tree span is much more suitable for relation extraction than SPT and our tree kernel outperforms the state - of - the - art Collins and Duffy 's convolution tree kernel .","label":"CompareOrContrast","metadata":{},"score":"49.63179"}
{"text":"As the algorithm generates dependency trees for partial translations left - to - right in decoding , it allows for efficient integration of both n - gram and dependency language models .To resolve conflicts in s ... \" .We introduce a shift - reduce parsing algorithm for phrase - based string - todependency translation .","label":"CompareOrContrast","metadata":{},"score":"49.700607"}
{"text":"But this method does not work well for web query spelling correction , because there is no lexicon that can cover the vast amount of terms occurring across the web .Recent work showed that using search query logs helps to solve this problem to some extent .","label":"CompareOrContrast","metadata":{},"score":"49.71639"}
{"text":"Lexical chains have been successfully employed to evaluate lexical cohesion of text segments and to predict topic boundaries .Our approach is based in the notion of semantic cohesion .It uses spectral embedding to estimate semantic association between content nouns over a span of multiple text segments .","label":"CompareOrContrast","metadata":{},"score":"49.77233"}
{"text":"We consider generative and di ... \" .Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .The wide availability of parallel text and accurate parsers in English has opened up the possibility of grammar induction through partial transfer across bitext .","label":"CompareOrContrast","metadata":{},"score":"50.0049"}
{"text":"We consider generative and di ... \" .Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .The wide availability of parallel text and accurate parsers in English has opened up the possibility of grammar induction through partial transfer across bitext .","label":"CompareOrContrast","metadata":{},"score":"50.0049"}
{"text":"In particular , it is important to see if the classification could accommodate new words from heterogeneous data sources , and whether simple similarity measures and clustering methods could cope with such variation .We use the cosine function for similarity and test it on automatically classifying 120 target words from four regions , using different datasets for the extraction of feature vectors .","label":"CompareOrContrast","metadata":{},"score":"50.118874"}
{"text":"The disambiguation component employs a vector space model and a process of maximizing the agreement between the contextual information extracted from Wikipedia and the context of a document , as well as the agreement among the category tags associated with the candidate entities .","label":"CompareOrContrast","metadata":{},"score":"50.53871"}
{"text":"It provides an open - source C++ implementation for the entire forest - to - string MT pipeline , including rule extraction , tuning , decoding , and evaluation .There are a number of options for ... \" .In this paper we describe Travatar , a forest - to - string machine translation ( MT ) engine based on tree transducers .","label":"CompareOrContrast","metadata":{},"score":"50.65094"}
{"text":"Phrase table smoothing with triplet lexicon models and with discriminative word lexicons are novel contributions .We also propose a new regularization technique for IBM model 1 by means of the Kullback - Leibler divergence with the empirical unigram distribution as regularization term .","label":"CompareOrContrast","metadata":{},"score":"50.673477"}
{"text":"We present a generative model for the unsupervised learning of dependency structures .We also describe the multiplicative combination of this dependency model with a model of linear constituency .The product model outperforms both components on their respective evaluation metrics , giving the best pu ... \" .","label":"CompareOrContrast","metadata":{},"score":"50.993885"}
{"text":"Yet SMT translation quality still obviously suffers from inaccurate lexical choice .In this paper , we address this problem by investigating a new strategy for integrating WSD into an SMT system , that performs fully phrasal multi - word disambiguation .","label":"CompareOrContrast","metadata":{},"score":"51.046894"}
{"text":"Most current word prediction systems make use of n - gram language models ( LM ) to estimate the probability of the following word in a phrase .In the past years there have been many attempts to enrich such language models with further syntactic or semantic information .","label":"CompareOrContrast","metadata":{},"score":"51.139893"}
{"text":"The new research begins to provide a sketch of infants as hypothesis selectors whose hypothesis space is narrowed over development by the statistical properties of their input .Sentence compression holds promise for many applications ranging from summarisation to subtitle generation and information retrieval .","label":"CompareOrContrast","metadata":{},"score":"51.31146"}
{"text":"In particular , we present a novel method for combining morphological and distributional information for seed selection .Experimental results demonstrate that our approach works well for English and Bengali , thus providing suggestive evidence that it is applicable to both morphologically impoverished langauges and highly inflectional langauges .","label":"CompareOrContrast","metadata":{},"score":"51.539234"}
{"text":"An adaptation technique is used to avoid this problem .The second problem is domain estimation .For adaptation , the domain must be given in advance .However , in many cases , the domain is not given or changes dynamically .","label":"CompareOrContrast","metadata":{},"score":"51.55082"}
{"text":"Their symbolic component is amenable to inspection by humans , while their probabilistic component helps resolve ambiguity .They also permit the use of well - understood , generalpurpose learn ... \" .Probabilistic grammars offer great flexibility in modeling discrete sequential data like natural language text .","label":"CompareOrContrast","metadata":{},"score":"51.565712"}
{"text":"Their symbolic component is amenable to inspection by humans , while their probabilistic component helps resolve ambiguity .They also permit the use of well - understood , generalpurpose learn ... \" .Probabilistic grammars offer great flexibility in modeling discrete sequential data like natural language text .","label":"CompareOrContrast","metadata":{},"score":"51.565712"}
{"text":"The tree with the maximal probability is outputted .The experiments are carried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser . ... arried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser .","label":"CompareOrContrast","metadata":{},"score":"51.71188"}
{"text":"The tree with the maximal probability is outputted .The experiments are carried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser . ... arried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser .","label":"CompareOrContrast","metadata":{},"score":"51.71188"}
{"text":"The deep processing approach uses the XLE LFG parser and English grammar : two versions are presented , one which uses the XLE directly to perform the classification , and another one which uses a decision tree trained on features consisting of the XLE 's output statistics .","label":"CompareOrContrast","metadata":{},"score":"51.748104"}
{"text":"The evaluation showed that PDMM is more effective than PMM .We address the problem of smoothing translation probabilities in a bilingual N - gram - based statistical machine translation system .It is proposed to project the bilingual tuples onto a continuous space and to estimate the translation probabilities in this representation .","label":"CompareOrContrast","metadata":{},"score":"51.88719"}
{"text":"In task ( 1 ) , cross - lingual measures are superior to conventional monolingual measures based on a wordnet .In task ( 2 ) , cross - lingual measures are able to solve more problems correctly , and despite scores being affected by many tied answers , their overall performance is again better than the best monolingual measures .","label":"CompareOrContrast","metadata":{},"score":"52.039604"}
{"text":"The interesting observations might inspire further investigations .Active learning is a promising way to solve the knowledge bottleneck problem faced by supervised word sense disambiguation ( WSD ) methods .Unfortunately , in real - world data , the distribution of the senses of a word is often skewed , which causes a problem for learning methods for WSD .","label":"CompareOrContrast","metadata":{},"score":"52.091118"}
{"text":"The algorithm is given in Table 1 .To obtain the Viterbi alignments , whi ... . \" ...We introduce a novel Bayesian approach for deciphering complex substitution ciphers .Our method uses a decipherment model which combines information from letter n - gram language models as well as word dictionaries .","label":"CompareOrContrast","metadata":{},"score":"52.194443"}
{"text":"To characterise the arguments in a given grammatical relationship we experiment with three models of selectional preference .Two use WordNet and one uses the entries from a distributional thesaurus as classes for representation .In previous work on selectional preference acquisition , the classes used for representation are selected according to the coverage of argument tokens rather than being selected according to the coverage of argument types .","label":"CompareOrContrast","metadata":{},"score":"52.207523"}
{"text":"We present a new multilingual statistical MT word alignment model based on a simple extension of the IBM and HMM Models and a two - step alignment procedure .Preliminary results on a small hand - aligned subset of the Europarl corpus show a 7 % relative improvement over a state of the art alignment model .","label":"CompareOrContrast","metadata":{},"score":"52.449894"}
{"text":"Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions .Tools . \" ...Statistical machine translation ( SMT ) treats the translation of natural language as a machine learning problem .By examining many samples of human - produced translation , SMT algorithms automatically learn how to translate .","label":"CompareOrContrast","metadata":{},"score":"52.4503"}
{"text":"Finally , we investigate when to stop active learning , and adopt two strategies , max - confidence and min - error , as stopping conditions for active learning .According to experimental results , we suggest a prediction solution by considering max - confidence as the upper bound and min - error as the lower bound of stopping conditions .","label":"CompareOrContrast","metadata":{},"score":"52.45034"}
{"text":"The results were achieved by using only information about heads and daughters as features to guide the parser which obeys strict incrementality .A memory - based learner was used to predict the next action of the parser .This paper presents an online algorithm for dependency parsing problems .","label":"CompareOrContrast","metadata":{},"score":"52.49727"}
{"text":"The toolkit supports several state - of - the - art models developed in statistical machine translation , including the phrase - based model , the hierachical phrase - based model , and various syntaxbased models .The key innovation provided by the toolkit is that the decoder can work with various grammars and offers different choices of decoding algrithms , such as phrase - based decoding , decoding as parsing / tree - parsing and forest - based decoding .","label":"CompareOrContrast","metadata":{},"score":"52.540733"}
{"text":"Parser actions are determined by a classifier , based on features that represent the current state of the parser .We apply this parsing framework to both tracks of the CoNLL 2007 shared task , in each case taking advantage of multiple models trained with different learners .","label":"CompareOrContrast","metadata":{},"score":"52.58332"}
{"text":"With the synthetic bilingual corpus , we can build an SMT system even if there is no real bilingual corpus .In our experiments using BLEU as a metric , the system achieves a relative improvement of 11.7 % over the best RBMT system that is used to produce the synthetic bilingual corpora .","label":"CompareOrContrast","metadata":{},"score":"52.592335"}
{"text":"During label prediction , the system automatically selects for each feature an appropriate level of smoothing .We report on several experiments that we conducted with our system .In the shared task evaluation , it scored better than average .We present Pro3Gres , a deep - syntactic , fast dependency parser that combines a hand - written competence grammar with probabilistic performance disambiguation and that has been used in the biomedical domain .","label":"CompareOrContrast","metadata":{},"score":"52.59721"}
{"text":"In a community question - answering setting , a good question is not just one that is found to be use - ful by other people : a question is good if it is also pre - sented clearly and shows prior research .","label":"CompareOrContrast","metadata":{},"score":"52.694736"}
{"text":"We could have potentially used these approaches to retrieve counts for our task , however , there are properties of our problem that will allow us to use significantly less memory than , e.g. , the comp ... . by Tong Xiao , Jingbo Zhu , Hao Zhang , Qiang Li - Jeju , Republic of Korea , 2012 . \" ...","label":"CompareOrContrast","metadata":{},"score":"52.807304"}
{"text":"Using only Lf - Lp and Lp - Le bilingual corpora , we can build a translation model for Lf - Le .The advantage of this method lies in that we can perform translation between Lf and Le even if there is no bilingual corpus available for this language pair .","label":"CompareOrContrast","metadata":{},"score":"52.81703"}
{"text":"Since recent work has shown that minimizing the model size in a Hidden . by Dirk Hovy , Ashish Vaswani , Stephen Tratz , David Chiang , Eduard Hovy . \" ...We present a preliminary study on unsupervised preposition sense disambiguation ( PSD ) , comparing different models and training techniques ( EM , MAP - EM with L0 norm , Bayesian inference using Gibbs sampling ) .","label":"CompareOrContrast","metadata":{},"score":"52.828358"}
{"text":"In order to compensate for the low recall , we used massive collection of HTML documents .Thus , we could prepare enough polar sentence corpus .This paper discusses automatic determination of case in Arabic .This task is a major source of errors in full diacritization of Arabic .","label":"CompareOrContrast","metadata":{},"score":"52.98762"}
{"text":"Tasks that trust the tags completely ( like ASR post - processing ) are more affected by a reduction of the starting dictionary , but still yield positive outcome .Index Terms : part - of - speech tagging , semi - supervised training , bayesian methods . .","label":"CompareOrContrast","metadata":{},"score":"52.989723"}
{"text":"There has been a long history in combinatorial optimization of methods that exploit structure in complex problems , using methods such as dual decomposition or Lagrangian relaxation ( Lemarchal , 200 ... . \" ...We formulate the problem of nonprojective dependency parsing as a polynomial - sized integer linear program .","label":"CompareOrContrast","metadata":{},"score":"53.017994"}
{"text":"This paper presents the task definition , resources , participating systems , and comparative results for the shared task on word alignment , which was organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts .The shared task included English -- Inuktitut , Romanian -- English , ... \" .","label":"CompareOrContrast","metadata":{},"score":"53.05294"}
{"text":"The shared task included English -- Inuktitut , Romanian -- English , and English -- Hindi sub - tasks , and drew the participation of ten teams from around the world with a total of 50 systems . \" ...This paper proposes a novel method for phrase - based statistical machine translation by using pivot language .","label":"CompareOrContrast","metadata":{},"score":"53.09613"}
{"text":"The main . \" ...Dependency cohesion refers to the observation that phrases dominated by disjoint dependency subtrees in the source language generally do not overlap in the target language .It has been verified to be a useful constraint for word alignment .","label":"CompareOrContrast","metadata":{},"score":"53.131367"}
{"text":"We focus on parsing algorithms for nonprojective head automata , a generalization of head - automata models to non - projective structures .The dual decomposition algorithms are simple and efficient , relying on standa ... \" .This paper introduces algorithms for nonprojective parsing based on dual decomposition .","label":"CompareOrContrast","metadata":{},"score":"53.145744"}
{"text":"However , parsing accuracies for Arabic usually lag behind non - semitic languages .Moreover , whil ...Tools . \" ...We examine models for unsupervised learning with concave log - likelihood functions .We begin with the most well - known example , IBM Model 1 for word alignment ( Brown et al . , 1993 ) , and study its properties , discussing why other models for unsupervised learning are so seldom concave .","label":"CompareOrContrast","metadata":{},"score":"53.415703"}
{"text":"Nada therefore operates as a fast , stand - alone system .Nada also improves over previous web - scale systems by considering the entire sentence , rather than narrow context windows , via long - distance lexical features .Nada very substantially outperforms other state - of - the - art systems in nonreferential detection accuracy . ...","label":"CompareOrContrast","metadata":{},"score":"53.47634"}
{"text":"We investigate methods to improve the recall in coreference resolution by also trying to resolve those definite descriptions where no earlier mention of the referent shares the same lexical head ( coreferent bridging ) .The problem , which is notably harder than identifying coreference relations among mentions which have the same lexical head , has been tackled with several rather different approaches , and we attempt to provide a meaningful classification along with a quantitative comparison .","label":"CompareOrContrast","metadata":{},"score":"53.605843"}
{"text":"Textual records of business - oriented conversations between customers and agents need to be analyzed properly to acquire useful business insights that improve productivity .For such an analysis , it is critical to identify appropriate textual segments and expressions to focus on , especially when the textual data consists of complete transcripts , which are often lengthy and redundant .","label":"CompareOrContrast","metadata":{},"score":"53.651546"}
{"text":"This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .We describe a hierarchy of loss functions that incorporate different levels of l ... \" .We present Minimum Bayes - Risk ( MBR ) decoding for statistical machine translation .","label":"CompareOrContrast","metadata":{},"score":"53.68141"}
{"text":"We found that our method could benefit from the two - preprocessing stages .To speed up training , in this year , we employ the MFN - SVM ( modified finite - Newton method support vector machines ) which can be learned in linear time .","label":"CompareOrContrast","metadata":{},"score":"53.747406"}
{"text":"Three different classifiers are trained to predict weighted soft - constraints on parts of the complex output .From these constraints , a standard weighted constraint satisfaction problem can be formed , the solution to which is a valid dependency tree .","label":"CompareOrContrast","metadata":{},"score":"53.846245"}
{"text":"Trained on billions of words , and consisting of billions of parameters , language models often are the single largest components of these systems .There have been many proposed techniques to reduce the sto ... \" .Language models are important components of speech recognition and machine translation systems .","label":"CompareOrContrast","metadata":{},"score":"53.97467"}
{"text":"Trained on billions of words , and consisting of billions of parameters , language models often are the single largest components of these systems .There have been many proposed techniques to reduce the sto ... \" .Language models are important components of speech recognition and machine translation systems .","label":"CompareOrContrast","metadata":{},"score":"53.97467"}
{"text":"The IBM translation models have been hugely influential in statistical machine translation ; they are the basis of the alignment models used in modern translation systems .Excluding IBM Model 1 , the IBM translation models , and practically all variants proposed in the literature , have relied on the optimization of likelihood functions or similar functions that are non - convex , and hence have multiple local optima .","label":"CompareOrContrast","metadata":{},"score":"54.121826"}
{"text":"HashTBO made it possible to ship a trigram contextual speller in Microsoft Office 2007 .In morphologically rich languages , should morphological and syntactic disambiguation be treated sequentially or as a single problem ?We describe several efficient , probabilistically - interpretable ways to apply joint inference to morphological and syntactic disambiguation using lattice parsing .","label":"CompareOrContrast","metadata":{},"score":"54.233376"}
{"text":"As auxiliary results , we also compare different syntactic parsers and alignment techniques that we tested in the process of developing the decoder .Travatar is available under the LGPL at . \" ...We present a simple and novel classifier - based preordering approach .","label":"CompareOrContrast","metadata":{},"score":"54.238052"}
{"text":"Compared with the widelyused SRILM , our PROBING model is 2.4 times as fast while using 57 % of the memory .The TRIE data structure is a trie with bit - level packing , sorted records , interpolation search , and optional quantization aimed at lower memory consumption .","label":"CompareOrContrast","metadata":{},"score":"54.32713"}
{"text":"Our proposal takes advantage of the one - sided error guarantees of the BF and simple inequalities that hold between related $ n$-gram statistics in order to further reduce the BF storage requirements and the error rate of the derived probabilities .","label":"CompareOrContrast","metadata":{},"score":"54.350513"}
{"text":"We learn our model using a Monte Carlo EM algorithm and present quantitative results validating the model .We present a maximally streamlined approach to learning HMM - based acoustic models for automatic speech recognition .In our approach , an initial monophone , single - Gaussian HMM is iteratively refined using a split - merge EM procedure which makes no assumptions about subphone structure or context - dependent structure and which uses only a single Gaussian per HMM state .","label":"CompareOrContrast","metadata":{},"score":"54.37137"}
{"text":"The beam - search decoder only requires the syntactic processing task to be broken into a sequence of decisions , such that , at each stage in the process , the decoder is able to consider the top - n candidates and generate all possibilities for the next stage .","label":"CompareOrContrast","metadata":{},"score":"54.404205"}
{"text":"The beam - search decoder only requires the syntactic processing task to be broken into a sequence of decisions , such that , at each stage in the process , the decoder is able to consider the top - n candidates and generate all possibilities for the next stage .","label":"CompareOrContrast","metadata":{},"score":"54.404205"}
{"text":"Our overall conclusion is that at least two measures , MI and PE , seem to differentiate MWEs from non - MWEs .We then investigate the influence of the size and quality of different corpora , using the BNC and the Web search engines Google and Yahoo .","label":"CompareOrContrast","metadata":{},"score":"54.57674"}
{"text":"Using a set of one - vs - all Support Vector Machines ( SVMs ) , we evaluate these LTAG - based features .Our experiments show that LTAG - based features can improve SRL accuracy significantly .When compared with the best known set of features that are used in state of the art SRL systems we obtain an improvement in F - score from 82.34 % to 85.25 % .","label":"CompareOrContrast","metadata":{},"score":"54.660088"}
{"text":"Yet , various grammar parameters are expected to be correlated because the elements in language they represent share linguistic properties .In this paper , we suggest an alternative to the Dirichlet prior , a family of logistic normal distributions .We derive an inference algorithm for this family of distributions and experiment with the task of dependency grammar induction , demonstrating performance improvements with our priors on a set of six treebanks in different natural languages .","label":"CompareOrContrast","metadata":{},"score":"54.81732"}
{"text":"Yet , various grammar parameters are expected to be correlated because the elements in language they represent share linguistic properties .In this paper , we suggest an alternative to the Dirichlet prior , a family of logistic normal distributions .We derive an inference algorithm for this family of distributions and experiment with the task of dependency grammar induction , demonstrating performance improvements with our priors on a set of six treebanks in different natural languages .","label":"CompareOrContrast","metadata":{},"score":"54.81732"}
{"text":"Our approach gives the same level of alignment accuracy as IBM Model 2 . ... ang , 2005 ; Marcu et al . , 2006 ) ) .Excluding IBM Model 1 , the IBM translation models , and practically all variants proposed in the literature , have relied on the optimization of likelihoo ... . by Nadi Tomeh , President Anne , Vilnat Universit Paris - sud , Reviewers Eric , Gaussier Universit , Joseph Fourier , Universit Montral , Examinator Hermann , Ney Rwth Aachen , Advisor Franois , Yvon Universit Paris - sud , Co - advisor Alex , Re Allauzen Universit Paris - sud , 2012","label":"CompareOrContrast","metadata":{},"score":"54.87163"}
{"text":"Unknown words are a well - known hindrance to natural language applications .In particular , they drastically impact machine translation quality .An easy way out commercial translation systems usually offer their users is the possibility to add unknown words and their translations into a dedicated lexicon .","label":"CompareOrContrast","metadata":{},"score":"54.893375"}
{"text":"We examine models for unsupervised learning with concave log - likelihood functions .We begin with the most well - known example , IBM Model 1 for word alignment ( Brown et al . , 1993 ) , and study its properties , discussing why other models for unsupervised learning are so seldom concave .","label":"CompareOrContrast","metadata":{},"score":"54.931145"}
{"text":"This robustness led to the third best overall average labeled attachment score in the task , despite using no discriminative methods .We also demonstrate that the parser is quite fast , and can provide even faster parsing times without much loss of accuracy . \" ...","label":"CompareOrContrast","metadata":{},"score":"55.03266"}
{"text":"This robustness led to the third best overall average labeled attachment score in the task , despite using no discriminative methods .We also demonstrate that the parser is quite fast , and can provide even faster parsing times without much loss of accuracy . \" ...","label":"CompareOrContrast","metadata":{},"score":"55.03266"}
{"text":"To predict elec - tion results , we apply SVM - based super - vised learning .To improve performance , we propose a novel technique which generalizes n - gram feature patterns .Experimental results show that Crystal significantly outperforms several baselines as well as a non - generalized n - gram ap - proach .","label":"CompareOrContrast","metadata":{},"score":"55.082684"}
{"text":"The parser is evaluated on the OVIS and WSJ corpora , and shows improvements on efficiency , parse accuracy and testset likelihood .Friday , June 29 , 2007 .A lexical analogy is a pair of word - pairs that share a similar semantic relation .","label":"CompareOrContrast","metadata":{},"score":"55.08773"}
{"text":"In order to incorporate HTML structure on the graph , three types of cliques are defined based on the HTML tree structure .We propose a method with Conditional Random Fields ( CRFs ) to categorize the nodes on the graph .","label":"CompareOrContrast","metadata":{},"score":"55.09836"}
{"text":"Such features can help accuracy - as we show .Hence we seek approximations .We will show how BP 's \" message - passing \" discipline offers a principled way for higher - order features to incrementally adjust the numerical edge weights that are fed to ... . by Terry Koo , Alexander M. Rush , Michael Collins , Tommi Jaakkola , David Sontag - In Proc . of EMNLP , 2010 . \" ...","label":"CompareOrContrast","metadata":{},"score":"55.174263"}
{"text":"Using this model in the pre - ordering framework results in significant gains in translation accuracy over standard phrasebased SMT and previously proposed unsupervised syntax induction methods . ... ing available in the source language .However , as building a parser for each sour ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"55.274155"}
{"text":"To reduce the cost of training data construction , our method accepts training examples in which complete word - by - word alignment labels are missing , but instead only the boundaries of coordinated conjuncts are marked .We report promising empirical results in detecting and disambiguating coordinated noun phrases in the GENIA corpus , despite a relatively small number of training examples and minimal features are employed .","label":"CompareOrContrast","metadata":{},"score":"55.30324"}
{"text":"Decoding algorithms for syntax based machine translation suffer from high computational complexity , a consequence of intersecting a language model with a context free grammar .Left - to - right decoding , which generates the target string in order , can improve decoding efficiency by simplifying the langu ... \" .","label":"CompareOrContrast","metadata":{},"score":"55.361397"}
{"text":"857 In this paper , we address the translation problem fo ... . by Karim Filali , Jeff Bilmes - In IEEE Workshop on Automatic Speech Recognition and Understanding . \" ...We present a new multilingual statistical MT word alignment model based on a simple extension of the IBM and HMM Models and a two - step alignment procedure .","label":"CompareOrContrast","metadata":{},"score":"56.011906"}
{"text":"We perform Bayesian training of a part - of - speech ( POS ) tagger from unannotated text and a dictionary of possible tags for each word .We complement that method with supervised p ... \" .When no training or adaptation data is available , semisupervised training is a good alternative for processing new domains .","label":"CompareOrContrast","metadata":{},"score":"56.11026"}
{"text":"Recognizing polarity requires a list of polar words and phrases .For the purpose of building such lexicon automatically , a lot of studies have investigated ( semi- ) unsupervised method of learning polarity of words and phrases .In this paper , we explore to use structural clues that can extract polar sentences from Japanese HTML documents , and build lexicon from the extracted polar sentences .","label":"CompareOrContrast","metadata":{},"score":"56.17655"}
{"text":"We focus on two important subtasks of opinion extraction : ( a ) extracting aspect - evaluation relations , and ( b ) extracting aspect - of relations , and we approach each task using methods which combine contextual and statistical clues .","label":"CompareOrContrast","metadata":{},"score":"56.63382"}
{"text":"We introduce a new smoothing method , dubbed Stupid Backoff , that is inexpensive to train on large data sets and approaches the quality of Kneser - Ney Smoothing as the amount of training data increases .We present an extension of phrase - based statistical machine translation models that enables the straight - forward integration of additional annotation at the word - level --- may it be linguistic markup or automatically generated word classes .","label":"CompareOrContrast","metadata":{},"score":"56.651627"}
{"text":"There are a number of options for model training , and tuning includes advanced options such as hypergraph MERT , and training of sparse features through online learning .The training pipeline is modeled after that of the popular Moses decoder , so users familiar with Moses should be able to get started quickly .","label":"CompareOrContrast","metadata":{},"score":"56.66848"}
{"text":"In this work , we compare the translation performance of word alignments obtained via Bayesian inference to those obtained via expectation - maximization ( EM ) .We propose a Gibbs sampler for fully Bayesian inference in IBM Model 1 , integrating over all possible parameter values in finding the alignment ... \" .","label":"CompareOrContrast","metadata":{},"score":"56.923332"}
{"text":"In both the English all - words task and the English lexical sample task , the method achieved significant improvement over the simple naive Bayes classifier and higher accuracy than the best offical scores on Senseval-3 for both task .We develop latent Dirichlet allocation with WordNet ( LDAWN ) , an unsupervised probabilistic topic model that includes word sense as a hidden variable .","label":"CompareOrContrast","metadata":{},"score":"56.944336"}
{"text":"This paper reports on the benefits of large - scale statistical language modeling in machine translation .A distributed infrastructure is proposed which we use to train on up to 2 trillion tokens , resulting in language models having up to 300 billion n - grams .","label":"CompareOrContrast","metadata":{},"score":"57.17038"}
{"text":"Evaluation on a list of 500 proper names shows that the method achieves high precision and recall , and outperforms commercial machine translation systems .It has been widely observed that different NLP applications require different sense granularities in order to best exploit word sense distinctions , and that for many applications WordNet senses are too fine - grained .","label":"CompareOrContrast","metadata":{},"score":"57.24637"}
{"text":"The parser first identifies dependencies using a discriminative classifier and then labels those dependencies as a sequence labeling problem .The features for two stages are proposed .For four languages have different values of ROOT , we design some special features for ROOT labeler .","label":"CompareOrContrast","metadata":{},"score":"57.65195"}
{"text":"We participated in the CoNLL Shared Task-2007 and evaluated our system for ten languages .We got an average multilingual labeled attachment score of 74.54 % ( with 65.50 % being the average and 80.32 % the highest ) and an average multilingual unlabeled attachment score of 80.30 % ( with 71.13 % being the average and 86.55 % the highest ) .","label":"CompareOrContrast","metadata":{},"score":"57.868317"}
{"text":"In cdec , the only model - specific logic is confined to the first step in the process where an input string ( or lattice , e .. \" ...Via an oracle experiment , we show that the upper bound on accuracy of a CCG parser is significantly lowered when its search space is pruned using a supertagger , though the supertagger also prunes many bad parses .","label":"CompareOrContrast","metadata":{},"score":"57.885696"}
{"text":"In text categorization , term selection is an important step for the sake of both categorization accuracy and computational efficiency .Different dimensionalities are expected under different practical resource restrictions of time or space .Traditionally in text categorization , the same scoring or ranking criterion is adopted for all target dimensionalities , which considers both the discriminability and the coverage of a term , such as $ \\chi^2 $ or IG .","label":"CompareOrContrast","metadata":{},"score":"58.00911"}
{"text":"These methods are attractive for their ability to manage uncertainty about model parameters and allow o .. \" ...The Minimum Description Length ( MDL ) principle is a method for model selection that trades off between the explanation of the data by the model and the complexity of the model itself .","label":"CompareOrContrast","metadata":{},"score":"58.059074"}
{"text":"We were able to accept 66 papers to be presented as full talks , and 43 papers to be presented as leisurely posters .All 109 final papers were allowed 9 pages plus bibliography .In a separate track , 22 specially designated short papers reported results in the CoNLL Shared Task competition , an annual tradition .","label":"CompareOrContrast","metadata":{},"score":"58.12851"}
{"text":"We present two techniques for training the MST parser : tree - normalized and graph - normalized conditional training .We describe the reranker features which include non - projective edge attributes .We provide an analysis of the errors made by our system and suggest changes to the models and features that might rectify the current system .","label":"CompareOrContrast","metadata":{},"score":"58.142746"}
{"text":"In deterministic approaches to this task , dependency trees are constructed by series of actions of attaching a bunsetsu chunk to one of the nodes in the tree being constructed .Conventional techniques select the node based on whether the new bunsetsu chunk and each node in the trees are in a parent - child relation or not .","label":"CompareOrContrast","metadata":{},"score":"58.176407"}
{"text":"Dependency cohesion refers to the observation that phrases dominated by disjoint dependency subtrees in the source language generally do not overlap in the target language .It has been verified to be a useful constraint for word alignment .However , previous work either treats this as a hard constraint or uses it as a feature in discriminative models , which is ineffective for large - scale tasks .","label":"CompareOrContrast","metadata":{},"score":"58.18573"}
{"text":"The second extension is to apply the approach to secondorder parsing models , such as those described in ( Carreras , 2007 ) , using a twostage semi - supervised learning approach .We demonstrate the effectiveness of our proposed methods on dependency parsing experiments using two widely used test collections : the Penn Treebank for English , and the Prague Dependency Treebank . \" ...","label":"CompareOrContrast","metadata":{},"score":"58.21897"}
{"text":"DeSR implements an incremental deterministic Shift / Reduce parsing algorithm , using specific rules to handle non - projective dependencies .For the multilingual track we adopted a second order averaged perceptron and performed feature selection to tune a feature model for each language .","label":"CompareOrContrast","metadata":{},"score":"58.275"}
{"text":"In the multilingual exercise of the CoNLL-2007 shared task ( Nivre et al.,2007 ) , our system obtains the best accuracy for English , and the second best accuracies for Basque and Czech .We present our system used in the CoNLL 2007 shared task on multilingual parsing .","label":"CompareOrContrast","metadata":{},"score":"58.295677"}
{"text":"Inclusions from other languages can be a significant source of errors for monolingual parsers .We show this for English inclusions , which are sufficiently frequent to present a problem when parsing German .We describe an annotation - free approach for accurately detecting such inclusions , and develop two methods for interfacing this approach with a state - of - the - art parser for German .","label":"CompareOrContrast","metadata":{},"score":"58.407402"}
{"text":"This motivates a Bayesian approach using a sparse prior to bias the estimator toward such a skewed distribution .We investigate Gibbs Sampling ( GS ) and Variational Bayes ( VB ) estimators and show that VB converges faster than GS for this task and that VB significantly improves 1-to-1 tagging accuracy over EM .","label":"CompareOrContrast","metadata":{},"score":"58.440636"}
{"text":"The new method can be applied on more complex substitution ciphers and we demonstrate its utility by cracking the famous Zodiac-408 cipher in a fully automated fashion , which has never been done before . ... ubstitution ciphers .Snyder et al .","label":"CompareOrContrast","metadata":{},"score":"58.466156"}
{"text":"We present an evaluation measure that takes into account the possibility of incompatible token segmentation between the gold standard and the parsed data .Results indicate that ( a ) MST - parser performs better on Hebrew data than Malt - Parser , and ( b ) both parsers do not make good use of morphological information when parsing Hebrew . ... s on Hebrew dependency parsing .","label":"CompareOrContrast","metadata":{},"score":"58.563457"}
{"text":"We present an evaluation measure that takes into account the possibility of incompatible token segmentation between the gold standard and the parsed data .Results indicate that ( a ) MST - parser performs better on Hebrew data than Malt - Parser , and ( b ) both parsers do not make good use of morphological information when parsing Hebrew . ... s on Hebrew dependency parsing .","label":"CompareOrContrast","metadata":{},"score":"58.563457"}
{"text":"Their ability to automatically induce features results in multilingual parsing which is robust enough to achieve accuracy well above the average for each individual language in the multilingual track of the CoNLL-2007 shared task .This robustness led to the third best overall average labeled attachment score in the task , despite using no discriminative methods .","label":"CompareOrContrast","metadata":{},"score":"58.74536"}
{"text":"The past 20 years of work on human language learning has highlighted infants ' extreme sensitivity to input statistics , including frequency of particular phonemes and sequences , distributions of acoustic tokens of phoneme types , and transitional probabilities between adjacent and non - adjacent syllables .","label":"CompareOrContrast","metadata":{},"score":"58.990494"}
{"text":"Part of speech tagging is a fundamental component in many NLP systems .When taggers developed in one domain are used in another domain , the performance can degrade considerably .We present a method for developing taggers for new domains without requiring POS annotated text in the new domain .","label":"CompareOrContrast","metadata":{},"score":"59.164726"}
{"text":"The results of the experiments show that , contrary to Kbler et al .( 2006 ) , the question whether or not German is harder to parse than English remains undecided .In this paper , we study the problem of automatically segmenting written text into paragraphs .","label":"CompareOrContrast","metadata":{},"score":"59.394745"}
{"text":"most languages are projective .In Figure 8 An example Chinese dependency tree .Although non - projec ... . \" ...Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .","label":"CompareOrContrast","metadata":{},"score":"59.503338"}
{"text":"most languages are projective .In Figure 8 An example Chinese dependency tree .Although non - projec ... . \" ...Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .","label":"CompareOrContrast","metadata":{},"score":"59.503338"}
{"text":"To globally model parsing actions of all steps that are taken on the inpu ... \" .Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .They only determine parsing actions stepwisely by a trained classifier .","label":"CompareOrContrast","metadata":{},"score":"59.644264"}
{"text":"To globally model parsing actions of all steps that are taken on the inpu ... \" .Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .They only determine parsing actions stepwisely by a trained classifier .","label":"CompareOrContrast","metadata":{},"score":"59.644264"}
{"text":"We present extensive experiments on 22 language pairs , including preordering into English from 7 other languages .We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task .For languages from different families the improvements often exceed 2 BLEU .","label":"CompareOrContrast","metadata":{},"score":"59.64437"}
{"text":"We propose a new algorithm for approximate MAP inference on factor graphs , by combining augmented Lagrangian optimization with the dual decomposition method .Each slave subproblem is given a quadratic penalty , which pushes toward faster consensus than in previous subgradient approaches .","label":"CompareOrContrast","metadata":{},"score":"59.6625"}
{"text":"We propose a new algorithm for approximate MAP inference on factor graphs , by combining augmented Lagrangian optimization with the dual decomposition method .Each slave subproblem is given a quadratic penalty , which pushes toward faster consensus than in previous subgradient approaches .","label":"CompareOrContrast","metadata":{},"score":"59.6625"}
{"text":"Unfortunately , this procedure suffers from severe numerical problems in the low - temperature setting , which prevents its use in DD - Acc where the temperature must be set as O(/(n log n ) ) .Finally , n ..Tools . by Kenneth Heafield - In Proc . of the Sixth Workshop on Statistical Machine Translation , 2011 . \" ...","label":"CompareOrContrast","metadata":{},"score":"59.907692"}
{"text":"They also permit the use of well - understood , generalpurpose learning algorithms .There has been an increased interest in using probabilistic grammars in the Bayesian setting .To date , most of the literature has focused on using a Dirichlet prior .","label":"CompareOrContrast","metadata":{},"score":"59.908554"}
{"text":"They also permit the use of well - understood , generalpurpose learning algorithms .There has been an increased interest in using probabilistic grammars in the Bayesian setting .To date , most of the literature has focused on using a Dirichlet prior .","label":"CompareOrContrast","metadata":{},"score":"59.908554"}
{"text":"3.3 N - gram Language Modeling The toolkit includes a simple but effective n - gram language model ( LM ) .To reduce the size of resulting language model , low - frequency n - grams ... . \" ...We introduce a reinforcement learning - based approach to simultaneous ma - chine translation - producing a trans - lation while receiving input words- between languages with drastically dif - ferent word orders : from verb - final lan - guages ( e.g. , German ) to verb - medial languages ( English ) .","label":"CompareOrContrast","metadata":{},"score":"60.035725"}
{"text":"E ... \" .We formulate dependency parsing as a graphical model with the novel ingredient of global constraints .We show how to apply loopy belief propagation ( BP ) , a simple and effective tool for approximate learning and inference .","label":"CompareOrContrast","metadata":{},"score":"60.101875"}
{"text":"We propose a Gibbs sampler for fully Bayesian inference in IBM Model 1 , integrating over all possible parameter values in finding the alignment distribution .We show that Bayesian inference outperforms EM in all of the tested language pairs , domains and data set sizes , by up to 2.99 BLEU points .","label":"CompareOrContrast","metadata":{},"score":"60.276505"}
{"text":"Its space requirements fall significantly below lossless information - theoretic lower bounds but it produces false positives with some quantifiable probability .Here we present a general framework for deriving smoothed language model probabilities from BFs .We investigate how a BF containing n -gram statistics can be used as a direct replacement for a conventional n -gram model .","label":"CompareOrContrast","metadata":{},"score":"60.276527"}
{"text":"We estimate the parameters of our model by collecting counts from automatically parsed text using standard n - gram language model estimation techniques , allowing us to train a model on over one billion tokens of data using a single machine in a matter of hours .","label":"CompareOrContrast","metadata":{},"score":"60.467133"}
{"text":"Smoothing probabilities is most important for tasks with a limited amount of training material .We consider here the Btec task of the 2006 Iwslt evaluation .Improvements in all official automatic measures are reported when translating from Italian to English .","label":"CompareOrContrast","metadata":{},"score":"60.758728"}
{"text":"The reordering approach improved the BLEU score for the MOSES system from 28.52 to 30.86 on the NIST 2006 evaluation data .We also conducted a series of experiments to analyze the accuracy and impact of different types of reordering rules .","label":"CompareOrContrast","metadata":{},"score":"60.8478"}
{"text":"The savings can be quite substantial ( up to 90 % ) and cause no reduction in BLEU score .In some cases , an improvement in BLEU is obtained at the same time although the effect is less pronounced if state - of - the - art phrasetable smoothing is employed .","label":"CompareOrContrast","metadata":{},"score":"61.22979"}
{"text":"Scalable term selection is proposed to optimize the term set at a given dimensionality according to an expected average vector length .Discriminability and coverage are separately measured ; by adjusting the ratio of their weights in a combined criterion , the expected average vector length can be reached , which means a good compromise between the specificity and the exhaustivity of the term subset .","label":"CompareOrContrast","metadata":{},"score":"61.431133"}
{"text":"The parameterization of SCFG models follows a similar pattern of diversity .2.4.2 Discriminative Models Generative models are useful i .. \" ...We formulate dependency parsing as a graphical model with the novel ingredient of global constraints .We show how to apply loopy belief propagation ( BP ) , a simple and effective tool for approximate learning and inference .","label":"CompareOrContrast","metadata":{},"score":"61.48506"}
{"text":"Tags from Present Day English source text are projected to Middle English text using alignments on parallel Biblical text .We explore the use of multiple alignment approaches and a bigram tagger to reduce the noise in the projected tags .Finally , we train a maximum entropy tagger on the output of the bigram tagger on the target Biblical text and test it on tagged Middle English text .","label":"CompareOrContrast","metadata":{},"score":"61.49643"}
{"text":"We compare V - measure to a number of popular cluster evaluation measures and demonstrate that it satisfies several desirable properties of clustering solutions , using simulated clustering results .Finally , we use V - measure to evaluate two clustering tasks : document clustering and pitch accent type clustering .","label":"CompareOrContrast","metadata":{},"score":"62.923965"}
{"text":".. provides an excellent introduction .Language model compression and storage is an entire subgenre in itself .A typical format that is used for static finite state acceptors in OpenFst [ 7 ] is illustrated in Figure 1 .This format makes c .. Tools . \" ...","label":"CompareOrContrast","metadata":{},"score":"63.01993"}
{"text":"While parsing algorithms can be used to parse partial translations in phrase - based decoding , the se ... .Despite these successful efforts , challenges still remain for both directions .While parsing algorithms can be used to parse partial translations in phrase - based decoding , the se ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"63.175236"}
{"text":"The results show that all three systems achieve competitive performance , with a best labeled attachment score over 88 % .All three parsers benefit from the use of automatically derived lemmas , while morphological features seem to be less important .","label":"CompareOrContrast","metadata":{},"score":"63.176426"}
{"text":"The results show that all three systems achieve competitive performance , with a best labeled attachment score over 88 % .All three parsers benefit from the use of automatically derived lemmas , while morphological features seem to be less important .","label":"CompareOrContrast","metadata":{},"score":"63.176426"}
{"text":"On CCGbank we achieve a labelled dependency F - measure of 88.8 % on gold POS tags , and 86.7 % on automatic part - of - speeoch tags , the best reported results for this task . ... of combining models to avoid the pipeline problem ( Felzenszwalb and McAllester , 2007 ) is very much in line with much recent work in NLP . \" ...","label":"CompareOrContrast","metadata":{},"score":"63.31293"}
{"text":"The estimated domain ( sub - corpus ) specific language and translation models are used for the translation .The IWSLT05 Japanese to English evaluation set that we used in our experiments gave 2.7 points ( 52.4 to 55.1 ) higher Blue score using this method .","label":"CompareOrContrast","metadata":{},"score":"63.370544"}
{"text":"We also present an analysis of what is and is not learned by our system .This paper describes ETK ( Ensemble of Transformation based Keys ) a new algorithm for inducing search keys for name filtering .ETK has the low computational cost and ability to filter by phonetic similarity characteristic of phonetic keys such as Soundex , but is adaptable to alternative similarity models .","label":"CompareOrContrast","metadata":{},"score":"63.3897"}
{"text":"Like recent state - of - the - art approaches , Nada uses very large - scale web N - gram features , but Nada makes these features practical by compressing the N- ... \" .Nada is a novel , publicly - available program that accurately distinguishes between the referential and non - referential pronoun it in raw English text .","label":"CompareOrContrast","metadata":{},"score":"63.813858"}
{"text":"The technology of opinion extraction allows users to retrieve and analyze people 's opinions scattered over Web documents .We define an opinion unit as a quadruple consisting of the opinion holder , the subject being evaluated , the part or the attribute in which it is evaluated , and the value of the evaluation that expresses a positive or negative assessment .","label":"CompareOrContrast","metadata":{},"score":"64.053986"}
{"text":"Even with second - order features or latent variables , which would make exact parsing considerably slower or NP - hard , BP needs only O(n3 ) time with a small constant factor .Furthermore , such features significantly improve parse accuracy over exact first - order methods .","label":"CompareOrContrast","metadata":{},"score":"64.328285"}
{"text":"The type - based models perform better than the models which use tokens for selecting the classes .Furthermore , the models which use the automatically acquired thesaurus entries produced the best results .The correlation for the thesaurus models is stronger than any of the individual features used in previous research on the same dataset .","label":"CompareOrContrast","metadata":{},"score":"64.50235"}
{"text":"We present a preliminary study on unsupervised preposition sense disambiguation ( PSD ) , comparing different models and training techniques ( EM , MAP - EM with L0 norm , Bayesian inference using Gibbs sampling ) .To our knowledge , this is the first attempt at unsupervised preposition sense disambiguation . \" ...","label":"CompareOrContrast","metadata":{},"score":"64.65216"}
{"text":"Akamon implements all of the algorithms required for tree / forestto - string decoding using tree - to - string translation rules : multiple - thread forest - based decoding , n - gram language model integration , beam- and cube - pruning , k - best hypotheses extraction , and minimum error rate training .","label":"CompareOrContrast","metadata":{},"score":"64.91534"}
{"text":"Given a prediction message , Crystal first identifies which party the message predicts to win and then aggregates prediction analysis results of a large amount of opinions to project the election results .We collect past election prediction messages from the Web and automatically build a gold standard .","label":"CompareOrContrast","metadata":{},"score":"65.13195"}
{"text":"Asking the right question in the right way is an art ( and a science ) .In a community question - answering setting , a good question is not just one that is found to be use - ful by other people : a question is good if it is also pre - sented clearly and shows prior research .","label":"CompareOrContrast","metadata":{},"score":"65.15874"}
{"text":"Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .They only determine parsing actions stepwisely by a trained classifier .To globally model parsing actions of all steps that are taken on the input sentence , we propose two kinds of probabilistic parsing action models that can compute the probability of the whole dependency tree .","label":"CompareOrContrast","metadata":{},"score":"65.16231"}
{"text":"The interpolated model achieves an absolute improvement of 0.0245 BLEU score ( 13.1 % relative ) as compared with the individual model trained on the real bilingual corpus .This paper investigates why the HMMs estimated by Expectation - Maximization ( EM ) produce such poor results as Part - of - Speech ( POS ) taggers .","label":"CompareOrContrast","metadata":{},"score":"65.60179"}
{"text":"The PROBING data structure uses linear probing hash tables and is designed for speed .Compared with the widelyused SRILM , our PROBING model is 2.4 times as fast ... \" .We present KenLM , a library that implements two data structures for efficient language model queries , reducing both time and memory costs .","label":"CompareOrContrast","metadata":{},"score":"66.012085"}
{"text":".. provides an excellent introduction .Language model compression and storage is an entire subgenre in itself .A typical format that is used for static finite state acceptors in OpenFst [ 7 ] is illustrated in Figure 1 .This format makes c .. \" ...","label":"CompareOrContrast","metadata":{},"score":"66.05366"}
{"text":"A careful error analysis suggests that when we account for annotation errors in the gold standard , the error rate drops to 0.9 % , with the hand - written rules outperforming the machine learning - based system .We present in this paper methods to improve HMM - based part - of - speech ( POS ) tagging of Mandarin .","label":"CompareOrContrast","metadata":{},"score":"66.247116"}
{"text":"As a test , we used MavenRank to identify the most influential members of the US Senate using data from the US Congressional Record and used committee ranking to evaluate the output .Our results show that MavenRank scores are largely driven by committee status in most topics , but can capture speaker centrality in topics where speeches are used to indicate ideological position instead of influence legislation .","label":"CompareOrContrast","metadata":{},"score":"67.04202"}
{"text":"This paper presents a method for categorizing named entities in Wikipedia .In Wikipedia , an anchor text is glossed in a linked HTML text .We formalize named entity categorization as a task of categorizing anchor texts with linked HTML texts which glosses a named entity .","label":"CompareOrContrast","metadata":{},"score":"68.69333"}
{"text":"The Minimum Description Length ( MDL ) principle is a method for model selection that trades off between the explanation of the data by the model and the complexity of the model itself .Inspired by the MDL principle , we develop an objective function for generative models that captures the description of the data by the model ( log - likelihood ) and the description of the model ( model size ) .","label":"CompareOrContrast","metadata":{},"score":"71.41519"}
{"text":"Trigram language models are compessed using a Golomb coding method inspired by the original Unix spell program .Compression methods trade off space , time and accuracy ( loss ) .The proposed HashTBO method optimizes space at the expense of time and accuracy .","label":"CompareOrContrast","metadata":{},"score":"71.78923"}
{"text":"Query segmentation is the process of taking a user 's search - engine query and dividing the tokens into individual phrases or semantic units .Identification of these query segments can potentially improve both document retrieval precision , by first returning pages which contain the exact query segments , and document retrieval recall , by allowing query expansion or substitution via the segmented units .","label":"CompareOrContrast","metadata":{},"score":"72.990295"}
{"text":"For Lf - Lp and Lp - Le , there exist large bi ... \" .This paper proposes a novel method for phrase - based statistical machine translation by using pivot language .To conduct translation between languages Lf and Le with a small bilingual corpus , we bring in a third language Lp , which is named the pivot language .","label":"CompareOrContrast","metadata":{},"score":"74.4491"}
{"text":"These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation .Therefore , the standard evaluation does not provide a true indication of algorithm quality .We present a new measure , Neutral Edge Direction ( NED ) , and show that it greatly reduces this undesired phenomenon .","label":"CompareOrContrast","metadata":{},"score":"75.09656"}
{"text":"These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation .Therefore , the standard evaluation does not provide a true indication of algorithm quality .We present a new measure , Neutral Edge Direction ( NED ) , and show that it greatly reduces this undesired phenomenon .","label":"CompareOrContrast","metadata":{},"score":"75.09656"}
{"text":"Additionally , we compare the maximum a - posteriori decision rule and the minimum Bayes risk decision rule .We show that not only from a theoretical point but also in terms of translation quality the minimum Bayes risk decision rule is preferable .","label":"CompareOrContrast","metadata":{},"score":"75.87931"}
{"text":"The dual decomposition algorithms are simple and efficient , relying on standard dynamic programming and minimum spanning tree algorithms .They provably solve an LP relaxation of the non - projective parsing problem .Empirically the LP relaxation is very often tight : for many languages , exact solutions are achieved on over 98 % of test sentences .","label":"CompareOrContrast","metadata":{},"score":"75.98328"}
{"text":"PDMM is an expansion of an existing probabilistic generative model : Parametric Mixture Model(PMM ) by hierarchical Bayes model .PMM models multiple - topic documents by mixing model parameters of each single topic with an equal mixture ratio .PDMM models multiple - topic documents by mixing model parameters of each single topic with mixture ratio following Dirichlet distribution .","label":"CompareOrContrast","metadata":{},"score":"76.80707"}
{"text":"Saturday , June 30 , 2007 .In the last decade , there have been significant developments in the design of approximate randomized algorithms for high - dimensional data .These include : hashing - based algorithms for similarity search problems , computing succinct approximate \" sketches \" of high - dimensional objects , etc .","label":"CompareOrContrast","metadata":{},"score":"79.10185"}
{"text":"For instance , 14.4 % of section 23 is tagged differently by ( 1 ) and ( 2 ) 8 .5 The Neutral Edge Direction ( NED ) Me ... . by Shay B. Cohen , Noah A. Smith , Alex Clark , Dorota Glowacka , Colin De La Higuera , Mark Johnson , John Shawe - taylor . \" ...","label":"CompareOrContrast","metadata":{},"score":"80.65309"}
{"text":"For instance , 14.4 % of section 23 is tagged differently by ( 1 ) and ( 2 ) 8 .5 The Neutral Edge Direction ( NED ) Me ... . by Shay B. Cohen , Noah A. Smith , Alex Clark , Dorota Glowacka , Colin De La Higuera , Mark Johnson , John Shawe - taylor . \" ...","label":"CompareOrContrast","metadata":{},"score":"80.65309"}
