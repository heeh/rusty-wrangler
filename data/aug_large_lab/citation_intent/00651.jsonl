{"text":"Solving these problems will be of great utility in dealing with both the broadcast news problem and more general transcription of ' ' found ' ' speech .That system was constructed using HMMs trained on the Wall Street Journal ( WSJ ) corpus as a base and then adapted to individual data types of broadcast news data using supervised maximum likelihood linear regression ( MLLR )","label":"CompareOrContrast","metadata":{},"score":"37.954422"}
{"text":"That system was constructed using HMMs trained on the Wall Street Journal ( WSJ ) corpus as a base and then adapted to individual data types of broadcast news data using supervised maximum likelihood linear regression ( MLLR ) [ 7 , 6 , 3 ] .","label":"CompareOrContrast","metadata":{},"score":"40.577965"}
{"text":"The transcription of broadcast radio and television news poses a number of challenges for large vocabulary transcription systems .The data in broadcasts is not homogeneous and includes a number of data types for which speech recognition systems trained on read speech corpora such as the WSJ corpus have high error rates .","label":"CompareOrContrast","metadata":{},"score":"41.086296"}
{"text":"If some method of increasing retrieval performance despite these errors could be found , then even low - accuracy automatically generated transcriptions could be used as part of a successful spoken document retrieval ( SDR ) system .This paper presents results using four query expansion techniques described in [ 3 ] on 8 different sets of transcriptions generated for the 1997 TREC-7 SDR evaluation .","label":"CompareOrContrast","metadata":{},"score":"41.638557"}
{"text":"We therefore did not include FD modelling in the 1998 evaluation system .The soft - clustering technique developed at JHU [ 9 ] had shown worthwhile reductions in word error rate on the Switchboard corpus and we performed a preliminary evaluation on Broadcast News data .","label":"CompareOrContrast","metadata":{},"score":"41.849472"}
{"text":"The search used a single pass decoder with MLLR based adaptation technique .Although on the standard DARPA 20k WSJ task our system obtained 11.6 % word error , the 39 % error on this year 's evaluation suggests there are still many aspects need to be learned for a new comer like us .","label":"CompareOrContrast","metadata":{},"score":"42.35717"}
{"text":"However there is still much interest in reducing the error rate of such systems further which will increase the potential for further applications as well as establishing techniques for the accurate transcription of general audio material .The HTK Broadcast News Transcription System used in the 1997 DARPA / NIST Hub4 evaluation had an overall word error rate of 15.8 % .","label":"CompareOrContrast","metadata":{},"score":"44.28424"}
{"text":"The word error rate on BNeval97 of 14.3 % ( including FV and SAT ) represents a 13 % reduction relative to the same stage of the 1997 evaluation system [ 16 ] .We have recently experimented with discriminative training of large vocabulary systems and using the frame discrimination ( FD ) technique [ 13 ] .","label":"CompareOrContrast","metadata":{},"score":"44.63481"}
{"text":"This 25K - word vocabulary system used continuous HMMs for acoustic modeling and the standard backo ... \" .This paper presents the CSLU Broadcast News transcription system used in the DARPA 1997 evaluation .The system was built using the softwares developed for the CSLU LVCSR project started in January 1997 .","label":"CompareOrContrast","metadata":{},"score":"45.1209"}
{"text":"Most of the above papers reporting on the use of ML for WSD follow a similar pattern .A set of ambiguous words is selected , a corpus for each word is collected , and the different senses within the corpus are annotated ( automatically or manually ) .","label":"CompareOrContrast","metadata":{},"score":"45.45752"}
{"text":"The system takes the 1997 system and includes the additional acoustic training data in BNtrain98 ; cluster - based normalisation and VTLN ; the revised language modelling data and build procedure and full variance adaptation with SAT training .The word N - grams were trained by interpolating ( and merging ) component LMs trained on the acoustic transcriptions , the broadcast news texts and the newspaper texts .","label":"CompareOrContrast","metadata":{},"score":"45.967865"}
{"text":"This poorer performance was also reflected in the number of frames assigned to multiple speaker segments : 1.6 % for BNeval97 but 4.3 % for BNeval98 .This paper has described the development and performance of the 1998 HTK broadcast news transcription system .","label":"CompareOrContrast","metadata":{},"score":"46.649822"}
{"text":"We subsequently based our assessment of performance on error rates and associated standard errors .Our method also differs from related work because the sample size for each sense is always fixed , whereas in related work the sample size for the entire corpus is generally fixed but not the sample sizes of the senses .","label":"CompareOrContrast","metadata":{},"score":"47.51703"}
{"text":"The system uses the LIMSI 1993 WSJ pronunciation dictionary augmented by pronunciations from a TTS system and hand generated corrections .Cross - word context dependent decision tree state clustered mixture Gaussian HMMs [ 16 ] are used with a 65k word vocabulary .","label":"CompareOrContrast","metadata":{},"score":"47.92106"}
{"text":"The final system yielded the lowest overall word error rate in the 1997 DARPA broadcast news evaluation by a statistically significant margin .1998 DARPA Broadcast News Transcription and Understanding Workshop , Virginia .Niesler T.R. , Whittaker E.W.D. & Woodland P.C. ( 1998 )","label":"CompareOrContrast","metadata":{},"score":"48.02459"}
{"text":"Using all of the knowledge sources , the SVM method achieved the highest accuracy rate of 65.4 % .Another type of WSD approach uses established knowledge from curated terminology systems [ 23 , 24 ] .In the biomedical domain , Schijvenaars [ 13 ] developed a simple thesaurus - based algorithm to disambiguate human gene symbols using training data from PubMed abstracts and annotations from the Online Mendelian Inheritance in Man(OMIM )","label":"CompareOrContrast","metadata":{},"score":"48.313004"}
{"text":"Annotation of Read Spe ... . ...( the North American Business news corpus ) and conversational telephone speech ( the Switchboard corpus ) , both in American English .The Sphinx - II system [ 1 ] is used for the NAB tests .","label":"CompareOrContrast","metadata":{},"score":"48.576927"}
{"text":"It should also be noted that all results presented in this paper for the BNdev96ue set use the 1996 NIST scoring conventions , while the results for BNeval97 use the 1997 conventions .The use of global MLLR and gender dependent models reduces the first - pass error by between 12 - 16 % with a word trigram , and it should be noticed that larger reductions occur for the more challenging data types .","label":"CompareOrContrast","metadata":{},"score":"49.675552"}
{"text":"Two adaptation approaches are also described : adapting language models to the speech styles correlated with different focus conditions , and building cluster - specific LM mixtures .These two approaches give some reduction in per ... . \" ...This paper presents the CSLU Broadcast News transcription system used in the DARPA 1997 evaluation .","label":"CompareOrContrast","metadata":{},"score":"49.79368"}
{"text":"It can be seen that the new training corpus reduces the WER by a 0.7 % absolute and a further 0.5 % absolute reduction was obtained by using a merged interpolated language model .The merged interpolated models gave most improvement on the spontaneous speech portions of the data .","label":"CompareOrContrast","metadata":{},"score":"50.393772"}
{"text":"This is augmented by pronunciations from a TTS system and hand generated corrections .Cross - word context dependent decision tree state clustered mixture Gaussian HMMs are used with a 65k word vocabulary and a language model trained on 132 million words of broadcast news texts , along with the 1995 newswire texts and the transcriptions from BNtrain96 .","label":"CompareOrContrast","metadata":{},"score":"50.4088"}
{"text":"Across tasks and corpora , we obtain a significant improvement over word - only models using a probabilistic combination of prosodic and lexical information .Inspection reveals that the prosodic models capture language - independent boundary indicators described in the literature .","label":"CompareOrContrast","metadata":{},"score":"50.47895"}
{"text":"View Article .Engelson SP , Dagan I : Minimizing manual annotation cost in supervised training from corpora .34th Annual Meeting of Association for Computational Linguistics 319 - 326 .Pustejovsky J , Castano J , Cochran B , Kotecki M , Morrell M : Automatic extraction of acronym - meaning pairs from MEDLINE databases .","label":"CompareOrContrast","metadata":{},"score":"50.55816"}
{"text":"It consists of a total of approxi ... . by Hauptmann Jones , R. E. Jones , K. Seymore , S. T. Slattery , M. J. Witbrock , M. A. Siegler , 1998 . \" ...This paper describes the experiments performed as part of the TREC-97 Spoken Document Retrieval Track .","label":"CompareOrContrast","metadata":{},"score":"50.55884"}
{"text":"307 - 312 .Morgan Kaufmann .ABSTRACT .This paper presents the development of the HTK broadcast news transcription system for the November 1998 Hub4 evaluation .Overall these changes to the system reduced the error rate by 13 % on the 1997 evaluation data and the final system had an overall word error rate of 13.8 % for the 1998 evaluation data sets .","label":"CompareOrContrast","metadata":{},"score":"50.578293"}
{"text":"Using decision tree and hidden Markov modeling techniques , we combine prosodic cues with word - based approaches , and evaluate performance on two speech corpora , Broadcast News and Switchboard .Results show that the prosodic model alone performs on par with , or better than , word - based statistical language models - for both true and automatically recognized words in news speech .","label":"CompareOrContrast","metadata":{},"score":"51.403786"}
{"text":"As shown in Table 4 , this gave a substantial increase in recognition performance ( overall 1.4 % absolute and 2.3 % for female speakers ) and appears to have largely mitigated the gender bias in the training data .The effect of using the automatically derived segments from both the CMU segmenter described in [ 12 ] and the S1 and S2 segmenters described in Sec .","label":"CompareOrContrast","metadata":{},"score":"51.474194"}
{"text":"The reduced bandwidth models are used for data classified as narrow band .The system uses the LIMSI 1993 WSJ pronunciation dictionary augmented by pronunciations from a TTS system and hand generated corrections for a 65k word vocabulary .The 1997 system used N - gram language models trained on 132 million words of broadcast news texts , the LDC - distributed 1995 newswire texts , and the transcriptions from BNtrain97 ( LMtrain97 ) .","label":"CompareOrContrast","metadata":{},"score":"51.527817"}
{"text":"This paper has described the development and performance of the 1997 HTK broadcast news transcription system .The system uses a data segmentation and classification scheme which incorporates clustering .The use of HMMs that are independent of detailed data type fits well with automatic data segmentation and classification and yields at least as good performance as data type specific models .","label":"CompareOrContrast","metadata":{},"score":"51.579254"}
{"text":"Therefore , this type of method may not be applicable and ML approaches may be useful .Recently , Humphrey [ 26 ] proposed another type of statistical - based method to resolve the ambiguity problem within the UMLS Metathesaurus .They used a Journal Descriptor Indexing ( JDI ) method , which is ultimately based on statistical associations between words in a training set of MEDLNE citations and a small set of journal descriptors assumed to be inherited by the citations .","label":"CompareOrContrast","metadata":{},"score":"52.01803"}
{"text":"The baseline acoustic corpus available in 1997 used recorded audio from various US broadcast news shows ( television and radio ) .This amounted to a total of 72 hours of usable data ( BNtrain97 ) .This data was annotated to ensure that each segment was acoustically homogeneous ( same speaker , background noise condition and channel ) .","label":"CompareOrContrast","metadata":{},"score":"52.67437"}
{"text":"Most of today 's state - of - the - art speech recognition systems can recognize only words that belong to some predefined finite word vocabulary .When encountering an OOV word , a speech reco ... \" .This thesis concerns the problem of unknown or out - of - vocabulary ( 00V ) words in continuous speech recognition .","label":"CompareOrContrast","metadata":{},"score":"52.803837"}
{"text":"Some of these were included in 1998 HTK Hub4 evaluation system .Other experiments which did n't lead to overall word error rate reductions include discriminative training using the frame discrimination method and use of the soft - clustering technique .The paper is arranged as follows .","label":"CompareOrContrast","metadata":{},"score":"53.143864"}
{"text":"The data in broadcasts is not homogeneous and includes a number of data types for which speech recognition systems trained on read speech corpora such as the WSJ corpus have high error rates .A typical news broadcast may include data of different speech styles ( read , spontaneous and conversational ) ; native and non - native speakers ; high or low bandwidth channels either with or without background music or other background noise .","label":"CompareOrContrast","metadata":{},"score":"53.260788"}
{"text":"It is clear that adding geographic semantic posets , noun - based semantic posets from WordNet and parallel blind relevance feedback ( PBRF ) increases performance for all transcription error rates .PBRF is especially beneficial at high error rates which confirms the theory that it is compensating for transcription errors .","label":"CompareOrContrast","metadata":{},"score":"53.5027"}
{"text":"We show that this approach can dramatically reduces the cost of building acoustic models .INTRODUCTION The last decade has witnessed substantial progres ... .In addition to the word transcriptions , the annotations include speech fragments and non - speech events , speaker turns and identities , and markers for overlapping portions and non - English speech .","label":"CompareOrContrast","metadata":{},"score":"53.752365"}
{"text":"Here , as others have done previously ( e.g. [ 15 ] ) , we experimented with building separate language models for each of the 3 data sources and then interpolating the language models .For efficiency and ease of use in decoding , a model merging process was employed using tools supplied by Entropic Ltd. , that gives a similar effect to explicit model interplotation but saves run - time computation and storage .","label":"CompareOrContrast","metadata":{},"score":"53.961742"}
{"text":"Furthermore , it has previously been shown that data condition independent models can give surprisingly good performance [ 5 , 3 ] .The data type specific models used WSJ secondary channel HMMs with 6399 speech states and were subsequently adapted to broadcast news ( used in [ 8 ] ) .","label":"CompareOrContrast","metadata":{},"score":"54.064888"}
{"text":"Proc EMNLP 2002 , 41 - 48 .Mohammad S , Pedersen T : Combining lexical and syntactic features for supervised word sense disambiguation .Proc of the CoNLL .Wilks Y , Fass D , Guo C , MacDonald J , Plate T , Slator B : Providing Machine Tractable Dictionary Tools Cambridge , MA : MIT Press 1990 .","label":"CompareOrContrast","metadata":{},"score":"54.318916"}
{"text":"View Article PubMed .Maglott D , Ostell J , Pruitt KD , Tatusova T : Entrez Gene : Gene - centered information at NCBI .Nucleic Acids Res 2005 , 3 : D54-D58 .Yngve VH : Syntax and the problem of multiple meaning .","label":"CompareOrContrast","metadata":{},"score":"54.35646"}
{"text":"The data used is the speaker - independent portion of ... . by L. Welling , S. Kanthak , H. Ney - In Proc . of the IEEE Int .Conf . on Acoustics Speech and Signal Processing , 1999 . \" ...","label":"CompareOrContrast","metadata":{},"score":"54.40748"}
{"text":"In this paper , we also demonstrated that ambiguity of biomedical entities is a significant problem , which has a substantial impact on text mining and retrieval tasks in the biomedical domain .ML methods are still needed for WSD , which is critical for increasing the accuracy of biomedical natural language , text mining , and information retrieval systems .","label":"CompareOrContrast","metadata":{},"score":"54.413353"}
{"text":"The main variations are usually in the selection of features and choice of machine - learning algorithms .Experiments are usually performed on a fixed amount of documents ( i.e. 1,000 abstracts ) per an ambiguous word , where the entire set consists of all the senses , and the sense distribution is generally uneven .","label":"CompareOrContrast","metadata":{},"score":"54.778225"}
{"text":"Finally , we decided to use a different ( though similarly sized ) portion of newspaper texts covering 1995 to February 1998 ( about 70MW in total ) .All these sources excluded data from the designated test epochs .This corpus was denoted LMtrain98 .","label":"CompareOrContrast","metadata":{},"score":"54.97355"}
{"text":"It is also possible to calculate the TER after preprocessing to take into account the effects of stopping , stemming etc .It has been shown that this processed term error rate ( PTER ) can offer a better predictor of retrieval performance than WER [ 1 ] and therefore the transcriptions described in this paper are compared by PTER ( averaged over stories ) .","label":"CompareOrContrast","metadata":{},"score":"55.32055"}
{"text":"Some corrections to these transcriptions were made by us and used to estimate the HMMs described in [ 8 ] .This corpus will be referred to as BNtrain96 .A further tranche of data of similar size was released in 1997 to form in total 72 hours of broadcast news training data .","label":"CompareOrContrast","metadata":{},"score":"55.3492"}
{"text":"Liu H , Johnson SB , Friedman C : Automatic resolution of ambiguous terms based on machine learning and conceptual relations in the UMLS .J Am Med Inform Assoc 2002 , 9 : 621 - 636 .View Article PubMed .","label":"CompareOrContrast","metadata":{},"score":"55.53324"}
{"text":"X. Luo of JHU supplied code to help with the soft - clustering experiments .Fiscus , J.G. ( 1997 )A Post - Processing System to Yield Reduced Word Error Rates : Recogniser Output Voting Error Reduction ( ROVER ) .","label":"CompareOrContrast","metadata":{},"score":"55.734158"}
{"text":"View Article .Pedersen T , Bruce R : Distinguishing word senses in untagged text .Second Conference on Empirical Methods in Natural Language Processing .Hsu G , Lin C : A comparison of methods for multi - class support vector machines .","label":"CompareOrContrast","metadata":{},"score":"55.778107"}
{"text":"The multiple -- pass strategy is an efficient method but it is suboptimal because the normalization scale and the word sequence are determined sequentially .We found that for telephon ... . ... recognition performance by 30 % relative . ffl Results on WSJ , Verbmobil and SieTill .","label":"CompareOrContrast","metadata":{},"score":"55.81039"}
{"text":"We developed a fast implementation technique to make FD training on large HMM sets practical and on the WSJ / NAB task FD gives similar reductions in word error rate ( about 5 % relative ) to lattice - based MMIE with a much smaller computational cost .","label":"CompareOrContrast","metadata":{},"score":"55.863857"}
{"text":"This section gives an overview of the basic recognition architecture used for the experiments reported in Section 5 .The system is a development of previous HTK large vocabulary recognisers ( e.g. [ 13 ] ) .Each frame of input speech is represented by a 39 dimensional feature vector that consists of 13 ( including ) MF - PLP cepstral parameters [ 15 ] and their first and second differentials .","label":"CompareOrContrast","metadata":{},"score":"55.888412"}
{"text":"A test plan is presented for the suggested use of the LDC 's YOHO CD - ROM for testing voice verification systems .This plan is based upon ITT 's voice verification test methodology as described by Higgins , et al . , but differs slightly in order to match the LDC 's CD - ROM version of YOHO and to accommodate different systems .","label":"CompareOrContrast","metadata":{},"score":"56.308582"}
{"text":"Earlier studies have investigated a number of the issues discussed here in the context of constructing better classifiers .A discussion of some of the issues involved can be found in [ 43 ] .Here , we examined these issues in the context of word sense disambiguation .","label":"CompareOrContrast","metadata":{},"score":"56.386826"}
{"text":"ISCA ITRW ASR2000 , 2000 . \" ...Although tremendous progress has been made in speech recognition technology , with the capability of todays state - of - the - art systems to transcribe unrestricted continuous speech from broadcast data , these systems rely on the availability of large amounts of manually transcribed acoustic training data ... \" .","label":"CompareOrContrast","metadata":{},"score":"56.728874"}
{"text":"Among the experiments we described here are : Vocabular ... \" .This paper describes the experiments performed as part of the TREC-97 Spoken Document Retrieval Track .The task was to pick the correct document from 35 hours of recognized speech documents , based on a text query describing exactly one document .","label":"CompareOrContrast","metadata":{},"score":"56.997154"}
{"text":"This system was shown to give good performance in the 1996 DARPA / NIST broadcast news partitioned evaluation ( PE ) [ 15 ] .Our current research has concentrated on the more general situation where information about data segmentation and type is not supplied to the recogniser ( unpartitioned or UE data ) .","label":"CompareOrContrast","metadata":{},"score":"57.19101"}
{"text":"The FWP is implemented in the front - end preprocessing of our speech recognition system .We investigate the formant -based and ML - based FWP in linear and nonlinear warping modes , and compare them in detail .All experimental results are based on our JANUS3 large vocabulary continuous speech recognition system and the Spanish Spontaneous Scheduling Task database ( SSST ) .","label":"CompareOrContrast","metadata":{},"score":"57.528954"}
{"text":"In addition , papers should also characterize the difficulty of the WSD task , the WSD situations addressed and not addressed , as well as the ML methods and features used .This should lead to an improved understanding of the generalizablility and the limitations of the methodology .","label":"CompareOrContrast","metadata":{},"score":"57.63772"}
{"text":"Whilst the results shown in Table 3 are encouraging , they mask the separate effects on male and female speakers .Since two thirds of the broadcast news training and test data is from male speakers , there is a significant gender bias which is n't present in the WSJ models .","label":"CompareOrContrast","metadata":{},"score":"57.77167"}
{"text":"We describe a method for explicitly minimizing WER by extracting word hypotheses with the highest posterior probabilities from word lattices .We change the standard problem formulation by replacing global search over a large set of sentence hypotheses with local search over a small set of word candidates .","label":"CompareOrContrast","metadata":{},"score":"57.78906"}
{"text":"The index file was then generated containing the term frequencies , collection frequencies and document lengths and used for retrieval with the part - of - speech weighted query .A ranked list of documents was thus produced using the standard combined weight formulae .","label":"CompareOrContrast","metadata":{},"score":"57.7893"}
{"text":"As will be seen in Section 6 , the full HTK system can operate in multiple passes and use quinphone HMMs , more complex language models and iterative unsupervised adaptation .However , for the initial experiments reported in Section 5 , the decoder was run in a single pass using triphone models , a trigram language model and fairly tight beamwidths .","label":"CompareOrContrast","metadata":{},"score":"57.810547"}
{"text":"They reported an F - measure of over 0.7 for genes with sufficient number of known document references .Liu [ 29 ] investigated the effect of window size and claimed that biomedical ambiguous words needed a larger window size than general English ambiguous words .","label":"CompareOrContrast","metadata":{},"score":"57.951427"}
{"text":"The results of these experiments are shown in Table 5b ) , which confirms the advantage of the S2 segmenter for all data types .It is expected that the S2 system will have a further advantage when speaker / environment adaptation is used due to the small amount of data it includes in multiple - speaker segments .","label":"CompareOrContrast","metadata":{},"score":"58.248493"}
{"text":"During recognition we used iterative unsupervised MLLR to adapt clusters of segments to the particular audio conditions .This system was shown to give good performance in the 1996 DARPA / NIST broadcast news partitioned evaluation ( PE ) [ 8 ] .","label":"CompareOrContrast","metadata":{},"score":"58.260086"}
{"text":"We made some corrections to these transcriptions and used them to estimate the HMMs described in [ 15 ] .This corpus will be referred to as BNtrain96 .A further tranche of data of similar size was released in 1997 to form in total 72 hours of broadcast news training data .","label":"CompareOrContrast","metadata":{},"score":"58.39695"}
{"text":"Results obtained from the experiments demonstrate the feasibility of these methods . ...l - known vocabulary and phrases in spontaneous spoken scenario .The baseline system for native English speech use acoustic models trained on 34 hours ESST data .","label":"CompareOrContrast","metadata":{},"score":"58.42591"}
{"text":"New features , apart from those discussed above , include an interpolated word - based and class - based language model and the combination of different output stages based on confidence annotation .The overall decoding process is as follows .Firstly the data is segmented using the S2 segmenter described in previous sections .","label":"CompareOrContrast","metadata":{},"score":"58.446194"}
{"text":"Conclusion .Several different independent aspects affect performance when using ML techniques for WSD .We found that combining them into one single result obscures understanding of the underlying methods .Although we studied only four abbreviations , we utilized a well - established statistical method that guarantees the results are likely to be generalizable for abbreviations with similar characteristics .","label":"CompareOrContrast","metadata":{},"score":"58.72035"}
{"text":"The system was built using software developed for the CSLU LVCSR project , initiated in January 1997 .The project proceeded through development and evaluation of systems associated with previous DARPA tasks ; specifically the RM system , and the WSJ-5k and WSJ-20k system ...","label":"CompareOrContrast","metadata":{},"score":"58.837257"}
{"text":"The experiments reported in this paper use the reference ( manually generated ) transcriptions , two baseline transcriptions generated by NIST using the CMU recogniser and our own HTK transcriptions .These constituted the mandatory runs in the 1997 TREC-7 SDR evaluation .","label":"CompareOrContrast","metadata":{},"score":"58.85276"}
{"text":"It should be noted however that the advantage of using separate telephone bandwidth models decreases significantly when also using MLLR adaptation .This section describes the HTK system used in the 1997 evaluation .The system uses the modelling techniques described in previous sections with the addition of more complex acoustic and language models and multiple passes of unsupervised MLLR adaptation .","label":"CompareOrContrast","metadata":{},"score":"58.86687"}
{"text":"However , acoustic model development for the recognizers requires large corpora of manually transcrib ... \" .The last decade has witnessed substantial progress in speech recognition technology , with todays state - of - the - art systems being able to transcribe broadcast audio data with a word error of about 20 % .","label":"CompareOrContrast","metadata":{},"score":"58.87799"}
{"text":"Several strong additions to the set of predictor variables used for this purpose are discussed .Extensions which allow prediction of separate types of errors , as o ... \" .We present improvements in confidence annotation of automatic speech recognizer output for large vocabulary , speakerindependent systems .","label":"CompareOrContrast","metadata":{},"score":"59.111477"}
{"text":"The last decade has witnessed substantial progress in speech recognition technology , with todays state - of - the - art systems being able to transcribe unrestricted broadcast news audio data with a word error of about 20 % . ...","label":"CompareOrContrast","metadata":{},"score":"59.124153"}
{"text":"It can be seen that there is a rather different distribution data type between the two sets : particularly for F0 , F2 , F4 and FX .The HTK Broadcast News system runs in a number of stages .This is followed by generating a lattice for each segment using the adapted triphone models with a bigram LM , expanding these lattices using a word 4-gram interpolated with a category trigram LM , and performing iterative lattice rescoring and MLLR adaptation with a set of quinphone HMMs .","label":"CompareOrContrast","metadata":{},"score":"59.16533"}
{"text":"Our study is different because it quantified the effect of similarity of senses , and studied the relation between \" similarity of senses \" and other issues such as \" sample size \" and \" sense distribution \" .Podowski 's [ 28 ] work covered task types 2 and 3 , while Hatzivassiloglou 's [ 10 ] work addressed task type 4 .","label":"CompareOrContrast","metadata":{},"score":"59.35946"}
{"text":"Furthermore the 1998 4-gram language model gave a constant 15 % improvement ( over all test sets ) in perplexity over the equivalent model used in the 1997 evaluation .The overall decoding process proceeds as for the 1997 system , but with a couple of additional stages .","label":"CompareOrContrast","metadata":{},"score":"59.38482"}
{"text":"This thesis is about modeling , analyzing , and predicting errorful behavior in large vocabulary continuous speech recognition systems .Because today 's state - of - the - art recognizers are not designed to be situated naturally in an error feedback loop , they are ill - positioned for inclusion in multi- ... \" .","label":"CompareOrContrast","metadata":{},"score":"59.41995"}
{"text":"[ ps ] Proc .DARPA Speech Recognition Workshop , pp .73 - 78 , Chantilly , Virginia .Affiliated with .Abstract .Background .Automated techniques have been developed that address the WSD problem for a number of text processing situations , but the problem is still a challenging one .","label":"CompareOrContrast","metadata":{},"score":"59.44986"}
{"text":"IEEE Workshop on Automatic Speech Recognition and Understanding , pp .347 - 354 , Santa Barbara .Abstract : .This paper presents the recent development of the HTK broadcast news transcription system .Previously we have used data type specific modelling based on adapted Wall Street Journal trained HMMs .","label":"CompareOrContrast","metadata":{},"score":"59.52487"}
{"text":"Based on these experiments , the HTK system for the 1997 broadcast news evaluation was designed .A detailed description of this system is given which includes a class - based language modelling component .The complete system yields an overall word error rate of 22.0 % on the 1996 unpartitioned broadcast news development test data and just 15.8 % on the 1997 evaluation test set .","label":"CompareOrContrast","metadata":{},"score":"59.675865"}
{"text":"More recently , supervised machine learning ( ML ) technologies have received considerable attention and have shown promising results [ 16 - 18 ] .Bruce [ 19 ] applied a Bayesian algorithm and chose features based on their \" informative \" nature .","label":"CompareOrContrast","metadata":{},"score":"59.694145"}
{"text":"Most current speech recognition systems are dedicated to one specific task ( for example , the recognition of broadcast news ) , and thus use a language model which has been trained on text which is appropriate to that task .If , however , one wants to perform recognition on more general language , then creating an appropriate language model is far from straightforward .","label":"CompareOrContrast","metadata":{},"score":"59.6951"}
{"text":"Initially we used bandwidth independent , gender independent triphones to evaluate the technique and under these conditions it gave a 1 % absolute reduction in WER .However , when bandwidth dependent , gender dependent models with variance normalisation and MLLR adaptation were used , there was no WER advantage and hence soft clustering was not used in the 1998 evaluation system .","label":"CompareOrContrast","metadata":{},"score":"59.84169"}
{"text":"They see this as b ..In the first ap ... \" .In SRI 's language modeling experiments for the Hub4 domain , three basic approaches were pursued : interpolating multiple models estimated from Hub4 and non - Hub4 training data , adapting the language model ( LM ) to the focus conditions , and adapting the LM to different topic types .","label":"CompareOrContrast","metadata":{},"score":"59.889317"}
{"text":"Meanwhile , we also recorded the percentage of ambiguous words that were removed from the ambiguous word - list for different thresholds .We removed words with frequencies higher than 10 % , 1 % , 0.1 % and 0.05 % from the two lists of the mouse organism .","label":"CompareOrContrast","metadata":{},"score":"60.027596"}
{"text":"The use of these models improved performance on F2 data using the S2 segmentation of the BNdev96ue to 35.9 % error ( from 38.3 % ) and reduced the overall error rate to 28.3 % ( from 28.6 % ) .However a much more dramatic effect was observed for the S2 segmentation of the BNeval97 data .","label":"CompareOrContrast","metadata":{},"score":"60.09496"}
{"text":"Automatic Segmentation , Classification and Clustering of Broadcast News Data .[HTML ]Proc .DARPA Speech Recognition Workshop , pp .97 - 99 , Chantilly , Virginia .Woodland P.C. , Gales M.J.F. , Pye D. & Young S.J. ( 1997 )","label":"CompareOrContrast","metadata":{},"score":"60.19091"}
{"text":"Despite fairly high word error rates , information retrieval performance was only slightly degraded for speech recognizer transcribed documents .INTRODUCTION For the first time , the 1997 Text REtrieval Conference ( TREC97 ) included an evaluation track for information retrieval on spoken documents .","label":"CompareOrContrast","metadata":{},"score":"60.270397"}
{"text":"It should be noted that some of the data ( that identified as pure music ) is discarded by the S1/S2 segmenters while the CMU approach retains the entire data stream .As can be seen in Table 5a ) , recognition performance improves with the S1 segmenter , particularly on F3 segments due in part to the removal of pure music , and S2 improves overall recognition performance further .","label":"CompareOrContrast","metadata":{},"score":"60.277294"}
{"text":"Our experiments demonstrate that light supervision is sufficient for acoustic model development , drastically reducing the development cost . \" ...Statistical language models encode linguistic information in such a way as to be useful to systems which process human language .","label":"CompareOrContrast","metadata":{},"score":"60.28177"}
{"text":"The basic adaptation approach in our system remains MLLR for both means and variances [ 2 ] .In addition , for the quinphone stage of iterative unsupervised adaptation , the effect of a single full variance ( FV ) transform [ 3 ] was investigated .","label":"CompareOrContrast","metadata":{},"score":"60.358223"}
{"text":"Using a clustering procedure and a set of smoothing rules the final segments to be processed by the decoder are generated .For recognition , each frame of input speech is represented by a 39 dimensional feature vector that consists of 13 ( including ) MF - PLP cepstral parameters and their first and second differentials .","label":"CompareOrContrast","metadata":{},"score":"60.41057"}
{"text":"The system then uses quinphone models ( VTLN / SAT trained ) and MLLR with an additional FV transform to process the data ( P4 ) .This stage is repeated twice more while increasing the number of MLLR transforms ( P5/P6 ) .","label":"CompareOrContrast","metadata":{},"score":"60.435024"}
{"text":"This paper has described a number of experiments in broadcast news transcription .It has been shown that a segmentation scheme which integrates clustering is particularly effective and that automatically segmented broadcast news data can yield close to the performance of hand partitioned data using data condition independent modelling .","label":"CompareOrContrast","metadata":{},"score":"60.52444"}
{"text":"However for all experiments reported here the decoder was run in a single pass using triphone models , a trigram language model and fairly tight beamwidths .We have found that using the full system with adaptation results in a 20 % decrease in word error rate on broadcast news .","label":"CompareOrContrast","metadata":{},"score":"60.640625"}
{"text":"To try to improve the performance for female speakers we investigated gender dependent modelling .Gender dependent versions of the HMM - BN2 set were created by splitting the BNtrain97 data according to gender and retraining the Gaussian means and mixture weights on the gender - specific data portions .","label":"CompareOrContrast","metadata":{},"score":"60.86128"}
{"text":"The full - form in the title or abstract of the article was then replaced with the ambiguous abbreviation , and the appropriate sense was noted separately .Table 1 shows the number of articles that were obtained for the different abbreviations and senses .","label":"CompareOrContrast","metadata":{},"score":"60.86831"}
{"text":"System details can be found in [ 16 ] .The data segmentation [ 4 ] aims to generate acoustically homogeneous speech segments and discard non - speech portions such as pure music .It uses a set of Gaussian mixture models to classify the data as to type ( wideband speech , narrow - band speech , pure music , speech and music ) , and then any pure music is discarded .","label":"CompareOrContrast","metadata":{},"score":"60.957207"}
{"text":"Table 7 : % Word error rates on BNdev96pe split by gender for gender independent ( GI ) and gender dependent ( GD ) models .The effect of using the automatically derived segments from both the CMU segmenter and the S1 segmenter described in Sec .","label":"CompareOrContrast","metadata":{},"score":"61.081894"}
{"text":"This paper investigates the potential of graphemes acting as subunits .In order to develop context dependent grapheme based speech recognizers several decision tree based clustering procedures are performed and compared to each other .Grapheme based speech recognizers in three languages - English , German , and Spanish - are trained and compared to their phoneme based counterparts .","label":"CompareOrContrast","metadata":{},"score":"61.111557"}
{"text":"Perhaps more surprisingly the HMM - BN1 models give slightly better overall performance than the data specific WSJ adapted models .In particular , it can be seen that there is a large improvement for the HMM - BN1 models on the spontaneous speech conditions .","label":"CompareOrContrast","metadata":{},"score":"61.119587"}
{"text":"Performance figures are reported on both read news ( the North American Business news corpus ) and conversational telephone speech ( the Switchboard corpus ) , both in American English .The Sphinx - II system [ 1 ] is used for the NAB tests .","label":"CompareOrContrast","metadata":{},"score":"61.198814"}
{"text":"This was similarly transcribed at the speaker turn level but did n't distinguish between background conditions which meant that marked training segments were no longer necessarily homogeneous .The combined set of 1997 and 1998 data is denoted BNtrain98 .System development mainly used the 1997 Hub4 evaluation data , BNeval97 .","label":"CompareOrContrast","metadata":{},"score":"61.2362"}
{"text":"When encountering an OOV word , a speech recognizer erroneously substitutes the OOV word with a similarly sounding word from its vocabulary .Furthermore , a recognition error due to an OOV word tends to spread errors into neighboring words ; dramatically degrading overall recognition performance . by Lori Lamel , Jean - luc Gauvain , Gilles Adda - Computer Speech and Language , 2002 . \" ...","label":"CompareOrContrast","metadata":{},"score":"61.25657"}
{"text":"It should be noted that some of the data ( that identified as pure music ) is discarded by the S1 segmenter while the CMU approach retains the entire data stream .As can be seen in Table 8 recognition performance improves with the S1 segmenter , particularly on F3 segments due in part to the removal of pure music .","label":"CompareOrContrast","metadata":{},"score":"61.263054"}
{"text":"For each abbreviation , we measured error rates of the SVM classifier under different combinations of sample size , sense distribution , cross validation scheme ( 5-fold vs. 10-fold ) , and multi - class SVM algorithms ( for BPD only , which has 3 different senses ) .","label":"CompareOrContrast","metadata":{},"score":"61.28817"}
{"text":"This figure shows the plots of ' ' error rate ' ' versus ' ' sample size ' ' with different sense distributions of PCA data set ( case where the 2 ambiguous senses are very similar ) using 5-fold cross validation .","label":"CompareOrContrast","metadata":{},"score":"61.37654"}
{"text":"In addition , we used an SVM classifier for all the experiments .Since the goals of our study did not include the comparison of different algorithms , we do not present related results here .Other studies showed that different ML algorithms had similar performance for WSD tasks [ 29 , 30 ] .","label":"CompareOrContrast","metadata":{},"score":"61.426632"}
{"text":"Two adaptation approaches are also described : adapting language models to the speech styles correlated with different focus conditions , and building cluster - specific LM mixtures .These two approaches give some reduction in perplexity , but no significant reduction in word error .","label":"CompareOrContrast","metadata":{},"score":"61.45426"}
{"text":"Merkel M , Andersson M : Combination of contextual features for word sense disambiguation .SENSEVAL-2 Workshop 123 - 127 .Bruce R , Wiebe J : Word sense disambiguation using decomposable models .Proceedings of the Thirty - second Annual Meeting of the Association of Computational Linguistics 139 - 146 .","label":"CompareOrContrast","metadata":{},"score":"61.470497"}
{"text":"The final lattices can be further processed in two ways .Firstly they can be re - scored using an unsupervised unigram cache model .Alternatively the output from the pass5 lattices can be combined with that from the pass2/ic lattices to form the final recognition output .","label":"CompareOrContrast","metadata":{},"score":"61.543743"}
{"text":"More specifically we want to estimate acoustic models for a new target language using speech data from varied source languages , but only limited data from the target language .For this purpose we introduce different methods for multilingual acoustic model combination and a polyphone decision tree specialization procedure .","label":"CompareOrContrast","metadata":{},"score":"61.574116"}
{"text":"[ Before ROVER combination an alignment pass was run to get exact word timings .Due to the effects of automatic segmentation this process reduces the WER by about 0.1 % absolute .] Table 6 : Word error rates for each stage of the 1998 HTK broadcast news evaluation system ( also P4 FV contrast ) .","label":"CompareOrContrast","metadata":{},"score":"61.662575"}
{"text":"We describe a new framework for distilling information from word lattices to improve the accuracy of speech recognition and obtain a more perspicuous representation of a set of alternative hypotheses .In the standard MAP decoding approach the recognizer outputs the string of words corresponding to the path with the highest posterior probability given the acoustics and a language model .","label":"CompareOrContrast","metadata":{},"score":"61.816658"}
{"text":"To test the null hypothesis of no differences in the error rates among the different sample sizes ( and overall probability distribution ) for the BSA and PCA abbreviations , we used Friedman 's test .Then we performed sub - analysis using the sign - test ( see Methods section for details ) .","label":"CompareOrContrast","metadata":{},"score":"61.88057"}
{"text":"This adaptation was performed separately for each of the four shows and only for classes with at least 15 seconds of data .Table 2 : Overall audio classification accuracy and percentage loss of speech to discarded music class on the BNdev96ue data set .","label":"CompareOrContrast","metadata":{},"score":"61.89652"}
{"text":"For classification , each frame of data was labelled using a conventional Viterbi decoder with each of the four models in parallel .An additional insertion penalty was applied to the music model in order to control the misclassification of speech into music .","label":"CompareOrContrast","metadata":{},"score":"61.907497"}
{"text":"INTRODUCTION .The YOHO voice verification corpus was collected while testing ITT 's prototype speaker verification system in an office environment [ 1 ] .This database is the largest supervised speaker verification database known to the author .The number of trials and the number of test subjects were chosen to allow testing at the 75 % confidence level to determine whether a system meets 0.1 % false rejection and 0.01 % false acceptance .","label":"CompareOrContrast","metadata":{},"score":"62.05078"}
{"text":"Obtaining such data is both time - consuming and expensive , requiring trained human annotators with substantial amounts of supervision .In this paper we describe some recent experiments using lightly supervised techniques for acoustic model training in order to reduce the system development cost .","label":"CompareOrContrast","metadata":{},"score":"62.068405"}
{"text":"Therefore it is important that we understand the different elements affecting their performance .Methods .After manually reviewing a set of WSD papers in the biomedical domain , different issues associated with performance were enumerated .For an initial study , we conducted experiments to evaluate the effect of three confounding issues : \" sample size \" , \" sense distribution \" and \" degree of difficulty \" , and we used an automatically generated data set .","label":"CompareOrContrast","metadata":{},"score":"62.14377"}
{"text":"Other confounding issues of WSD .Other issues in addition to sample size , distribution of senses , and difficulty of the task also affect the performance and subsequent assessment of WSD classifiers , as noted below : .As often discussed in various papers , different features were evaluated to see their contribution to classifier performance [ 10 , 20 , 29 ] .","label":"CompareOrContrast","metadata":{},"score":"62.195633"}
{"text":"ABSTRACT .This paper presents the recent development of the HTK broadcast news transcription system .Previously we have used data type specific modelling based on adapted Wall Street Journal trained HMMs .However , we are now using data for which no manual pre - classification or segmentation is available and therefore automatic techniques are required and compatible acoustic modelling strategies must be adopted .","label":"CompareOrContrast","metadata":{},"score":"62.375553"}
{"text":"The Development of the 1996 Broadcast News Transcription System [ ps ] Proc .DARPA Speech Recognition Workshop , pp .73 - 78 , Chantilly , Virginia .Young S.J. , Odell J.J. & Woodland P.C. ( 1994 ) .Tree - Based State Tying for High Accuracy Acoustic Modelling [ ps ] Proc .","label":"CompareOrContrast","metadata":{},"score":"62.55334"}
{"text":"Since two thirds of the broadcast news training and test data is from male speakers there is a significant gender bias which is n't present in the WSJ models .Hence the error rate on the female speakers in the test is 29.8 % for the WSJ adapt models but is 33.3 % for the HMM - BN1 models ( and 31.3 % for HMM - BN2 ) .","label":"CompareOrContrast","metadata":{},"score":"62.573395"}
{"text":"Joseph P. Campbell , Jr. US Department of Defense , R2 Fort Meade , Maryland , USA 20755 - 6000 .ABSTRACT .A standard database for testing voice verification systems , called YOHO , is now available from the Linguistic Data Consortium ( LDC ) .","label":"CompareOrContrast","metadata":{},"score":"62.66014"}
{"text":"Bioinformatics 2004 , 20 : 2597 - 2604 .View Article PubMed .Schijvenaars BJ , Mons B , Weeber M , Schuemie MJ , van Mulligen EM , Wain HM , et al .: Thesaurus - based disambiguation of gene symbols .","label":"CompareOrContrast","metadata":{},"score":"62.693516"}
{"text":"The goal of the segment processing stages is to convert the continuous input audio stream into clusters of reasonably - sized speech segments .Ideally , each segment should be homogeneous ( i.e. same speaker and channel conditions ) and the segments should be grouped into clusters such that each cluster is sufficiently similar to share a single set of MLLR adaptation transforms .","label":"CompareOrContrast","metadata":{},"score":"62.84091"}
{"text":"The quinphone models with a global MLLR improve the error rate by 3 % over triphone models using global MLLR .It is somewhat surprising to find that while iterative MLLR gives further small gains on the BNdev96ue data ( about 1.5 % ) , barely measurable gains were found on BNeval97 .","label":"CompareOrContrast","metadata":{},"score":"63.01484"}
{"text":"Obtaining such data is both time - consuming and expensive , requiring trained human annotators with substantial amounts of supervision .In this paper we describe some recent experiments using different levels of supervision for acoustic model training in order to reduce the system development cost .","label":"CompareOrContrast","metadata":{},"score":"63.049404"}
{"text":"The S1/S2 segmenters also classify data as narrow - band or wide - band .A narrow - band model version of HMM - BN2 ( HMM - BN2 T ) was trained using single - pass retraining from the HMM - BN2 set and a reduced bandwidth data analysis ( 125Hz to 3.75kHz ) of the BNtrain97 dataset .","label":"CompareOrContrast","metadata":{},"score":"63.056892"}
{"text":"The data from an episode of NPR Marketplace is the only complete show that is common to both the BNdev96pe and BNdev96ue data sets .Finally the 1997 evaluation data , BNeval97 , contained extracts from 9 different shows and totalled about 3 hours of data .","label":"CompareOrContrast","metadata":{},"score":"63.169685"}
{"text":"In their study , rare senses ( senses appearing in less than 40 documents ) were excluded from the testing set .This makes the disambiguation task easier because it reduces the problem of sparse senses .In addition , the training set was created based on long - form and short - form pairs , where ambiguous words not having long - forms were not tested .","label":"CompareOrContrast","metadata":{},"score":"63.236847"}
{"text":"Again , the 1997 trigram LM and the HMM - BN2 acoustic model set were used .It can be seen from Table 6 that the overall degradation caused by the automatic segmentation is very small ( on the development data the degradation is approximately 1 % absolute ) .","label":"CompareOrContrast","metadata":{},"score":"63.252594"}
{"text":"Since these tests were not performed under identical conditions , they can not be compared directly with each other .They are presented to show a variety of algorithms and their corresponding performance .Please refer to the references for descriptions of the algorithms and test procedures used .","label":"CompareOrContrast","metadata":{},"score":"63.259995"}
{"text":"This could also be due to the existence of other confounding factors in the datasets that were used .In our study , we controlled for this factor by using \" bag - of - word \" features in all experiments , but it would be interesting to see if the performance improves when different feature vectors are used .","label":"CompareOrContrast","metadata":{},"score":"63.30441"}
{"text":"The initial audio classification uses 4 Gaussian mixture models : one for each of the required classes ( S , T and M ) plus a model for music and speech .Audio selected by this latter model is also labelled as ( S ) but its separate inclusion reduces the misclassification of speech as music .","label":"CompareOrContrast","metadata":{},"score":"63.31153"}
{"text":"The category - trigram used 1000 automatically derived word classes and was trained using LMtrain98 .Category bigrams and trigrams were added only if the leave - one training set likelihood improved and the final category model contained 0.85 million bigrams and 9.4 million trigrams .","label":"CompareOrContrast","metadata":{},"score":"63.320747"}
{"text":"Contrary to the CD 's 0readme.txt file .The speech data is divided into two directories to separate enrollment and verification sessions .The enrollment and verification ( or identification ) phases should only use data from their respective directories .ENROLLMENT .","label":"CompareOrContrast","metadata":{},"score":"63.330936"}
{"text":"View Article PubMed .Gaudan S , Krisch H , Rebholz - Schuhmann D : Resolving abbreviations to their senses in Medline .Bioinformatics 2005 , 21 : 3658 - 3664 .View Article PubMed .Schuemie MJ , Kors JA , Mons B : Word sense disambiguation in the biomedical domain : an overview .","label":"CompareOrContrast","metadata":{},"score":"63.421555"}
{"text":"This agrees with work by Rifkin and Klatau [ 34 ] .A description of the different multi - class algorithms is provided in the Methods section .Table 5 .Results for BPD data set .Annotation of the table : Dist : Distribution of senses ; S. Size : sample size ; Err .","label":"CompareOrContrast","metadata":{},"score":"63.431976"}
{"text":"These papers are important in that they report on useful methods and provide insights and overall results .However , a deeper and more systematic analysis is needed in order to obtain a better understanding of the different factors affecting the performance of ML methods for WSD .","label":"CompareOrContrast","metadata":{},"score":"63.46487"}
{"text":"MM and CF conceived of the study , and participated in its design and coordination and helped to draft the manuscript .MM also performed statistical analysis and interpreted the results .HL advised in the design of study .All authors read and approved the final manuscript .","label":"CompareOrContrast","metadata":{},"score":"63.477512"}
{"text":"Currently , however , the most common application of language modelling is in automatic ... \" .Statistical language models encode linguistic information in such a way as to be useful to systems which process human language .Such systems include those for optical character recognition and machine translation .","label":"CompareOrContrast","metadata":{},"score":"63.495544"}
{"text":"Table 7 : OOV rate and perplexities of the 1998 evaluation LMs .Perplexities shown for trigram ( tg ) , 4-gram ( fg ) and word 4-gram interpolated with category trigram ( fgintcat ) .The out - of - vocabulary ( OOV ) rate and perplexity of these language models on BNeval97 and the two halves of the BNeval98 set is shown in Table 7 .","label":"CompareOrContrast","metadata":{},"score":"63.547325"}
{"text":"Most subjects were from the New York City area , although there were many exceptions , including some nonnative English speakers .A high - quality telephone handset ( Shure XTH-383 ) was used to collect the speech ; however , the speech was not passed through a telephone channel .","label":"CompareOrContrast","metadata":{},"score":"63.587624"}
{"text":"The rest of the paper is arranged as follows .We first give details of the broadcast news data used , and then describe our work on segment processing ( segmentation , classification and clustering ) which splits the unpartitioned data stream into moderate length homogeneous segments .","label":"CompareOrContrast","metadata":{},"score":"63.61979"}
{"text":"Please state if any data is excluded from your tests .The author would appreciate reports of any other errors on the YOHO CD - ROM .LDC INFORMATION .For information about the LDC , including obtaining copies of YOHO , please contact the Linguistic Data Consortium , 441 Williams Hall , University of Pennsylvania , Philadelphia , PA 19104 - 6305 , USA .","label":"CompareOrContrast","metadata":{},"score":"63.69927"}
{"text":"View Article .Weston J , Watkins C : Multiclass support vector machines .Proceedings of ESANN99 .Copyright . Xu et al .2006 .This article is published under license to BioMed Central Ltd.This paper presents the results from adding several forms of query expansion to our retrieval system running on several sets of transcriptions of broadcast news from the 1997 TREC-7 spoken document retrieval track .","label":"CompareOrContrast","metadata":{},"score":"63.70693"}
{"text":"ICASSP'98 , Seattle .Siegler M.A. , Jain U. , Raj B. & Stern R.M. ( 1997 )Automatic Segmentation , Classification and Clustering of Broadcast News Data [ HTML ]Proc .DARPA Speech Recognition Workshop , pp .97 - 99 , Chantilly , Virginia .","label":"CompareOrContrast","metadata":{},"score":"63.772617"}
{"text":"P1 to P3 use triphones and P4-P6 quinphones .The results ( over the complete 1998 evaluation set ) for each of these stages , together with additional contrasts , is shown in Table 6 .There is a 12 % reduction in error by using gender dependent models and VTLN ( P1 to P2 ) and a further 7 % from using MLLR .","label":"CompareOrContrast","metadata":{},"score":"63.785942"}
{"text":"Finally complete recognition results are presented using the evaluation set - up for both the BNeval97 data and BNdev96ue .At various stages bigram , trigram and 4-gram word - based language models were used .The text - processing for this data expanded a number of abbreviations and corrected some common spelling errors .","label":"CompareOrContrast","metadata":{},"score":"63.8183"}
{"text":"The HMM - BN3 set has 8180 speech states each modelled with a 16 component Gaussian mixture .Gender dependent and bandwidth dependent versions of these models were used for each segment as appropriate .The system includes 3 passes through the data with MLLR - adapted quinphone models .","label":"CompareOrContrast","metadata":{},"score":"63.910355"}
{"text":"Adding semantic entities which are part - of more generalised entities is not restricted purely to location information .Providing a term has only one possible sense in the document file , this approach can be used on any kind of term .","label":"CompareOrContrast","metadata":{},"score":"63.953213"}
{"text":"Each frame of input speech is represented by a 39 dimensional feature vector that consists of 13 ( including c 0 ) MF - PLP cepstral parameters [ 8 ] and their first and second differentials .Cepstral mean normalisation ( CMN ) is applied over a segment .","label":"CompareOrContrast","metadata":{},"score":"63.965775"}
{"text":"Experiments with no adaptation ( or cluster - based normalisation ) showed that the word error rate ( WER ) was reduced by up to 0.9 % absolute .However when MLLR adaptation and VTLN were applied ( see below ) the WER gain was reduced to 0.4 % absolute .","label":"CompareOrContrast","metadata":{},"score":"64.06502"}
{"text":"The average precision for the expansion techniques described in section 2 on the transcriptions described in section 3 are given in Table 2 and the results are shown in Figure 2 .Table 2 : Average Precision on the TREC-7 SDR test collection with mean number of query terms in parenthesis .","label":"CompareOrContrast","metadata":{},"score":"64.08169"}
{"text":"Several papers [ 29 , 30 ] realized this issue and reported results for the baseline .More specifically , they excluded samples with a majority sense larger than a threshold because they realized the contribution of the classifier would not be much for those cases .","label":"CompareOrContrast","metadata":{},"score":"64.10065"}
{"text":"A crucial step in processing speech audio data for information - extraction , topic detection , or browsing / playback is to segment the input into sentence and topic units .Speech segmentation is challenging , since the cues typically present for segmenting text ( headers , paragraphs , punctuation ) are absent in spoken language .","label":"CompareOrContrast","metadata":{},"score":"64.11991"}
{"text":"guage model is used .The JANUS-3 decoder achieved a word error rate of 13.2 % in the 1996 VERBMOBIL evaluation .This was the lowest error rate of the five participating institutions .In the experiments descri ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"64.233185"}
{"text":"Aronson AR : Effective mapping of biomedical text to the UMLS Metathesaurus : the MetaMap program .Proc AMIA Symp 2001 , 17 - 21 : 17 - 21 .Weeber M , Klein H , Aronson AR , Mork JG , de Jong - van den Berg LT , Vos R : Text - based discovery in biomedicine : the architecture of the DAD - system .","label":"CompareOrContrast","metadata":{},"score":"64.25375"}
{"text":"The original data set for PCA contained 6 different senses , but we only used the two that were very similar for our experiments .We used a simple \" full - form substitution \" method to automatically generate a data set for the experiments described in this paper , and this dataset was partitioned into training and testing sets .","label":"CompareOrContrast","metadata":{},"score":"64.275185"}
{"text":"1471 - 2105 - 7 - 334-S1.doc Additional File 1 : Supplementary material for gene ambiguity for mining MEDLINE ( DOC 925 KB ) .Authors ' contributions .HX carried out data collection , programming , experiments using SVM and drafted the manuscript .","label":"CompareOrContrast","metadata":{},"score":"64.27908"}
{"text":"Furthermore , in line with the triphone figures , the overall gain for 1998 trained MLLR adapted quinphone models was 0.4 % absolute due to VTLN .For the 1998 system , the additional transcriptions from the 1998 acoustic training were available .","label":"CompareOrContrast","metadata":{},"score":"64.2862"}
{"text":"The data from an episode of NPR Marketplace is the only complete show that is common to both the BNdev96pe and BNdev96ue data sets .The goal of the segment processing stages is to convert the continuous input audio stream into clusters of reasonably - sized speech segments .","label":"CompareOrContrast","metadata":{},"score":"64.46979"}
{"text":"This paper motivates the task and describes the measures to be used to ... \" .The Text REtrieval Conference ( TREC ) workshops provide a forum for different groups to compare retrieval systems on common retrieval tasks .The 1997 TREC workshop will feature a Spoken Document Retrieval task for the first time .","label":"CompareOrContrast","metadata":{},"score":"64.4735"}
{"text":"All models used 12 component mixture Gaussian distributions .In all cases gender independent models were used .The results given in Table 6 show that the WSJ models are significantly improved by broadcast news adaptation ( 4 % absolute ) .","label":"CompareOrContrast","metadata":{},"score":"64.49992"}
{"text":"Furthermore , doubling the amount of training data reduces the error rate by a further 1.5 % absolute .Table 6 : % Word error rates on BNdev96pe for different training conditions .Only the WSJ adapt set is data condition dependent .","label":"CompareOrContrast","metadata":{},"score":"64.598816"}
{"text":"Effects of \" sense distribution \" have been addressed in other papers [ 30 , 37 ] because it is believed that the performance of a WSD classifier may change if the distribution of the different senses is unbalanced .For example , when there is a majority sense for an ambiguous word , the improvement of a WSD classifier is believed to be very small .","label":"CompareOrContrast","metadata":{},"score":"64.625275"}
{"text":"View Article PubMed .Humphrey SM , Rogers WJ , Kilicoglu H , Demner - Fushman D , Rindflesch TC : Word sense disambiguation by selecting the best semantic type based on Journal Descriptor Indexing : Preliminary experiment .Journal of the American Society for Information Science and Technology 2006 , 57 : 96 - 113 .","label":"CompareOrContrast","metadata":{},"score":"64.63165"}
{"text":"However there is a concern that a very limited set of words may have accounted for the vast majority of ambiguity .Therefore , for each ambiguous word , we calculated its frequency , which is defined as the ratio between the number of abstracts containing the word and the total number of abstracts in the pool .","label":"CompareOrContrast","metadata":{},"score":"64.67572"}
{"text":"This tree was trained using a preliminary version of the system run on the BNdev96ue data .Detailed performance for each stage of the evaluation system is shown in Table 8 for both the BNdev96ue set and the BNeval97 data set .","label":"CompareOrContrast","metadata":{},"score":"64.68168"}
{"text":"Gender dependent versions of the HMM - BN2 set were created by splitting the BNtrain97 data according to gender and retraining the Gaussian means and mixture weights on the gender - specific data portions .These gender dependent models were then tested only on data of the corresponding gender ( i.e. it is assumed that perfect gender determination is possible ) .","label":"CompareOrContrast","metadata":{},"score":"64.83334"}
{"text":"To be consistent with ITT , the cohort set speakers should be excluded as impostors and speaker dependent cohort sets should consist of the five \" closest \" speakers as determined from the 4 th enrollment session .Determining a fair way to compare systems using different size cohort sets is a difficult problem .","label":"CompareOrContrast","metadata":{},"score":"64.8483"}
{"text":"The same study , which was also performaned for the Fly organism , showed similar results , but with slightly higher ambiguity rates .For a more complete description of this study and the results , please [ see additional file 1 ] .","label":"CompareOrContrast","metadata":{},"score":"64.97174"}
{"text":"Mooney RJ : Comparative experiments on disambiguating word senses : An illustration of the role of bias in machine learning .Proc 1996 Conf on Empirical Methods in Natural Language Processing 82 - 91 .Ng HT , Lee HB : Integrating multiple knowledge sources to disambiguate word sense : An examplar - based approach .","label":"CompareOrContrast","metadata":{},"score":"65.00264"}
{"text":"This program uses dynamic programming based string alignment to obtain a word correspondence for all words in the hypotheses and then examines the correspondence pairs and chooses the word with the highest confidence score .The confidence scores were generated using an N - best homogeneity measure found using the 1000-best hypotheses from the lattices generated at the appropriate stage .","label":"CompareOrContrast","metadata":{},"score":"65.015305"}
{"text":"A subset of these waveform files comprises the LDC 's YOHO CD - ROM .There are 138 speakers ( 106 males and 32 females ) ; for each speaker , there are 4 enrollment sessions of 24 utterances each and 10 verification sessions of 4 utterances each .","label":"CompareOrContrast","metadata":{},"score":"65.07536"}
{"text":"specialized , e.g. , to a specific subtopic .Related approaches by other researchers have effectively used much smaller amounts of target - specific training data for LM adaptation purposes .Similarly , [ 4 ] reported improvementsby interpolating an in - domain LM wi ... . ...","label":"CompareOrContrast","metadata":{},"score":"65.0788"}
{"text":"Extensions which allow prediction of separate types of errors , as opposed to the simple presence of an error , are presented .A new development , acoustic confidence annotation , is explored , in which a predictor is built that indicates the likely successes and failures of the acoustic models alone .","label":"CompareOrContrast","metadata":{},"score":"65.12227"}
{"text":"We analyze why this relationship holds and show that it holds for other exponential language models as well , including class - based models and minimum discrimination information models .Finally , we discuss how this relationship can be applied to improve language model performance . ...","label":"CompareOrContrast","metadata":{},"score":"65.161545"}
{"text":"A multilingual recognizer ( MULTI ) based on the four languages German , English , Japanese and Spanish was developed to serve as a source system .Likewise this system is very useful for language identification and achieves 100 % language identification rate .","label":"CompareOrContrast","metadata":{},"score":"65.226234"}
{"text":"However the observed decrease in error rate was more dramatic in the cases where the different senses were well separated .For example , in BSA , the error rate dropped to approximately 5 % when the sample size was 80 and the sense distributions were almost balanced , and it was approximately 8 % for other distributions with the same size .","label":"CompareOrContrast","metadata":{},"score":"65.381874"}
{"text":"INTRODUCTION As the demand for speech recognition and translation systems in multiple languages grows , the development of multilingual systems is of increasing concern .On the one hand a multilingual system can be used as a language independent speech recognition and translation system with integrated automatic langu ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"65.424255"}
{"text":"The subsequent sections give the details of a number of experiments that we performed in system development .This is followed by a description of , and the results from , the 1998 Hub4 evaluation system .The full recognition results from the various stages of operation are included .","label":"CompareOrContrast","metadata":{},"score":"65.64115"}
{"text":"In this study , we used 4 abbreviations from Liu 's abbreviation list .However , we used a different method to collect the datasets because we wanted to control the sample sizes of the senses for our experiments .Leroy [ 30 ] tried to reduce the training sample size by supplying external knowledge from the UMLS for supervised machine learning algorithms , but the results were not promising .","label":"CompareOrContrast","metadata":{},"score":"65.739784"}
{"text":"Our baseline system uses most of the strategies applied in our 1997 TREC-7 SDR evaluation system [ 1 ] .Compound word processing was applied for geographical names such as New York and United Kingdom .A list of 400 words were defined for stopping and abbreviations such as ' ' C. N. N. ' ' were made into single words .","label":"CompareOrContrast","metadata":{},"score":"65.765144"}
{"text":"Each model was trained on data of the appropriate class extracted from the BNtrain97 data up to a maximum of three hours per model .For the speech models , data was selected to ensure that each training segment contained at least 90 % speech .","label":"CompareOrContrast","metadata":{},"score":"65.88447"}
{"text":"This FV transform was used with , for the wideband data , HMMs estimated with a single iteration of speaker adaptive training ( SAT ) [ 14 ] to update the mean parameters .The effect of these changes is shown in Table 5 .","label":"CompareOrContrast","metadata":{},"score":"65.92342"}
{"text":"For each claimant , sessions spoken by subjects other than the claimant and his / her cohorts are selected as impostors , with no more than one session per subject ( for independent tests ) .The sessions are processed using the normal verification procedure , resulting in accept / reject decisions .","label":"CompareOrContrast","metadata":{},"score":"65.94382"}
{"text":"This figure shows the plots of \" error rate \" versus \" sample size \" with different sense distributions of BPD data set ( where there are 3 ambiguous senses that are different ) using 5-fold cross validation and \" one - vs - rest \" algorithm .","label":"CompareOrContrast","metadata":{},"score":"65.98981"}
{"text":"Liu H , Teller V , Friedman C : A multi - aspect comparison study of supervised word sense disambiguation .J Am Med Inform Assoc 2004 , 11 : 320 - 331 .View Article PubMed .Leroy G , Rindflesch TC : Effects of information and machine learning algorithms on word sense disambiguation with small datasets .","label":"CompareOrContrast","metadata":{},"score":"66.21884"}
{"text":"If each ambiguous gene symbol in an article were accompanied by its corresponding long form , the disambiguation task would be much easier .Schijvenaars [ 13 ] showed that 33 % of the human genes in their thesaurus were affected by homonymy .","label":"CompareOrContrast","metadata":{},"score":"66.25715"}
{"text":"This section describes the various data sets that have been used in the experiments reported in the paper .For acoustic training a number of US broadcast news shows ( both television and radio ) transmitted prior to June 30th 1996 were recorded and labelled by the LDC .","label":"CompareOrContrast","metadata":{},"score":"66.36424"}
{"text":".. ures yield 39 total features as above .In Janus all of these features are treated in a single stream .Finally , linear discriminant analysis ( LDA ) is used to reduce the 39 features to a set of 24 features . 2.2","label":"CompareOrContrast","metadata":{},"score":"66.54302"}
{"text":"But some reported that certain classification algorithms were better than others .It is still an unclear issue , probably due to the interaction of different combinations of issues .The comparison between different classifiers should be a carefully controlled experiment .","label":"CompareOrContrast","metadata":{},"score":"66.56815"}
{"text":"To extend our previous approach to the UE case , it is necessary to first segment the data into homogeneous segments of differing data types as well as rejecting segments of data that contain no speech ( e.g. background music ) .","label":"CompareOrContrast","metadata":{},"score":"66.61308"}
{"text":"The perplexities for the various language models on the BNdev96ue and BNeval97 ( filtered ) reference transcriptions are given in Table 7 .The category model alone has a similar perplexity to the word bigram , however when interpolated with the word 4-gram it reduces the 4-gram perplexity by about 8 % .","label":"CompareOrContrast","metadata":{},"score":"66.7087"}
{"text":"The category language model used 1000 automatically generated word classes chosen to maximise the training set likelihood based on word bigram statistics [ 8 , 10 , 11 ] .The categories and the trigram category model were built using the broadcast news training texts , the acoustic training data and 1995 Marketplace transcriptions .","label":"CompareOrContrast","metadata":{},"score":"66.79202"}
{"text":"\" Sample size ' , \" sense distribution \" and \" degree of difficulty \" were three of multiple confounding issues that affect the performance of a WSD classifier .Results from our experiments demonstrated that these three factors were intrinsically connected .","label":"CompareOrContrast","metadata":{},"score":"66.80542"}
{"text":"Verification Speaker I d EER closed - set .ITT 's CSR 1.7 % ITT 's NN 0.5 % MIT / LL 's 0.51 % 0.8 % error .GMM 0.2%m , 1.8%f 1.1 avg rank Rutgers ' NTN 0.65 % Rutgers ' HMM 1.36 % error .","label":"CompareOrContrast","metadata":{},"score":"66.9194"}
{"text":"This should lead to better recognition performance since subsequent cepstral mean normalisation and speaker adaptation stages assume that individual segments are homogeneous .The goal of segment clustering is to group segments in order to optimise subsequent adaptation .This requires a compromise between the desire for homogeneity within clusters and the need for clusters of sufficient size for robust unsupervised adaptation .","label":"CompareOrContrast","metadata":{},"score":"66.9316"}
{"text":"The results presented here agree with general results presented in the literature on the performance of classifiers [ 43 - 45 ] .Future work .To further analyze the effects of \" sample size \" , \" sense distribution \" and \" degree of difficulty \" on the error rate , an error decomposition model will be explored .","label":"CompareOrContrast","metadata":{},"score":"66.93739"}
{"text":"When the senses are well separated , any increase in the sample size results in a statistically significant decrease of the error rate .This holds for all sense distributions and it is in agreement with the finding that for BSA there was no significant effect of the sense distributions on the error rates for the different sample sizes used .","label":"CompareOrContrast","metadata":{},"score":"67.239365"}
{"text":"Finally , the resulting segments are clustered in preparation for adaptation .The initial audio classification uses Gaussian mixture models with 1024 mixture components and diagonal covariance matrices .Four models are used , one for each of the required classes ( S , T and M ) plus a model for music and speech .","label":"CompareOrContrast","metadata":{},"score":"67.288864"}
{"text":"For example , pause and pitch features are highly informative for segmenting news speech , whereas pause , duration and word - based cues dominate for natural conversation . ... this paper we describe the prosodic modeling in detail .The two corpora are compared directly on the task of sentence segmentation , and the two tasks ( sentence and topic segmentation ) are compared for the Broadcast ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"67.34326"}
{"text":"Session 4 can be used to determine cohort [ 2 ] ( also known as ratio or likelihood [ 1 ] ) set speakers and used for building a speech segmenter .Unlike some text - dependent speaker verification systems , not all possible verification phrases are available from enrollment ( this would lead to excessive enrollment time ) .","label":"CompareOrContrast","metadata":{},"score":"67.368286"}
{"text":"The performance of speech recognition systems is consistently poor on non - native speech .The challenge for non - native speech recognition is to maximize the recognition performance with small amount of non - native data available .In this paper we report on the acoustic modeling adaptation for the recognition of non - native speech .","label":"CompareOrContrast","metadata":{},"score":"67.39905"}
{"text":"verify/101/1320/73_61_31.wav . verify/101/1320/86_79_65.wav .There is a total of 1,380 sessions , numbered from 528 to 2527 ( there are gaps in the sequence ) .False - rejection measurements are based on the 1,380 valid session trials .Impostor trials are simulated by presenting the system with one subject 's speech and prompted text ( embedded in the file name ) under a different subject 's hypothesized identity .","label":"CompareOrContrast","metadata":{},"score":"67.42702"}
{"text":"In each case , the clustering thresholds have been adjusted to give similar numbers of clusters so that measuring the increase in log likelihood provides a reasonably valid comparison .As can be seen , all of the methods give fairly similar performance .","label":"CompareOrContrast","metadata":{},"score":"67.46625"}
{"text":"The 72 hour corpus is denoted BNtrain97 .Each resulting segment in the training corpora was labelled by speaker and one of the audio ' ' focus ' ' conditions listed in Table 1 .For development test purposes , data broadcast in July 1996 from six shows ( ABC Prime Time , CNN World View , CSPAN Washington Journal , NPR Marketplace , NPR Morning Edition and NPR The World ) was used .","label":"CompareOrContrast","metadata":{},"score":"67.50653"}
{"text":"We first compared the performance of models which require knowledge of data type with condition independent models which are more suitable to automatically segmented data since fine classification is not required .Furthermore , it has previously been shown that data condition independent models can give surprisingly good performance [ 9 , 4 ] .","label":"CompareOrContrast","metadata":{},"score":"67.55955"}
{"text":"For many practical applications of speech recognition systems , it is desirable to have an estimate of con dence for each hypothesized word , i.e. to have an estimate which words of the speech recognizer 's output are likely to be correct and which are not reliable .","label":"CompareOrContrast","metadata":{},"score":"67.63962"}
{"text":"For many practical applications of speech recognition systems , it is desirable to have an estimate of con dence for each hypothesized word , i.e. to have an estimate which words of the speech recognizer 's output are likely to be correct and which are not reliable .","label":"CompareOrContrast","metadata":{},"score":"67.63962"}
{"text":"Similarly , using quinphone models with MLLR a gain of 0.5 % in WER was achieved with increased training data .We also did some experiments that used automatic segmentation of the extended training data to try and ensure that the segments used in training were acoustically homogeneous but this provided no additional improvements .","label":"CompareOrContrast","metadata":{},"score":"67.691635"}
{"text":"Supervised ML methods have also been applied to WSD in the biomedical domain .Hatzivassiloglou [ 10 ] developed a disambiguation system to determine the class of a known biomedical named entity by choosing one of three pre - defined senses : gene , RNA , protein .","label":"CompareOrContrast","metadata":{},"score":"67.82976"}
{"text":"The system achieved an accuracy rate of 92.7 % on an automatically generated testing set .Schijvenaars 's study described an effective method for gene disambiguation , but the evaluation results were limited to certain conditions .The automatically generated testing set contained human genes symbols that appeared as long - form and short - form pairs ( e.g. prostate specific antigen ( PSA ) ) in articles , where at least 6 articles were determined to be associated with each gene sense .","label":"CompareOrContrast","metadata":{},"score":"67.94348"}
{"text":"Traditionally word error rate ( WER ) has been used to report the performance of a speech recogniser .However , since this requires an alignment of the transcriptions and thus is word - order dependent , it does not seem appropriate in a retrieval context when word order is not important .","label":"CompareOrContrast","metadata":{},"score":"67.95215"}
{"text":"REPORTING RESULTS .In addition to using the critical number of errors tests , a number of other reporting means are of interest : .Raw error rates ( relative frequency ) .Histograms of the number of errors vs number of speakers for each error type ( e.g. , subject falsely rejected , subject falsely accepted as another , and another falsely accepted as subject ) .","label":"CompareOrContrast","metadata":{},"score":"68.017365"}
{"text":"Larger cohort set sizes should yield improved real - world unseen impostor performance , but one must be aware of these possible testing biases .Cross - validation could be used to iteratively partition impostor and cohort sets , but this may reduce the statistical confidence of the tests .","label":"CompareOrContrast","metadata":{},"score":"68.01817"}
{"text":"Unlike BNdev96ue for which show boundaries are known , the BNeval97 data is presented to the system as a single 3 hour audio file .Table 2 gives the proportions of the different audio types present in the BNdev96ue and BNeval97 data sets measured by the number of reference words assigned to each data category .","label":"CompareOrContrast","metadata":{},"score":"68.041046"}
{"text":"An additional issue is that this study limited the disambiguation of gene symbols to gene senses and one other category called \" non - gene sense \" , but the actual sense in this category was not resolved .This could be critical for NLP systems accessing phenotypic or disease - related information .","label":"CompareOrContrast","metadata":{},"score":"68.14845"}
{"text":"In speech recognition , speaker - dependence of a speech recognition system comes from speaker - dependence of the speech feature , and the variation of vocal tract shape is the major source of inter - speaker variations of the speech feature , though there are some other sources which also contribute .","label":"CompareOrContrast","metadata":{},"score":"68.15023"}
{"text":"In speech recognition , speaker - dependence of a speech recognition system comes from speaker - dependence of the speech feature , and the variation of vocal tract shape is the major source of inter - speaker variations of the speech feature , though there are some other sources which also contribute .","label":"CompareOrContrast","metadata":{},"score":"68.15023"}
{"text":"To understand the effects of increased sample size on the error rate , we stratified by the sense distribution and then tested the null hypothesis of no difference between the error rates obtained under the different sample sizes using the sign test .","label":"CompareOrContrast","metadata":{},"score":"68.19797"}
{"text":"Finally the use of hypothesis combination using ROVER reduced the error rate by a further 3 % to give a 15.8 % overall word error rate on BNeval97 and 22.0 % on BNdev96ue .It was noted that the confidence scores associated with the combined hypotheses had a normalised cross entropy of 0.173 for BNdev96ue and 0.179 for BNeval97 .","label":"CompareOrContrast","metadata":{},"score":"68.228134"}
{"text":"CONCLUSIONS .The LDC 's YOHO CD - ROM and its errata were described .A test plan was proposed that will , hopefully , unify the reporting of the performance of speaker verification systems .The performance of a few systems was presented .","label":"CompareOrContrast","metadata":{},"score":"68.23755"}
{"text":"To be able to identify whether there are significant differences in the error rates due to different sample sizes and sense distributions while controlling for the abbreviation used , we used Friedman 's procedure .Notice that if we stratify by the abbreviation , the mean error rates form a two - way table where the columns correspond to different sample sizes and the rows correspond to different sense distributions .","label":"CompareOrContrast","metadata":{},"score":"68.274124"}
{"text":"Retrieval was performed on this corpus and the top 15 documents were assumed to be relevant .From these documents the 5 terms with the highest Offer Weight were automatically extracted and added to the query .Since the parallel corpus supposedly contains no transcription errors it was hoped that this process would recover terms missing from the automatic transcriptions , thus increasing average precision .","label":"CompareOrContrast","metadata":{},"score":"68.295395"}
{"text":"Markatou M , Tian H , Biswas S , Hripcsak G : Analysis of variance of cross - validation estimators of the generalization error .Journal of Machine Learning Research 2005 , 6 : 1127 - 1168 .Resnik P , Yarowsky D : Distinguishing systems and distinguishing senses : New evaluation tools for words sense disambiguation .","label":"CompareOrContrast","metadata":{},"score":"68.35648"}
{"text":"by Elizabeth Shriberg , Andreas Stolcke , Dilek Hakkani - Tr , Gkhan Tr - SPEECH COMMUNICATION , 2000 . \" ...A crucial step in processing speech audio data for information - extraction , topic detection , or browsing / playback is to segment the input into sentence and topic units .","label":"CompareOrContrast","metadata":{},"score":"68.39569"}
{"text":"It is also desirable to remove as much of the non - speech from the input audio stream as possible .Our approach to segment processing is to first classify the audio data into three broad categories : wide - band speech ( S ) , narrow - band speech ( T ) and music ( M ) .","label":"CompareOrContrast","metadata":{},"score":"68.45694"}
{"text":"An approach for automatic audio segmentation and classification is described and evaluated as well as extensions to our previous work on segment clustering .A number of recognition experiments are presented that compare data - type specific and non - specific models ; differing amounts of training data ; the use of gender - dependent modelling and the effects of automatic data - type classification .","label":"CompareOrContrast","metadata":{},"score":"68.63663"}
{"text":"As a consequence our research focuses on the question of how to port LVCSR systems in a fast and efficient way .More specifically we want to estimate acoustic ... \" .With the distribution of speech technology products all over the world , the portability to new target languages becomes a practical concern .","label":"CompareOrContrast","metadata":{},"score":"68.645676"}
{"text":"The speech - to - speech translation system Verbmobil requires a multilingual setting .This consists of recognition engines in the three languages German , English and Japanese that run in one common framework together with a language identification component which is able to switch between these recogni ... \" .","label":"CompareOrContrast","metadata":{},"score":"68.74409"}
{"text":"Tools . by Fuliang Weng , Andreas Stolcke , Ananth Sankar - In Proceedings DARPA Speech Recognition Workshop , 1997 .In the first approach ... \" .In SRI 's language modeling experiments for the Hub4 domain , three basic approaches were pursued : interpolating multiple models estimated from Hub4 and non - Hub4 training data , adapting the language model ( LM ) to the focus conditions , and adapting the LM to different topic types .","label":"CompareOrContrast","metadata":{},"score":"68.807106"}
{"text":"The first quinphone pass ( pass 3 ) uses a global mean and variance MLLR speech transform ; the second quinphone pass ( pass 4 ) uses up to two MLLR speech transforms and the final pass ( pass 5 ) uses up to four transforms .","label":"CompareOrContrast","metadata":{},"score":"68.87126"}
{"text":"With the same sample size change , the error rate for PCA dropped from 43.00 % to only 28.53 % .Results for BPD are shown in Table 5 , which contains the results from three different multi - class SVM algorithms .","label":"CompareOrContrast","metadata":{},"score":"69.00714"}
{"text":"We exploit the use of such word lattices as information sources for the measure - of - con dence tagger JANKA [ 1].In experiments on spontaneous human - to - human speech data the use of word lattice related information signi cantly improves the tagging accuracy . .","label":"CompareOrContrast","metadata":{},"score":"69.148636"}
{"text":"This consists of recognition engines in the three languages German , English and Japanese that run in one common framework together with a language identification component which is able to switch between these recognizers .This article describes the challenges of multilingual speech recognition and presents different solutions to the problem of the automatic language identification task .","label":"CompareOrContrast","metadata":{},"score":"69.36837"}
{"text":"Details of these segment processing stages are given in a companion paper [ 5 ] , but a brief overview is included here for completeness .Our approach to segment processing is first to classify the audio data into three broad categories : wide - band speech ( S ) , narrow - band speech ( T ) and music ( M ) .","label":"CompareOrContrast","metadata":{},"score":"69.545944"}
{"text":"The same study , which was also performed for the Fly organism , showed similar results , but with slightly higher ambiguity rates .This study shows that the ambiguity among gene symbols , English words and other biomedical terms is extensive and the distribution of ambiguity is very sparse .","label":"CompareOrContrast","metadata":{},"score":"70.100075"}
{"text":"These smoothing rules also ensure that segments with durations between one second and 30 seconds are created .This basic segmenter is referred to as S1 .About 7 % ( by duration ) of the data consists of segments containing more than one speaker when using the S1 segmenter .","label":"CompareOrContrast","metadata":{},"score":"70.15292"}
{"text":"It was presented to show the degree of difficulty among different abbreviations .Results from 5-fold cross - validation showed no statistical difference with results from 10-fold cross - validation , which indicated 5-fold cross - validation might be used in evaluation in order to save computational power ( for a discussion of the relative merits of 5-fold cross - validation vs. 10-fold cross - validation , see [ 35 ] ) .","label":"CompareOrContrast","metadata":{},"score":"70.24042"}
{"text":"As can be seen , the use of segment clustering improves both the speaker segmentation and the gender detection .For comparison , the segmentation given by the CMU software [ 6 ] distributed by NIST is also included in Table 4 along with the reference hand derived segmentation .","label":"CompareOrContrast","metadata":{},"score":"70.24587"}
{"text":"This transcription is used for both gender selection as well as VTLN warp selection for each segment cluster .Gender dependent VTLN models are then used ( P2 ) to provide a revised transcription which is used to estimate global mean and variance MLLR transforms for each cluster .","label":"CompareOrContrast","metadata":{},"score":"70.247986"}
{"text":"Tables 2 , 3 and 4 display the results for BSA , PCA and RSV , each of which has two senses .The distribution shown with bold font in column 1 is the estimated distribution of the senses , which is calculated based on the number of retrieved articles for each sense and the number of retrieved articles for all the senses .","label":"CompareOrContrast","metadata":{},"score":"70.38985"}
{"text":"In 2000 , the UMLS Metathesaurus [ 6 ] , a comprehensive resource that specifies and categorizes biomedical concepts , contained 9,416 ambiguous terms , and in 2004 , the number increased to 21,295 , an increase of 126 % within 4 years [ 7 ] .","label":"CompareOrContrast","metadata":{},"score":"70.4025"}
{"text":"As the cohort set size increases , excluding cohort set speakers increasingly eliminates good impostors .This may optimistically bias the results in favor of larger cohort set size systems .Furthermore , if the cohort set speakers are not excluded as impostors , they are likely to be rejected ( since the system has models for them ) .","label":"CompareOrContrast","metadata":{},"score":"70.40904"}
{"text":"The second method represents segments by the covariance of the static and delta parameters and uses a hierarchical top - down clustering process in which each node of the hierarchy is split into a maximum of four child nodes .Segments are reassigned to the closest node using an arithmetic harmonic sphericity distance measure [ 1 ] .","label":"CompareOrContrast","metadata":{},"score":"70.52345"}
{"text":"The 1998 evaluation data , BNeval98 , consisted of two 1.5 hour data sets : the first drawn from a similar epoch as the 1997 data and the second drawn from June 1998 .The evaluation results are presented for each of the NIST ' ' focus ' ' conditions which are shown in Table 1 .","label":"CompareOrContrast","metadata":{},"score":"70.536736"}
{"text":"As shown in Figure 5 , PCA , which has two very close senses , had much higher error rates than BSA , which has two unrelated senses .Therefore , when comparing the performance of different WSD systems , data sets with the same degree of difficulty should be used .","label":"CompareOrContrast","metadata":{},"score":"70.54201"}
{"text":"Silence segments longer than 3 seconds are classified as non - speech and discarded .Sections of male speech with high pitch are frequently mis - classified as female and vice versa .Hence , a number of heuristic smoothing rules are applied .","label":"CompareOrContrast","metadata":{},"score":"70.556694"}
{"text":"There is a total of 138 speakers , numbered from 101 to 277 ( there are gaps in the sequence ) .VERIFICATION .A single trial can use all the speech in a given speaker 's verification session ( i.e. , up to four phrases ) .","label":"CompareOrContrast","metadata":{},"score":"70.73353"}
{"text":"SIGIR'04 Workshop on Search and Discovery in BioInformatics .Hatzivassiloglou V , Duboue PA , Rzhetsky A : Disambiguating proteins , genes , and RNA in text : a machine learning approach .Bioinformatics 2001 , 17 ( Suppl 1 ) : S97 - 106 .","label":"CompareOrContrast","metadata":{},"score":"70.848694"}
{"text":"The 72 hour corpus is denoted BNtrain97 .Each resulting segment in the training corpora was labelled by speaker and one of the audio ' ' focus ' ' conditions listed in Table 1 .For development test purposes , data broadcast in July 1996 from six shows was used .","label":"CompareOrContrast","metadata":{},"score":"71.00708"}
{"text":"Furthermore , multilingual grapheme based recognizers are designed to investigate whether grapheme based information can be successfully shared among languages .Finally , some bootstrapping experiments for Swedish were performed to test the potential for rapid language deployment . ... fifteen different languages . ...","label":"CompareOrContrast","metadata":{},"score":"71.113815"}
{"text":"After an initial classification of the data , MLLR adaptation transforms were computed for each class and then the decoding was repeated .This adaptation was performed separately for each of the four shows and only for classes with at least 15 seconds of data .","label":"CompareOrContrast","metadata":{},"score":"71.11633"}
{"text":"We show that using single Gaussian densities for selecting the normalization scales in training results in lower error rates than using mixture densities .For VTN in recognition , we propose an improvement of the well -- known multiple -- pass strategy : By using an unnormalized acoustic model for the first recognition pass instead of a normalized model lower error rates are obtained .","label":"CompareOrContrast","metadata":{},"score":"71.198685"}
{"text":"For each sense , we recorded all the retrieved PMIDs , randomly selected 250 , and then obtained the corresponding abstracts to form a data pool , from which all the experiments were drawn .Feature vector and machine - learning algorithm .","label":"CompareOrContrast","metadata":{},"score":"71.273"}
{"text":"The first scheme was used in our 1996 BN system [ 8 ] .This is a bottom - up method in which each segment is modelled by a single diagonal covariance Gaussian and segments are merged based on a furthest neighbour divergence - like distance measure .","label":"CompareOrContrast","metadata":{},"score":"71.3136"}
{"text":"This figure shows the plots of \" error rate \" versus \" sample size \" with different sense distributions of RSV data set ( case where the 2 ambiguous senses both refer to viruses but the viruses are different types of viruses ) using 5-fold cross validation .","label":"CompareOrContrast","metadata":{},"score":"71.35313"}
{"text":"This was the scheme that we used in our 1996 broadcast news evaluation system [ 15 ] .The second scheme represents segments by the covariance of the static and delta parameters and uses a hierarchical top - down clustering process in which each node of the hierarchy is split into a maximum of four child nodes .","label":"CompareOrContrast","metadata":{},"score":"71.41951"}
{"text":"There is a 6 % gain from employing the category trigram and 4-gram over the trigram alone , and a 7 % gain moving from adapted triphones to adapted quinphones : most of which ( 5 % ) was due to the full variance adaptation .","label":"CompareOrContrast","metadata":{},"score":"71.46451"}
{"text":"At the end of the process , all segments which were too small to compute a full covariance robustly are assigned to the leaf node with the closest mean .Table 5 : Percentage improvement in log likelihood after MLLR adaptation using the CMU segment clustering ( CMU ) , bottom - up divergence - based clustering ( BDIV ) and top - down covariance - based clustering ( TCOV ) .","label":"CompareOrContrast","metadata":{},"score":"71.55931"}
{"text":"We found an overall improvement in WER with cluster - based variance normalisation of 0.3 % absolute and a further 0.6 % absolute by applying VTLN in both training and testing without adaptation .However with mean and variance MLLR adaptation the separate beneficial effect of variance normalisation and VTLN is much reduced .","label":"CompareOrContrast","metadata":{},"score":"71.61517"}
{"text":"The results are given in Table 9 .It can be seen that automatic segmentation has added 2 % absolute to the PE error rate .However nearly half of this increase is due to recognition of a Bosnian speaker who is excluded from the PE segments but causes insertion errors in the automatically segmented data , causing a substantial increase in the error rate for FX data .","label":"CompareOrContrast","metadata":{},"score":"71.63832"}
{"text":"However , since approximately 85 % of segments boundaries have at least a short silence segment at the boundary , this does not cause severe degradation in performance .Table 4 : Segmentation results showing number of segments with multiple speakers ( # MSseg ) , average speakers per segment and gender detection accuracy for the basic system with heuristic smoothing ( S1 ) and the improved system which combines smoothing with segment clustering ( S2 ) .","label":"CompareOrContrast","metadata":{},"score":"71.72462"}
{"text":"Table 4 : % WER on BNeval97 for different trigram LMs with VTLN unadapted triphone HMMs with either pooled data or ( merged ) interpolated LMs .The effect of using three different LMs on BNeval97 with VTLN data and 1998 unadapted triphone HMMs is shown in Table 4 .","label":"CompareOrContrast","metadata":{},"score":"71.832886"}
{"text":"The three conditions tested are female wide - band ( F - WB ) , male wide - band ( M - WB ) and male narrow - band ( M - NB ) .Table 5 compares the three speaker clustering methods in terms of the percentage increase in log likelihood achieved by the subsequent MLLR - based mean adaptation with a global MLLR transform for each clustered group .","label":"CompareOrContrast","metadata":{},"score":"71.85686"}
{"text":"However , since most segment boundaries have at least a short silence segment at the boundary , this does not cause severe degradation in performance .The segmenter integrating segment clustering is denoted S2 and it reduces the proportion of the data represented by multiple speaker segments to 2 % .","label":"CompareOrContrast","metadata":{},"score":"71.9524"}
{"text":"Furthermore given an automatic segmentation it is of interest to develop acoustic modelling techniques that do not rely on detailed , manually derived , data classifications .The rest of the paper is arranged as follows .We first give details of the broadcast news data used in the experiments , and briefly describe our work on segment processing which splits the unpartitioned data stream into moderate length homogeneous segments .","label":"CompareOrContrast","metadata":{},"score":"71.97348"}
{"text":"Error rates for each combination of sense distribution and sample size were averaged using 30 runs .Statistical methodology .To quantify the effects of sample size , sense distribution and difficulty of the task on the error rate , appropriate statistical methods were used .","label":"CompareOrContrast","metadata":{},"score":"72.02273"}
{"text":"We investigate the task of performance prediction for language models belonging to the exponential family .First , we attempt to empirically discover a formula for predicting test set cross - entropy for n - gram language models .We build models over varying domains , data set sizes , and n - gram orders , and perform linear regression to see whether we can model test set performance as a simple function of training set performance and various model statistics .","label":"CompareOrContrast","metadata":{},"score":"72.03908"}
{"text":"Data set for experiments .Four abbreviations were used in the experiments .Table 1 lists the detailed information about the abbreviations and their senses .These abbreviations were originally specified in the ABBR data set [ 8 ] .We chose them by considering the different levels of semantic similarity among their senses .","label":"CompareOrContrast","metadata":{},"score":"72.16076"}
{"text":"Two sets of condition independent models were trained : the BNtrain96 HMM - BN1 has 5628 states and the BNtrain97 HMM - BN2 set 6684 states .All models used 12 component mixture Gaussian distributions .In all cases gender independent models were used .","label":"CompareOrContrast","metadata":{},"score":"72.18532"}
{"text":"Thirty - eight groups including representatives from nine different countries participated in TREC-5 in November , 1996 .TRE ... . ... rack will use stories ( i.e. , documents ) taken from the Linguistic Data Consortium ( LDC ) 1996 Broadcast News corpus .","label":"CompareOrContrast","metadata":{},"score":"72.2591"}
{"text":"The output of the phone recogniser is a sequence of relatively short segments having male , female or silence tags .Silence segments longer than 3 seconds are classified as non - speech and discarded .Sections of male speech with high pitch are frequently mis - classified as female and vice versa .","label":"CompareOrContrast","metadata":{},"score":"72.6221"}
{"text":"Ginter [ 27 ] introduced a new family of classifiers , which were based on an ordering and weighing of the feature vectors obtained from word counts and word co - occurrence in the text .This method was used to determine whether a term was a gene versus a protein and achieved 86 % accuracy .","label":"CompareOrContrast","metadata":{},"score":"72.67915"}
{"text":"To evaluate this techniques we collected the multilingual database GlobalPhone which currently consists of 9 different languages .A multilingual ... \" .In this paper we described an efficient method to bootstrap continuously spoken , large vocabulary speech recognition systems by multilingual phoneme sets .","label":"CompareOrContrast","metadata":{},"score":"72.6873"}
{"text":"Two ambiguous gene symbol lists were formed as a result of the comparisons : a gene - English list ( containing gene symbols ambiguous with general English words ) and a gene - UMLS list ( containing gene symbols ambiguous with biomedical terms ) .","label":"CompareOrContrast","metadata":{},"score":"72.748985"}
{"text":"We use a maximum likelihood technique to select the best data warp factor via a parabolic search .It is important when comparing the warped data likelihoods to properly take into account the effect of the transformation .We have done this implicitly by performing variance normalisation on the data .","label":"CompareOrContrast","metadata":{},"score":"72.86174"}
{"text":"For all other sense distributions , an increase in the sample size did not produce a significant reduction in the error rate - that is , there are no statistically significant differences between the error rates .We would like to stress here a limitation of the current study .","label":"CompareOrContrast","metadata":{},"score":"73.05234"}
{"text":"There are different types of WSD and some are more difficult than others .For example , if two senses are syntactically different , a reliable part of speech tagging method could be effective in resolving the ambiguity .For senses that correspond to the same syntactic category , the similarity of their semantic categories will affect the difficulty of the task ( i.e. the bovine serum albumin sense of BSA is substantially different from the body surface area sense ) .","label":"CompareOrContrast","metadata":{},"score":"73.07747"}
{"text":"While the system produces good results it is computationally expensive : a companion paper [ 12 ] discusses a version of the system that runs in less than ten times real - time on commodity hardware .This work is in part supported by an EPSRC grant on ' ' Multimedia Document Retrieval ' ' reference GR / L49611 and by a grant from DARPA .","label":"CompareOrContrast","metadata":{},"score":"73.09881"}
{"text":"This figure shows the plots of \" error rate \" versus \" sample size \" for BSA , RSV and PCA data sets with fixed distribution of \" ( 0.5 , 0.5 ) \" using 5-fold cross validation .Discussion .","label":"CompareOrContrast","metadata":{},"score":"73.22952"}
{"text":"A histogram of the identification rank .Average identification rank .Fine - grain results on problem speakers can be informative ( e.g. , 3-D plots of attacker 's vs attackee 's identification numbers vs number of false acceptance errors ) .","label":"CompareOrContrast","metadata":{},"score":"73.30336"}
{"text":"The online version of this article ( doi : 10 .1186/1471 - 2105 - 7 - 334 ) contains supplementary material , which is available to authorized users .Background .During the last few years , there has been a surge of interest in information extraction and text mining of the biomedical literature [ 1 , 2 ] .","label":"CompareOrContrast","metadata":{},"score":"73.464874"}
{"text":"When comparing the performance of WSD classifiers , those metrics are critical because they indicate whether or not an improvement is statistically significant ; if there is a large deviation , there may not actually be an improvement even though one error rate is smaller than the other .","label":"CompareOrContrast","metadata":{},"score":"73.544945"}
{"text":"Because today 's state - of - the - art recognizers are not designed to be situated naturally in an error feedback loop , they are ill - positioned for inclusion in multi - modal interfaces , multi - media databases , and other interesting applications .","label":"CompareOrContrast","metadata":{},"score":"73.58177"}
{"text":"Table 8 : % Word error rates on BNdev96ue for different segmentations algorithms using the gender independent HMM - BN2 model set .The S1 segmenter also classifies data as narrow - band or wideband .A narrow band model version of HMM - BN2 was trained using a reduced bandwidth data analysis ( 125Hz to 3.8kHz ) and use of these models improved performance on F2 data to 38.3 % error and reduced the overall error rate to 29.2 % .","label":"CompareOrContrast","metadata":{},"score":"73.684326"}
{"text":"Hand DJ : Construction and assessment of classification rules Chichester , England : John Wiley & Sons 1997 .Hand DJ : Assessing Classification Rules .Journal of Applied Statistics 1994 , 21 : 3 - 16 .View Article .Fukunaga K , Hayes RR : Effect of sample size in classifier design .","label":"CompareOrContrast","metadata":{},"score":"73.77896"}
{"text":"No assumptions are made about the original distribution ( e.g. normal vs. other ) of the documents .Analysis of variance models are versatile statistical tools for studying the relation between error rates and sense distribution , sample size , and degree of difficulty of a task .","label":"CompareOrContrast","metadata":{},"score":"73.933014"}
{"text":"AAAI Fall Symp 93 98 - 107 .Hamosh A , Scott AF , Amberger J , Bocchini C , Valle D , McKusick VA : Online Mendelian Inheritance in Man ( OMIM ) , a knowledgebase of human genes and genetic disorders .","label":"CompareOrContrast","metadata":{},"score":"74.120544"}
{"text":"The final hypothesis combination uses word - level confidence scores based on an N - best homogeneity measure .These are used with the NIST ROVER program [ 1 ] to produce the final output .We first compared the effect of using the additional training data in the BNtrain98 set .","label":"CompareOrContrast","metadata":{},"score":"74.26558"}
{"text":"This stage ( pass1 ) provides a putative transcription which is used both to select an appropriate gender dependent model set for subsequent use and also to provide an initial transcription for MLLR adaptation .The MLLR processing at this stage uses one global block - diagonal mean and diagonal variance speech transform per set of clustered segments .","label":"CompareOrContrast","metadata":{},"score":"74.27634"}
{"text":"verify/277/538/96_85_43.wav .The LDC promises to provide a script to solve this problem .It should be available via anonymous ftp from ftp.cis.upenn.edu as /pub / ldc / yohosphr .prl .Note that speaker 101 said \" 53 - 73 - 79 \" instead of the prompted phrase \" 56 - 73 - 79 \" in enrollment session 2 .","label":"CompareOrContrast","metadata":{},"score":"74.34483"}
{"text":"The triphone HMMs were estimated using BNtrain97 and contained 6684 decision - tree clustered states [ 17 ] , each with 12 Gaussians per state while the quinphone models used 8180 states and 16 Gaussians per state .The HMMs were initially trained on all the wide - band analysed training data .","label":"CompareOrContrast","metadata":{},"score":"74.63878"}
{"text":"The methodology is easy to apply , it provides a principled way of studying the effects of the different factors on the error rate , and since it is based on a strong theoretical foundation , it guarantees that the results to apply to all abbreviations with similar characteristics .","label":"CompareOrContrast","metadata":{},"score":"75.03133"}
{"text":"For BPD , which has three different senses , three different multi - class SVM methods [ 47 ] : \" mc - svm \" , \" one - vs - rest \" , \" one - vs - one \" , were used . \" Mc - svm \" implements the algorithm with a decision function which considers all classes at once , while \" one - vs - rest \" and \" one - ve - one \" are constructed by combining several binary SVM classifiers .","label":"CompareOrContrast","metadata":{},"score":"75.05665"}
{"text":"Results for BSA data set .Annotation of the table : Dist : Distribution of senses ; S. Size : sample size ; Err .Rate : Error Rate ; SE : Standard Error of error rates ; CV : cross - validation ; .","label":"CompareOrContrast","metadata":{},"score":"75.1306"}
{"text":"The syntax used in the YOHO database is \" combination lock \" phrases .For example , the prompt might read : \" Say : twenty - six , eighty - one , fifty - seven .\" Where the claimant is to speak the phrase as three doublets .","label":"CompareOrContrast","metadata":{},"score":"75.36053"}
{"text":"We propose a new method for VTN in training : By using acoustic models with single Gaussian densities per state for selecting the normalization scales it is avoided that the mod ... \" .This paper presents improved methods for vocal tract normalization ( VTN ) along with experimental tests on three databases .","label":"CompareOrContrast","metadata":{},"score":"75.42032"}
{"text":"All the words in the title and abstract of the articles were used as features for machine learning and an SVM algorithm was used to generate a classifier .We used a package called \" Spider \" [ 46 ] to perform all the SVM training and testing .","label":"CompareOrContrast","metadata":{},"score":"75.47156"}
{"text":"An internal IBM vocabulary is used . domain G Switchboard ( SWB ) text ( Godfrey et al . , 1992 ) .The vocabulary consists of all words occurring at least twice in the entire data set .We provide summary ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"75.87216"}
{"text":"For acoustic training a number of US broadcast news shows ( both television and radio ) transmitted prior to June 30th 1996 were recorded and labelled by the LDC .In total episodes from 11 different shows were present in the training data .","label":"CompareOrContrast","metadata":{},"score":"75.906"}
{"text":"Results .Support Vector Machine ( SVM ) classifiers were applied to an automatically generated data set containing four ambiguous biomedical abbreviations : BPD , BSA , PCA , and RSV , which were chosen because of varying degrees of differences in their respective senses .","label":"CompareOrContrast","metadata":{},"score":"76.07128"}
{"text":"Conclusion .In this paper , we aimed to further an understanding of the different factors affecting the performance of ML techniques for WSD by systematically simulating a variety of situations where different sample size , sense distribution , degree of difficulty , and cross validation methods were used .","label":"CompareOrContrast","metadata":{},"score":"76.11737"}
{"text":"Finally the segments are clustered separately for each gender and bandwidth combination for use with MLLR adaptation .Two alternative clustering techniques have been evaluated .The first was a bottom - up method in which each segment is modelled by a single diagonal covariance Gaussian and segments are merged based on a furthest neighbour divergence - like distance measure .","label":"CompareOrContrast","metadata":{},"score":"76.12967"}
{"text":"In order for the community to make comparative assessments , please explicitly state the options selected and any variations on this suggested test plan used when publishing results .The author welcomes your results .TEST RESULTS .The author knows of six tests using the YOHO databases .","label":"CompareOrContrast","metadata":{},"score":"76.21281"}
{"text":"It applies these N(N-1)/2 SVM classifiers and the class assignment is determined by a voting strategy ( e.g. the class chose by the maximum number of SVM classifiers wins ) .The performance was measured using both a 5-fold and a 10-fold cross - validation method .","label":"CompareOrContrast","metadata":{},"score":"76.31726"}
{"text":"In our study , we proposed a simple \" full - term substitution \" method , which is described in more detail in the Methods section , to automatically generate training data , but this is only applicable for abbreviations .In this study , we used a \" full - form substitution \" method to automatically generate the data set for the experiments , which is an artificial training set .","label":"CompareOrContrast","metadata":{},"score":"76.35855"}
{"text":"To demonstrate the extent of the ambiguity problem in MEDLINE we searched MEDLINE abstracts to determine how many abstracts contained gene symbols that were ambiguous with general English words or biomedical terms .We repeated the same procedure for the fly and yeast organisms as well .","label":"CompareOrContrast","metadata":{},"score":"77.055084"}
{"text":"Dietterich TG : Approximate statistical tests for comparing supervised classification learning algorithms .Neural Computation 1998 , 10 : 1895 - 1924 .View Article PubMed .Salzberg SL : On comparing classifiers : Pitfalls to avoid and a recommended approach .","label":"CompareOrContrast","metadata":{},"score":"77.067764"}
{"text":"The Text REtrieval Conference The Text REtrieval Conference ( TREC ) series is cosponsored by the National Institute of Standards and Technology ( NIST ) and the Information Technology Office of the Defense Advanced Research Projects Agency ( DARPA ) as part of the TIPSTER Text Program .","label":"CompareOrContrast","metadata":{},"score":"77.392746"}
{"text":"The i th binary SVM classifier is trained by considering all instances associated with the i th class as positive examples and the others as negative instances .It applies the N classifiers and chooses the one with the highest confidence .","label":"CompareOrContrast","metadata":{},"score":"77.40836"}
{"text":"Large vocabulary speech recognition systems traditionally represent words in terms of subword units , usually phonemes .This paper investigates the potential of graphemes acting as subunits .In order to develop context dependent grapheme based speech recognizers several decision tree based clustering ... \" .","label":"CompareOrContrast","metadata":{},"score":"77.43683"}
{"text":"Figures 1 , 2 and 3 show the error rate versus the sample size for each distribution of the BSA , PCA and RSV data sets with 5-fold cross - validation .As the figures indicate , the reduction of the error rate as a function of the sample size is more dramatic for BSA than for PCA .","label":"CompareOrContrast","metadata":{},"score":"77.51794"}
{"text":"For instance , for some F3 segments which include a gradual fade in / out of music during a sentence , automatic segmentation improves the results .This is because the automatic segmenter chooses pause points for segmentation , leading to better recognition results .","label":"CompareOrContrast","metadata":{},"score":"77.5623"}
{"text":"For example , a male segment followed by a short female segment is merged to form a single male segment when the following segment is silence .These smoothing rules also ensure that segments with durations between three seconds and 30 seconds are created .","label":"CompareOrContrast","metadata":{},"score":"77.93931"}
{"text":"The range of sample size per sense ranges from 10 - 40 , with increments of 10 per sense .Average error rates ( Err .Rate ) and average standard errors ( SE ) were reported for each combination of distribution and sample size ( see Methods section ) .","label":"CompareOrContrast","metadata":{},"score":"78.41459"}
{"text":"Impostor results should be reported in these three categories ( see the speaker.doc file for speaker genders ) : . males vs noncohort males .females vs noncohort females .each subject vs all other noncohort subjects .The last category is a compromise because the female population is too small to perform high confidence female - only impostor testing .","label":"CompareOrContrast","metadata":{},"score":"78.43025"}
{"text":"( If the four phrases were used for separate verification tests , the independence of the tests would be weak . )The verification file structure of the disc is verify / speaker#/session#/prompted_phrase.wav .For example , speaker 101 's verification session 1320 consists of the following set of 4 speech files : . verify/101/1320/41_34_23.wav .","label":"CompareOrContrast","metadata":{},"score":"78.85457"}
{"text":"Multiple comparisons , adjusted for multiple testing , indicated that when the overall significance level is 0.1 , the sense distributions ( 0.5 , 0.5 ) and ( 0.6 , 0.4 ) impact the error rate .These results show that almost balanced sense distributions and rather large training sample sizes reduce the error rate to approximately half of our best guess , which is using the majority sense .","label":"CompareOrContrast","metadata":{},"score":"79.01382"}
{"text":"In these experiments blind relevance feedback on the document set is beneficial for the lower error rate transcriptions , but is ineffective at higher error rates .The decision to include blind relevance feedback in a system should therefore be influenced by the accuracy of recognition process .","label":"CompareOrContrast","metadata":{},"score":"79.030075"}
{"text":"The frequency within a document of a location word is then the sum of occurrences of its sub - locations ( which includes itself ) , whilst its collection frequency is the number of documents in which at least one of its sub - locations occur .","label":"CompareOrContrast","metadata":{},"score":"79.1152"}
{"text":"Splitting continues while a minimum occupancy count is exceeded in all clusters .At the end of the process , all segments which were too small to compute a full covariance robustly are assigned to the leaf node with the closest mean .","label":"CompareOrContrast","metadata":{},"score":"79.14613"}
{"text":"This table shows that around 80 % of the pure music and 15 % of the noise is classified as music and discarded .Overall 63 % of the non - speech is discarded with only 0.5 % loss of speech data .","label":"CompareOrContrast","metadata":{},"score":"79.24938"}
{"text":"It was assumed that if a user wants to retrieve documents about a general entity , then documents which are about a more specific entity which is seen as a part - of it may also be relevant .For example , if someone is trying to find information about events in the U.S. , occurrences of ' California ' within the documents should not be ignored .","label":"CompareOrContrast","metadata":{},"score":"79.27037"}
{"text":"As the Friedman 's test indicated , the effect of the sense distribution on the error rate is significant .When the sense distribution is ( 0.5 , 0.5 ) there are statistically significant differences between the pairs of error rates produced under sample size ( 20 and 120 ) , the sample sizes ( 40 and 120 ) and the sample sizes ( 80 and 120 ) .","label":"CompareOrContrast","metadata":{},"score":"79.296364"}
{"text":"Whilst on average the overall error rate produced by the quinphone models is a little better than the triphone models we have observed that the systems often make rather different errors .Therefore we made an initial attempt at combining the final quinphone output ( pass 5 ) with the best triphone stage ( pass 2/ic ) .","label":"CompareOrContrast","metadata":{},"score":"79.37422"}
{"text":"We compare the performance of acoustic data specific modelling and non - specific models on PE data ; the effect of varying the amount of acoustic training data ; the use of gender - dependent modelling ; and the effects of two automatic segmentation algorithms on recognition performance .","label":"CompareOrContrast","metadata":{},"score":"79.74454"}
{"text":"We compare the performance of acoustic data specific modelling and non - specific models on PE data ; the effect of varying the amount of acoustic training data ; the use of gender - dependent modelling ; and the effects of two automatic segmentation algorithms on recognition performance .","label":"CompareOrContrast","metadata":{},"score":"79.74454"}
{"text":"Table 1 : Critical Number of Errors --------------------------------------------Mode Target Conf Ppass e Size Crit Err .FR 1.0 % 75 % 0.7 2/3 1,080 8 .FA 0.1 % 75 % 0.7 2/3 10,802 8 .FR 0.1 % 75 % 0.5 1/2 1,386 0 .","label":"CompareOrContrast","metadata":{},"score":"79.828156"}
{"text":"The speech recognizer 's functionality is extended to include con dence annotations , which are \\meta - level \" markings that indicate how certain the recognizer is that it has decoded its input correctly .This is accomplished by feeding externally de ned error conditions back to the recognizer .","label":"CompareOrContrast","metadata":{},"score":"79.97333"}
{"text":"Error Rate versus Sample Size with different sense distributions of BSA data set .This figure shows the plots of \" error rate \" versus \" sample size \" with different sense distributions of BSA data set ( case where the 2 ambiguous senses are very different ) using 5-fold cross - validation .","label":"CompareOrContrast","metadata":{},"score":"80.04534"}
{"text":"divergence 1.01 avg rank .PROBLEMS WITH YOHO .The following files were not compressed and contain empty headers ( the speech data is intact ) ; thus , w_decode is not needed for these files : . verify/277/538/29_51_23.wav .verify/277/538/65_56_74.wav .","label":"CompareOrContrast","metadata":{},"score":"80.06988"}
{"text":"Of 2.3 million votes on optical - scan machines , 6,731 ballots were not recorded or flawed for an error rate of 0.29 percent .In the March primary , optical scan machines had an error rate of 0.12 percent , while the touch screen machines had a 1.09 percent rate of undervotes , the newspaper found .","label":"CompareOrContrast","metadata":{},"score":"80.09079"}
{"text":"For example , when the total sample size is 20 and 5-fold cross validation is used the size of the training set is 16 , while if the sample size is 80 the size of the training set is 64 .","label":"CompareOrContrast","metadata":{},"score":"80.25554"}
{"text":"For the details of the ambiguity study , please refer to the sub - section \" Gene Ambiguity for mining MEDLINE \" in the Methods section .Research in automated WSD can be traced back to the 1950s [ 15 ] .","label":"CompareOrContrast","metadata":{},"score":"80.490135"}
{"text":"The estimate of the standard error was then obtained by averaging the above values over the 30 runs .Gene ambiguity for mining MEDLINE .To determine the extent of the gene ambiguity problem in MEDLINE , we searched MEDLINE abstracts to determine how many abstracts contained gene symbols that were ambiguous with general English words or biomedical terms .","label":"CompareOrContrast","metadata":{},"score":"80.69716"}
{"text":"Four ambiguous abbreviations : BPD , BSA , PCA , and RSV , were used in this study .They were chosen because they were associated with varying degrees of differences between their respective senses .For example , two of the senses of PCA studied are very similar whereas two senses of BSA are very different .","label":"CompareOrContrast","metadata":{},"score":"80.91103"}
{"text":"For example , a sample testing set with size 20 and sense distribution ( 0.5 , 0.5 ) means 10 samples in the set are with one sense and the other 10 samples are with the other sense .The estimated sense distribution is listed in the last column of Table 1 , which is calculated based on the number of retrieved articles for each sense and the number of retrieved articles for all the senses .","label":"CompareOrContrast","metadata":{},"score":"80.91768"}
{"text":"In particular , we notice that when the sense distribution ( P1 , P2 ) was very unbalanced ( i.e. 0.9 , 0.1 ) , then the error rate was almost equal to the minority sense proportion .All these findings indicate that the effectiveness of an increase in the sample size is very dependent on the degree of difficulty .","label":"CompareOrContrast","metadata":{},"score":"81.37721"}
{"text":"The category trigram model contained 803k bigrams and 7.1 million trigrams .In use the word 4-gram lattices were rebuilt by interpolating the category trigram language model ( weight 0.30 ) with the word 4-gram ( weight 0.70 ) .","label":"CompareOrContrast","metadata":{},"score":"81.49094"}
{"text":"by Ellen Voorhees , John Garofolo , Karen Sparck Jones - In TREC-6 notebook , 1997 . \" ...The Text REtrieval Conference ( TREC ) workshops provide a forum for different groups to compare retrieval systems on common retrieval tasks .","label":"CompareOrContrast","metadata":{},"score":"81.553444"}
{"text":"Figure 4 shows plots of the error rate versus sample size for each distribution of the BPD data set based on the 5-fold cross validation using the \" one - vs - rest \" algorithm .The plots for the four different sense distributions are very similar and actually agree with results obtained indicating that the effect of the different distributions on the error rate is insignificant .","label":"CompareOrContrast","metadata":{},"score":"81.77286"}
{"text":"Approximately 3-day verification intervals .Real - world office environment .4 enrollment sessions per subject .24 phrases per enrollment session .10 verification sessions per subject .4 phrases per verification session .Total of 1,380 verification sessions . 8 kHz sampling with 3.8 kHz bandwidth .","label":"CompareOrContrast","metadata":{},"score":"82.00744"}
{"text":"Chen L , Liu H , Friedman C : Gene name ambiguity of eukaryotic nomenclatures .Bioinformatics 2005 , 21 : 248 - 256 .View Article PubMed .Schuemie MJ , Weeber M , Schijvenaars BJA , van Mulligen EM , van der Eijk CC , Jelier R , et al .","label":"CompareOrContrast","metadata":{},"score":"82.08098"}
{"text":"Smaller increases in the sample size had an insignificant effect .We performed further sub - analysis using non - parametric multiple comparisons to identify the pairs of sample sizes that differ when the abbreviations BSA and RSV were analyzed .This analysis revealed that in the case of BSA the improvements in terms of error rate were statistically significant across distributions as the sample size increased from 20 to 40 .","label":"CompareOrContrast","metadata":{},"score":"82.11038"}
{"text":"Shatkay H , Feldman R : Mining the biomedical literature in the genomic era : an overview .J Comput Biol 2003 , 10 : 821 - 855 .View Article PubMed .Fukuda K , Tamura A , Tsunoda T , Takagi T : Toward information extraction : identifying protein names from biological papers .","label":"CompareOrContrast","metadata":{},"score":"82.14401"}
{"text":"Segments which appear in the same leaf node and are temporally adjacent ( ignoring intervening silences ) are then merged into a single segment .This process corrects many of the gender misclassifications but results in long segments .The clustering is then repeated taking account of the inter - segment silences in order to obtain the final segmentation .","label":"CompareOrContrast","metadata":{},"score":"82.25909"}
{"text":"IEEE , 2003 . \" ...The performance of speech recognition systems is consistently poor on non - native speech .The challenge for non - native speech recognition is to maximize the recognition performance with small amount of non - native data available .","label":"CompareOrContrast","metadata":{},"score":"82.484375"}
{"text":"We computed the standard deviation of the error rate as follows .Recall that for each abbreviation , each sense distribution and each sample size we run the experiment 30 times .The error rate was computed using both a 5-fold and a 10-fold cross - validation scheme .","label":"CompareOrContrast","metadata":{},"score":"82.56241"}
{"text":"For example , malaria is - a disease , so the query term disease would be expanded to include malaria .Note that words which have more than one possible sense were ignored during the expansion process .A parallel corpus of 18628 documents from manually transcribed broadcast news shows was assembled .","label":"CompareOrContrast","metadata":{},"score":"82.766525"}
{"text":"Segmentation and gender labelling is applied to both the narrow - band ( T ) and wide band ( S ) data using a phone recogniser which has 45 context independent phone models per gender plus a silence / noise model .","label":"CompareOrContrast","metadata":{},"score":"82.81645"}
{"text":"Finally , the effect of the automatic segmentation procedure on the BNeval98 set was investigated .On BNeval97 we had found that automatic segmentation had produced very similar overall accuracy to manually defined segments .However on BNeval98 the automatic segmenter faired more poorly .","label":"CompareOrContrast","metadata":{},"score":"83.322914"}
{"text":"View Article PubMed .Friedman M : The use of ranks to avoid the assumption of normality implicit in the analysis of variance .Journal of the American Statistical Association 1937 , 32 : 675 - 701 .View Article .Rifkin R , Klatau A : In defense of one - vs - all classification .","label":"CompareOrContrast","metadata":{},"score":"83.4755"}
{"text":"It is useful for testing whether one random variable in a pair tends to have larger ( smaller or simply different ) values than the other random variable in the pair .In our case , the random variables in the pair are the error rates obtained under the different sample sizes used .","label":"CompareOrContrast","metadata":{},"score":"83.515625"}
{"text":"Segments which appear in the same leaf node and are temporally adjacent ( ignoring intervening silences ) are merged into a single segment .This process corrects many of the gender misclassifications but results in long segments .The clustering is then repeated taking account of the inter - segment silences in order to obtain the final segmentation .","label":"CompareOrContrast","metadata":{},"score":"83.578064"}
{"text":"Last Modified : Monday , January 17 , 2005 at 12:22 a.m. .FORT LAUDERDALE - Optical - scan machines outperformed touch screens in the general election , although both had a similar error rate , a newspaper reported Sunday .The touch - screen voting machines performed better in the Nov. 2 presidential election than they did in the March presidential preference primary , according to a South Florida Sun - Sentinel analysis .","label":"CompareOrContrast","metadata":{},"score":"83.59622"}
{"text":"A story is generally defined as a continuous stretch of news material with the same content or theme ( e.g .... . \" ...We investigate the task of performance prediction for language models belonging to the exponential family .First , we attempt to empirically discover a formula for predicting test set cross - entropy for n - gram language models .","label":"CompareOrContrast","metadata":{},"score":"83.59622"}
{"text":"Acknowledgements .This work was supported by part by Grants R01 LM7659 , R01 LM8635 from the National Library of Medicine , and Grants NSF - DMS-0504957 , NSF- IIS-0430743 from the National Science Foundation .We would like to thank Lyudmila Shagina for providing technical support .","label":"CompareOrContrast","metadata":{},"score":"83.895355"}
{"text":"The study did not examine votes cast absentee or those cast during the early voting period .A spokeswoman for Florida Secretary of State Glenda Hood said the difference between the two voting systems was not significant , noting both obtained an error rate of less than 0.5 percent in the newspaper 's analysis .","label":"CompareOrContrast","metadata":{},"score":"84.74577"}
{"text":"For PCA , the estimated distribution was ( 0.67 , 0.33 ) .Four different sample sizes were used ( 20 , 40 , 80 and 120 ) , and for each , a proportional sample for each sense was obtained based on the particular distribution .","label":"CompareOrContrast","metadata":{},"score":"84.97297"}
{"text":"Ginter F , Boberg J , Salakoski T , Salakoski T : New Techniques for Disambiguation in Natural Language and Their Application to Biological Text .Journal of Machine Learning Research 2004 , 5 : 605 - 621 .Podowski RM , Cleary JG , Goncharoff NT , Amoutzias G , Hayes WS : AZuRE , a scalable system for automated term disambiguation of gene and protein names .","label":"CompareOrContrast","metadata":{},"score":"85.634766"}
{"text":"An undervote . . .is the prerogative of the voter and not an error .\" State officials have praised the performance of touch - screen devices , touting them as the future of voting and the solution to the punch - card machines that added to the confusion of the controversial 2000 presidential election .","label":"CompareOrContrast","metadata":{},"score":"85.64368"}
{"text":"Statistical tests [ 39 , 40 ] can be used to compare different classifiers .It is very important that the baseline of a classification task is reported because it shows how much of an improvement there is using a classifier as compared to the baseline .","label":"CompareOrContrast","metadata":{},"score":"85.68067"}
{"text":"Department of Biomedical Informatics , Columbia University .Department of Biostatistics , Bioinformatics and Biomathematics , Georgetown University Medical Center .References .Krallinger M , Valencia A : Text - mining and information - retrieval services for molecular biology .Genome Biol 2005 , 6 : 224 .","label":"CompareOrContrast","metadata":{},"score":"85.929504"}
{"text":"Table 3 : Confusion matrix for audio classification ( % ) for the BNdev96ue data set .Table 3 shows a confusion matrix for the adapted models .Notice that although some of the data is labelled as noise ( N ) , the classifier does not attempt to explicitly identify noise .","label":"CompareOrContrast","metadata":{},"score":"86.445145"}
{"text":"For each combination of error rates we have a sample of 30 observations .To exemplify , assume the pair consisted of the error rates obtained under sample size 20 and 40 .Then the set of observations was comprised of those error rates obtained from the 30 simulation runs .","label":"CompareOrContrast","metadata":{},"score":"86.79706"}
{"text":"Critical Number of Errors .Likewise , as shown in Table 1 , to test the hypothesis that the actual false acceptance ( FA ) rate is less than or equal to 0.1 % at 75 % confidence requires 8 or fewer errors in 10,802 tests .","label":"CompareOrContrast","metadata":{},"score":"86.941956"}
{"text":"The Ohio secretary of state said this week that they will no longer use touch - screen machines . Copyright 2006 - 2015 Gatehouse Media , Inc.Some rights reserved . \" ...We describe a new framework for distilling information from word lattices to improve the accuracy of speech recognition and obtain a more perspicuous representation of a set of alternative hypotheses .","label":"CompareOrContrast","metadata":{},"score":"89.30172"}
{"text":"A number of natural language processing systems in the biomedical domain reported decreased precision due to the ambiguity problem [ 3 , 4 ] .Weeber [ 5 ] found that in order to replicate Swanson 's literature - based discovery of the involvement of magnesium deficiency in migraine , it was important to resolve the ambiguity of an abbreviation mg , which can denote either magnesium or milligram .","label":"CompareOrContrast","metadata":{},"score":"89.45345"}
{"text":"The evaluation was based on undervotes cast on each system .Undervotes are instances in which the voter skipped the presidential race or a choice was not tallied for reasons including machine and software error .Overvotes occur when more than one choice was recorded for a single - candidate race .","label":"CompareOrContrast","metadata":{},"score":"90.01423"}
{"text":"ACKNOWLEDGMENTS .The assistance and contributions of Ron Benincasa , Tom Crystal , Mark Forsyth , David Graff , Alan Higgins , Jerry O'Leary , Han - Sheng Liou , Qiguang Lin , Jack Porter , Scott Reider , Doug Reynolds , and Michael Schmidt are gratefully acknowledged .","label":"CompareOrContrast","metadata":{},"score":"90.99008"}
{"text":"Because of the difficulty this may cause for some , text - independent test results also can be reported using YOHO .The enrollment file structure of the disc is enroll / speaker#/session#/prompted_phrase.wav .For example , speaker 101 's enrollment session 1 phrase \" 26_81_57 \" file is .","label":"CompareOrContrast","metadata":{},"score":"91.473335"}
{"text":"For BSA , RSV and BPD , we found that the effect of the sense distribution on the error rate was insignificant .For PCA this effect was significant .The effect of different sample sizes on the error rate was significant for BSA , RSV , and BPD .","label":"CompareOrContrast","metadata":{},"score":"96.55355"}
