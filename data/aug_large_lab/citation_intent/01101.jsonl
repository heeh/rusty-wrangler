{"text":"In this regard , some or all of the basic additional interactions that take place between a computer and a human that are not present in human - human interaction may be analyzed and all or parts of the computer - human interactions may be inserted into the human - human utterance data .","label":"Background","metadata":{},"score":"23.885796"}
{"text":"Therefore , the run - time environment is designed to be able to run on a distributed computing environment with specialized CPU resources for speech recognition , text to speech , audio recording and play - back ( coded or not ) , spoken language understanding , spoken language generation and conversational models .","label":"Background","metadata":{},"score":"26.70406"}
{"text":"If it were possible to specify the input in such a way , then this would mean that the conceptual component has to provide all information needed by the grammatical component to make decisions about lexical and syntactic choices .Hence , the conceptual component would need detailed information about the language to use .","label":"Background","metadata":{},"score":"28.107208"}
{"text":"A computer implemented speech recognition method for performing Natural Language Understanding ( NLU ) functions , comprising the steps of : .( a ) converting a user utterance directly into a plurality of basic speech units without convening the utterance into a sequence of textually represented words , said user utterance being a sequence of words expressing a query or a command ; .","label":"Background","metadata":{},"score":"28.25533"}
{"text":"We describe a method and its implementation for self - monitoring during natural language generation .In situations of communication where the generation of ambiguous utterances should be avoided our method is able to compute an unambiguous utterance for a given semantic input .","label":"Background","metadata":{},"score":"28.821493"}
{"text":"This feature was implemented through a Dialog Manager ( DM ) module that provides the appropriate target function .The speech recognition task used a language model based on words .The model was obtained from a corpus having sentences the users could use .","label":"Background","metadata":{},"score":"28.95671"}
{"text":"On the contrary , with the conceptual speech recognition system of the present invention , the important issues are the concepts and the data involved in the utterance , not the discrete words used to express those concepts .The second observation is that most speech recognition systems are capable of operating with virtually any language because most , if not all , features characterizing a language ( such as the pronunciation , the vocabulary , the syntax , etc . ) can be defined in specific data files .","label":"Background","metadata":{},"score":"29.048237"}
{"text":"The drive to make the man - machine interface more user - friendly has led researchers to create machines capable of understanding spoken commands .Speech recognition systems have been built which provide good results when the speech is limited to a particular list of commands , or a specialized vocabulary .","label":"Background","metadata":{},"score":"29.32998"}
{"text":"The drive to make the man - machine interface more user - friendly has led researchers to create machines capable of understanding spoken commands .Speech recognition systems have been built which provide good results when the speech is limited to a particular list of commands , or a specialized vocabulary .","label":"Background","metadata":{},"score":"29.32998"}
{"text":"2 ) and the voice classification module 68 ( FIG .3 ) .It is to be appreciated that the static and dynamic information utilized in the models is usually distinct from any other information provided and utilized in response to the random questions , but this is not a necessary condition .","label":"Background","metadata":{},"score":"29.417587"}
{"text":"This idea assumes a large amount of human - human data , which generally is the case .Making the appropriate selection of human - human utterance data that resembles human - computer interaction , better models may be developed when little or no human - machine data is available .","label":"Background","metadata":{},"score":"30.336536"}
{"text":"a text - independent speaker recognition module ( module 52 of FIG .2 ) is utilized , text - dependent or text - prompted speaker recognition modules may also be used .Such systems are described in the Furui article ( text - dependent speaker recognition ) and in U.S. Ser .","label":"Background","metadata":{},"score":"30.354452"}
{"text":"( a ) converting a user utterance directly into a plurality of basic speech units without converting the utterance into a sequence of textually represented words , said user utterance being a sequence of words expressing a query or a command ; .","label":"Background","metadata":{},"score":"30.512642"}
{"text":"The accomplishment of these and other related objects can be achieved by a system and method which configures a speech recognition system to accept natural language utterances as input .Further , the speech recognition system can be configured to generate a compound of specific data and ' semantic identifiers ' directly as output .","label":"Background","metadata":{},"score":"30.961243"}
{"text":"Directly using the human - human utterance for training human - human data does not result in good semantic classification models because there are differences in the language patterns between human - computer and human - human conversations .The present invention seeks to process the human - human data such that it reflects the characteristics of human - machine interactions before using it for training the semantic classification model .","label":"Background","metadata":{},"score":"31.174686"}
{"text":"( b ) decoding said spoken utterance via automatic speech recognition to obtain information bearing indications of identity of the user ; .( c ) performing text - independent speaker recognition on said spoken utterance to test whether said spoken utterance was likely uttered by a person corresponding to said indications of said identity of the user ; and .","label":"Background","metadata":{},"score":"31.266802"}
{"text":"Notice in such utterances the customer besides disconfirming the understanding has restated what they want .Because human operators have better understanding abilities , such an exchange would be infrequent in human - human interaction .However , when training an NLU module , such interactions are needed in the training data .","label":"Background","metadata":{},"score":"31.659994"}
{"text":"Generally , conventional speech recognition systems that perform Natural Language Understanding ( NLU ) functions operate in two main sequential stages .In a first stage , a speech recognition unit translates speech into text which contains a transcription of a user utterance .","label":"Background","metadata":{},"score":"31.753735"}
{"text":"In this model , the application can be seen as another agent that is not limited to communicative actions .An interfacing conversational agent can participate fully in dialogue and is limited to communicative actions .Such an interfacing agent exists in the rather limited world of language and thought and can only perceive utterances said to it or passed to it from the user or the application .","label":"Background","metadata":{},"score":"31.909203"}
{"text":"If one of those pieces is missing , due to a recognition error or due to the user simply leaving the information out , the understanding component will ask the user to repeat the missing piece of information .The question and answer dialogue will continue until the understanding component is satisfied that it has all the information .","label":"Background","metadata":{},"score":"31.99556"}
{"text":"If one of those pieces is missing , due to a recognition error or due to the user simply leaving the information out , the understanding component will ask the user to repeat the missing piece of information .The question and answer dialogue will continue until the understanding component is satisfied that it has all the information .","label":"Background","metadata":{},"score":"31.99556"}
{"text":"During the monitored generation step , a previously generated ( possibly ) ambiguous utterance is parsed and the obtained alternative derivation trees are used as a ' guide ' for re - generating the utterance .To achieve such an integrated approach the underlying grammar must be reversible .","label":"Background","metadata":{},"score":"32.171925"}
{"text":"A speech recognition system for performing Natural Language Understanding , said system comprising : .( a ) a converter , said converter directly converting a user utterance into a plurality of basic speech units without converting the utterance into a sequence of textually represented words , said user utterance being a sequence of words expressing a query or a command ; .","label":"Background","metadata":{},"score":"32.71897"}
{"text":"These conventional interactions do not at all resemble a natural conversation between two humans .[ 0037 ]As in the case of the Voice Recognition Module 104 described above , in one embodiment , the Voice Generator Module 106 can be configured only to enable conversion of the 30 most common world languages .","label":"Background","metadata":{},"score":"32.766045"}
{"text":"Our results indicate that repeating or spelling a misrecognized subsection of an utterance can be an effective way of repairing more than two thirds of recognition errors .While the present invention has been described in conjunction with preferred embodiments thereof , those of ordinary skill in the art will recognize that many modifications and variations may be implemented .","label":"Background","metadata":{},"score":"32.778706"}
{"text":"Our results indicate that repeating or spelling a misrecognized subsection of an utterance can be an effective way of repairing more than two thirds of recognition errors .While the present invention has been described in conjunction with preferred embodiments thereof , those of ordinary skill in the art will recognize that many modifications and variations may be implemented .","label":"Background","metadata":{},"score":"32.778706"}
{"text":"In experiment 2 , the same speaker spoke all 390 primary utterances as well as the respoken repair utterances for those primary utterances that were misrecognized .For those experiments , the continuous speech recognition engine 14 was run in a sub - optimal mode to generate more errorful tokens over our test database .","label":"Background","metadata":{},"score":"32.86158"}
{"text":"In experiment 2 , the same speaker spoke all 390 primary utterances as well as the respoken repair utterances for those primary utterances that were misrecognized .For those experiments , the continuous speech recognition engine 14 was run in a sub - optimal mode to generate more errorful tokens over our test database .","label":"Background","metadata":{},"score":"32.86158"}
{"text":"These systems are continuous speech systems which use an understanding component to extract the meaning from the text output by a speech recognizer .Such systems sometimes incorporate another type of repair mechanism not used in the commercially available systems , namely the method of initiating a directed disambiguation dialogue .","label":"Background","metadata":{},"score":"33.033188"}
{"text":"These systems are continuous speech systems which use an understanding component to extract the meaning from the text output by a speech recognizer .Such systems sometimes incorporate another type of repair mechanism not used in the commercially available systems , namely the method of initiating a directed disambiguation dialogue .","label":"Background","metadata":{},"score":"33.033188"}
{"text":"In particular he shows that a speaker is also able to note that what she is saying involves a potential ambiguity for the hearer and can handle this problem by means of selfmonitoring .In this paper we describe an approach for self - monitoring which allows to generate unambiguous utterances in such situations where possible misunderstandings by the user have to be avoided .","label":"Background","metadata":{},"score":"33.247665"}
{"text":"The development environment incorporates an integrated suite of tools that manipulate the various application - dependent data files needed by the runtime elements .Rather than the desktop model of GUIs , spoken communication may best be viewed as involving multiple conversational agents in which the purpose of the communication is for one agent to affect the cognitive states of others .","label":"Background","metadata":{},"score":"33.340725"}
{"text":"( a ) receiving a spoken utterance of a user ; .( b ) decoding said spoken utterance via automatic speech recognition to obtain information bearing indications of identity of the user ; .( c ) performing text - independent speaker recognition on said spoken utterance to test whether said spoken utterance was likely uttered by a person corresponding to said indications of said identity of the user ; and .","label":"Background","metadata":{},"score":"33.540844"}
{"text":"The NLU system then can generate the information required to process the speech .Prior art NLU techniques have been based on this two - stage process which operates at the word level .The process compares the words of the uttered speech to words previously stored in a word vocabulary .","label":"Background","metadata":{},"score":"33.676605"}
{"text":"Furthermore , by combining the scores from the first n - best list with the scores from the second n - best list , all of the information is used from both utterances to thereby improve the chances that the speech is correctly identified .","label":"Background","metadata":{},"score":"33.796997"}
{"text":"Furthermore , by combining the scores from the first n - best list with the scores from the second n - best list , all of the information is used from both utterances to thereby improve the chances that the speech is correctly identified .","label":"Background","metadata":{},"score":"33.796997"}
{"text":"Sentence Simplification for Spoken Language Understanding - Sentence simplification may be provided .A spoken phrase may be received and converted to a text phrase .An intent associated with the text phrase may be identified .The text phrase may then be reformatted according to the identified intent and a task may be performed according to the reformatted text phrase .","label":"Background","metadata":{},"score":"34.072613"}
{"text":"It is to be appreciated that such speaker recognition process of module 52 is preferably implemented by default , regardless of the partial score(s ) achieved in the question / answer phase , in order to provide an additional measure of security with regard to service / facility access .","label":"Background","metadata":{},"score":"34.36939"}
{"text":"These and other features of the present invention will become more fully apparent from the following description and appended claims , or may be learned by the practice of the invention as set forth herein .The present invention relates to a method of exploiting human - human utterances for training a semantic classification model for use in a natural language understanding module for a spoken dialog system .","label":"Background","metadata":{},"score":"34.374577"}
{"text":"This approach may be used in conjunction with clausification ( 306 ) .Finally , the utterances that are selected are labeled and used to train the semantic classification model ( 308 ) .The process of deciding which human - human utterances to select may involve many more factors .","label":"Background","metadata":{},"score":"34.443813"}
{"text":"The plurality of basic speech units can be matched against a plurality of combinations of items wherein each item can be tagged data or a concept code .The most likely combination of items representative of the user utterance can be generated .","label":"Background","metadata":{},"score":"34.44535"}
{"text":"Automatic speech recognition is performed on ones of the utterance data not having a corresponding manual transcription to produce automatically transcribed utterances .A model is trained using all of the manually transcribed data and the automatically transcribed utterances .A predetermined number of utterances not having a corresponding manual transcription are intelligently selected and manually transcribed .","label":"Background","metadata":{},"score":"34.626358"}
{"text":"Despite these conditions , the proposed method can be used as a general application .The method can be used for speech recognition software based on grammars as well as language models .In any case , the grammars or the corpus for training the language model must be defined using the selected codes for concepts and data .","label":"Background","metadata":{},"score":"34.752205"}
{"text":"Or , the information received by the perception process from the user may be in semantic meaning form from a natural language understanding process .The information received by the perception process from the at least one application program may include at least one of keystrokes from a keyboard and selections from an application - associated menu .","label":"Background","metadata":{},"score":"34.821686"}
{"text":"2 , this occurs in the ASR module 24 of the speech layer 23 .The recognized input speech is thereby converted into a representative text word string , step 404 .This text sequence then must under go natural language understanding processing , step 405 in the NLU module 35 of the utterance layer 34 .","label":"Background","metadata":{},"score":"34.909145"}
{"text":"( ii ) a speech perception module that converts semantic meaning messages from the utterance layer into representative beliefs for the dialogue manager .A speech controlled computer user interface for communicating between a user and at least one application program , the user interface comprising : . a speech layer in communication with the user that converts between speech messages and text messages ; . an utterance layer in communication with the speech layer that conerts between text messages and semantic meaning messages ; and .","label":"Background","metadata":{},"score":"34.98145"}
{"text":"B )The prototype application using the method of the present invention was developed from the original application as described above .This was performed by replacing the speech recognition system by a conceptual speech recognition system that directly recognizes concepts and data from a user utterance .","label":"Background","metadata":{},"score":"35.01648"}
{"text":"Description .Published .SYSTEM AND METHOD OF SPOKEN LANGUAGE UNDERSTANDING USING WORD CONFUSION NETWORKS - Word lattices that are generated by an automatic speech recognition system are used to generate a modified word lattice that is usable by a spoken language understanding module .","label":"Background","metadata":{},"score":"35.068604"}
{"text":"controlling basic dialog behavior , . generating speech messages related to the actions , and .managing the various software and hardware resources .All the above problems require extensive knowledge of speech technology and natural language understanding .It is not reasonable to expect many application developers to acquire such knowledge in order to enable applications with a speech interface .","label":"Background","metadata":{},"score":"35.126244"}
{"text":"In the context of the present invention , the clausifier may clausify the text before or after the augmentation steps .The second embodiment of the invention is shown in .FIG .3 .This embodiment uses selective sampling to improve the human - human utterances for training an NLU system .","label":"Background","metadata":{},"score":"35.193756"}
{"text":"METHOD FOR BUILDING A NATURAL LANGUAGE UNDERSTANDING MODEL FOR A SPOKEN DIALOG SYSTEM - A method of generating a natural language model for use in a spoken dialog system is disclosed .The method comprises using sample utterances and creating a number of hand crafted rules for each call - type defined in a labeling guide .","label":"Background","metadata":{},"score":"35.23367"}
{"text":"The speech is recognized and converted into text .The text is transmitted to a natural language understanding ( NLU ) module 106 that determines the intent or purpose of the speech .A dialog management ( DM ) module 108 processes the received intent or purpose of the user 's speech and generates an appropriate response .","label":"Background","metadata":{},"score":"35.570732"}
{"text":"2 , the components convert between the intermediate formats - text and suprasegmentals - used by the processes in the speech layer 23 , and an utterance meaning used by the discourse layer 27 .Specifically , the natural language understanding ( NLU ) module 35 converts text from the speech layer 23 into an utterance meaning representation for the discourse layer 27 .","label":"Background","metadata":{},"score":"35.76059"}
{"text":"There is also the problem that there might be multiple , identical subpieces in the primary recognition first hypothesis .In that case , recognizing exactly what sequence of words was respoken is not enough to determine which of any identical sequences in the utterance was respoken .","label":"Background","metadata":{},"score":"35.88905"}
{"text":"There is also the problem that there might be multiple , identical subpieces in the primary recognition first hypothesis .In that case , recognizing exactly what sequence of words was respoken is not enough to determine which of any identical sequences in the utterance was respoken .","label":"Background","metadata":{},"score":"35.88905"}
{"text":"A method according to claim 18 , wherein converting between text messages and semantic meaning messages includes converting , with a natural language understanding module , text messages from the speech layer into representative semantic meaning messages for the discourse layer .","label":"Background","metadata":{},"score":"36.14019"}
{"text":"The utterances are recognized and processed by a natural language understanding module within the speech recognizer in order to identify the name of the user and the address , if available .The stream ; of acoustic features are also fed to a text - independent speaker recognition module ( such as module 52 in FIG .","label":"Background","metadata":{},"score":"36.377487"}
{"text":"[ 0033 ] The Session Manager Module 105 is equipped with set of lexicons , for particular natural languages , connected with ontology .This enables it to convert the text of natural speech into special structures containing grammatical and ontological information .","label":"Background","metadata":{},"score":"36.478767"}
{"text":"( ii ) a speech action module that converts intentions from the dialogue manager into representative semantic meaning messages for the utterance layer .A speech controlled computer user interface for communicating between a user and at least one application program , the user interface comprising : . a speech layer in communication with the user that converts between speech messages and text messages ; . an utterance layer in communication with the speech layer that conerts between text messages and semantic meaning messages ; and .","label":"Background","metadata":{},"score":"36.5438"}
{"text":"In a further embodiment , the at least one application program is other than a word processing program .Converting the spoken message to a semantic meaning message may further include converting the spoken message to a text message , then converting the text message to a semantic meaning message .","label":"Background","metadata":{},"score":"36.64669"}
{"text":"While great improvements have been made in recent years , no recognition algorithms or systems have been created which eliminate the possibility of recognition errors .If large vocabulary speech recognizers are going to be used for any tasks where exact recognition is critical , then the inevitable errors need to be eliminated in some way that is acceptable to the users of the system .","label":"Background","metadata":{},"score":"36.71039"}
{"text":"While great improvements have been made in recent years , no recognition algorithms or systems have been created which eliminate the possibility of recognition errors .If large vocabulary speech recognizers are going to be used for any tasks where exact recognition is critical , then the inevitable errors need to be eliminated in some way that is acceptable to the users of the system .","label":"Background","metadata":{},"score":"36.71039"}
{"text":"Thus , in theory , these three basic APIs are sufficient to allow a developer to create a speech - enabled application .In practice , these basic speech - related APIs are still quite low - level , and they present application developers with many difficulties .","label":"Background","metadata":{},"score":"36.736492"}
{"text":"( a ) receiving a spoken utterance of a user ; .( b ) decoding said spoken utterance via automatic speech recognition to obtain information bearing indications of identity of the user ; .( c ) performing speaker identification , via text - independent speaker recognition , on said spoken utterance to develop an estimation of said identity of the user ; and .","label":"Background","metadata":{},"score":"36.737778"}
{"text":"( c ) generating a combination of items likely to be representative of said user utterance .The method of .claim 1 , said step ( b ) further comprising : .( d ) a first step of matching said plurality of basic speech units against a vocabulary of items to generate a first list of items likely to be representative of said user utterance .","label":"Background","metadata":{},"score":"36.884155"}
{"text":"a resource manager in communication with the discourse layer that manages use of system resources by the user interface .A user interface according to claim 1 , wherein the speech layer includes at least one of : . a DTMF module that converts Dial Tone Multi - Frequency ( DTMF ) tones into representative text - based codes ; . an ASR module that converts speech signals into representative text using Automatic Speech Recognition ( ASR ) techniques ; . an SMC module that converts acoustic signals into digitally encoded speech signals using Speech / Music Compression ( SMC ) techniques ; . a concatenation module that converts text messages into electronic speech representative signals ; and .","label":"Background","metadata":{},"score":"36.910397"}
{"text":"A user interface according to claim 1 , wherein the utterance layer includes a natural language understanding module that converts text messages from the speech layer into representative semantic meaning messages for the discourse layer .A user interface according to claim 1 , wherein the utterance layer includes a message generator module that converts semantic meaning messages from the discourse layer into representative text messages for the speech layer .","label":"Background","metadata":{},"score":"36.951317"}
{"text":"Such a technique may improve the accuracy of a question answering system and may decrease the length of answers for enabling voice interface to a question answering system .Discriminating Between Natural Language and Keyword Language Items - This disclosure pertains to a classification model , and to functionality for producing and applying the classification model .","label":"Background","metadata":{},"score":"36.954807"}
{"text":"We then describe several methods for repairing or otherwise correcting the located error .Automatic Subpiece Location .This technique is used when a primary utterance 42 in FIG .3 has been spoken and the hypothesis output at step 44 by speech recognition engine 14 contains an error .","label":"Background","metadata":{},"score":"37.21432"}
{"text":"We then describe several methods for repairing or otherwise correcting the located error .Automatic Subpiece Location .This technique is used when a primary utterance 42 in FIG .3 has been spoken and the hypothesis output at step 44 by speech recognition engine 14 contains an error .","label":"Background","metadata":{},"score":"37.21432"}
{"text":"No repair is provided with this type of system .Recognition engines may be either discrete - word or continuous - speech systems .With discrete - word systems , the recognizer can only recognize a single word at a time , so the user must pause between each word until the recognizer produces the output for the last word spoken .","label":"Background","metadata":{},"score":"37.25262"}
{"text":"No repair is provided with this type of system .Recognition engines may be either discrete - word or continuous - speech systems .With discrete - word systems , the recognizer can only recognize a single word at a time , so the user must pause between each word until the recognizer produces the output for the last word spoken .","label":"Background","metadata":{},"score":"37.25262"}
{"text":"A machine - implemented method to build a library of reusable components for use in building a natural language spoken dialog system may include storing a dataset in a database .The dataset may include a group of reusable components for building a spoken dialog system .","label":"Background","metadata":{},"score":"37.286297"}
{"text":"At least one of sanitizing or anonymizing the natural language input may be performed to form a clean output .The clean output may be stored .Library of Existing Spoken Dialog Data for Use in Generating New Natural Language Spoken Dialog Systems - A machine - readable medium may include a group of reusable components for building a spoken dialog system .","label":"Background","metadata":{},"score":"37.519287"}
{"text":"Converting between text messages and semantic meaning messages may include converting , with a message generator module , semantic meaning messages into representative text messages .Processing messages may include analyzing , with a dialogue manager based on a conversational agent model , internal beliefs , intentions , and desires that are associated with the user and the at least one application , updating the beliefs , and generating new intentions .","label":"Background","metadata":{},"score":"37.803257"}
{"text":"The speaker classification is performed by doing identification with models obtained by clustering close codebooks associated with similar speakers .It is to be appreciated that , in order to implement the embodiments described herein , various existing components may be implemented .","label":"Background","metadata":{},"score":"37.810143"}
{"text":"In one aspect , active learning is employed to selectively sample the data to be re - used .A query click graph may be used to assist in determining candidate pairs for the SMT training data .All / portion of the candidate pairs may be used to train the SMT model .","label":"Background","metadata":{},"score":"37.905582"}
{"text":"FIG .1 is a block diagram of an exemplary speech recognition system according to the present invention .FIG .2 is a block diagram of exemplary elements involved in the generation of a conceptual pronunciation dictionary and a conceptual syntax module .","label":"Background","metadata":{},"score":"37.987057"}
{"text":"It should be appreciated , however , that the Voice Generator Module 106 can be configured by the system administrator to recognize any language as long as the linguistic characteristics of the language avail the language to be converted via computer processing .","label":"Background","metadata":{},"score":"38.12978"}
{"text":"Since the human - human dialogs do not represent the actual human - machine dialogs , training the semantic classifier using human - human utterances directly does not give a good model for human - machine interaction .The call - type distribution , length , perplexity and some other characteristics of human - human utterances are very different than human - machine utterances .","label":"Background","metadata":{},"score":"38.38704"}
{"text":"2 , and from the application in response to queries .From the perspective of the conversational agent , its awareness of the user includes senses without semantic meaning such as speech detection , speech output markers , too loud / silent , etc .","label":"Background","metadata":{},"score":"38.536957"}
{"text":"It should be noted that although in the present example the scores are combined simply by addition , other types of combinations are possible .Additionally , it is possible to weight scores so that certain hypotheses are preferred .For example , one might presume that in a tertiary utterance , the speaker is at this point enunciating very clearly so that the hypotheses from the tertiary utterance would be given a greater weight than hypotheses from the primary utterance .","label":"Background","metadata":{},"score":"38.541"}
{"text":"It should be noted that although in the present example the scores are combined simply by addition , other types of combinations are possible .Additionally , it is possible to weight scores so that certain hypotheses are preferred .For example , one might presume that in a tertiary utterance , the speaker is at this point enunciating very clearly so that the hypotheses from the tertiary utterance would be given a greater weight than hypotheses from the primary utterance .","label":"Background","metadata":{},"score":"38.541"}
{"text":"Because such systems recognize a whole utterance at a time , repair is performed by indicating an error , or not indicating that it was correctly recognized , and simply respeaking the whole utterance until it is recognized correctly .In addition to the above - mentioned commercial systems , there are also several research systems under development .","label":"Background","metadata":{},"score":"38.576984"}
{"text":"Because such systems recognize a whole utterance at a time , repair is performed by indicating an error , or not indicating that it was correctly recognized , and simply respeaking the whole utterance until it is recognized correctly .In addition to the above - mentioned commercial systems , there are also several research systems under development .","label":"Background","metadata":{},"score":"38.576984"}
{"text":"Another interface design is to force the user to edit the recognized text with a keyboard or mouse - based editor .Though this method may guarantee correction of the errors , it requires the user to switch input modalities to accomplish a single task , and also eliminates many of the hands - free , eyes - free benefits of a speech interface .","label":"Background","metadata":{},"score":"38.672707"}
{"text":"Another interface design is to force the user to edit the recognized text with a keyboard or mouse - based editor .Though this method may guarantee correction of the errors , it requires the user to switch input modalities to accomplish a single task , and also eliminates many of the hands - free , eyes - free benefits of a speech interface .","label":"Background","metadata":{},"score":"38.672707"}
{"text":"It is also possible to add new questions , decode and understand the answer and add this question in the pool of the random questions for next access request by the same user .It is also to be appreciated that the methods and apparatus described herein use voice prints ( speaker recognition ) , speech recognition , natural language understanding , acoustic and content analysis to build a new biometric .","label":"Background","metadata":{},"score":"38.77837"}
{"text":"In most human - machine dialogs people are co - operative and speak in short and simple sentences .This differs from human - human dialogs where people try to explain every detail of their request in the same utterance .To process the human - human utterances so that it is suitable for training the semantic classifier for human - machine dialogs , another step in the process involves clausification of the utterances ( 206 ) .","label":"Background","metadata":{},"score":"38.814995"}
{"text":"Accordingly , what is needed in the art is a more efficient way to train NLU systems using existing utterances .SUMMARY OF THE INVENTION .Additional features and advantages of the invention will be set forth in the description which follows , and in part will be obvious from the description , or may be learned by practice of the invention .","label":"Background","metadata":{},"score":"38.872314"}
{"text":"In many situations of communication a speaker need not to worry about the possible ambiguity of what she is saying because she can assume that the hearer will be able to disambiguate the utterance by means of contextual information or would otherwise ask for clarification .","label":"Background","metadata":{},"score":"38.87339"}
{"text":"( c ) generating a combination of items likely to be representative of said user utterance .The machine - readable storage of . claim 21 , said step ( b ) further comprising : .( d ) a first step of matching said plurality of basic speech units against a vocabulary of terms to generate a first list of items likely to be representative of said user utterance .","label":"Background","metadata":{},"score":"39.135025"}
{"text":"No .5,502,774 ( Bellegarda et al . ) may be employed to perform the functions of the score estimator 44 .A semantic analyzer as is disclosed in either of the articles : G. Gazdar and C. Mellish , Natural Language Processing in PROLOG - An Introduction to Computational Linguistics ( 1989 ) ; P. Jacobs and L. Rau , Innovation in Text Interpretation , Artificial Intelligence , Vol .","label":"Background","metadata":{},"score":"39.166405"}
{"text":"A speech controlled computer user interface for communicating between a user and at least one application program , the user interface comprising : . a speech layer in communication with the user that converts between speech messages and text messages ; . an utterance layer in communication with the speech layer that conerts between text messages and semantic meaning messages ; and .","label":"Background","metadata":{},"score":"39.23755"}
{"text":"A speech controlled computer user interface for communicating between a user and at least one application program , the user interface comprising : . a speech layer in communication with the user that converts between speech messages and text messages ; . an utterance layer in communication with the speech layer that conerts between text messages and semantic meaning messages ; and .","label":"Background","metadata":{},"score":"39.23755"}
{"text":"The result of the semantic analyzer 40 is sent to a score estimator 44 via link 46 where a partial score associated with the answer received from the user is generated .Also , it is to be understood that some speech recognition and natural language understanding techniques may have recognition and/or understanding errors associated therewith such that , as a result , they do not correctly recognize and/or understand the answer provided by the speaker .","label":"Background","metadata":{},"score":"39.328583"}
{"text":"During self - monitoring a generated ambigu- . 1As pointed out in Fodor ( 1983 ) one of the characteristic properties of a module is that it is computationally autonomous .But a relevant consideration of computationally autonomy is that modules do not share sources ( in our case the grammar ) .","label":"Background","metadata":{},"score":"39.35178"}
{"text":"[ 0064 ] Although a few embodiments have been described in detail herein , it should be understood , by those of ordinary skill , that the systems and methods described herein may be embodied in many other specific forms .Therefore , the present examples and embodiments are to be considered as illustrative and not restrictive , and the systems and methods described herein are not to be limited to the details provided herein , but may be modified and practiced within the scope of the appended claims .","label":"Background","metadata":{},"score":"39.373783"}
{"text":"In another embodiment , the discourse layer may include a dialogue manager based on a conversational agent model that analyzes internal beliefs , intentions , and desires that are associated with the user and the at least one application , updates the beliefs , and generates new intentions .","label":"Background","metadata":{},"score":"39.4251"}
{"text":"If , at step 55 , it is determined that the top hypothesis is correct , then speech recognition may continue if more words are to be recognized as shown by decision step 72 .If the top hypothesis is not correct , then the system goes into a repair mode as shown by the \" No \" branch coming from step 55 .","label":"Background","metadata":{},"score":"39.459118"}
{"text":"If , at step 55 , it is determined that the top hypothesis is correct , then speech recognition may continue if more words are to be recognized as shown by decision step 72 .If the top hypothesis is not correct , then the system goes into a repair mode as shown by the \" No \" branch coming from step 55 .","label":"Background","metadata":{},"score":"39.459118"}
{"text":"The user interface has a speech layer , an utterance layer , and a discourse layer .The speech layer is in communication with the user and converts between speech messages and text messages .A speech controlled computer user interface communicates between a user and at least one application program .","label":"Background","metadata":{},"score":"39.60161"}
{"text":"Deep Linking From Task List Based on Intent - Task list linking may be provided .Upon receiving an input from a user , the input may be translated into at least one actionable item .The at least one actionable item may be linked to a data source and displayed to the user .","label":"Background","metadata":{},"score":"39.67956"}
{"text":"This part of the process requires speech understanding grammars such as are known in the art , which are typically based on Backus - Naur Format ( BNF ) formalism with action linking and segment fragment tagging .These tools - e.g . , grammar checker , grammar compiler , lexicon tool , etc.-are intended to be designed by the application developer .","label":"Background","metadata":{},"score":"39.695957"}
{"text":"Another embodiment of the invention comprises a spoken dialog system generated by practicing the steps of the invention set forth herein .Yet another embodiment of the invention comprises a natural language understanding module generated according to the method set forth herein .","label":"Background","metadata":{},"score":"39.71916"}
{"text":"The following is one example of an implementation of the speaker verification principles described herein .However , it is to be appreciated that the present invention is not limited to this particular example and that one of ordinary skill in the art will contemplate many other implementations given the teachings described herein .","label":"Background","metadata":{},"score":"39.867985"}
{"text":"Translating Natural Language Utterances to Keyword Search Queries - Natural language query translation may be provided .A statistical model may be trained to detect domains according to a plurality of query click log data .Upon receiving a natural language query , the statistical model may be used to translate the natural language query into an action .","label":"Background","metadata":{},"score":"39.932068"}
{"text":"For instance , generalized speech recognition systems such as the commercially available large vocabulary Via Voice system from International Business Machines Corporation can be adapted to permit and/or perform conceptual speech recognition functions in accordance with the invention .In any case , it should be understood that the elements illustrated in .","label":"Background","metadata":{},"score":"39.964294"}
{"text":"In fact in some systems , the identity claim is often itself part of the tested utterance ; however , this does not change in any significant way the limitations of the conventional approaches .For example , a text - dependent system can not prevent an intruder from using a pre - recorded tape with a particular speaker 's answers recorded thereon in order to breach the system .","label":"Background","metadata":{},"score":"39.99444"}
{"text":"Interactive Grammar Repair . \" in Proceedings of the Workshop on Automated Acquisition of Syntax and Parsing of the 10th European Summer School in Logic , Languageand Information ( ESSLLI-1998 ) , Saarbricken , German , Aug. 1998 .Mingwen Wang , Jian - Yun Nie , A Latent Semantic Structure Model for Text Classification , 2003 .","label":"Background","metadata":{},"score":"40.022823"}
{"text":"Furthermore , another embodiment of the invention is a spoken dialog service and spoken dialog system generated according to the steps set forth herein to more efficiently develop the training data for the NLU module .Such computer - readable media can be any available media that can be accessed by a general purpose or special purpose computer .","label":"Background","metadata":{},"score":"40.04495"}
{"text":"( c ) a generator , said generator generating a combination of items likely to be representative of said user utterance .A speech recognition system for performing Natural Language Understanding , said system comprising : . an acoustic processor , said acoustic processor for receiving a user spoken utterance and directly determining a string of labels identifying a corresponding sound of said user spoken utterance without converting the utterance into a sequence of textually represented words ; . a decoder communicatively linked to said acoustic processor , said decoder determining a likely sequence of items corresponding to said determined string of labels ; . a conceptual pronunciation dictionary providing said decoder with a pronunciation of said items ; . a conceptual syntax module providing said decoder with a set of allowable combined items ; and .","label":"Background","metadata":{},"score":"40.05808"}
{"text":"( a ) receiving a first natural language spoken utterance of the user ; .( b ) decoding said first natural language spoken utterance , via natural language understanding ( NLU ) speech recognition , to obtain a first decoded utterance having factual content ; .","label":"Background","metadata":{},"score":"40.075516"}
{"text":"These sentences can be transcribed into text to make possible the association between the words used and how these words have been uttered .A statistical process can extract the required information .The transcription can be input directly to decoder 106 as text .","label":"Background","metadata":{},"score":"40.118195"}
{"text":"Utterance meaning is occasionally known in the art as context independent meaning , whereas discourse meaning is context dependent .Since the term \" context \" may be ambiguous in this setting ( although , it is not ambiguous in the setting of ASR ) , the terms utterance meaning and discourse meaning are deemed more satisfactory .","label":"Background","metadata":{},"score":"40.169716"}
{"text":"A method according to claim 55 , wherein the at least one application program is other than a word processing program .A method according to claim 55 , wherein converting the spoken message to a semantic meaning message further comprises converting the spoken message to a text message , then converting the text message to a semantic meaning message .","label":"Background","metadata":{},"score":"40.19425"}
{"text":"In another embodiment , the Voice Recognition Module 104 is configured to recognize only the languages specified by the services that are handled by the Human Understanding System 103 .It should be understood , however , that the Voice Recognition Module 104 can be configured by the system administrator to recognize any language as long as the linguistic characteristics of the language avail the language to be converted via computer processing .","label":"Background","metadata":{},"score":"40.21634"}
{"text":"More precisely , the invention discloses a method that identifies user queries or commands from the general information involved in spoken utterances directly by the speech recognition system , and not by a post - process as is conventionally used .In a phase of preparation of the system , a vocabulary of items representing data and semantic identifiers is created as well as a syntax module having valid combinations of items .","label":"Background","metadata":{},"score":"40.293137"}
{"text":"Similarly , the requested service may be automatically recognized'and different levels of security or tolerance may be established based on the type of request .Also , both approaches may be combined .The system may recognize the name and address of the speaker ; however , recognition and/or understanding errors may occur and/or a list of speakers with the same name / address may exist .","label":"Background","metadata":{},"score":"40.306904"}
{"text":"Natural language input may be received .At least one of sanitizing or anonymizing the natural language input may be performed to form a clean output .The clean output may be stored .KERNEL DEEP CONVEX NETWORKS AND END - TO - END LEARNING - Data associated with spoken language may be obtained .","label":"Background","metadata":{},"score":"40.34931"}
{"text":"The method of .claim 1 , wherein clausifying the received human - human utterances occurs before the augmenting steps .The method of .claim 1 , wherein clausifying the received human - human utterances further comprises : . detecting sentence boundaries within a speech utterance text ; . editing the speech utterance text to remove unneeded words ; and .","label":"Background","metadata":{},"score":"40.379684"}
{"text":"No . 08/788,471 , overcomes many disadvantages of the text - dependent speaker recognition approach discussed above .But there are still several issues which exist with respect to text - independent speaker recognition , in and of itself .In many applications , text - independent speaker recognition requires a fast and accurate identification of the identity of a user from among a large number of other prospective users .","label":"Background","metadata":{},"score":"40.407528"}
{"text":"Such a formation of this unique speech biometric including voice prints and knowledge based systems has , prior to this invention , been unknown since the two concepts have previously been considered substantially mutually exclusive concepts .The overall system provides a security level with an arbitrary level of security with speech and speaker recognition technology and natural language understanding .","label":"Background","metadata":{},"score":"40.423416"}
{"text":"Human - human utterances are on average three times longer than human - machine utterances and include multiple sentences and sentential clauses .The classifier performance is generally worse on utterances meant for human interaction .Long incoherent utterances , that typically contain more than one semantic class , confuse the learning algorithm , because they contain many features .","label":"Background","metadata":{},"score":"40.535004"}
{"text":"2 illustrates the repair paradigm of the present invention ; .FIG .3 is a flow chart illustrating the steps of one method performed by the speech recognition system illustrated in FIG .1 of locating a subpiece for purposes of repairing the subpiece ; .","label":"Background","metadata":{},"score":"40.541405"}
{"text":"2 illustrates the repair paradigm of the present invention ; .FIG .3 is a flow chart illustrating the steps of one method performed by the speech recognition system illustrated in FIG .1 of locating a subpiece for purposes of repairing the subpiece ; .","label":"Background","metadata":{},"score":"40.541405"}
{"text":"If the confidence score is below a predetermined threshold , the system will do nothing , and the user must repeat the command again and again until the score is above the threshold .Dictation recognition systems must handle a very large vocabulary , up to tens of thousands of possible words , because they are used for dictating text of various kinds .","label":"Background","metadata":{},"score":"40.558784"}
{"text":"If the confidence score is below a predetermined threshold , the system will do nothing , and the user must repeat the command again and again until the score is above the threshold .Dictation recognition systems must handle a very large vocabulary , up to tens of thousands of possible words , because they are used for dictating text of various kinds .","label":"Background","metadata":{},"score":"40.558784"}
{"text":"If a substantial set of candidates still exist , random questions may be used to decide who the speaker is before going through the verification process .The advantage of having a text - independent speaker recognition engine is apparent when the actual service is provided .","label":"Background","metadata":{},"score":"40.614777"}
{"text":"The present invention provides for a method and system for exploiting human - human utterances for training spoken language understanding systems .FIG .1 provides the basic modules that are used in a spoken dialog system 100 .A user 102 that is interacting with the system will speak a question or statement .","label":"Background","metadata":{},"score":"40.707657"}
{"text":"Thus , speech acts generated by one agent are perceived by the other agent , and vice versa .In a man - machine interface , one agent is human , the other one is artificial .In the SUI of a preferred embodiment , there are one or more artificial conversational agents that communicate between the user(s ) and the application(s ) .","label":"Background","metadata":{},"score":"40.79725"}
{"text":"However , as mentioned above , even if the speaker does n't provide his / her name , the system may use other information and voice characteristics to generate the list of candidates .Next , personal databases ( block 66 ) of users with names from the list are activated .","label":"Background","metadata":{},"score":"40.866287"}
{"text":"Therefore the classifier not only must learn what the important features are , it must also learn which features are associated with which class .As can be appreciated , when training a semantic classification model for an NLU module , human - human interactions , which are generally available , are not always helpful .","label":"Background","metadata":{},"score":"40.965767"}
{"text":"Description .Published .Combining active and semi - supervised learning for spoken language understanding - Combined active and semi - supervised learning to reduce an amount of manual labeling when training a spoken language understanding model classifier .The classifier may be trained with human - labeled utterance data .","label":"Background","metadata":{},"score":"40.992523"}
{"text":"( c ) performing speaker identification , via text - independent speaker recognition , on said spoken utterance to develop an estimation of said identity of the user ; and .( d ) granting access to the user if steps ( b ) and ( c ) indicate such access to be warranted .","label":"Background","metadata":{},"score":"41.070038"}
{"text":"The information received by the perception process from the at least one application program may include at least one of keystrokes from a keyboard and selections from an application - associated menu .Containing past and current beliefs may include using data frames to model a conversation .","label":"Background","metadata":{},"score":"41.082268"}
{"text":"The simplest error correction interface is to force the user to respeak the whole utterance numerous times until the recognizer identifies the proper words .That interface may be easy to design and build , but it meets with very low user acceptance due to the fact that the greater user investment of time does not lead to a greater likelihood of the error being corrected .","label":"Background","metadata":{},"score":"41.099045"}
{"text":"The simplest error correction interface is to force the user to respeak the whole utterance numerous times until the recognizer identifies the proper words .That interface may be easy to design and build , but it meets with very low user acceptance due to the fact that the greater user investment of time does not lead to a greater likelihood of the error being corrected .","label":"Background","metadata":{},"score":"41.099045"}
{"text":"A speech recognition and repair apparatus for use in a speech recognition system of the type including a recognition engine which generates an n - best list of hypotheses and scores for each hypothesis in response to the speech to be recognized , said apparatus comprising : . means for receiving from a recognition engine a first n - best list of hypotheses , and scores for each hypothesis , generated in response to a primary utterance to be recognized ; . means for locating an error within the hypothesis having the best score ; . means for generating control signals from said first n - best list , said control signals being input to the recognition engine to constrain the selection of hypotheses ; . means for receiving from the recognition engine a second n - best list of hypotheses , and scores for each hypothesis , generated in response to an event independent of the primary utterance and in accordance with said control signals ; . means for combining the scores for the hypotheses in the first n - best list with the scores for the hypotheses in the second n - best list ; and .","label":"Background","metadata":{},"score":"41.10962"}
{"text":"A speech recognition and repair apparatus for use in a speech recognition system of the type including a recognition engine which generates an n - best list of hypotheses and scores for each hypothesis in response to the speech to be recognized , said apparatus comprising : . means for receiving from a recognition engine a first n - best list of hypotheses , and scores for each hypothesis , generated in response to a primary utterance to be recognized ; . means for locating an error within the hypothesis having the best score ; . means for generating control signals from said first n - best list , said control signals being input to the recognition engine to constrain the selection of hypotheses ; . means for receiving from the recognition engine a second n - best list of hypotheses , and scores for each hypothesis , generated in response to an event independent of the primary utterance and in accordance with said control signals ; . means for combining the scores for the hypotheses in the first n - best list with the scores for the hypotheses in the second n - best list ; and .","label":"Background","metadata":{},"score":"41.10962"}
{"text":"Note that when a new speaker is enrolled , it does not affect any of the previous models .When an enrolled speaker uses the system , the acoustic features are computed and simultaneously given to the speaker identification system and to the speech recognizer .","label":"Background","metadata":{},"score":"41.148197"}
{"text":"Then , an operator manually inputs the information specific to the user into the system .Alternatively , the user may interact with a human operator who asks questions and then inputs answers to questions into the system .Still further , the user may complete a web ( internet ) question / answer form , or use e - mail , or answer questions from an IVR ( Integrated Voice Response ) system .","label":"Background","metadata":{},"score":"41.20929"}
{"text":"Application control of this process is limited to starting and stopping dialogues .The language independent conversational agent of FIG .7 is controlled by dialogue description scripts 701 .An example of a script 701 for use in conversation management is depicted in FIG . 8 .","label":"Background","metadata":{},"score":"41.36431"}
{"text":"For example , rather than dealing with the specific APIs of the ASR module 24 and the NLU module 35 , the dialog manager 32 may act through a speech understanding API that hides irrelevant ASR- and NLU - specific functionality .","label":"Background","metadata":{},"score":"41.450485"}
{"text":"System and method of exploiting human - human data for spoken language understanding systems US 7853451 B1 .Abstract .A method is disclosed for generating labeled utterances from human - human utterances for use in training a semantic classification model for a spoken dialog system .","label":"Background","metadata":{},"score":"41.51405"}
{"text":"Those substrings are then input at step 48 to speech recognition engine 14 .A secondary utterance ( a respeaking of a subpiece of the primary utterance ) 42 ' is then run through the speech recognition engine 14 at step 50 which uses the newly constructed language model .","label":"Background","metadata":{},"score":"41.521816"}
{"text":"Those substrings are then input at step 48 to speech recognition engine 14 .A secondary utterance ( a respeaking of a subpiece of the primary utterance ) 42 ' is then run through the speech recognition engine 14 at step 50 which uses the newly constructed language model .","label":"Background","metadata":{},"score":"41.521816"}
{"text":"The dialog system understands user requests when multiple users are interacting with each other as well as the dialog system .The dialog system uses multi - human conversational context to improve domain detection .Using interactions between multiple users allows the dialog system to better interpret machine directed conversational inputs in multi - user conversational systems .","label":"Background","metadata":{},"score":"41.555088"}
{"text":"These sentences must be composed of valid sequences of items ( concepts and data ) .Preferably , a trigram language model , as is well known to those skilled in the art , is trained using a transcription of a large corpus of text .","label":"Background","metadata":{},"score":"41.6463"}
{"text":"A semantic representation of the message , step 901 , is sent from the speech action process , 29 in FIG .2 , to the message generator 36 in the utterance layer 34 .In natural language generation step 902 , semantic representation 901 is converted into a message specification 903 of natural language text and suprasegmental phrases .","label":"Background","metadata":{},"score":"41.653893"}
{"text":"In such a scenario , a module substantially equivalent to the central server module may use such information as the last time the user received a facsimile on the computer , etc . , to decide whether or not to allow access .","label":"Background","metadata":{},"score":"41.726814"}
{"text":"4 could be modified to substitute the spelling recognition engine 16 in place of the speech recognition engine 14 with respect to processing of the second utterance 38 .Repairing a recognition with spelling is very similar to correction by speech .","label":"Background","metadata":{},"score":"41.92612"}
{"text":"4 could be modified to substitute the spelling recognition engine 16 in place of the speech recognition engine 14 with respect to processing of the second utterance 38 .Repairing a recognition with spelling is very similar to correction by speech .","label":"Background","metadata":{},"score":"41.92612"}
{"text":"A method as in claim 45 , wherein the information received from the user is in semantic meaning form from a natural language understanding process .A method as in claim 45 , wherein the information received by the perception process from the at least one application program includes at least one of keystrokes from a keyboard and selections from an application - associated menu .","label":"Background","metadata":{},"score":"41.964973"}
{"text":"A language identifier can initially receive linguistic input and identify the language within which such linguistic input is provided to select an appropriate machine translation component .A hybrid process , comprising machine translation components and linguistic components associated with the anchor language , can also serve as an initiating construct from which a single language process is created over time .","label":"Background","metadata":{},"score":"41.98819"}
{"text":"Upon receiving an input from a user comprising a plurality of elements , the input may be decoded into a word lattice comprising a plurality of words .A tag may be assigned to each of the plurality of words and a most - likely sequence of word - tag pairs may be identified .","label":"Background","metadata":{},"score":"42.135796"}
{"text":"For the current experiments , the first matching subpiece ( scanned in normal reading order ) in the primary recognition hypothesis was used .Though other selection criteria could be used , that simple method was found to work well for a mostly non - repetitive resource management task .","label":"Background","metadata":{},"score":"42.184784"}
{"text":"For the current experiments , the first matching subpiece ( scanned in normal reading order ) in the primary recognition hypothesis was used .Though other selection criteria could be used , that simple method was found to work well for a mostly non - repetitive resource management task .","label":"Background","metadata":{},"score":"42.184784"}
{"text":"0006 ] Traditional interaction styles of IVR systems include menus , directed dialogs , and mixed - initiative dialogs made possible by improvements in utterance recognition technology .Menu style interactions typically use pre - recorded voice prompts asking the user to press a number on a telephone keypad or speak simple answers , e.g. , \" yes , \" \" no , \" or simple numbers , to select an item from a set of choices .","label":"Background","metadata":{},"score":"42.207054"}
{"text":"A program storage device readable by machine , tangibly embodying a program of instructions executable by the machine to perform method steps for evaluating a user of one of a service and a facility , said method steps comprising : .( a ) receiving a spoken utterance of a user ; .","label":"Background","metadata":{},"score":"42.2686"}
{"text":"BRIEF DESCRIPTION OF THE DRAWINGS .For the present invention to be clearly understood and readily practiced , the present invention will be described in conjunction with the following figures wherein : .FIG .1 is a block diagram illustrating a speech recognition system having a correction and repair module constructed according to the teachings of the present invention ; .","label":"Background","metadata":{},"score":"42.320206"}
{"text":"BRIEF DESCRIPTION OF THE DRAWINGS .For the present invention to be clearly understood and readily practiced , the present invention will be described in conjunction with the following figures wherein : .FIG .1 is a block diagram illustrating a speech recognition system having a correction and repair module constructed according to the teachings of the present invention ; .","label":"Background","metadata":{},"score":"42.320206"}
{"text":"Longer utterances are not as productive or useful .The length may be determined by the number of words or the length in time or some other parameter .Therefore , this step involves ignoring utterances in a human - human utterance database that are longer than X number of words or longer than Y number of seconds .","label":"Background","metadata":{},"score":"42.52971"}
{"text":"A user interface as in claim 35 , wherein the information received by the perception process from the user is in semantic meaning form from a natural language understanding process .A user interface as in claim 35 , wherein the information received by the perception process from the at least one application program includes at least one of keystrokes from a keyboard and selections from an application - associated menu .","label":"Background","metadata":{},"score":"42.531998"}
{"text":"0017 ]FIG .5 is a diagram illustrating the generation of structures for example utterances that can take place in the session manager of FIGS . 1 and 2 in accordance with one embodiment .DETAILED DESCRIPTION .[ 0018 ] Methods and systems for interactively accessing hosted services using voice communications as described below .","label":"Background","metadata":{},"score":"42.569435"}
{"text":"As a result , .FIG .1 can be considered to include a suitable and preferred processor architecture for practicing the invention which can be achieved by programming the one or more general purpose processors .Of course , special purpose processors can be employed to implement the invention .","label":"Background","metadata":{},"score":"42.57386"}
{"text":"At the heart of the NLU is a semantic classifier .This semantic classifier is trained off - line to make such a determination using labeled utterances .Training utterances may be obtained from several different sources .For example , a company that is developing an NLU system may have recordings of communications between its call center and customers .","label":"Background","metadata":{},"score":"42.667404"}
{"text":"It is to be understood that the components described herein in accordance with the invention may be implemented in hardware , software , or a combination thereof .Preferably , the invention is implemented in software in the form of functional software modules on an appropriately programmed general purpose digital computer or computers .","label":"Background","metadata":{},"score":"42.679924"}
{"text":"Instead , the user interface is developed first .This allows human factors related to man - machine interfacing to be addressed independently of the application functionality .Many development tools are currently available that provide for convenient design of Graphical User Interfaces ( GUIs ) and easy integration with application software .","label":"Background","metadata":{},"score":"42.73156"}
{"text":"These utterances are placed in an annotation list along with a type of annotation to be performed for the utterances and an order in which the annotation should proceed .The utterances in the annotation list can be annotated for speech recognition purposes , spoken language understanding purposes , labeling purposes , etc .","label":"Background","metadata":{},"score":"42.772118"}
{"text":"A method as in claim 52 , wherein the speech - related process includes an automatic speech recognition process .A method as in claim 52 , wherein the speech - related process includes a natural language understanding process .A method for a user to use a spoken message to control at least one application program , the method comprising : . converting the spoken message to a semantic meaning message ; . processing the semantic meaning message to generate a set of commands to control the at least one application program ; and .","label":"Background","metadata":{},"score":"42.928146"}
{"text":"There are many different types of classification models and no particular model is preferable when practicing the present invention .One issue with human - human interactions is that some call types are missing .The context of a user contacting a call center of a company , such as a bank or a transportation reservation company , will be used in this description .","label":"Background","metadata":{},"score":"42.93182"}
{"text":"In another aspect of the invention , audio data is mined from at least one source , and a language model is trained for call classification from the mined audio data to produce a language model .Answer Determination for Natural Language Questioning -","label":"Background","metadata":{},"score":"43.01233"}
{"text":"A second NLU model is built using the sample utterances as new training data and using the hand crafted rules .The second NLU model is tested for performance using a first batch of labeled data .A series of NLU models are built by adding a previous batch of labeled data to training data and using a new batch of labeling data as test data to generate the series of NLU models with training data that increases constantly .","label":"Background","metadata":{},"score":"43.035942"}
{"text":"Using the automatic subpiece location method disclosed herein , there is some possibility that no subpiece will be found because wordpair language models are not strong enough to guarantee that result .A finite state grammar to constrain the search would be able to guarantee that only exact substrings are produced .","label":"Background","metadata":{},"score":"43.055283"}
{"text":"Using the automatic subpiece location method disclosed herein , there is some possibility that no subpiece will be found because wordpair language models are not strong enough to guarantee that result .A finite state grammar to constrain the search would be able to guarantee that only exact substrings are produced .","label":"Background","metadata":{},"score":"43.055283"}
{"text":"A brief explanation of the functionality of the components of the conceptual speech recognition system 100 will now be given .The acoustic processor 102 can receive speech ( a sequence of spoken words ) uttered by a speaker .The output signal of the acoustic processor 102 can be a combination of feature vectors from the input utterance and labels ( or phonemes ) from the feature vectors .","label":"Background","metadata":{},"score":"43.21503"}
{"text":"The present invention provides for a specific language covering the scope of the user 's application where the pronunciation of each word can be exactly the same as the natural language .Moreover , the spellings of the words can be codes representing concepts and tags representing data .","label":"Background","metadata":{},"score":"43.46584"}
{"text":"( c ) forming a ranked list of possible users to whom the user may correspond , based on speaker identification performed on a spoken utterance of the user ; and .( d ) searching for a match between said ranked list of possible users and members of said multi - user group .","label":"Background","metadata":{},"score":"43.473495"}
{"text":"Some queries may be set aside for testing and the model may be adapted using in - domain sentences that are not annotated .The models may be tested using these implicitly annotated natural - language - like queries in an unsupervised fashion .","label":"Background","metadata":{},"score":"43.494556"}
{"text":"In the experiments reported here , the language model used was a simple bigram model ( no unseen wordpair probability ) based only on the counts found in the appropriate subpieces of the n - best list .To find all the possible subpieces in the n - best list which were alternatives for the highlighted section of the best hypothesis , the start and end frames of the highlighted section were determined .","label":"Background","metadata":{},"score":"43.518803"}
{"text":"In the experiments reported here , the language model used was a simple bigram model ( no unseen wordpair probability ) based only on the counts found in the appropriate subpieces of the n - best list .To find all the possible subpieces in the n - best list which were alternatives for the highlighted section of the best hypothesis , the start and end frames of the highlighted section were determined .","label":"Background","metadata":{},"score":"43.518803"}
{"text":"Errors in recognized speech can be identified automatically or may be identified manually through some type of input such as the operation of a keyboard or mouse .However , errors can be automatically located by respeaking a portion of the primary utterance such that the input modality need not be changed .","label":"Background","metadata":{},"score":"43.541344"}
{"text":"Errors in recognized speech can be identified automatically or may be identified manually through some type of input such as the operation of a keyboard or mouse .However , errors can be automatically located by respeaking a portion of the primary utterance such that the input modality need not be changed .","label":"Background","metadata":{},"score":"43.541344"}
{"text":"Still further , a voice classification module 68 is accessed via link 69 .The module 68 , which performs a voice classification analysis , checks for certain voice characteristics of the caller and browses the selected databases 66 via link 67 to eliminate users who do not fit these characteristics , thus narrowing the list of possible candidates .","label":"Background","metadata":{},"score":"43.559967"}
{"text":"Based on our understanding of the various types of speech recognition systems currently sold in the marketplace , we believe that such systems may be divided into four types : recognition engines , command systems , dictation systems , and special purpose speech - driven applications .","label":"Background","metadata":{},"score":"43.57058"}
{"text":"Based on our understanding of the various types of speech recognition systems currently sold in the marketplace , we believe that such systems may be divided into four types : recognition engines , command systems , dictation systems , and special purpose speech - driven applications .","label":"Background","metadata":{},"score":"43.57058"}
{"text":"In order to maintain a modular design additional mechanisms are necessary to perform some monitoring of the generator 's output .Several authors argue for such additional mechanisms ( Jameson and Wahlster , 1982 ; De Smedt and Kempen , 1987 ; Joshi , 1987 ; Levelt , 1989 ) .","label":"Background","metadata":{},"score":"43.83345"}
{"text":"An error within the hypothesis having the highest score is located ....Locating and correcting erroneously recognized portions of utterances by rescoring based on two n - best lists US 5712957 A .Abstract .A method of repairing machine - recognized speech is comprised of the steps of receiving from a recognition engine a first n - best list of hypotheses and scores for each hypothesis generated in response to a primary utterance to be recognized .","label":"Background","metadata":{},"score":"43.849148"}
{"text":"Systems data , e.g. , for timing and statistics , includes use of rephrasing and user satisfaction control .The intentions developed by the reasoning process 705 are sent to the action process 706 which develops QLF output for action in the application and utterance meaning speech output for message generation to the user .","label":"Background","metadata":{},"score":"44.11554"}
{"text":"00480123.9 , filed Dec. 20 , 2000 at the European Patent Office .BACKGROUND OF THE INVENTION .Technical Field .The present invention relates to a speech recognition system , and more particularly , to performing Natural Language Understanding functions by directly identifying the semantic information and other information derived from a spoken utterance .","label":"Background","metadata":{},"score":"44.11714"}
{"text":"FIG .1 is a block diagram of an exemplary conceptual speech recognition system 100 according to a preferred embodiment of the present invention .The speech recognition system of .FIG .1 is shown operatively coupled to an application - specific TFIM 120 .","label":"Background","metadata":{},"score":"44.200897"}
{"text":"In the embodiment illustrated in FIG .2 , processes in the discourse layer 27 must be allocated per conversation , but processes in the other layers can be allocated at need , yielding economies in the amount of memory and CPU power required .","label":"Background","metadata":{},"score":"44.284332"}
{"text":"Thus it is seen that the correction and repair method of the present invention can be used with a variety of processes for identifying the error to be corrected .Furthermore , the method and apparatus of the present invention can be used with a wide variety of techniques for developing information to correct the machine recognized speech such as speech to speech correction , speech to spelling correction , and speech to writing correction .","label":"Background","metadata":{},"score":"44.359573"}
{"text":"Thus it is seen that the correction and repair method of the present invention can be used with a variety of processes for identifying the error to be corrected .Furthermore , the method and apparatus of the present invention can be used with a wide variety of techniques for developing information to correct the machine recognized speech such as speech to speech correction , speech to spelling correction , and speech to writing correction .","label":"Background","metadata":{},"score":"44.359573"}
{"text":"A method of communicating via a speech controlled computer user interface between a user and at least one application program , the method comprising : . converting between speech messages and text messages with a speech layer in communication with the user ; . converting between text messages and semantic meaning messages with an utterance layer in communication with the speech layer ; . wherein the analyzing with a dialogue manager includes converting , with a speech perception module , semantic meaning messages from the utterance layer into representative beliefs for the dialogue manager .","label":"Background","metadata":{},"score":"44.441902"}
{"text":"If the recognized user utterance is not classifiable to a predetermined rejection threshold , then the method transfers the user to a human as this may imply a task - specific utterance .The received and classified user utterance is then used for training the spoken dialog system .","label":"Background","metadata":{},"score":"44.479927"}
{"text":"Association for Computational Linguistics , Morristown , NJ , 162 - 173 .Rosset , S Tribout , D. , and Lamel , L. 2008 .Multi - level information and automatic dialog act detection in human - human spoken dialogs .","label":"Background","metadata":{},"score":"44.505966"}
{"text":"Also , it is to be understood that because the components of the invention described herein are preferably implemented as software modules , the actual links shown in the figures may differ depending on the manner in which the invention is programmed .","label":"Background","metadata":{},"score":"44.63833"}
{"text":"The concepts and the data can be decoded from the utterance of one or more words .The concept codes and the data tags can be as simple and short or as complex and long as required by the application .Moreover , a unique concept code can be associated with various combinations of words .","label":"Background","metadata":{},"score":"44.676136"}
{"text":"Based on the inquiry , question - answer pairs retrieved from the network are analyzed to determine a response to the inquiry .The QA pairs are not predefined .As a result , the QA pairs have to be analyzed in order to determine whether they are responsive to a particular inquiry .","label":"Background","metadata":{},"score":"44.67935"}
{"text":"( d ) granting access to the user if both said factual content of said first decoded utterance and said text - independent speaker recognition of said first natural language spoken utterance indicate such access to be warranted .A program storage device readable by machine , tangibly embodying a program of instructions executable by the machine to perform method steps for evaluating a user of one of a service and a facility , said method steps comprising : .","label":"Background","metadata":{},"score":"44.697838"}
{"text":"Field of the Invention .The present invention relates to spoken dialog systems and more specifically to a system and method of using human - human labeled utterance data for training spoken language understanding systems .Introduction .Spoken dialog systems require various components or modules to intelligently receive human speech , understand the speech and intent of the speaker , generate an appropriate response text , and synthesize an audible response .","label":"Background","metadata":{},"score":"44.717606"}
{"text":"In this way , the server 22 initially narrows the possible candidate databases from the set of databases 18 before asking any questions or accessing the voice classification module 68 .Once the list of user databases are limited by the password , then the above iterative process may be performed to identify one of the candidates or to exclude all candidates .","label":"Background","metadata":{},"score":"44.721497"}
{"text":"The vocabulary can be a collection of individual items defined during a preparatory / training phase of the system .Also , the combination of items can be selected valid combinations of items defined during the preparatory / training phase of the system .","label":"Background","metadata":{},"score":"44.774834"}
{"text":"The output of the correction and repair module 12 may also be input to a printer 34 which provides a printed copy of the recognized speech .FIG .2 shows the repair paradigm used by the correction and repair module 12 .","label":"Background","metadata":{},"score":"44.776485"}
{"text":"The output of the correction and repair module 12 may also be input to a printer 34 which provides a printed copy of the recognized speech .FIG .2 shows the repair paradigm used by the correction and repair module 12 .","label":"Background","metadata":{},"score":"44.776485"}
{"text":"The recognition engine 14 must also be able to output a segmented , scored , n - best list and/or word lattice .In our work , we have used an HMM continuous speech recognizer .The system 10 also includes a spelling recognition engine 16 .","label":"Background","metadata":{},"score":"44.786392"}
{"text":"The recognition engine 14 must also be able to output a segmented , scored , n - best list and/or word lattice .In our work , we have used an HMM continuous speech recognizer .The system 10 also includes a spelling recognition engine 16 .","label":"Background","metadata":{},"score":"44.786392"}
{"text":"It is to be appreciated that the present invention can dynamically create new questions ( from information provided in real - time ) , understand the respective answers and then use the information during the next transaction .Automatic enrollment of a new user may also be accomplished in a similar manner .","label":"Background","metadata":{},"score":"44.888824"}
{"text":"In this case , utterance length may be one of the parameters evaluated to determine whether to select a particular utterance .Other parameters may include , for example , a number of clauses selected or available , ASR confidence and NLU confidence .","label":"Background","metadata":{},"score":"45.020374"}
{"text":"The method of . claim 2 , said step ( b ) further comprising : .( e ) a second step of matching said first list of items against said plurality of combinations of items to generate said combination of items likely , to be representative of said user utterance in said step ( c ) .","label":"Background","metadata":{},"score":"45.02794"}
{"text":"Also , one of ordinary skill in the art will appreciate further variations to the above - described embodiments given the inventive teachings disclosed herein .Referring now to FIG .4 , a block diagram illustrating the possible types of information contained in a user database 18 is shown .","label":"Background","metadata":{},"score":"45.11006"}
{"text":"That problem , however , is not seen much in actual usage because humans tend to respeak a few words around the error to make it easier for other humans to locate the exact position in the utterance where the misrecognition occurred .","label":"Background","metadata":{},"score":"45.120506"}
{"text":"That problem , however , is not seen much in actual usage because humans tend to respeak a few words around the error to make it easier for other humans to locate the exact position in the utterance where the misrecognition occurred .","label":"Background","metadata":{},"score":"45.120506"}
{"text":"Preferably , the conceptual language model is an n - gram model which makes the assumption that the a - priori probability of an item sequence can be decomposed into conditional probabilities of each item given the n items preceding it .","label":"Background","metadata":{},"score":"45.137505"}
{"text":"Building upon the foregoing , the apparatus and method of the present invention can be extended to allow the user to correct the original recognition by uttering a paraphrase .Such a method is set forth in FIG .5 .In FIG .","label":"Background","metadata":{},"score":"45.221172"}
{"text":"Building upon the foregoing , the apparatus and method of the present invention can be extended to allow the user to correct the original recognition by uttering a paraphrase .Such a method is set forth in FIG .5 .In FIG .","label":"Background","metadata":{},"score":"45.221172"}
{"text":"Thereafter , the process is the same as the process shown in FIG .4 with the repair module 12 sorting according to the combined scores , displaying the new top choice , etc . .Test Results .As previously discussed , merely replacing the errorful sub - section with the top hypothesis from the secondary recognition means that all of the subpiece order information from the n - best list is unused .","label":"Background","metadata":{},"score":"45.44772"}
{"text":"Thereafter , the process is the same as the process shown in FIG .4 with the repair module 12 sorting according to the combined scores , displaying the new top choice , etc . .Test Results .As previously discussed , merely replacing the errorful sub - section with the top hypothesis from the secondary recognition means that all of the subpiece order information from the n - best list is unused .","label":"Background","metadata":{},"score":"45.44772"}
{"text":"The expectations are activated in parallel for all currently active intentions and indirectly define possible QLF events from speech .This conversation management plan is both event driven and data driven .Being event driven supports features such as mixed - initiative , barge - in capability , time - outs , and asynchronous database access .","label":"Background","metadata":{},"score":"45.49932"}
{"text":"The patent applications incorporated above provide further details regarding clausification of utterances .Clausification removes most of the noise injected in the data because of the variability in individual speaking styles .It breaks down the input into small semantically self contained clauses that can be labeled with ease and without many errors .","label":"Background","metadata":{},"score":"45.53477"}
{"text":"[ 0047 ] In step 304 , the voice recognition module can be configured to translate or convert the utterances into text that can be forwarded to Session Manager 105 in step 306 .[0048 ] Session Manager 105 can then convert the text to structures in step 308 using lexicon linked with ontology .","label":"Background","metadata":{},"score":"45.55281"}
{"text":"6 represents a sample of typical BNF grammar rules for a process according to FIG .5 .FIG .7 illustrates functional blocks of a conversational agent as used in a preferred embodiment .FIG .8 represents an example of a dialogue description script as used in the conversational agent of a preferred embodiment .","label":"Background","metadata":{},"score":"45.562958"}
{"text":"It is noted that in an embodiment , converting intentions to application messages could also be viewed as a function of the application itself .A dialogue manager 32 is in communication with and controls the other modules of the discourse layer 27 and determines answers or prompts that have to be generated based on the current state of the dialogue .","label":"Background","metadata":{},"score":"45.653557"}
{"text":"SUMMARY OF THE INVENTION .The invention disclosed herein provides a novel and more efficient way to operate a speech recognition system for Natural Language Applications wherein the specific Natural Language unit and associated computer resources are no longer required .The new speech recognition system can accept Natural Language utterances as input and directly generate the information required to process a user request .","label":"Background","metadata":{},"score":"45.923153"}
{"text":"The predicted queries are used to train a language model , such as a query language model .The query language model may be interpolated other language models , such as a background language model , as well as a feed language model trained using the content used in determining the predicted queries .","label":"Background","metadata":{},"score":"45.937904"}
{"text":"System and Method of Semi - Supervised Learning for Spoken Language Understanding Using Semantic Role Labeling - A system and method are disclosed for providing semi - supervised learning for a spoken language understanding module using semantic role labeling .The method embodiment relates to a method of generating a spoken language understanding module .","label":"Background","metadata":{},"score":"45.978134"}
{"text":"Towards the right side of FIG .2 , is a block of developments tools 39 for use in the SUI development environment .The development tools 39 include , for example , a grammar checker that enables off - line checking of grammars on test sentences .","label":"Background","metadata":{},"score":"45.98207"}
{"text":"For example , in a personal computer environment there may be various applications that are using the same microphone input channel to listen for commands simultaneously .Similarly , it is also possible to disable some applications .For example , if a dialogue is ongoing , only the active application will get focus and the commands of other applications may be temporarily disabled .","label":"Background","metadata":{},"score":"46.033836"}
{"text":"When a user calls a call center , the user talks with humans .The language patterns in these conversations differ from human - computer interactions in various ways .For example , when talking with a human , the user would not request to talk with a customer representative .","label":"Background","metadata":{},"score":"46.053738"}
{"text":"For such systems , the repair mechanisms are designed to repair only a single word at a time , and usually just the last word that has been spoken .If a recognition error occurred before the last word , the user must say \" backup \" , or some other key word , which indicates that there was an error .","label":"Background","metadata":{},"score":"46.07308"}
{"text":"For such systems , the repair mechanisms are designed to repair only a single word at a time , and usually just the last word that has been spoken .If a recognition error occurred before the last word , the user must say \" backup \" , or some other key word , which indicates that there was an error .","label":"Background","metadata":{},"score":"46.07308"}
{"text":"( a ) receiving an identity claim of the user ; .( b ) querying the user with a random question ; .( c ) receiving an answer of the user to said random question ; at least one of said identity claim and said answer being received as a spoken utterance of the user ; .","label":"Background","metadata":{},"score":"46.15483"}
{"text":"Association for Computational Linguistics , Morristown , NJ , 162 - 173 .Prasad , R. and Walker , M. 2002 .Training a Dialogue Act Tagger for human - human and human - computer travel dialogues .In Proceedings of the 3rd Sigdial Workshop on Discourse and Dialogue - vol . 2 ( Philadelphia , Pennsylvania , Jul. 11 - 12 , 2002 ) .","label":"Background","metadata":{},"score":"46.22486"}
{"text":"By checking the type of request made by the user , using additional information , if provided , and by using the acoustic match , discussed above , user identification may be established .Further , by using the random questions in addition to the acoustic identification , a more accurate identification is achieved in almost any type of environment .","label":"Background","metadata":{},"score":"46.242477"}
{"text":"In a further embodiment , the information received from the user may be provided by at least one of a speech music compression ( SMC ) process , an automatic speech recognition process ( ASR ) , and a Dial Tone Multi - Frequency ( DTMF ) process .","label":"Background","metadata":{},"score":"46.27614"}
{"text":"For example in the case of an intelligent help - system that supports the use of an operating system ( Wilensky et al . , 1984 ) , asking an inexperienced user to ' Remove the folder with the system tools ' could have tremendous effects on the system itself .","label":"Background","metadata":{},"score":"46.28295"}
{"text":"This may be accomplished in a variety of ways .The speaker may call into the system and , after making an identity claim , the system asks questions and uses the answers to build acoustic and non - acoustic models and to improve the models throughout the entire interaction and during future interactions .","label":"Background","metadata":{},"score":"46.408512"}
{"text":"With non - modal prompts , a dialogue can continue without input .In addition , internal timers may be either synchronous , in which case , the action queue is blocked for a specified time during operation , or the timers may be asynchronous , in which case , events time out after time has elapsed .","label":"Background","metadata":{},"score":"46.4152"}
{"text":"The user provides his answer to the question via link 72 and the server 22 , via the ASR 60 , uses the answer to eliminate more of the candidates .Further , the server 22 uses the user 's voice sample from the answer to run a more precise voice classification analysis via module 68 to reduce the list of candidates even further .","label":"Background","metadata":{},"score":"46.476234"}
{"text":"( c ) performing text - independent speaker recognition on said first natural language spoken utterance ; and .( d ) granting access to the user if both said factual content of said first decoded utterance and said text - independent speaker recognition of said first natural language spoken utterance indicate such access to be warranted .","label":"Background","metadata":{},"score":"46.561844"}
{"text":"( b ) accessing a database , based on said first piece of information , to identify said multi - user group ; .( c ) forming a ranked list of possible users to whom the user may correspond , based on speaker identification performed on a spoken utterance of the user ; and .","label":"Background","metadata":{},"score":"46.597153"}
{"text":"( c ) determining a most likely member of said multi - user group to whom the user corresponds , based on speaker identification performed on a spoken utterance of the user .A program storage device readable by machine , tangibly embodying a program of instructions executable by the machine to perform method steps for evaluating a user of one of a service and a facility , said method steps comprising : .","label":"Background","metadata":{},"score":"46.626755"}
{"text":"1 illustrates the general architecture of a conversational agent such as used in a preferred embodiment of the present invention .FIG .2 illustrates a block diagram of a Speech User Interface ( SUI ) according to a preferred embodiment .","label":"Background","metadata":{},"score":"46.64425"}
{"text":"Another object of the present invention is to provide a system and method which facilitates easy building of applications using limited computer resources .The invention disclosed herein further can offer improved response times .Accordingly , the invention can be used with embedded systems or in digital signal processing systems .","label":"Background","metadata":{},"score":"46.651276"}
{"text":"2 , the components deal with the acoustic nature of speech using modules for the basic speech technologies : ASR 24 , SMC 25 and TTS 26 .These either convert the acoustic signal to another representation ( text , codes ) , or generate an acoustic signal from text or codes .","label":"Background","metadata":{},"score":"46.65238"}
{"text":"A method of communicating via a speech controlled computer user interface between a user and at least one application program , the method comprising : . converting between speech messages and text messages with a speech layer in communication with the user ; . converting between text messages and semantic meaning messages with an utterance layer in communication with the speech layer ; . processing messages from the user and the at least one application program with a discourse layer in communication with the utterance layer and the at least one application program , and generating responsive messages to the user and the at least one application program ; and .","label":"Background","metadata":{},"score":"46.754875"}
{"text":"The invention also relates to nucleic acids encoding the variants of TNF family ligands , vectors and host cells comprising the nucleic acid and methods for the treatment of diseases associated with aberrant signalling through a TNF receptor .For language generation , we are using Rosetta , which is a language generation toolkit originally designed for the CMU Communicator .","label":"Background","metadata":{},"score":"46.788635"}
{"text":"An error within the hypothesis having the highest score is located ....Locating and correcting erroneously recognized portions of utterances by rescoring based on two n - best lists US 5712957 A .Rsum .A method of repairing machine - recognized speech is comprised of the steps of receiving from a recognition engine a first n - best list of hypotheses and scores for each hypothesis generated in response to a primary utterance to be recognized .","label":"Background","metadata":{},"score":"46.83772"}
{"text":"A method of communicating via a speech controlled computer user interface between a user and at least one application program , the method comprising : . converting between speech messages and text messages with a speech layer in communication with the user ; . converting between text messages and semantic meaning messages with an utterance layer in communication with the speech layer ; . wherein the analyzing with a dialogue manager includes converting , with an application perception module , application messages from the at least one application program into representative beliefs for the dialogue manager .","label":"Background","metadata":{},"score":"46.854618"}
{"text":"A more detailed explanation of the functionality of some of the components of the conceptual speech recognition system 100 is now given .The acoustic model 104 is built and trained by analyzing speech samples of hundreds of speakers .The model contains a collection of acoustic prototypes .","label":"Background","metadata":{},"score":"46.871376"}
{"text":"( e ) performing speaker recognition on said at least one of said identity claim and said answer which is received as said spoken utterance ; and .( f ) granting access to the user if steps ( d ) and ( e ) indicate such access to be warranted .","label":"Background","metadata":{},"score":"46.889626"}
{"text":"( e ) performing speaker recognition on said at least one of said identity claim and said answer which is received as said spoken utterance ; and .( f ) granting access to the user if steps ( d ) and ( e ) indicate such access to be warranted .","label":"Background","metadata":{},"score":"46.889626"}
{"text":"The present invention relates to the training process to generate the NLU module 106 .The basic operation of the spoken dialog system 100 may be on a single server or in a client / server environment .It is immaterial to the present invention whether all the modules are processed on a single server , numerous servers , or on various nodes within a network like the world - wide - web or a wireless network .","label":"Background","metadata":{},"score":"46.970406"}
{"text":"In this case , the new user is then prompted with an enrollment menu in order to perform the enrollment process .Different embodiments may be employed for the text - independent speaker verifier .Again , the feature vectors ( obtained as the output of the acoustic front - end ) are of the mel cepstral , delta , and delta - delta type ( including C0 energy ) .","label":"Background","metadata":{},"score":"47.000572"}
{"text":"There are also commercially available special purpose speech - driven applications .We have seen such applications developed for particular fields such as the medical and legal field .Such special - purpose applications may be set up to generate medical reports or complete legal forms .","label":"Background","metadata":{},"score":"47.035526"}
{"text":"There are also commercially available special purpose speech - driven applications .We have seen such applications developed for particular fields such as the medical and legal field .Such special - purpose applications may be set up to generate medical reports or complete legal forms .","label":"Background","metadata":{},"score":"47.035526"}
{"text":"Using general topic segmentation methods , as well as the specific domain detector trained with conversational inputs collected by a single user system , allows the dialog system to better determine the relevant context .The use of conversational context helps reduce the domain detection error rate , especially in certain domains , and allows for better interactions with users when the machine addressed turns are not recognized or are ambiguous .","label":"Background","metadata":{},"score":"47.045532"}
{"text":"The multitask learning method aims at training tasks in parallel while using a shared representation .A computing device automatically re - uses the existing labeled data from various applications , which are similar but may have different call - types , intents or intent distributions to improve the performance .","label":"Background","metadata":{},"score":"47.06907"}
{"text":"The digitized speech signal 906 is transformed ( block not shown ) into an analog speech signal 907 comprehensible to the user .The present invention discloses a computer - implemented method to understand queries or commands spoken by users when they use natural language utterances similar to those that people use spontaneously to communicate .","label":"Background","metadata":{},"score":"47.073547"}
{"text":"The simpler the question , the more likely it is that the actual user will not be denied access simply because he forgot his answers .Still further , for a frauder to know the answers to all the questions will not help gain access to the service or facility , since if the frauder has a different speech rate or voice print , for example , then the identification and verification claim will fail .","label":"Background","metadata":{},"score":"47.086266"}
{"text":"Only unique substrings were used to determine the counts for the bigram language model .The original subpiece ( known to contain at least one error ) is also excluded from the language model data so that it can not reoccur .","label":"Background","metadata":{},"score":"47.20391"}
{"text":"Only unique substrings were used to determine the counts for the bigram language model .The original subpiece ( known to contain at least one error ) is also excluded from the language model data so that it can not reoccur .","label":"Background","metadata":{},"score":"47.20391"}
{"text":"( i ) a dialogue manager based on a conversational agent model that analyzes internal beliefs , intentions , and desires that are associated with the user and the at least one application , updates the beliefs , and generates new intentions , and .","label":"Background","metadata":{},"score":"47.249367"}
{"text":"Communicating with the various internal processes through standard APIs is preferred so that replacing components or updating versions is simplified .Moreover , use of standard existing APIs within the SUI is appropriate because the SUI architecture has to incorporate existing system architectures for ASR , TTS and SMC , and has to define extensions for spoken language understanding , spoken language generation and conversation modeling .","label":"Background","metadata":{},"score":"47.29164"}
{"text":"C++ expressions are copied to generated code which are referred to by index for evaluation as either a numeric or a string .Based on the dialogue description scripts 701 , meaning is interpreted in context according to the inputs received in the perception processes 702 .","label":"Background","metadata":{},"score":"47.42677"}
{"text":"Conversational agent awareness of the application also includes application events such as keyboard strokes and menu .Conversation data 703 related to open instances of dialogue is maintained .Each user conversation is modeled as a sequence of several smaller dialogues .","label":"Background","metadata":{},"score":"47.441303"}
{"text":"3 illustrates a portion of a typical user session with a preferred embodiment .FIG .4 illustrates the conceptual transformations occurring when the user provides an input message using the SUI .FIG .5 depicts the conversion of representative text into a language independent semantic representation of utterance meaning .","label":"Background","metadata":{},"score":"47.49054"}
{"text":"Still further , the automatic nature of the invention permits the building of a user profile for any purpose including the possibility of having other self - enrolling , self - validating and/or self - updating biometrics ( e.g. , face patterns for face recognition , iris recognition , etc . ) .","label":"Background","metadata":{},"score":"47.50727"}
{"text":"Each concept 508 is connected to a plurality of lexemes in each lexicon 210 , because in natural language communication , there are many synonyms and different ways of communicating the same concept .[ 0055 ] Still referring to FIG .","label":"Background","metadata":{},"score":"47.52989"}
{"text":"The value , or rank is an indication of how strongly the data provided corresponds to this information .The task of determining whether the data is included and providing a value or rank can fall to Special Concepts Processor 230 .","label":"Background","metadata":{},"score":"47.535286"}
{"text":"FIG .2 , involves augmenting the data with the missing or infrequent call types ( 202 ) .The call types used to augment the data may be borrowed from other applications or separately developed .The process next involves augmenting the utterances themselves ( 204 ) .","label":"Background","metadata":{},"score":"47.55291"}
{"text":"A method according to claim 57 , wherein converting between text messages and semantic meaning messages includes converting , with a natural language understanding module , text messages into representative semantic meaning messages .A method according to claim 57 , wherein converting between text messages and semantic meaning messages includes converting , with a message generator module , semantic meaning messages into representative text messages .","label":"Background","metadata":{},"score":"47.553806"}
{"text":"The action queue also maintains an historical record of executed actions to enable later rephrasings .Further details of the conversation management plan depicted in FIG .7 include the internal use of prompts which may be either modal or non - modal .","label":"Background","metadata":{},"score":"47.633575"}
{"text":"It should be noted that this exchange between the application and the SUI is asynchronous , the application is always in control of the process .The user may now speak over the phone with the application by way of the SUI in natural language exchanges .","label":"Background","metadata":{},"score":"47.67243"}
{"text":"5 .It is further to be understood that P(acoustic data speaker i ) may be computed using some acoustic models for speakers that may be represented as Hidden Markov Models ( HMM ) .In , . another embodiment , one can interpret P(speaker i ) as a weighted factor and update a general speaker score using a known formula .","label":"Background","metadata":{},"score":"47.73243"}
{"text":"The results of both recognitions 36 and 40 are then used to locate and/or repair the original error such that utterance 20 \" is the same as primary utterance 20 as shown in recognition 41 .Before an error can be corrected , the error must be located .","label":"Background","metadata":{},"score":"47.77953"}
{"text":"The results of both recognitions 36 and 40 are then used to locate and/or repair the original error such that utterance 20 \" is the same as primary utterance 20 as shown in recognition 41 .Before an error can be corrected , the error must be located .","label":"Background","metadata":{},"score":"47.77953"}
{"text":"A method of communicating via a speech controlled computer user interface between a user and at least one application program , the method comprising : . converting between speech messages and text messages with a speech layer in communication with the user ; . converting between text messages and semantic meaning messages with an utterance layer in communication with the speech layer ; . wherein the analyzing with a dialogue manager includes receiving , with a perception process , information from the user and the at least one application program and generating beliefs representative of current states of the user and the at least one application program .","label":"Background","metadata":{},"score":"47.786915"}
{"text":"The actual method of asking the questions is not critical to the invention .Alternatively , it is to be appreciated that at least a portion of the answers provided by the potential user may be in a form other than speech , i.e. , text format , keyed - in information , etc . .","label":"Background","metadata":{},"score":"47.836426"}
{"text":"143 - 191 ( 1993 ) ; W. Zadrozny et al . , \" Natural Language Understanding with a Grammar of Constructions \" , Proceedings of the International Conference on Computational Linguistics ( August 1994 ) .Clarisse Tur , Cleveland , OH US .","label":"Background","metadata":{},"score":"47.986004"}
{"text":"0007 ] Despite these advances , conventional IVRs still tend to be slow , impersonal , and offer a cumbersome platform for assisting interactions between the system and the user .Maneuvering through a maze of menu options and choices on the phone tends to be very time consuming and the voice command recognition / understanding features of directed and mixed - initiative dialog systems are not designed to effectively handle voice commands that are not responsive to scripted questions .","label":"Background","metadata":{},"score":"48.001965"}
{"text":"The speaker verification phase is implemented as a vector quantizer decoder .On a frame by frame basis , the closest codebook is identified or the N closest codebooks are ranked .An histogram is created which counts how many frames have selected each codebook .","label":"Background","metadata":{},"score":"48.108936"}
{"text":"FIG .1 represents a basic spoken dialog system ; .FIG .2 illustrates a method according to first embodiment of the present invention ; and .FIG .3 illustrates a method according to a second embodiment of the invention .","label":"Background","metadata":{},"score":"48.163055"}
{"text":"One of ordinary skill in the art will appreciate further variations to the above - described embodiments given the inventive teachings disclosed herein .Referring now to FIG .3 , another embodiment of the invention , illustrated via a flow chart / block diagram , is shown .","label":"Background","metadata":{},"score":"48.21071"}
{"text":"The method of . claim 21 , wherein step ( a ) comprises receiving said spoken utterance of the user as at least one of a static feature and a dynamic feature .The method of . claim 21 , wherein : . step ( a ) comprises receiving said spoken utterance of said user as indicative of a subset of users having more than one member ; and . step ( b ) comprises decoding said spoken utterance to obtain said information , said information bearing indications of membership of the user in said subset .","label":"Background","metadata":{},"score":"48.310593"}
{"text":"0002 ] The embodiments disclosed in this application generally relate to an interactive voice response system , and more particularly , systems and methods that enable voice communication access to hosted services , e.g. , shops , car rentals , motels etc . , via telephony .","label":"Background","metadata":{},"score":"48.332672"}
{"text":"The speech layer is in communication with the user and converts between speech messages and text messages .The utterance layer is in communication with the speech layer , and converts between text messages and semantic meaning messages .The discourse layer is in communication with the utterance layer and the at least one application program , and processes messages from the user and the at least one application program , and generates responsive messages to the user and the at least one application program .","label":"Background","metadata":{},"score":"48.35222"}
{"text":"2 presents a more detailed overview of a preferred embodiment of the SUI .The run - time environment of the SUI is shown towards the center of FIG .2 .The right side of FIG .2 has a collection of tools which interact with the SUI in the design environment and which access many of the databases with application - specific data that the SUI components use at run time .","label":"Background","metadata":{},"score":"48.409706"}
{"text":"Thus , the SUI is well - suited for dialogues with medium to high complexity such as with quasi - spontaneous input .Typical applications include command & control , data retrieval for information systems , and data entry such as for reservation systems .","label":"Background","metadata":{},"score":"48.411484"}
{"text":"The machine - readable storage of .claim 29 , further comprising : . defining said plurality of combinations of items of said step ( c ) in a training step .The machine - readable storage of . claim 21 , further comprising : . storing a set of prototype acoustic models obtained from a training phase , wherein each said acoustic model represents one or more possible basic speech units of an utterance of a word .","label":"Background","metadata":{},"score":"48.451283"}
{"text":"All the input feature vectors are clustered in a set of about 65 codewords .Typically , about 10 seconds of speech are required for enrollment .This is easily obtained as the new user enrolls all of his aliases .However , when the user interacts with the system rather than for the purpose of enrolling his aliases , data obtained may be used to build acoustic models of the voice prints .","label":"Background","metadata":{},"score":"48.59584"}
{"text":"Because of these reasons , use of clausification enables development of better semantic classification models .Since clausifiers are general purpose tools they can be used across applications .A clausifier may be comprised of several components : a sentence boundary classifier detects sentence boundaries within a speech utterance text , an editing classifier edits the speech utterance text to remove unneeded words and a conjunction classifier detects conjunctions within the speech utterance text .","label":"Background","metadata":{},"score":"48.599506"}
{"text":"Many ways for communicating the random questions to the user may be envisioned by one of ordinary skill in the art .For instance , if the user is attempting to access the service / facility through a web page , the questions may be presented in text form .","label":"Background","metadata":{},"score":"48.76649"}
{"text":"Log data associated with a search engine , each associated with a search query , may be received .A domain label for each search query may be identified and the domain label and link data may be provided to a training set for a spoken language understanding model .","label":"Background","metadata":{},"score":"48.788532"}
{"text":"4 is a flow chart illustrating the steps of one method performed by the speech recognition system illustrated in FIG .1 of repairing machine - recognized speech based on the error being respoken ; and .FIG .5 is a flow chart illustrating the steps of another method performed by the speech recognition system illustrated in FIG .","label":"Background","metadata":{},"score":"48.90878"}
{"text":"4 is a flow chart illustrating the steps of one method performed by the speech recognition system illustrated in FIG .1 of repairing machine - recognized speech based on the error being respoken ; and .FIG .5 is a flow chart illustrating the steps of another method performed by the speech recognition system illustrated in FIG .","label":"Background","metadata":{},"score":"48.90878"}
{"text":"Description .BACKGROUND OF THE INVENTION .Field of the Invention .The present invention is directed generally to speech recognition systems , and more particularly to a method and apparatus for correcting and repairing speech recognized by such speech recognition systems .","label":"Background","metadata":{},"score":"48.925213"}
{"text":"Description .BACKGROUND OF THE INVENTION .Field of the Invention .The present invention is directed generally to speech recognition systems , and more particularly to a method and apparatus for correcting and repairing speech recognized by such speech recognition systems .","label":"Background","metadata":{},"score":"48.925213"}
{"text":"A user interface as in claim 35 , wherein the acting process includes using artificial speech .A user interface as in claim 35 , wherein the acting process includes an acting queue that sequences the information provided by the acting process .","label":"Background","metadata":{},"score":"48.941032"}
{"text":"The method of .claim 25 , wherein step ( a ) comprises receiving said spoken utterance of the user as at least one of a static feature and a dynamic feature .The method of .claim 25 , wherein : . step ( a ) comprises receiving said spoken utterance of said user as indicative of a subset of users having more than one member ; and . step ( b ) comprises decoding said spoken utterance to obtain said information , said information bearing indications of membership of the user in said subset .","label":"Background","metadata":{},"score":"48.999424"}
{"text":"Questions of the QA pairs may be repetitive and , without more , will not be useful in determining whether their corresponding answer responds to an inquiry .Preserving Privacy in Natural Language Databases - An apparatus and a method for preserving privacy in natural language databases are provided .","label":"Background","metadata":{},"score":"49.05092"}
{"text":"Thus , compared with prior art speech application interfaces , the SUI is more user - friendly and has greater functionality and flexibility .In its simplest form , a preferred embodiment of the SUI need only support limited performance capabilities sufficient for tasks such as command and control with restricted speech .","label":"Background","metadata":{},"score":"49.085644"}
{"text":"Accordingly , FIG .1 should not be seen as limiting the systems and methods described herein to a certain architecture or configuration .Rather , FIG .1 is presented by way of example only .[0031 ]In one embodiment , the Voice Recognition Module 104 is configured to recognize the 30 most common languages of the world .","label":"Background","metadata":{},"score":"49.11846"}
{"text":"The system of claim 20 , wherein the session manger is further configured to perform the service by storing the information included in the utterance and associated with the special concepts .Description : .[ 0001 ] 1 .Technical Field .","label":"Background","metadata":{},"score":"49.156204"}
{"text":"The estimation of the static parameters S j and dynamic parameters D k are respectively done in blocks 210 and 212 .Additional special parameters can be introduced in the set S j .Such parameters may be vocabulary , prosody , speech rate , accent , etc .","label":"Background","metadata":{},"score":"49.17984"}
{"text":"Control signals are generated from the first n - best list which are input to the recognition engine to constrain the generation of a second n - best list of hypotheses , and scores for each hypothesis , in response to an event independent of the primary utterance .","label":"Background","metadata":{},"score":"49.210037"}
{"text":"Control signals are generated from the first n - best list which are input to the recognition engine to constrain the generation of a second n - best list of hypotheses , and scores for each hypothesis , in response to an event independent of the primary utterance .","label":"Background","metadata":{},"score":"49.210037"}
{"text":"Most have a small , fixed vocabulary of between ten and one hundred commands that can be recognized in any one situation .None of the command - based systems of which we are aware has any kind of repair mechanism for repairing incorrect recognition .","label":"Background","metadata":{},"score":"49.233654"}
{"text":"Most have a small , fixed vocabulary of between ten and one hundred commands that can be recognized in any one situation .None of the command - based systems of which we are aware has any kind of repair mechanism for repairing incorrect recognition .","label":"Background","metadata":{},"score":"49.233654"}
{"text":"The use of a semantic role labeling approach to the extraction of the answers to an open domain factoid ( Who / When / What / Where ) natural language question that contains a predicate is described .Semantic role labeling identities predicates and semantic argument phrases in the natural language question and the candidate sentences .","label":"Background","metadata":{},"score":"49.254013"}
{"text":"When a segment of a speech is input to the conceptual speech recognition system 100 , the acoustic processor 102 examines the uttered speech in successive time intervals and a label is assigned to the interval based on a prototype of the acoustic model which is the closest .","label":"Background","metadata":{},"score":"49.2645"}
{"text":"The semantic representation of the utterance meaning , step 406 in FIG .4 , is the output from the utterance layer 34 of the SUI that is input into the discourse layer 27 of FIG .2 .Within the discourse layer 27 , the SUI performs conversation management utilizing conversational agents , depicted generally in FIG .","label":"Background","metadata":{},"score":"49.35665"}
{"text":"The machine - readable storage of . claim 21 , further comprising : . sending said most likely combination of items to a function identification module to perform said user query or command .Description .CROSS - REFERENCE TO RELATED APPLICATIONS .","label":"Background","metadata":{},"score":"49.387905"}
{"text":"The present invention solves the foregoing problems by providing a method and apparatus for repairing speech recognized by a recognition engine of the type which generates an n - best list of hypotheses and scores for each hypothesis in response to the speech to be recognized .","label":"Background","metadata":{},"score":"49.426426"}
{"text":"The present invention solves the foregoing problems by providing a method and apparatus for repairing speech recognized by a recognition engine of the type which generates an n - best list of hypotheses and scores for each hypothesis in response to the speech to be recognized .","label":"Background","metadata":{},"score":"49.426426"}
{"text":"Previously , application developers desiring to integrate speech capabilities into their applications have had to acquire a significant body of knowledge related to the various necessary speech technologies .At best , a separate application programming interface ( API ) might be used for each specific speech capability such as automatic speech recognition ( ASR ) , text - to - speech ( TTS ) , and speech / music compression ( SMC ) .","label":"Background","metadata":{},"score":"49.449326"}
{"text":"A computing device automatically re - uses the existing labeled data from various applications , which are similar but may have different call - types , intents or intent distributions to improve the performance .An automated intent mapping algorithm operates across applications .","label":"Background","metadata":{},"score":"49.482773"}
{"text":"4 is a block diagram illustrating a user database according to the invention ; and .FIG .5 is a flow chart / block diagram illustrating the generation of a user model according to the invention .DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS .","label":"Background","metadata":{},"score":"49.491398"}
{"text":"176 , Vol .However , other methods of implementing natural language understanding may be employed .Furthermore , a voice classification module such as is disclosed in either U.S. Ser .No . 08/787,031 or the patent application entitled , \" Speaker Recognition Over Large Population with Combined Fast and Detailed Matches \" , filed on May 6 , 1997 , may be employed to perform the functions of the voice classification module 68 .","label":"Background","metadata":{},"score":"49.54924"}
{"text":"A plurality of log data associated with an intent may be received , and at least one step associated with completing the intent according to the plurality of log data may be identified .An understanding model associated with the intent may be created , including a plurality of queries mapped to the intent .","label":"Background","metadata":{},"score":"49.593483"}
{"text":"Description .Published .APPARATUS AND METHOD FOR MODEL ADAPTATION FOR SPOKEN LANGUAGE UNDERSTANDING - An apparatus and a method are provided for building a spoken language understanding model .Labeled data may be obtained for a target application .A new classification model may be formed for use with the target application by using the labeled data for adaptation of an existing classification model .","label":"Background","metadata":{},"score":"49.595253"}
{"text":"The data can be marked with tags used to distinguish different kinds of data .The semantic identifiers or concepts can be represented by concept codes .The tags and the concept codes can be defined during a preparation / training phase of the system and can be chosen independently of the language used in the application .","label":"Background","metadata":{},"score":"49.626682"}
{"text":"Then , based only on the scores achieved by the answers received to the questions , the server 22 makes a determination whether or not to permit access to the caller .However , the system collects voice samples from the caller 's answers to the plurality of questions and builds a user voice model ( e.g. , user model 20 ) therefrom .","label":"Background","metadata":{},"score":"49.72574"}
{"text":"At step 70 , the user decides if the new top choice is correct .If yes , the process proceeds with decision step 72 .If the new top choice is not correct , the process returns to step 62 where the secondary utterance is respoken .","label":"Background","metadata":{},"score":"49.783154"}
{"text":"At step 70 , the user decides if the new top choice is correct .If yes , the process proceeds with decision step 72 .If the new top choice is not correct , the process returns to step 62 where the secondary utterance is respoken .","label":"Background","metadata":{},"score":"49.783154"}
{"text":"The various processes in a preferred embodiment do not all need to be instantiated per interface channel .Only the processes in the discourse layer 27 need to maintain data during an entire conversation .The other processes are not even active during large parts of the conversation .","label":"Background","metadata":{},"score":"49.786118"}
{"text":"A dialogue tracer visualizes the state of a dialogue , allows dialogue debugging , provides debugging facilities , and provides development facilities .A preferred embodiment is not limited to interfacing a single application , but may support multiple applications per channel .","label":"Background","metadata":{},"score":"49.820667"}
{"text":"The classifier may be changed , via semi - supervised learning , based on the selected ones of the unselected utterance data .Gokhan Tur , Castro Valley , CA US .Patent application number .Description .Published .Multitask Learning for Spoken Language Understanding - A system , method and computer - readable medium provide a multitask learning method for intent or call - type classification in a spoken language understanding system .","label":"Background","metadata":{},"score":"49.87192"}
{"text":"Further , the invention may be implemented in an internet environment in which case various portions of the invention may reside at the user 's location and/or the service providers location .Referring now to FIG .2 , one embodiment of the invention , illustrated via a flow chart / block diagram , is shown .","label":"Background","metadata":{},"score":"49.88974"}
{"text":"The SUI supports multi - modal applications , barge - in , and asynchronous message - based communication are supported , resulting in robust applications .Also included are development and testing tools for easy design and debugging of dialogues .A language independent description language is employed for conversation management which is modular and easily reusable .","label":"Background","metadata":{},"score":"49.91301"}
{"text":"SUMMARY OF THE INVENTION .A preferred embodiment of the present invention provides a speech controlled computer user interface for communicating between a user and at least one application program .As used herein and in the accompanying claims , \" communicating between \" means communications from the user to the at least one application program , communications from the at least one application program to the user , and/or both ways .","label":"Background","metadata":{},"score":"49.961643"}
{"text":"That location could be determined , for example , with the use of the mouse 32 highlighting an errorful subsection of the recognition .In FIG .3 , we describe how to accomplish that highlighting by voice only , requiring the user to respeak only the errorful subsection of the primary utterance 42 .","label":"Background","metadata":{},"score":"49.97515"}
{"text":"That location could be determined , for example , with the use of the mouse 32 highlighting an errorful subsection of the recognition .In FIG .3 , we describe how to accomplish that highlighting by voice only , requiring the user to respeak only the errorful subsection of the primary utterance 42 .","label":"Background","metadata":{},"score":"49.97515"}
{"text":"At the beginning of the conversation between the user and the central server , the speaker will provide his name and some information such as his address or the object of his request .An acoustic front - end in the speech recognizer ( such as ASR 28 in FIG .","label":"Background","metadata":{},"score":"49.986847"}
{"text":"Voice - based verification systems are especially useful when it is necessary to identify a user who is requesting telephone access to a service / facility but whose telephone is not equipped with the particular pushbutton capability that would allow him to electronically send his identification password .","label":"Background","metadata":{},"score":"50.10351"}
{"text":"The method of .claim 1 , wherein the data that relates to call - type gaps used to augment the received human - human utterances is borrowed from other spoken dialog system applications .The method of .claim 4 , wherein the other spoken dialog system applications have a related function to the spoken dialog system .","label":"Background","metadata":{},"score":"50.165718"}
{"text":"claim 32 , further comprising : . assigning one of said acoustic models to each said basic speech unit .The machine - readable storage of . claim 21 , wherein said user utterance is in the form of isolated data .","label":"Background","metadata":{},"score":"50.17044"}
{"text":"A user interface according to claim 11 , wherein the dialogue manager uses a planning process in communication with the beliefs knowledge base that determines how to change a current state to attain another possible state .A user interface according to claim 12 , wherein the discourse layer includes a desires knowledge base that contains goals for the dialogue manager to determine a desirability of alternate possible states .","label":"Background","metadata":{},"score":"50.284855"}
{"text":"If the score does not fall within the above preferred range , then access may be denied to the speaker , the process may be repeated in order to obtain a new score , or a system provider may decide on another appropriate course of action .","label":"Background","metadata":{},"score":"50.477238"}
{"text":"The selected databases contain personal user data , such as age , profession , family status , etc . , as well as information about the user 's voice , such as prototypes , prosody , speech rate , accent , etc .","label":"Background","metadata":{},"score":"50.54525"}
{"text":"1 , the Human Understanding System 103 includes the following : a Voice Recognition Module 104 , a Voice Generator Module 106 , and a Session Manager module 105 .The Voice Recognition Module 104 can be configured to receive utterance from a user 101 via a telephony device 102 that is communicatively linked to the Human Understanding System 103 , e.g. , using any of the telephony communication configurations described above .","label":"Background","metadata":{},"score":"50.559555"}
{"text":"The complete transaction is monitored so that possible problems can be detected in using this large amount of data and flags are raised for further processing for action by the service provider .These and other objects , features and advantages of the present invention will become apparent from the following detailed description of illustrative embodiments thereof , which is to be read in connection with the accompanying drawings .","label":"Background","metadata":{},"score":"50.622444"}
{"text":"The method of the present invention has been implemented to demonstrate its validity .A prototype was developed based on a telephony application already developed according to the conventional approach .The following paragraphs contain a brief description of both the traditional application ( A ) and the prototype application using the method of the present invention ( B ) .","label":"Background","metadata":{},"score":"50.62931"}
{"text":"Analysis of the SUI must clearly distinguish between a run - time environment and a development environment for spoken dialogues .The runtime environment includes a collection of processes and documentation of their APIs organized as described herein .The run - time environment can be ported and integrated for a variety of platforms in different fields of use .","label":"Background","metadata":{},"score":"50.66017"}
{"text":"The subpiece that was recognized by the spelling recognition engine 16 is then used to replace the errorful subpiece in the original hypothesis .Another method tried is to let the spelling recognition engine 16 do a free recognition ( no language model ) , and then score each possible subpiece by the number of characters which differ from the recognized sequence .","label":"Background","metadata":{},"score":"50.74125"}
{"text":"The subpiece that was recognized by the spelling recognition engine 16 is then used to replace the errorful subpiece in the original hypothesis .Another method tried is to let the spelling recognition engine 16 do a free recognition ( no language model ) , and then score each possible subpiece by the number of characters which differ from the recognized sequence .","label":"Background","metadata":{},"score":"50.74125"}
{"text":"SYSTEM AND METHOD OF PROVIDING AN AUTOMATED DATA - COLLECTION IN SPOKEN DIALOG SYSTEMS - The invention relates to a system and method for gathering data for use in a spoken dialog system .An aspect of the invention is generally referred to as an automated hidden human that performs data collection automatically at the beginning of a conversation with a user in a spoken dialog system .","label":"Background","metadata":{},"score":"50.74873"}
{"text":"Embodiments within the scope of the present invention may also include computer - readable media for carrying or having computer - executable instructions or data structures stored thereon .The above steps naturally involve human involvement but the same steps and processing of human - human data could occur via a computer program that performs the same analysis and steps .","label":"Background","metadata":{},"score":"50.75734"}
{"text":"Correction And Repair Methods .FIG .4 illustrates the steps of one method performed by the speech recognition system 10 illustrated in FIG .1 of repairing speech improperly recognized by a machine .In FIG .4 , when primary utterance 20 is spoken , speech recognition engine 14 produces at step 54 the primary recognition , which is shown in FIG .","label":"Background","metadata":{},"score":"50.81138"}
{"text":"Correction And Repair Methods .FIG .4 illustrates the steps of one method performed by the speech recognition system 10 illustrated in FIG .1 of repairing speech improperly recognized by a machine .In FIG .4 , when primary utterance 20 is spoken , speech recognition engine 14 produces at step 54 the primary recognition , which is shown in FIG .","label":"Background","metadata":{},"score":"50.81138"}
{"text":"Yet another way for the process of FIG .4 to be expanded is to use as recognition engine 18 a handwriting recognition engine in combination with the input device 24 .Given an incorrect section which has been highlighted as in step 56 , a handwriting recognizer can also be constrained by the repair module 12 to only recognize and score the words or sequences from the primary alternative list .","label":"Background","metadata":{},"score":"50.829666"}
{"text":"Yet another way for the process of FIG .4 to be expanded is to use as recognition engine 18 a handwriting recognition engine in combination with the input device 24 .Given an incorrect section which has been highlighted as in step 56 , a handwriting recognizer can also be constrained by the repair module 12 to only recognize and score the words or sequences from the primary alternative list .","label":"Background","metadata":{},"score":"50.829666"}
{"text":"As mentioned , the use of random questions in an iterative process makes the fraudulent use of recorders or synthesizers to fool the system substantially useless .Also , the use of a relatively large quantity of random questions overcomes the known problem of speech recognition and natural language understanding techniques making recognition and understanding errors .","label":"Background","metadata":{},"score":"50.843445"}
{"text":"By searching for matches between the recognized name and the top - ranked identified speakers , the identity claim is obtained .Alternatively , the recognition of the name reduces the population of candidates to a subset , namely , the set of speakers with the same name .","label":"Background","metadata":{},"score":"50.90827"}
{"text":"3 is a block diagram of exemplary elements involved in the generation of the target function identification module .DETAILED DESCRIPTION OF THE INVENTION .The method of the present invention is based , at least in part , from two observations .","label":"Background","metadata":{},"score":"50.93122"}
{"text":"Isolation is a concept that has recently emerged in computer user interface technology .In this context , isolation refers to separating human factors and ergonomical aspects of an application ( i.e. , the user interface ) from the functionality of the application itself .","label":"Background","metadata":{},"score":"51.01029"}
{"text":"A method for evaluating a user of one of a service and a facility having a plurality of permitted users , said method comprising the steps of : .( b ) accessing a database , based on said first piece of information , to identify said multi - user group ; and .","label":"Background","metadata":{},"score":"51.15918"}
{"text":"[ 0040 ] The Session Manager also includes Text - to - Structure module 212 , which can transform text of human utterance into special structures using appropriate Lexicon 210 .These Lexicons 210 are linked with Ontology 211 .This association allows the Text - to - Structure module 212 to convert text in any defined human language into structure containing grammatical and ontological information , independent of human language .","label":"Background","metadata":{},"score":"51.165535"}
{"text":"An acting process 7 provides information to the user and the application program in order to accomplish the desired policy .Specifically , the acting process 7 performs speech acts such as uttering phrases for the user which ask , request , inform , deny , confirm , etc .","label":"Background","metadata":{},"score":"51.204376"}
{"text":"Within the SUI of a preferred embodiment , all the internal processes support multiple instances or multiple threads and maintain no instance data that is necessary over a conversation ( except for the processes in the utterance layer 34 ) .Rather , the internal processes share static data as much as possible between instances and threads to minimize memory consumption .","label":"Background","metadata":{},"score":"51.34832"}
{"text":"In order to describe the manner in which the above - recited and other advantages and features of the invention can be obtained , a more particular description of the invention briefly described above will be rendered by reference to specific embodiments thereof which are illustrated in the appended drawings .","label":"Background","metadata":{},"score":"51.353798"}
{"text":"Draft of DAMSL : Dialog Act Markup in Several Layers .Oct. 18 , 1997 .pp . 1 - 32 .C. de Loupy , M. El - Beze , P.F. Marteau , Using Semantic Classification Trees for WSD , 2000 .","label":"Background","metadata":{},"score":"51.37367"}
{"text":"In order to train the acoustic model 104 , acoustic training data can be provided by a user of the system , as well as a transcription representative of the training data .The voices of many people can be recorded .","label":"Background","metadata":{},"score":"51.385303"}
{"text":"Within these modules , there are a variety of templates that generate utterances .For example , the Request module has a ' ' query.departure_place ' ' template which generates the utterance ' ' Where are you leaving from ? ' ' , which requests the corresponding concept from the user .","label":"Background","metadata":{},"score":"51.39602"}
{"text":"For example , if a caller calls the central server 22 for the first time and the system has a database of information pertaining to the caller but does not have an acoustic model set up for that caller , the following procedure may be performed .","label":"Background","metadata":{},"score":"51.401333"}
{"text":"Of the conversational agent elements outlined above , four - perception , planning , commitment and actions - are processes , and three - beliefs , desires and intentions - are knowledge bases comprising the agent 's cognitive state .The conversational agent is continually updating its beliefs on perceptions , using its beliefs to reason about possible plans , committing to certain intentions based on beliefs and desires , and realizing these intentions by acting .","label":"Background","metadata":{},"score":"51.40539"}
{"text":"The hypothesis having the highest combined score is selected as the replacement for the located error .A method of repairing speech recognized by a recognition engine of the type which generates an n - best list of hypotheses and scores for each hypothesis in response to the speech to be recognized , said method comprising the steps of : . receiving from a recognition engine a first n - best list of hypotheses , and scores for each hypothesis , generated in response to a primary utterance to be recognized ; . locating an error within the hypothesis having the highest score : . generating control signals from said first n - best list ; . inputting said control signals to said recognition engine ; generating a second n - best list of hypotheses , and scores for each hypothesis , from an event independent of the primary utterance in accordance with said control signals ; . combining the scores for the hypotheses in the first n - best list with the scores for the hypotheses in the second n - best list ; . selecting the hypothesis having the highest combined score ; and . replacing the located error with the selected hypothesis .","label":"Background","metadata":{},"score":"51.429836"}
{"text":"The hypothesis having the highest combined score is selected as the replacement for the located error .A method of repairing speech recognized by a recognition engine of the type which generates an n - best list of hypotheses and scores for each hypothesis in response to the speech to be recognized , said method comprising the steps of : . receiving from a recognition engine a first n - best list of hypotheses , and scores for each hypothesis , generated in response to a primary utterance to be recognized ; . locating an error within the hypothesis having the highest score : . generating control signals from said first n - best list ; . inputting said control signals to said recognition engine ; generating a second n - best list of hypotheses , and scores for each hypothesis , from an event independent of the primary utterance in accordance with said control signals ; . combining the scores for the hypotheses in the first n - best list with the scores for the hypotheses in the second n - best list ; . selecting the hypothesis having the highest combined score ; and . replacing the located error with the selected hypothesis .","label":"Background","metadata":{},"score":"51.429836"}
{"text":"EXPLOITING THE SEMANTIC WEB FOR UNSUPERVISED NATURAL LANGUAGE SEMANTIC PARSING - Structured web pages are accessed and parsed to obtain implicit annotation for natural language understanding tasks .Search queries that hit these structured web pages are automatically mined for information that is used to semantically annotate the queries .","label":"Background","metadata":{},"score":"51.521088"}
{"text":"Training a Dialogue Act Tagger for human - human and human - computer travel dialogues .In Proceedings of the 3rd Sigdial Workshop on Discourse and Dialogue - vol . 2 ( Philadelphia , Pennsylvania , Jul. 11 - 12 , 2002 ) .","label":"Background","metadata":{},"score":"51.55382"}
{"text":"In general , C code need not be written in order for an application to use the SUI , with the exception of additions to enable communication with the SUI API 22 .Although the data files thus contain no C code , they may still be highly complex since some such files contain , for example , descriptions of application- or language - specific grammar .","label":"Background","metadata":{},"score":"51.57602"}
{"text":"In this case , the secondary utterance is a spelling of the correct words for the subsection that contained the error .That is , the process would be identical to the spoken repetition except that the primary alternative list created in step 58 would be formed into a sequence of letters : .","label":"Background","metadata":{},"score":"51.626747"}
{"text":"In this case , the secondary utterance is a spelling of the correct words for the subsection that contained the error .That is , the process would be identical to the spoken repetition except that the primary alternative list created in step 58 would be formed into a sequence of letters : .","label":"Background","metadata":{},"score":"51.626747"}
{"text":"The TFIM 120 knows every relevant concept and data involved in the sentence .Accordingly , it can infer the global meaning using simple rules that can be implemented easily at a high level programming language , especially when the language provides built - in pattern matching and string functions .","label":"Background","metadata":{},"score":"51.628906"}
{"text":"For example , the application - specific TFIM 120 can be a telephone modem system whereby the spoken utterances received by the conceptual speech recognition system 100 represent concepts and data to be electronically forwarded to a remote location .The recognized concepts and data can correspond to a command from a housewife and the remote location can be a home computer .","label":"Background","metadata":{},"score":"51.663677"}
{"text":"An error within the best hypothesis , that is the hypothesis having the highest score , is located using one of several different techniques .Control signals are generated based on the first n - best list .The control signals are input to the recognition engine .","label":"Background","metadata":{},"score":"51.678238"}
{"text":"An error within the best hypothesis , that is the hypothesis having the highest score , is located using one of several different techniques .Control signals are generated based on the first n - best list .The control signals are input to the recognition engine .","label":"Background","metadata":{},"score":"51.678238"}
{"text":"The relation detection model training solution scales to other domains and languages , pushing the burden from natural language semantic parsing to knowledge base population .The relation detection model training solution exhibits performance comparable to supervised solutions , which require design , collection , and manual labeling of natural language data .","label":"Background","metadata":{},"score":"51.741306"}
{"text":"Human - machine dialog typically refer to dialogs between a computer system and a human , such as a customer talking to an automated dialog system .Before the deployment of a new NLU system , human - machine dialogs necessary for training a semantic classifier may not be available .","label":"Background","metadata":{},"score":"51.995808"}
{"text":"Thus , the conversation data 703 reflects historical and current beliefs , desires , and intentions of the conversational agent .Thus , intentions are formal representations of goals of the dialogue manager 32 and hold links to expectations for interpretation in context .","label":"Background","metadata":{},"score":"51.997204"}
{"text":"In addition , or alternatively , an embodiment may use the SUI API 22 to modify , add , or remove items in the various databases , with , for example , lexical entries and semantic codes ( eg.,open word classes , user dictionaries , etc . ) .","label":"Background","metadata":{},"score":"52.028355"}
{"text":"50 , ( Jan. 1 , 2008 ) , 1 - 13 .Sign up to receive free email alerts when patent applications with chosen keywords are published SIGN UP .Abstract : .Claims : .The method of claim 1 , further comprising converting the utterance into text and then converting the text into the one or more structures .","label":"Background","metadata":{},"score":"52.211258"}
{"text":"In prior art systems , the secondary utterance is treated as an independent event such that the probability that the secondary utterance will be recognized correctly is no greater than the probability that the primary utterance will be recognized correctly .However , in the present invention , by combining the weights from both the primary and secondary utterance , the probability is increased that the new top choice is correct .","label":"Background","metadata":{},"score":"52.261406"}
{"text":"In prior art systems , the secondary utterance is treated as an independent event such that the probability that the secondary utterance will be recognized correctly is no greater than the probability that the primary utterance will be recognized correctly .However , in the present invention , by combining the weights from both the primary and secondary utterance , the probability is increased that the new top choice is correct .","label":"Background","metadata":{},"score":"52.261406"}
{"text":"Although the above description may contain specific details , they should not be construed as limiting the claims in any way .Other configurations of the described embodiments of the invention are part of the scope of this invention .Accordingly , the appended claims and their legal equivalents should only define the invention , rather than any specific examples given .","label":"Background","metadata":{},"score":"52.273613"}
{"text":"DESCRIPTION OF A PREFERRED EMBODIMENT .FIG .1 is a block diagram illustrating a speech recognition system 10 having a correction and repair module 12 constructed according to the teachings of the present invention .The speech recognition system 10 also includes a commercially available speech recognition engine 14 .","label":"Background","metadata":{},"score":"52.27617"}
{"text":"DESCRIPTION OF A PREFERRED EMBODIMENT .FIG .1 is a block diagram illustrating a speech recognition system 10 having a correction and repair module 12 constructed according to the teachings of the present invention .The speech recognition system 10 also includes a commercially available speech recognition engine 14 .","label":"Background","metadata":{},"score":"52.27617"}
{"text":"1 , a flow chart / block diagram of the basic components of the invention is shown .The invention employs a unique combination of random questions , automatic speech recognition ( ASR ) and text - independent speaker recognition to provide a significant improvement in secure access to services and/or facilities ( as discussed previously ) requiring security measures .","label":"Background","metadata":{},"score":"52.28012"}
{"text":"Further , such existing systems are often unable to attain the level of security expected by most service providers .Still further , even when existing voice verification techniques are applied under constrained conditions , whenever the constraints are modified as is required from time to time , verification accuracy becomes unpredictable .","label":"Background","metadata":{},"score":"52.300636"}
{"text":"This application is related to the application ( Docket Number YO997 - 136 ) entitled \" Portable Acoustic Interface For Remote Access To Automatic Speech / Speaker Recognition Server \" , Ser .No .08/873,079 filed Jun. 11 , 1997 , now U.S. Pat .","label":"Background","metadata":{},"score":"52.30552"}
{"text":"FIG .1 illustrates the architecture of a conversational agent used in a SUI according to a preferred embodiment .A perception process 1 receives information communicated from the user and the application program .A beliefs knowledge base 2 is in communication with the perception process 1 and represents the current states of the user , the application program , and the interface itself .","label":"Background","metadata":{},"score":"52.334732"}
{"text":"A user interface according to claim 15 , wherein the dialogue manager uses an acting process in communications with the intentions knowledge base that converts the intentions into information for the user and the at least one application program to accomplish the desired policy .","label":"Background","metadata":{},"score":"52.3416"}
{"text":"The relation detection model training solution mines freely available resources from the World Wide Web to train a relationship detection model for use during linguistic processing .The relation detection model training system searches the web for pairs of entities extracted from a knowledge graph that are connected by a specific relation .","label":"Background","metadata":{},"score":"52.475235"}
{"text":"Speech recognition engine 14 then produces , at step 62 , a secondary alternative list from the secondary utterance : ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . sent are !","label":"Background","metadata":{},"score":"52.481586"}
{"text":"Speech recognition engine 14 then produces , at step 62 , a secondary alternative list from the secondary utterance : ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . sent are !","label":"Background","metadata":{},"score":"52.481586"}
{"text":"The scores for the hypotheses in the first n - best list are combined with the scores for the hypotheses in the second n - best list and the hypothesis having the highest combined score is selected .The present invention enables the incorrectly recognized speech to be corrected through an event independent of the primary utterance .","label":"Background","metadata":{},"score":"52.579685"}
{"text":"The scores for the hypotheses in the first n - best list are combined with the scores for the hypotheses in the second n - best list and the hypothesis having the highest combined score is selected .The present invention enables the incorrectly recognized speech to be corrected through an event independent of the primary utterance .","label":"Background","metadata":{},"score":"52.579685"}
{"text":"Before decoder 106 is used in a real application and performs the utterance decoding process by using the feature vector signals and labels provided by acoustic processor 102 , the acoustic model 104 and the conceptual language model 116 need to be trained .","label":"Background","metadata":{},"score":"52.661903"}
{"text":"An acting process in communications with the intentions knowledge base may convert the intentions into information for the user and the at least one application program to accomplish the desired policy .A further embodiment may also include a resource manager in communication with the discourse layer that manages use of system resources by the user interface .","label":"Background","metadata":{},"score":"52.75302"}
{"text":"It can also randomly select from a list of templates for a given response .The generated utterances are then sent to the TTS module ( in this case , Festival ) for synthesis .Rosetta identifies different kinds of actions that require utterances to be generated ; these actions are their own self - contained modules that have mappings between different concepts and the templates that generate utterances for those concepts .","label":"Background","metadata":{},"score":"52.804592"}
{"text":"Error locating can be performed in several ways , one of which is explained herein in conjunction with FIG .3 .After the errorful section has been located , the repair module 12 finds the matching section in each hypothesis as follows : .","label":"Background","metadata":{},"score":"52.8245"}
{"text":"Error locating can be performed in several ways , one of which is explained herein in conjunction with FIG .3 .After the errorful section has been located , the repair module 12 finds the matching section in each hypothesis as follows : .","label":"Background","metadata":{},"score":"52.8245"}
{"text":"The discourse layer 27 is language independent .The utterance layer 34 and the speech layer 23 layers are language dependent .Similarly , the component processes of the utterance layer 34 and the speech layer 23 may also be language dependent .","label":"Background","metadata":{},"score":"52.847122"}
{"text":"0062 ]Again , Conversation Scripts 203 generate and respond to received utterances in a natural manner using natural language .Thus , user 101 should fell as though they are having a normal conversation as they are prompted for an provide the needed information .","label":"Background","metadata":{},"score":"52.947273"}
{"text":"claim 22 , wherein said step ( d ) is performed using Hidden Markov Models .The machine - readable storage of .claim 22 , said step ( b ) further comprising : .( e ) a second step of matching said first list of items against said plurality at combinations of items to generate said combination of items likely to be representative of said user utterance in said step ( c ) .","label":"Background","metadata":{},"score":"52.957558"}
{"text":"Abstract .A program storage device readable by machine , tangibly embodying a program of instructions executable by the machine to perform method steps for evaluating a user of one of a service and a facility , said method steps comprising : .","label":"Background","metadata":{},"score":"53.02526"}
{"text":"The training involves inputting the sentences and determining statistics for each item ( concept or datum ) model in a manner which enhances the probability of the correct item relative to the probabilities associated with other items .Such training provides counts for all trigrams , bigrams and unigrams identified in the conceptual corpus .","label":"Background","metadata":{},"score":"53.03542"}
{"text":"A preferred embodiment includes a method of communicating via a speech controlled computer user interface between a user and at least one application program .Another embodiment may include managing , with a resource manager in communication with the discourse layer , use of system resources by the user interface , and/or allowing , with a set of development tools , an application developer to integrate the user interface with an application program .","label":"Background","metadata":{},"score":"53.041504"}
{"text":"Accordingly , TTS , SMC , and wave playback formats can be mixed together .Moreover , such an approach leads to easy localizing to other user languages .FIG .9 shows the steps involved in communicating such a message to the user , and FIG .","label":"Background","metadata":{},"score":"53.09272"}
{"text":"These feature vectors are 39 dimension vectors and are computed on frames of about 25 milliseconds with shifts of about 10 milliseconds .It is to be appreciated that the speaker recognition module and the speech recognizer may use the same types of feature vectors ; however , this is not critical to the invention .","label":"Background","metadata":{},"score":"53.095573"}
{"text":"( b ) querying the user with a random question ; .( c ) receiving an answer of the user to said random question ; at least one of said identity claim and said answer being received as a spoken utterance of the user ; .","label":"Background","metadata":{},"score":"53.118057"}
{"text":"That is because conversational English contains a wide variety of words , slang , and non - words such as \" umm \" and \" uhh \" .Recognizing conversational English is also complicated by regional accents and poor enunciation .Finally , conversational English frequently contains numerous mistakes which typically do not impair a human listener 's ability to understand the message , although such mistakes very often confuse a recognition system .","label":"Background","metadata":{},"score":"53.1438"}
{"text":"That is because conversational English contains a wide variety of words , slang , and non - words such as \" umm \" and \" uhh \" .Recognizing conversational English is also complicated by regional accents and poor enunciation .Finally , conversational English frequently contains numerous mistakes which typically do not impair a human listener 's ability to understand the message , although such mistakes very often confuse a recognition system .","label":"Background","metadata":{},"score":"53.1438"}
{"text":"It is to be appreciated that , while preferable , the name of the speaker is not mandatory in establishing the identity claim .The identity claim may be made from other information provided by the speaker or voice characteristics , as explained herein .","label":"Background","metadata":{},"score":"53.30919"}
{"text":"The concepts can then be used in step 312 to identify the service 108 being requested .Concepts and their identification within system 103 are described in more detail below .[ 0049 ] When not enough information is present in the utterances to sufficiently identify a service 108 , then the Session Manager can be configured to generate in step 314 , text massages design to elicit further information to allow the identification of a service 108 .","label":"Background","metadata":{},"score":"53.32148"}
{"text":"The method of claim 4 wherein said secondary utterance includes spelling at least a portion of said primary utterance .The method of claim 1 wherein said step of generating a second n - best list includes the step of generating a second n - best list from an event which includes writing at least a portion of the primary utterance .","label":"Background","metadata":{},"score":"53.33195"}
{"text":"The method of claim 4 wherein said secondary utterance includes spelling at least a portion of said primary utterance .The method of claim 1 wherein said step of generating a second n - best list includes the step of generating a second n - best list from an event which includes writing at least a portion of the primary utterance .","label":"Background","metadata":{},"score":"53.33195"}
{"text":"In order to restrict the number of prospective users to be considered by a speech recognition . device and to speed up the recognition process , it has been suggested to use a \" fast match \" technique on a speaker , as disclosed in the patent application Ser .","label":"Background","metadata":{},"score":"53.345676"}
{"text":"If the recognized user utterance is not understood or classifiable to a predetermined acceptance threshold , then the method re - prompts the user .If the recognized user utterance is not classifiable to a predetermined rejection threshold , then the method transfers the user to a human as this may imply a task - specific utterance .","label":"Background","metadata":{},"score":"53.354416"}
{"text":"A method according to claim 32 , wherein analyzing with a dialogue manager includes converting , with an acting process in communications with the intentions knowledge base , the intentions into information for the user and the at least one application program to accomplish the desired policy .","label":"Background","metadata":{},"score":"53.41626"}
{"text":"Each unit 504 and 512 can correspond to one or more lexemes in an utterance .For example , a unit 504 can correspond to a single lexeme , or can have multiple sub - units such that it can correspond to multiple lexemes , such as the grouping \" would like to \" in utterance 502 in the example of FIG .","label":"Background","metadata":{},"score":"53.42472"}
{"text":"A user interface as in claim 42 , wherein the speech - related processes include automatic speech recognition .A user interface as in claim 42 , wherein the speech - related processes include natural language understanding .A method of communicating via a speech controlled computer user interface between a user and at least one application program , the method comprising : . receiving information from the user and the at least one application program with a perception process , and generating beliefs representative of current states of the user and the at least one application program ; . containing past and current beliefs in a beliefs knowledge base in communication with the perception process ; . determining how to change the current states with a planning process in communication with the beliefs knowledge base ; . containing goals to determine a desirability of alternate possible states in a desires knowledge base ; . comparing desirability of selected possible states with a commitment process in communication with the beliefs knowledge base and the desires knowledge base , and determining a desired policy based on the current state and the desirability of the selected possible states ; . maintaining intentions representative of the desired policy in an intentions knowledge base in communication with the commitment process ; and . converting , with an acting process in communications with the intentions knowledge base , the intentions into information for the user and the at least one application program to accomplish the desired policy .","label":"Background","metadata":{},"score":"53.54641"}
{"text":"The network connection can be distributed as a localized network , i.e. , local area network , or a wide area network , i.e. , the Internet .The Human Understanding System 103 can in turn be communicatively linked with multiple domain systems via the Internet or a LAN .","label":"Background","metadata":{},"score":"53.568336"}
{"text":"Also , the indicia may serve as additional information about the user which may serve as static and/or dynamic parameters in building or updating the user 's acoustic model .Of course , it is possible to repeat the entire process if no speaker candidate is chosen or a system provider may choose another appropriate course of action .","label":"Background","metadata":{},"score":"53.576088"}
{"text":"The SUI API 22 also has numerous dialogue specific tasks .Generally , dialogues may be added , removed , enabled or disabled .Any particular dialogue may be assigned focus .Various controls associated with the SUI API 22 can be active at the same time ( e.g. , general functions , window specific functions , operating system functions , etc . ) .","label":"Background","metadata":{},"score":"53.584023"}
{"text":"Referring to .FIG .3 , a block diagram of the elements involved in the generation of the TFIM 120 is described .A function / concept table 300 can be built to store the functions to be executed in relation to every possible combination of concepts .","label":"Background","metadata":{},"score":"53.779335"}
{"text":"Again , a potential user 12 calls a central server 22 via link 24 , identifies himself and requests access to the particular service / facility .Next , the server 22 provides the name of the user to a speaker - independent ASR 60 via link 62 .","label":"Background","metadata":{},"score":"53.8174"}
{"text":"The method of claim 1 , further comprising communicating the voice message to the user .The method of claim 1 , wherein converting the utterance into one or more structures using lexicon tied to ontology comprises associating the utterance with one or more units linked to a plurality of concepts , which in turn are associated with a plurality of services .","label":"Background","metadata":{},"score":"53.860153"}
{"text":"The semantic representation is used when creating entity - relation patterns that are used to mine natural language ( NL ) examples ( e.g. NL surface forms from the web and search query click logs ) .The structure of the content source ( e.g. semantic graph ) is enriched with the mined NL examples .","label":"Background","metadata":{},"score":"53.957485"}
{"text":"In one embodiment , the SUI API 22 is used to directly control some system options and even to place hooking filter functions in various modules within the SUI .This use can be a practical way to experiment with the various internal modules and to provide extended capabilities through hooks for some situations .","label":"Background","metadata":{},"score":"53.99797"}
{"text":"The method of .claim 4 , wherein said step ( c ) is processed using a conceptual grammar .The method of . claim 2 , further comprising : . a training step defining said vocabulary of items of said step ( d ) .","label":"Background","metadata":{},"score":"54.130806"}
{"text":"The Voice Recognition Module 104 can be configured to translate the voice data received from the user 101 into text data and transfer that data to the Session Manager module 105 .[ 0030 ] It will be understood that Human Understanding System 103 can comprise the components , both hardware and software , required to carry out the functions described herein .","label":"Background","metadata":{},"score":"54.146343"}
{"text":"An NL linguistic item expresses an intent using a natural language , while a KL linguistic item expresses the intent using one or more keywords .In a training phase , the functionality produces the classification model based on query click log data or the like .","label":"Background","metadata":{},"score":"54.163242"}
{"text":"After all the training data is received , at least once , the method comprises building a third NLU model using all the labeling data , wherein the third NLU model is used in generating the spoken dialog service .Gokhan Tur , Parsippany , NJ US .","label":"Background","metadata":{},"score":"54.209515"}
{"text":"A beliefs knowledge base in communication with the perception process may contain past and current beliefs for use by the dialogue manager .A planning process in communication with the beliefs knowledge base may determine how to change a current state to attain another possible state .","label":"Background","metadata":{},"score":"54.20965"}
{"text":"claim 1 , wherein only a portion of the clausified human - human utterances are labeled and used to build the semantic classification model .The method of .claim 6 , wherein the portion of the clausified human - human utterances that are labeled and used to build the semantic classification model relate to identifying the intent of the speaker .","label":"Background","metadata":{},"score":"54.32367"}
{"text":"SUMMARY . [0008 ] Methods and systems for interactively accessing hosted services using voice communications are disclosed herein .[ 0011 ] These and other features , aspects , and embodiments of the invention are described below in the section entitled \" Detailed Description . \" BRIEF DESCRIPTION OF THE DRAWINGS .","label":"Background","metadata":{},"score":"54.326843"}
{"text":"A speech controlled computer user interface for communicating between a user and at least one application program , the interface comprising : . a perception process that receives information from the user and the at least one application program and generates beliefs representative of current states of the user and the at least one application program ; . a beliefs knowledge base in communication with the perception process that contains past and current beliefs ; . a planning process in communication with the beliefs knowledge base that determines how to change the current states ; . a desires knowledge base that contains goals to determine a desirability of alternate possible states ; . a commitment process in communication with the beliefs knowledge base and the desires knowledge base that compares desirability of selected possible states and determines a desired policy based on the current state and the desirability of the selected possible states ; . an intentions knowledge base in communication with the commitment process that maintains intentions representative of the desired policy ; and .","label":"Background","metadata":{},"score":"54.360138"}
{"text":"For example , a common code for representing the concept of querying can be ' QUERY ' associated with a specific code ' EN ' for English , ' SP ' for Spanish , etc .Accordingly , a final function relevant to the application can be operated .","label":"Background","metadata":{},"score":"54.447517"}
{"text":"Labeled data may be obtained for a target application .A new classification model may be formed for use with the target application by using the labeled data for adaptation of an existing classification model .In some implementations , the existing classification model may be used to determine the most informative examples to label .","label":"Background","metadata":{},"score":"54.478584"}
{"text":"The method of . claim 15 , wherein step ( c ) comprises receiving said answer as said spoken utterance .The method of . claim 2 , wherein step ( d ) comprises evaluating correctness of said answer of the user based on said identity claim .","label":"Background","metadata":{},"score":"54.501865"}
{"text":"In any case , the data that is exchanged between processes will be language dependent , except in the discourse layer 27 .Next to the horizontal layers , there is a section of processes that are not acting upon the main data flow but are rather helping the SUI in performing its tasks .","label":"Background","metadata":{},"score":"54.513927"}
{"text":"Description .Published .Multi - Channel Sampling of Pulse Streams at the Rate of Innovation - A method includes accepting an analog input signal including a sequence of pulses of a given pulse shape .The analog input signal is distributed to multiple processing channels ( 40 ) operating in parallel .","label":"Background","metadata":{},"score":"54.55027"}
{"text":"Preferably , the detailed acoustic match examines those items from the fast match candidate items list which have a reasonable likelihood of being the spoken item based on either the conceptual language model computation or the conceptual grammar .After the detailed match comparison , the conceptual syntax module is , preferably , again invoked to compute the likelihood of a segment of acoustics given the conceptual language model .","label":"Background","metadata":{},"score":"54.666157"}
{"text":"A method according to claim 28 , wherein analyzing with a dialogue manager includes determining , with a planning process in communication with the beliefs knowledge base , how to change a current state to attain another possible state .A method according to claim 29 , wherein analyzing with a dialogue manager includes containing , in a desires knowledge base , goals for the dialogue manager to determine a desirability of alternate possible states .","label":"Background","metadata":{},"score":"54.721027"}
{"text":"9 illustrates the conceptual transformations occurring when the user receives and output message from the SUI .FIG .10 represents an example of a message generation script as used in a preferred embodiment .DETAILED DESCRIPTION OF SPECIFIC EMBODIMENTS .The concepts of computer user interface technology - i.e . , isolation of the user interface and application , and user interface builders - may be employed in the creation a man - machine interface based on speech .","label":"Background","metadata":{},"score":"54.859974"}
{"text":"Feedback is provided from the correction and repair module 12 to the speech recognition engine 14 for the purpose of correcting and repairing the speech recognized by speech recognition engine 14 when the mode of correction is to respeak the incorrect word or words .","label":"Background","metadata":{},"score":"54.93155"}
{"text":"Feedback is provided from the correction and repair module 12 to the speech recognition engine 14 for the purpose of correcting and repairing the speech recognized by speech recognition engine 14 when the mode of correction is to respeak the incorrect word or words .","label":"Background","metadata":{},"score":"54.93155"}
{"text":"2 is a block diagram of the elements involved in the generation of the conceptual pronunciation dictionary 112 and the conceptual syntax module 114 .Three units , a concept / word table 200 , a word corpus 202 , and a word pronunciation dictionary 204 are used to define a specific application .","label":"Background","metadata":{},"score":"54.938652"}
{"text":"The acting process may include using artificial speech and/or an acting queue that sequences the information provided by the acting process .The intentions knowledge base may be further in communication with an expectations process that defines a grammar to use for a speech - related process which may include automatic speech recognition and/or natural language understanding .","label":"Background","metadata":{},"score":"54.943565"}
{"text":"Within those 58 classes , 44 represented concepts codes and 14 represented tags .The following table is an extract of some of the 44 concept codes of the prototype application and alternative sentences : .The following list shows some of the sentences generated for the prototype conceptual corpus : .","label":"Background","metadata":{},"score":"55.095394"}
{"text":"PROBABILITY - BASED STATE MODIFICATION FOR QUERY DIALOGUES - A device may facilitate a query dialog involving queries that successively modify a query state .However , fulfilling such queries in the context of possible query domains , query intents , and contextual meanings of query terms may be difficult .","label":"Background","metadata":{},"score":"55.102303"}
{"text":"Bernard Suhm , Brad Myers and Alex Waibel , Interactive Recovery from Speech Recognition Errors in Speech User Interfaces , Proceedings of the International Conference on Spoken Language Processing , ICSLP 96 , Philadelphia , PA , Oct. 1996 .Hermann Hild and Alex Waibel ( Stephen Jos e Hanson ed . , 1993 ) , Connected Letter Recognition with a Multi State Time Delay Neural Network , Neural Information Processing System 5 , 1993 , published by Morgan Kaufmann , S.F. California .","label":"Background","metadata":{},"score":"55.127575"}
{"text":"Bernard Suhm , Brad Myers and Alex Waibel , Interactive Recovery from Speech Recognition Errors in Speech User Interfaces , Proceedings of the International Conference on Spoken Language Processing , ICSLP 96 , Philadelphia , PA , Oct. 1996 .Hermann Hild and Alex Waibel ( Stephen Jos e Hanson ed . , 1993 ) , Connected Letter Recognition with a Multi State Time Delay Neural Network , Neural Information Processing System 5 , 1993 , published by Morgan Kaufmann , S.F. California .","label":"Background","metadata":{},"score":"55.127575"}
{"text":"The conceptual syntax module 114 can specify the allowable combinations of items , and can be implemented as a conceptual language model 116 or as a conceptual grammar 118 .Generally , in speech recognition systems , the collection of words that the system is able to recognize is contained in a file called a vocabulary .","label":"Background","metadata":{},"score":"55.286797"}
{"text":"The candidate variations are scored to assist in determining the variations to include within an understanding model .The variations may also be used when delivering responses and displayed output in the SLU system .For example , instead of using the listed named entity , a popular and/or shortened name may be used by the system .","label":"Background","metadata":{},"score":"55.288067"}
{"text":"ACTIVE LABELING FOR SPOKEN LANGUAGE UNDERSTANDING - A spoken language understanding method and system are provided .The system includes modules configured to control a processor in the system to perform the steps of the method .Gokhan Tur , Denville , NJ US .","label":"Background","metadata":{},"score":"55.397987"}
{"text":"For example , to find out where a person resides , a discrete dialog system would first ask for the person to name the state he lives in followed by asking for the city .Mixed - initiative dialog systems let the user enter multiple pieces of data in a single utterance and provide partial information .","label":"Background","metadata":{},"score":"55.442505"}
{"text":"Special concepts and their use are described in more detail below .[ 0043 ] Special instructions can be embedded in the conversation script 203 to make a query to an appropriate database .Other instructions can be embedded in the conversation scripts 203 associated with services 108 to allow the results to be presented to the customer in order to enable him to choose a specific value .","label":"Background","metadata":{},"score":"55.579124"}
{"text":"An aspect of the invention is generally referred to as an automated hidden human that performs data collection automatically at the beginning of a conversation with a user in a spoken dialog system .The method comprises presenting an initial prompt to a user , recognizing a received user utterance using an automatic speech recognition engine and classifying the recognized user utterance using a spoken language understanding module .","label":"Background","metadata":{},"score":"55.597477"}
{"text":"The method of . claim 36 , wherein step ( a ) comprises receiving said name associated with the user ; and . said multi - user group comprises users having names which are similar - sounding to said name associated with the user .","label":"Background","metadata":{},"score":"55.625553"}
{"text":"For example , certain information must be present for certain service 108 to be selected , whereas other information can not be included if a certain service 108 is to be selected .[0058 ]The concepts 508 can then be associated with the services 108 .","label":"Background","metadata":{},"score":"55.642353"}
{"text":"The method of . claim 10 , further comprising the additional step of decoding said spoken utterance , via speaker - independent speech recognition , to comprehend said identity claim .The method of .claim 11 , wherein said decoding and step ( e ) are performed substantially simultaneously .","label":"Background","metadata":{},"score":"55.77359"}
{"text":"The application 21 initiates the dialogue manager 32 and can access conversation data 33 through the dialogue manager 32 .The application 21 also sends information to the application perception module 30 and receives queries and information from the application action module 31 .","label":"Background","metadata":{},"score":"55.82124"}
{"text":"The method of claim 1 wherein said step of locating an error within the hypothesis having the highest score includes the step of highlighting the error by using a keyboard .The method of claim 1 wherein said step of locating an error within the hypothesis having the highest score includes the step of respeaking the portion of the primary utterance that is in error .","label":"Background","metadata":{},"score":"56.01312"}
{"text":"The method of claim 1 wherein said step of locating an error within the hypothesis having the highest score includes the step of highlighting the error by using a keyboard .The method of claim 1 wherein said step of locating an error within the hypothesis having the highest score includes the step of respeaking the portion of the primary utterance that is in error .","label":"Background","metadata":{},"score":"56.01312"}
{"text":"0012 ]For a more complete understanding of the principles disclosed herein , and the advantages thereof , reference is now made to the following descriptions taken in conjunction with the accompanying drawings , in which : . [ 0013 ] FIG .","label":"Background","metadata":{},"score":"56.054634"}
{"text":"This lead to the generation of 58 classes of items ( concepts , codes , and tags ) which can represent every sentence in the corpus in an alternative way .Every item was defined by a set of words and/or phrases having a similar meaning or a similar role in the sentences .","label":"Background","metadata":{},"score":"56.063576"}
{"text":"FIG .1 is a flow chart / block diagram illustrating the functional interconnection between components of the invention ; .FIG .2 is a flow chart / block diagram further illustrating components of the invention ; .FIG .3 is a flow chart / block diagram illustrating an iterative procedure performed according to the invention ; .","label":"Background","metadata":{},"score":"56.16289"}
{"text":"[ 0057 ] Thus , each service 108 defined in system 103 can have a set of concepts 508 associated with it .In many embodiments , only significant concepts are included in to avoid unnecessary associations .Also , in other embodiments , lexemes that only communicate grammar are omitted .","label":"Background","metadata":{},"score":"56.34455"}
{"text":"For example , tags that are located on a structured web page that are associated with the search query may be used to annotate the query .The mined search queries may be filtered to create a set of queries that is in a form of a natural language query and/or remove queries that are difficult to parse .","label":"Background","metadata":{},"score":"56.481842"}
{"text":"In certain embodiments , Session Manager 105 can also be configured to determine whether any required conditions and excluding conditions have been met for each service 108 in determining which service 108 is most closely associated with the utterance 502 .[ 0059 ] Once a service 108 is selected , then the next step can be to gather data for the service using the Conversation Scripts 203 .","label":"Background","metadata":{},"score":"56.73974"}
{"text":"Static information may be either internal ( block 106 ) or external ( block 108 ) .Examples of external information are phone numbers , time of day , etc .On the other hand , dynamic information may include information regarding the caller 's trips , meetings with people , facsimile and e - mail information .","label":"Background","metadata":{},"score":"56.769394"}
{"text":"Accordingly , the Special Concepts Prospector 230 is analyzing text and structures produced from utterance to extract special concept values .Additionally , there can be defined sets of questions , in appropriate languages , designed to produce information from user 101 that can further clarify the concept associated with the value .","label":"Background","metadata":{},"score":"56.79824"}
{"text":"In one particular form , one can interpret a search of a best matching speaker with respect to acoustic data as a maximum value of a function defined as the conditional probability of a speaker ( speaker . )P(speaker i ) .","label":"Background","metadata":{},"score":"56.84596"}
{"text":"7 , this conversation data 703 is kept in the form of data frames 704 for each dialogue which are managed in a frame stack from which one dialogue may call another .Each dialogue data frame 704 has various specified slots in which relevant data is maintained , with slot values being in the form of lists with an associated belief strength - unknown , ambiguous , unconfirmed , confirmed , etc .","label":"Background","metadata":{},"score":"56.85297"}
{"text":"The system of .claim 18 , wherein said decoder comprises a fast acoustic match and a detailed acoustic match .The system of .claim 18 , wherein said conceptual syntax module comprises a conceptual language model or a conceptual grammar .","label":"Background","metadata":{},"score":"56.897667"}
{"text":"Patent application number .Description .Published .LOW - RATE SAMPLING OF PULSE STREAMS - A method includes accepting an analog input signal that includes a sequence of pulses .The filter output is sampled so as to produce digital samples .","label":"Background","metadata":{},"score":"56.934807"}
{"text":"The question and answer process between the user 12 and the central server 22 may continue for as many iterations as are desired to substantially ensure that the potential user is the user associated with the subject user database .The module 52 utilizes the user model previously built ( as will be explained in the context of FIG .","label":"Background","metadata":{},"score":"56.968277"}
{"text":"Another embodiment includes allowing , with a set of development tools , an application developer to integrate the user interface with an application program .BRIEF DESCRIPTION OF THE DRAWINGS .The present invention will be more readily understood by reference to the following detailed description taken with the accompanying drawings , in which : .","label":"Background","metadata":{},"score":"57.12758"}
{"text":"Description .The present application claims priority from provisional patent application No .60/103,059 , filed Oct. 5 , 1998 , which is incorporated herein by reference .TECHNICAL FIELD .The present invention relates to a speech controlled computer user interface for managing communications between a user and one or more computer applications .","label":"Background","metadata":{},"score":"57.29315"}
{"text":"claim 1 , further comprising : . storing a set of prototype acoustic models obtained from a training phase , wherein each said acoustic model represents one or more possible basic speech units of an utterance of a word .The method of .","label":"Background","metadata":{},"score":"57.54389"}
{"text":"The SUI API 22 also performs other dialogue specific functions in an embodiment .For example , data to and from the conversation database 33 may be queried , modified , added , or copied .It may be desirable , for instance , to be able to copy history or profile data for a specific user , and to use this data later again if the same user uses the dialogue .","label":"Background","metadata":{},"score":"57.561035"}
{"text":"In addition , a variety of acoustic information may be included in the databases .The information may be categorized as information exhibiting static features , i.e. information that does not change or changes slowly or periodically with time ( block 102 ) , and information exhibiting dynamic features , i.e. , information that changes quickly or non - periodically with time ( block 104 ) .","label":"Background","metadata":{},"score":"57.57672"}
{"text":"Related Art .[0004 ] Corporations today routinely provide customer service via the Internet and the telephone for reasons of cost or expediency .Currently , users may obtain such Internet services from an access device that offers visual presentation capabilities -- for example , a personal computer ( PC ) with an Internet web browser that requests and receives HyperText Markup Language ( HTML ) documents produced by a Web server .","label":"Background","metadata":{},"score":"57.637474"}
{"text":"A method according to claim 18 , wherein the converting between speech messages and text messages includes at least one of : . converting Dial Tone Multi - Frequency ( DTMF ) tones into representative text - based codes with a DTMF module ; . converting speech signals into representative text using Automatic Speech Recognition ( ASR ) techniques with an ASR module ; . converting acoustic signals into digitally encoded speech signals using Speech / Music Compression ( SMC ) techniques with an SMC module ; . converting text messages into electronic speech representative signals with a concatenation module ; . converting text messages into representative acoustic speech signals with a Text - to - Speech ( TTS ) module ; and .","label":"Background","metadata":{},"score":"57.716934"}
{"text":"The invention itself , however , as well as these and other related objects and advantages thereof , will be best understood with reference to the following detailed description to be read in conjunction with the accompanying drawings .BRIEF DESCRIPTION OF THE DRAWINGS .","label":"Background","metadata":{},"score":"57.726517"}
{"text":"Embodiments may also be practiced in distributed computing environments where tasks are performed by local and remote processing devices that are linked ( either by hardwired links , wireless links , or by a combination thereof ) through a communications network .","label":"Background","metadata":{},"score":"57.794178"}
{"text":"The shortcomings inherent with the above - discussed security measures have prompted an increasing interest in biometric security technology , i.e. , verifying a person 's identity by personal biological characteristics .Several biometric approaches are known .However , one disadvantage of biometric approaches , with the exception of voice - based verification , is that they are expensive and cumbersome to implement .","label":"Background","metadata":{},"score":"57.82311"}
{"text":"In contrast , local area networks ( LAN ) are smaller networks of servers such as those covering a small local area , such as a home , office , or college .[ 0022 ] FIG .1 is a diagram illustrating the functional elements of an Interactive Voice Response ( IVR ) system that permits a user to interactively access hosted services using voice communication , in accordance with one embodiment .","label":"Background","metadata":{},"score":"57.90305"}
{"text":"There are significant utterances in human - machine dialogs that simply confirm / deny system understanding .For example , if the user is talking with a bank 's computer spoken dialog system , and the user asks \" I need my account balance .","label":"Background","metadata":{},"score":"58.07312"}
{"text":"A method as in claim 45 , wherein converting with an acting process includes using artificial speech .A method as in claim 45 , wherein converting with an acting process includes sequencing the information provided by the acting process with an acting queue .","label":"Background","metadata":{},"score":"58.08459"}
{"text":"The speech recognition engine 14 receives audio input , referred to as a primary utterance and generally designated 20 , through a microphone 22 and input electronics 23 in a known manner .The output of the speech recognition engine 14 is input to the correction and repair module 12 , the details of which will be described hereinbelow in conjunction with FIGS .","label":"Background","metadata":{},"score":"58.116806"}
{"text":"The speech recognition engine 14 receives audio input , referred to as a primary utterance and generally designated 20 , through a microphone 22 and input electronics 23 in a known manner .The output of the speech recognition engine 14 is input to the correction and repair module 12 , the details of which will be described hereinbelow in conjunction with FIGS .","label":"Background","metadata":{},"score":"58.116806"}
{"text":"Similarly , the SUI of a preferred embodiment provides the developer with tools to add speech controls to an application , and to assign actions to these controls .For example , in one embodiment , giving feedback to the user makes use of pre - selected computer - spoken messages .","label":"Background","metadata":{},"score":"58.123062"}
{"text":"GUIs are traditionally based on a metaphor of a desktop model having various different kinds of documents .GUI applications create , modify , move , and copy these documents through point and click actions .The graphical user interface of an application include devices such as commands organized in menus and dialog boxes that contain visual controls such as buttons , sliders , text , panels , meters , etc .","label":"Background","metadata":{},"score":"58.170067"}
{"text":"Thus , any such connection is properly termed a computer - readable medium .Combinations of the above should also be included within the scope of the computer - readable media .Computer - executable instructions include , for example , instructions and data which cause a general purpose computer , special purpose computer , or special purpose processing device to perform a certain function or group of functions .","label":"Background","metadata":{},"score":"58.439903"}
{"text":"5 , a flow chart / block diagram illustrating the generation of user model 20 , formed according to the invention , is shown .As previously explained , a user model is employed to estimate a probability of a particular user 's identity .","label":"Background","metadata":{},"score":"58.460068"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ can there !At step 66 , the module 12 sorts according to the new summed score : .","label":"Background","metadata":{},"score":"58.463463"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ can there !At step 66 , the module 12 sorts according to the new summed score : .","label":"Background","metadata":{},"score":"58.463463"}
{"text":"( f-2 ) granting access to the user if said combined probability score is one of greater than or equal to a predetermined value .A method for evaluating a user of one of a service and a facility , said method comprising the steps of : .","label":"Background","metadata":{},"score":"58.682407"}
{"text":"The SUI relates to ASR , TTS and SMC in much the same way that a graphical user interface ( GUI ) relates to screen , keyboard and mouse drivers .The SUI also provides development tools that enable easy design of the user interface and easy integration of the interface with an application .","label":"Background","metadata":{},"score":"58.8208"}
{"text":"[0044 ] Conditional instructions in the conversation scripts 203 make it possible to react to anticipated human reactions .[0045 ] The conversation scripts 203 can be configured to operate on message numbers , which can be converted to messages in natural language depending on language used by the customer .","label":"Background","metadata":{},"score":"58.896633"}
{"text":"The features are usually computed on frames of about 25 milliseconds with shifts of about 10 milliseconds .The speaker verifier is preferably a vector quantizer which stores , during enrollment , a minimum of information about each speaker .All the input feature vectors are clustered in a set of about 65 codewords ( centroids and variances ) .","label":"Background","metadata":{},"score":"58.930275"}
{"text":"Before describing the system of the present invention , the new language description is illustrated using three basic user utterances .A first utterance type can be in the form of a query such as \" Please , give me the phone number of Pedro Romero \" .","label":"Background","metadata":{},"score":"58.952953"}
{"text":"That is , based on the feature vector values generated during a particular interval for example , one acoustic prototype from the set of acoustic prototypes included in the acoustic model can be selected as being the closest .Each item ( concept or datum ) in the dictionary vocabulary can be represented by a sequence of phonemes which are combined to form the pronunciation of the item .","label":"Background","metadata":{},"score":"59.06481"}
{"text":"Accordingly , it is to be appreciated that the invention can build databases and models both automatically and manually .Automatic enrollment is performed by obtaining the name , address and whatever other identification tag that the service / facility desires and then building , from scratch , models and compiling data usable for future identification or verification .","label":"Background","metadata":{},"score":"59.08898"}
{"text":"In the preferred embodiment , both recognition engines 14 and 16 use the same input format , which simplifies their use in one common interface , although that is not required to practice the present invention .The speech recognition engine 14 uses a trigram , bigram , or wordpair language model to constrain the hypothesis search while the spelling recognition engine 16 can use letter n - grams or finite - state grammars as discussed below .","label":"Background","metadata":{},"score":"59.105995"}
{"text":"In the preferred embodiment , both recognition engines 14 and 16 use the same input format , which simplifies their use in one common interface , although that is not required to practice the present invention .The speech recognition engine 14 uses a trigram , bigram , or wordpair language model to constrain the hypothesis search while the spelling recognition engine 16 can use letter n - grams or finite - state grammars as discussed below .","label":"Background","metadata":{},"score":"59.105995"}
{"text":"Gokhan Tur , Morris Plains , NJ US .Patent application number .Description .Published .SYSTEMS AND METHODS FOR REDUCING ANNOTATION TIME - Systems and methods for annotating speech data .The present invention reduces the time required to annotate speech data by selecting utterances for annotation that will be of greatest benefit .","label":"Background","metadata":{},"score":"59.174583"}
{"text":"Generally , program modules include routines , programs , objects , components , and data structures , etc . that perform particular tasks or implement particular abstract data types .Computer - executable instructions , associated data structures , and program modules represent examples of the program code means for executing steps of the methods disclosed herein .","label":"Background","metadata":{},"score":"59.232853"}
{"text":"08/851,982 entitled , \" Speaker Recognition Over Large Population with Combined Fast and Detailed Matches \" , filed on May 6 , 1997 .While this procedure is significantly faster than a \" detailed match \" speaker recognition technique , it still requires processing of acoustic prototypes for each user in a database .","label":"Background","metadata":{},"score":"59.25737"}
{"text":"Each of the integrals can be integrated over time .In a particular embodiment , the pulse analyzer can be configured to compare the ratio with a predetermined value and to identify the electrical pulse as a neutron - induced pulse when the ratio is at least the predetermined value .","label":"Background","metadata":{},"score":"59.273373"}
{"text":"Other measures which represent the probability of a speaker given a parameter , including more complex models , may be employed and , as a result , the invention is not limited to the use of a U - measure of the static and dynamic parameters described herein .","label":"Background","metadata":{},"score":"59.32496"}
{"text":"However , if the top hypothesis is not correct .The error is located and the matching section found at step 56 .Each hypothesis in the n - best list is sent through a parser which produces , at step 74 , a scored paraphrase for each .","label":"Background","metadata":{},"score":"59.728584"}
{"text":"However , if the top hypothesis is not correct .The error is located and the matching section found at step 56 .Each hypothesis in the n - best list is sent through a parser which produces , at step 74 , a scored paraphrase for each .","label":"Background","metadata":{},"score":"59.728584"}
{"text":"For example , the addition of an entry to an information database with the SUI , may be sufficient to also update the ASR lexicon with a phonetic transcription and add a meaning value that refers to the database entry .The SUI of a preferred embodiment thus represents a revolutionary new way to add speech capabilities to applications and to setup conversation systems over the phone .","label":"Background","metadata":{},"score":"59.78415"}
{"text":"In step 412 , information or values associated with the information received in step 410 can be stored in service database 412 .[0054 ]FIG .5 is a diagram illustrating an example for forming structures and linking them to concepts in accordance with on embodiment .","label":"Background","metadata":{},"score":"59.79099"}
{"text":"The speech recognition process is constrained by the acoustic model 104 which corresponds to the phonemes employed in system 100 , the conceptual pronunciation dictionary 112 , and the conceptual syntax module 114 .The conceptual pronunciation dictionary 112 can define the pronunciation of every concept code and every tagged data ( also called the items ) .","label":"Background","metadata":{},"score":"59.892838"}
{"text":"FIG .4 shows greater detail regarding the speech understanding process embodied in the speech to concept conversion such as in step 305 of FIG .3 , when the user asks the system for new e - mail .The user 's voice input is initially an acoustic signal , 401 , which is preprocessed into a digitized speech signal 402 ( not shown ) which is input for continuous speech recognition , step 403 .","label":"Background","metadata":{},"score":"59.95652"}
{"text":"The interrogating also includes sending at least two probe tones into the optical fiber from another end of the optical fiber , such that a frequency spacing between the probe tones is different from the frequency spacing between the pump tones .","label":"Background","metadata":{},"score":"60.00245"}
{"text":"The service logic is programmed using any number of popular Web programming tools .IVR systems are automated to allow a telephone user to access linked services on the system through verbal commands .The service logic is typically programmed in a general - purpose software language using the platform 's application - programming interface ( API ) , or a platform - specific scripting language .","label":"Background","metadata":{},"score":"60.006294"}
{"text":"No . 081788,471 .Cohorts are sets of similarly sounding speakers who are in the database .The verification results from a competition between the speaker model and the models of the cohorts or background ( new model built over the whole cohort group ) models .","label":"Background","metadata":{},"score":"60.063713"}
{"text":"[ 0015 ] FIG .3 is a flow chart illustrating the operation of the system illustrated in FIGS . 2 and 3 in accordance with one embodiment ; .[ 0016 ] FIG .4 is a flow chart illustrating the operation of the system illustrated in FIGS . 2 and 3 in even more detail and in accordance with one embodiment ; and .","label":"Background","metadata":{},"score":"60.07789"}
{"text":"Thus , within this invention , the vocabulary is not as in the prior art systems , a list of words , but a list of \" items \" defining \" concept codes \" and \" tagged data \" .The output of acoustic processor 102 ( a string of labels identifying a corresponding sound type ) is input to decoder 106 including the fast acoustic match 108 and the detailed acoustic match 110 .","label":"Background","metadata":{},"score":"60.089565"}
{"text":"The method of .claim 1 , wherein said user utterance is in the form of isolated data .The method of .claim 1 , wherein said tagged data includes a plurality of segmentable data elements .The method of .","label":"Background","metadata":{},"score":"60.126072"}
{"text":"Patent application number .Description .Published .Linguistic input is directed to machine translation components that translate such input from its language into the anchor language .Those existing linguistic components are then utilized to initiate responsive processing and generate output .","label":"Background","metadata":{},"score":"60.242943"}
{"text":"The method of claim 2 additionally comprising the step of repeating the method in the event that the selected hypothesis is incorrect .The method of claim 1 wherein said step of generating a second n - best list includes the step of generating a second n - best list from an event which includes a secondary utterance .","label":"Background","metadata":{},"score":"60.451515"}
{"text":"The method of claim 2 additionally comprising the step of repeating the method in the event that the selected hypothesis is incorrect .The method of claim 1 wherein said step of generating a second n - best list includes the step of generating a second n - best list from an event which includes a secondary utterance .","label":"Background","metadata":{},"score":"60.451515"}
{"text":"The separation of links is meant to illustrate functionality rather than physical implementation .The central server 22 receives the user 's answer and processes it through ASR 28 .After decoding the answer , ASR 28 passes the decoded answer to a semantic analyzer 40 via link 42 .","label":"Background","metadata":{},"score":"60.46703"}
{"text":"The system of claim 15 , wherein the session manger is further configured to identify concepts in the utterance using the structures by determining which concepts are linked with the units .The system of claim 13 , wherein the session manger is further configured to identify special concepts associated the selected service and assign a value to the identified special concepts based on information included in the utterance .","label":"Background","metadata":{},"score":"60.469967"}
{"text":"The top ( best ) hypothesis in a primary recognition 36 is designated as 20 ' .In FIG .2 , a secondary or repair utterance 38 is shown .The top hypothesis in a secondary recognition 40 is designated as utterance 38 ' .","label":"Background","metadata":{},"score":"60.496483"}
{"text":"The top ( best ) hypothesis in a primary recognition 36 is designated as 20 ' .In FIG .2 , a secondary or repair utterance 38 is shown .The top hypothesis in a secondary recognition 40 is designated as utterance 38 ' .","label":"Background","metadata":{},"score":"60.496483"}
{"text":"4 is a flow chart illustrating the process of selecting a service undertaken by Session Manager 105 in more detail and in accordance with one embodiment .In step 402 , Script Engine 202 receives the text information from Voice Recognition module 104 and sends the text to Text - to - Structure engine 212 , which can be configured to convert the text into structures in step 404 using an appropriate lexicon 210 and associated ontology 211 .","label":"Background","metadata":{},"score":"60.528496"}
{"text":"On a frame by frame basis , it identifies the closest codebook ( or ranks the N closest codebooks ) .An histogram is created which counts how many frames have been selected for each codebook .The codebook which is most often selected identifies the potential speaker .","label":"Background","metadata":{},"score":"60.549206"}
{"text":"Again , special concepts are concepts system 103 is not really trying to understand , but for which system 103 is trying to generate an associated value rank .In the example of FIG .5 , such concepts can be : Person , i.e. , who is going to the doctor ; Time , i.e. , when the appointment should be made ; and Doctor , which doctor is needed .","label":"Background","metadata":{},"score":"60.59024"}
{"text":"A second method may include storing at least one set of data .Each one of the at least one set of data may include ones of the reusable components associated with audible data collected during a different collection phase .Method and Apparatus for Responding to an Inquiry - Disclosed is a method and apparatus for responding to an inquiry from a client via a network .","label":"Background","metadata":{},"score":"60.765594"}
{"text":"The method of claim 7 , further comprising selecting a service based on the concepts comprises determining which service is most closely related to the utterance based on the number of associated concepts that are linked to the utterance via the units for each of the plurality of services .","label":"Background","metadata":{},"score":"60.82468"}
{"text":"[ 0050 ] The process will then repeat until enough information is present to select a service in step 318 .One the service is selected , the appropriate Conversation Scripts 203 can be activated , in step 320 , in order to generate text messages that can be forward to Voice Generator 106 , in step 322 , in order to communicate with user 101 .","label":"Background","metadata":{},"score":"60.85382"}
{"text":"5 illustrates the process for the following utterance : \" I would like to make an appointment for my wife with her doctor ; \" and the equivalent in Polish \" Chciabym umowi moj on z jej lekarzem .\" Each utterance 502 ( English ) and 514 ( Polish ) includes a plurality of lexems as defined by the associated lexicon 210 for that language .","label":"Background","metadata":{},"score":"60.89986"}
{"text":"claim 25 , wherein steps ( b ) and ( c ) are performed substantially simultaneously .A method for evaluating a user of one of a service and a facility , said method comprising the steps of : .( a ) receiving a first natural language spoken utterance of the user ; .","label":"Background","metadata":{},"score":"60.900574"}
{"text":"Each unit 504 , or sub - unit , can then be linked via links 506 and 510 to one or more concepts 508 based on the associated ontology 211 .[ 0056 ] The combination of units 504 and 512 and links 506 and 510 respectively , form the structures 505 and 515 associated with the various concepts 508 .","label":"Background","metadata":{},"score":"61.22663"}
{"text":"The method of . claim 2 , wherein said random question pertains to personal information of said user , and wherein step ( b ) comprises querying via a natural language dialog .The method of . claim 2 , wherein step ( c ) comprises receiving said answer as natural language dialog .","label":"Background","metadata":{},"score":"61.261353"}
{"text":"[0052 ] In Step 408 , the selected service can then cause script engine 202 to generate the appropriate text messages , using Conversation Scripts 203 , needed to provide the appropriate information to , or solicit information from user 101 .","label":"Background","metadata":{},"score":"61.29719"}
{"text":"In other instances , well known process operations have not been described in detail for the sake of brevity .[ 0019 ]As used herein , telephony is the general use of equipment , e.g. , land line phones , mobile phones , Internet communications devices , etc . , to provide voice communication over distances .","label":"Background","metadata":{},"score":"61.468605"}
{"text":"SUMMARY OF THE INVENTION .It is an object of the present invention to provide methods and apparatus for providing secure access to services and/or facilities which preferably utilize random questioning , automatic speech recognition ( ASR ) and text - independent speaker recognition techniques .","label":"Background","metadata":{},"score":"61.489372"}
{"text":"In a particular embodiment , the pulse analyzer can be configured to compare the ratio with a predetermined value and to identify the electrical pulse as a neutron - induced pulse when the ratio is at least the predetermined value .Gokham Tur , Denville , NJ US .","label":"Background","metadata":{},"score":"61.54063"}
{"text":"Maintaining intentions may include defining , with an expectations process , a grammar to use for a speech - related process which may include an automatic speech recognition process or a natural language understanding process .A preferred embodiment includes a method for a user to use a spoken message to control at least one application program .","label":"Background","metadata":{},"score":"61.56911"}
{"text":"RELATED APPLICATION DATA .This application is related to the application Ser .No .08/873,079 entitled \" Portable Acoustic Interface For Remote Access To Automatic Speech / Speaker Recognition Server \" , which is commonly assigned and is filed concurrently with the present invention .","label":"Background","metadata":{},"score":"61.715714"}
{"text":"The application knew phone numbers of some 4,000 Spanish International Business Machines Corporation employees and was designed to answer calls from users asking for the phone number of an employee or requesting to transfer a call to one of them .Because the application is designed for use in a particular speaking environment , one of the main features of this application is that users need no special knowledge about how to use the application .","label":"Background","metadata":{},"score":"61.873383"}
{"text":"The candidate items can be selected when acoustically similar to the stored items .Accordingly , a fast match candidate items list can be produced from the fast acoustic match process .Once the fast match reduces the number of candidate items , the fast match candidate item list can be input to the detailed acoustic match module .","label":"Background","metadata":{},"score":"61.911625"}
{"text":"In one embodiment , each registered hosted service is related to one or more groups of service provider , e.g. , shops , car rentals , motels .It should be understood that many aspects of human life can be served by appropriate hosted services as long as these services can be ordered by the user 101 via a telephony device 102 .","label":"Background","metadata":{},"score":"62.13974"}
{"text":"If the combined score is above or within an acceptable predetermined range of the threshold value , the central server 22 may permit access , else the server may decide to deny access completely or merely repeat the process .Further , a service provider may decide to take other appropriate security actions .","label":"Background","metadata":{},"score":"62.17926"}
{"text":"A second utterance type can be in the form of a command such as : \" Please , transfer me to him \" .This sentence contains no data .Rather , the expression \" Transfer me to him \" is a semantic identifier that can be recognized by a concept code \" DIAL \" or \" DIAL - EN \" for an English application .","label":"Background","metadata":{},"score":"62.499344"}
{"text":"1 can be implemented in various forms of hardware , software , or combinations thereof .Each general purpose digital computer can contain , for example , a central processing unit ( CPU ) operatively coupled to an associated system memory , such as RAM , ROM , and/or a mass storage device , via a computer interface bus .","label":"Background","metadata":{},"score":"62.564316"}
{"text":"The method of .claim 25 , wherein : . step ( a ) comprises receiving said spoken utterance of the user as at least one of : . a name associated with the user ; . a password associated with the user ; . a social security number associated with the user ; . an identification number associated with the user ; . a phone number associated with the user ; . a customer number associated with the user ; . an address associated with the user ; and .","label":"Background","metadata":{},"score":"62.602226"}
{"text":"In FIG .2 , the SUI internal components are organized in three horizontal layers and two vertical parts .In the left vertical part , the signal flow is from bottom to top , whereas it is from top to bottom towards the right side of the figure .","label":"Background","metadata":{},"score":"62.672417"}
{"text":"The U.S. Government defined Resource Management task was used for our experiments .The specific set of utterances chosen consisted of all the male utterances from the February and October 1989 official test data .That included 390 utterances , in which were 300 unique sentences .","label":"Background","metadata":{},"score":"62.68863"}
{"text":"The U.S. Government defined Resource Management task was used for our experiments .The specific set of utterances chosen consisted of all the male utterances from the February and October 1989 official test data .That included 390 utterances , in which were 300 unique sentences .","label":"Background","metadata":{},"score":"62.68863"}
{"text":"The named entities may be obtained from one or more sources and include an initial list of named entities .A search may be performed within one or more search engines to determine common phrases that are used to identify the named entity in addition to the named entity initially included in the named entity list .","label":"Background","metadata":{},"score":"62.767487"}
{"text":"At step 68 , repair module 12 replaces the highlighted section with the new top - choice , displays it , prints it , etc . as the corrected hypothesis : ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ center !","label":"Background","metadata":{},"score":"62.895092"}
{"text":"At step 68 , repair module 12 replaces the highlighted section with the new top - choice , displays it , prints it , etc . as the corrected hypothesis : ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ center !","label":"Background","metadata":{},"score":"62.895092"}
{"text":"The method of . claim 21 , wherein : . step ( a ) comprises receiving said spoken utterance of the user as at least one of : . a name associated with the user ; . a password associated with the user ; . a social security number associated with the user ; . an identification number associated with the user ; . a phone number associated with the user ; . a customer number associated with the user ; . an address associated with the user ; and .","label":"Background","metadata":{},"score":"62.9298"}
{"text":"The VOIP - enabled computer communicates via a broadband Internet connection that is communicatively linked to the Human Understanding System 103 through a network connection , e.g. , the Internet , LAN , etc . .[ 0028 ] It should be appreciated that the scenarios provided above have been included for illustrative purposes only and are not intended to limit the communication configurations available for system 100 in any way .","label":"Background","metadata":{},"score":"62.943054"}
{"text":"In the above example , the customer will be asked ( in talk script ) about the date of the appointment , because only this information has not specified when ordering the service .[ 0061 ] Once the values generated indicate that all the needed information is present , then the data can be stored and used to make the appointment .","label":"Background","metadata":{},"score":"62.98047"}
{"text":"BACKGROUND OF THE INVENTION .In many instances , it is necessary to verify that an individual requesting access to a service or a facility is in fact authorized to access the service or facility .For example , such services may include banking services , telephone services , or home video provision services , while the facilities may be , for example , banks , computer systems , or database systems .","label":"Background","metadata":{},"score":"63.080822"}
{"text":"Table 2 shows the success rates for the various repair methods in both experiments .The column labeled \" Highlight \" reports the results when the errorful section was highlighted exactly by hand .The other column gives the results when the highlighting was with the automatic subpiece location method described above .","label":"Background","metadata":{},"score":"63.082592"}
{"text":"Table 2 shows the success rates for the various repair methods in both experiments .The column labeled \" Highlight \" reports the results when the errorful section was highlighted exactly by hand .The other column gives the results when the highlighting was with the automatic subpiece location method described above .","label":"Background","metadata":{},"score":"63.082592"}
{"text":"A string of words like \" GET ME ANY \" would be spoken as \" G - E - T - M - E - A - N - Y \" .Again , a language model is created from the subpiece hypotheses in the same position as the errorful subsection in the primary n - best list .","label":"Background","metadata":{},"score":"63.108276"}
{"text":"A string of words like \" GET ME ANY \" would be spoken as \" G - E - T - M - E - A - N - Y \" .Again , a language model is created from the subpiece hypotheses in the same position as the errorful subsection in the primary n - best list .","label":"Background","metadata":{},"score":"63.108276"}
{"text":"claim 1 , further comprising : . defining said plurality of combinations of items of said step ( c ) in a training step .The method of .claim 9 , further comprising : . defining said plurality of combinations of items of said step ( c ) in a training step .","label":"Background","metadata":{},"score":"63.12255"}
{"text":"The method of .The method of .claim 38 , wherein step ( a ) comprises receiving a name associated with the user ; and . said multi - user group comprises users having names which are similar - sounding to said name associated with the user .","label":"Background","metadata":{},"score":"63.206818"}
{"text":"claim 1 , wherein the at least one word is either no or yes .The method of .claim 1 , wherein the at least one word relates to a phrase related to a computer - human interaction .The method of .","label":"Background","metadata":{},"score":"63.2669"}
{"text":"The fast acoustic match initially recognizes items in the incoming labels and performs a reduction process to reduce the number of recognized items that require further processing .Preferably , the fast acoustic match is based on probabilistic finite state machines .","label":"Background","metadata":{},"score":"63.406887"}
{"text":"Input device 24 and recognition engine 18 could take any suitable form to provide other correction modalities .The output of the correction and repair module 12 may be displayed on a screen 26 of a computer 28 .The computer 28 may be provided with standard input devices such as keyboard 30 and mouse 32 .","label":"Background","metadata":{},"score":"63.480278"}
{"text":"Input device 24 and recognition engine 18 could take any suitable form to provide other correction modalities .The output of the correction and repair module 12 may be displayed on a screen 26 of a computer 28 .The computer 28 may be provided with standard input devices such as keyboard 30 and mouse 32 .","label":"Background","metadata":{},"score":"63.480278"}
{"text":"Use of dependent formalism would occasionally eliminate a conversion and imposes no limitations on messages , however , dependent formalism would also permit excessive application specific knowledge within the discourse layer 27 of the SUI ( e.g. , the fact that a specific query is SQL - format ) .","label":"Background","metadata":{},"score":"63.538094"}
{"text":"The conceptual language model 116 which can be one implementation of the conceptual syntax module 114 can be built and trained by analyzing a large conceptual corpus as will be described in greater detail with reference to FIG .2 .The conceptual language model can include a collection of conditional probabilities corresponding to the combination of items in the vocabulary .","label":"Background","metadata":{},"score":"63.63095"}
{"text":"This data defines the behavior of the processes , and as such the behavior of the whole SUI .In order to develop an application with the SUI these data files have to be filled with application specific data .The SUI data files contain application specific information that can be edited with development tools .","label":"Background","metadata":{},"score":"63.834316"}
{"text":"A preferred embodiment of the present invention includes a general speech user interface ( SUI ) employing spoken dialog technology that combines and coordinates the traditional speech technologies - ASR , TTS , and SMC - along with the technologies of spoken language understanding , spoken language generation and dialog management .","label":"Background","metadata":{},"score":"64.042725"}
{"text":"claim 24 , wherein said step ( c ) is processed using conceptual grammar .The machine - readable storage of .claim 22 , further comprising : . a training step defining said vocabulary of items of said step ( d ) .","label":"Background","metadata":{},"score":"64.06009"}
{"text":"Next , utilizing the specific information from the identified user 's database , the server 22 generates a random question ( or multiple random questions ) for the user via link 36 .The user answers the random question(s ) which is sent back to the server 22 via link 38 .","label":"Background","metadata":{},"score":"64.34272"}
{"text":"The method and apparatus receive the inquiry from a client via a network .Based on the inquiry , question - answer pairs retrieved from the network are analyzed to determine a response to the inquiry .The QA pairs are not predefined .","label":"Background","metadata":{},"score":"64.34695"}
{"text":"The word corpus 202 can include real sentences that should be recognized .The word pronunciation dictionary 204 can include sequences of phonemes reflecting the pronunciations of words contained in the word corpus .A conceptual corpus 206 can be generated from the combination of the concepts / words contained in the concept / word table 200 with the words contained in the word corpus 202 by performing every possible translation defined in the concept / word table 200 .","label":"Background","metadata":{},"score":"64.51768"}
{"text":"S j .Likewise , dynamic parameters ( features ) may be introduced , i.e. age , time when a person attempts to access the service / facility , location from which the caller is calling , etc . and denote them as D 1 , D 2 , D 3 , . . .","label":"Background","metadata":{},"score":"64.732635"}
{"text":"In some special transactions , handwriting recognition or signature verification is also used .However , such conventional user verification techniques present many drawbacks .First , information typically used to verify a user 's identity may be easily obtained .Any perpetrator who is reasonably prepared to commit fraud usually finds it easy to obtain such personal information such as a social security number , mother 's maiden name or date of birth of his intended target .","label":"Background","metadata":{},"score":"64.78793"}
{"text":"Self - validation is also provided such that whenever a score associated with the biometric match is poor , the present invention may be used to still admit the person but also to correct the models on the assumption that they are outdated .","label":"Background","metadata":{},"score":"65.182594"}
{"text":"Each hypothesis in the secondary n - best list ( from best to worst ) is evaluated to determine if it is a substring of the first hypothesis of the primary recognition at step 52 .The best match is presented to the user at step 51 , and if accepted by the user , the endpoints of that substring are returned as the location of the respoken subpiece at step 53 and the evaluation stops .","label":"Background","metadata":{},"score":"65.20548"}
{"text":"Each hypothesis in the secondary n - best list ( from best to worst ) is evaluated to determine if it is a substring of the first hypothesis of the primary recognition at step 52 .The best match is presented to the user at step 51 , and if accepted by the user , the endpoints of that substring are returned as the location of the respoken subpiece at step 53 and the evaluation stops .","label":"Background","metadata":{},"score":"65.20548"}
{"text":"[ 0035 ]In one embodiment , this process can be repeated by the Session Manager 105 as often as necessary until the Session Manager 105 has received sufficient information to determine the identity of the service 108 requested in the voice data presented by the user 101 .","label":"Background","metadata":{},"score":"65.272064"}
{"text":"The method further includes communicating a subset of the digitized ultrasound data for at least some of the plurality of transmit events , wherein the subsets of communicated digitized ultrasound data are different for the plurality transmit events .Ronen Tur , Binyamina IL .","label":"Background","metadata":{},"score":"65.35858"}
{"text":"The output of decoder 106 is then a reduced list of decoded items resulting from both processes of the fast and the detailed acoustic match modules .The decoded items output from the acoustic decoder 106 can be provided to the application - specific TFIM 120 which can execute the function corresponding to the decoded output .","label":"Background","metadata":{},"score":"65.56134"}
{"text":"Vicente R. Tur , Barcelona ES .Patent application number .Description .Published .TNF Family Ligand Variants - The present invention relates to variants of TNF family ligands which have been mutated at the ligand trimerisation interface so that they are not capable of assembling into trimers , and either assemble into dimers or remain as monomers .","label":"Background","metadata":{},"score":"65.593796"}
{"text":"The TFIM 120 can check the decoder 106 output under specific conditions .A condition can be a combination of concept codes .For example , if in a decoded sentence the concept codes \" QUERY \" and \" PHONE \" are identified , the TFIM 120 can execute the function \" QUERY - PHONE - FUNCTION \" passing the datum \" NAME \" as an argument in the call .","label":"Background","metadata":{},"score":"65.62775"}
{"text":"The SUI processes the user input , extracts the meaning , and sends a message , step 306 , instructing the application to list unread mail .The application then , in step 307 , looks mail in its database , and sends a message back to the SUI that five new messages are waiting , step 308 .","label":"Background","metadata":{},"score":"65.684326"}
{"text":"By way of analogy , a fast match technique employed in the speech recognition environment is disclosed in the article by L. R. Bahl et al . , \" A Fast Approximate Acoustic Match for Large Vocabulary Speech Recognition \" , IEEE Trans .","label":"Background","metadata":{},"score":"65.68648"}
{"text":"In another embodiment , the telephony device 102 can be communicatively linked with the Human Understanding System 103 via a digital land line , e.g. , digital fiber optic connection , configured to transmit voice data using discrete digital binary signals .","label":"Background","metadata":{},"score":"65.71922"}
{"text":"5,953,700 , which is commonly assigned and is filed concurrently with the present invention , and to copending application Ser .No .09/548,016 filed Apr. 12 , 2000 , which is itself a continuation of U.S. application Ser .No . 08/788,471 filed Jan. 28 , 1997 , now U.S. Pat .","label":"Background","metadata":{},"score":"65.86823"}
{"text":"0038 ] Once the Session Manager 105 has successfully identified the service 108 requested by the user , the Session Manager 105 starts to execute conversation script defined for this service .[ 0039 ] FIG .2 is a detailed illustration of the internal components of the Session Manager 105 and how those components interact with the rest of the modules in the Human Understanding System 103 , in accordance with one embodiment .","label":"Background","metadata":{},"score":"66.071884"}
{"text":"The method of claim 10 , further comprising when all special concepts are present and assigned a value , then performing or completing the service .The method of claim 11 , wherein performing the service comprises storing the information included in the utterance and associated with the special concepts .","label":"Background","metadata":{},"score":"66.10164"}
{"text":"In step 301 of FIG .3 , a user calls into an e - mail application which in communication with the SUI .In step 302 , the e - mail application sends an application - specific message to the SUI telling it to initialize an instance of email - type dialogue , which the SUI does in step 303 .","label":"Background","metadata":{},"score":"66.17253"}
{"text":"2 shows an application 21 interfaced with the SUI .The application 21 communicates to the SUI via the SUI API 22 .To the application 21 , the SUI is just another input / output means .Besides the SUI , the application 21 may also communicate with the user in various non - speech ways such as by a graphical user interface that allows keyboard and mouse input and that shows results on a display screen .","label":"Background","metadata":{},"score":"66.508606"}
{"text":"FIG .3 is a flow chart illustrating an example process whereby system 100 is used to select and provide a service 108 ( the \" Selective Service State ' ) to a user 101 in more detail and in accordance with one embodiment .","label":"Background","metadata":{},"score":"66.66974"}
{"text":"Conversation scripts 203 can call other services in certain embodiments .For example , in a rental car application , a special service configured to chose an appropriate rental car company based on the state , city , type of car , etc . , can be called in order to complete the service .","label":"Background","metadata":{},"score":"66.669815"}
{"text":"Patent application number .Description .Published .Sweep - Free Stimulated Brillouin Scattering - Based Fiber Optical Sensing - Methods and systems used to perform sweep - free stimulated Brillouin scattering - based fiber optical sensing are described .In one aspect , a method includes interrogating different parts of a Brillouin gain spectrum using multiple optical tones in an optical fiber .","label":"Background","metadata":{},"score":"66.84233"}
{"text":"Gokhan Tur , Fremont , CA US .Patent application number .METHOD AND APPARATUS FOR TAILORING THE OUTPUT OF AN INTELLIGENT AUTOMATED ASSISTANT TO A USER - The present invention relates to a method and apparatus for tailoring the output of an intelligent automated assistant .","label":"Background","metadata":{},"score":"66.89344"}
{"text":"The resource manager 37 needs to be instantiated only once and may serve multiple applications and multiple instances in a system .The resource manager 27 has its own platform independent API , however , its specific implementation is platform and configuration dependent .","label":"Background","metadata":{},"score":"67.5795"}
{"text":"In case of lack of this information , Special Concepts Prospector 230 returns to Script Engine 202 appropriate questions which can be forwarded to customer 101 via Voice Generator Module 106 .After receiving an answer , the process can be repeated if necessary .","label":"Background","metadata":{},"score":"67.75793"}
{"text":"The method of .The method of .claim 32 , wherein step ( a ) comprises receiving said first piece of information as one of a static feature and a dynamic feature .The method of .The method of .","label":"Background","metadata":{},"score":"68.09907"}
{"text":"claim 3 , wherein step ( a ) comprises receiving said identity claim as an internal static feature comprising at least one of : gender , speech rate , accent , preferred vocabulary , preferred request , name , address , date of birth , and family status .","label":"Background","metadata":{},"score":"68.2215"}
{"text":"claim 30 , further comprising the additional steps of : . receiving a second natural language spoken utterance of the user ; . prior to at least one of step ( a ) and said step of receiving said second utterance , querying said user with a question , such that at least one of said first and second natural language spoken utterances are uttered in response to said question ; and .","label":"Background","metadata":{},"score":"68.39061"}
{"text":"The original application was started from a telephony application in Spanish called Conversational Name dialer which was developed by International Business Machines Corporation .Corresponding applications in German , French , and English also were developed using the traditional approach as described below .","label":"Background","metadata":{},"score":"68.51594"}
{"text":"0036 ] It should be appreciated , that the various embodiments discussed above are configured to effectuate highly interactive dialog between the user 101 and the Human Understanding System 103 .The intention is to mimic , as closely as possible , the communications environment between the user 101 and handled services 108 including trying to determine which service 108 or other information is being requested by the user 101 .","label":"Background","metadata":{},"score":"68.72919"}
{"text":"Similarly , a bigram is a string of two consecutive items , and a unigram is a single item .An alternative implementation of the conceptual syntax module 114 can be a conceptual grammar 118 designed to accept each valid combination of concepts and/or data contained in a conceptual corpus which will be discussed with reference to FIG .","label":"Background","metadata":{},"score":"69.194176"}
{"text":"In a preferred embodiment , the SUI API 22 may also provide some additional functionality that is not directly speech - related , e.g. , provisions to enable smart resource allocation .In a preferred embodiment , the SUI API 22 contains a platform - independent core with platform - specific layers over the core .","label":"Background","metadata":{},"score":"69.35351"}
{"text":"The application was able to answer user questions and to establish dialogues when the request had some degree of ambiguity .The application utilized a text - to - speech ( TTS ) module to synthesize voice responses .For example , if the user asked \" Give me the phone number of Fernndez \" the application answered something like \" There are many people so called , let me know some additional information \" .","label":"Background","metadata":{},"score":"69.370605"}
{"text":"Telephony server systems with many telephone lines designed to handle multiple calls simultaneously can run multiple applications at once , e.g. , a server system handling 32 lines for a hotel reservation and another 32 lines for tourist information .FIGS .","label":"Background","metadata":{},"score":"69.427826"}
{"text":"A commitment process in communication with the beliefs knowledge base and the desires knowledge base may compare the desirability of selected possible states and determine a desired policy based on the current state and the desirability of the selected possible states .","label":"Background","metadata":{},"score":"69.82043"}
{"text":"TABLE 3______________________________________Improvement of Sentence AccuracyRepair Method Sentence Accuracy______________________________________None ( baseline ) 63.1%Speak 83.8%Spell 88.5%Speak + Spell 89.0 % _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"70.249245"}
{"text":"TABLE 3______________________________________Improvement of Sentence AccuracyRepair Method Sentence Accuracy______________________________________None ( baseline ) 63.1%Speak 83.8%Spell 88.5%Speak + Spell 89.0 % _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"70.249245"}
{"text":"Now , spelling recognition engine 16 receives a secondary utterance 38 which is spelled \" C E N T E R \" .Spelling recognition engine 16 produces the following secondary alternative list from the spelled secondary utterance : ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 .","label":"Background","metadata":{},"score":"70.9953"}
{"text":"Now , spelling recognition engine 16 receives a secondary utterance 38 which is spelled \" C E N T E R \" .Spelling recognition engine 16 produces the following secondary alternative list from the spelled secondary utterance : ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 .","label":"Background","metadata":{},"score":"70.9953"}
{"text":"The method of .claim 7 , wherein step ( a ) comprises receiving said identity claim via a card swipe .The method of .claim 7 , wherein step ( a ) comprises receiving said identity claim via keyboard input .","label":"Background","metadata":{},"score":"71.21103"}
{"text":"The method of claim 1 additionally comprising the step of weighting the hypotheses , and wherein said step of combining the scores for the hypotheses includes the step of adjusting the score for each hypothesis based on the weight assigned to that hypothesis before combining the scores .","label":"Background","metadata":{},"score":"71.25159"}
{"text":"The method of claim 1 additionally comprising the step of weighting the hypotheses , and wherein said step of combining the scores for the hypotheses includes the step of adjusting the score for each hypothesis based on the weight assigned to that hypothesis before combining the scores .","label":"Background","metadata":{},"score":"71.25159"}
{"text":"The third recognition engine 18 receives input from an appropriate input device 24 .Input device 24 may be a touch sensitive pad or any other input transducer and the third recognition engine 18 may be a handwriting recognition engine or any other device for data entry .","label":"Background","metadata":{},"score":"71.53171"}
{"text":"The third recognition engine 18 receives input from an appropriate input device 24 .Input device 24 may be a touch sensitive pad or any other input transducer and the third recognition engine 18 may be a handwriting recognition engine or any other device for data entry .","label":"Background","metadata":{},"score":"71.53171"}
{"text":"The server 22 then accesses a database ( which is part of the user databases 18 ) via link 30 corresponding to the user ( candidate ) identified during the identification claim .As will be explained , the user .database contains information specific to that particular user .","label":"Background","metadata":{},"score":"71.58795"}
{"text":"The method of . claim 2 , wherein : . step ( d ) comprises generating a first partial probability score ; . step ( e ) comprises generating a second partial probability score ; and . step ( f ) comprises the sub - steps of : .","label":"Background","metadata":{},"score":"71.70196"}
{"text":"O. Schmidbauer et al . , An LVQ Based Reference Model For Speaker Adaptive Speech Recognition , IEEE Proceedings of the International Conference on Acoustics , Speech , and Signal Processing , Mar. 1992 , Pittsburgh , PA . .O. Schmidbauer et al . , An LVQ Based Reference Model For Speaker - Adaptive Speech Recognition , IEEE Proceedings of the International Conference on Acoustics , Speech , and Signal Processing , Mar. 1992 , Pittsburgh , PA .","label":"Background","metadata":{},"score":"71.95936"}
{"text":"O. Schmidbauer et al . , An LVQ Based Reference Model For Speaker Adaptive Speech Recognition , IEEE Proceedings of the International Conference on Acoustics , Speech , and Signal Processing , Mar. 1992 , Pittsburgh , PA . .O. Schmidbauer et al . , An LVQ Based Reference Model For Speaker - Adaptive Speech Recognition , IEEE Proceedings of the International Conference on Acoustics , Speech , and Signal Processing , Mar. 1992 , Pittsburgh , PA .","label":"Background","metadata":{},"score":"71.95936"}
{"text":"The scintillating material can extend over a length greater than approximately 1.1 meters .In an embodiment , the radiation detector can be used near a passageway to detect radioactive material passing through the passageway .More particularly , the radiation detector can be used to detect the radioactive material within a vehicle passing through the passageway .","label":"Background","metadata":{},"score":"72.055176"}
{"text":"The application 21 communicates with the SUI through a SUI API 22 that shields the application 21 from the internals of the SUI .Thus , the SUI API 22 provides all the necessary functionality so that the application 21 can use speech as an interface , without handling many speech - specific details .","label":"Background","metadata":{},"score":"72.39677"}
{"text":"The resulting kernel deep convex network may also be constructed by stacking one shallow kernel network over another with concatenation of the output vector of the lower network with the input data vector .A probability associated with a slot that is associated with slot - filling may be determined , based on local , discriminative features that are extracted using the kernel deep convex network .","label":"Background","metadata":{},"score":"72.423325"}
{"text":"Patent application number .Description .Published .RADIATION DETECTION SYSTEM AND METHOD OF ANALYZING AN ELECTRICAL PULSE OUTPUT BY A RADIATION DETECTOR - A radiation detection system can include a photosensor to receive light from a scintillator via an input and to send an electrical pulse at an output in response to receiving the light .","label":"Background","metadata":{},"score":"72.75894"}
{"text":"A standard reference of probabilistic measure on some set may be found in the reference : Encyclopedia of Mathematics , Vol .6 , Kluwer Academic Publishers , edited by M. Hazewinkel , London ( 1990 ) .In order to estimate the U - measure for all users in the database , one can use one of the following procedures .","label":"Background","metadata":{},"score":"72.81947"}
{"text":"When the information is not sufficient for the Session Manager 105 to determine the identity of the service 106 requested , the Session Manager 105 can be configured to generate an appropriate text to query the user 101 for the necessary information required to make that determination .","label":"Background","metadata":{},"score":"73.06516"}
{"text":"The expression \" Give me the phone number of \" can be treated as a semantic identifier and can be recognized by a concept code \" QUERY \" or \" QUERY - EN \" to indicate the English language in a multilingual application .","label":"Background","metadata":{},"score":"73.16362"}
{"text":"To understand Special Concepts Prospector 230 , it is necessary to explain what these special concepts are .They are concepts which do not need to be understood , e.g. names , colors , addresses .Rather , what is of interest is a value or rank that can be associated with the concept .","label":"Background","metadata":{},"score":"73.192474"}
{"text":"FIG .5 depicts the conversion of representative text into a language independent semantic representation of the utterance meaning by the natural language understanding step 405 of FIG .4 .In the representative text phrase : \" please list my mail since Friday the twenty - second , \" the NLU module 35 performs an action linking mapping of the first part of the phrase , please list my mail 501 into the linguistic content meaning LIST MAIL 502 .","label":"Background","metadata":{},"score":"73.490524"}
{"text":"To confirm the call type , the spoken dialog service may request a confirmation : \" You are asking for your account balance .Is this correct ? \" The customer may respond by a simple \" Yes \" or \" No . \" Some customer may however choose to elaborate and say \" No I am not asking about my balance .","label":"Background","metadata":{},"score":"73.728065"}
{"text":"claim 4 , wherein said step ( e ) is processed using a conceptual language model .The method of . claim 5 , wherein said conceptual language model is an n - gram conceptual language model .The method of .","label":"Background","metadata":{},"score":"73.789215"}
{"text":"Patent application number .Description .Published .CYTOKINE DESIGN -The present invention relates to novel cytokines , which have a modified selectivity / specificity for their cognate receptors .In particular , the invention relates to a variant TRAIL protein , which has superior selectivity for the death receptor 4 ( TRAIL - RI ) over the death receptor 5 ( TRAIL - R2 ) .","label":"Background","metadata":{},"score":"73.9126"}
{"text":"Mehmet Kemal Tur , Koln DE .Patent application number .The complex allows to influence the growth and the physiology of cells .In particular said complex , nucleic acid molecules encoding it , cells transfected or transformed with these nucleic acid molecules are usable for the preparation of medicaments for the treatment of proliferative diseases , inflammatory diseases , allergies and autoimmune diseases .","label":"Background","metadata":{},"score":"74.22508"}
{"text":"The method of .The method of .claim 3 , wherein step ( a ) comprises receiving said identity claim as an external static feature comprising at least one of : phone number from which the user is calling and time of day when the user is calling .","label":"Background","metadata":{},"score":"74.28396"}
{"text":"( score 20)3 . center !( score 19)4 . sent there !( score 17)5 . sent are !( score 14 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"74.522736"}
{"text":"( score 20)3 . center !( score 19)4 . sent there !( score 17)5 . sent are !( score 14 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"74.522736"}
{"text":"In order to be accessed via the Human Understanding System 103 , each service 106 must be first defined in this system .[ 0023 ] Thus , system 100 can be configured to handle a plurality of services 108 and provide them to the user 101 through the Human Understanding System 103 .","label":"Background","metadata":{},"score":"74.7599"}
{"text":"The computer - readable medium is any data storage device that can store data , which can thereafter be read by a computer system .Examples of the computer - readable medium include hard drives , network attached storage ( NAS ) , read - only memory , random - access memory , CD - ROMs , CD - Rs , CD - RWs , magnetic tapes , and other optical and non - optical data storage devices .","label":"Background","metadata":{},"score":"74.77495"}
{"text":"1 : Speak 70.1 % 64.6%Exp . 1 : Spell 82.6 % 70.8%Exp .1 : Speak + Spell 84.0 % 73.6%Exp .2 : Speak 67.4 % 62.7 % _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"75.183945"}
{"text":"1 : Speak 70.1 % 64.6%Exp . 1 : Spell 82.6 % 70.8%Exp .1 : Speak + Spell 84.0 % 73.6%Exp .2 : Speak 67.4 % 62.7 % _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"75.183945"}
{"text":"This expression can be interpreted as a command utterance where the system understands \" I want to speak to ' Pedro Romero ' \" .As will be discussed later in further detail , in such cases the speech recognition system can tag the utterance as \" Pedro_fn Romero_In \" .","label":"Background","metadata":{},"score":"75.393326"}
{"text":"RADIATION DETECTOR AND METHOD OF USING A RADIATION DETECTOR - A radiation detector can include a scintillating material to produce scintillation light in response to receiving neutrons , gamma radiation , potentially other targeted radiation , or any combination thereof .In a particular embodiment , the detector converts scintillating light to an electrical pulse and analyzes the shape of the electrical pulse to determine whether neutrons , gamma rays , or potentially other targeted radiation are detected .","label":"Background","metadata":{},"score":"75.473816"}
{"text":"A desires knowledge base 4 determines a qualitative evaluation of possible states by having positive or negative responses to possible states , thereby creating a comparison of the desirability of various states .A commitment process 5 determines a desired action policy based on the information in the beliefs knowledge base 2 and in the desires knowledge base 4 .","label":"Background","metadata":{},"score":"75.540375"}
{"text":"Description .RELATED APPLICATIONS .The present application is related to U.S. patent application Ser .No .10/329,138 filed Dec. 24 , 2002 , and U.S. patent application Ser .No .10/446,489 filed May 28 , 2003 .The contents of each of these patent applications are incorporated herein by reference .","label":"Background","metadata":{},"score":"75.903175"}
{"text":"Patent application number .Description .Published .ORGANIC COMPOUNDS - The present invention relates to human thymic stromal lymphopoietin ( hTSLP ) antibodies and especially those which neutralize hTSLP activity .It further relates to methods for using anti - hTSLP antibody molecules in diagnosis or treatment of hTSLP related disorders , such as asthma , atopic dermatitis , allergic rhinitis , fibrosis , inflammatory bowel disease and Hodgkin 's lymphoma .","label":"Background","metadata":{},"score":"76.108475"}
{"text":"The term \" U - measure \" simply refers to a user measure or a measure on a user population .The measure may be any standard statistical measure on some set of events .In the context of the invention , the events are that some users from a set of users will try to access a service and/or facility .","label":"Background","metadata":{},"score":"76.34005"}
{"text":"For example , the user can address the application using formal or informal expressions , such as beginning a sentence with a greeting like \" hello \" , \" good morning \" , \" good afternoon \" , etc .Alternatively , the user optionally can identify him or herself ( \" I 'm Antonio Garca from IBM Madrid \" ) .","label":"Background","metadata":{},"score":"77.65525"}
{"text":"Patent application number .Organic Compounds - The present invention relates to human thymic stromal lymphopoietin ( hTSLP ) antibodies and especially those which neutralize hTSLP activity .It further relates to methods for using anti - hTSLP antibody molecules in diagnosis or treatment of hTSLP related disorders , such as asthma , atopic dermatitis , allergic rhinitis , fibrosis inflammatory bowel disease , and Hodgkin 's lymphoma .","label":"Background","metadata":{},"score":"77.78501"}
{"text":"Voice over Internet Protocol ( VOIP ) is a modern form of digital - based telephony that uses Transmission Control Protocol / Internet Protocol ( TCP / IP ) and other network transmission formats for transmitting digitized voice data through the Internet .","label":"Background","metadata":{},"score":"79.121025"}
{"text":"[0053 ] The Service Data Manager 205 can be configured to store data associated with the various services in Service Database 204 .In addition , Service Database 205 can be configured to store information received from user 101 as well as , e.g. , Special Concepts Processor 230 .","label":"Background","metadata":{},"score":"79.56213"}
{"text":"claim 24 , wherein said step ( e ) is processed using a conceptual language model .The machine - readable storage of .claim 25 , wherein said conceptual language model is an n - gram conceptual language model .The machine - readable storage of . claim 26 , further comprising an initial step of training said conceptual language model .","label":"Background","metadata":{},"score":"80.16425"}
{"text":"DISTRIBUTED AND DYNAMICAL BRILLOUIN SENSING IN OPTICAL FIBERS - A method of distributed and dynamical Brillouin sensing in optical fibers is provided herein .FAST BRILLOUIN OPTICAL TIME DOMAIN ANALYSIS FOR DYNAMIC SENSING - A method for conducting fast Brillouin optical time domain analysis for dynamic sensing of optical fibers is provided herein .","label":"Background","metadata":{},"score":"80.245834"}
{"text":"Such utterances are composed of \" No \" plus some intent , such as \" No I do not want the checking account balance I want the savings account balance \" .According to this invention , this is accomplished for example by placing the word \" no \" in front of some selected utterances .","label":"Background","metadata":{},"score":"82.2807"}
{"text":"( Score 11 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"82.45892"}
{"text":"( Score 11 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"82.45892"}
{"text":"That creates a primary alternative list as follows : ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . can there !","label":"Background","metadata":{},"score":"82.8804"}
{"text":"That creates a primary alternative list as follows : ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . can there !","label":"Background","metadata":{},"score":"82.8804"}
{"text":"That produces an alternative meaning list of the following type which is input to the repair module 12 at step 76 ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . is it near the indian ocean ( score 1020)2 .","label":"Background","metadata":{},"score":"83.16708"}
{"text":"That produces an alternative meaning list of the following type which is input to the repair module 12 at step 76 ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . is it near the indian ocean ( score 1020)2 .","label":"Background","metadata":{},"score":"83.16708"}
{"text":"( score 22)3 . sent there !( score 15)4 . send there !( score 11)5 . can there !( score 10 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"83.68407"}
{"text":"( score 22)3 . sent there !( score 15)4 . send there !( score 11)5 . can there !( score 10 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"83.68407"}
{"text":"The user 12 calls a central server 22 via link 24 .The user 12 identifies himself via his name , for example , and requests access to the service / facility .The central server 22 then performs the following operations .","label":"Background","metadata":{},"score":"84.34279"}
{"text":"The conceptual pronunciation dictionary 112 can be generated from the combination of the concept / word table 200 with the word pronunciation dictionary 204 .The conceptual pronunciation dictionary 112 can be obtained by replacing every word of the concept word table 200 by its corresponding pronunciation stored in the word pronunciation dictionary 204 .","label":"Background","metadata":{},"score":"84.52096"}
{"text":"No .09/275,592 , filed Mar. 24 , 1999 , now U.S. Pat .No .6,161,090 , which is continuation of U.S. application Ser .No .08/871,784 , filed Jun. 11 , 1997 , now U.S. Pat .No .","label":"Background","metadata":{},"score":"84.75272"}
{"text":"S E N T A R E !( Score 14 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"85.63377"}
{"text":"S E N T A R E !( Score 14 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"85.63377"}
{"text":"As in the previous examples , the speech recognition engine 14 generates , at step 54 , the n - best list : ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . can there it around the indian ocean ( score 102)2 . send there it around the indian ocean ( score 95)3 . center it around the indian ocean ( score 93)4 . sent there around the indian ocean ( score 80)5 . sent are around the indian ocean ( score 73 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"87.33983"}
{"text":"As in the previous examples , the speech recognition engine 14 generates , at step 54 , the n - best list : ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . can there it around the indian ocean ( score 102)2 . send there it around the indian ocean ( score 95)3 . center it around the indian ocean ( score 93)4 . sent there around the indian ocean ( score 80)5 . sent are around the indian ocean ( score 73 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"87.33983"}
{"text":"it was sent to the indian ocean ( score 800 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"87.36902"}
{"text":"it was sent to the indian ocean ( score 800 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"87.36902"}
{"text":"The time is now [ current time]. ' ' or ' ' It is currently [ current time]. ' '","label":"Background","metadata":{},"score":"89.52646"}
{"text":"The last part of the representative text phrase , Friday the twenty - second 505 , is handled by a semantic fragment interpreter for dates into the proper content form //22//FRI 506 .Example BNF grammar rules for such a process are illustrated in FIG .","label":"Background","metadata":{},"score":"90.598885"}
{"text":"( Score 24)2 .S E N T A R E !( Score 22)3 .C A N T H E R E !( Score 17)4 .S E N T T H E R E !( Score 15)5 .","label":"Background","metadata":{},"score":"90.63628"}
{"text":"( Score 24)2 .S E N T A R E !( Score 22)3 .C A N T H E R E !( Score 17)4 .S E N T T H E R E !( Score 15)5 .","label":"Background","metadata":{},"score":"90.63628"}
{"text":"C A N T H E R E !( Score 23)2 .S E N D T H E R E !( Score 20)3 .C E N T E R !( Score 19)4 .S E N T T H E R E !","label":"Background","metadata":{},"score":"91.46269"}
{"text":"C A N T H E R E !( Score 23)2 .S E N D T H E R E !( Score 20)3 .C E N T E R !( Score 19)4 .S E N T T H E R E !","label":"Background","metadata":{},"score":"91.46269"}
{"text":"the indian ocean is the center ( score 1300)4 .remove the contents of the center in ( score 1210)the indian ocean5 .where in the indian ocean was it sent ( score 1100)6 .is it near the indian ocean ( score 1020)7 .","label":"Background","metadata":{},"score":"91.62924"}
{"text":"the indian ocean is the center ( score 1300)4 .remove the contents of the center in ( score 1210)the indian ocean5 .where in the indian ocean was it sent ( score 1100)6 .is it near the indian ocean ( score 1020)7 .","label":"Background","metadata":{},"score":"91.62924"}
{"text":"The primary n - best list may be of the following type : ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . can there it around the indian ocean ( score 102)2 . send there it around the indian ocean ( score 95)3 . center it around the indian ocean ( score 93)4 . sent there around the indian ocean ( score 80)5 . sent are around the indian ocean ( score 73 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"92.472244"}
{"text":"The primary n - best list may be of the following type : ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . can there it around the indian ocean ( score 102)2 . send there it around the indian ocean ( score 95)3 . center it around the indian ocean ( score 93)4 . sent there around the indian ocean ( score 80)5 . sent are around the indian ocean ( score 73 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"92.472244"}
{"text":"The fast acoustic match 108 and detailed acoustic match 110 , which are operatively coupled to each other , can be collectively referred to as a decoder 106 .A conceptual pronunciation dictionary 112 and a conceptual syntax module 114 each can be operatively coupled to both the fast acoustic match 108 and the detailed acoustic match 110 .","label":"Background","metadata":{},"score":"92.65033"}
{"text":"Ronen Tur , Tirat Carmel IL .Patent application number .Description .Published .METHODS AND SYSTEMS FOR DATA COMMUNICATION IN AN ULTRASOUND SYSTEM - Methods and systems for data communication in an ultrasound system are provided .One method includes acquiring ultrasound data using an ultrasound probe having a plurality of transducer elements , wherein the ultrasound data includes echo information acquired from the plurality of transducer elements and the ultrasound data is acquired using a plurality of transmit events of the ultrasound probe .","label":"Background","metadata":{},"score":"93.86222"}
{"text":"the indian ocean is the center ( score 1300)4 .remove the contents of the center in ( score 1210)the indian ocean5 .where in the indian ocean was it sent ( score 1100 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"95.42982"}
{"text":"the indian ocean is the center ( score 1300)4 .remove the contents of the center in ( score 1210)the indian ocean5 .where in the indian ocean was it sent ( score 1100 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"95.42982"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . but the center in the indian ocean ( score 150)2 . put the center in the indian ocean ( score 148)3 .","label":"Background","metadata":{},"score":"95.69827"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . but the center in the indian ocean ( score 150)2 . put the center in the indian ocean ( score 148)3 .","label":"Background","metadata":{},"score":"95.69827"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . move the center to the indian ocean ( score 2500)2 .","label":"Background","metadata":{},"score":"97.477234"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . move the center to the indian ocean ( score 2500)2 .","label":"Background","metadata":{},"score":"97.477234"}
{"text":"HELLO QUESTION PHONE Pedro(FIRSTNAME ) LOCATION Madrid(CITY ) POLITE .QUESTION DUMMY PHONE Pedro(FIRSTNAME)Romero(LASTNAME ) DUMMY LOCATION Sevilla(CITY ) .PHONE Maria(FIRSTNAME)Fernndez(LASTNAME ) DUMMY LOCATION Sevilla(CITY ) .The invention can be embodied in other specific forms without departing from the spirit or essential attributes thereof , and accordingly , reference should be had to the following claims , rather than to the foregoing specification , as indicating the scope of the invention .","label":"Background","metadata":{},"score":"100.20472"}
{"text":"gut the center in the indian ocean ( score 121)5 .put was sent where in the indian ocean ( score 110 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"101.715546"}
{"text":"gut the center in the indian ocean ( score 121)5 .put was sent where in the indian ocean ( score 110 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"101.715546"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . the center is in the indian ocean ( score 1500)2 .","label":"Background","metadata":{},"score":"102.3506"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . the center is in the indian ocean ( score 1500)2 .","label":"Background","metadata":{},"score":"102.3506"}
{"text":"it around the indian ocean ( score 93)4 . sent there ! around the indian ocean ( score 80)5 . sent are ! around the indian ocean ( score 73 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"104.177826"}
{"text":"it around the indian ocean ( score 93)4 . sent there ! around the indian ocean ( score 80)5 . sent are ! around the indian ocean ( score 73 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"104.177826"}
