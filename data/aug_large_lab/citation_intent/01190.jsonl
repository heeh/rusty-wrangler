{"text":"Evaluating on 10,000 pairs of summaries , where hit A appears above B , but B receives more clicks , Clarke et al . , 2007 found significant effects for the following features : .Where possible , all the query terms should appear in the surrogate , reflecting their relationship to the corresponding Web page .","label":"Background","metadata":{},"score":"34.896805"}
{"text":"The results which are returned and which contain \" most likely \" query term translations may be placed higher in a ranked list of results than those containing a target language query term generated from a less likely translation alternative .A specific example illustrating such re - ranking is described hereinafter .","label":"Background","metadata":{},"score":"35.092926"}
{"text":"In the specific example , the first two documents are clearly relevant as they contain the preferred glossing translations of the terms of the source language query .However , by using a limited number of less - preferred translations , the chances of missing a relevant document are reduced whereas the number of irrelevant documents located is also reduced .","label":"Background","metadata":{},"score":"38.19888"}
{"text":"The highest scoring sentences are then included in the summary .White et al . , 2003a experimented with different sentence selection mechanisms , including giving more weight to sentences that contained query words along with text formatting ( e.g. , boldface or italics ) .","label":"Background","metadata":{},"score":"39.21498"}
{"text":"A look at their nearest neighbors is usually sufficient to get a good idea of the topic that the word pertains to as demonstrated in Table 1 .With higher - order word representations , the user examines nearest neighbors as direct diagnostics for each individual term , thereby composing a query that matches the information needs of the user more closely .","label":"Background","metadata":{},"score":"40.03177"}
{"text":"5.2.1 : Sentence Selection for Query - Oriented Summaries .There are significant design questions about how best to formulate and display query - biased summaries .As with standard document summarization and extraction , tradeoff decisions must be made between how many lines of text to show and which lines to display .","label":"Background","metadata":{},"score":"40.076332"}
{"text":"The language and query processing components of the automatic query translation and construction system are described in detail in Hedlund , et al .( 2001a ) and Pirkola , et al .Retrieval system and query operators .As a test system , the study used the Inquery retrieval system ( Allan , et al . , 2000 ; Broglio , et al .","label":"Background","metadata":{},"score":"40.888912"}
{"text":"look for the word itself ( A ) in word A 's FreqComp List and get its value .a apply formula of ( Lower×6+Higher)/7 , where Lower is the lower of the two values obtained in the above two steps and Higher is the higher of the two values .","label":"Background","metadata":{},"score":"41.179626"}
{"text":"look for the word itself ( A ) in word A 's FreqComp List and get its value .a apply formula of ( Lower×6+Higher)/7 , where Lower is the lower of the two values obtained in the above two steps and Higher is the higher of the two values .","label":"Background","metadata":{},"score":"41.179626"}
{"text":"Instead of evaluating the query as a whole , each subtopic should be evaluated individually and the results combined .If a document is irrelevant to one of the important subtopics of the query , then it often is irrelevant as a whole .","label":"Background","metadata":{},"score":"41.458855"}
{"text":"In terms of relevance feedback , the basic approach has been to modify the initial query using words from top - ranked ( for query expansion ) or identified relevant documents .Ponte ( 2000 ) simply adds some additional words to the query based on the log ratio of the probability of occurrence in the model for relevant documents to the probability in the whole collection .","label":"Background","metadata":{},"score":"41.5524"}
{"text":"If the query is sufficiently ambiguous ( according to our measure ) , we should be able to identify the most probable contexts ( word associations , language models ) .Given those contexts , we plan to select sample sentences that are representative of them .","label":"Background","metadata":{},"score":"42.26996"}
{"text":"Joachims et al . , 2005 also found bias in relevance judgements based on placement location .They did a followup experiment focusing on the top two results , since these are scanned equally frequently .They compared how often a participant clicked on either result 1 or result 2 depending on the manually judged relevance of the abstract .","label":"Background","metadata":{},"score":"42.33399"}
{"text":"Joachims et al . , 2005 also found that participants tended to view the first and second - ranked results right away , with a large gap before viewing the third - ranked abstract .They also found that while participants did not necessarily view all abstracts above a click , they view substantially more abstracts above than below the click .","label":"Background","metadata":{},"score":"42.739502"}
{"text":"In this case , the words \" making use of \" constitute a non - continuous collocation spanning the word \" good \" .By detecting such non - continuous collocations , it is possible to improve the precision of translating the query into the target language .","label":"Background","metadata":{},"score":"43.001892"}
{"text":"The average rank of a click in the normal condition was 2.66 and 4.03 in the reversed condition .However , the average relevance of the selected documents in the reversed condition was lower than in the normal condition .Guan and Cutrell , 2007 performed an eye - tracking study in which they pre - determined the queries and results , and controlled which of the top 10 positions the one relevant result appeared in .","label":"Background","metadata":{},"score":"43.284218"}
{"text":"In the alternative , the ranking can be stored in a RAM or permanent storage device .Referring to FIG .13 , each memory location stores the rank , the document identification and the correlation coefficient .The process described in FIG .","label":"Background","metadata":{},"score":"43.28486"}
{"text":"In the specific example described hereinbefore , the glosser was required to identify only a single continuous collocation in addition to the individual words of the source language query .However , the glosser disclosed in EP 0 813 160 and GB 2 314 183 is also capable of identifying non - continuous collocations .","label":"Background","metadata":{},"score":"43.41993"}
{"text":"The keywords are then ranked by SWAPS value and the highest ranked are presented to the user as suggested SWAPS terms to be added to the query .The Soft Boolean Connectors concept involves penalizing pairs of terms that co - occur often ( i.e. , in many documents ) when calculating the adjustment to be applied to the summed relpoly percentages .","label":"Background","metadata":{},"score":"43.531273"}
{"text":"The keywords are then ranked by SWAPS value and the highest ranked are presented to the user as suggested SWAPS terms to be added to the query .The Soft Boolean Connectors concept involves penalizing pairs of terms that co - occur often ( i.e. , in many documents ) when calculating the adjustment to be applied to the summed relpoly percentages .","label":"Background","metadata":{},"score":"43.531273"}
{"text":", 2001b ) .The correspondents were combined by the syn - operator .This method was useful improving query performance , but in RATF - weighting seems to be harmful .Single key weighting based on aekvRATF gives better performance than baseline .","label":"Background","metadata":{},"score":"43.850876"}
{"text":"In Miller et al ( 1999 ) , words from relevant documents were added to the query and probabilities in their model adjusted by training over queries .Although both of these approaches produced good results , they are not very satisfactory models from the point of view of describing and defining query contexts and user models , which are central to personalization .","label":"Background","metadata":{},"score":"43.859062"}
{"text":"By scoring each factor separately and recombining them appropriately , documents are scored highly on all factors , and thus introduce a conjunctive constraint .For example , a document may score high for a query as a whole although it deals with only one of the subtopics of the query .","label":"Background","metadata":{},"score":"43.890984"}
{"text":"For a source language query including a compound AB and a single word C , the syn - query is as follows : .Test queries ( CLIR queries ) .Reduced Queries .In the first test we examined whether the RATF scheme is helpful in recognizing bad query keys , i.e. , keys which tend to lower query performance .","label":"Background","metadata":{},"score":"43.903603"}
{"text":"In particular , the step 34 selects the most likely translations using the ordering generated in the step 32 .The source words and collocations and the remaining target language translations are then arranged as indexing features by appending an identifier of the document d in which they were contained or from which they were derived .","label":"Background","metadata":{},"score":"44.008713"}
{"text":"This is discussed in the next section .Inferring Language Models .To infer the query model from either top - ranked documents ( in the case of query expansion ) or identified relevant documents ( in the case of relevance feedback ) requires an approach where document text can be viewed as samples from the query model .","label":"Background","metadata":{},"score":"44.217865"}
{"text":"Therefore in this study we will use the best syn - query type ( i.e. , syn - queries without uwn ) as baseline for RATF - based queries .The results of the syn / uwn tests are published later but shortly discussed here .","label":"Background","metadata":{},"score":"44.594666"}
{"text":"For example , if the document contains only 3 out of the 4 original terms in the query , then its maximum rank is 75 % .Related terms contribute less weight than the original ( exact ) words .If your query consists of three query terms , a document containing one instance of each of the three terms will be ranked higher than a document containing 100 instances of one of the query terms .","label":"Background","metadata":{},"score":"44.737732"}
{"text":"The sentences would be shown to the user for clarification .This process can be viewed as a generalization of a KWIC index .By using a language model view of ambiguity , we hope to resolve the context of the query quickly and with minimal user input .","label":"Background","metadata":{},"score":"44.87284"}
{"text":"Also , alternative translations may be ranked according to a criterion indicating the likelihood of each translation being correct .Thus , the number of translations actually used in target - language query formulation may be adjusted to the requirements of a searcher .","label":"Background","metadata":{},"score":"44.922077"}
{"text":"Table 2 shows that the word \" tank \" can be disambiguated both ways in WordSpace .A query consisting of the terms \" tank \" and \" water \" retrieves only words relevant to the \" receptacle \" sense of the word \" tank .","label":"Background","metadata":{},"score":"45.381165"}
{"text":"Such terms may then be used in the target language query so that either : only documents containing such terms are retrieved ; or documents containing such terms and documents not containing such terms but fulfilling other search criteria are retrieved .","label":"Background","metadata":{},"score":"45.601467"}
{"text":"For example , such terms may be carried over into the target language query only if they are identified as proper names .Thus , terms which are not identified as proper names are rejected and do not form part of the target language query .","label":"Background","metadata":{},"score":"45.661053"}
{"text":"However , the best RATF - based queries performed better than baseline queries also in the CLEF collection .Introduction .Standard best - match retrieval systems are based on the tf.idf weighting scheme ( e.g. , Robertson , et al . , 1995 ; Salton , 1989 ; Singhal , et al .","label":"Background","metadata":{},"score":"45.692787"}
{"text":"The data for this analysis is a corpus language model based on co - occurrence of words .This approach was initially developed for summarization ( Lawrie and Croft , 2001 ) and we are currently testing its application to query ambiguity .","label":"Background","metadata":{},"score":"45.826435"}
{"text":"In an earlier study we demonstrated that the use of average term frequencies of keys as key weights contributes to better retrieval performance in monolingual IR ( Pirkola and Järvelin , 2001b ) .We developed a query key goodness scheme that calculates goodness weights for keys on the basis of cf / df ( average term frequency ) and df statistics of a document collection .","label":"Background","metadata":{},"score":"45.869926"}
{"text":"The information management system 16 performs a matching process .In particular , the system 16 searches the target language documents for matches between the target language query and the text of the documents .Whenever a match is found , the document is down - loaded as a target language result 17 .","label":"Background","metadata":{},"score":"46.201412"}
{"text":"Given the extra information available , this is not the desired behaviour .Using the extra information , the results are re - ranked based on the likelihood of the translation alternatives .In the simplest case , for example , the formula : \" number of occurrences of the terms in the document \" times \" likelihood of the term \" may be applied .","label":"Background","metadata":{},"score":"46.24804"}
{"text":"The word interstice is an example of a mistranslated word whose RATF is high .Methods and data .Test collections , requests , and query formulation .In this study we used the same training request set as in the monolingual retrieval tests in Pirkola and Järvelin ( 2001b ) .","label":"Background","metadata":{},"score":"46.25631"}
{"text":"One solution to this problem is to perform a dimensionality reduction of the order-1 vectors by means of a singular value decomposition , which is disclosed in Deerwester et al . cited above .It can be used to find a linear approximation of the original high - dimensional space ( one dimension for each word ) in an r - dimensional , reduced space , for an r on the order of 10 . sup.2 .","label":"Background","metadata":{},"score":"46.358635"}
{"text":"Note that the final reduction in dimensionality was performed because smoothing and improved generality results from a singular value decomposition reduction .Similarity between b - component vectors can contain a large error measure of semantic similarity since there may be several word classes with similar topics .","label":"Background","metadata":{},"score":"46.445343"}
{"text":"Several of these studies are discussed below .The first result was selected approximately 85 % of the time , and the second link about 10 % of the time .Furthermore , the first and second results were by far the most viewed , with a sharp dropoff starting with the third result .","label":"Background","metadata":{},"score":"46.46768"}
{"text":"( 5 )A user program that accepts a query , suggests modifications to the query , and ranks the documents based on the modified query using the weights and relative strengths of the terms of the query .The Vocabulary file is structured as a list of headwords each with a short synonym list .","label":"Background","metadata":{},"score":"46.657703"}
{"text":"( 5 )A user program that accepts a query , suggests modifications to the query , and ranks the documents based on the modified query using the weights and relative strengths of the terms of the query .The Vocabulary file is structured as a list of headwords each with a short synonym list .","label":"Background","metadata":{},"score":"46.657703"}
{"text":"Thus , the step 32 provides a prioritising or ordering of each set of translations corresponding to a source language word or collocation .A technique for deriving such priority information is disclosed in EP 0 813 160 and GB 2 314 183 .","label":"Background","metadata":{},"score":"46.81493"}
{"text":"In the second ( see Figure 5.4 ) , an overview screen on the side showed a miniature version of the entire document with query terms highlighted , as well as providing highlighting on the main page as in the first case .","label":"Background","metadata":{},"score":"46.859528"}
{"text":"This display helps draw the searcher 's attention to the parts of the document most likely to be relevant to the query , and to show how closely the query terms appear to one another in the text .As discussed in Chapter 4 , query term proximity is a strong indicator of relevance .","label":"Background","metadata":{},"score":"46.9899"}
{"text":"2 illustrates a method of retrieving information which may be performed by the apparatus shown in FIG .1 .A source language query , for example in English , is formulated at 11 , for instance , by being entered on a keyboard of the input interface 3 .","label":"Background","metadata":{},"score":"47.267006"}
{"text":"See Grefenstette , G. ; \" Use of Syntactic Context to Produce Term Association Lists for Text Retrieval \" ; Proceedings of SIGIR 1992 ; pp .89 - 97 .See Ruge , G. ; \" Experiments on Linguistically - based Term Associations \" ; Information Processing & Management 28 ( 3 ) ; pp .","label":"Background","metadata":{},"score":"47.292274"}
{"text":"They then describe a technique for constructing a query model with no relevance data .These probabilities are used to smooth the query model , and the computation is very similar to successful , ad - hoc query expansion techniques such as LCA ( Xu and Croft , 2000 ) .","label":"Background","metadata":{},"score":"47.5202"}
{"text":"Any of these techniques are always more effective when applied to document filtering rather than relevance feedback , because in that application there is significantly more training data .The language model approach to feedback does not at first appear to lend itself to relevance feedback .","label":"Background","metadata":{},"score":"47.534607"}
{"text":"By contrast , research suggests that query - biased summaries are superior to showing the first few sentences in retrieval results .Tombros and Sanderson , 1998 , in a study with 20 participants using TREC ad hoc data , found higher precision and recall and higher subjective preferences for query - biased summaries over summaries showing the first few sentences of retrieval results .","label":"Background","metadata":{},"score":"47.65032"}
{"text":"This time the previously added SWAPS term \" statutes \" will be given extra weight in determining which new terms are suggested to the user .In FIG .5 we see the resulting suggested SWAPS terms generated from the four query terms \" agreement \" , \" statutes \" , \" enforcement \" , and \" can \" , with \" statutes \" given more weight than the other three terms .","label":"Background","metadata":{},"score":"47.68438"}
{"text":"This time the previously added SWAPS term \" statutes \" will be given extra weight in determining which new terms are suggested to the user .In FIG .5 we see the resulting suggested SWAPS terms generated from the four query terms \" agreement \" , \" statutes \" , \" enforcement \" , and \" can \" , with \" statutes \" given more weight than the other three terms .","label":"Background","metadata":{},"score":"47.684395"}
{"text":"Thus , the equation for the correlation coefficient is : # # EQU15 # # where d.sub.i is the query vector and d.sub.j is the document vector .After calculating all of the correlation coefficients , the documents are ranked in step 252 from most relevant to least relevant .","label":"Background","metadata":{},"score":"47.780746"}
{"text":"Thus , a searcher who is unfamiliar with the target language can determine with higher precision whether identified target language documents are indeed relevant to the query .The efficacy of cross - linguistic retrieval may therefore be substantially improved irrespective of whether a searcher is familiar with the target language .","label":"Background","metadata":{},"score":"47.847584"}
{"text":"Such a characterization makes the user less dependent on well chosen document titles .It is easier to process than a long title , particularly if only the coarse topic of a document is of interest .In general , the nearest neighbors provide additional information on the content of a document that can be used for document selection or relevance feedback .","label":"Background","metadata":{},"score":"48.283638"}
{"text":"For example , where the multilingual resource is a bilingual dictionary , this default translation may be the preferred translation obtained from the dictionary .Where information has been obtained on the frequency of occurrence of a term , for example by analysing a large number of documents , the most common term may be selected as the default translation .","label":"Background","metadata":{},"score":"48.47351"}
{"text":"Each element b.sub.ij records the number of times the w.sub.j co - occurs with any of the medium - frequency words from class g.sub.Ai .This is similar to the usual co - occurrence matrix construction except that the matrix is no longer symmetric .","label":"Background","metadata":{},"score":"48.540092"}
{"text":"The RATF - based CLIR queries are compared with syn - queries .In many studies the syn - queries of the Inquery retrieval system have been demonstrated to perform very well in CLIR ( Ballesteros and Croft , 1998 ; Gollins , 2000 ; Hedlund , et al . , 2001a ; Meng , et al . , 2000 ; Pirkola , 1998 ; Pirkola , et al . , 2000 ; Oard and Wang , 2001 ; Sperer and Oard , 2000 ) .","label":"Background","metadata":{},"score":"48.618996"}
{"text":"Finally a Sanitize algorithm is used to \" X \" out ( eliminate ) proper names from in the highlights .See FIG .12 for specific details on the algorithms used in the ABSTRACT program .Once the indexing and optionally the ABSTRACT programs have been run , the QSEARCH program can be used to search for documents .","label":"Background","metadata":{},"score":"48.722733"}
{"text":"Finally a Sanitize algorithm is used to \" X \" out ( eliminate ) proper names from in the highlights .See FIG .12 for specific details on the algorithms used in the ABSTRACT program .Once the indexing and optionally the ABSTRACT programs have been run , the QSEARCH program can be used to search for documents .","label":"Background","metadata":{},"score":"48.722733"}
{"text":"If both A and F are in each other 's FC lists , the resulting Relative value will be added to both words ' Relative lists .If F is in A 's FC List , but A is not in F 's then F - VAL will be divided by seven and added only to A 's Relative list .","label":"Background","metadata":{},"score":"48.828003"}
{"text":"If both A and F are in each other 's FC lists , the resulting Relative value will be added to both words ' Relative lists .If F is in A 's FC List , but A is not in F 's then F - VAL will be divided by seven and added only to A 's Relative list .","label":"Background","metadata":{},"score":"48.828003"}
{"text":"The representation of documents gives rise to a similarity measure that reflects topical relatedness better than a scheme based on literal matches .Topical or semantic similarity between two words can then be defined as the cosine between the corresponding columns of the matrix C as defined in equation 3a .","label":"Background","metadata":{},"score":"48.83039"}
{"text":"White et al . , 2003b performed an experiment with 18 participants that found that showing high - ranking sentences alone might be better than showing snippets .Kanungo and Orr , 2009 obtained hand - labeled readability scores and then used a machine learning algorithm to determine which of a small set of features predicted readability .","label":"Background","metadata":{},"score":"48.898422"}
{"text":"Mitra , M. , Buckley , C. , Singhal , A. and Cardie , C. ( 1997 ) . \"An analysis of statistical and syntactic phrases \" .Proceedings of RIAO'97 , Computer Assisted Information Searching on the Internet , Montreal , Canada , pp . , 200 - 214 .","label":"Background","metadata":{},"score":"49.012604"}
{"text":"For example , a hierarchical thesaurus is formed from a computer list of complex noun phrases where subsumption roughly corresponds to the subset relation defined on terms , e.g. , \" intelligence \" subsumes \" artificial intelligence \" .See Evans et al . ; \" Automatic Indexing Using Selective NLP and First - order Thesauri \" ; Proceedings of the RIAO ; Vol . 2 , pp .","label":"Background","metadata":{},"score":"49.102264"}
{"text":"Another problem is that a query and a document can share ambiguous words .Thus , the word may be used in a different sense in the document than in the query .In this case , the query and the document may have a high degree of similarity according to a measurement of the cosine function of equation 3b even though the query and the document do not overlap in the intended topic .","label":"Background","metadata":{},"score":"49.18207"}
{"text":"For each term having more than one translation , the glosser may be arranged to supply more than one of the translations .The query forming means may be arranged to include in the target language query at least some of any terms in the source language query which can not be converted into the target language by the multilingual resource .","label":"Background","metadata":{},"score":"49.217964"}
{"text":"A large - scale singular value decomposition can be used for information retrieval .See Deerwester et al . ; \" Indexing by Latent Semantic Analysis \" ; Journal of the American Society of Information Science 41 ( 6 ) ; pp .","label":"Background","metadata":{},"score":"49.23032"}
{"text":"In this case , it is necessary to identify words which are likely to appear in the relevant documents but which are unlikely to appear in irrelevant documents .Searching using keywords than reveals all documents which contain the keywords or combination of keywords .","label":"Background","metadata":{},"score":"49.248573"}
{"text":"5.3 : Highlighting Query Terms .Highlighting of query terms has been found time and again to be a useful feature for information access interfaces ( Landauer et al . , 1993 , Lesk , 1997 , Marchionini , 1995 ) .","label":"Background","metadata":{},"score":"49.293808"}
{"text":"The revised query is then used to produce a new document ranking .Another common way of describing relevance feedback is to a Bayesian classification model of retrieval ( Van Rijsbergen , 1979 ) .In this approach , identified relevant documents are used to estimate the characteristics ( probabilities of occurrences of words ) of the relevant class of documents for a query .","label":"Background","metadata":{},"score":"49.308617"}
{"text":"This is preferably of the limited non - deterministic type , for instance as disclosed in EP 0 813 160 and GB 2 314 183 .Although the document glosser 13 is the preferred type of multilingual resource for the apparatus , other types of resource are illustrated in FIG .","label":"Background","metadata":{},"score":"49.318966"}
{"text":"Thus , the evidence suggests that for queries that are more exploratory in nature , a paragraph - length excerpt may be preferable to a short , elided snippet , despite the extra scrolling it requires to see more results , so long as that paragraph is not too long .","label":"Background","metadata":{},"score":"49.509296"}
{"text":"These sets do not contain translations of the individual words \" make \" , \" use \" and \" of \" so that a large number of possibly irrelevant senses of the constituent terms of the collocation \" make use of \" are eliminated .","label":"Background","metadata":{},"score":"49.537758"}
{"text":"The query is treated as a sample of text from a language model , and the documents are ranked according to the probability that the document language model could generate the query text .This simple model produces surprisingly good retrieval results , and the model has been extended in a variety of ways .","label":"Background","metadata":{},"score":"49.627625"}
{"text":"That is , the original matrix lists only the words actually in each document , whereas we might be interested in all words related to each document - generally a much larger set due to synonymy .The consequence of the rank lowering is that some dimensions are combined and depend on more than one term : .","label":"Background","metadata":{},"score":"49.70079"}
{"text":"The result of the maximum rank is stored in step 346 of FIG .16 .The memory locations of the final ranking is shown in FIG .18 .The highest ranking document is most relevant to the query .The memory lists the rank , the result of the maximum ranking of equation 23 , and the document identification number .","label":"Background","metadata":{},"score":"49.745426"}
{"text":"For example , one effect of this may be that , because information retrieval systems are often statistical in nature , more common terms may be allowed to contribute fewer documents to a retrieval system so as to leave more room for other terms to contribute documents .","label":"Background","metadata":{},"score":"49.79837"}
{"text":"In FIG .6 he would choose the View Documents option .The system will then use its index files to assign a value to each document and then rank the documents .Then the summed - weightpoly values are adjusted using the Soft Boolean Connectors concept to come up with a final value for each document .","label":"Background","metadata":{},"score":"49.871414"}
{"text":"In FIG .6 he would choose the View Documents option .The system will then use its index files to assign a value to each document and then rank the documents .Then the summed - weightpoly values are adjusted using the Soft Boolean Connectors concept to come up with a final value for each document .","label":"Background","metadata":{},"score":"49.871414"}
{"text":"This is used to compute the amount of contextual evidence that supports a word .The closer the terms are in relationship to the query words , the more weight they are given .To further refine the relevance , the search looks at the physical location of query words and related terms within the document , as well as the total number of terms .","label":"Background","metadata":{},"score":"49.92221"}
{"text":"3 .A query is shown in the section CURRENT QUERY .These words are collected in the pool of words to be examined in the section called POOL .The user can add or delete words from this pool depending on the output of the search .","label":"Background","metadata":{},"score":"49.954094"}
{"text":"However , both of these approaches have disadvantages .Selecting all possible translations of source language query terms may lead to the retrieval of many documents which are not relevant to the query .This is because source language words have different meanings in different contexts and , based on these , have different preferred translations .","label":"Background","metadata":{},"score":"49.954117"}
{"text":"The generating step may comprise accessing a multilingual resource with each identified term and the equivalent terms may be translations of the identified terms , more general terms than the identified terms and more specific terms than the identified terms .The multilingual resource may comprise a glosser .","label":"Background","metadata":{},"score":"49.994434"}
{"text":"Words are then compared by taking the cosine of the angle between the two vectors formed by any two rows .Values close to 1 represent very similar words while values close to 0 represent very dissimilar words .[ 1 ] .","label":"Background","metadata":{},"score":"50.14054"}
{"text":"In earlier studies the contribution of the uwn - operator on the effectiveness of syn - queries have not been tested .We , however , tested the effects of the uwn - operator .The results are presented in a later paper .","label":"Background","metadata":{},"score":"50.1589"}
{"text":"5 ; .FIG .7 is a view of the display screen as a result of ranking the documents for the query of FIG .6 ; .FIG .8 is an operational flow diagram for indexing a set of documents ; .","label":"Background","metadata":{},"score":"50.18746"}
{"text":"5 ; .FIG .7 is a view of the display screen as a result of ranking the documents for the query of FIG .6 ; .FIG .8 is an operational flow diagram for indexing a set of documents ; .","label":"Background","metadata":{},"score":"50.18746"}
{"text":"( d.sub.j ) is the context vector for document d.sub.j .In step 342 , the documents are ranked based on the correlation coefficient assigned and the appropriate factor .The ranking of the documents within a factor is based on correlation : .","label":"Background","metadata":{},"score":"50.21473"}
{"text":"Synonymous terms have similar neighbors and hence will contribute a similar \" direction \" in the multidimensional space of document vectors .Ambiguous terms have two different sorts of neighbors .In computing a document vector , those terms that correspond to the sense used in the document will be reinforced whereas the direction represented by the inappropriate sense will not be present in other words .","label":"Background","metadata":{},"score":"50.269756"}
{"text":"The at least part of each document may comprise a sentence containing terms which match the query in the target language .The multilingual resource may be a bilingual glosser .The glosser may be arranged to identify and translate each term of the source language query .","label":"Background","metadata":{},"score":"50.407513"}
{"text":"Proper nouns and other named entities tended to appear at a higher percentage in summary vs. non - summary sentences .Those approaches ignore relationships between sentences .Varadarajan and Hristidis , 2006 presented a method to create query specific summaries by identifying the most query - relevant fragments and then combining them using graphs representing the document structure .","label":"Background","metadata":{},"score":"50.449585"}
{"text":"The definitions for encoding words are analogous to those in equations 1 - 2 and 4 - 5 except that the restricted vocabulary V.sub .N containing the N most frequent content words is used .In the second step , the representations for the total vocabulary are computed by summing up the reduced order-1 vectors of all neighbors of a given word .","label":"Background","metadata":{},"score":"50.508705"}
{"text":"Length and complexity of URLs should be reduced , and URLs should be selected and displayed in a manner that emphasizes their relationship to the query .They also found effects for the appearance of particular words .Among others , official , and , tourism , attractions , sexy , and information had positive influence on clickthrough , whereas encyclopedia , wikipedia , and free had negative influence .","label":"Background","metadata":{},"score":"50.56499"}
{"text":"When deciding on a strategy for formulating target language queries , it may be necessary to consider the actual form of the multilingual resource .For example , machine translation systems may generate target language query terms which are quite rare whereas glossers might generate more common terms .","label":"Background","metadata":{},"score":"50.598846"}
{"text":"2 to the analysis shown in FIG .3 .For instance , the operation of the analysis illustrated in FIG .3 will be described with reference to a document having an identifier number # 8 .Document # 8 comprises English sentences which are analyzed one at a time .","label":"Background","metadata":{},"score":"50.661224"}
{"text":"Thus , short documents with many hits are ranked higher than longer documents where those same hits are present .A method for forming an index comprising indexing features for a plurality of documents , comprising data - processing apparatus implemented steps of : . identifying each of at least some of the terms present in the documents ; . generating from each identified term at least one equivalent term which is different from but linguistically related to the identified term ; . forming for each of the identified terms a first indexing feature comprising the identified term and an identifier of the or each document in which the identified term occurs ; . forming for each of the equivalent terms a second indexing feature comprising the equivalent term and an identifier of the or each document in which the identified term to which the equivalent term is equivalent occurs ; and .","label":"Background","metadata":{},"score":"50.71717"}
{"text":"The source and target languages are preferably natural languages .The multilingual resource may be a bilingual glosser .The glosser may identify and translate each term of the source language query .The glosser may identify and translate terms which are collocations but may not translate the individual words of the collocations .","label":"Background","metadata":{},"score":"50.767612"}
{"text":"The results suggest that RATF - based weighting is not useful in queries where important keys are weighted through query key frequencies .RATF - based weighting and query key frequency weighting seem to be competitive methods .Third , in the CLEF tests source query keys not found in the dictionary were translated by an n - gram matching technique .","label":"Background","metadata":{},"score":"50.852623"}
{"text":"It is unclear if sentence fragments are preferable to full sentences , despite the fact that sentences take up more space on the page .Aula , 2004 performed a controlled experiment comparing three different layouts for query - biased summaries , as shown in Figure 2.3 in Chapter 2 , with the aim of determining if showing a series of sentence fragments separated by ellipses is desirable .","label":"Background","metadata":{},"score":"50.948677"}
{"text":"( b ) storing on said file system a collection of documents each with an associated unique document - number ; .( c ) creating index files which contain for each said term - code in ( a ) .( i ) the set of document - numbers in ( b ) such that the corresponding documents contain the corresponding term ; and .","label":"Background","metadata":{},"score":"50.975967"}
{"text":"( b ) storing on said file system a collection of documents each with an associated unique document - number ; .( c ) creating index files which contain for each said term - code in ( a ) .( i ) the set of document - numbers in ( b ) such that the corresponding documents contain the corresponding term ; and .","label":"Background","metadata":{},"score":"50.975967"}
{"text":"The decision whether a word factor was relevant or not was made manually .The word factors that were judged relevant were then combined according to the algorithm described above .The top line in FIG .19 shows the precision for 11 recall points for .","label":"Background","metadata":{},"score":"50.989594"}
{"text":"However , it is very likely that cases close to . will occur .This leads to results which can be justified on the mathematical level , but have no interpretable meaning in natural language .LSA can not capture polysemy ( i.e. , multiple meanings of a word ) .","label":"Background","metadata":{},"score":"51.019825"}
{"text":"Another approach is to reuse existing on - line lexicographic databases , such as WordNet ( see Voorhees et al . ; \" Vector Expansion in a Large Collection \" ; Proceedings of TREC , 1992 . ) or Longman 's subject codes ( see Liddy et al . ; \" Statistically - guided Word Sense Disambiguation \" ; Working Notes of the AAAI Fall Symposium on Probabilistic Approaches to Natural Language ; 1992 AAAI Press ) .","label":"Background","metadata":{},"score":"51.073837"}
{"text":"Thus , documents with many hits close together are ranked higher than documents where those same hits are present , but scattered very far apart .Hit Density : The greater the ratio of query words and related terms to the total number of words in the document , the greater the weight .","label":"Background","metadata":{},"score":"51.13079"}
{"text":"The second goal of word factorization is to eliminate irrelevant words semi - automatically .Many words in the Tipster topic descriptions are not relevant for the query in question , but they should not be placed on a stop list either because they could be relevant for other queries .","label":"Background","metadata":{},"score":"51.157425"}
{"text":"There is a very high probability that this limited number of translations selected from all possible translations will include the best or correct translation .Accordingly , accessing documents using indexes formed in this way provides a high probability of locating all relevant documents while reducing the numbers of irrelevant documents which might otherwise be located .","label":"Background","metadata":{},"score":"51.226753"}
{"text":"As a first step , the search simply looks for the existence or absence of query words or related terms in the document .The rank calculation process takes into account various factors - each factor adds a certain relative \" weight \" to the document .","label":"Background","metadata":{},"score":"51.228165"}
{"text":"The steps 24 and 25 are performed by the document glosser 13 .In a step 26 , a parameter \" element \" is set to a value of one and a parameter X is set to the value of the cardinality of the set D i.e. the number of words and collocations in the set D. A step 27 tests whether \" element \" is less than or equal to X and , if so , a step 28 is performed .","label":"Background","metadata":{},"score":"51.23346"}
{"text":"The preliminary tests have been encouraging .It is possible that n - gram matching together with RKA will effectively recognize the correct correspondents .This in turn may allow an effective use of RATF in CLIR also when n - gram based translation is applied .","label":"Background","metadata":{},"score":"51.24733"}
{"text":"The glosser may form a plurality of translations of at least one of the identified terms and may assign to each translation a priority according to the likelihood of the translation being correct .The multilingual resource may comprise a bilingual dictionary .","label":"Background","metadata":{},"score":"51.27587"}
{"text":"This is especially important for ambiguous queries for which there are several common interpretations or meanings for a given word .For example , a search on the term labs at Google at the time of writing shows three sets of results on the first page , separated by horizontal rules ( see Figure 5.1 ) .","label":"Background","metadata":{},"score":"51.27661"}
{"text":"By making use of the thesaurus entries , synonymic , more general and more specific terms may be added to the index to increase the likelihood that an arbitrary query will locate a relevant document during information retrieval .By using multilingual resources , indexing may be performed in an efficient and effective manner in languages other than the source or document language .","label":"Background","metadata":{},"score":"51.30535"}
{"text":"For navigational queries , when participants did not find the result below position 3 , they either selected the first hit ( 40 % of the time ) or reformulated their query .For informational search , participants rarely reformulated the query without first trying to click on the first hit ( about 50 % of the time ) or clicking on the other links at random .","label":"Background","metadata":{},"score":"51.307648"}
{"text":"Similar results for timing and subjective measurements were found by White et al . , 2003a in a study with 24 participants .With a query - biased summary , in many cases , an information need can be satisfied by viewing the document surrogate alone .","label":"Background","metadata":{},"score":"51.32171"}
{"text":"Baseline and test queries .In this section , we will describe the baseline and test queries ( CLIR queries ) investigated in the study .The following notations will be used : .In query language expressions below the translation equivalents are just enumerated , without intervening commas and braces , following the InQuery query language syntax .","label":"Background","metadata":{},"score":"51.400444"}
{"text":"Thus , although known techniques for cross - linguistic information retrieval may be used , the efficacy of such information retrieval can only be checked by searchers who have sufficient familiarity with the target language not to need to use such techniques .","label":"Background","metadata":{},"score":"51.474335"}
{"text":"The discussion of search ads is outside the scope of this book .5.5 : The Effects of Search Results Ordering .Search results are often listed in an order specified by a relevance metric .Alternatively , results are ordered according to a metadata attribute , such as reverse chronological order for news search and email search , or number of citing papers for journal article search .","label":"Background","metadata":{},"score":"51.50563"}
{"text":"118 - 155 .Crouch , C.J. , \" An Approach to the Automatic Construction of Global Thesauri \" , Information Processing & Management , vol .26 , No . 5 , pp .629 - 640 , 1990 .Deerwester et al . , \" Indexing by Latent Semantic Analysis \" , Journal of the American Society for Information Science 41(6 ) , pp .","label":"Background","metadata":{},"score":"51.519405"}
{"text":"In order to search documents in a different \" target \" language from the \" source \" language of the query , the dictionary - based approach looks up the query terms in a bilingual dictionary .All possible translations of each source language query term are used to form a query in the target language and the matching process is then performed in the target language .","label":"Background","metadata":{},"score":"51.541714"}
{"text":"The target language query may include at least some of any terms in the source language query which can not be converted into the target language by the multilingual resource .The at least part of each document may comprise a title of the document .","label":"Background","metadata":{},"score":"51.623177"}
{"text":"To facilitate very rapid perusal of the ranked documents , the document values ( used in the ranking ) are presented as a bar graph as shown in FIG . 7 .Also the documents are presented in 3 forms .The first form consists of a ranked array of the highest ranked terms in the document that requires only about 1/3 of the display screen ( FIG .","label":"Background","metadata":{},"score":"51.65556"}
{"text":"To facilitate very rapid perusal of the ranked documents , the document values ( used in the ranking ) are presented as a bar graph as shown in FIG . 7 .Also the documents are presented in 3 forms .The first form consists of a ranked array of the highest ranked terms in the document that requires only about 1/3 of the display screen ( FIG .","label":"Background","metadata":{},"score":"51.655563"}
{"text":"A method according to . claim 1 , wherein the source and target languages are natural languages .A method according to . claim 1 , wherein the multilingual resource is a bilingual glosser .A method according to .claim 3 , wherein the glosser identifies and translates each term of the source language query .","label":"Background","metadata":{},"score":"51.805824"}
{"text":"1 is a block diagram of a computer system embodying the present invention ; .FIG .2 is a view of the display screen showing an entered query and the result of parsing it ; .FIG .3 is a view of the display screen showing suggested SWAPS terms for the query of FIG .","label":"Background","metadata":{},"score":"51.838005"}
{"text":"1 is a block diagram of a computer system embodying the present invention ; .FIG .2 is a view of the display screen showing an entered query and the result of parsing it ; .FIG .3 is a view of the display screen showing suggested SWAPS terms for the query of FIG .","label":"Background","metadata":{},"score":"51.838005"}
{"text":"The user program will parse the query to find all the keywords it contains using algorithms similar to those in the AIM program .After the query is parsed the user is shown the keywords that are contained in the query in order of their polysemantic weight and is given the opportunity to add and delete words in the query and to have the program suggest SWAPS terms based on the query .","label":"Background","metadata":{},"score":"51.842766"}
{"text":"The user program will parse the query to find all the keywords it contains using algorithms similar to those in the AIM program .After the query is parsed the user is shown the keywords that are contained in the query in order of their polysemantic weight and is given the opportunity to add and delete words in the query and to have the program suggest SWAPS terms based on the query .","label":"Background","metadata":{},"score":"51.842766"}
{"text":"This is short - term personalization .Starting with the same query , two users could end up with very different documents or answers depending on their feedback .Put another way , the system uses the user 's feedback to learn the specific context they have in mind for the initial query .","label":"Background","metadata":{},"score":"51.903267"}
{"text":"For example , any word with a frequency of one and any word pair with a frequency of less than five are not important .The word pair \" computer science \" will appear throughout the text .Therefore , it will probably appear more times than the other three word pairs , which will only appear in the title .","label":"Background","metadata":{},"score":"51.945675"}
{"text":"Thus , a query and a document could have a similarity measure of zero in this simple scheme even though the query content can be understood as a reasonable description of the topic of the document .This is the problem of synonymy of words .","label":"Background","metadata":{},"score":"51.99163"}
{"text":"Byrd , 1999 suggested applying a different color to each query term , and showing the corresponding colors to the appropriate locations within a scrollbar - like widget ( see Figure 10.13 ) .The Thumbar system ( Graham , 1999 ) used a similar scrollbar widget on the left hand side and a visualization of hits for the important terms of the document on the right hand side .","label":"Background","metadata":{},"score":"52.165363"}
{"text":"The use of query key frequency is a kind of disambiguation technique .( 3 ) Syn - queries .In syn - based structuring the translation equivalents of each source language key are grouped together by the syn- operator of the Inquery retrieval system .","label":"Background","metadata":{},"score":"52.1703"}
{"text":"However , short avgRATF / syn - queries and short aekvRATF / syn - queries perform slightly worse than short plain syn - queries .The CLEF tests .The CLEF results are presented in Table 10 .As shown , single key weighting using RATF results in the decrease in retrieval performance .","label":"Background","metadata":{},"score":"52.259415"}
{"text":"Alternatives are related by the Boolean logic OR operator in the query .The query is applied to the target language information management system in a step 31 , which retrieves the search results in the form of documents in the target language .","label":"Background","metadata":{},"score":"52.297836"}
{"text":"LSA can use a term - document matrix which describes the occurrences of terms in documents ; it is a sparse matrix whose rows correspond to terms and whose columns correspond to documents .This matrix is also common to standard semantic models , though it is not necessarily explicitly expressed as a matrix , since the mathematical properties of matrices are not always used .","label":"Background","metadata":{},"score":"52.41922"}
{"text":"The first part of addressing query ambiguity is to define it and quantify it .We are currently developing a language model framework to do this .One simple approach would be to assume that there are a fixed number of topic models for a collection and use a clustering technique to \" discover \" them .","label":"Background","metadata":{},"score":"52.530205"}
{"text":"In the graph of FIG .19 , the bottom line uses the recall points for tf.idf .The middle line uses the recall points for linear combination for the optimal choice of . alpha . , which is 0.7 .Thus the average precision for tf.idf is 0.271 and the average precision for the linear combination of tf.idf and context vectors is 0.300 .","label":"Background","metadata":{},"score":"52.569984"}
{"text":"This , however , seems to imply that we will need more input from the users rather than less .In summary then , relevance feedback and query expansion is a personalization technique that attempts to infer a user 's context from the query and additional feedback .","label":"Background","metadata":{},"score":"52.575184"}
{"text":"5.2.2 : Summary Length for Query - Oriented Summaries .For determining how many words or sentences to show , there is an inherent tradeoff between showing long , informative summaries and minimizing the screen space required by each search hit .","label":"Background","metadata":{},"score":"52.661304"}
{"text":"A third preferred embodiment uses the thesaurus vectors to analyze the query into topic - coherent word groups , which are called word factors .The goal is to ensure that documents are relevant to the entire query such that their score with respect to each factor is high .","label":"Background","metadata":{},"score":"52.7144"}
{"text":"Use of only the preferred translation of each query term solves the problem of large numbers of documents .However , known machine translation systems are of limited accuracy and would frequently select an inappropriate translation as the preferred translation .Thus , whenever the translation system selects the wrong translation , the information retrieval system is not very likely to identify documents which are relevant to the subject matter which is sought .","label":"Background","metadata":{},"score":"52.80249"}
{"text":"Abstract .A document indexing and retrieval system and method which assigns weights to the key words and assigns a relative value to pairs of key words ( i.e. defines a relative relation on K×K ) based on their frequency of occurrence and co - occurrence in the document data base .","label":"Background","metadata":{},"score":"52.822727"}
{"text":"Abstract .A document indexing and retrieval system and method which assigns weights to the key words and assigns a relative value to pairs of key words ( i.e. defines a relative relation on K×K ) based on their frequency of occurrence and co - occurrence in the document data base .","label":"Background","metadata":{},"score":"52.822727"}
{"text":"Table 2 shows ambiguity resolution with word vectors of order-2 .The nearest neighbors suggest that higher - order vectors deal with ambiguity and synonymy to some extent , even without user interaction .The example of \" tank \" shows that the information present in higher - order vectors can be used to resolve ambiguity , which is one of the main problems for representations of order-0 .","label":"Background","metadata":{},"score":"52.947563"}
{"text":"Zaromb et al .found that the PLIs had larger cosine values to the just - recalled word in LSA space than the correct item did .[ 7 ] .[ 8 ] .The SVD is typically computed using large matrix methods ( for example , Lanczos methods ) but may also be computed incrementally and with greatly reduced resources via a neural network -like approach , which does not require the large , full - rank matrix to be held in memory .","label":"Background","metadata":{},"score":"52.956173"}
{"text":"Therefore , a false similarity match could occur ( ambiguity problem ) .A second problem is that the same content may be expressed in different words .Therefore , a short query may miss a relevant document ( synonymy problem ) .","label":"Background","metadata":{},"score":"52.96643"}
{"text":"Two terms lexically co - occur if they appear in text within some distance of each other , i.e. , a window of k words .Qualitatively , the fact that two words often occur close to each other is more likely to be significant than the fact that they occur in the same documents .","label":"Background","metadata":{},"score":"52.97464"}
{"text":"Note that the percentages for the co - occurring words can be higher than 100 % if they are heavily weighted in the same records in which A appears .The co - occurring words are then sorted in descending order ( from highest percentage value to lowest ) and the top 127 are written to a file ( see below for structure ) .","label":"Background","metadata":{},"score":"53.03064"}
{"text":"Note that the percentages for the co - occurring words can be higher than 100 % if they are heavily weighted in the same records in which A appears .The co - occurring words are then sorted in descending order ( from highest percentage value to lowest ) and the top 127 are written to a file ( see below for structure ) .","label":"Background","metadata":{},"score":"53.03064"}
{"text":"The full co - occurrence matrix is constructed for a subset of terms in the corpus .For example , 3,000 medium frequency words ( frequency ranks 2,000 through 5,000 ) are chosen for this subset .FIG .6 shows Matrix A with the dimensions of 3000 words by 3000 words .","label":"Background","metadata":{},"score":"53.12533"}
{"text":"For example , if you are searching for information on HIV / AIDS in correctional facilities you could enter : .( AIDS or HIV ) and ( correctional or prison or jail ) .A Concept search will look for the words and phrases you typed as well as related concepts .","label":"Background","metadata":{},"score":"53.130695"}
{"text":"2 shows the options the user will be presented with after entering the query \" when can a contract be enforced \" .If the user chooses the menu option \" Related Terms \" he will be shown a list of SWAPS terms as shown in FIG .","label":"Background","metadata":{},"score":"53.14045"}
{"text":"2 shows the options the user will be presented with after entering the query \" when can a contract be enforced \" .If the user chooses the menu option \" Related Terms \" he will be shown a list of SWAPS terms as shown in FIG .","label":"Background","metadata":{},"score":"53.14045"}
{"text":"Wildcard and Proximity Searching .You can also search for words to be found within a specified number of words of each other .The pattern to follow is : . word1 word2 within N .This means that word1 must be found within N words of word2 . for example . mothers incarcerated within 10 .","label":"Background","metadata":{},"score":"53.151695"}
{"text":"Table 4 displays the nearest neighbors of the articles displayed in Table 3 .These nearest neighbors show that the neighborhood of a document in the space of word vectors is a good characterization of its topic for short , topically focused documents .","label":"Background","metadata":{},"score":"53.242916"}
{"text":"The \" weights \" are determined by the following factors : .Completeness : The greater the number of query words ( either exactly or by reference ) , the higher the weight .A relevant document should contain at least one term or related term for each word in the query .","label":"Background","metadata":{},"score":"53.249638"}
{"text":"Selecting several best matching words was necessary , because the correct key is often found in the word set of 1 - 10 best words in the ranked word list of n - gram matching .However , from the RATF weighting perspective the use of several best matching keys is harmful , since it disturbs query balance .","label":"Background","metadata":{},"score":"53.26265"}
{"text":"If key weighting is solely based on the tf.idf weighting scheme , the word mention might have a strong influence on search results because of its low df , though it apparently is non - topical .The RATF formula , however , ranks it low because of its low atf .","label":"Background","metadata":{},"score":"53.276726"}
{"text":"A further disadvantage with machine translation systems when used to translate documents into a target language for indexing purposes is that the effectiveness of the index may be seriously compromised .Some machine translation systems generate a single preferred translation of an input text .","label":"Background","metadata":{},"score":"53.292374"}
{"text":"Word factors containing nuisance or non - topical terms can be deleted from the query .FIG .14 shows the process for query factorization .In step 300 , the query is input into the processor .The processor retrieves the thesaurus vectors for the words in the query in step 302 .","label":"Background","metadata":{},"score":"53.2927"}
{"text":"In fact , in the bolded view , participants were significantly slower than with the standard view without boldface .Rose et al . , 2007 varied search results summaries along several dimensions , finding that text choppiness and sentence truncation had negative effects , and genre cues had positive effects .","label":"Background","metadata":{},"score":"53.357132"}
{"text":", 1996 , as shown in Figure 5.9 .It remains to be seen if people will use this kind of interface on a regular basis .The extreme sensitivity of searchers to delays of even 0.5 seconds suggests that such highly interactive and visual displays need to have a clear use - case advantage over simple text results before they will succeed .","label":"Background","metadata":{},"score":"53.395275"}
{"text":"Although KWIC and query term highlighting has been thought to be an effective technique for decades ( Luhn , 1959 ) , the prevalence of query - biased summaries is relatively recent .Hearst , 1999b wrote : . \" The KWIC facility is usually not shown in Web search result display , most likely because the system must have a copy of the original document available from which to extract the sentences containing the search terms .","label":"Background","metadata":{},"score":"53.395386"}
{"text":"Terms are then grouped by their occurrence in these document clusters .Since a complete - link document clustering is performed , the procedure is very computationally intensive and does not scale to a large reference corpus .Further , the central assumption that terms are related if they often occur in the same documents seems problematic for corpora with long documents .","label":"Background","metadata":{},"score":"53.55733"}
{"text":"3 .An order-0 retrieval system will only do well on documents that contain both the ambiguous and the disambiguating term , but it will give the same ranking to documents that contain only one of them ( e.g. only water or only tank ) .","label":"Background","metadata":{},"score":"53.593674"}
{"text":"From the language model perspective , inferring the query language model is what is meant by inferring the context of the query .Give the query model , we can predict good suggestions for additional search terms and produce better results by personalizing the search .","label":"Background","metadata":{},"score":"53.636932"}
{"text":"( C ) summing said modified relative penalties to produce a sum of relative penalties ; .( D ) modifying said sum of relative penalties by taking the minimum of said sum and some maximum sum value which depends on the number of terms in the parsed - query table to produce a modified sum of penalties ; .","label":"Background","metadata":{},"score":"53.641647"}
{"text":"( C ) summing said modified relative penalties to produce a sum of relative penalties ; .( D ) modifying said sum of relative penalties by taking the minimum of said sum and some maximum sum value which depends on the number of terms in the parsed - query table to produce a modified sum of penalties ; .","label":"Background","metadata":{},"score":"53.641647"}
{"text":"Second , a similarity measure is induced on words by comparing these vectors .Given a particular word its synonyms are then defined to be its nearest neighbors with respect to the similarity measure .This method of exploiting a lexical co - occurrence structure of words , i.e. , forming a word 's vector representation from entries of its near lexical neighbors rather than from only itself is superior to conventional methods .","label":"Background","metadata":{},"score":"53.655663"}
{"text":"Make your wording more specific .Remember that all of the publications on the Site deal with criminal justice , so including words like crime or justice in your search will bring back too much .Choose a Boolean search instead of a Concept search by using the Advanced Search .","label":"Background","metadata":{},"score":"53.66179"}
{"text":"N - gram matching typically gives one correct correspondent whose RATF is high and five false correspondents whose RATFs also are high ( see the Discussion section ) .The correct correspondent of a source language proper name often occurred in the set of 1 - 10 best matching words in the ranked word list of n - gram matching .","label":"Background","metadata":{},"score":"53.67408"}
{"text":"Howard and Kahana found a positive correlation between the semantic similarity of two words ( as measured by LSA ) and the probability that the words would be recalled one after another in free recall tasks using study lists of random common nouns .","label":"Background","metadata":{},"score":"53.760937"}
{"text":"( t ) displaying other documents corresponding to other document - numbers in the sorted rank table in response to inputs from the user .A method as in claim 1 wherein additional steps ( j)(l ) and ( p)(l ) are carried out after steps ( j ) and ( p ) respectively to implement the soft boolean connector algorithm which consists of the following steps : .","label":"Background","metadata":{},"score":"53.779995"}
{"text":"( t ) displaying other documents corresponding to other document - numbers in the sorted rank table in response to inputs from the user .A method as in claim 1 wherein additional steps ( j)(l ) and ( p)(l ) are carried out after steps ( j ) and ( p ) respectively to implement the soft boolean connector algorithm which consists of the following steps : .","label":"Background","metadata":{},"score":"53.779995"}
{"text":"In an earlier study , we presented a query key goodness scheme , which can be used to separate between good and bad query keys .The scheme is based on the relative average term frequency ( RATF ) values of query keys .","label":"Background","metadata":{},"score":"53.821262"}
{"text":"In the title of this paper the term Kwok 's formula is used as a synonym to the term RATF formula .We developed the RATF formula independently based on our findings in Pirkola and Järvelin ( 2001a ) , which showed that typically 1 - 2 query keys have far higher cf / df and far lower df than the other keys of a query .","label":"Background","metadata":{},"score":"53.919525"}
{"text":"a save the first 63 ( or as many as are found ) of this list as the relatives for keyword A .NOTE :If A is not found in F 's FCList , then A - VAL is zero ( 0 ) .","label":"Background","metadata":{},"score":"53.932465"}
{"text":"a save the first 63 ( or as many as are found ) of this list as the relatives for keyword A .NOTE :If A is not found in F 's FCList , then A - VAL is zero ( 0 ) .","label":"Background","metadata":{},"score":"53.932465"}
{"text":"See McCune et al . ; \" Rubric , A System for Rule - based Information Retrieval \" ; IEEE Transactions on Software Engineering 9 ; pp .939 - 44 ; 1985 .Each topic is a boolean combination of other topics and search terms .","label":"Background","metadata":{},"score":"53.99563"}
{"text":"of_PREP .the_DET . furnace_NOUN .The step 34 generates the indexing features by applying the limited non - determinism i.e. selecting the most likely translations , and associating the source language words and collocations and the target language translations with the identifier ( # 8 ) of the document currently being analyzed as follows : .","label":"Background","metadata":{},"score":"54.007378"}
{"text":"The source language document d is shown at 23 and is supplied to an \" optional \" non - deterministic analysis at a step 24 and then to a step 25 , which identifies individual document words and collocations from the document d and stores them in a set D. The step 24 is performed in turn on each sentence of the document d and represents a non - deterministic analysis of the source language of the sentence .","label":"Background","metadata":{},"score":"54.149612"}
{"text":"The effectiveness of this technique in locating documents in other languages may therefore be poor or nonexistent .In each case , each translation is to be performed by a machine translation system .In the other technique , the documents are not translated but each query is translated into the source or document language and the translations are used to search the document collection .","label":"Background","metadata":{},"score":"54.15933"}
{"text":"The multilingual resource 11 shows four resources which may be used during operation of the apparatus .A document glosser 13 is a \" device \" which labels an \" ordered \" plurality of source language words or collocations ( groups of words ) with target language translations .","label":"Background","metadata":{},"score":"54.2398"}
{"text":"In a study with 18 participants , they found a significant main effect of target position on total task time and on query type .Participants spent more time when the target was farther down the result list , but this extra time did not result in more success at making the correct choice .","label":"Background","metadata":{},"score":"54.240116"}
{"text":"In USER Program Only : IF word NOT found THEN find both the stem AND find the Good prefix .( In the following \" find \" means that the stem and/or prefix is said to be in the document if the prefix is of the right type and the stem has the indicated length and is a keyword . )","label":"Background","metadata":{},"score":"54.250305"}
{"text":"In USER Program Only : IF word NOT found THEN find both the stem AND find the Good prefix .( In the following \" find \" means that the stem and/or prefix is said to be in the document if the prefix is of the right type and the stem has the indicated length and is a keyword . )","label":"Background","metadata":{},"score":"54.250305"}
{"text":"The value of each component is a function of the frequency the term has in that document .They show that query expansion using the cosine similarity measure on these vectors improves retrieval performance .However , the time complexity for computing the similarity between terms is related to the size of the corpus because the term vectors are high - dimensional .","label":"Background","metadata":{},"score":"54.263702"}
{"text":"They then developed high - quality answer passages of different lengths for a subset of these queries , and asked judges to rate the quality of these answers .They found that different query types are best served with different response lengths , and that for a subset of especially clear queries , human judges can predict the preferred result length .","label":"Background","metadata":{},"score":"54.30372"}
{"text":"The fact that RATF - based queries , in particular aekvRATF - queries are effective in CLIR is significant in that document and collection frequencies often are standard records in retrieval system packages .This allows an easy integration of a RATF - type key goodness evaluation method into cross - language retrieval systems .","label":"Background","metadata":{},"score":"54.32489"}
{"text":"The third subprocedure assigns individual documents to the closest center represented by one of these trimmed sum profiles .Referring to FIG .2 , the steps of the Buckshot method are shown .In step 30 , a random sample of C ' is constructed from corpus C of size . sqroot.kN.","label":"Background","metadata":{},"score":"54.408096"}
{"text":"The parameters for RATF calculation were learned through extensive tests using a training set of 50 requests and several parameter value combinations .In this study the RATF formula was tested in cross - language retrieval .We conclude that RATF as such is useful in CLIR queries formed from such source language queries in which each key has one occurrence ( such queries typically used , for example , in the Web ) .","label":"Background","metadata":{},"score":"54.418465"}
{"text":"Because of DocumentSpace 's independence from literal matches , it also does well even on one - word queries .There is a benefit of the parallel design of WordSpace and DocumentSpace .For a query consisting of words , the topic and content of a document can be described by its near neighbors in WordSpace , in complete analogy to the retrieval of document neighbors in DocumentSpace .","label":"Background","metadata":{},"score":"54.49166"}
{"text":"For example , the occurrence of \" chair \" in a document containing \" The Chair of the Board \" and in a separate document containing \" the chair maker \" are considered the same .The behavior results in the vector representation being an average of all the word 's different meanings in the corpus , which can make it difficult for comparison .","label":"Background","metadata":{},"score":"54.56208"}
{"text":"An index comprising indexing features for a plurality of documents , the index formed by a method comprising data - processing apparatus implemented steps of : . identifying each of at least some of the terms present in the documents ; . generating from each identified term at least one equivalent term which is different from but linguistically related to the identified term ; . forming for each of the identified terms a first indexing feature comprising the identified term and an identifier of the or each document in which the identified term occurs ; . forming for each of the equivalent terms a second indexing feature comprising the equivalent term and an identifier of the or each document in which the identified term to which the equivalent term is equivalent occurs ; and .","label":"Background","metadata":{},"score":"54.608208"}
{"text":"This type of glosser is capable of identifying and translating sequential ( continuous ) and non - sequential ( non - continuous ) collocations which are indexed by a headword .Further , this system can be used to ascribe priorities to alternative translations in such a way that consistent translations of complete sections of text are always obtained irrespective of which of several translations of a word or collocation is in fact selected .","label":"Background","metadata":{},"score":"54.634914"}
{"text":"The first preferred embodiment described above is a rich representation of words and documents that is based on global information about the document collection .The first preferred embodiment is superior to the literal representation used in classical vector similarity search .","label":"Background","metadata":{},"score":"54.641827"}
{"text":"Only if B is not in A 's Relative list check for A in B 's list .Enter the Relative Penalty value resulting from the following formula into the table for each combination ( pair ) : # # EQU4 # # .","label":"Background","metadata":{},"score":"54.645874"}
{"text":"Only if B is not in A 's Relative list check for A in B 's list .Enter the Relative Penalty value resulting from the following formula into the table for each combination ( pair ) : # # EQU4 # # .","label":"Background","metadata":{},"score":"54.645874"}
{"text":"This first set of SWAPS terms that are presented to the user includes the term \" statutes \" .The user may choose one or more of these suggested SWAPS terms to add to the query .In FIG .4 we see that the user has chosen to add the term \" statutes \" to the query .","label":"Background","metadata":{},"score":"54.649582"}
{"text":"This first set of SWAPS terms that are presented to the user includes the term \" statutes \" .The user may choose one or more of these suggested SWAPS terms to add to the query .In FIG .4 we see that the user has chosen to add the term \" statutes \" to the query .","label":"Background","metadata":{},"score":"54.649582"}
{"text":"The use of a glosser can overcome the problems associated with selection by a machine translation system of a single most likely , but perhaps incorrect , translation and the selection of all possible translations including those which are incorrect and may be entirely inappropriate for indexing purposes .","label":"Background","metadata":{},"score":"54.7281"}
{"text":"The identifying means and the generating means may comprise a multilingual resource .The multilingual resource may comprise a glosser .The glosser may be a limited non - deterministic glosser .The glosser may be arranged to form a plurality of translations of at least one of the identified term and to assign to each translation a priority according to the likelihood of the translation being correct .","label":"Background","metadata":{},"score":"54.732502"}
{"text":"( d.sub.j ) is computed for document d.sub.j by summing up the vectors of all tokens occurring in it .Similarity between the vector representations for words is measured by the cosine function : # # EQU3 # # Equation 3a is used to determine topical or semantic similarities between two words .","label":"Background","metadata":{},"score":"54.82084"}
{"text":"The second subprocedure determines a trimmed sum profile from selected documents closest to a document group centroid .Given a set of k document groups that are to be treated as k centers for the purpose of attracting other documents , it is necessary to define a centroid for each group .","label":"Background","metadata":{},"score":"54.837307"}
{"text":"That is , documents are generated from document language models associated with authors and queries are generated by information need language models associated with individual users .This raises the interesting possibility that users , like documents , could be represented as a mixture of topic language models , but we do not pursue that further here .","label":"Background","metadata":{},"score":"54.8704"}
{"text":"The target language query terms and the additional information are supplied to a query formulator 14 which converts the terms into a target language query 15 .The query formulator 14 uses the additional information , for instance to ignore each target language query term whose probability of being correct is less than a threshold .","label":"Background","metadata":{},"score":"54.934547"}
{"text":"Therefore the CLEF queries are marked by ( QKF ) in Table 10 , where QKF refers to query key frequency .In fact , in the case of CLEF queries ' undisambiguated ' queries were disambiguated , in part , through QKF .","label":"Background","metadata":{},"score":"54.99962"}
{"text":"Such glossers are more efficient than machine translation systems .An index merely requires the identification and translation of terms and does not require other processing steps such as parsing and generation of a readable translation as provided by machine translation systems .","label":"Background","metadata":{},"score":"55.00263"}
{"text":"Another way to highlight query term hits in a long document is to use an overview display .Baudisch et al ., 2004 asked 13 participants to compare three different methods of viewing long web pages retrieved for pre - defined queries .","label":"Background","metadata":{},"score":"55.024597"}
{"text":"The closest feature found in some search engines is \" find more documents like this \" .Query expansion techniques have been used in a number of systems to suggest additional search terms , with limited success .There are a number of reasons for the apparent failure of relevance feedback in current systems .","label":"Background","metadata":{},"score":"55.052956"}
{"text":"An apparatus according to . claim 11 , wherein the multilingual resource is a bilingual glosser .An apparatus according to . claim 13 , wherein the glosser is arranged to identify and translate each term of the source language query .","label":"Background","metadata":{},"score":"55.07469"}
{"text":"In the order-0 scheme , the word vector representation was constructed from one entry for the word .The generalization of order-1 representations is to construct a word vector representation from entries for the word 's neighbors in the document collection .","label":"Background","metadata":{},"score":"55.109413"}
{"text":"Neither is RATF useful in CLIR queries in which proper names are translated through n - gram matching .N - gram translation gives many bad words whose RATFs are high .However , it is possible to improve the effectiveness of n - gram translation .","label":"Background","metadata":{},"score":"55.128925"}
{"text":"One solution is to lengthen the query through relevance feedback .After conducting the first search using an initial query .Additional words are added to the query to narrow the search for the next search iteration .Another solution is to expand a query through synonym relations as found in thesaurus .","label":"Background","metadata":{},"score":"55.14223"}
{"text":"It is believed that such a technique may not result in too many relevant documents being retrieved because the fact that the term is common is a clue to the information retrieval system that its value in distinguishing relevant documents from non - relevant ones is probably quite low .","label":"Background","metadata":{},"score":"55.147064"}
{"text":"The automatically translated words were used as query keys in the CLIR queries .Several RATF - based weighting methods were tested .As a test system we used the Inquery retrieval system .We will demonstrate that query key weighting based on the RATF formula will yield substantial performance improvements in cross - language retrieval with respect to queries where no disambiguation method is applied .","label":"Background","metadata":{},"score":"55.200745"}
{"text":"Each term of the documents is associated with a vector that represents the term 's pattern of local co - occurrences .This vector can then be compared with others to measure the co - occurrence similarity , and hence semantic similarity of terms .","label":"Background","metadata":{},"score":"55.234993"}
{"text":"98 - 107 .McCune et al . , \" Rubric : A System for Rule - Based Information Retrieval \" , IEEE Transactions on Software Engineering , vol .SE-11 , No . 9 , 1985 , pp .939 - 945 .","label":"Background","metadata":{},"score":"55.341923"}
{"text":"The second form consists of a program generated \" highlight \" of the document which consists of very short portions of the document of less than a dozen words that contain the highest ranked terms .This highlight scrolls in about 2/3 of the screen and is shown along with the array of highest ranked terms .","label":"Background","metadata":{},"score":"55.364403"}
{"text":"The second form consists of a program generated \" highlight \" of the document which consists of very short portions of the document of less than a dozen words that contain the highest ranked terms .This highlight scrolls in about 2/3 of the screen and is shown along with the array of highest ranked terms .","label":"Background","metadata":{},"score":"55.364418"}
{"text":"We compared the CLIR queries that are presented in Section 3.3.2 with the following three types of baseline queries .All the baseline and test query types were run in the TREC collection .Undisambiguated ( unstructured , unweighted ) and syn - queries ( types 2 and 3 below ) and the best test query types based on the results of the TREC tests were run in the CLEF collection .","label":"Background","metadata":{},"score":"55.40983"}
{"text":"Conclusions .In Pirkola and Järvelin ( 2001b ) we proposed a query key goodness scheme , which can be used to identify the best keys among the words of a natural language request .The scheme is based on the relative average term frequency ( RATF ) values of query keys .","label":"Background","metadata":{},"score":"55.418858"}
{"text":"The Soft Boolean Connectors concept involves penalizing pairs of terms that co - occur often ( i.e. in many documents ) when calculating the adjustment to be applied to the summed relpoly percentages .First , multiply original query words by .","label":"Background","metadata":{},"score":"55.438522"}
{"text":"The Soft Boolean Connectors concept involves penalizing pairs of terms that co - occur often ( i.e. in many documents ) when calculating the adjustment to be applied to the summed relpoly percentages .First , multiply original query words by .","label":"Background","metadata":{},"score":"55.438526"}
{"text":"In traditional information retrieval systems , it is hard to assess the impact of the terms used in a query .The user communicates with the system on the level of document descriptions .In the case of relevance feedback , one specifies which documents returned as response to the original query should be the basis for the next search iteration .","label":"Background","metadata":{},"score":"55.463264"}
{"text":"Such a process aids the selection of sensible translations because there are fewer possible translations of a collocation than of its separate constituent words .For example , the collocation \" make use of \" has only a few translations into target languages whereas the frequently used terms \" make \" , \" use \" and \" of \" give rise to a large number of translation terms .","label":"Background","metadata":{},"score":"55.503914"}
{"text":"FIG .1 is a block diagram of an apparatus for determining lexical co - occurrence of terms within a document or query ; .FIG .2 is a flow diagram of the Buckshot clustering algorithm ; .FIG .3 shows the query formulation using WordSpace ; .","label":"Background","metadata":{},"score":"55.524353"}
{"text":"While this does not solve the usability issues associated with feedback , it does provide more stable , predictable , and effective outcomes when the user does provide relevance data .Quantifying Ambiguity .Many of the queries presented to an information retrieval system are ambiguous .","label":"Background","metadata":{},"score":"55.56317"}
{"text":"For the equivalent set an aggregate collection term frequency was computed .The researcher demonstrated that the method is useful in English to Chinese CLIR .In this study we tested the use of the RATF formula in CLIR .The formula calculates goodness values for query keys on the basis of document frequency and collection frequency statistics of words in a document collection .","label":"Background","metadata":{},"score":"55.578293"}
{"text":"For half of the test questions , the results were visible in the original snippet , and for the other half , the participant needed to view more information from the relevant search result .They compared three interface conditions : .","label":"Background","metadata":{},"score":"55.580597"}
{"text":"\" Working Notes for CLEF 2001 Workshop .Kwok , K.L. ( 1996 ) .\"A new method of weighting query terms for ad - hoc retrieval .\" Proceedings of the 19thAnnual I nternational ACM SIGIR Conference on Research and Development in Information Retrieval , Zurich , Switzerland , pp .","label":"Background","metadata":{},"score":"55.599922"}
{"text":"( C ) allows the user to peruse the documents extremely quickly .Indexing the documents by creating index files of which documents contain each term , how many times the term appears in the document , and how many documents each term appears in .","label":"Background","metadata":{},"score":"55.602676"}
{"text":"( C ) allows the user to peruse the documents extremely quickly .Indexing the documents by creating index files of which documents contain each term , how many times the term appears in the document , and how many documents each term appears in .","label":"Background","metadata":{},"score":"55.602676"}
{"text":"Thus , the procedure simply maps from one word to other closely related words .For a thesaurus to be useful in information retrieval , it must be specific enough to offer synonyms for words as used in the corpus of interest .","label":"Background","metadata":{},"score":"55.629333"}
{"text":"In all cases , the most effective RATF - based weighting method is aekvRATF .Performance differences between aekvRATF - queries and syn - queries are small ( Tables 6 - 7 ) .The results for the question whether the RATF - weighting of syn - sets of syn - queries will improve performance are shown in Tables 8 ( long queries ) and 9 ( short queries ) .","label":"Background","metadata":{},"score":"55.706116"}
{"text":"A \" glosser \" enables an ( ordered ) plurality of source language words ( or collocations ) to be labelled with target language translations .Another disadvantage of known arrangements of the type described hereinbefore is that identified documents are presented to the searcher in the target language .","label":"Background","metadata":{},"score":"55.796352"}
{"text":"For instance , linguistically related terms include synonyms , more general terms and more specific terms in the same ( natural ) language and translations into a different ( natural ) language .Although the documents may be in any type of language , such as a high level computer programming language , the documents are preferably natural language documents .","label":"Background","metadata":{},"score":"55.832916"}
{"text":"V. Lavrenko and W. B.Croft , \" Relevance - based language models \" , submitted to ACM SIGIR 2001 . D. Lawrie and W.B. Croft , \" Selecting terms for hierarchical document summaries \" , submitted to ACM 2001 . D. Miller , T. Leek and R. Schwartz , \" A Hidden Markov Model information retrieval system \" , Proceedings of ACM SIGIR 99 , 1999 .","label":"Background","metadata":{},"score":"55.834023"}
{"text":"Query keys were weighted and queries were reduced based on the RATF values of keys .The tests were carried out in TREC and CLEF document collections using the InQuery retrieval system .The TREC tests indicated that the best RATF - based queries delivered substantial and statistically significant performance improvements , and performed as well as syn - structured queries shown to be effective in many CLIR studies .","label":"Background","metadata":{},"score":"55.87193"}
{"text":"A method for accessing documents comprising data processing apparatus implemented steps of : . forming an index by : . identifying each of at least some of the terms present in the documents ; . generating from each identified term at least one equivalent term which is different from but linguistically related to the identified term ; . forming for each of the identified terms a first indexing feature comprising the identified term and an identifier of the or each document in which the identified term occurs ; . forming for each of the equivalent terms a second indexing feature comprising the equivalent term and an identifier of the or each document in which the identified term to which the equivalent term is equivalent occurs ; . forming an index comprising the first and second indexing features ; and .","label":"Background","metadata":{},"score":"55.881077"}
{"text":"In contrast , every word co - occurs with several words in the B - subset and hence will have many co - occurrence events with respect to B - classes .The 200 word clusters ( g.sub.B1,g.sub.B2 . . .","label":"Background","metadata":{},"score":"55.90633"}
{"text":"The crucial operation of the user interface is retrieval of nearest neighbors , either a small number ( e.g. 10 ) that is presented directly for inspection , or a large number that is clustered and presented to the user in digested form .","label":"Background","metadata":{},"score":"55.937477"}
{"text":"A standard method in dictionary - based CLIR is to replace each source language key by all of its target language equivalents included in a translation dictionary ( Pirkola , 1998 ; Pirkola , et al .Dictionaries typically give several translations for one source language word , and the number of mistranslated keys , i.e. , the keys that have wrong meanings in the context of the topic , in a CLIR query ( the final translated query ) is usually high .","label":"Background","metadata":{},"score":"55.96134"}
{"text":"The problem with this approach is that it is not clear how many topic models there should be , or how many is appropriate for a given query .The query \" middle east \" is less ambiguous than \" java \" at a high level of abstraction , but there are many subtopics related to the Middle East in a news corpus so the context of the query could still be viewed as poorly defined .","label":"Background","metadata":{},"score":"56.010223"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .After the frequent companions have been found RELATIVE.BAS is run to define the relatives of each Keyword ( A ) according to the following algorithm : . are there any FreqComps for A ?","label":"Background","metadata":{},"score":"56.02391"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .After the frequent companions have been found RELATIVE.BAS is run to define the relatives of each Keyword ( A ) according to the following algorithm : . are there any FreqComps for A ?","label":"Background","metadata":{},"score":"56.02391"}
{"text":"( n ) repeating steps ( i ) through ( m ) as many times as the user indicates by his input ; .( o ) accepting an input from the user indicating a command to retrieve documents ; .( r ) creating a sorted rank table by sorting said temporary rank table by the value of the second elements of the pairs in descending order ; .","label":"Background","metadata":{},"score":"56.13365"}
{"text":"( n ) repeating steps ( i ) through ( m ) as many times as the user indicates by his input ; .( o ) accepting an input from the user indicating a command to retrieve documents ; .( r ) creating a sorted rank table by sorting said temporary rank table by the value of the second elements of the pairs in descending order ; .","label":"Background","metadata":{},"score":"56.13365"}
{"text":"B200 ) generated are of high coverage .The Buckshot method is one example of a method to cluster the groups .In step 112 , a third co - occurrence matrix C is collected for the full corpus vocabulary versus the B - classes .","label":"Background","metadata":{},"score":"56.135155"}
{"text":"( police or law enforcement ) and California .( narcotics or drugs ) and ( adolescents or juveniles ) .Look for misspellings in the terms you have entered .How Documents are Found , Ranked , and Displayed .Documents are located based on the relevance criteria described below , and are displayed to the user from highest relevance to lowest up to a limit of 500 documents .","label":"Background","metadata":{},"score":"56.17012"}
{"text":"The difference in time before first action was significantly shorter for the economic searchers , especially when good results were available .The authors find a marginal difference between the evaluation style and computer experience , with more experienced searchers tending to use the economic style , and speculate that the Granka et al . , 2004 study may have employed only expert searchers , thus explaining the different results .","label":"Background","metadata":{},"score":"56.24538"}
{"text":"Allan , J. , Connell , M.E. , Croft , W.B. , Feng , F.-F , Fisher , D. , and Li , X. ( 2000 ) \" Inquery and TREC-9 . \" The Ninth Text REtrieval Conference ( TREC-9 ) , Gaithesburg , MD .","label":"Background","metadata":{},"score":"56.24997"}
{"text":"In unstructured queries mistranslated keys with low document frequency may ruin query performance .In structured queries in syn - sets they are downweighted because of the aggregate document frequency ( Sperer and Oard 2000 ) .Important keys often have 1 - 2 translations only , and have relatively more weight in structured than in unstructured CLIR queries .","label":"Background","metadata":{},"score":"56.257378"}
{"text":"Any particular class size will either separate some words from close neighbors or lump together some words with distant terms .A thesaurus can be constructed by defining a similarity measure on terms within the document .See Qiu et al . ; \" Concept Based Query Expansion \" ; Proceedings of SIGIR 1993 .","label":"Background","metadata":{},"score":"56.28151"}
{"text":"A query vector is formed from the combination of word vectors associated with the words in the query .The query vector and document vectors are compared to determine the relevant documents .The query vector can be divided into several factor clusters to form factor vectors .","label":"Background","metadata":{},"score":"56.338825"}
{"text":"The neighbors of the word \" Societies \" suggest that it is related to political and religious organizations , but no clear topic emerges .This indicates that the word is an ambiguous and , consequently , less useful search term .","label":"Background","metadata":{},"score":"56.3417"}
{"text":"Based on the user 's query and the document corpus , possible contexts for the query are inferred and used to suggest additional query terms .By studying these issues in the short - term ( a single session ) , we may learn how to handle context effectively in the long - term ( over multiple sessions ) .","label":"Background","metadata":{},"score":"56.3679"}
{"text":"If there are fewer than 63 Relatives , then all of the Relatives will be written to A 's Relative List , in descending order of RELATIVE value .# # EQU2 # # .Here the SmallerPercent Value is the smaller of the A - VAL and the F - VAL and the LargerPercent Value is the larger of the A - VAL and the F - VAL .","label":"Background","metadata":{},"score":"56.392426"}
{"text":"If there are fewer than 63 Relatives , then all of the Relatives will be written to A 's Relative List , in descending order of RELATIVE value .# # EQU2 # # .Here the SmallerPercent Value is the smaller of the A - VAL and the F - VAL and the LargerPercent Value is the larger of the A - VAL and the F - VAL .","label":"Background","metadata":{},"score":"56.392426"}
{"text":"Even the most relevant document is unlikely to be selected if the title is uninformative or misleading .( Some Web search algorithms try to capture the quality of the title description as part of the ranking score . )The descriptiveness of the summary is also very important and is discussed in detail below .","label":"Background","metadata":{},"score":"56.413826"}
{"text":"Once the indexing programs have been run , the ABSTRACT program is run to create highlights of the full text that will be presented to the user before or in place of the full text itself .First the documents are broken into sentences using a Sentence Ends Algorithm .","label":"Background","metadata":{},"score":"56.464565"}
{"text":"Once the indexing programs have been run , the ABSTRACT program is run to create highlights of the full text that will be presented to the user before or in place of the full text itself .First the documents are broken into sentences using a Sentence Ends Algorithm .","label":"Background","metadata":{},"score":"56.464565"}
{"text":"Each of the possible translations obtained from the dictionary is stored in a set T element .The context of the word or collocation is taken into account so as to ensure that the translations into the target language makes sense .","label":"Background","metadata":{},"score":"56.46631"}
{"text":"The matrix C has v.sup.2 /2 distinct entries , where v is the size of the vocabulary .Although this matrix is sparse , v is expected to be very large .Therefore , the overall storage requirement needed to form the co - occurrence thesaurus is unworkable .","label":"Background","metadata":{},"score":"56.483128"}
{"text":"WO 97/08604 discloses an information retrieval system which is based on translating queries and documents .However , this technique makes use of a language - independent conceptual representation of each query and of each document which is available for searching .","label":"Background","metadata":{},"score":"56.533714"}
{"text":"The use of such translations for information retrieval results in the generation of spurious matches on queries posed to the system so that very large numbers of irrelevant documents may be located together with the relevant documents .According to a first aspect of the invention , there is provided a method of forming , for a plurality of documents , an index comprising indexing features , the method comprising the steps of : . identifying each of at least some of the terms present in the documents ; . generating from each identified term at least one equivalent term which is different from but linguistically related to the identified term ; and .","label":"Background","metadata":{},"score":"56.656155"}
{"text":"Using eye tracking , they found that participants spent a larger proportion of time looking at information other than the URL for the navigational queries with long contexts , thus suggesting that the less relevant information was distracting them .They did not report on subjective responses to the different summary lengths .","label":"Background","metadata":{},"score":"56.66598"}
{"text":"FIG .17 shows the memory divided into sections for each factor .In each section , the documents are ranked from highest to lowest .Each factor rank is associated with the document identification and the correlation coefficient .In step 344 , the documents are ranked based on the maximum rank of the factors .","label":"Background","metadata":{},"score":"56.79378"}
{"text":"Fourth , showing the score gives information to a search engine 's competitors and spammers who might try to reverse - engineer the ranking algorithm .More elaborate graphical representations of search results matches are discussed in Chapter 10 .Some systems have experimented with making the document content more immediately available without the need to leave the Web page ; Figure 5.5 shows content prefetching when viewing a hyperlink using Snap 's Snap Shot system .","label":"Background","metadata":{},"score":"56.80268"}
{"text":"In a step 29 , the parameter element is incremented by one and the step 27 is performed again .This loop continues until all of the words and collocations in the set D have been translated , after which a step 30 is formed .","label":"Background","metadata":{},"score":"56.8123"}
{"text":"The sum of all words in a document is a good topic descriptor for short documents .However , long documents tend to contain words from different topics .If too many topics enter in the computation of a document vector , then the document vector will be in a region that is at an intermediate distance to all its topics , but not particularly close to any of them .","label":"Background","metadata":{},"score":"56.83577"}
{"text":"The original term - document matrix is presumed noisy : for example , anecdotal instances of terms are to be eliminated .From this point of view , the approximated matrix is interpreted as a de - noisified matrix ( a better matrix than the original ) .","label":"Background","metadata":{},"score":"56.844353"}
{"text":"In contrast , systems using more rare terminology may be punished more heavily for mistakes in the translation process because the rarity of a resulting term may mean that it is given greater importance in the retrieval system and thus can contribute more potentially irrelevant documents to the result .","label":"Background","metadata":{},"score":"56.86008"}
{"text":"A step 25 increments the parameter \" element \" by one and the steps 23 to 25 are repeated until all of the query terms have been translated .A step 26 sets a parameter i to a value of one and a step 27 tests whether i is less than or equal to N. If so , a step 28 sorts the target language translations stored in the set T i according to priority information obtained during the look up process performed in the step 24 .","label":"Background","metadata":{},"score":"56.902565"}
{"text":"A document indexing and retrieval system and method which assigns weights to the key words and assigns a relative value to pairs of key words ( i.e. defines a relative relation on K×K ) based on their frequency of occurrence and co - occurrence in the document data base .","label":"Background","metadata":{},"score":"56.916306"}
{"text":"( 2 ) Undisambiguated CLIR queries were flat sum - queries : . # sum(a 1 ... a n b 1 ... b m ... ) .The undisambiguated CLIR queries included the same query keys as the test queries , but no disambiguation method was applied .","label":"Background","metadata":{},"score":"57.00105"}
{"text":"Thus , automatic linguistic processing of such queries can be difficult and may lead to unsatisfactory results , such as failure to locate relevant documents and location of irrelevant documents .The use of automatic machine translation to translate whole collections of documents to form an index is also problematic .","label":"Background","metadata":{},"score":"57.007538"}
{"text":"FIG .10 is a flow diagram for computing context vectors for documents ; .FIG .11 shows a document context vector ; .FIG .12 is a flow diagram for ranking the documents based on the query context vector and the document context vectors ; .","label":"Background","metadata":{},"score":"57.06077"}
{"text":"We will test the effectiveness of the formula by using the same RATF weighting method as in Pirkola and Järvelin ( 2001b ) , where RATF values of keys as such were used key weights .We will also develop and test new RATF - based key weighting methods that particularly are suited for CLIR .","label":"Background","metadata":{},"score":"57.10767"}
{"text":"However , the term N / n .sub.i is inversely proportional to document frequency such that high frequency words receive less weight .For example , the frequency of the word \" the \" is high for a document .Therefore , this word has a high weight for the document .","label":"Background","metadata":{},"score":"57.11706"}
{"text":"You do n't need to look at B 's list to find A 's value there because , if it is there , it would have the same value as B has in A 's list .Only if B is not in A 's Relative list check for A in B 's list .","label":"Background","metadata":{},"score":"57.144157"}
{"text":"You do n't need to look at B 's list to find A 's value there because , if it is there , it would have the same value as B has in A 's list .Only if B is not in A 's Relative list check for A in B 's list .","label":"Background","metadata":{},"score":"57.144173"}
{"text":"New York , NY : Association for Computing Machinery .Pirkola , A. , Hedlund , T. , Keskustalo , H. , Järvelin , K. ( 2000 ) .\" Cross - lingual Information Retrieval Problems : Methods and findings for three language pairs \" .","label":"Background","metadata":{},"score":"57.150696"}
{"text":"Words and documents are represented as vectors in the same multi - dimensional space that is derived from global lexical co - occurrence patterns .The method forms an improved retrieval performance for non - literal matches with queries .The computation of the lexical co - occurrence thesaurus proceeds in two phases .","label":"Background","metadata":{},"score":"57.15373"}
{"text":"The identifying step may be performed by a part of speech tagger .According to a second aspect of the invention , there is provided an apparatus for forming , for a plurality of documents , an index comprising indexing features , the apparats comprising : . means for identifying each of at least some of the terms present in a document ; . means for generating from each identified term at least one equivalent term which is different from but linguistically related to the identified term ; and . means for forming for each of the identified terms and the equivalent terms an indexing feature comprising the identified term or the equivalent term and an identifier of the or each document in which the identified term or the identified term to which the equivalent term is equivalent occurs .","label":"Background","metadata":{},"score":"57.212982"}
{"text":"Each row displays a word and its nine nearest neighbors .For example , \" repair \" is the nearest neighbor of \" accident \" .Word pairs used as terms are displayed without being separated by a semicolon .Words in upper case are hand selected synonyms as might be found in a manually constructed thesaurus .","label":"Background","metadata":{},"score":"57.216545"}
{"text":"[ 10 ] MATLAB and Python implementations of these fast algorithms are available .Unlike Gorrell and Webb 's ( 2005 ) stochastic approximation , Brand 's algorithm ( 2003 ) provides an exact solution .The resulting dimensions might be difficult to interpret .","label":"Background","metadata":{},"score":"57.248753"}
{"text":"But more importantly we can now treat the term and document vectors as a \" semantic space \" .The vector then has entries mapping it to a lower dimensional space dimensions .These new dimensions do not relate to any comprehensible concepts .","label":"Background","metadata":{},"score":"57.284134"}
{"text":"A standard search results listing , in which a mouse click on the title brings up the full text of the Web page , .( ii ) \" Instant \" view , which upon a mouseclick , expanded the document summary to show additional sentences from the document , where those sentences contained query terms and the answer to the search task , and .","label":"Background","metadata":{},"score":"57.32975"}
{"text":"If You Find Too Little .Change one of the terms to a broader term .For example , replace juvenile gangs with gangs .Try to think of synonyms or related words and combine them with OR , selecting a Boolean search .","label":"Background","metadata":{},"score":"57.362823"}
{"text":"In this study we will test whether the RATF formula is useful in cross - language information retrieval .Cross - language information retrieval ( CLIR ) refers to an information retrieval task where the language of queries is other than that of the retrieved documents .","label":"Background","metadata":{},"score":"57.370274"}
{"text":"First , in order to understand the score one must have some knowledge of the complex underlying ranking algorithm , which is of course not to be expected for general users .Second , often the top scores are close together numerically , and so showing the score does not add information beyond the rank ordering provided by the vertical results list .","label":"Background","metadata":{},"score":"57.37301"}
{"text":"7 shows Matrix B , which has rows corresponding to A - classes , i.e. , columns to words .For example , the B - subset contains the 20,000 most frequent words , excluding stop words .In step 110 , this B - subset is again partitioned into 200 word classes by clustering the columns of matrix B. The purpose of this second iteration is to ensure that each word in the corpus has a sufficient number of neighbors from at least one word class .","label":"Background","metadata":{},"score":"57.440945"}
{"text":"The user need not waste time formulating a good query that will not retrieve any relevant documents because there happen to be no such documents in the data base .The SWAPS terms that are suggested will always retrieve documents that contain them i.e. documents that are likely to be relevant .","label":"Background","metadata":{},"score":"57.458557"}
{"text":"The user need not waste time formulating a good query that will not retrieve any relevant documents because there happen to be no such documents in the data base .The SWAPS terms that are suggested will always retrieve documents that contain them i.e. documents that are likely to be relevant .","label":"Background","metadata":{},"score":"57.458557"}
{"text":"The method of claim 32 , wherein ranking of the documents within a factor cluster is based on correlation : . where the rank of d.sub.j according to this ranking is r.sub.m ( j ) ; and corr(f.sub.m , d.sub.j ) is the correlation of factor m and document j. .","label":"Background","metadata":{},"score":"57.51394"}
{"text":"One frequently suggested idea is to show search results as thumbnail images rather than as textual surrogates ( Czerwinski et al . , 1999 , Dziadosz and Chandrasekar , 2002 , Woodruff et al . , 2001 ) , but none have shown a proven advantage for search results viewing .","label":"Background","metadata":{},"score":"57.526405"}
{"text":"Proximity : The closer together the query words and related terms within the document , the greater the weight .A document is judged more relevant if it contains related terms that occur close together , preferably in the same sentence or paragraph .","label":"Background","metadata":{},"score":"57.55024"}
{"text":"Queries may be viewed as short documents and hence may also be represented as vectors .Search proceeds by searching near neighbors to the query vector in document space .The assumption is that queries and documents are similar to the extent that they contain the same words .","label":"Background","metadata":{},"score":"57.61453"}
{"text":"In this paper , we focus on the algorithms for inferring context .In particular , we describe how a language modeling approach to the problem can lead to new perspectives and potentially more effective algorithms .Relevance Feedback and Language Models .","label":"Background","metadata":{},"score":"57.61499"}
{"text":"The technique of singular value decomposition ( SVD ) is used to achieve a dimensional reduction by obtaining a compact and tractable representation for search purposes .The uniform representation for words and documents provides a simple and elegant user interface for query focusing and expansion .","label":"Background","metadata":{},"score":"57.628876"}
{"text":"The syn -operator treats its operand search keys as instances of the same search key .For the keys linked by the syn - operator , an aggregate document frequency is computed instead of individual document frequencies for every key ( Sperer and Oard , 2000 ) .","label":"Background","metadata":{},"score":"57.64498"}
{"text":"The topical word classes agglomerate information over similar words .In FIG .5 , step 100 computes the word and word pair frequencies in the corpus .A word pair is two consecutive words in the corpus .For example , the title \" The Journal of Computer Science \" has four word pairs : The Journal ; Journal of ; of Computer ; and Computer Science .","label":"Background","metadata":{},"score":"57.674942"}
{"text":"However , where the set T i contains more than one possible translation , the translations are sorted in order of the likelihood of being correct .The parameter i is incremented by one in the step 29 and the steps 27 to 29 are repeated until all of the target language translations of the input source language query terms have been sorted .","label":"Background","metadata":{},"score":"57.694126"}
{"text":"The query \" Japanese American research \" was performed using DocumentSpace .In the SEARCH RESULT section of FIG .4 , the ten top ranking documents are shown .These documents seem to conform well with the query although there are few literal matches .","label":"Background","metadata":{},"score":"57.700874"}
{"text":"Perform a keyword search across the entire site by following these steps : .Enter a keyword(s )Enclose phrases in quotes .For example : gangs \" drug court \" .Select \" Go \" or press enter .To search for an event , visit the Criminal Justice Events search page and select the criteria that you would like to search by .","label":"Background","metadata":{},"score":"57.706345"}
{"text":"An HTML document is pre processed by placing notional barriers around the HTML codes so as to preserve them .The remaining text and data outside these barriers are then translated to the desired language .Finally , the barriers are removed so that the pages retain their original format or appearance but all relevant text is translated into the desired language .","label":"Background","metadata":{},"score":"57.770752"}
{"text":"5.7 : Conclusions .Search results presentation is a critical component of the search cycle .This chapter has summarized empirical research showing which aspects of a document are best shown in retrieval results , along with the characteristics of the results listing itself .","label":"Background","metadata":{},"score":"57.828606"}
{"text":"Eye - tracking studies suggest that even when placed lower down , an image often attracts the eye first ( Hotchkiss et al . , 2007 ) .It may be best to show this richness only for certain types of queries , such as the general ones shown here .","label":"Background","metadata":{},"score":"57.8461"}
{"text":"Context vectors are then computed from these dictionary - based word representations .This method has the same problems as other dictionary - based approaches .In particular , a genre - specific distinction that is not covered in the dictionary is not adequately represented in the dictionary - based representations .","label":"Background","metadata":{},"score":"57.873016"}
{"text":"With full text and limited relevance information , the relevance feedback techniques developed in the 70 's and 80 's are simply not as reliable as the experiments with collections of abstracts had indicated .In other words , identifying the correct context is not simple .","label":"Background","metadata":{},"score":"57.96331"}
{"text":"The multilingual resource 11 may comprise a bilingual dictionary 15 of the machine - readable type .For instance , the source language text may not be processed but may simply be divided into words , and possibly collocations , which are then used to access the dictionary 15 to provide word - by - word translations of the text .","label":"Background","metadata":{},"score":"57.96944"}
{"text":"Pirkola , A. , Hedlund , T. , Keskustalo , H. , and Järvelin , K. ( 2001 ) .\" Dictionary - based cross - language information retrieval : problems , methods , and research findings \" .Information Retrieval , 4 ( 3/4 ) , 209 - 230 .","label":"Background","metadata":{},"score":"58.11753"}
{"text":"A query - oriented extract shows sentences that summarize the ways the query terms are used within the document .In addition to showing which subsets of query terms occur in a retrieved documents , this display also exposes the context in which the query terms appear with respect to one another .","label":"Background","metadata":{},"score":"58.1662"}
{"text":"Element c.sub.i,j contains the number of times that term j co - occurs in a window of k words with any word in class g.sub.Bi .Referring to FIG .8 , matrix C has b rows and v columns .","label":"Background","metadata":{},"score":"58.177277"}
{"text":"Machine - readable dictionaries can be used to derive \" context vectors . \" See Wilks et al . , \" Providing Machine Tractable Dictionary Tools \" ; Machine Translation ; Vol .5 , No . 2 , pp .99 - 154 ; 1990 .","label":"Background","metadata":{},"score":"58.25295"}
{"text":"FIG .16 shows the retrieval of documents using the word factor method .In step 320 , the three factors of the query computed by the process shown in FIG .14 are retrieved .The factor vector for each factor cluster is computed in step 322 .","label":"Background","metadata":{},"score":"58.304802"}
{"text":"\"The effects of query structure and dictionary setups in dictionary - based cross - language information retrieval \" .Proceedings of the 21st Annual International ACM Sigir Conference on Research and Development in Information Retrieval , Melbourne , Australia , pp .","label":"Background","metadata":{},"score":"58.333908"}
{"text":"The tests in the TREC collection showed that there are many effective RATF - based weighting methods .The best one was aekvRATF , which takes into account both the number of translation equivalents of a source language key and the RATF values of the equivalents .","label":"Background","metadata":{},"score":"58.34111"}
{"text":"# # SPC1 # # .System and method for information retrieval by using keywords associated with a given set of data elements and the frequency of each keyword as determined by the number of data elements attached to each keyword A document indexing and retrieval system and method which assigns weights to the key words and assigns a relative value to pairs of key words ( i.e. defines a relative relation on K×K ) based on their frequency of occurrence and co - occurrence in the document data base .","label":"Background","metadata":{},"score":"58.3574"}
{"text":"An important result is that aekvRATF , which takes into account the RATF values of keys and the number of translation equivalents of source keys was effective in all tests of this study .The importance of this finding is in that aekvRATF can be computed easily .","label":"Background","metadata":{},"score":"58.402725"}
{"text":"It is based on searching by character strings for useful documents or files and selecting the most appropriate translation environment ( such as a glosser or machine translation system ) for located documents on the basis of the character string .Any translation which occurs is performed exclusively on located documents by the most appropriate translation environment for the subject matter as identified by the character string .","label":"Background","metadata":{},"score":"58.46555"}
{"text":"It is collection dependent and derived experimentally .For each word ( and a syn - set containing these words ) , the avgRATF is 1,65 .In the case of equivalent sets containing 1 - 3 equivalents , aekvRATF ( S A ) is the same as avgRATF ( S A ) .","label":"Background","metadata":{},"score":"58.48683"}
{"text":"In Figure 5.1 , sitelinks for the Google Labs site point to Trends , Code Search , and other pages on the site .Shortcuts : : Search engines are also attempting to provide \" shortcuts \" for directed or focused information needs directly on the search results page , becoming in effect \" answer engines \" for certain queries ( Nielsen , 2004b ) .","label":"Background","metadata":{},"score":"58.565258"}
{"text":"Queries are similarly processed and searching is performed by matching the conceptual representations .SUMMARY OF THE INVENTION .A multilingual resource is any system which is capable of converting a term ( word or collocation ) in the source language into one or more equivalent terms in the target language .","label":"Background","metadata":{},"score":"58.60728"}
{"text":"In this case the program boosts the relative percentages of the last chosen set of SWAPS terms before calculating summed relpoly percentages .This allows the user to navigate in the data base by modifying his query so that it will find documents containing the SWAPS terms .","label":"Background","metadata":{},"score":"58.613598"}
{"text":"In this case the program boosts the relative percentages of the last chosen set of SWAPS terms before calculating summed relpoly percentages .This allows the user to navigate in the data base by modifying his query so that it will find documents containing the SWAPS terms .","label":"Background","metadata":{},"score":"58.613598"}
{"text":"Formally , document ranks of the form are considered : . where r.sub.cv is the context vector rank ; r.sub.tf.idf is the tf.idf rank ; and . alpha . is a free parameter between 0 and 1 .FIG .19 shows a precision graph for 11 points of recall .","label":"Background","metadata":{},"score":"58.61948"}
{"text":"J. Xu and W.B. Croft , \" Improving the Effectiveness of Information Retrieval with Local Context Analysis \" , ACM Transactions on Information Systems , 18(1 ) , 79 - 112 , ( 2000 ) .Latent semantic analysis ( LSA ) is a technique in natural language processing , in particular in vectorial semantics , of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms .","label":"Background","metadata":{},"score":"58.644188"}
{"text":"Such a \" device \" performs limited grammatical analysis of the source language text to determine the part of speech of each word .The result of this limited analysis may then be applied to the bilingual dictionary 15 so as to provide an improved word - by - word translation than may be obtained by using the dictionary 15 alone .","label":"Background","metadata":{},"score":"58.710133"}
{"text":"A program memory 7 in the form of a read only memory ( ROM ) contains a program for controlling operation of the data processor 2 .The apparatus further comprises a document glosser 8 which labels the terms ( words and collocations ) of the source language query with target language translations .","label":"Background","metadata":{},"score":"58.816376"}
{"text":"Hence , further detail regarding the specific code itself has been omitted for the sake of brevity .A multilingual resource 11 and a machine - readable thesaurus 12 are shown as individual devices in FIG 1 .However , these devices may be embodied within the components of the apparatus already described .","label":"Background","metadata":{},"score":"58.83378"}
{"text":"DocKeys holds all of the Keywords and Keyword - Counts for all documents .IDF holds the document frequency , i.e. , the number of documents a keyword appears in .IF UC word is at the beginning of a sentence AND we do n't have it in our vocabulary as a LC word THEN look for it the Vocabulary as an UC word .","label":"Background","metadata":{},"score":"58.91726"}
{"text":"DocKeys holds all of the Keywords and Keyword - Counts for all documents .IDF holds the document frequency , i.e. , the number of documents a keyword appears in .IF UC word is at the beginning of a sentence AND we do n't have it in our vocabulary as a LC word THEN look for it the Vocabulary as an UC word .","label":"Background","metadata":{},"score":"58.91726"}
{"text":"Studies and query logs show that searchers rarely look beyond the first page of search results .If the searcher does not find what they want in the first page , they usually either give up or reformulate their query ( Chapter 6 discusses query reformulation in detail ) .","label":"Background","metadata":{},"score":"58.931026"}
{"text":"11 shows the normalized context vector for the query or document .Each context vector has 20 real - valued dimensions .FIG .12 shows the process of using context vectors to retrieve relevant documents for a query .In step 230 , a query is entered into the processor by the user .","label":"Background","metadata":{},"score":"58.957417"}
{"text":"The optimal query is defined as a vector obtained by taking the difference between the relevant and non - relevant sets of documents , also represented as vectors .This query vector can be shown to be the \" best \" , under some assumptions , for distinguishing relevant and non - relevant documents .","label":"Background","metadata":{},"score":"59.00031"}
{"text":"The rationale behind aekvRATF(S A ) is that that those keys ( concepts ) that have many translations in another language probably are harmful or less important than the keys that only have a few translations .Its value is given by : .","label":"Background","metadata":{},"score":"59.155197"}
{"text":"1 is a block diagram of a preferred embodiment according to the invention of an apparatus 10 for determining lexical co - occurrence of terms within a document or query and forming a thesaurus .The apparatus 10 includes a user input device 12 which includes , for example , one or more of an image scanner ( optical or electronic ) , a keyboard , a touchscreen , a mouse , etc .","label":"Background","metadata":{},"score":"59.186607"}
{"text":"A method according to . claim 11 , wherein the query includes terms in the source language and the target language .A data - processing apparatus for forming an index comprising indexing features for a plurality of documents , comprising : . means for identifying each of at least some of the terms present in the documents ; . means for generating from each identified term at least one equivalent term which is different from but linguistically related to the identified term ; . means for forming for each of the identified terms a first indexing feature comprising the identified term and an identifier of the or each document in which the identified term occurs ; . means for forming for each of the equivalent terms a second indexing feature comprising the equivalent term and an identifier of the or each document in which the identified term to which the equivalent term is equivalent occurs ; and . means for forming an index comprising the first and second indexing features , .","label":"Background","metadata":{},"score":"59.2341"}
{"text":"Overview .From some perspectives , personalization has been studied in information retrieval for some time .If the goal of personalization is to improve the effectiveness of information access by adapting to individual users ' needs , then techniques such as relevance feedback and filtering would certainly be considered to support personalization .","label":"Background","metadata":{},"score":"59.278057"}
{"text":"It should be noted that this monolingual component is involved in CLIR .One should also note that there are different types compounds , which probably should be handled in different ways for improved CLIR performance .This issue is investigated by Hedlund and colleagues at UTA .","label":"Background","metadata":{},"score":"59.339073"}
{"text":"The revised estimates are used to produce a new document ranking based on the probability of belonging to the relevant class .Both of these approaches can be viewed as applications of different machine learning techniques to the problem of identifying relevant documents based on training data .","label":"Background","metadata":{},"score":"59.33934"}
{"text":"Table 2 gives two examples of words whose synonyms have almost identical direction in the multidimensional space .DocumentSpace , which is the second part of TwinSpaces , contains 34,000 articles from the New York Times newswire between the months of June and November of 1990 .","label":"Background","metadata":{},"score":"59.498913"}
{"text":"Graphical Displays of Relevance Score : : For many years , systems that use statistical ranking showed a numerical score or an icon alongside the title , indicating the computed degree of match or probability of relevance to the query .Icons included partially filled horizontal bars or a line of graphical stars , as in movie ratings , indicating degree of match or relevance .","label":"Background","metadata":{},"score":"59.510513"}
{"text":"A vector for each query sub - topic is formed and compared to the document vectors .The document vectors are then scored and ranked by the degree to which they simultaneously match the subtopics of the query .BRIEF DESCRIPTION OF THE DRAWINGS .","label":"Background","metadata":{},"score":"59.62168"}
{"text":"For a word occurring n times in the document collection and for a definition of co - occurrence as occurring in a window of k words , there are nk co - occurrence events .However , there are only n occurrence - in - document events .","label":"Background","metadata":{},"score":"59.65367"}
{"text":"It also mitigates the problem with polysemy , since components of polysemous words that point in the \" right \" direction are added to the components of words that share a similar meaning .Conversely , components that point in other directions tend to either simply cancel out , or , at worst , to be smaller than components in the directions corresponding to the intended sense .","label":"Background","metadata":{},"score":"59.659355"}
{"text":"The second preferred embodiment uses the computed thesaurus vectors to perform a search for relevant documents .To use this information directly in the search , a similar representation for documents is needed .The document vectors that are computed are called \" context vectors .","label":"Background","metadata":{},"score":"59.673576"}
{"text":"The query formulator 14 detects that there are various possible translations for the remaining terms of the source language query .In particular , the translations for the individual words \" athlete \" and \" foot \" would both have to be present in a relevant document but an alternative to this would be the presence of the translation for the term \" athlete 's foot \" .","label":"Background","metadata":{},"score":"59.768234"}
{"text":"As shown in the tables , all the weighting methods give substantial performance improvements .For long queries , the relative improvement figures ( avg . precision ) due to single key weighting are 94.1 % ( RATF ) , 98.0 % ( avgRATF ) , and 123.5 % ( aekvRATF ) .","label":"Background","metadata":{},"score":"59.77498"}
{"text":"RATF / non - parameter queries perform worse than the queries where key weighting is based on the basic RATF formula .The improvement potentials for short RATF - based queries are limited , since short undisambiguated queries perform very well .","label":"Background","metadata":{},"score":"59.802673"}
{"text":"293 - 309 , 1991 .Grefenstette , Gregory , \" Use of Syntactic Context to Produce Term Association Lists for Text Retrievel \" , Computer Science Department , University of Pittsburgh , Pittsburgh , PA , pp .89 - 97 , 1992 .","label":"Background","metadata":{},"score":"59.805405"}
{"text":"Dimensions of Meaning \" , Hinrich Schuetze , Proceedings Supercomputing ' 92 , Nov. 16 - 20 , 1992 , pp .787 - 796 .Douglas R. Cutting et al . , Scatter / Gather : A Cluster - based Approach to Browsing Large Document Collections , pp . 1 - 12 , 15th Ann Int'l SIGIR ' 92 ( 1992 ) .","label":"Background","metadata":{},"score":"59.882824"}
{"text":"Although such processing need not be performed in real time and , in particular , is not required as part of each information retrieval request , substantial resources are necessary and there may be a continuing requirement as further documents are added to the collection .","label":"Background","metadata":{},"score":"59.897396"}
{"text":"Figure 5.7 shows results for a very general query on kittens at Hakia , which the search engine converts into a query on Cats .Recognizing that this is a very general query , the system provides general resources about the topic , separated by tabs , including news headlines , general pet care sites , general sites for finding a pet , and a table of contents for these different types of information .","label":"Background","metadata":{},"score":"59.89943"}
{"text":"9 is a procedure tree for the QSEARCH program used for searching an indexed set of documents using the SWAPS and RANKING features ; .FIGS .10A to 10J are description of the program modules in FIG .8 ; .","label":"Background","metadata":{},"score":"59.924553"}
{"text":"9 is a procedure tree for the QSEARCH program used for searching an indexed set of documents using the SWAPS and RANKING features ; .FIGS .10A to 10J are description of the program modules in FIG .8 ; .","label":"Background","metadata":{},"score":"59.924553"}
{"text":"Proceedings of the 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , Philadelphia , PA , pp .84 - 91 .New York , NY : Association for Computing Machinery .Ballesteros , L. and Croft , W.B. ( 1998 ) . \"","label":"Background","metadata":{},"score":"60.02542"}
{"text":"Thus , synonyms are not required to co - occur , but they must have similar co - occurrence patterns .A multi - dimensional continuous space is formed where each word 's thesaurus vector represents its individual position .A continuous space does not force a classification choice , and hence avoids some of the ensuing problems .","label":"Background","metadata":{},"score":"60.04907"}
{"text":"As mentioned above , most search results listings today show an extract from a retrieved document that summarizes its contents .This extract is referred to with several different names , including summary , snippet , and abstract .An important property of modern Web search surrogates is the display of a summary that takes the searcher 's query terms into account .","label":"Background","metadata":{},"score":"60.069664"}
{"text":"Thus , a more compact word representation of order-0 and order-1 are as follows : .Compact order-0 encoding : # # EQU7 # # .Compact order-1 encoding : # # EQU8 # # .Reduced order-1 encoding : . where V.sub .","label":"Background","metadata":{},"score":"60.10305"}
{"text":"However , if the query consists of general words that are not terms of art , the query may produce unsatisfactory retrieval results by either producing few documents that are of interest to the user or producing many documents that are not interesting to the user or both .","label":"Background","metadata":{},"score":"60.116947"}
{"text":"However , if the query consists of general words that are not terms of art , the query may produce unsatisfactory retrieval results by either producing few documents that are of interest to the user or producing many documents that are not interesting to the user or both .","label":"Background","metadata":{},"score":"60.116947"}
{"text":"Formally , # # EQU12 # # where d.sub.j is the vector for document j ; w.sub.ij is the weight for word i in document j ; and v.sub.i is the thesaurus vector for word i. Queries may be represented as vectors by using equation 15 .","label":"Background","metadata":{},"score":"60.122627"}
{"text":"Journal of the American Society for Information Science and Technology , 52 ( 7 ) , 575 -583 .Pirkola , A. and Järvelin , K. ( 2001b ) .Exploiting average term frequency and word distribution statistics in text retrieval .","label":"Background","metadata":{},"score":"60.171204"}
{"text":"Hence , further detail regarding the specific code itself has been omitted for the sake of brevity .The information management system 1 is of the type which contains machine - readable documents and which is arranged to access or search for such documents on the basis of queries .","label":"Background","metadata":{},"score":"60.223633"}
{"text":"Then the derivation of compact representations for the whole vocabulary proceeds in two steps .In the first step , an order-1 representation . phi . ' sub.1 is derived using a restricted vocabulary of N words , and a singular value decomposition computes a low - dimensional encoding .","label":"Background","metadata":{},"score":"60.262318"}
{"text":"The analysis step 24 identifies that \" air \" could be a noun or verb , \" passes \" could be a plural noun or the third person of a verb etc .The step 25 identifies all words and collocations in the sentence to provide the following analysis . air_NOUN . air_VERB . pass_VERB .","label":"Background","metadata":{},"score":"60.287838"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _( The previous value will be called \" Temp Value\")Create table for every pair combination of query words ( A B C )","label":"Background","metadata":{},"score":"60.332657"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _( The previous value will be called \" Temp Value\")Create table for every pair combination of query words ( A B C )","label":"Background","metadata":{},"score":"60.33267"}
{"text":"According to a third aspect of the invention , there is provided a storage medium characterised by containing a program for controlling a data processor of such an apparatus .The glosser is preferably of the type disclosed in EP 0 813 160 and GB 2 314 183 , the contents of which are incorporated herein by reference .","label":"Background","metadata":{},"score":"60.381355"}
{"text":"In order to search for documents containing information of relevance to a chosen topic , a query is formulated by the searcher .A typical query comprises a short item of text , such as a sentence , which indicates the subject matter to be located .","label":"Background","metadata":{},"score":"60.461487"}
{"text":"Although these vectors are somewhat sparse , this implies that word comparisons are an order v operation , which is prohibitively expensive for large scale application .Thus , the dimensionality of the problem must be reduced to a workable size by using a singular value decomposition of a matrix of co - occurrence counts .","label":"Background","metadata":{},"score":"60.531116"}
{"text":"The word vectors represent global lexical co - occurrence patterns and relationships between word neighbors .Document vectors , which are formed from the combination of word vectors , are in the same multi - dimensional space as the word vectors .","label":"Background","metadata":{},"score":"60.575363"}
{"text":"Indicators of Additional / Related Hits : : Some Web search engines group related hits from one Web site using an indented link , along with a link to more hits from that site ; an example can be seen under the link Adobe Labs - Homepage in Figure 5.1 .","label":"Background","metadata":{},"score":"60.59762"}
{"text":"In aekvRATF - queries , however , the effects of such kinds of keys are depressed .It should be noted that aekvRATF - queries performed better than baseline queries both in the TREC and CLEF tests .The next step in the development of our automatic CLIR system at UTA is to develop a more effective n - gram translation technique .","label":"Background","metadata":{},"score":"60.621883"}
{"text":"g.sub.A200 using group average agglomerative clustering are found .These 200 word clusters are considered low coverage clusters .The Buckshot method is one example of a method to cluster the groups .A second matrix B is formed in step 108 by considering a larger vocabulary subset .","label":"Background","metadata":{},"score":"60.72163"}
{"text":"The RATF formula gives high values for the keys whose atf ( i.e. , cf / df ) is high and df low .The scaling parameter SP is used to downweight rare words .In the CLEF tests , the SP value of 800 was used based on the relative collection sizes of the TREC and CLEF collections .","label":"Background","metadata":{},"score":"60.80573"}
{"text":"Step 106 forms the first set of topical word classes by clustering Matrix A into groups .The clustering algorithm is based on the cosine similarity between the columns of matrix A. For example , 200 A - classes g.sub.A1 , g.sub.","label":"Background","metadata":{},"score":"60.829624"}
{"text":"If the text is long , then showing an overview of where the highlighted terms occur throughout the document can be useful .This can be done in several ways .One way is to use the document scrollbar to show the location of term hits .","label":"Background","metadata":{},"score":"60.870358"}
{"text":"In order-0 retrieval , the occurrence of the word \" coast \" in one document and the use of its synonym \" shoreline \" in a related document will not increase the similarity of the two documents .The higher - order scheme can exploit synonymy since \" coast \" and \" shoreline \" have similar neighbors .","label":"Background","metadata":{},"score":"60.900887"}
{"text":"Filter results of a full - text publication search by selecting specific dimensions of information you wish to view relevant to the publications ( e.g. , Crime Type , Geography , Language , Demographics , or Information Type ) .Selecting more types of information narrows your results further .","label":"Background","metadata":{},"score":"60.909092"}
{"text":"Documents 13609 , 22872 , and 27081 are long documents with more than one topic .Therefore , their document vectors are closer to the global centroid .Their nearest neighbors are function words , because function words share the characteristic of having a large number of words from different topics as their neighbors .","label":"Background","metadata":{},"score":"60.948357"}
{"text":"Furthermore , many researchers use measures for defining closeness that will group words according to frequency .By using these measures , it is impossible for a frequent word to have an infrequent neighbor .SUMMARY OF THE INVENTION .An object of the invention is to form a new corpus based method for constructing a thesaurus based on lexical co - occurrence of terms in the corpus .","label":"Background","metadata":{},"score":"61.086357"}
{"text":"words co - occurring next to each other .In practice , a substantial number of collocations in real languages are non - continuous .For example , the collocation \" make use of \" may occur in natural language documents as \" make good use of \" , spanning the word \" good \" so as to be a non - continuous collocation .","label":"Background","metadata":{},"score":"61.089844"}
{"text":"The second pass computes Matrix A and the A - classes .The third pass computes Matrix B and the B - classes .Finally , the fourth pass computes Matrix C. In addition , Matrix C is decomposed by using singular value decomposition to compute the thesaurus vectors .","label":"Background","metadata":{},"score":"61.11246"}
{"text":"This collection of information is sometimes referred to as the document surrogate .Marchionini and White , 2008 note that document surrogates are summary information intended to help the user understand the primary object , as opposed to metadata more broadly construed , which can also serve this purpose but is often more tailored towards use by computer programs .","label":"Background","metadata":{},"score":"61.186897"}
{"text":"The basic idea of tf.idf weighting is that the more occurrences a query key has in a document and the fewer there are documents where the key occurs , the more likely the document is to be relevant with respect to the query .","label":"Background","metadata":{},"score":"61.306667"}
{"text":"In systems in which the user can view the full text of a retrieved document , it is often useful to highlight the occurrences of the terms or descriptors that match those of the user 's query .The Firefox Web browser and Google toolbar allow users to search for words within the currently viewed document , and then display the hits with color highlighting .","label":"Background","metadata":{},"score":"61.307316"}
{"text":"A method according .claim 4 , wherein the multilingual resource comprises a glosser .A method according to . claim 5 , wherein the glosser is a limited non - deterministic glosser .A method according to .claim 6 , wherein the glosser forms a plurality of translations of at least one of the identified terms and assigns to each translation a priority according to the likelihood of the translation being correct .","label":"Background","metadata":{},"score":"61.449608"}
{"text":"Simply providing \" relevant \" and \" not relevant \" buttons in the interface does not seem to provide enough incentive for the user .For this reason , a number of researchers are investigating techniques to infer relevance through passive measures such as time spent browsing a page or number of links followed from a page .","label":"Background","metadata":{},"score":"61.480766"}
{"text":"Despite these results , Joachims et al . , 2005 found that participants were not blindly following link order .In a condition in which they complete reversed the rank order of the top 10 results , they found that in the reversed condition , participants viewed lower ranked links more frequently , scanning significantly more results than in the normal condition .","label":"Background","metadata":{},"score":"61.541378"}
{"text":"As can be seen , long RATF - reduced queries perform slightly better than unreduced ( undisambiguated ) queries , but in the case of short queries the removal of low - RATF keys actually results in performance drop .An obvious reason for this is that , though most keys with low RATFs apparently are harmful , some keys with low RATFs are important .","label":"Background","metadata":{},"score":"61.543434"}
{"text":"For example : . gangs . \" drug court \" .Narrow Results .Results will be sorted by content type .Narrow your results further by selecting the type of information you wish to view , e.g. , Publications ( Full Text ) , Publications ( Abstracts Only ) , Federal Justice Web Pages , Q&A , Related Links , or Conferences .","label":"Background","metadata":{},"score":"61.628616"}
{"text":"Filter results of a full - text publication search by selecting specific dimensions of information you wish to view relevant to the publications ( e.g. Crime Type , Geography , Language , Demographics , or Information Type ) .Selecting more types of information narrows your results further .","label":"Background","metadata":{},"score":"61.64245"}
{"text":"7 shows the Matrix B computed in the flow diagram of FIG .5 ; .FIG .8 shows the Matrix C computed in the flow diagram of FIG .5 ; .FIG .9 shows the reduced Matrix C computed in the flow diagram of FIG .","label":"Background","metadata":{},"score":"61.642845"}
{"text":"1 .In the example described hereinafter , the multilingual glosser 12 converts between English and Dutch terms and is of the type disclosed EP 0 813 160 and GB 2 314 183 .The glosser 12 converts the terms of the source language query into target language query terms as indicated at 13 .","label":"Background","metadata":{},"score":"61.684547"}
{"text":"The simplest , and perhaps most conventional , approach to thesaurus construction is to manually build an explicit semantic mapping table .This is clearly labor - intensive , and hence only possible in specialized domains where repeated use may justify the cost .","label":"Background","metadata":{},"score":"61.705498"}
{"text":"Words are supported by their related terms .If a document contains a word and its related terms , the word is given a higher weight because it 's surrounded by supporting evidence .Semantic Distance : The more closely related the terms , the higher the weight .","label":"Background","metadata":{},"score":"61.77025"}
{"text":"A thesaurus must also cover all or most of the words found in queries , including the potentially unbounded set of proper nouns .These two considerations suggest that generic thesauri , which are restricted to common usage , are unlikely to be helpful .","label":"Background","metadata":{},"score":"61.819107"}
{"text":"These findings are referred to as the Semantic Proximity Effect .[ 6 ] .Expanding on these semantic proximity effects , in 2006 Zaromb et al .found that when participants made mistakes in recalling studied items , these mistakes tended to be items that were more semantically related to the desired item and found in a previously studied list .","label":"Background","metadata":{},"score":"61.83171"}
{"text":"For instance , in the case of subject matter without well - defined or stand terminology it may be difficult or impossible to select all keywords which might identify relevant documents .On the other hand , the use of more general keywords can lead to the disclosure of very large numbers of documents many of which are irrelevant .","label":"Background","metadata":{},"score":"61.89488"}
{"text":"B47 , then they would not be similar in the 200-dimensional space ; but they are similar in the reduced space .This is because the singular value decomposition algorithm recognizes and eliminates such redundancies .Four passes through the corpus are required to complete the computation .","label":"Background","metadata":{},"score":"61.93424"}
{"text":"FIG .3 illustrates part of the method shown in FIG .2 in more detail .The use of the method will be described with reference to a specific but arbitrary source language query in English for accessing documents in Dutch .","label":"Background","metadata":{},"score":"62.04498"}
{"text":"Likewise , the vector is an approximation in this lower dimensional space .We write this approximation as .Synonymy is the phenomenon where different words describe the same idea .Thus , a query in a search engine may fail to retrieve a relevant document that does not contain the words which appeared in the query .","label":"Background","metadata":{},"score":"62.10453"}
{"text":"4 shows the query formulation using DocumentSpace ; .FIG .5 is a flow diagram for computing the word vectors for the thesaurus ; .FIG .6 shows the Matrix A computed in the flow diagram of FIG .5 ; .","label":"Background","metadata":{},"score":"62.12663"}
{"text":"Thus , the multilingual resource 11 may comprise a machine translation system 14 .A suitable machine translation system is disclosed in W. John Hutchins and Harold L. Somers , \" An Introduction to Machine Translation \" , Academic Press , 1992 , ISBN 0 - 12 - 362830-X , the contents of which are incorporated herein by reference .","label":"Background","metadata":{},"score":"62.129128"}
{"text":"FIG .17 shows the memory locations for the ranking of document vectors by factor clusters ; .FIG .18 shows the final ranking of documents based on the factor cluster ranking ; and .FIG .19 is a graph showing the precision points computed by the context vector and the factor cluster vector methods .","label":"Background","metadata":{},"score":"62.166748"}
{"text":"( h ) accepting a query consisting of a sequence of words entered by a user using said keyboard and creating a parsed - query table of term - codes which consist of the term - codes in said vocabulary that are associated with the terms that are contained in said query ; .","label":"Background","metadata":{},"score":"62.191925"}
{"text":"( h ) accepting a query consisting of a sequence of words entered by a user using said keyboard and creating a parsed - query table of term - codes which consist of the term - codes in said vocabulary that are associated with the terms that are contained in said query ; .","label":"Background","metadata":{},"score":"62.191925"}
{"text":"Appendix A shows the ten highest ranking documents for each query term in Table 1 .With the exception of Societies , the document titles generally correspond to the topic described by the nearest neighbors of the query term .The cause for the religious articles retrieved for Societies may be the use of this term in the phrase \" Center for Religion and Human Rights in Closed Societies .","label":"Background","metadata":{},"score":"62.21783"}
{"text":"The key goodness scheme ( called RATF formula , where RATF refers to relative average term frequency ) was tested through several experiments in monolingual retrieval in a TREC collection .The highest ranked keys by the RATF scheme were weighted higher than other keys structurally and using the RATF values as query key and subquery weights .","label":"Background","metadata":{},"score":"62.26246"}
{"text":"The size of the CLEF collection was around one fourth of that of the TREC collection ( Section 3.1 ) .Second , duplet query keys were not removed from the CLEF queries .In other words , in the CLEF experiments the effectiveness of RATF - based queries was tested against that of queries in which query key frequencies were applied .","label":"Background","metadata":{},"score":"62.298637"}
{"text":"To illustrate the processing performed in the step 32 , a source language query \" introducing security passes \" is considered .The Dutch language translations of \" passes \" and their probabilities of being correct are given as : .A query generated from these alternatives ( and of course those of the other terms ) returns the following sets of results : .","label":"Background","metadata":{},"score":"62.35853"}
{"text":"The documents are analyzed to determine the number that are actually relevant to the query .The precision of the search is the ratio of the number of relevant documents to the number of retrieved documents .The recall of the search is the ratio of the number of relevant documents to the number of relevant documents in the corpus .","label":"Background","metadata":{},"score":"62.497673"}
{"text":"B4 contains words like \" navy \" , radar \" , and \" missile \" , while some of the member of class g.sub.B47 are \" tanks \" , \" missiles \" , and \" helicopters \" .If one of two words has many neighbors in g.sub.","label":"Background","metadata":{},"score":"62.503014"}
{"text":"No .07/790,316 to Pedersen et al . , which is incorporated herein by reference .The Buckshot method , which employs three subprocedures , will be described briefly .The first subprocedure , truncated group average agglomerate clustering , merges disjoint document sets , or groups , starting with individuals until only k groups remain .","label":"Background","metadata":{},"score":"62.513046"}
{"text":"A method according to . claim 1 , wherein the documents are natural language documents .A method according to . claim 1 , wherein the generating step comprises accessing a thesaurus with each identified term and the equivalent terms are synonyms of the identified terms , more general terms than the identified terms and more specific terms than the identified terms .","label":"Background","metadata":{},"score":"62.563576"}
{"text":"For instance , the index formed by the apparatus may be written to any of the storage media 8 , 9 , 10 shown in FIG .1 .The program memory 7 contains the aforementioned program which is executed by the data processor 2 and/or the multilingual resource 11 and/or the thesaurus 12 in order to carry out the various operations described herein .","label":"Background","metadata":{},"score":"62.587852"}
{"text":"Because the length of an order-1 representation is equal to the number of unique terms in the vocabulary , the order-1 representations are dense and require a lot of storage , which is a severe disadvantage .The order-1 vector of a long document will hardly have any zeros since almost every word is a neighbor of one of the document 's terms somewhere in the corpus .","label":"Background","metadata":{},"score":"62.62972"}
{"text":"378 - 383 , 1991 .Qui et al . , \" Concept Based Query Expansion \" , Department of Computer Science , Swiss Federal Institute of Technology , Zurich , Switzerland , pp .160 - 169 .Ruge , Gerda , \" Experiments on Linguistically - Based Term Associations \" , Information Processing & Management , vol .","label":"Background","metadata":{},"score":"62.676178"}
{"text":"5 : Presentation of Search Results .5.1 : Document Surrogates .The most common way that search results are displayed is as a vertical list of information summarizing the retrieved documents .( These search results listings are often known as \" search engine results pages , \" or SERPs , in industry . )","label":"Background","metadata":{},"score":"62.689434"}
{"text":"N ; and r are the dimensions of the reduced space .A singular value decomposition is an expensive operation .Therefore , compact representations can only be derived for a small part of the vocabulary using singular value decomposition .Let N be the number of words for which a singular value decomposition is feasible given the computational means available in a particular setting .","label":"Background","metadata":{},"score":"62.780075"}
{"text":"( in English : \" Getting pass marks in school : is a pass really good enough ? \" ) Veiligheid op kantoor : passen en beveiligingsbeambten .Now even though \" passen \" is by far the most likely query term translation , a document containing the least likely one has been ranked highest .","label":"Background","metadata":{},"score":"62.781097"}
{"text":"The method of claim 1 , wherein the similarity between two words uses a cosine similarity function of : # # EQU18 # # where V is a set of words ; w.sub.i is the word ; w.sub.j is the co - occurring word ; . phi . is a word encoding vector of the word and the co - occurring word .","label":"Background","metadata":{},"score":"62.803886"}
{"text":"Cross - Language Information Retrieval and Evaluation : Proceedings of the CLEF 2000 Workshop , Lecture Notes in Computer Science , 2069 , pp .211 - 225 .Heidelberg : Springer .Hedlund , T. , Keskustalo , H. , Pirkola , A. , Airio , E. , and Järvelin , K. ( 2001b ) .","label":"Background","metadata":{},"score":"62.814106"}
{"text":"After clustering the document , each document can then be described by the centroids of its subtopic clusters .The derivation of the structured document representations of order-2 are : .Order-2 clustering function : .Order-2 encoding function : # # EQU11 # # where .","label":"Background","metadata":{},"score":"62.825035"}
{"text":"If you are looking to hire a patent attorney , you 've come to the right place .Protect your idea and hire a patent lawyer .Document information retrieval using global word co - occurrence patterns .Abstract .A method and apparatus accesses relevant documents based on a query .","label":"Background","metadata":{},"score":"62.833668"}
{"text":"Plain syn - queries perform better than syn / avgRATF and syn / aekvRATF queries .Thus , using avgRATF and aekvRATF as syn - set weights does not improve performance .The factors that affect the performance of syn - queries are discussed in Pirkola , et al .","label":"Background","metadata":{},"score":"62.87349"}
{"text":"Thus , the dimensionality of the matrix fed into singular value decomposition can not be too high .In particular , the original matrix C can not be used .Instead , a two stage computation is performed that derives two sets of topical word classes from the corpus : 200 word clusters of low coverage ; and 200 word clusters of high coverage .","label":"Background","metadata":{},"score":"62.911377"}
{"text":"The reduced matrix C is shown in FIG .9 .To reduce compute time in the example , only a subset of the matrix , corresponding to the 1000th through 6000th most frequent word , was decomposed .This decomposition defined a mapping from the 200 dimensional B - class space to a 20 dimensional reduced space .","label":"Background","metadata":{},"score":"62.91144"}
{"text":"Assigning a \" polysemantic \" weight to each term , which polysemantic weight depends on the number of documents that the term is in , the number of relatives that the term has , and the relative strength of the first few relatives to the other relatives .","label":"Background","metadata":{},"score":"63.086433"}
{"text":"Assigning a \" polysemantic \" weight to each term , which polysemantic weight depends on the number of documents that the term is in , the number of relatives that the term has , and the relative strength of the first few relatives to the other relatives .","label":"Background","metadata":{},"score":"63.086433"}
{"text":"Multiplying either the modified summed relative percentages calculated in step j ) or the summed document weight×poly values calculated in step ( p ) by the adjust value .A method as in claim 1 where the formula for calculating the weight - in - document in step ( d ) is : # # EQU6 # # .","label":"Background","metadata":{},"score":"63.166634"}
{"text":"Multiplying either the modified summed relative percentages calculated in step j ) or the summed document weight×poly values calculated in step ( p ) by the adjust value .A method as in claim 1 where the formula for calculating the weight - in - document in step ( d ) is : # # EQU6 # # .","label":"Background","metadata":{},"score":"63.166634"}
{"text":"Description of the Prior Art .Document retrieval based on indexing of the documents in a document data base is well known .Typically the documents are indexed by creating an index file which records the documents that each word is in .","label":"Background","metadata":{},"score":"63.1735"}
{"text":"Description of the Prior Art .Document retrieval based on indexing of the documents in a document data base is well known .Typically the documents are indexed by creating an index file which records the documents that each word is in .","label":"Background","metadata":{},"score":"63.1735"}
{"text":"The method of claim 32 , wherein the rank of the most relevant document is output .An apparatus for generating a thesaurus of word vectors for each word in a corpus of documents , the word vectors being based on the lexical co - occurrence of words within each of the documents , comprising : . a memory containing the corpus of documents ; . an extractor for retrieving a word from the corpus ; . a generator generating a word vector for the word based on every recorded number ; and .","label":"Background","metadata":{},"score":"63.217514"}
{"text":"See Peat et al . ; \" The Limitations of Term Co - occurrence Data for Query Expansion in Document Retrieval Systems \" ; Journal of the American Society for Information Science 42 ( 5 ) ; pp .378 - 83 ; 1991 .","label":"Background","metadata":{},"score":"63.220695"}
{"text":"Guan and Cutrell , 2007 examined the results of the eye - tracking data and found that participants did look at the lower ranked results .They concluded that the participants ' behavior was caused by their expectation that the relevant results would be at or near the top .","label":"Background","metadata":{},"score":"63.245056"}
{"text":"In this study the training queries were used in the development of different RATF - based query types , and in determining the threshold RATFs .The TREC test request set consisted of the TREC Topics 76 - 100 and 126 - 150 .","label":"Background","metadata":{},"score":"63.276016"}
{"text":"Syn - Set Weighting .In this test , syn - sets of syn - queries ( baseline 3 ) were weighted using avgRATF and aekvRATF . AvgRATF .Syn - sets were weighted by their avgRATF values .AekvRATF .Syn - sets were weighted by their aekvRATF values .","label":"Background","metadata":{},"score":"63.28141"}
{"text":"An often - used example of such a query in Web search is \" java \" , where the context could be programming languages , Indonesia , or coffee ( or possibly others ) .Given such a query , the only way the ambiguity can be resolved is to ask the user for clarification in some form .","label":"Background","metadata":{},"score":"63.30551"}
{"text":"As shown in FIG .2 , the target language features are added to a target language index T in a step 36 .A specific example to illustrate this method will now be described .In this specific example , the source language documents are in English and it is required to be able to access the documents in English or Dutch .","label":"Background","metadata":{},"score":"63.430454"}
{"text":"If the query terms do not co - occur near one another in the same sentences , then the extract has to become very long if full sentences are to be shown .Some Web search engine snippets compromise by showing fragments of sentences instead .","label":"Background","metadata":{},"score":"63.452103"}
{"text":"This research had essentially the same goal as current research on personalization , which is to build a model of a user 's interests and preferences over time .Filtering systems , too , emphasize learning a user 's interest profile ( or profiles ) over time .","label":"Background","metadata":{},"score":"63.477043"}
{"text":"The user can use arrow keys to move rapidly from one document to the next .Appendix 1 contains the full BASIC program source code that implements the preferred embodiment described above .This code must be compiled using the Microsoft 7.1 BASIC compiler to produce object modules which must then be linked along with libraries containing object code for assembler routines from the Crescent Software QuickPak Professional Advanced Programming Library for BASIC Compilers Version 4.12 to produce an executable file .","label":"Background","metadata":{},"score":"63.53123"}
{"text":"The user can use arrow keys to move rapidly from one document to the next .Appendix 1 contains the full BASIC program source code that implements the preferred embodiment described above .This code must be compiled using the Microsoft 7.1 BASIC compiler to produce object modules which must then be linked along with libraries containing object code for assembler routines from the Crescent Software QuickPak Professional Advanced Programming Library for BASIC Compilers Version 4.12 to produce an executable file .","label":"Background","metadata":{},"score":"63.53123"}
{"text":"Discussion .One of the main problems associated with dictionary - based CLIR is translation ambiguity , which refers to the abundance of mistranslated keys in CLIR queries .The techniques to handle translation ambiguity involve corpus - based query expansion to reduce the effects of mistranslated and other bad keys ( Ballesteros and Croft , 1997 ; Chen , et al . , 1999 ) , the use of word co - occcurrence statistics for selecting the best or correct translations ( Chen , et al .","label":"Background","metadata":{},"score":"63.547577"}
{"text":"New York , NY : Association for Computing Machinery .Kwok , K.L. ( 2000 ) .Exploiting a Chinese - English bilingual wordlist for English - Chinese cross language information retrieval .Proceedings of the 5 th International Workshop on Information Retrieval with Asian languages , IRAL2000 , pp .","label":"Background","metadata":{},"score":"63.566307"}
{"text":"The effectiveness of the test queries was evaluated as precision at 10 % recall ( Pr . at 10 % R ) and average precision over 10%-100 % recall levels ( avg . precision ) .The former is a user - oriented measure for high - precision queries while the latter is a system - oriented average performance measure .","label":"Background","metadata":{},"score":"63.591347"}
{"text":"The remainder of this paper is structured as follows .Section 2 presents the RATF formula .Section 3 describes the methodology , and Section 4 the findings .Sections 5 and 6 contain the discussion and conclusions .The RATF formula .","label":"Background","metadata":{},"score":"63.595573"}
{"text":"Conover , W.J. ( 1980 )Practical non - parametric statistics .New York : John Wiley & Sons .Hedlund T , Keskustalo H , Pirkola A , Sepponen M & Järvelin K , ( 2001a ) .\" Bilingual tests with Swedish , Finnish and German queries : dealing with morphology , compound words and query structure \" .","label":"Background","metadata":{},"score":"63.63535"}
{"text":"A storage medium containing a program for controlling a data processor to perform a method for forming an index comprising indexing features for a plurality of documents , the method comprising the steps of : . identifying each of at least some of the terms present in the documents ; . generating from each identified term at least one equivalent term which is different from but linguistically related to the identified term ; . forming for each of the identified terms a first indexing feature comprising the identified term and an identifier of the or each document in which the identified term occurs ; . forming for each of the equivalent terms a second indexing feature comprising the equivalent term and an identifier of the or each document in which the identified term to which the equivalent term is equivalent occurs ; and .","label":"Background","metadata":{},"score":"63.69534"}
{"text":"Thus , the weight of the word drops because it has a low inverse document frequency .The context vectors d.sub.j depend only on the underlying thesaurus vectors .Thus , this method is automatic .The document vectors are a derivation from the corpus .","label":"Background","metadata":{},"score":"63.70616"}
{"text":"A \" dynamic \" view that responded to a mouse hover , and dynamically expanded the summary with a few words at a time .Eleven out of 18 participants preferred the instant view over the other two views , and on average all participants produced faster and more accurate results with this view .","label":"Background","metadata":{},"score":"63.728996"}
{"text":"The construction of the thesaurus will be described with reference to FIGS .5 - 9 .The goal is to apply a singular value decomposition to reduce the dimensionality of the matrix in a disciplined fashion and in the process produce more compact representations .","label":"Background","metadata":{},"score":"63.774746"}
{"text":"Average precision is 0.3218 .This is a five percent improvement over the tf.idf result of 0.271 .Although the invention has been illustrated with particularity , it is intended to be illustrative of the preferred embodiments .It is understood that the disclosure has been made byway of example only .","label":"Background","metadata":{},"score":"63.902794"}
{"text":"Instead , a better method would be to first determine if a query is ambiguous , then ask the user specific questions to resolve the ambiguity .How to accomplish this goal is another focus of our research .Even if we could resolve this domain ambiguity , we would still have to deal with task ambiguity ( e.g. do you want to buy Java , travel to Java , learn about Java , etc . )","label":"Background","metadata":{},"score":"63.957882"}
{"text":"The context vectors were computed for the 25 Category B topics of the Tipster collection .For each query , documents were ranked according to vector similarity as computed by the correlation coefficient and precision / recall statistics collected .The results of the invention were compared against a baseline standard vector space similarity search with augmented tf.idf term weighting .","label":"Background","metadata":{},"score":"64.02664"}
{"text":"A Google VP reported that despite the fact that users said they wanted more hits per page , an experiment in which the number of hits was increased to 30 hits per page showed a 20 % reduction in traffic ( Linden , 2006 ) .","label":"Background","metadata":{},"score":"64.07337"}
{"text":"The thesaurus vector is added to the context vector for the document in step 206 .If there are more words to process from the document , then the flow returns to step 204 to retrieve the thesaurus vector for the next word .","label":"Background","metadata":{},"score":"64.141106"}
{"text":"Evans et al . , \" Automatic Indexing Using Selective NLP And First - Order Thesauri \" , Departments of Philosophy and Computer Science Laboratory for Computational Linguistics , Carnegie Mellon University , Pittsburgh , PA , pp .624 - 639 .","label":"Background","metadata":{},"score":"64.178314"}
{"text":"An apparatus according to . claim 14 , wherein , for each term having more than one translation , the glosser is arranged to supply more than one of the translations .An apparatus according to claims 11 , wherein the query forming means is arranged to include in the target language query at least some of any terms in the source language query which can not be converted into the target language by the multilingual resource .","label":"Background","metadata":{},"score":"64.18439"}
{"text":"# # SPC1 # # .System and method for information retrieval by using keywords associated with a given set of data elements and the frequency of each keyword as determined by the number of data elements attached to each keyword","label":"Background","metadata":{},"score":"64.22272"}
{"text":"IF POOR prefix THEN .If word is found THEN DON'T find stem .List of Poor Prefixes : .List of Good Prefixes : .The next indexing program is AIMPASS2.BAS .It creates Key and Weight files .The nth Rec of Key .","label":"Background","metadata":{},"score":"64.26911"}
{"text":"IF POOR prefix THEN .If word is found THEN DON'T find stem .List of Poor Prefixes : .List of Good Prefixes : .The next indexing program is AIMPASS2.BAS .It creates Key and Weight files .The nth Rec of Key .","label":"Background","metadata":{},"score":"64.26911"}
{"text":"These might be hand built for a restricted domain or computed from the text of corpus itself .A thesaurus is a data structure that defines semantic relatedness between words .It is typically used in information retrieval to expand search terms with other closely related words .","label":"Background","metadata":{},"score":"64.33633"}
{"text":"partitions the corpus of documents D into subtopic clusters C ; and . psi . sub.2 ' assigns centroids of subtopic clusters to documents .The partitioning function makes sure that words pertaining to different topics remain separated in different clusters , thus avoiding document vectors that are too close to the global centroid .","label":"Background","metadata":{},"score":"64.352806"}
{"text":"Document titles are often uninformative or do not represent crucial parts of the content of a document .It also takes a relatively long time to read and evaluate them with respect to the user 's information needs .In systems based on order-0 representations , the user can only assess the impact of search terms indirectly by analyzing the retrieval results for varying search terms .","label":"Background","metadata":{},"score":"64.43163"}
{"text":"An improved retrieval performance results by inducing representations for documents that reflect term dependencies and remedy the bumpiness of small counts .However , undetected term dependencies and small counts are a problem if document occurrence is the basis of representation .","label":"Background","metadata":{},"score":"64.46988"}
{"text":"The equation to normalize the context vector is : # # EQU14 # # where p is the number of dimensions in the reduced space ; and d.sub.j is the context vector .By normalizing the context vectors , all of the context vectors will have the same length regardless of the size of the document .","label":"Background","metadata":{},"score":"64.520096"}
{"text":"Documents are then ranked by number of hits adjusted for the weights of hit words and their relative values .A method of indexing and retrieving documents , said method using a digital computer system having a central processing unit , a memory , a display screen , a keyboard , and a large capacity file system , said method comprising the steps of : .","label":"Background","metadata":{},"score":"64.54983"}
{"text":"Documents are then ranked by number of hits adjusted for the weights of hit words and their relative values .A method of indexing and retrieving documents , said method using a digital computer system having a central processing unit , a memory , a display screen , a keyboard , and a large capacity file system , said method comprising the steps of : .","label":"Background","metadata":{},"score":"64.54983"}
{"text":"See Crouch , C. ; \" An Approach to the Automatic Construction of Global Thesauri \" ; Information Processing & Management 26 ( 5 ) ; pp .629 - 40 ; 1990 .Documents are clustered into small groups based on similarity measure .","label":"Background","metadata":{},"score":"64.55239"}
{"text":"claim 16 , wherein the multilingual resource comprises a machine translation system .An apparatus according to . claim 13 , wherein the generating means comprises a bilingual dictionary .An apparatus according to . claim 13 , wherein the identifying means comprises a part of speech tagger .","label":"Background","metadata":{},"score":"64.62717"}
{"text":"In step 32 , sample C ' is partitioned into k groups by truncated group average agglomerative clustering .This partition is called partition G. In step 34 , partition P is constructed from corpus C by assigning each individual document to one of the centers in partition G. This is accomplished by applying assign - to - nearest over the corpus C and the k centers of partition G. In step 36 , partition G is replaced with partition P. Steps 34 and 36 are repeated once .","label":"Background","metadata":{},"score":"64.634"}
{"text":"The Wilcoxon test uses both the direction and the relative magnitude of the difference of comparable samples .The statistical program that was used is based on Conover ( 1980 ) .The statistical significance levels of 0.01 and 0.001 are indicated in the tables .","label":"Background","metadata":{},"score":"64.67093"}
{"text":"The invention will be further described by way of example , with reference to the accompanying drawings , in which : .FIG .1 is a block schematic diagram of an apparatus for forming an index constituting an embodiment of the invention ; and .","label":"Background","metadata":{},"score":"64.84462"}
{"text":"Incomplete sentences were marked with ellipses at the start and/or end of the list item .The 27 participants each performed 30 tasks , doing 10 tasks in each display condition .They were asked to find the right answer for a query from the results list as quickly as possible .","label":"Background","metadata":{},"score":"64.85516"}
{"text":"13 shows the memory locations for the ranking of documents ; .FIG .14 is a flow diagram for forming factor clusters of document vectors ; .FIG .15 shows the memory locations for the factor clusters ; .FIG .","label":"Background","metadata":{},"score":"64.96123"}
{"text":"Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , Melbourne , Australia , pp .64 - 71 .New York , NY : Association for Computing Machinery .Broglio , J. , Callan , J. and Croft , W.B. ( 1994 ) .","label":"Background","metadata":{},"score":"64.97051"}
{"text":"Early versions of this idea were developed in the Snippet Search tool by Pedersen et al .( Pedersen et al . , 1991 , Rao et al . , 1994 ) and the SuperBook tool ( Landauer et al . , 1993 ) ( see Figure 8.4 in Chapter 8 ) .","label":"Background","metadata":{},"score":"64.98764"}
{"text":"FIG .4 is a view of the display screen showing the modified query ; .FIG .5 is a view of the display screen showing suggested SWAPS terms for the modified query of FIG .4 ; .FIG .","label":"Background","metadata":{},"score":"65.042244"}
{"text":"FIG .4 is a view of the display screen showing the modified query ; .FIG .5 is a view of the display screen showing suggested SWAPS terms for the modified query of FIG .4 ; .FIG .","label":"Background","metadata":{},"score":"65.042244"}
{"text":"An example of a target language query is as follows : . behandelingen AND voor AND ( voetschimmel OR ( atleet AND ( voet OR basis ) ) ) .The query formulator 14 detects that the source language query terms \" treatments \" and \" for \" have single Dutch translations and must be present in any document of relevance .","label":"Background","metadata":{},"score":"65.07405"}
{"text":"The context vector is a combination of the weighted sums of the thesaurus vectors of all the words contained in the document .These context vectors then induce a similarity measure on documents and queries that can be directly compared to standard vector - space methods .","label":"Background","metadata":{},"score":"65.07475"}
{"text":"The full list of indexing programs can be found in FIG .10 .Here we will describe the most important of these programs : AIM , AIMPASS2 , FREQCOMP , RELATIVE , and POLYSEMY .The first indexing program is AIM.BAS : Automatic Indexing Module .","label":"Background","metadata":{},"score":"65.10939"}
{"text":"The full list of indexing programs can be found in FIG .10 .Here we will describe the most important of these programs : AIM , AIMPASS2 , FREQCOMP , RELATIVE , and POLYSEMY .The first indexing program is AIM.BAS : Automatic Indexing Module .","label":"Background","metadata":{},"score":"65.10939"}
{"text":"Instead , they stored and displayed only the first few sentences of text from each document .Subsequent to that writing , Google began storing full text of documents , making them visible in their cache and using their content for query - biased summaries .","label":"Background","metadata":{},"score":"65.1846"}
{"text":"Therefore , syn - queries can be run only in some systems .Nevertheless , the experiments in the CLEF collection showed that the utilization of RATF in CLIR has limitations .The CLEF experiments differed from the TREC experiments in three main points .","label":"Background","metadata":{},"score":"65.25221"}
{"text":"Synonyms rarely co - occur .Synonyms tend to share neighbors that occur with both .For example , \" litigation \" and \" lawsuit \" share neighbors such as \" court \" , \" judge \" , and \" proceedings \" .","label":"Background","metadata":{},"score":"65.272026"}
{"text":"A principal object of the present invention is to provide an improved method of indexing and retrieving documents which : .( A ) allows a user to easily modify his query based on the content of the documents so that the new query will retrieve documents that are of interest to the user ; .","label":"Background","metadata":{},"score":"65.330605"}
{"text":"A principal object of the present invention is to provide an improved method of indexing and retrieving documents which : .( A ) allows a user to easily modify his query based on the content of the documents so that the new query will retrieve documents that are of interest to the user ; .","label":"Background","metadata":{},"score":"65.330605"}
{"text":"An example of the result of such a search is as follows : .Moderne behandelingen voor voetschimmel .Voetschimmel : nieuwe behandelingen voor een oude kwaal .Behandelingen voor aandoeningen van de atleet op basis van nieuwe medische vindingen .A step 32 then processes the search results based on sorting and priority information calculated in the step 28 and a specific example of this is described hereinafter .","label":"Background","metadata":{},"score":"65.37239"}
{"text":"FIG .4 shows the user interface for DocumentSpace , which is parallel to the user interface for WordSpace .The user interface has functions for adding to and deleting from the pool and for looking at the nearest neighbors of the pool or an individual document .","label":"Background","metadata":{},"score":"65.42452"}
{"text":"Full Text Indexing Based on Lexical Relations An Application : Software Libraries \" , Yoelle S. Maarek et al . , Proceedings of the Twelfth Annual International ACMSIGIR Conference on Research and Development in Information Retrieval , Jun. 25 - 28 , 1989 , pp .","label":"Background","metadata":{},"score":"65.43792"}
{"text":"There are fewer fourgram combinations than there are words in the English language .The informational significance of individual terms can be evaluated by looking at their nearest neighbors .The topical characteristics of the selected words are obvious from looking at the few nearest neighbors given .","label":"Background","metadata":{},"score":"65.51708"}
{"text":"Description of Related Art .Information retrieval systems typically define similarity between queries and documents in terms of a weighted sum of matching words .The usual approach is to represent documents and queries as long vectors and use similarity search techniques .","label":"Background","metadata":{},"score":"65.70141"}
{"text":"Machine translation systems also perform tasks which are not useful to information retrieval and , in particular , to the forming of a multilingual index .For instance , in addition to translating words and groups of words contained in documents , machine translation systems also attempt to produce a good quality translation which is readable for human beings .","label":"Background","metadata":{},"score":"65.74048"}
{"text":"An apparatus according to .claim 16 , wherein the multilingual resource comprises a glosser .An apparatus according to . claim 17 , wherein the glosser is a limited non - deterministic glosser .An apparatus according to .claim 18 , wherein the glosser is arranged to form a plurality of translations of at least one of the identified terms and to assign to each translation a priority according to the likelihood of the translation being correct .","label":"Background","metadata":{},"score":"65.74109"}
{"text":"The content of each patent specification is analyzed in accordance with the International Classification and the relevant classification numbers for the subject matter form part of the heading of both the printed patent specification and he machine - readable form .In order to locate patent specifications , or indeed other documents , whose collections are similarly classified according to subject matter , it is necessary to select the correct international class and to apply this to a searching system .","label":"Background","metadata":{},"score":"65.90146"}
{"text":"Any opinions , findings and conclusions or recommendations expressed in this material are the author(s ) and do not necessarily reflect those of the sponsor .References . A. Berger and J. Lafferty , \" Information retrieval as statistical translation \" , Proceedings of ACM SIGIR 99 , 222 - 229 , 1999 .","label":"Background","metadata":{},"score":"65.91629"}
{"text":"By using the order-2 scheme , 55,000 word vectors are computed .An alternative method is to compute vectors for 5,000 letter fourgrams instead of words in iteration 1 ( for . psi . ' sub.1 ) .A fourgram is a sub - word fragment of four letters .","label":"Background","metadata":{},"score":"65.98241"}
{"text":"Therefore , the new ranking is : .Veiligheid op kantoor : passen en beveiligingsbeambten .Een pas opent alle deuren .Het halen van voldoendes in school : zijn voldoendes echt voldoende ? which is more in line with the information about the likelihoods of the translation alternatives being correct .","label":"Background","metadata":{},"score":"66.03099"}
{"text":"Table 4 shows the results of the baseline TREC runs .Tables 5 - 9 show the results of the test TREC runs .In Tables 5 - 9 the performance of test queries is compared with that of undisambiguated queries .","label":"Background","metadata":{},"score":"66.07325"}
{"text":"Organic Results vs. Advertisements : In most Web search engines , the search hits are shown in order of computed relevance to the query .In some cases , however , paid advertisements are shown at the top and/or to the side of search results .","label":"Background","metadata":{},"score":"66.236664"}
{"text":"The expression \" identifier \" as used herein is any means for identifying one or more locations of a term , for instance a heading or arbitrary serial number of a document containing the term .The expression \" indexing feature \" as used herein means a term and an identifier .","label":"Background","metadata":{},"score":"66.23749"}
{"text":"A clustering algorithm is used in step 304 to cluster the retrieved thesaurus vectors based on different topics or factors .The clustered vectors are stored in the RAM in step 306 according to the relevant factor .In FIG .15 , the memory locations are divided into factors .","label":"Background","metadata":{},"score":"66.285736"}
{"text":"The method of claim 32 , wherein computing the correlation coefficient for each document uses the following formula : # # EQU26 # # where . psi .( f.sub.m ) is the factor vector for factor cluster f.sub.m and . psi .","label":"Background","metadata":{},"score":"66.432945"}
{"text":"11 is a description of the program modules in FIG .9 ; and .FIGS .12A to 12C are description of the ABSTRACT program module .DESCRIPTION OF THE PREFERRED EMBODIMENTS .This invention will now be described as embodied in a computer system of the type shown in FIG .","label":"Background","metadata":{},"score":"66.47453"}
{"text":"11 is a description of the program modules in FIG .9 ; and .FIGS .12A to 12C are description of the ABSTRACT program module .DESCRIPTION OF THE PREFERRED EMBODIMENTS .This invention will now be described as embodied in a computer system of the type shown in FIG .","label":"Background","metadata":{},"score":"66.47453"}
{"text":"C # version of SVDLIBC is used .To perform a keyword search across the entire site and select Federal justice Web pages , type the word or words that describe your topic into the open search box .Select go or press enter .","label":"Background","metadata":{},"score":"66.58532"}
{"text":"The method of claim 25 , further comprising outputting at least one document according to its ranking . inputting a query ; . generating a factor vector for the query based on a clustering of the word vectors of the query ; . determining a correlation coefficient for each document based on the factor vector and the context vector for that document ; . ranking each document within a factor cluster based on the determined correlation coefficients ; and . determining a maximum rank of each document based on a combination of the ranks of the documents in each factor cluster ; and . outputting a final rank for at least one of the documents .","label":"Background","metadata":{},"score":"66.68175"}
{"text":"The TREC topics 101 - 150 are narrower in scope and have fewer relevant documents than the topics 51 - 100 ( Harman , 1993 ) .The average performance level of the queries 51 - 100 is higher than that of the queries 101 - 150 .","label":"Background","metadata":{},"score":"66.71862"}
{"text":"Using the companion lists to construct relative lists for each term which relative lists usually contain only those companions which also have said term as a companion .Associated with each relative is the relative percentage which is a weighted average of the companion 's percentage as a companion of the term and the term 's companion percentage as a companion of the companion .","label":"Background","metadata":{},"score":"66.72989"}
{"text":"Using the companion lists to construct relative lists for each term which relative lists usually contain only those companions which also have said term as a companion .Associated with each relative is the relative percentage which is a weighted average of the companion 's percentage as a companion of the term and the term 's companion percentage as a companion of the companion .","label":"Background","metadata":{},"score":"66.72989"}
{"text":"The net effect of this computation is to produce for each unique term a dense p - dimensional vector that characterizes its co - occurrence neighborhoods .These vectors then define a thesaurus by associating each word with its nearest neighbors .","label":"Background","metadata":{},"score":"66.755585"}
{"text":"( F ) Calculating some function of the number of hits value and the modified sum of penalties value to produce a power value ; .( G )Raising a number approximately equal to 2 to the power value to produce an adjust value ; .","label":"Background","metadata":{},"score":"66.91087"}
{"text":"( F ) Calculating some function of the number of hits value and the modified sum of penalties value to produce a power value ; .( G )Raising a number approximately equal to 2 to the power value to produce an adjust value ; .","label":"Background","metadata":{},"score":"66.91087"}
{"text":"For example , in Voorhees et al . , \" acts \" is expanded with the meaning \" acts of the apostles \" in a corpus of legal documents .In addition , they frequently do not record information about proper nouns , yet proper nouns are often excellent retrieval cues .","label":"Background","metadata":{},"score":"66.929504"}
{"text":"The invention will be further described , by way of example , with reference to the accompanying drawings , in which : .FIG .1 is a block schematic diagram of an apparatus for retrieving information constituting an embodiment of the invention ; .","label":"Background","metadata":{},"score":"66.94655"}
{"text":"We thus assumed that by applying RATF values as key and subquery weights CLIR queries will perform well despite the abundance of mistranslated and other bad keys .This is because many of the bad keys are general words whose RATFs are low , and when RATF values are used as key weights bad keys are downweighted with respect to the more specific important keys which typically have high RATFs .","label":"Background","metadata":{},"score":"67.0396"}
{"text":"In step 250 , the correlation coefficient is computed based on the context vector of the query and the context vectors of the corpus of documents .The correlation coefficient is computed using the cosine function described earlier ( see equation 3 ) .","label":"Background","metadata":{},"score":"67.07799"}
{"text":"Order-2 encoding for words : # # EQU9 # # .Order-2 encoding for documents : # # EQU10 # # .Since order-1 vectors are based on word neighbors , the representation for a word w.sub.i that is derived in this way contains information about the neighbors of the neighbors of w.sub.i in the document collection .","label":"Background","metadata":{},"score":"67.148705"}
{"text":", 2005b .They analyzed the eye movements of 42 students on 10 pre - defined queries , and found two distinct styles of scanning results list .46 % of the participants were \" economic , \" scanning at most half of the 6 - 7 visible search results in 50 % of the tasks .","label":"Background","metadata":{},"score":"67.24717"}
{"text":"An apparatus for retrieving information from a plurality of documents in a target language using a query in a source language , comprising : . a multilingual resource for converting the query into the target language , . means for applying the query in the target language to an information management system which identifies a plurality of documents in the target language based on the query , . means for using the additional information on the target language to re - rank the plurality of documents identified by the information management system according to a degree of relevance , . wherein the multilingual resource is arranged to convert at least part or all of at least one of the plurality of documents in the target language identified by the information management system into the source language .","label":"Background","metadata":{},"score":"67.3962"}
{"text":"Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , Zurich , Switzerland , pp .21 - 29 .New York , NY : Association for Computing Machinery .Sperer , R. and Oard , D. ( 2000 )","label":"Background","metadata":{},"score":"67.40179"}
{"text":"2 is a flow diagram illustrating a method of retrieving information constituting an embodiment of the invention ; and .FIG .3 is a more detailed flow diagram of a method similar to that illustrated in FIG .2 . DETAILED DESCRIPTION OF THE INVENTION .","label":"Background","metadata":{},"score":"67.43408"}
{"text":"The method of claim 14 , wherein the number of intervening words is 50 .The method of claim 1 , further comprising generating a context vector for each document of the corpus , the context vector for a document based on the word vectors from the thesaurus for each word located in the document .","label":"Background","metadata":{},"score":"67.4603"}
{"text":"But there are many pieces of information that are relevant , yet can not be searched for , because the journalist does n't know about them yet .Thus TwinSpaces is ideal for this type of search , which is intermediate between literal retrieval and simply browsing all of the documents .","label":"Background","metadata":{},"score":"67.48441"}
{"text":"Accordingly , when it is desired to retrieve information from the document collection , queries in either English or Dutch may be applied to the index by means of an information retrieval system .These queries may be in the form of words or collocations related to the subject matter to be searched .","label":"Background","metadata":{},"score":"67.51842"}
{"text":"In step 330 , the documents of the corpus are retrieved into the processor .The document vectors for each document are computed in step 332 by using equation 15 .The document vectors are stored in step 334 .In step 340 , the correlation coefficients between the computed document vectors and the factor vector are computed by using the following equation : # # EQU17 # # where . psi .","label":"Background","metadata":{},"score":"67.579865"}
{"text":"The nearest neighbors of the pool ( tank , artillery ) are printed in the section SEARCH RESULT .By inspecting these neighbors , the user can make sure that the \" receptacle \" sense of the word \" tank \" will not interfere with a query on military equipment .","label":"Background","metadata":{},"score":"67.655106"}
{"text":"The present invention facilitates the rapid searching of a document data base for documents that are of interest to the user .By using the suggested SWAPS terms the user can modify his query so as to retrieve those documents , if they exist in the data base , which are of interest .","label":"Background","metadata":{},"score":"67.66939"}
{"text":"The present invention facilitates the rapid searching of a document data base for documents that are of interest to the user .By using the suggested SWAPS terms the user can modify his query so as to retrieve those documents , if they exist in the data base , which are of interest .","label":"Background","metadata":{},"score":"67.66939"}
{"text":"In addition to the standard metadata of title , author , date , etc . , and search result summaries , this section discusses several other features that have been found useful ( or not ) for search results listings .Number of Hits Per Page : : Web search engines typically show ten results , or \" hits , \" per page , with hyperlinks to additional pages of results .","label":"Background","metadata":{},"score":"67.70552"}
{"text":"The information management system 16 is , in this example , a Dutch World Wide Web search engine .The source language query is \" treatments for athlete 's foot \" .In a step 21 , the glosser identifies the individual terms of the query , which terms may be words , non - continuous collocations and continuous collocations , and stores these terms in a set S. The specific query is converted into the set of terms : . treatments .","label":"Background","metadata":{},"score":"67.736786"}
{"text":"If that translation is incorrect , then retrieval of information based on the incorrect translation will be ineffective because relevant documents may not be located and irrelevant documents may be located .SUMMARY OF THE INVENTION .Other machine translation systems attempt to generate all possible translations of input text .","label":"Background","metadata":{},"score":"67.91352"}
{"text":"Examples of such applications include information retrieval systems , such as search engines , for accessing information on the internet or in office information systems , information filtering applications ( also known as information routing systems ) and information extraction applications .","label":"Background","metadata":{},"score":"68.02777"}
{"text":"J. Ponte , \" Language models for relevance feedback \" , in Advances in Information Retrieval , ed .W.B. Croft , 73 - 96 , 2000 .C.J. Van Rijsbergen , Information Retrieval , Butterworths , 1979 .G. Salton , Automatic Information Organization and Retrieval , McGraw - Hill , 1968 .","label":"Background","metadata":{},"score":"68.03731"}
{"text":"AekvRATF reduces the weights of false correspondents of n - gram matching .This is because the six best corespondents of n - gram matching were grouped together , and aekvRATF was computed for this key group of the six keys .","label":"Background","metadata":{},"score":"68.088005"}
{"text":"A storage medium containing an index comprising indexing features for a plurality of documents , the index formed by a method comprising the steps of : . identifying each of at least some of the terms present in the documents ; . generating from each identified term at least one equivalent term which is different from but linguistically related to the identified term ; . forming for each of the identified terms a first indexing feature comprising the identified term and an identifier of the or each document in which the identified term occurs ; . forming for each of the equivalent terms a second indexing feature comprising the equivalent term and an identifier of the or each document in which the identified term to which the equivalent term is equivalent occurs ; and .","label":"Background","metadata":{},"score":"68.57881"}
{"text":"According to a fifth aspect of the invention , there is provided a storage medium containing an index according to the fourth aspect of the invention .According to a sixth aspect of the invention , there is provided use of an index according to the fourth aspect of the invention to access the documents .","label":"Background","metadata":{},"score":"68.60286"}
{"text":"( k ) sorting said modified swap table by said modified summed - relative - percentages in descending order ; .( l ) displaying on said display the terms corresponding to the term - codes of said modified swap table ; .","label":"Background","metadata":{},"score":"68.705574"}
{"text":"( k ) sorting said modified swap table by said modified summed - relative - percentages in descending order ; .( l ) displaying on said display the terms corresponding to the term - codes of said modified swap table ; .","label":"Background","metadata":{},"score":"68.705574"}
{"text":"This problem is not particular to higher - order representations .A computationally simple approach to segment long documents is to cluster the set of tokens in a document into a set of coherent subtopic clusters .A token is a single item in full text .","label":"Background","metadata":{},"score":"68.82719"}
{"text":"claim 4 , wherein the multilingual resource comprises a bilingual dictionary .A method according to .claim 4 , wherein the multilingual resource comprises a machine translation system .A method according to . claim 1 , wherein the identifying step is performed by a part of speech tagger .","label":"Background","metadata":{},"score":"68.86398"}
{"text":"# # EQU5 # # ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ MAXIMUM PENALTY TABLE ( RANKING ) query words Max .","label":"Background","metadata":{},"score":"68.88279"}
{"text":"# # EQU5 # # ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ MAXIMUM PENALTY TABLE ( RANKING ) query words Max .","label":"Background","metadata":{},"score":"68.8828"}
{"text":"The topic is identified as belonging to the general area of \" Science and Technology \" .Therefore , \" science \" is one of the terms of the query .However , it is not relevant for the query .One of the word factors of the topic 75 is the following : . failed ; instance ; force ; conversely ; science .","label":"Background","metadata":{},"score":"68.90417"}
{"text":"This solution is costly since parsing technology is required to determine head - modifier relations in sentences .It is also unclear to what extent words with similar heads or modifiers are good candidates for expansion .For example , adjectives referring to countries have similar heads ( \" the Japanese / Chilean capital \" , \" the Japanese / Chilean government \" ) , but adding \" Japanese \" to a query that contains \" Chilean \" will rarely produce good results .","label":"Background","metadata":{},"score":"68.91591"}
{"text":"athlete . foot .athlete 's foot .A step 22 sets a parameter \" element \" to a value of 1 and a parameter N to the cardinality of the set S ie .a value equal to the number of elements of the set S which , in the specific example , is 5 .","label":"Background","metadata":{},"score":"69.09007"}
{"text":"Inquery is based on Bayesian inference networks .All keys are attached with a belief value , which is calculated by the tf.idf modification of the system ( Allan , et al .The value 0.4 is a default value given to a key not occurring in a document .","label":"Background","metadata":{},"score":"69.14348"}
{"text":"The method of claim 3 , wherein a number of words selected from the corpus to form the first matrix is 3000 words .The method of claim 5 , wherein the selected words are medium frequency words .The method of claim 3 , wherein the clustering of the first matrix and the second matrix use a Buckshot fast clustering algorithm .","label":"Background","metadata":{},"score":"69.23974"}
{"text":"If the word \" tank \" occurs in two documents , but water does n't , the document containing words related to water ( such as pipes or flush ) will be rated higher than the one pertaining to a different topic .","label":"Background","metadata":{},"score":"69.26233"}
{"text":"This feature is referred to in the industry as sitelinks or deep links , and informal reports suggest they are frequently clicked on .Presumably , these links are chosen based on clickthrough popularity for other queries as well as descriptive titles on the links .","label":"Background","metadata":{},"score":"69.33426"}
{"text":"While this method is superior to approaches that treat phrase terms as unanalyzed segments , there is no notion of semantic similarity of basic terms .For example , the semantic similarity of \" astronaut \" and \" cosmonaut \" is not represented in the hierarchy .","label":"Background","metadata":{},"score":"69.36889"}
{"text":"There are many data bases which contain documents in machine - readable form and which can be accessed to locate and retrieve information .Similarly , there are various known techniques for locating documents on the basis of subject matter .One example of this is the collection of published patent specifications .","label":"Background","metadata":{},"score":"69.529465"}
{"text":"The method of claim 25 , wherein the step of outputting comprises outputting , instead of the ranking for at least one document , at least one document according to its corresponding ranking .The method of claim 25 , further comprising outputting at least one document according to its ranking .","label":"Background","metadata":{},"score":"69.560715"}
{"text":"10 .The computed context vectors are stored by the processor in step 234 .The documents are retrieved by the processor in step 240 .This step can be performed before or in parallel with the query processing .The context vectors for each document are computed in step 242 .","label":"Background","metadata":{},"score":"69.62439"}
{"text":"An apparatus for retrieving relevant documents from a corpus of documents based on a query , comprising : . a memory containing the corpus of documents ; . a thesaurus of word vectors for each word of the corpus , the word vectors being based on lexical co - occurrence of words within each of the documents ; . determining means for determining a co - occurrence correlation relationship between the document vectors and the query vector ; and .","label":"Background","metadata":{},"score":"69.66618"}
{"text":"Narrow Results .Results will be sorted by content type .Narrow your results further by selecting the type of information you wish to view , e.g. , Publications ( Full Text ) , Publications ( Abstracts Only ) , Federal Justice Web Pages , Q&A , Related Links , or Conferences .","label":"Background","metadata":{},"score":"69.693726"}
{"text":"By using the SWAPS feature repeatedly the user can in effect roam around the data base without actually retrieving and reading documents .Only after the query has been modified to include all the interesting SWAPS terms , does the user need to actually retrieve the documents .","label":"Background","metadata":{},"score":"69.94307"}
{"text":"By using the SWAPS feature repeatedly the user can in effect roam around the data base without actually retrieving and reading documents .Only after the query has been modified to include all the interesting SWAPS terms , does the user need to actually retrieve the documents .","label":"Background","metadata":{},"score":"69.94307"}
{"text":"claim 4 , wherein the glosser identifies and translates terms which are collocations but does not translate the individual words of the collocations .A method according to .claim 4 , wherein , for each term having more than one translation , the glosser supplies more than one of the translations .","label":"Background","metadata":{},"score":"69.96644"}
{"text":"The original English queries contained as query keys the title words ( short queries ) and the title and description words ( long queries ) of the TREC Topics ( 76 - 100 and 126 - 150 ) .The English queries were run in the study to show the performance level of the test queries .","label":"Background","metadata":{},"score":"69.98993"}
{"text":"TwinSpaces uses the methods of thesaurus vectors and document vectors defined in this application .TwinSpaces has two parts : WordSpace ( generation of word vectors ) and DocumentSpace ( generation of document vectors ) .TwinSpaces is ideal for a user who has a clearly defined information need , but who may not be fully aware of the vocabulary that is used for the topic of interest in the document collection .","label":"Background","metadata":{},"score":"70.05024"}
{"text":"The scheme is defined as the function RATF as follows : .Let k denote some key of a collection and cf k its collection frequency , and df k its document frequency .Let SP be a collection dependent scaling parameter , and p the power parameter .","label":"Background","metadata":{},"score":"70.131676"}
{"text":"The Adaptive Threshold Value is the average Weight value of the 80thKeyword in each document ( 0 if there are less than 80 Keywords in a document ) .The nth Rec of Weight .Ndx contains up to 127 ( or as many Keywords are above the Adaptive Threshold Value ) Document Weights computed with the following weight formula : # # EQU1 # # .","label":"Background","metadata":{},"score":"70.16419"}
{"text":"The Adaptive Threshold Value is the average Weight value of the 80thKeyword in each document ( 0 if there are less than 80 Keywords in a document ) .The nth Rec of Weight .Ndx contains up to 127 ( or as many Keywords are above the Adaptive Threshold Value ) Document Weights computed with the following weight formula : # # EQU1 # # .","label":"Background","metadata":{},"score":"70.16419"}
{"text":"The words of the ( 1 ) title and ( 2 ) title and description fields of the TREC request sets were used as query keys .The former queries are called short queries and the latter ones long queries .The CLEF test request set contained CLEF 2001 topics ( 50 topics ) .","label":"Background","metadata":{},"score":"70.1781"}
{"text":"No . 07/456,558 , filed Dec. 26 , 1989 , both now abandoned .BACKGROUND OF THE INVENTION .Field of the Invention .This invention relates generally to document storage and retrieval systems and more particularly to a method of indexing documents so that they can be retrieved in response to a query in order of their relevance to the query .","label":"Background","metadata":{},"score":"70.22716"}
{"text":"No . 07/456,558 , filed Dec. 26 , 1989 , both now abandoned .BACKGROUND OF THE INVENTION .Field of the Invention .This invention relates generally to document storage and retrieval systems and more particularly to a method of indexing documents so that they can be retrieved in response to a query in order of their relevance to the query .","label":"Background","metadata":{},"score":"70.22716"}
{"text":"Limitations of bag of words model ( BOW ) , where a text is represented as an unordered collection of words .Complete LSA DEMO in C # for Windows .DEMO includes enumeration of text files , filtering stop words , stemming , making document - term matrix and SVD .","label":"Background","metadata":{},"score":"70.34128"}
{"text":"Processing results and user input information can be monitored on a CRT display monitor 14 .After processor 16 has completed processing the documents , the results can be output to an output device 18 , which includes , for example , a storage means ( hard or floppy disk ) , a printer , a photocopier , a facsimile machine or a CRT display .","label":"Background","metadata":{},"score":"70.378334"}
{"text":"See Salton et al . ; \" Introduction to Modern Information Retrieval \" ; McGraw - Hill , New York ; 1983 .These vectors can be represented as an encoding scheme of order-0 , which is defined as : .Order-0 encoding for words : # # EQU1 # # .","label":"Background","metadata":{},"score":"70.40593"}
{"text":"A Boolean search finds exactly the words you typed .If the word , words , or combination of words is found anywhere in a document , that document is included in the search results .Since the match is perfect , the results of a Boolean search are always 100 % .","label":"Background","metadata":{},"score":"70.42003"}
{"text":"Acknowledgements .The Inquery search engine was provided by the Center for Intelligent Information Retrieval at the University of Massachusetts .This research is part of the research project Query structures and dictionaries as tools in concept - based and cross - lingual information retrieval funded by the Academy of Finland ( Research Projects 44703 ; 49157 ) .","label":"Background","metadata":{},"score":"70.42322"}
{"text":"Order-1 encoding for words : # # EQU5 # # .A reasonable setting of W is 50 words .So a word is represented as the sum of its neighbors .To make the similarity between the two approaches explicit , an occurrence of a word is defined to be its own neighbor of order-0 and ordinary neighbors are defined to be neighbors of order-1 .","label":"Background","metadata":{},"score":"70.7384"}
{"text":"293 - 309 ; 1991 .Word vectors are manually encoded for a medium number of words .Then , the document vectors are computed as sums of word vectors .However , this hand - encoding of documents is labor - intensive .","label":"Background","metadata":{},"score":"70.7711"}
{"text":"The generating means may comprise a bilingual dictionary .The identifying means may comprise a part of speech tagger .The apparatus may comprise a programmed data processor .According to a third aspect of the invention , there is provided a storage medium containing a program for controlling a data processor to perform a method according to the first aspect of the invention .","label":"Background","metadata":{},"score":"70.7986"}
{"text":"A method according to . claim 1 , wherein the at least part of each document comprises a title of the document .A method according to . claim 1 , wherein the at least part of each document comprises an abstract or abridgement of the document .","label":"Background","metadata":{},"score":"70.82216"}
{"text":"Method of and apparatus for retrieving information and storage medium US 6360196 B1 .Résumé .A method for retrieving information from a plurality of documents in a target language using a query in a source language , including the steps of : . converting the query into the target language using a multilingual resource , . forming a query in the target language from the converted query and additional information on the target language , the additional information on the target language including information indicating a likelihood or probability of a converted query term in the target language being a correctly converted term , .","label":"Background","metadata":{},"score":"70.92472"}
{"text":"Similar to the order-0 and order-1 functions ( . psi . sub.0 and . psi . sub.1 ) , order-2 function . psi . sub.2( d.sub.j ) is computed by summing up the vectors of the tokens occurring in d.sub.j .","label":"Background","metadata":{},"score":"70.97023"}
{"text":"The matrix product contains all these dot products .Element ( which is equal to element ) contains the dot product ( ) .Likewise , the matrix contains the dot products between all the document vectors , giving their correlation over the terms : .","label":"Background","metadata":{},"score":"70.97609"}
{"text":"The dynamic view suffered from the problem that , as the text expanded , the mouse no longer covered the selected results , and so an unintended , different search result sometimes started to expand .Notably , none of the participants preferred the standard results listing view .","label":"Background","metadata":{},"score":"71.11895"}
{"text":"Any rectangular matrix ( including square matrices such as matrix X ) can be decomposed into the product of three matrices : . such that matrices T.sub.0 and D.sub.0 have orthonormal columns and matrix S.sub.0 is diagonal .This is called the singular value decomposition of matrix X. Matrices T.sub.0 and D.sub.0 are the matrices of left and right singular vectors , respectively , and matrix S.sub.0 is the diagonal matrix of singular values .","label":"Background","metadata":{},"score":"71.1735"}
{"text":"The number of results per content type is shown on the right of the search results page .Order Select Publications Online .An \" Order Print Copy \" image appears for items available for online ordering .An \" Order Photocopy \" image appears for results that are not available for hardcopy ordering , but may be ordered through NCJRS photocopy services .","label":"Background","metadata":{},"score":"71.23589"}
{"text":"An apparatus according to . claim 11 , wherein the at least part of each document comprises an abstract or abridgement of the document .An apparatus according to . claim 11 , herein the at least part of each document comprises a sentence containing terms which match the query in the target language .","label":"Background","metadata":{},"score":"71.250565"}
{"text":"Documents containing the terms or logical combinations of the terms of each query are then made available to the apparatus , for instance by down - loading into the memory 5 .In order to provide sufficient memory capacity , the memory 5 may include disc drives of the magnetic or optical storage type .","label":"Background","metadata":{},"score":"71.28934"}
{"text":"It only retrieves the documents , which contain the arguments of the operator within the defined window .In queries , the operators are marked by the hash sign \" # \" , e.g. , # sum and # wsum .Commas are not needed between query keys or their weights .","label":"Background","metadata":{},"score":"71.33941"}
{"text":"The method of claim 3 , wherein a number of low coverage word clusters is 200 .The method of claim 3 , wherein the second subset contains 20,000 words .The method of claim 10 , wherein the words within the second subset are the most frequent words excluding stop words .","label":"Background","metadata":{},"score":"71.448204"}
{"text":"The participants were asked to perform 4 tasks .The time taken depended on the task and the interface , but 10 out of 13 participants preferred the highlighted overview version over the other two .Chapter 10 discusses other variations on these ideas .","label":"Background","metadata":{},"score":"71.45273"}
{"text":"FIG .10 shows the process of computation of context vectors .In step 200 , the query or document is loaded into the processor 16 ( see FIG .1 ) .All of the words in the query or document are extracted in step 202 .","label":"Background","metadata":{},"score":"71.52516"}
{"text":"37 , No .02A , Feb. 1994 , pp . 79 - 82 .\" LSI meets TREC :A Status Report \" , Susan T. Dumais , NIST Special Publication 500 - 207 , The First Text Retrieval Conference ( TREC-1 ) , Mar. , 1993 , pp .","label":"Background","metadata":{},"score":"71.55025"}
{"text":"However , LSI is based on document occurrence .Decomposing a term - by - document matrix of a large collection can take days or even weeks because the time complexity is quadratic in the number of documents to process .Documents can be represented as vectors whose entries correspond to microfeatures such as finance , animal kingdom , etc .","label":"Background","metadata":{},"score":"71.86676"}
{"text":"The method of claim 25 , wherein computing the correlation coefficient uses the following formula : # # EQU24 # # where . psi .( d.sub.i ) is the query vector and . psi .( d.sub.j ) is the document vector .","label":"Background","metadata":{},"score":"71.88347"}
{"text":"Single Key Weighting .In the second test we investigated whether the RATF scheme applies for the weighting of single keys .The following four weighting methods were tested .( RATF values were multiplied by 100 . )RATF .Query keys were weighted by their RATF values .","label":"Background","metadata":{},"score":"71.979294"}
{"text":"3 and in particular a new SWAPS term \" statute of limitations \" is suggested .Here the fact that both terms \" statutes \" and \" statute of limitations \" contain the same word is fortuitous .It is the meaning of the term \" statutes \" which makes it a close relative of \" statute of limitations \" by virtue of the fact that these two terms co - occur in many of the same documents .","label":"Background","metadata":{},"score":"71.994705"}
{"text":"3 and in particular a new SWAPS term \" statute of limitations \" is suggested .Here the fact that both terms \" statutes \" and \" statute of limitations \" contain the same word is fortuitous .It is the meaning of the term \" statutes \" which makes it a close relative of \" statute of limitations \" by virtue of the fact that these two terms co - occur in many of the same documents .","label":"Background","metadata":{},"score":"71.994705"}
{"text":"The TREC and CLEF queries differed from each other , first , in that unlike TREC queries duplet keys were retained in the CLEF queries .Second , in the CLEF tests proper names and other words not contained in the translation dictionary were translated by an n - gram matching method .","label":"Background","metadata":{},"score":"72.03822"}
{"text":"By convention the diagonal elements of matrix S.sub.0 are constructed to be all positive and ordered in decreasing magnitude .Singular value decomposition allows a simple strategy for optimal approximate fit using smaller matrices .If the singular values in matrix S.sub.0 are ordered by size , the first k largest may be kept and the remaining smaller ones set to zero .","label":"Background","metadata":{},"score":"72.37763"}
{"text":"Both products have the same non - zero eigenvalues , given by the non - zero entries of , or equally , by the non - zero entries of .Now the decomposition looks like this : .The values are called the singular values , and and the left and right singular vectors .","label":"Background","metadata":{},"score":"72.404976"}
{"text":"The disambiguation effect of the uwn - operator refers to the fact that normally a combination of two mistranslated keys does not make any sense .Therefore , the proximity combination method applied for the translation equivalents probably has a clear disambiguation effect .","label":"Background","metadata":{},"score":"72.502335"}
{"text":"There is no overlap between word vectors .In the order-0 encoding , each word corresponds to a vector with exactly one non - zero weight ; that is , one entry for its own dimension .In the simplest case , this weight is one .","label":"Background","metadata":{},"score":"72.6084"}
{"text":"The closeness of terms with equal frequency occurs because the terms have about the same number of zero entries in their term vectors .For a given term , singular value decomposition assigns values to all dimensions of the space , so that frequent and infrequent terms can be close in the reduced space if they occur with similar terms .","label":"Background","metadata":{},"score":"72.72182"}
{"text":"More precisely , the space of word vectors can be viewed as the surface of a partial hypersphere in a multidimensional space that is centered around the global centroid .Vectors in the area of the global centroid are equally close to everything .","label":"Background","metadata":{},"score":"72.733536"}
{"text":"This embodiment utilizes the following computer hardware and software : .( 1 ) IBM compatible personal computer with at least 4 MB of RAM , a large capacity hard drive , a display screen , and a keyboard .( 2 ) MS - DOS compatible operating system and LIM 3.2 compatible expanded memory manager .","label":"Background","metadata":{},"score":"72.824036"}
{"text":"This embodiment utilizes the following computer hardware and software : .( 1 ) IBM compatible personal computer with at least 4 MB of RAM , a large capacity hard drive , a display screen , and a keyboard .( 2 ) MS - DOS compatible operating system and LIM 3.2 compatible expanded memory manager .","label":"Background","metadata":{},"score":"72.824036"}
{"text":"Sample : # # STR4##Resulting File : Main Word Relatives . . .( sorted)______________________________________A B 70 . . .BA 70 . ..._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"73.088745"}
{"text":"Sample : # # STR4##Resulting File : Main Word Relatives . . .( sorted)______________________________________A B 70 . . .BA 70 . ..._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"73.088745"}
{"text":"The number of results per content type is shown on the right of the search results page .Order Select Publications Online .A shopping cart icon appears for items available for online ordering .An \" order photocopy \" icon appears for results that are not available for hardcopy ordering , but may be ordered through NCJRS photocopy services .","label":"Background","metadata":{},"score":"73.17267"}
{"text":"( The dictionary gave 60 translations ; in Table 2 only the words with the highest and lowest RATFs are presented ) .In Tables 1 and 2 , words are sorted by their RATF values .In both cases the word Airbus is ranked high .","label":"Background","metadata":{},"score":"73.18859"}
{"text":"The apparatus of claim 46 , wherein the relevant documents are determined by combining the ranking of the document within each factor cluster .Description .BACKGROUND OF THE INVENTION .Field of the Invention .This invention relates to improvements in retrieving relevant documents from a corpus of documents .","label":"Background","metadata":{},"score":"73.53483"}
{"text":"1 shows an apparatus for retrieving information using an information management system 1 , such as an Internet search engine .The apparatus is of the programmed data processor type , such as a computer , and comprises a programmable data processor 2 provided with an input interface 3 , such as a keyboard and mouse , and an output interface 4 , such as a display and printer .","label":"Background","metadata":{},"score":"73.727974"}
{"text":"Proceedings of the TIPSTER Text Program ( Phase I ) , pp .47 - 67 .San Francisco , CA : Morgan Kaufman Publishers Inc. .Buckley , C. , Singhal , A. , Mitra , M. and Salton , G. ( 1995 ) \" New retrieval approaches using SMART : TREC-4 .","label":"Background","metadata":{},"score":"73.73375"}
{"text":"The output interface 4 may be used for displaying the results of searches and for providing information about operation of the apparatus .The data processor 2 has a \" working memory \" in the form of random access memory ( RAM ) 5 for temporarily storing data during data processing .","label":"Background","metadata":{},"score":"73.79214"}
{"text":"An apparatus according to . claim 13 , wherein the generating means comprises a thesaurus and the equivalent terms are synonyms of the identified terms , more general terms than the identified terms and more specific terms than the identified terms .","label":"Background","metadata":{},"score":"73.83727"}
{"text":"1 .The document store 1 contains a collection S of documents in a source language such as a natural language .For the purpose of illustration only , operation will be described for the case where the documents of the collection S are in English and an English and Dutch index is required .","label":"Background","metadata":{},"score":"73.97549"}
{"text":"317 - 332 , 1992 .Voorhees et al . , \" Vector Expansion in a Large Collection \" , Siemens Corporate Research , Inc. , Princeton , New Jersey .Wilks et al . , \" Providing Machine Tractable Dictionary Tools \" , Computer Research Laboratory , New Mexico State University , Las Cruces , New Mexico , pp .","label":"Background","metadata":{},"score":"74.22145"}
{"text":"However , a disadvantage of this system is that efficient use requires familiarity with and experience of using the International Classification system .Also , this technique relies on correct classification of patent specifications .Inexperienced use can result in relevant patent specifications being missed whereas incorrect classification can prevent a relevant patent specification from ever being located by this technique .","label":"Background","metadata":{},"score":"74.38114"}
{"text":"The method of claim 1 , wherein a matrix of word vectors is formed using all of the generated word vectors of the corpus .The method of claim 2 , wherein forming the matrix comprises the steps of : . forming a first matrix from a first subset of words within the corpus , each element of the first matrix recording the number of times that two words within the first subset co - occur in the predetermined range ; . clustering the first matrix into groups to form a set of low coverage word clusters ; . clustering the second matrix into groups to form a set of high coverage word clusters ; . reducing dimensionality of the third matrix to represent each element of the third matrix as a compact vector .","label":"Background","metadata":{},"score":"74.417786"}
{"text":"The method of claim 19 , wherein the word vectors are weighted before being added together .The method of claim 19 further comprising the step of normalizing the context vector .The method of claim 18 , wherein generating the context vector uses the equation : # # EQU21 # # where d.sub.j is the vector for document j ; w.sub.ij is the weight for word i in document j ; and v.sub.i is the thesaurus vector for word i. .","label":"Background","metadata":{},"score":"74.842575"}
{"text":"Crouch constructs thesaurus classes by grouping words into bins of related words .Unfortunately , the boundaries between classes will be inevitably somewhat artificial .If classes are made too small , some words will be cut off from part of their topical neighborhood .","label":"Background","metadata":{},"score":"75.26437"}
{"text":"D -- a set of documents ; . d.sub.j--a document j in D ; . psi . --document encoding ; . vertline.d.sub.j .vertline .--the number of tokens in d.sub.j ; and . t.sub.j,k --the k.sup.th token in document d.sub.j .","label":"Background","metadata":{},"score":"75.50855"}
{"text":"The query is formed on the basis of the title of the TREC Topic 52 ( South African Sanctions ) .Table 3 shows the RATF values for these keys .# wsum(100 382 africa 249 sanction 177 south ) .Table 3 : RATF values for the words of the title of the Topic 52 .","label":"Background","metadata":{},"score":"75.729416"}
{"text":"Polysemy is the phenomenon where the same word has multiple meanings .So a search may retrieve irrelevant documents containing the desired words in the wrong meaning .For example , a botanist and a computer scientist looking for the word \" tree \" probably desire different sets of documents .","label":"Background","metadata":{},"score":"75.97384"}
{"text":"The WebForager search system placed search results into virtual \" books \" that could be \" flipped through \" using animation in a 2.5D rendering .( Image courtesy Stuart Card . )5.6 : Visualization of Search Results .The bulk of the information visualization ideas that are tried for search apply to the display of retrieval results .","label":"Background","metadata":{},"score":"75.98979"}
{"text":"phi . sub.0 is an order-0 vector for tokens t.sub.j,l . .The method of claim 14 , wherein the word vector is generated based on : # # EQU20 # # where . phi .phi .sub.1 is an order-1 vector for token t.sub.j,l . .","label":"Background","metadata":{},"score":"75.99681"}
{"text":"Many changes , modifications , variations and other uses and applications of the subject invention will , however , become apparent to those skilled in the art after considering this specification and the accompanying drawings which disclose the preferred embodiments therefor .","label":"Background","metadata":{},"score":"76.05754"}
{"text":"Many changes , modifications , variations and other uses and applications of the subject invention will , however , become apparent to those skilled in the art after considering this specification and the accompanying drawings which disclose the preferred embodiments therefor .","label":"Background","metadata":{},"score":"76.05756"}
{"text":"Description .TECHNICAL FIELD OF THE INVENTION .The present invention relates to a method of and an apparatus for forming an index .The invention also relates to a storage medium storing a program for performing the method , an index , a storage medium containing the index and the use of the index to access documents .","label":"Background","metadata":{},"score":"76.25879"}
{"text":"A common example of this is where queries contain proper names .For example , it is unlikely that the multilingual resource would be able to translate proper names such as \" Dagmar Dwehus \" .However , such query terms may be very useful in retrieving relevant documents , for example where it is desired to retrieve only documents containing such a proper name .","label":"Background","metadata":{},"score":"76.53331"}
{"text":"Salton , G. ( 1989 ) .Automatic text processing : the transformation , analysis , and retrieval of information by computer .Reading , MA : Addison - Wesley .Singhal , A. , Buckley , C. and Mitra , M. ( 1996 ) .","label":"Background","metadata":{},"score":"76.89685"}
{"text":"A storage medium containing a program for controlling a programmed data processor of an apparatus for retrieving information from a plurality of documents in a target language using a query in a source language , the apparatus comprising : . a multilingual resource for converting the query into the target language , . means for applying the query in the target language to an information management system which identifies a plurality of documents in the target language based on the query , . means for using the additional information on the target language to re - rank the plurality of documents identified by the information management system according to a degree of relevance , . wherein the multilingual resource is arranged to convert at least part or all of at least one of the plurality of documents in the target language identified by the information management system into the source language .","label":"Background","metadata":{},"score":"76.986145"}
{"text":"Primary Examiner : Hayes ; Gail O. Assistant Examiner : Kalidindi ; Krishna Attorney , Agent or Firm : . Oliff & Berridge Claims .I claim : .A method , using a processor and memory , for generating a thesaurus of word vectors based on lexical co - occurrence of words within documents of a corpus of documents , the corpus stored in the memory , the method comprising : . retrieving into the processor a retrieved word from the corpus ; . recording a number of times a co - occuring word co - occurs in a same document within a predetermined range of the retrieved word ; . repeating the recording step for every co - occurring word located within the predetermined range for each occurrence of the retrieved word in the corpus ; . generating a word vector for the word based on every recorded number ; . repeating the retrieving , recording , recording repeating and generating steps for each word in the corpus , and .","label":"Background","metadata":{},"score":"77.39942"}
{"text":"The apparatus of claim 40 , wherein the thesaurus comprises : . an extractor for retrieving a word from the corpus ; . a generator generating a word vector for the word based on every recorded number .The apparatus of claim 40 , wherein the determining means ranks the documents based on the correlation relationship .","label":"Background","metadata":{},"score":"77.499176"}
{"text":"A method as in claim 1 where the function in step ( j ) is the identity function .A method as in claim 1 where the function in step ( p ) is the identity function .Description .This is a continuation of application Ser .","label":"Background","metadata":{},"score":"77.808945"}
{"text":"A method as in claim 1 where the function in step ( j ) is the identity function .A method as in claim 1 where the function in step ( p ) is the identity function .Description .This is a continuation of application Ser .","label":"Background","metadata":{},"score":"77.808945"}
{"text":"1 . DETAILED DESCRIPTION OF THE INVENTION .FIG .1 shows an apparatus for forming an index to a plurality of documents in machine - readable form stored in a document store 1 , such as a magnetic disc or an optical storage medium such as a CD - ROM .","label":"Background","metadata":{},"score":"77.83918"}
{"text":"Let this row vector be called .Likewise , the only part of that contributes to is the column , .These are not the eigenvectors , but depend on all the eigenvectors .It turns out that when you select the largest singular values , and their corresponding singular vectors from and , you get the rank approximation to X with the smallest error ( Frobenius norm ) .","label":"Background","metadata":{},"score":"77.87741"}
{"text":"The foregoing and other objects , features and advantages of the present invention will become apparent from the following , more particular description of the preferred embodiments of the invention , as illustrated in the accompanying drawings .BRIEF DESCRIPTION OF THE DRAWINGS .","label":"Background","metadata":{},"score":"78.061325"}
{"text":"The foregoing and other objects , features and advantages of the present invention will become apparent from the following , more particular description of the preferred embodiments of the invention , as illustrated in the accompanying drawings .BRIEF DESCRIPTION OF THE DRAWINGS .","label":"Background","metadata":{},"score":"78.061325"}
{"text":"A linear - time clustering algorithm such as Buckshot ( Cutting et al .1992 ) can be used .See Cutting et al . ; \" Scatter - gather : A Cluster - Based Approach to Browsing Large Document Collections \" ; Proceedings of SIGIR 1992 .","label":"Background","metadata":{},"score":"78.18332"}
{"text":"For the sum -operator , the system computes the average of key ( or subquery ) weights .The keys contained in the weighted sum ( wsum ) operator are weighted according to the weight value associated with each key ( or subexpression ) .","label":"Background","metadata":{},"score":"78.22638"}
{"text":"Once you have selected your criteria , click the search button to get your results .For more tips on searching for events , visit the Criminal Justice Events help page .Search the NCJRS Abstracts Database .Use the NCJRS Abstracts Database Online Tutorial to learn more about how to search the Database .","label":"Background","metadata":{},"score":"78.40619"}
{"text":"While this invention is described in some detail herein , with specific reference to illustrated embodiments , it is to be understood that there is no intent to be limited to these embodiments .On the contrary , the aim is to cover all the modifications , alternatives and equivalents falling within the spirit and scope of the invention as defined by the claims .","label":"Background","metadata":{},"score":"78.58453"}
{"text":"Although the glosser 8 is illustrated as an independent component of the apparatus , it may be embodied by the data processor 2 and the memories 5 to 7 .The program memory 7 contains the aforementioned program which is executed by the data processor 2 and/or the document glosser 8 included therein in order to carry out the various operations described herein .","label":"Background","metadata":{},"score":"78.58674"}
{"text":"A professional translator translated the TREC and CLEF topics ( title and description fields ) into Finnish according to the guidelines provided by CLEF ( Peters , 2000 ) .The Finnish words were retranslated to English using an automatic query translation and construction system developed in the Information Retrieval Laboratory at the University of Tampere ( UTA ) .","label":"Background","metadata":{},"score":"78.88122"}
{"text":"For the purpose of the singular value decomposition , all order-1 representations of the vocabulary V are collected into a . vertline .V.vertline.x.vertline . V.vertline . matrix X such that row i of matrix X contains the order-1 vector of word i , i.e. , . phi .","label":"Background","metadata":{},"score":"79.824875"}
{"text":"A group average agglomerative clustering was used to group query terms into factors based on their thesaurus vectors .Each topic was clustered into three word factors .All directly juxtaposed words occurring at least five times in the corpus were used as terms . trade conflicts - airbus subsidies , anti dumping , countervailing , countervailing duty , dumping , dumping duty , federal subsidies , gatt , general agreement , review group , subsidies , tariffs , trade dispute , trade policy , trade tension .","label":"Background","metadata":{},"score":"80.14345"}
{"text":"In addition , presentation of search results has been a major focus of the work on employing visualization techniques to search interfaces ; these efforts are discussed in detail elsewhere .Easy To Use Patents Search & Patent Lawyer Directory .At Patents you can conduct a Patent Search , File a Patent Application , find a Patent Attorney , or search available technology through our Patent Exchange .","label":"Background","metadata":{},"score":"81.83606"}
{"text":"ProLISSaProgress in Library and Information Science in Southern Africa .First biannual DISSAnet Conference .Pretoria , 26 - 27 October 2000 .Pretoria : Centre for Information Development , University of Pretoria .Pirkola , A. and Järvelin , K. 2001a .","label":"Background","metadata":{},"score":"81.90326"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ( for each pair ) 2 0.3 3 1.0 4 & up 0.9(for sum of pairs ) 2 0.3 3 1.4 4 1.8 5 2.3 6 & up 2.8 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"82.14342"}
{"text":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ( for each pair ) 2 0.3 3 1.0 4 & up 0.9(for sum of pairs ) 2 0.3 3 1.4 4 1.8 5 2.3 6 & up 2.8 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .","label":"Background","metadata":{},"score":"82.14342"}
{"text":"Tipster is a corpus of documents controlled by the government ( NIST - National Institute of Standards and Technology ) to further information retrieval methods .Note that these computations could have been accelerated by using loosely coupled coarse - grained parallelism to effect a linear reduction in compute time .","label":"Background","metadata":{},"score":"83.330666"}
{"text":"The approximation of X in the k - dimensional space amounts to a dimension reduction from the original .vertline .V.vertline . dimensional to the k - dimensional space .The new lower dimensional representations for words are the rows of matrix T. Row i of matrix T is the reduced vector representation of word w.sub.i .","label":"Background","metadata":{},"score":"83.48532"}
{"text":"Note also the diversity of topics in the first few results , including a link to the New York Jets football team site , a link to a site selling private jets , and a link to an engineering society .Informal reports suggest that in most cases , these kinds of multimedia results best placed a few positions down in the search results list ; when they replace the first hit they can cause people to leave the site .","label":"Background","metadata":{},"score":"83.48663"}
{"text":"Thus , the target language search results given hereinbefore are translated by the glosser , which gives the following result : .Modern treatments for athlete 's foot .Athlete 's foot : new treatments for an old problem .Treatments for injuries of athletes based on new medical discoveries .","label":"Background","metadata":{},"score":"85.658005"}
{"text":"TECHNICAL FIELD OF THE INVENTION .The present invention relates to a method of and an apparatus for retrieving information .The invention also relates to a storage medium containing a program for performing such a method .These techniques may be used in information management systems , such as information retrieval systems or \" search engines \" , information filtering applications also known as information routing systems , and information extraction applications .","label":"Background","metadata":{},"score":"85.85286"}
{"text":"litigation LAWSUITS ; audit ; lawsuit ; file ; auditors ; auditor ; suit ; sued ; proceedings .tax taxes ; income tax ; new tax ; income taxes ; taxpayers ; incentives ; LEVIES ; taxpayer ; corporate taxes .","label":"Background","metadata":{},"score":"86.92023"}
{"text":"Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , Athens , Greece , pp .120 - 127 .New York , NY : Association for Computing Machinery .Turtle , H.R. 1990 .","label":"Background","metadata":{},"score":"87.70632"}
{"text":"The data processor 2 has a \" working memory \" in the form of random access memory ( RAM ) 5 for temporarily storing data during data processing .A non - volatile read / write memory 6 is provided for storing data which are required to be retained , for instance , when the power supply to the apparatus is switched off .","label":"Background","metadata":{},"score":"88.447754"}
{"text":"The description of the topic 51 is as follows : .Document will discuss government assistance to Airbus Industrie , or mention a trade dispute between Airbus and a United States aircraft producer over the issue of subsidies .Table 2 presents the RATF values for the retranslated words of the Topic 51 .","label":"Background","metadata":{},"score":"89.054306"}
{"text":"The formula gives high values for the important topic words ( Airbus , subsidy ) , and low values for mistranslated and other bad words .However , automatic translation provides some pecularities .The form industrielle is a Finnish inflectional form of the word Industrie .","label":"Background","metadata":{},"score":"91.44696"}
{"text":"RATF .africa . sanction . south .RATF / nil - parameter .Query keys were weighted by their RATF / nil - parameter values .AvgRATF .Keys were weighted by their avgRATF values .AekvRATF .Keys were weighted by their aekvRATF values .","label":"Background","metadata":{},"score":"91.73831"}
{"text":"( \" pass\",#8 ) .( \" doorgeven\",#8 ) .( \" pas\",#8 ) .( \" kaart\",#8 ) .( \" out of\",#8 ) .( \" de\",#8 ) .( \" het\",#8 ) .( \" furnace\",#8 ) .( \" oven\",#8 ) .","label":"Background","metadata":{},"score":"92.33752"}
{"text":"A processor 16 is connected to the input device 12 for processing the document image into co - occurrence vectors and comparing the vectors .Processor 16 operates to perform these functions in accordance with operating programs read from read only memory ( ROM ) 20 , and by using random access memory ( RAM ) 22 .","label":"Background","metadata":{},"score":"92.5439"}
{"text":"The apparatus may also be provided with other memory devices .For instance , these may comprise suitable drives for CD - ROMs 8 , floppy discs 9 , and digital video discs ( DVDs ) 10 .These devices may be of the read - only type or , for instance in the case of floppy discs 9 , the read / write type .","label":"Background","metadata":{},"score":"92.602905"}
{"text":"The TREC collection contained 515,000 documents and the CLEF collection some 112,000 documents .As test requests we used 50 TREC and 50 CLEF topics .The title and description fields of the topics were translated by a professional translator into Finnish .","label":"Background","metadata":{},"score":"94.79411"}
{"text":"Figure 5.6 : \" Short cut \" information provided by Yahoo in response to the query weather in Berkeley .( Reproduced with permission of Yahoo ! Inc.2009 Yahoo ! Inc.YAHOO ! and the YAHOO ! logo are registered trademarks of Yahoo ! Inc. ) .","label":"Background","metadata":{},"score":"97.84242"}
{"text":"Acknowledgments .This paper describes some of the ongoing research in the Mongrel project , which is a collaboration between Professor Nick Belkin at Rutgers University , and Professors Allan and Croft at the University of Massachusetts .The paper is also related to research done in collaboration with Professor John Lafferty at Carnegie Mellon University .","label":"Background","metadata":{},"score":"98.25552"}
{"text":"interfaith effort aims to ease children 's suffering .blahoslav s. hruby , presbyterian minister , dies at 78 . rabbi kelman , leader of conservative judaism , dies at 66 . greek orthodox group wants to permit married bishops .vatican , jewish groups see need to fight anti - semitism in east .","label":"Background","metadata":{},"score":"98.674835"}
{"text":"The apparatus of claim 40 , wherein the memory is one of a RAM , a ROM and an external storage unit .The apparatus of claim 40 , wherein the query vector is a plurality of query factor vectors , each query factor vector based on a cluster factor of the query .","label":"Background","metadata":{},"score":"99.214554"}
{"text":"The user can also check whether a proper name like \" Eschenbach \" is used for a specific person in the corpus ( here it is the conductor Christopher Eschenbach ) .If there were a tennis player of the same name , then it would make Eschenbach less useful in a search for documents on classical music .","label":"Background","metadata":{},"score":"101.62831"}
{"text":"pope issue key document on roman catholic higher education .churches , s.f . mayor begin new push to enlist aids volunteers .leader of eastern orthodox christians begins visit to u.s . .leader of easter orthodox christians begins visit to u.s . .","label":"Background","metadata":{},"score":"110.12317"}
{"text":"Amherst , MA : University of Massachusetts , Computer and Information Science Department .PhD Dissertation .( COINS Technical Report 90 - 92 ) .Last updated : 18th January , 2001 University of Massachusetts .Amherst , MA 01003 - 4610 .","label":"Background","metadata":{},"score":"122.75339"}
