{"text":"Four iterative parameter estimation algorithms are compared on several NLP tasks .L - BFGS is observed to be the most effective parameter estimation method for Maximum Entropy model , much better than IIS and GIS .( Wallach 02 ) reported similar results on parameter estimation of Conditional Random Fields .","label":"CompareOrContrast","metadata":{},"score":"32.12541"}{"text":"In addition , the experimental result on text chunking shows that fewer serious errors help to improve the performance of subsequent NLP tasks .\" There are several techniques available and approved for realizing this classification task .Referred to section 3.1 SVMs can be used for such a task as applied by ( Nakagawa et al . , 2001 ) .","label":"CompareOrContrast","metadata":{},"score":"34.366226"}{"text":"The accuracy may be im- proved by incorporating some beam search scheme .Furthermore , our method outputs only the best answer and can not output the second or third best answer .There is a way to translate the outputs of SVMs as proba- bilities ( Platt , 1999 ) , which may be applied directly to remedy this problem .","label":"CompareOrContrast","metadata":{},"score":"35.24838"}{"text":"The concept of Maximum Entropy can be traced back along multiple threads to Biblical times .However , not until the late of 21st century has computer become powerful enough to handle complex problems with statistical modeling technique like Maxent .Maximum Entropy was first introduced to NLP area by Berger , et al ( 1996 ) and Della Pietra , et al .","label":"CompareOrContrast","metadata":{},"score":"35.7277"}{"text":"This paper aims to minimize these serious errors while retaining the overall performance of POS tagging .Two gradient loss functions are proposed to reflect the different types of errors .They are designed to assign a larger cost to serious errors and a smaller one to minor errors .","label":"CompareOrContrast","metadata":{},"score":"35.78914"}{"text":"We will focus here on a comparison with Back - off type methods , because an experimental comparison in Chen & Goodman ( 1996 ) shows the superiority of Back - off based methods over count re - estimation s .. \" ...","label":"CompareOrContrast","metadata":{},"score":"37.59391"}{"text":"That is to say , when characterizing some unknown events with a statistical model , we should always choose the one that has Maximum Entropy .Maximum Entropy Modeling has been successfully applied to Computer Vision , Spatial Physics , Natural Language Processing and many other fields .","label":"CompareOrContrast","metadata":{},"score":"37.6426"}{"text":"On a broader perspective our approach contributes to a better understanding on where corpuslinguistics and theoretical linguistics can meet and enrich each other .The need of large - scale corpora for higherlevel syntactic frameworks is addressed in Sadler et al ( 2000 ) , Frank ( 2000 ) , Frank et al ( 2001 ) , who develop methods to enrich treebanks with higher - level ... . by","label":"CompareOrContrast","metadata":{},"score":"38.88163"}{"text":"On a broader perspective our approach contributes to a better understanding on where corpuslinguistics and theoretical linguistics can meet and enrich each other .The need of large - scale corpora for higherlevel syntactic frameworks is addressed in Sadler et al ( 2000 ) , Frank ( 2000 ) , Frank et al ( 2001 ) , who develop methods to enrich treebanks with higher - level ... . by","label":"CompareOrContrast","metadata":{},"score":"38.88163"}{"text":"This method has the merit of having a small computational cost , but it has the demerit of not using the information of the succeeding POS tags .A tag dictionary which provides the lists of POS tags for known words ( i.e. , that appeared in training data ) is used .","label":"CompareOrContrast","metadata":{},"score":"39.012833"}{"text":"( van Halteren , 1996 ) ) .RankBoost can also use a variety of local and long distance features more easily than n - gram - based approaches ( cf .( Chen , Bangalore and Vijay - Shanker , 1999 ) ) because it makes sparse data less of an issue . \" ...","label":"CompareOrContrast","metadata":{},"score":"39.327023"}{"text":"( van Halteren , 1996 ) ) .RankBoost can also use a variety of local and long distance features more easily than n - gram - based approaches ( cf .( Chen , Bangalore and Vijay - Shanker , 1999 ) ) because it makes sparse data less of an issue . \" ...","label":"CompareOrContrast","metadata":{},"score":"39.327034"}{"text":"Advances in Large Margin Classifiers .MIT Press . A. Ratnaparkhi .Entropy Model for Part - of - Speech Tag- ging .In Proceedings of Conference on Empirical Methods in Natural Language Processing(EMNLP-1 ) , pages 133 - 142 .A Maximum D. Roth and D. Zelenko . of Speech Tagging Using a Network of Linear Separators .","label":"CompareOrContrast","metadata":{},"score":"39.896706"}{"text":", 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs of a statistical parser ( Collins , 2000 ) and ranking sentence plans ( Walker , Rambow and Rogati , 2001 ) .","label":"CompareOrContrast","metadata":{},"score":"40.44268"}{"text":", 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs of a statistical parser ( Collins , 2000 ) and ranking sentence plans ( Walker , Rambow and Rogati , 2001 ) .","label":"CompareOrContrast","metadata":{},"score":"40.44268"}{"text":"Later , Rosenfeld and his group proposed a Whole Sentence Exponential Model that overcome the computation bottleneck of conditional ME model .You can find more on my SLM page .This dissertation discusses the application of maxent model to various Natural Language Dis - ambiguity tasks in detail .","label":"CompareOrContrast","metadata":{},"score":"41.637623"}{"text":"4.1Using Only the Preceding POS Tags The first method uses only the POS tags of the preceding words .In probabilistic models such as HMM , the generative probabilities of all sequences are considered and the most likely path is selected by the Viterbi algorithm .","label":"CompareOrContrast","metadata":{},"score":"41.76094"}{"text":"T. Kudoh and Y. Matsumoto .Use of Support Vector Learning for Chunk Iden- tificationIn Proceedings of the Fourth Conference on Computational Natural Lan- guage Learning(CoNLL-2000 ) , pages 142- 144 . A. Mikheev .Automatic Rule Induc- tion for Unknown - Word Guessing .","label":"CompareOrContrast","metadata":{},"score":"42.062286"}{"text":"Computational Linguis- tics , 21(4 ) , pages 543 - 565 . E. Charniak , C. Hendrickson , N. Jacobson and M. Perkowitz .Part - of - Speech Tagging .In Proceedings of 1993 .Equations for .Page 7 . the Eleventh National Conference on Artifi- cial Intelligence(AAAI-93 ) , pages 784 - 789 .","label":"CompareOrContrast","metadata":{},"score":"43.769413"}{"text":"Eric Brill .Automatic grammar induction and parsing free text : A transformation - based appraoch .In Proceedings of the 31stAnnual Meeting of the ACL .Walter Daelemans , Jakub Zavrel , Peter Berck & Steven Gillis .MBT : A memory - based part of speech tagger - generator .","label":"CompareOrContrast","metadata":{},"score":"44.204163"}{"text":"a large number of features and hardly over- fit .Consequently , SVMs can be applied suc- cessfully to natural language processing ap- plications ( Joachims , 1998 ; Kudoh and Mat- sumoto , 2000 ) .In this paper , we show how to apply SVMs to more general POS tagging as well as unknown word guessing , and report some experimental results .","label":"CompareOrContrast","metadata":{},"score":"44.290188"}{"text":"In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) and in Kinyon ( 00b ) , which allows to factor the information contained in several Supertags into a single structure and to encode functional information in a systematic manner .","label":"CompareOrContrast","metadata":{},"score":"44.389957"}{"text":"In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) and in Kinyon ( 00b ) , which allows to factor the information contained in several Supertags into a single structure and to encode functional information in a systematic manner .","label":"CompareOrContrast","metadata":{},"score":"44.38996"}{"text":"Cross - entropy on held - out data shows these models to be state of the art in terms of performance . ... is kind of smoothing .We believe this is a direct correlate of the effectiveness of update exclusion ; the lower - order models do not need to be the best possible models of those orders , b .. by Csaba Oravecz , Péter Dienes - IN PROC .","label":"CompareOrContrast","metadata":{},"score":"44.71174"}{"text":"The optimal syntactic parse for a user query thus obtained is employed for phrase recognition and expansion .Phrase recognition is used to increase retrieval precision ; phrase expansion is applied to make the best use possible of very short Web queries . \" ... Abstract .","label":"CompareOrContrast","metadata":{},"score":"44.92083"}{"text":"In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .Because of the highly lexicalized nature of the LTAG formalism , we experimentally show that notions other than sentence length play a factor in observed parse times .","label":"CompareOrContrast","metadata":{},"score":"44.96215"}{"text":"In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .Because of the highly lexicalized nature of the LTAG formalism , we experimentally show that notions other than sentence length play a factor in observed parse times .","label":"CompareOrContrast","metadata":{},"score":"44.96215"}{"text":"Thirdly , the corpus should be enriched with various kinds of linguistic information .Given the special character of the speech contained in CoDAS , we can not simply carry over the design and the annotation protocols of existing corpora , such as SDC or CHILDES .","label":"CompareOrContrast","metadata":{},"score":"45.42017"}{"text":"Page 2 . rule - based method ( Mikheev , 1997 ) and the decision tree - based method ( Orphanos and Christodoulakis , 1999 ) .In this paper , we propose a method to pre- dict POS tags of unknown English words as a post - processing of POS tagging using Sup- port Vector Machines ( SVMs ) .","label":"CompareOrContrast","metadata":{},"score":"45.993034"}{"text":"We then describe our method for unknown word guessing and POS tagging in sections 3 and 4 .In section 5 , we describe the results of some experiments .While several of such separating hyperplanes exist ( Figure 1 , left ) , SVMs find the opti- mal hyperplane that maximizes the margin ( the distance between the hyperplane and the nearest points ) ( Figure 1 , right ) .","label":"CompareOrContrast","metadata":{},"score":"46.33229"}{"text":"We achieve high accuracy in POS tag prediction using substrings and surrounding context as the features .Furthermore , we integrate this method with a practical English POS tagger , and achieve accuracy of 97.1 % , higher than conventional approaches . aist - nara .","label":"CompareOrContrast","metadata":{},"score":"46.556175"}{"text":"Considering the high accuracy rate of up - to - date statis- tical POS taggers , unknown words account for a non - negligible portion of the errors .This paper describes POS prediction for unknown words usingSupportVector We achieve high accuracy in POS tag prediction using substrings and surrounding context as the features .","label":"CompareOrContrast","metadata":{},"score":"47.243088"}{"text":"In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the coverage of harid - crafted grammars .","label":"CompareOrContrast","metadata":{},"score":"47.33635"}{"text":"In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the coverage of harid - crafted grammars .","label":"CompareOrContrast","metadata":{},"score":"47.33635"}{"text":"Among several methods of multi - class classification for SVMs ( We- ston and Watkins , 1999 ) , we employ the one- versus - rest approach .Page 3 .Capital ?( 2 ) Word context : The lexical forms of the two words on both sides of the unknown word .","label":"CompareOrContrast","metadata":{},"score":"47.659073"}{"text":"Support Vec- tor Networks Machine Learning , 20 , pages 273 - 297 .S. Cucerzan and D. Yarowsky .Lan- guage Independent , Minimally Supervised Induction of Lexical Probabilities .Proceedings of the 38th Annual Meet- ing of the Association for Computational Linguistics(ACL-2000 ) , pages 270 - 277 .","label":"CompareOrContrast","metadata":{},"score":"47.68094"}{"text":"This paper describes the architecture of a word and phoneme aligner based on Hidden Markov Models ( HMMs ) .It was developed to allow for word , syllable and segment length extraction as part of a feature extraction stage for prosody recognition .","label":"CompareOrContrast","metadata":{},"score":"47.69191"}{"text":"This paper describes the architecture of a word and phoneme aligner based on Hidden Markov Models ( HMMs ) .It was developed to allow for word , syllable and segment length extraction as part of a feature extraction stage for prosody recognition .","label":"CompareOrContrast","metadata":{},"score":"47.69191"}{"text":"All of them are trained and tested on three corpora of di#erent languages and domains .In the course of this evaluation , synther resulted in the lowest error rates or at least below average error rates .Finally , it is shown that the linear interpolation smoothing strategy with coverage - dependent weights features better properties than the two other approaches . \" ...","label":"CompareOrContrast","metadata":{},"score":"47.702347"}{"text":"The two related issues of priming effects compromising the results and disagreement between human annotators are also addressed . ... ical trigram - based HMM decoder of the kind described in e.g. ( Church 1988 ) , ( DeRose 1988 ) and numerous other articles . \" ...","label":"CompareOrContrast","metadata":{},"score":"47.842827"}{"text":"Tools . by Hans Van Halteren , Jakub Zavrel , Walter Daelemans - Computational Linguistics , 2000 . \" ... this paper , we combine different systems employing known representations .The observation that suggests this approach is that systems that are designed differently , either because they use a different formalism or because they contain different knowledge , will typically produce different errors .","label":"CompareOrContrast","metadata":{},"score":"47.870636"}{"text":"Unfortunately , words are assigned on average a much higher number of Supertags than traditional POS .In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) ... \" .Srinivas ( 97 ) enriches traditional morpho - syntactic POS tagging with syntactic information by introducing Supertags .","label":"CompareOrContrast","metadata":{},"score":"47.996876"}{"text":"Unfortunately , words are assigned on average a much higher number of Supertags than traditional POS .In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) ... \" .Srinivas ( 97 ) enriches traditional morpho - syntactic POS tagging with syntactic information by introducing Supertags .","label":"CompareOrContrast","metadata":{},"score":"47.996895"}{"text":"TAGGIT [ 35 ] was used to generate an initial tagging of the Brown corpus , which was then hand - edited .( Thus it provided the data that has since been used to train other taggers [ 20]. )","label":"CompareOrContrast","metadata":{},"score":"48.230026"}{"text":"In the second pass , POS tagging is performed using the POS tags predicted in the first pass for the succeeding context ( i.e. , using the same features as sec- tion 3 ) .This method has the advantage of handling known and unknown words in the same way .","label":"CompareOrContrast","metadata":{},"score":"48.26333"}{"text":"The algorithms included in this study are Hidden Markov Model , Maximum Entropy , Memory - Based Learning , and Transformation - Based Learni ... \" .The aim of this study is a systematic evaluation and comparison of four state - of - the - art datadriven learning algorithms applied to part of speech tagging of Swedish .","label":"CompareOrContrast","metadata":{},"score":"48.42384"}{"text":"The algorithms included in this study are Hidden Markov Model , Maximum Entropy , Memory - Based Learning , and Transformation - Based Learni ... \" .The aim of this study is a systematic evaluation and comparison of four state - of - the - art datadriven learning algorithms applied to part of speech tagging of Swedish .","label":"CompareOrContrast","metadata":{},"score":"48.42384"}{"text":"It is difficult to train for a large amount of training data , and testing time increases in more complex mod- els .Another point to be improved is the search algorithm for POS tagging .a deterministic method is used as a search algorithm .","label":"CompareOrContrast","metadata":{},"score":"48.534393"}{"text":"The conversion and grammar extraction process imports linguistic generalisations that are missing the in original treebank .This supports the extraction of a linguistically sound grammar with maximal generalisation , as well as grammar induction techniques to capture unseen data in stochastic parsing .","label":"CompareOrContrast","metadata":{},"score":"48.828323"}{"text":"The conversion and grammar extraction process imports linguistic generalisations that are missing the in original treebank .This supports the extraction of a linguistically sound grammar with maximal generalisation , as well as grammar induction techniques to capture unseen data in stochastic parsing .","label":"CompareOrContrast","metadata":{},"score":"48.828323"}{"text":"We show that the two approaches are closely related , and we argue that feature weighting methods in the Memory - Based paradigm can offer the ... \" .This paper analyses the relation between the use of similarity in Memory - Based Learning and the notion of backed - off smoothing in statistical language modeling .","label":"CompareOrContrast","metadata":{},"score":"48.85293"}{"text":"Here 13.000 nouns or adjective tokens are previously unseen cases .Tested on these unknown words , our method achieves an accuracy of 81 % on the lemmatisation task .Tools . by Hans Van Halteren , Jakub Zavrel , Walter Daelemans - Computational Linguistics , 2000 . \" ... this paper , we combine different systems employing known representations .","label":"CompareOrContrast","metadata":{},"score":"48.903812"}{"text":"We extract different LTAGs from the Penn Treebank .We show that certain strategies yield an improved extracted LTAG in terms of compactness , broad coverage , and supertagging accuracy .Furthermore , we perform a preliminary investigation in smoothing these grammars by means of an external linguistic resource , namely , the tree families of an XTAG grammar , a hand built grammar of English . by Hans Van Halteren , Jakub Zavrel , Walter Daelemans - Computational Linguistics , 2000 . \" ... this paper , we combine different systems employing known representations .","label":"CompareOrContrast","metadata":{},"score":"49.02262"}{"text":"We extract different LTAGs from the Penn Treebank .We show that certain strategies yield an improved extracted LTAG in terms of compactness , broad coverage , and supertagging accuracy .Furthermore , we perform a preliminary investigation in smoothing these grammars by means of an external linguistic resource , namely , the tree families of an XTAG grammar , a hand built grammar of English . by Hans Van Halteren , Jakub Zavrel , Walter Daelemans - Computational Linguistics , 2000 . \" ... this paper , we combine different systems employing known representations .","label":"CompareOrContrast","metadata":{},"score":"49.02262"}{"text":"Each of the methods makes a priori assumptions , which Many of these arc important stand - alone problems it employs , given the data , when searching for its hy- but even more important is thei role in many applicapothesis .","label":"CompareOrContrast","metadata":{},"score":"49.466805"}{"text":"Th ...What is Maximum Entropy Modeling .In his famous 1957 paper , Ed .T. Jaynes wrote : Information theory provides a constructive criterion for setting up probability distributions on the basis of partial knowledge , and leads to a type of statistical inference which is called the maximum entropy estimate .","label":"CompareOrContrast","metadata":{},"score":"49.583153"}{"text":"Presented are the details of the manually corrected test corpus and an analysis of the tagging errors .The paper also discusses a simple transformation - based program that fixes some of the more common errors , and concludes with some directions for future work .","label":"CompareOrContrast","metadata":{},"score":"49.609283"}{"text":"Presented are the details of the manually corrected test corpus and an analysis of the tagging errors .The paper also discusses a simple transformation - based program that fixes some of the more common errors , and concludes with some directions for future work .","label":"CompareOrContrast","metadata":{},"score":"49.609283"}{"text":"The general approach as well as the application to POS tagging has been proposed by Brill [ 1993].Example - based tagger ET : Example - based models ( also called memory - based , instance - based or distance - based ) rest on the assumption that cognitive behavior can be achieved by looking at past experiences that resemble the current problem rather than learning and applying abstract rules .","label":"CompareOrContrast","metadata":{},"score":"49.82672"}{"text":"this paper , we combine different systems employing known representations .The observation that suggests this approach is that systems that are designed differently , either because they use a different formalism or because they contain different knowledge , will typically produce different errors .","label":"CompareOrContrast","metadata":{},"score":"49.981335"}{"text":"The performance at the different degree of polynomial kernel is shown in Table 6 .The best degree seems to be 1 or 2 for this task , and the best degree tends to increase when the training data increases .5.2 The accuracies of POS tagging are shown in Table 7 .","label":"CompareOrContrast","metadata":{},"score":"50.28082"}{"text":"Such unknown words are usually handled by an exceptional process- ing , because the statistical information or rules for those words are unknown .methods have good performance , the accu- racy for unknown words is much lower than that for known words , and this is a non-","label":"CompareOrContrast","metadata":{},"score":"50.34208"}{"text":"Trigram Tagger ( T3 ) : This kind of tagger is based on Hidden Markov Models where the states are tag pairs that emit words , i.e. , it is based on transitional and lexical probabilities .The technique has been suggested by Rabiner [ 1990 ] and the implementation is influenced by Brants [ 2000].","label":"CompareOrContrast","metadata":{},"score":"50.342377"}{"text":"On the other hand , the words themselves have much less contribution while the POS con- text have moderate contribution to the final accuracy .In general , features that rarely appear in the training data are statistically unreliable , and often decrease the performance of the sys- tem .","label":"CompareOrContrast","metadata":{},"score":"50.402546"}{"text":"2009 ) , has issues when used directly for the task of native language detection ( NLD ) .The topic biases in the corpus are a confounding factor that results in ... \" .We begin by showing that the best publicly available , multiple - L1 learner corpus , the International Corpus of Learner English ( Granger et al .","label":"CompareOrContrast","metadata":{},"score":"50.540367"}{"text":"The paper will describe a robust tagging scenario for Hungarian using a relatively simple stochastic system augmented with external morphological processing , which can overcome the two most conspcicuous problems : the complexity of morphosyntactic descriptions and most importantly the huge number of possible wordforms . by David Undermann And , David Sündermann , Hermann Ney - In Proc .","label":"CompareOrContrast","metadata":{},"score":"50.546013"}{"text":"ua.ac.be ( ) 2000 Association for Computational Linguistics We use a number of different learning algorithms simultaneously on the same training corpus .Each type of learning method brings its own ' inductive bias ' to the task and will produce a classifier with slightly different characteristics , so that different methods will tend to produce different errors . by Christer Samuelsson , Atro Voutilainen - Proceedings of the Thirty - Fifth Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics , 1997 . \" ...","label":"CompareOrContrast","metadata":{},"score":"50.58075"}{"text":"This method can be extended to more general POS tagging by predicting the POS tags of all words in a given sentence .Differing from unknown word guessing as a post - processing of POS tagging , the POS tags for succeed- ing words are usually not known during POS tagging .","label":"CompareOrContrast","metadata":{},"score":"50.595684"}{"text":"We performed some of ... . \" ...In this paper we examine the question of query parsing for World Wide Web queries and present a novel method for phrase recognition and expansion .Given a training corpus of approximately 16 million Web queries and a handwritten context - free grammar , the EM algorithm is used to estimate the paramete ... \" .","label":"CompareOrContrast","metadata":{},"score":"50.65389"}{"text":"Since then , Maximum Entropy technique ( and the more general framework Random Fields ) has enjoyed intensive research in NLP community .YASMET --Yet Another Simple Maximum Entropy Toolkit with Feature Selection .YASMET(2 ) --Yet Another Small MaxEnt Toolkit .","label":"CompareOrContrast","metadata":{},"score":"50.66029"}{"text":"Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .We believe that is largely in part due to the absence of large corpora accurately bracketed in terms of a perspicuous yet broad coverage LTAG .","label":"CompareOrContrast","metadata":{},"score":"50.78694"}{"text":"We hope to make use of this fact and reduce the number of errors with very little additional effort by exploiting the disagreement between different language models .Al- though the approach is applicable to any type of language model , we focus on the case of statistical disambiguators that are trained on annotated corpora .","label":"CompareOrContrast","metadata":{},"score":"50.861744"}{"text":"Lawrence R. Rabiner .A tutorial on hidden markov models and selected applications in speech recognition .In Alex Waibel & Kai - Fu Lee , ed . , Readings in Speech Recognition .Morgan Kaufmann , San Mateo , CA , USA , pages 267 - 290 .","label":"CompareOrContrast","metadata":{},"score":"50.887238"}{"text":"Each type of learning method brings its own ' inductive bias ' to the task and will produce a classifier with slightly different characteristics , so that different methods will tend to produce different errors . ... eras , 1999 ) for combining ensembles of neural networks .","label":"CompareOrContrast","metadata":{},"score":"50.950916"}{"text":"Each type of learning method brings its own ' inductive bias ' to the task and will produce a classifier with slightly different characteristics , so that different methods will tend to produce different errors . ... eras , 1999 ) for combining ensembles of neural networks .","label":"CompareOrContrast","metadata":{},"score":"50.950916"}{"text":"Another must read paper on maxent .It deals with a more general frame work : Random Fields and proposes an Improved Iterative Scaling algorithm for estimating parameters of Random Fields .This paper gives theoretical background to Random Fields ( and hence Maxent model ) .","label":"CompareOrContrast","metadata":{},"score":"51.21846"}{"text":"In Proceedings of V. Vapnik .The Nature of Statistical Learning Theory .Springer .R. Weischedel , M. Meteer , R. Schwartz , L. Ramshaw and J. Palmucci .Cop- ing with Ambiguity and Unknown Words through Probabilistic Models . tional Linguistics , 19(2 ) , pages 359 - 382 . Computa-","label":"CompareOrContrast","metadata":{},"score":"51.336906"}{"text":"Cucerzan and Yarowsky proposed paradigmatic similarity measures and showed a good result for highly inflectional languages using a large amount of unannotated text ( Cucerzan and Yarowsky , 2000 ) .Other methods for unknown word guessing have been studied , such as the Brants used the lin-","label":"CompareOrContrast","metadata":{},"score":"51.448368"}{"text":"SVM classifiers are created for each POS tag using all words in the training set , then POS tags to unknown words predict using those classifiers . \" In this context , dealing with unknown words ( words do not appear in the lexicon referred as unknown words ) is also an important task , since growing NLP systems are used in more and more new applications .","label":"CompareOrContrast","metadata":{},"score":"51.52794"}{"text":"They used that POS tag for the succeeding words .They report that about 2 % of accuracy decrease is caused by incorrectly attached POS tags by their method .We use a similar two pass method without using a dictionary .","label":"CompareOrContrast","metadata":{},"score":"51.67844"}{"text":"Trigram Tagger T3 : This kind of tagger is based on Hidden Markov Models ( HMM ) where the states are tag pairs that emit words , i. e. , it 's based on transitional and lexical probabilities .The technique has been suggested by Rabiner [ 1990 ] and the implementation is influenced by Brants [ 2000].","label":"CompareOrContrast","metadata":{},"score":"51.74783"}{"text":"ox.ac.uk/ ) , WackyPedia and ukWaC ( http : //wacky.sslmit.unibo.it/ ) .We process the corpus in two steps to compute semantic vectors representing our phrases of interest .We ...Tools . by Dan Roth - In Proceedings of the National Conference on Artificial Intelligence .","label":"CompareOrContrast","metadata":{},"score":"51.846306"}{"text":"The systems are evaluated from several aspects .Both the eects of tag set and the eects of the size of training data are examined .The accuracy is calculated as well as the error rate for known and unknown tokens .","label":"CompareOrContrast","metadata":{},"score":"51.946644"}{"text":"The systems are evaluated from several aspects .Both the eects of tag set and the eects of the size of training data are examined .The accuracy is calculated as well as the error rate for known and unknown tokens .","label":"CompareOrContrast","metadata":{},"score":"51.946644"}{"text":"The distinction between open class words and closed class words together with syntactical features of the language used in this research to predict lexical categories of unknown words in the tagging process .An experiment is performed to investigate the ability of the approach to parse unknown words using syntactical knowledge without human intervention .","label":"CompareOrContrast","metadata":{},"score":"51.95794"}{"text":"Comparison with other machine learning technique ( Naive Bayes , Transform Based Learning , Decision Tree etc . ) was given .Ratnaparkhi also had a short introduction paper on ME .Abney applies Improved Iterative Scaling algorithm to parameters estimation of Attribute - Value grammars , which can not be corrected calculated by ERF method ( though it works on PCFG ) .","label":"CompareOrContrast","metadata":{},"score":"52.045624"}{"text":"The POS tags for following words are obtained from a two - pass approach proposed by Nakagawa et al .[ 23].[ Show abstract ] [ Hide abstract ] ABSTRACT : All types of part - of - speech ( POS ) tagging errors have been equally treated by existing taggers .","label":"CompareOrContrast","metadata":{},"score":"52.740616"}{"text":"Brill tagger , and the Multext tagger [ 8]. 1 Moreover , taggers have now been developed for a number of different languages .Dermatas and Kokkinakis [ 24 ] compare taggers for seven different languages .The Multext project [ 8 ] is currentl ... . by Stefan Evert , Brigitte Krenn - In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics , 2001 . \" ...","label":"CompareOrContrast","metadata":{},"score":"52.74234"}{"text":"This article introduces the problem of partial or shallow parsing ( assigning partial syntactic structure to sentences ) and explains why it is an important natural language processing ( NLP ) task .The complexity of the task makes Machine Learning an attractive option in comparison to the handcrafting of rules .","label":"CompareOrContrast","metadata":{},"score":"52.99797"}{"text":"This article introduces the problem of partial or shallow parsing ( assigning partial syntactic structure to sentences ) and explains why it is an important natural language processing ( NLP ) task .The complexity of the task makes Machine Learning an attractive option in comparison to the handcrafting of rules .","label":"CompareOrContrast","metadata":{},"score":"52.99797"}{"text":"However , for languages like Japanese and Chinese , it is difficult to apply our meth- ods straightforwardly because words are not separated by spaces in those languages .One problem of our methods is computa- tional cost .It took about 16.5 hours for training with 100,000 tokens and 4 hours for testing with 285,000 tokens in POS tagging using POS tags on both sides on an Alpha 21164A 500MHz processor .","label":"CompareOrContrast","metadata":{},"score":"53.152565"}{"text":"Partial parsing techniques , like tagging techniques , aim for reliability and robustness in the face of t ... \" .m we can carve o # next . 'Partial parsing ' is a cover term for a range of di#erent techniques for recovering some but not all of the information contained in a traditional syntactic analysis .","label":"CompareOrContrast","metadata":{},"score":"53.43295"}{"text":"ACOPOST currently consists of four taggers which are based on different frameworks : .Maximum Entropy Tagger MET : This tagger uses an iterative procedure to successively improve parameters for a set of features that help to distinguish between relevant contexts .","label":"CompareOrContrast","metadata":{},"score":"53.728188"}{"text":"A small post - hoc analysis further suggests that , when the model - generated AN vector is not similar to the corpus - observed AN vector , this is due to anomalies in the latter .We show moreover that our approach provides two novel ways to represent adjective meanings , alternative to its representation via corpus - based co - occurrence vectors , both outperforming the latter in an adjective clustering task .","label":"CompareOrContrast","metadata":{},"score":"53.881924"}{"text":"An word morphology application for English was developed . longer version .This paper applies ME technique to statistical language modeling task .More specifically , it builds a conditional Maximum Entropy model that incorporates traditional N - gram , distant N - gram and trigger pair features .","label":"CompareOrContrast","metadata":{},"score":"53.89572"}{"text":"RankBoost ( Freund et al ., 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs ... \" .this paper , we investigate an approach to such a choice based on reranking a set of candidate supertags and their confidence scores .","label":"CompareOrContrast","metadata":{},"score":"54.38177"}{"text":"RankBoost ( Freund et al ., 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs ... \" .this paper , we investigate an approach to such a choice based on reranking a set of candidate supertags and their confidence scores .","label":"CompareOrContrast","metadata":{},"score":"54.381783"}{"text":"In this article the three modules text preprocessing , prosody generation and acoustic synthesis are described .The results we achieved in the second evaluation are investigated .epending on the training data coverage as suggested in ( Sündermann and Ney , 2003 ) .","label":"CompareOrContrast","metadata":{},"score":"54.43068"}{"text":"The contribution of each feature has the same tendency as the case of the unknown word guessing in section 5.1 .The biggest difference of features be- tween our method and the TnT is the use of word context .Although using a lot of features such as word context is difficult in Markov model , it is easy in SVMs as seen in section 5.1 .","label":"CompareOrContrast","metadata":{},"score":"54.675056"}{"text":"The topic biases in the corpus are a confounding factor that results in cross - validated performance that appears misleadingly high , for all the feature types which are traditionally used .Our approach here is to look for other , cheap ways to get training data for NLD .","label":"CompareOrContrast","metadata":{},"score":"54.684616"}{"text":"The observation that suggests this approach is that systems that are designed differently , either because they use a different formalism or because they contain different knowledge , will typically produce different errors .We ... \" .this paper , we combine different systems employing known representations .","label":"CompareOrContrast","metadata":{},"score":"54.87223"}{"text":"The ex- periments show that for the same amount of remainin ... \" .Concerning different approaches to automatic PoS tagging : EngCG-2 , a constraintbased morphological tagger , is compared in a double - blind test with a state - of - the - art statistical tagger on a common disambiguation task using a common tag set .","label":"CompareOrContrast","metadata":{},"score":"54.97394"}{"text":"This also seems to facilitate the use of lexical features , which have been previously avoided .We also investigate ways to do NLD that do not involve having learner corpora at all , including double - translation and extracting information from L1 corpora directly .","label":"CompareOrContrast","metadata":{},"score":"55.27471"}{"text":"News .Current status ( 2012 - 11 - 22 ) .The version patched for 64-bit systems is ready in Git .The bugs in t3 and met related to large and/or noisy lexicons seem to have been fixed .","label":"CompareOrContrast","metadata":{},"score":"55.290375"}{"text":"In our pilot study , we have established the basic requirements with respect to text types , metadata , and annotation levels that CoDAS should fulfill .In this respect , we have investigated whether and how the procedures and protocols for . ... word suffixes .","label":"CompareOrContrast","metadata":{},"score":"55.37514"}{"text":"Differing provisions from the publisher 's actual policy or licence agreement may be applicable .\" Scott M. Thede and Mary Harper [ 5 ] in their paper presented an approach using morphology and syntactic parsing rules in post - mortem method for determining the probable lexical classes of words .","label":"CompareOrContrast","metadata":{},"score":"55.52137"}{"text":"Whole Sentence Language Model ) with sampling based training .Now seems to be part of scipy .Stanford Classifer is another open source implementation of Maximum Entropy Model in java , suitable for NLP tagging and parsing tasks .NLTK includes a maxent classifier written entirely in Python .","label":"CompareOrContrast","metadata":{},"score":"55.8538"}{"text":"Each type of learning method brings its own ' inductive bias ' to the task and will produce a classifier with slightly different characteristics , so that different methods will tend to produce different errors . \" ...This article introduces the problem of partial or shallow parsing ( assigning partial syntactic structure to sentences ) and explains why it is an important natural language processing ( NLP ) task .","label":"CompareOrContrast","metadata":{},"score":"55.975063"}{"text":"Each type of learning method brings its own ' inductive bias ' to the task and will produce a classifier with slightly different characteristics , so that different methods will tend to produce different errors . \" ...This article introduces the problem of partial or shallow parsing ( assigning partial syntactic structure to sentences ) and explains why it is an important natural language processing ( NLP ) task .","label":"CompareOrContrast","metadata":{},"score":"55.975063"}{"text":"We sketch the origins of shallow parsing as a specific task for machine learning of language , and introduce the articles accepted for this special issue , a representative sample of current research in this area .Finally , future directions for machine learning of shallow parsing are suggested . \" ...","label":"CompareOrContrast","metadata":{},"score":"56.07603"}{"text":"We sketch the origins of shallow parsing as a specific task for machine learning of language , and introduce the articles accepted for this special issue , a representative sample of current research in this area .Finally , future directions for machine learning of shallow parsing are suggested . \" ...","label":"CompareOrContrast","metadata":{},"score":"56.07603"}{"text":"..We just list two of them which seem to be most relevant : C4 uses a reduced tagset while C3 uses the PTB tagset . 9 Instead , we re - ran 8 All use Section 2 - 21 of the PTB for training , and Section 22 or 23 for testing .","label":"CompareOrContrast","metadata":{},"score":"56.321884"}{"text":"..We just list two of them which seem to be most relevant : C4 uses a reduced tagset while C3 uses the PTB tagset . 9 Instead , we re - ran 8 All use Section 2 - 21 of the PTB for training , and Section 22 or 23 for testing .","label":"CompareOrContrast","metadata":{},"score":"56.321884"}{"text":"Adwait Ratnaparkhi .Maximum Entropy Models for Natural Language Ambiguity Resolution .Ph.D. thesis , University of Pennsylvania .Tools . \" ... Trigrams'n'Tags ( TnT ) is an efficient statistical part - of - speech tagger .Contrary to claims found elsewhere in the literature , we argue that a tagger based on Markov models performs at least as well as other current approaches , including the Maximum Entropy framework .","label":"CompareOrContrast","metadata":{},"score":"56.325817"}{"text":"information extraction and intelligent human - machine We use this to build an argument for a data driven interaction .Most of the ambiguity resolution problems approach which merely searches for a good linear sepa- are at the lower level of the natural language inferences rator in the feature space , without further assumptions chain ; a wide range and a large number of ambigui- . ... estimates measured on the training data , and the coefficients ) , ! are also estimated given the training data .","label":"CompareOrContrast","metadata":{},"score":"56.501144"}{"text":"Given a training corpus of approximately 16 million Web queries and a handwritten context - free grammar , the EM algorithm is used to estimate the parameters of a probabilistic context - free grammar ( PCFG ) with a system developed by Carroll [ 5].","label":"CompareOrContrast","metadata":{},"score":"56.53018"}{"text":"Here 's an English example of a tagged sentence taken from the Wall Street Journal of the Penn Treebank : . than .IN . the .DT . overall .JJ . measures .NNS . . . . .ACOPOST is a set of freely available POS taggers modeled after well - known techniques .","label":"CompareOrContrast","metadata":{},"score":"56.72824"}{"text":"( 3 ) ( 4 )y For linearly non - separable cases , feature vectors are mapped into a higher dimensional space by a nonlinear function Φ(x ) and lin- early separated there . since all data points appear as a form of in- ner product , we only need the inner product of two points in the higher dimensional space .","label":"CompareOrContrast","metadata":{},"score":"56.728577"}{"text":"We report two applications of this approach : PP - attachment and POS - tagging .Our method achieves state - of - the - art performance in both domains , and allows the easy integration of diverse information sources , such as rich lexical representations . .","label":"CompareOrContrast","metadata":{},"score":"56.81234"}{"text":"We ... \" .this paper , we combine different systems employing known representations .The observation that suggests this approach is that systems that are designed differently , either because they use a different formalism or because they contain different knowledge , will typically produce different errors .","label":"CompareOrContrast","metadata":{},"score":"57.167446"}{"text":"We ... \" .this paper , we combine different systems employing known representations .The observation that suggests this approach is that systems that are designed differently , either because they use a different formalism or because they contain different knowledge , will typically produce different errors .","label":"CompareOrContrast","metadata":{},"score":"57.167446"}{"text":"We ... \" .this paper , we combine different systems employing known representations .The observation that suggests this approach is that systems that are designed differently , either because they use a different formalism or because they contain different knowledge , will typically produce different errors .","label":"CompareOrContrast","metadata":{},"score":"57.167446"}{"text":"Part In Proceedings of H. Schmid . of - Speech Tagging Using Decision Trees .In Proceedings of the International Con- ference on New Methods in Language Processing(NeMLaP-1 ) , pages 44 - 49 .Probabilistic Part- S. Thede .Predicting Part - of - Speech Information about Unknown Words using Statistical Methods .","label":"CompareOrContrast","metadata":{},"score":"57.2863"}{"text":"5 Evaluation Experiments for unknown word guessing and POS tagging are performed using the Penn Treebank WSJ corpus having 50 POS tags .Four training data sets were constructed by randomly selecting approximately 1,000 , 10,000 , 100,000 and 1,000,000 tokens .","label":"CompareOrContrast","metadata":{},"score":"57.295174"}{"text":"We show how a Supertagger can be used to drastically reduce the syntactic lexical ambiguity for a given input and can be used in combination with an LTAG parser to radically improve parsing efficiency .We then turn our attention to from parsing efficiency to parsing accuracy and provide a method by which we can effectively combine the output of a Supertagger and a statistical LTAG parser using a co - training algorithm for bootstrapping new labeled data .","label":"CompareOrContrast","metadata":{},"score":"57.30716"}{"text":"We show how a Supertagger can be used to drastically reduce the syntactic lexical ambiguity for a given input and can be used in combination with an LTAG parser to radically improve parsing efficiency .We then turn our attention to from parsing efficiency to parsing accuracy and provide a method by which we can effectively combine the output of a Supertagger and a statistical LTAG parser using a co - training algorithm for bootstrapping new labeled data .","label":"CompareOrContrast","metadata":{},"score":"57.30717"}{"text":"Well , it 's time to have a look at this one .Edwin Thompson Jaynes presented some insightful results of maximum entropy principle in this 1957 paper published in Physics Reviews .This is also his first paper in information theory .","label":"CompareOrContrast","metadata":{},"score":"57.386227"}{"text":"You need GCC 2.9x to compile the source .link2 .MEGA Model Optimization Package .A recently appeared ME implementation by Hal Daumé III .The software features CG and LM - BFGS Optimization and is written in OCaml .Although I no longer use OCaml , I 'd say that 's a great language , and is worth learning .","label":"CompareOrContrast","metadata":{},"score":"57.622986"}{"text":"We analyze a few of the commonly used statistics based The surrounding context- word associations and syn - and machine learning algorithms for natural language tactic patterns in this case- are suffl ... \" . distinct semanticonceptsuch as interest rate and has interest in Math are conflated in ordinary text .","label":"CompareOrContrast","metadata":{},"score":"57.794144"}{"text":"For unknown words , all possible POS tags are taken as the candidates .This method requires no exceptional pro- cessings to handle unknown words .Page 4 .Same features as shown in Table 1 are used .In general , the POS tags of the succeed- ing words are unknown .","label":"CompareOrContrast","metadata":{},"score":"57.81127"}{"text":"ACOPOST currently consists of four taggers which are based on different frameworks : .Maximum Entropy Tagger ( MET ) : This tagger uses an iterative procedure to successively improve parameters for a set of features that help to distinguish between relevant contexts .","label":"CompareOrContrast","metadata":{},"score":"57.90702"}{"text":"Once the models have been training , the taggers can be used .The corpora to be tagged must be in the same one line per sentence format , with tokens ( including punctuation marks ) separated by one or more whice spaces .","label":"CompareOrContrast","metadata":{},"score":"57.91839"}{"text":"Assuming that the corpus to be tagged is stored in file \" corpus \" : .Resouces .I have developed a set of resource files for testing ACOPOST , based on a small ( about 100,000 tokens ) corpus for Brazilian Portugues developed by the Núcleo Interinstitucional de Lingüística Computacional ( NILC ) of the University of São Paulo ( link ) .","label":"CompareOrContrast","metadata":{},"score":"58.19503"}{"text":"G. Orphanos and D. Christodoulakis .POS Disambiguation and Unknown Word Guessing with Decision Trees .In Proceed- ings of the Ninth Conference of the Euro- pean Chapter of the Association for Com- putationalLinguistics(EACL-99 ) , 134 - 141 .pages J. Platt .","label":"CompareOrContrast","metadata":{},"score":"58.24769"}{"text":"In this paper we propose to use supertags to expose syntactic dependencies which are unavailable with POS tags .We first propose a novel method of app ... \" .Supertagging is the tagging process of assigning the correct elementary tree of LTAG , or the correct supertag , to each word of an input sentence .","label":"CompareOrContrast","metadata":{},"score":"58.296043"}{"text":"In this paper we propose to use supertags to expose syntactic dependencies which are unavailable with POS tags .We first propose a novel method of app ... \" .Supertagging is the tagging process of assigning the correct elementary tree of LTAG , or the correct supertag , to each word of an input sentence .","label":"CompareOrContrast","metadata":{},"score":"58.296043"}{"text":"The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .We believe that is largely in part due to the absence of large corpora accurately bracketed in terms of a perspicuous yet broad coverage LTAG .","label":"CompareOrContrast","metadata":{},"score":"58.49205"}{"text":"The general approach as well as the application to POS tagging has been proposed by Brill [ 1993].Example - based tagger ( ET ) : Example - based models ( also called memory - based , instance - based or distance - based ) rest on the assumption that cognitive behavior can be achieved by looking at past experiences that resemble the current problem rather that learning and applying abstract rules .","label":"CompareOrContrast","metadata":{},"score":"58.744637"}{"text":"Trigrams'n'Tags ( TnT ) is an efficient statistical part - of - speech tagger .Contrary to claims found elsewhere in the literature , we argue that a tagger based on Markov models performs at least as well as other current approaches , including the Maximum Entropy framework .","label":"CompareOrContrast","metadata":{},"score":"58.857426"}{"text":"Support Vector Machines for Multi - Class Pattern Recognition .In Proceedings of the Seventh European Symposium On Artificial Neural Networks(ESANN-99 ) .Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .","label":"CompareOrContrast","metadata":{},"score":"59.296097"}{"text":".. sister adjunction can be used to create parse trees for all input strings , with only a slight penalty in accuracy .The results are graphed in Figure 14 .They use a different set of Supertags and so we used their result simply to get an approxima ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"59.640602"}{"text":".. sister adjunction can be used to create parse trees for all input strings , with only a slight penalty in accuracy .The results are graphed in Figure 14 .They use a different set of Supertags and so we used their result simply to get an approxima ... . \" ...","label":"CompareOrContrast","metadata":{},"score":"59.640614"}{"text":"Suitable for text categorization and related NLP tasks .Here is another small maxent package in C++ with a BSD - like license , written by Dekang Lin .A must read paper on applying maxent technique to Natural Language Processing .","label":"CompareOrContrast","metadata":{},"score":"59.685944"}{"text":"Morphosyntactic Tagging of Slovene : Evaluating Taggers and Tagsets .Proceedings of the Second International Conference on Language Resources and Evaluation(LREC-2000 ) , pages 1099 - 1104 .T. Erjavec and J. Zavrel .In T. Joachims .Text Categorization with Support Vector Machines : Learning with Many Relevant Features .","label":"CompareOrContrast","metadata":{},"score":"60.00998"}{"text":"Although lexical amb ...Tools . \" ...The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .","label":"CompareOrContrast","metadata":{},"score":"60.055267"}{"text":".. lexicon and the parser accomplish verbal processing .A possibly required process step is stemming , removal of morphological inflection , of the text events whose sophistication varies with the language used .Second , a lexicon lookup is done for the res ... . by Julian Brooke , Graeme Hirst - In : Proceedings of the 2011 Conference on Learner Corpus Research ( LCR2011 ) ( 2011 . \" ...","label":"CompareOrContrast","metadata":{},"score":"60.471638"}{"text":"Grammars are core elements of many NLP applications .In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the cove ... \" .","label":"CompareOrContrast","metadata":{},"score":"60.6446"}{"text":"Grammars are core elements of many NLP applications .In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the cove ... \" .","label":"CompareOrContrast","metadata":{},"score":"60.6446"}{"text":"Part - of - Speech Tagging 6 Conclusion and Future Work In this paper , we applied SVMs to unknown word guessing and showed that they per- form quite well using context and substring information .Furthermore , extending the method to POS tagging , the resulting tag- ger achieves higher accuracy than the state- of - the - art HMM - based tagger . to other machine learning algorithms , SVMs have the advantage of considering the com- binations of features automatically by intro- ducing a kernel function and seldom over - fit Comparing with a large set of features .","label":"CompareOrContrast","metadata":{},"score":"61.017284"}{"text":"Here 13.000 nouns or adjective tokens are previously unseen cases .Tested on these unknown words , our method achieves an accuracy of 81 % on the lemmatisation task .This page hosts my upgrades to ACOPOST ( for \" A COllection of Part - Of - Speech Taggers ) , a set of taggers developed by Ingo Schröder .","label":"CompareOrContrast","metadata":{},"score":"61.024925"}{"text":"One known approach for unknown word guessing is to use suffixes or surrounding context of unknown words ( Thede , 1998 ) .ear interpolation of fixed length suffix model for unknown word handling in his part - of- speech tagger TnT ( Brants , 2000 ) .","label":"CompareOrContrast","metadata":{},"score":"61.222477"}{"text":"5.1Unknown Word Guessing The accuracy of the unknown word guessing is shown in Table 3 together with the degree of polynomial kernel used for the experiments .Our method has higher accuracy compared to TnT for every training data set .Accuracies with various settings are shown in Table 4 .","label":"CompareOrContrast","metadata":{},"score":"61.378883"}{"text":"You will probably want to perform the training in the background , redirecting its output : .To generate an example - based model , you need to specify features to be known , unknown and tags to be excluded ( example files are given in the resources ) .","label":"CompareOrContrast","metadata":{},"score":"61.44854"}{"text":"Our online models build character - level PAT trie structures on the fly using heavily data - unfolded implementations of an mutable daughter maps with a long intege ... \" .We describe the implementation steps required to scale high - order character language models to gigabytes of training data without pruning .","label":"CompareOrContrast","metadata":{},"score":"61.508865"}{"text":"Terminal nodes are shared .Character 8-gram training runs at 200,000 characters per second and allows online tuning of hyperparameters .Our compiled models precompute all probability estimates for observed n - grams and all interpolation parameters , along with suffix pointers to speedup context computations from proportional to n - gram length to a constant .","label":"CompareOrContrast","metadata":{},"score":"61.552567"}{"text":".. grams , and POS n - grams ; we also include word n - grams , which have mostly been avoided .Here n - grams include unigrams ( single elements ) and bigrams ( pairs of elements ) .Our input to the machine classifier consists of the normalized ( to 1,000 words ) frequency of these elements in the texts .","label":"CompareOrContrast","metadata":{},"score":"62.327625"}{"text":"From the second to fourth columns , some features are deleted so as to see the contribution of the features to the accuracy .The decrease of accuracy caused by the errors in POS tagging by TnT is about 1 % .","label":"CompareOrContrast","metadata":{},"score":"62.41059"}{"text":"Named entity tagging of English and German training , development , and test data , was done by hand at the University of Antwerp .Mostly , MUC conventions were followed ( Chinchor et al . , 1999 ) .An ext .. \" ... m we can carve o # next . '","label":"CompareOrContrast","metadata":{},"score":"63.52395"}{"text":"The paper discusses a machine learning approach to the automatic lemmatisation of unknown words , in particular nouns and adjectives , in Slovene texts .We decompose the problem of learning to perform lemmatisation into two subproblems : the first is to learn to perform morphosyntactic tagging , and the second is to learn to perform morphological analysis , which produces the lemma from the word form given the correct morphosyntactic tag .","label":"CompareOrContrast","metadata":{},"score":"63.64161"}{"text":"The paper discusses a machine learning approach to the automatic lemmatisation of unknown words , in particular nouns and adjectives , in Slovene texts .We decompose the problem of learning to perform lemmatisation into two subproblems : the first is to learn to perform morphosyntactic tagging , and the second is to learn to perform morphological analysis , which produces the lemma from the word form given the correct morphosyntactic tag .","label":"CompareOrContrast","metadata":{},"score":"63.64161"}{"text":"The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .We believe that is largely in part due to the absence of large cor ... \" .","label":"CompareOrContrast","metadata":{},"score":"63.673473"}{"text":"This paper discusses a machine learning approach to the automatic lemmatization of unknown words in Slovene texts .We decompose the problem of learning to perform lemmatization into two subproblems : learning to perform morphosyntactic tagging of words in a text , and learning to perform morphological analysis , which produces the lemma from the word - form given the correct morphosyntactic tag .","label":"CompareOrContrast","metadata":{},"score":"63.93462"}{"text":"This paper discusses a machine learning approach to the automatic lemmatization of unknown words in Slovene texts .We decompose the problem of learning to perform lemmatization into two subproblems : learning to perform morphosyntactic tagging of words in a text , and learning to perform morphological analysis , which produces the lemma from the word - form given the correct morphosyntactic tag .","label":"CompareOrContrast","metadata":{},"score":"63.93462"}{"text":"We describe the basic model of TnT , the techniques used for smoothing and for handling unknown words .Furthermore , we present evaluations on two corpora . ... ished .They are only surpassed by combinations of different systems , fo ... . ... hared task .","label":"CompareOrContrast","metadata":{},"score":"64.38343"}{"text":"We first propose a novel method of applying Sparse Network of Winnow ( SNoW ) to sequential models .Then we use . \" ...In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .","label":"CompareOrContrast","metadata":{},"score":"64.41844"}{"text":"We first propose a novel method of applying Sparse Network of Winnow ( SNoW ) to sequential models .Then we use . \" ...In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .","label":"CompareOrContrast","metadata":{},"score":"64.41844"}{"text":"We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .","label":"CompareOrContrast","metadata":{},"score":"64.912384"}{"text":"We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .","label":"CompareOrContrast","metadata":{},"score":"64.912384"}{"text":"We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .","label":"CompareOrContrast","metadata":{},"score":"64.912384"}{"text":"We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .","label":"CompareOrContrast","metadata":{},"score":"64.912384"}{"text":"Introduction As a first step prior to parsing , traditional Part of Speech ( POS ) tagging assigns limited morpho - syntactic information to lexical items .These labels can be more or less fine - grained depending on the tagset , but syntactic information is often absent or limited .","label":"CompareOrContrast","metadata":{},"score":"65.059845"}{"text":"Introduction As a first step prior to parsing , traditional Part of Speech ( POS ) tagging assigns limited morpho - syntactic information to lexical items .These labels can be more or less fine - grained depending on the tagset , but syntactic information is often absent or limited .","label":"CompareOrContrast","metadata":{},"score":"65.059875"}{"text":"In our approach , we compare the entire list of candidates , sorted accor ... \" .This paper presents methods for a qualitative , unbiased comparison of lexical association measures and the results we have obtained for adjective - noun pairs and preposition - noun - verb triples extracted from German corpora .","label":"CompareOrContrast","metadata":{},"score":"65.21243"}{"text":"We propose an approach to adjective - noun composition ( AN ) for corpus - based distributional semantics that , building on insights from theoretical linguistics , represents nouns as vectors and adjectives as data - induced ( linear ) functions ( encoded as matrices ) over nominal vectors .","label":"CompareOrContrast","metadata":{},"score":"65.2676"}{"text":"We propose an approach to adjective - noun composition ( AN ) for corpus - based distributional semantics that , building on insights from theoretical linguistics , represents nouns as vectors and adjectives as data - induced ( linear ) functions ( encoded as matrices ) over nominal vectors .","label":"CompareOrContrast","metadata":{},"score":"65.2676"}{"text":"( as version 1.8.4 was probably written for gcc-2.95 , it was issuing some warnings ) .The latest version is 1.8.6-tresoldi , which compiles silently in gcc version 4.1 with both the -Wall and the -ansi options .It also compiles ( even though with some warning being issued ) with -Wall -ansi -pedantic .","label":"CompareOrContrast","metadata":{},"score":"65.31598"}{"text":"In this paper , the Part - Of - Speech ( POS ) tagger synther based on m - gram statistics is described .After explaining its basic architecture , three smoothing approaches and the strategy for handling unknown words is exposed .","label":"CompareOrContrast","metadata":{},"score":"65.82654"}{"text":"In this paper , the Part - Of - Speech ( POS ) tagger synther based on m - gram statistics is described .After explaining its basic architecture , three smoothing approaches and the strategy for handling unknown words is exposed .","label":"CompareOrContrast","metadata":{},"score":"65.82654"}{"text":"[ 1996].How can I use ACOPOST ?For the various trainings , you need a cooked file , i.e. , a manually tagged corpus .The cooked file format used by ACOPOST requires a sentence per line , with tokens ' text and tags separed by white spaces .","label":"CompareOrContrast","metadata":{},"score":"66.17235"}{"text":"Claude Elwood Shannon 's influential 1948 paper that laid the foundation of information theory and changed the whole world since then .I see no reason who has read the above papers does not want to read this one .Information Theory and Statistical Mechanics ( Jaynes , E. T. , 1957 )","label":"CompareOrContrast","metadata":{},"score":"66.56851"}{"text":"For training the Transformation - based Tagger ( TBT ) , we use : .Some notes on training a Transformatio - based model : .You need to provide a file with templates for the transformations , such as nilc.templates in our example ( which is included in the \" Resources \" section at the bottom of this page ) ; .","label":"CompareOrContrast","metadata":{},"score":"66.650505"}{"text":"Given the lack of resources of this kind not only for Dutch but also for other languages , CoDAS will be able to set standards and will contribute to the future research in this area .A corpus ... \" .In this thesis , a pilot study for the development of a corpus of Dutch aphasic speech ( CoDAS ) is presented .","label":"CompareOrContrast","metadata":{},"score":"67.04875"}{"text":"We have made it compile and work on Mac OS X , and have created autoconf / automake scripts , as well as an RPM spec file .We are close to being able to make a release of a new version .","label":"CompareOrContrast","metadata":{},"score":"67.56236"}{"text":"The POS tags on both sides of the unknown word were tagged by TnT. Test data for POS tagging consists of about 285,000 tokens differing from the training data .The number of known / unknown words and the percentage of unknown word in the test data are shown in Table 2 .","label":"CompareOrContrast","metadata":{},"score":"67.7998"}{"text":"The simulation of feedback behavior for artificial conversational agents poses big challenges such as the concurrent and integrated perception and production of multi - modal and multi - functional expressions .We present an approach on modeling feedback for and with virtual humans , based on an approach to study \" embodied feedback \" as a special case of a more general theoretical account of embodied communication .","label":"CompareOrContrast","metadata":{},"score":"68.43758"}{"text":"Editing and refereeing are distributed .Each editor from the Editorial Board can conduct the refereeing process by appointing two new referees or referees from the Board of Referees or Editorial . \" ...Abstract .Automatic lemmatisation is a core application for many language processing tasks .","label":"CompareOrContrast","metadata":{},"score":"68.96575"}{"text":"Editing and refereeing are distributed .Each editor from the Editorial Board can conduct the refereeing process by appointing two new referees or referees from the Board of Referees or Editorial . \" ...Abstract .Automatic lemmatisation is a core application for many language processing tasks .","label":"CompareOrContrast","metadata":{},"score":"68.96575"}{"text":"For the following example sentence , ... Greenville/(Unknown Word ) days / NNSbefore / IN thefeatures \" Greenville \" These features are almost same as those used by Ratnaparkhi ( Ratnaparkhi , 1996 ) , but combination of POS tags is not used because polynomial kernel can automatically consider them .","label":"CompareOrContrast","metadata":{},"score":"69.14339"}{"text":"The results show that the performance is comparable to TnT in the first case and better in the second case .Between the first case and the second case , the accuracy for known words are al- most equal , but the accuracy of the first case for unknown words is lower than that of the second case .","label":"CompareOrContrast","metadata":{},"score":"69.48457"}{"text":"Automatic lemmatization is a core application for many language processing tasks .In inflectionally rich languages , such as Slovene , assigning the correct lemma ( base form ) to each word in a running text is not trivial , since for instance , nouns inflect for number and case , with a complex configurat ... \" .","label":"CompareOrContrast","metadata":{},"score":"69.58519"}{"text":"Automatic lemmatization is a core application for many language processing tasks .In inflectionally rich languages , such as Slovene , assigning the correct lemma ( base form ) to each word in a running text is not trivial , since for instance , nouns inflect for number and case , with a complex configurat ... \" .","label":"CompareOrContrast","metadata":{},"score":"69.58519"}{"text":"Al- though the approach is applicable to any type of language model , we focus on the case of statistical disambiguators that are trained on annotated corpora .The examples of the task that are present in the corpus and its annotation are fed into a learning algorithm , which induces a model of the desired input - output mapping in the form of a classifier .","label":"CompareOrContrast","metadata":{},"score":"70.026085"}{"text":"Al- though the approach is applicable to any type of language model , we focus on the case of statistical disambiguators that are trained on annotated corpora .The examples of the task that are present in the corpus and its annotation are fed into a learning algorithm , which induces a model of the desired input - output mapping in the form of a classifier .","label":"CompareOrContrast","metadata":{},"score":"70.026085"}{"text":"Al- though the approach is applicable to any type of language model , we focus on the case of statistical disambiguators that are trained on annotated corpora .The examples of the task that are present in the corpus and its annotation are fed into a learning algorithm , which induces a model of the desired input - output mapping in the form of a classifier .","label":"CompareOrContrast","metadata":{},"score":"70.026085"}{"text":"Al- though the approach is applicable to any type of language model , we focus on the case of statistical disambiguators that are trained on annotated corpora .The examples of the task that are present in the corpus and its annotation are fed into a learning algorithm , which induces a model of the desired input - output mapping in the form of a classifier .","label":"CompareOrContrast","metadata":{},"score":"70.026085"}{"text":"Abstract .Automatic lemmatisation is a core application for many language processing tasks .In inflectionally rich languages , such as Slovene , assigning the correct lemma to each word in a running text is not trivial : nouns and adjectives , for instance , inflect for number and case , with a complex configuration of endings and stem modifications .","label":"CompareOrContrast","metadata":{},"score":"70.25584"}{"text":"Abstract .Automatic lemmatisation is a core application for many language processing tasks .In inflectionally rich languages , such as Slovene , assigning the correct lemma to each word in a running text is not trivial : nouns and adjectives , for instance , inflect for number and case , with a complex configuration of endings and stem modifications .","label":"CompareOrContrast","metadata":{},"score":"70.25584"}{"text":"Linguistic categories coded in the lexicon can also be included in the generated label files . \" ...We introduce two ways to detect entailment using distributional semantic representations of phrases .We introduce two ways to detect entailment using distributional semantic representations of phrases .","label":"CompareOrContrast","metadata":{},"score":"70.27599"}{"text":"In inflectionally rich languages , such as Slovene , assigning the correct lemma ( base form ) to each word in a running text is not trivial , since for instance , nouns inflect for number and case , with a complex configuration of endings and stem modifications .","label":"CompareOrContrast","metadata":{},"score":"70.31329"}{"text":"In inflectionally rich languages , such as Slovene , assigning the correct lemma ( base form ) to each word in a running text is not trivial , since for instance , nouns inflect for number and case , with a complex configuration of endings and stem modifications .","label":"CompareOrContrast","metadata":{},"score":"70.31329"}{"text":"The dataset used is the 90.000 word Slovene translation of Orwell 's ' 1984 ' , split into a training and validation set .The validation set is the Appendix of the novel , on which extensive testing of the two components , singly and in combination , is performed .","label":"CompareOrContrast","metadata":{},"score":"70.52995"}{"text":"The dataset used is the 90.000 word Slovene translation of Orwell 's ' 1984 ' , split into a training and validation set .The validation set is the Appendix of the novel , on which extensive testing of the two components , singly and in combination , is performed .","label":"CompareOrContrast","metadata":{},"score":"70.52995"}{"text":"Table 1\"^ \" and \" $ \" mean the beginning and the end of the word respectively .SVM classifiers are created for each POS tag using all words in the training data .Then POS tags of unknown words are predicted us- ing those classifiers .","label":"CompareOrContrast","metadata":{},"score":"70.58342"}{"text":"By categorizing a user and related connections , one can be placed in an imaginary category specific subset of users , called Thought Bubbles .Following the trace of people who are also active within the same specific Thought Bubble , should reveal interesting and helpful connections between similar minded users .","label":"CompareOrContrast","metadata":{},"score":"70.76239"}{"text":"Informatica is a journal primarily covering the European computer science and informatics community ; scientific and educational as well as technical , commercial and industrial .Its basic aim is to enhance communications between different European structures on the basis of equal rights and internati ... \" .","label":"CompareOrContrast","metadata":{},"score":"71.13307"}{"text":"Informatica is a journal primarily covering the European computer science and informatics community ; scientific and educational as well as technical , commercial and industrial .Its basic aim is to enhance communications between different European structures on the basis of equal rights and internati ... \" .","label":"CompareOrContrast","metadata":{},"score":"71.13307"}{"text":"The accuracy of part - of - speech ( POS ) tagging for unknown words is substantially lower than that for known words .Considering the high accuracy rate of up - to - date statis- tical POS taggers , unknown words account for a non - negligible portion of the errors .","label":"CompareOrContrast","metadata":{},"score":"71.51894"}{"text":"We train the tagger on a manually annotated corpus consisting of 100,000 running words .We train the analyzer on open - class inflecting Slovene words , namely nouns , adjectives , and main verbs , together being characterized by more than 400 different morphosyntactic tags .","label":"CompareOrContrast","metadata":{},"score":"71.63412"}{"text":"We train the tagger on a manually annotated corpus consisting of 100,000 running words .We train the analyzer on open - class inflecting Slovene words , namely nouns , adjectives , and main verbs , together being characterized by more than 400 different morphosyntactic tags .","label":"CompareOrContrast","metadata":{},"score":"71.63412"}{"text":"TnT - A Statistical Part- of - Speech Tagger .6th Applied NLP Conference(ANLP-2000 ) , pages 224 - 231 .In Proceedings of the E. Brill .Transformation - Based Error-Driven Learning and Natural Language Processing : A Case Study in Part - of-","label":"CompareOrContrast","metadata":{},"score":"72.35791"}{"text":"Its basic aim is to enhance communications between different European structures on the basis of equal rights and international refereeing .It publishes scientific papers accepted by at least two referees outside the author 's country .In addition , it contains information about conferences , opinions , critical examinations of existing publications and news .","label":"CompareOrContrast","metadata":{},"score":"72.74908"}{"text":"Its basic aim is to enhance communications between different European structures on the basis of equal rights and international refereeing .It publishes scientific papers accepted by at least two referees outside the author 's country .In addition , it contains information about conferences , opinions , critical examinations of existing publications and news .","label":"CompareOrContrast","metadata":{},"score":"72.74908"}{"text":"One activity of Siemens in the TC - STAR project is to develop a high - quality text - to - speech ( TTS ) system for UK English .Our main focus is the improvement of the text preprocessing and the acoustic synthesis .","label":"CompareOrContrast","metadata":{},"score":"72.78697"}{"text":"One activity of Siemens in the TC - STAR project is to develop a high - quality text - to - speech ( TTS ) system for UK English .Our main focus is the improvement of the text preprocessing and the acoustic synthesis .","label":"CompareOrContrast","metadata":{},"score":"72.78697"}{"text":"We examined the be- havior when reducing the sparse features .Ta-ble 5 shows the result for 10,000 training to- kens .Ignoring the features that appeared only once , the accuracy is a bit improved .Page 5 .Page 6 .","label":"CompareOrContrast","metadata":{},"score":"72.82617"}{"text":"A corpus of Dutch aphasic speech should fulfill at least three requirements .First , it should en - code a plausible sample of contemporary Dutch as spoken by aphasic patients .That is , it should include speech representing different types of aphasia as well as various communication settings .","label":"CompareOrContrast","metadata":{},"score":"73.103226"}{"text":"Measures NNS of IN manufacturing VBG activity NN fell VBD more RBR than IN the DT overall JJ measures NNS . . .ACOPOST is a set of freely available POS taggers that Ingo Schöder modelled after well - known techniques .","label":"CompareOrContrast","metadata":{},"score":"74.35789"}{"text":"Renamed ICOPOST to ACOPOST and moved the package to the Sourceforge repository of open source projects .Released version 1.8.4 , which contained a preliminary user 's guide .The project was put on halt since Ingo Schröder ( the original maintainer ) would not have the time to maintain the package .","label":"CompareOrContrast","metadata":{},"score":"74.67479"}{"text":"I tried to contact the author and all the member of the SourceForge project , but unfortunately all messages were returned or not replied .Thus , consider my modifications an unauthorised fork .If you are or know one of the maintainers of ACOPOST , please drop me an email .","label":"CompareOrContrast","metadata":{},"score":"75.91647"}{"text":"While a speaker contributes new information , a listener gives feedback by producing unobtrusive ( usually short ) vocal or non - vocal bodily expressions to indicate whether he / she is able and willing to communi ... \" .Abstract .","label":"CompareOrContrast","metadata":{},"score":"76.340836"}{"text":"integratethis 1Introduction Part - of - speech ( POS ) tagging is fundamen- tal in natural language processing . statistical POS taggers use text data which are manually annotated with POS tags as training data to obtain the statistical infor- mation or rules to perform POS tagging .","label":"CompareOrContrast","metadata":{},"score":"77.540115"}{"text":"In the paper we report on an experiment on morphosyntactic tagging of Slovene , on a sample of Slovene legal language .We evaluate the accuracy of the TnT tagger , which had been trained on the MULTEXT - East language resources for Slovene .","label":"CompareOrContrast","metadata":{},"score":"78.798"}{"text":"In the paper we report on an experiment on morphosyntactic tagging of Slovene , on a sample of Slovene legal language .We evaluate the accuracy of the TnT tagger , which had been trained on the MULTEXT - East language resources for Slovene .","label":"CompareOrContrast","metadata":{},"score":"78.798"}{"text":"[ 1996].A detailed description , an extensive evaluation and new suggestions can be found in an accompanying technical report [ Schröder 2002 ] .References .Thorsten Brants .TnT - as statistical part - of - speech tagger .","label":"CompareOrContrast","metadata":{},"score":"79.36818"}{"text":"Although lexical amb ...","label":"CompareOrContrast","metadata":{},"score":"82.45048"}{"text":"Part - of - speech tagging or , more accurately , morphosyntactic tagging , is a procedure that assigns to each word token appearing in a text its morphosyntactic description , e.g. \" masculine singular common noun in the genitive case \" .","label":"CompareOrContrast","metadata":{},"score":"83.92175"}{"text":"Part - of - speech tagging or , more accurately , morphosyntactic tagging , is a procedure that assigns to each word token appearing in a text its morphosyntactic description , e.g. \" masculine singular common noun in the genitive case \" .","label":"CompareOrContrast","metadata":{},"score":"83.92175"}{"text":"Part - of - speech tagging or , more accurately , morphosyntactic tagging , is a procedure that assigns to each word token appearing in a text its morphosyntactic description , e.g. \" masculine singular common noun in the genitive case \" .","label":"CompareOrContrast","metadata":{},"score":"83.92175"}{"text":"Part - of - speech tagging or , more accurately , morphosyntactic tagging , is a procedure that assigns to each word token appearing in a text its morphosyntactic description , e.g. \" masculine singular common noun in the genitive case \" .","label":"CompareOrContrast","metadata":{},"score":"83.92175"}{"text":"\" [ Show abstract ] [ Hide abstract ] ABSTRACT : The concept of so called Thought Bubbles deals with the problem of finding appropriate new connections within Social Networks , especially Twitter .As a byproduct of exploring new users , Tweets are classified and rated and are used to generate a kind of news feed , which will extend the personal Twitter feed .","label":"CompareOrContrast","metadata":{},"score":"84.117424"}{"text":"No . of sentences : 4415 No of words : 104963 Most frequent words : 7739 \" , \" 4414 \" .of features : 10 ( from \" nilc.unknown.etf \" )No . of sentences : 4415 No of words : 104963 Most frequent words : 7739 \" , \" 4414 \" .","label":"CompareOrContrast","metadata":{},"score":"87.400665"}{"text":"Welcome to the home page of ACOPOST , a free and open source collection of part - of - speech taggers .A simplified form of this is commonly taught to school - age children , in the identification of words as nouns , verbs , adjectives , adverbs , etc .","label":"CompareOrContrast","metadata":{},"score":"90.15166"}{"text":"For more information on the project , please write me ( Tiago ) .Project changes : Tiago Tresoldi is the new maintainer ; besides a new home page , the programs are being adapted to 64-bit systems and code is being cleaned .","label":"CompareOrContrast","metadata":{},"score":"93.41469"}{"text":"What is ACOPOST about ?Part - of - speech ( POS ) tagging is the task os assigning grammatical classes to words in a natural language sentence .It is important because subsequent processing states ( such as parsing ) become easier if the word class for a word is available .","label":"CompareOrContrast","metadata":{},"score":"95.664604"}{"text":"Released version 0.9.0 ( first public release ) .First public talk about ICOPOST .Web page started .What is ACOPOST about ?Part - of - speech ( POS ) tagging is the task of assigning grammatical classes to words in a natural language sentence .","label":"CompareOrContrast","metadata":{},"score":"97.05432"}{"text":"Inspecting the last lines ( as the first ones will usually include only punctuation ) : .$ tail nilc.lex últimas ADJ 9 último ADJ 20 ORD 1 últimos ADJ 13 úmida ADJ 2 úmido ADJ 1 única ADJ 14 únicas ADJ 4 único ADJ 13 útero N 4 útil ADJ 2 .","label":"CompareOrContrast","metadata":{},"score":"99.41248"}