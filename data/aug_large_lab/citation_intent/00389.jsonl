{"text":"In this paper , we investigate lexicon models for hierarchical phrase - based statistical machine translation .We explore sourceto - target models with phrase - level as well as sentence - level scoring and target - to - source models with scoring on phrase level only .","label":"Motivation","metadata":{},"score":"39.791397"}{"text":"The results are compared to variants of the model that are applied in reranking of n - be ... \" .We show how the integration of an extended lexicon model into the decoder can improve translation performance .The model is based on lexical triggers that capture long - distance dependencies on the sentence level .","label":"Motivation","metadata":{},"score":"39.94436"}{"text":"By substituting verb forms by the lemma of their head verb , the data sparseness problem caused by highly - inflected languages can be successfully addressed .On the othe ... \" .This paper introduces a rule - based classification of single - word and compound verbs into a statistical machine translation approach .","label":"Motivation","metadata":{},"score":"40.143646"}{"text":"Given the task of predicting the correct rule to associate with a parse - tree node , or the corre ... \" .In this article , we apply to natural language parsing and tagging the device of triggerpair predictors , previously employed exclusively within the field of language modelling for speech recognition .","label":"Motivation","metadata":{},"score":"41.176785"}{"text":"In this paper we present a novel approach for inducing word alignments from sentence aligned data .We use a Conditional Random Field ( CRF ) , a discriminative model , which is estimated on a small supervised training set .The CRF is conditioned on both the source and target texts , and thus allows for t ... \" .","label":"Motivation","metadata":{},"score":"42.205505"}{"text":"It includes extensions to the hierarchical approach developed by RWTH as well as other research institutions .In this paper we give an overview of its main features .We also introduce a novel reordering model for the hierarchical phrase - based approach which further enhances translation performance , and analyze the effect some recent extended lexicon models have on the performance of the system . ... word alignment for each phrase , too , with the exception of phrases which are composed purely of non - terminals .","label":"Motivation","metadata":{},"score":"43.30275"}{"text":"Most SMT systems assume that translation rules can be applied without paying attention to the sentence context .The direct translation model in ( Ittycheriah and Roukos , 2007 ) empl ... . \" ...In past Evaluations for Machine Translation of European Languages , it could be shown that the translation performance of SMT systems can be increased by integrating a bilingual language model into a phrase - based SMT system .","label":"Motivation","metadata":{},"score":"43.362385"}{"text":"Workshop on Spoken Language Translation ( IWSLT'04 ) Evaluation Campaign are shown and discussed . ...the tuple is aligned to a word out of the tuple .Each tuple can not be decomposed into smaller phrases without violating the previous constraint .","label":"Motivation","metadata":{},"score":"43.387886"}{"text":"However , we also find that the speed - based methods degrade the perplexity of the language models by 5 - 10 % over traditional likelihood - based classing .We remedy this via the introduction of a speed - based regularization term in the likelihood objective function .","label":"Motivation","metadata":{},"score":"44.03845"}{"text":"Given the task of predicting the correct rule to as - sociate with a parse - tree node , or the cor - rec ... \" .In this article , we apply to natural language parsing and tagging the device of trigger - pair predictors , previously employed exclu - sively within the field of language mod - elling for speech recognition .","label":"Motivation","metadata":{},"score":"44.41084"}{"text":"We explore sourceto - target models with phrase - level as well as sentence - level scoring and target - to - source models with scoring on phrase level only .For the first two types of lexicon models , we compare several scoring variants .","label":"Motivation","metadata":{},"score":"44.515144"}{"text":"In the present work , we introduce lexico - syntactic descriptions in the form of supertags as source - side context features in the state - of - the - art hierarchical phrase - based SMT ( HPB ) model .These features enable us to exploit source similarity in addition to target similarity , as modelled by the language model .","label":"Motivation","metadata":{},"score":"45.14226"}{"text":"As both types of extended lexicon models can grow very large , we apply ... \" .In this work we give a detailed comparison of the impact of the integration of discriminative and trigger - based lexicon models in state - ofthe - art hierarchical and conventional phrasebased statistical machine translation systems .","label":"Motivation","metadata":{},"score":"45.256927"}{"text":"The models capture dependencies that go beyond the scope of conventional SMT models such as phraseand language models .We show that the models improve translation quality by 1 % in BLEU over a competitive baseline on a large - scale task . ...","label":"Motivation","metadata":{},"score":"45.371513"}{"text":"In t ... \" .Word - classing has been used in language modeling for two distinct purposes : to improve the likelihood of the language model , and to improve the runtime speed .In particular , frequency - based heuristics have been proposed to improve the speed of recurrent neural network language models ( RNN - LMs ) .","label":"Motivation","metadata":{},"score":"46.123623"}{"text":"On the latter topic , we discuss new work on feature and decision fusion combination , the modeling of audio - visual speech asynchrony , and incorporating modality reliability estimates to the bimodal recognition process .We also briefly touch upon the issue of audio - visual adaptation .","label":"Motivation","metadata":{},"score":"46.91374"}{"text":"Our experiments demonstrate that the visual modality improves automatic speech recognition over all conditions and data considered , though less so for visually challenging environments and large vocabulary tasks . ... of isolated word recognition ) are rescored by the stream log - likelihoods , independently computed over the entire utterance .","label":"Motivation","metadata":{},"score":"47.0634"}{"text":"Results show how the ngram - based approach outperforms the phrase - based approach by achieving similar accuracy scores in less computational time and with less memory needs .The addition of reordering abilities in the phrase - based approach is achieved by enabling a certain level of reordering in the source sentence .","label":"Motivation","metadata":{},"score":"47.082"}{"text":"We obtain gains in ... \" .Word alignments that violate syntactic correspondences interfere with the extraction of string - to - tree transducer rules for syntaxbased machine translation .We present an algorithm for identifying and deleting incorrect word alignment links , using features of the extracted rules .","label":"Motivation","metadata":{},"score":"47.44082"}{"text":"In this paper we show that using cross- and multilingual detectors to support an HMM based speech recognition system significantly reduces the word error rate .By selecting and weighting the features in a discriminative way , we achieve an error rate reduction that lies in the same range as that seen when using language specific feature detectors .","label":"Motivation","metadata":{},"score":"47.56375"}{"text":"On the other hand , we allow for a modifica - tion of the translation units that unfolds the tuples , so that shorter units are learnt from a new parallel corpus , where the source sen - tences are reordered according to the target lan - guage .","label":"Motivation","metadata":{},"score":"47.745613"}{"text":"However , this hard constraint can also rule out correct alignments , and its utility decreases as alignment models become more ... \" .Word alignment methods can gain valuable guidance by ensuring that their alignments maintain cohesion with respect to the phrases specified by a monolingual dependency tree .","label":"Motivation","metadata":{},"score":"47.769245"}{"text":"This is achieved through the creation of an adaptation technique called reference speaker weighting and in the development of a speaker clustering technique called speaker cluster weighting .However , speaker . ... and language models .The consistency modeling framework is easily extensible to these models .","label":"Motivation","metadata":{},"score":"48.05143"}{"text":"This work summarizes a comparison between two approaches to Statistical Machine Translation ( SMT ) , namely Ngram - based and Phrase - based SMT .In both approaches , the translation process is based on bilingual units related by word - to - word alignments ( pairs of source and target words ) , while the main differences are based on the extraction process of these units and the statistical modeling of the translation context .","label":"Motivation","metadata":{},"score":"48.100628"}{"text":"In this paper , we describe how overly aggressive key - target resizing can sometimes prevent users from typing their desired text , violating basic user expectations about keyboard functionality .We propose an anchored key - target method which aims to provide an input method that is robust to errors while respecting usability principles .","label":"Motivation","metadata":{},"score":"48.10737"}{"text":"Afterwards , we classify these pairs into groups , following recursively a co - occurrence block criterion , in order to infer reorderings .Inside the same group , we allow new internal combination in or - der to generalize the reorder to unseen pairs of blocks .","label":"Motivation","metadata":{},"score":"48.182007"}{"text":"We further apply the model to the Wall Street Journal speech recognition task , where we observe improvements in word - error - rate . ...Finally , in whole - sentence language models [ 20 , 21 ] , trigger features based on the existence of widely separate ... . by Ebru Arısoy , Tara N. Sainath , Brian Kingsbury , Bhuvana Ramabhadran - In Proceedings of NAACL - HLT 2012 Workshop : Will We Ever Really Replace the N - gram Model ?","label":"Motivation","metadata":{},"score":"48.398796"}{"text":"The features used in this work are non - terminal labels , non - terminal length distribution , source string context and source dependency LM scores .The effectiveness of our techniques is demonstrated by significant improvements over a strong baseline .","label":"Motivation","metadata":{},"score":"48.41238"}{"text":"We report several techniques for efficiently prune out the search space .The combinatory explosion of the search space derived from the search graph structure is reduced by limiting the number of reorderings a given translation is allowed to perform , and also the maximum distance a word ( or a phrase ) is allowed to be reordered .","label":"Motivation","metadata":{},"score":"48.71663"}{"text":"A remaining disadvantage , however , is the high model complexity .This paper describes a word alignment training procedure for statistical machine translation that uses a simple and clear statistical model , different from the IBM models .The main idea of the algorithm is to generate a symmetric and monotonic alignment between the target sentence and a permutation graph representing different reorderings of the words in the source sentence .","label":"Motivation","metadata":{},"score":"48.722263"}{"text":"Index Terms : voice search , language modeling , speech recognition , personalization . ... equeries a past request .Index Terms : voice search , language modeling , speech recognition , personalization 1 .The key ideas present are the modeling of word n - gram probabilities with a log - linear model , and the use of word - class informat ... . \" ...","label":"Motivation","metadata":{},"score":"48.744255"}{"text":"We present a framework for statistical machine translation of natural languages based on direct maximum entropy models , which contains the widely used source -channel approach as a special case .All knowledge sources are treated as feature functions , which depend on the source language sentence , the target language sentence and possible hidden variables . .","label":"Motivation","metadata":{},"score":"49.08954"}{"text":"In ( Chen , 2009 ) , we show that for a variety of language models belonging to the exponential family , the test set cross - entropy of a model can be accurately predicted from its training set cross - entropy and its parameter values .","label":"Motivation","metadata":{},"score":"49.16076"}{"text":"In ( Chen , 2009 ) , we show that for a variety of language models belonging to the exponential family , the test set cross - entropy of a model can be accurately predicted from its training set cross - entropy and its parameter values .","label":"Motivation","metadata":{},"score":"49.16076"}{"text":"In both approaches , the translation process is based on bilingual units related by word - to - word alignments ( pairs of source and target words ) , while the main di ... \" .This work summarizes a comparison between two approaches to Statistical Machine Translation ( SMT ) , namely Ngram - based and Phrase - based SMT .","label":"Motivation","metadata":{},"score":"49.911522"}{"text":"d unit is augmented with its context dependent pronunciation .MaxEnt LMs provide the flexibility to incorporate various features , but consume many resources depending on vocabulary size .For LVCSR , in general , the LM data is obtained from multiple domains like ... . \" ...","label":"Motivation","metadata":{},"score":"50.09675"}{"text":"The unfolding technique produces a different bilingual n - gram language model with reordered source words .Figure 1 : ... .Therefore , all models are combined in search and a single best hypothesis is output .4.2.4 Optimisation procedure Minimum - error training states that we can directly train our models according the an errorminimisation function on a certain development data , as discussed in § 2.4.1 .","label":"Motivation","metadata":{},"score":"50.352104"}{"text":"First , we use chunks to refine the set of word alignments typically used as a starting point in SMT systems .Second , we extend an N - grambased SMT system with chunk tags to better account for long - distance reorderings .","label":"Motivation","metadata":{},"score":"50.545223"}{"text":"First , we use chunks to refine the set of word alignments typically used as a starting point in SMT systems .Second , we extend an N - grambased SMT system with chunk tags to better account for long - distance reorderings .","label":"Motivation","metadata":{},"score":"50.545223"}{"text":"However , the difference in word order between two languages is one of t ... \" .Statistical Machine Translation ( SMT ) is based on alignment models which learn from bilingual corpora the word corre - spondences between source and target lan - guage .","label":"Motivation","metadata":{},"score":"50.62513"}{"text":"We show that our algorithm leads not only to improved alignments but also to machine translation outputs of higher quality . ... evious work on discriminative training for wordalignment differed most strongly from our approach in that it generally views word - alignment as a supervised task .","label":"Motivation","metadata":{},"score":"50.694275"}{"text":"TALP generates translations by searching for the best scoring path through a Finite - State Transducers ( FSTs ) , which models an X - gram of the bilingual language defined by tuples .A de - tailed description of the system and the core processes to train it from a parallel corpus are presented .","label":"Motivation","metadata":{},"score":"50.93955"}{"text":"Discriminative learning allows easy incorporation of any feature one might have access to during the alignment search .Because the features are handled so easily , ... . \" ...Word alignments that violate syntactic correspondences interfere with the extraction of string - to - tree transducer rules for syntaxbased machine translation .","label":"Motivation","metadata":{},"score":"51.103443"}{"text":"Building on this work , we demonstrate substan ... \" .For many years , statistical machine translation relied on generative models to provide bilingual word alignments .In 2005 , several independent efforts showed that discriminative models could be used to enhance or replace the standard generative approach .","label":"Motivation","metadata":{},"score":"51.114582"}{"text":"On the other hand , the information of seen verb forms can be used to generate new translations for unseen verb forms .Translation results for an English to Spanish task are reported , producing a significant performance improvement .rases , that is , we have a table of the probabilities of translating a certain source phrase ˜ fj into a certain target phrase ˜ek .","label":"Motivation","metadata":{},"score":"51.237965"}{"text":"However , because of the form of ( 1 ) , the closed - form solution of DMC does not apply ; instead , we optimize by gradient descent on a smoothed word - error function in the style of GPD [ 12].","label":"Motivation","metadata":{},"score":"51.255844"}{"text":"The extended graph is traversed in decoding when a fullyinformed decision can be taken ( no preprocessing decision about reordering is taken ) .We also show how the N - gram translation model can be successfully used as reordering model when estimated with reordered source words ( to harmonize the source and target word order ) .","label":"Motivation","metadata":{},"score":"51.26801"}{"text":"Thus it extends a previous work were both approaches were compared under monotone conditions .We finally report comparative results in terms of translation accuracy , computation time and memory size .Results show how the ngram - based approach outperforms the phrase - based approach by achieving similar accuracy scores in less computational time and with less memory needs .","label":"Motivation","metadata":{},"score":"51.33488"}{"text":"Thus , the benefits of both the MaxEnt LMs and the traditional class - based LMs are effectively combined .Furthermore , we experiment the use of Maximum a - posteriori adaptation over the MaxEnt class - based LMs .We show consistent reductions in both the OOV recognition error rate and the word error rate ( WER ) on a German LVCSR task from the Quaero project , compared to the traditional class - based and the N - gram morpheme based LM . .","label":"Motivation","metadata":{},"score":"51.38505"}{"text":"We investigate the extent to which alignment can be simulated using word sequences alone ( not syntactic structures ) .To this end , we interpolate a default language model with one calculated on the basis of a cached sentence .Experiments on sentences with the prepositional / double object alternation show that varying the weight given to the cache model varies the propensity to align .","label":"Motivation","metadata":{},"score":"51.725468"}{"text":"In this paper we investigate the possibility of evaluating MT quality and fluency at the sentence level in the absence of reference translations .We measure the correlation between automatically - generated scores and human judgments , and we evaluate the performance of our system when used as a classifier for identifying highly dysfluent and illformed sentences .","label":"Motivation","metadata":{},"score":"52.04335"}{"text":"Author Keywords source - channel key - target resizing , language model , touch model . ... odel predicts that it is very unlikely compared to the key ' s ' .The key - target outlines are shown in heavy lines . \" ...","label":"Motivation","metadata":{},"score":"52.050438"}{"text":"We introduce a semi - supervised approach to training for statistical machine translation that alternates the traditional Expectation Maximization step that is applied on a large training corpus with a discriminative step aimed at increasing word - alignment quality on a small , manually word - aligned sub ... \" .","label":"Motivation","metadata":{},"score":"52.135044"}{"text":"In past Evaluations for Machine Translation of European Languages , it could be shown that the translation performance of SMT systems can be increased by integrating a bilingual language model into a phrase - based SMT system .In the bilingual language model , target words with their aligned source words build the tokens of an n - gram based language model .","label":"Motivation","metadata":{},"score":"52.188515"}{"text":"The model is based on lexicalized triplets ( ) which can be understood as two query terms triggering one expansion term ... . \" ...We show how the integration of an extended lexicon model into the decoder can improve translation performance .","label":"Motivation","metadata":{},"score":"52.78893"}{"text":"Results on Chinese - to - English and Arabic - to - English tracks using supplied data are reported . ... rdered search , which is guided by the N - gram model of the unfolded tuples and the additional feature models .","label":"Motivation","metadata":{},"score":"52.82369"}{"text":"We use the first heuristic to develop a novel class - based language model that outperforms a baseline word trigram model by 28 % in perplexity and 1.9 % absolute in speech recognition word - error rate on Wall Street Journal data .","label":"Motivation","metadata":{},"score":"52.937836"}{"text":"We use the first heuristic to develop a novel class - based language model that outperforms a baseline word trigram model by 28 % in perplexity and 1.9 % absolute in speech recognition word - error rate on Wall Street Journal data .","label":"Motivation","metadata":{},"score":"52.937836"}{"text":"Model M is a superior class - based n - gram model that has shown improvements on a variety of tasks and domains .In previous work with Model M , bigram mutual information clustering has been used to derive word classes .","label":"Motivation","metadata":{},"score":"52.97082"}{"text":"Model M is a superior class - based n - gram model that has shown improvements on a variety of tasks and domains .In previous work with Model M , bigram mutual information clustering has been used to derive word classes .","label":"Motivation","metadata":{},"score":"52.97082"}{"text":"This set - up is suitable for our initial experiments since having a moderate size vocabulary minimizes the effect of using a shortlist at the output layer .It also allows ... . by M. Ali , Basha Shaik , Amr El - desoky Mousa , Ralf Schlüter , Hermann Ney . \" ...","label":"Motivation","metadata":{},"score":"53.047413"}{"text":"These models are trained on pairs of user queries and titles of clicked documents .Evaluations on a real world data set show that the lexicon models , integrated into a ranker - based QE system , not only significantly improve the document retrieval performance but also outperform two state - of - the - art log - based QE methods . ... algorithm , where the number of iterations is determined empirically on held - out data .","label":"Motivation","metadata":{},"score":"53.129807"}{"text":"More specifically , we tackle the problem of estimating the appropriate combination weights for each of the modalities .ndent exponents , using per frame voicing estimates .The results are compared with the baseline and the per utterance exponent results .","label":"Motivation","metadata":{},"score":"53.19463"}{"text":"Briefly , the system performs a log - linear combination of a translation model and additional feature functions .The translation model is estimated as an N - gram of bilingual units called tuples , and the feature functions include a target language model , a word penalty , and lexical features , depending on the language pair and task .","label":"Motivation","metadata":{},"score":"53.266132"}{"text":"One of the main challenges in the German LVCSR is the recognition of the OOV words .For this purpose , data - driven morphemes are used to provide higher lexical coverage .On the other hand , the probability estimates of a sub - lexical LM could be further improved using feature - rich LMs like maximum entropy ( MaxEnt ) and class - based LMs .","label":"Motivation","metadata":{},"score":"53.316353"}{"text":"These models are trained on pairs of user queries and titles of clicked documents .Evaluations on a real world data set show t ... \" .This paper explores log - based query expansion ( QE ) models for Web search .","label":"Motivation","metadata":{},"score":"53.686455"}{"text":"All models are used during search , i.e. they are incorporated directly into the log - linear model combination of the decoder .Phrase table smoothing with triplet lexicon models and with discriminative word lexicons are novel contributions .We also propose a new regularization technique for IBM model 1 by means of the Kullback - Leibler divergence with the empirical unigram distribution as regularization term .","label":"Motivation","metadata":{},"score":"53.693893"}{"text":"We use a publicly available structured output SVM to create a max - margin syntactic aligner with a soft cohesion constraint .The resulting aligner is the first , to our knowledge , to use a discriminative learning method to train an ITG bitext parser . ... rence for links to appear near one another ( Vogel et al .","label":"Motivation","metadata":{},"score":"53.81078"}{"text":"However , the difference in word order between two languages is one of the most important sources of errors in SMT .In this paper , we show that SMT can take advantatge of in - ductive learning in order to solve reorder - ing problems .","label":"Motivation","metadata":{},"score":"53.968346"}{"text":"In this paper , we extend it with personalization features , address the scalability issues present with large data sets , and test its effectiveness on the Bing Mobile voice - search task .We find that Model M by itself reduces both perplexity and word error rate compared with a conventional model , and that the personalization features produce a further significant improvement .","label":"Motivation","metadata":{},"score":"54.047226"}{"text":"As opposed to past explanations , our interpretation can recover exactly the formulation of interpolated Kneser - Ney , and performs better than interpolated Kneser - Ney when a better inference procedure is used . \" ...In ( Chen , 2009 ) , we show that for a variety of language models belonging to the exponential family , the test set cross - entropy of a model can be accurately predicted from its training set cross - entropy and its parameter values .","label":"Motivation","metadata":{},"score":"54.193626"}{"text":"In this paper we investigate the possibility of evaluating MT quality and fluency at the sentence level in the absence of reference translations .We measure the correlation between automatically - generated scores and human judgments , and we evaluate the performance of our system when used a ... \" .","label":"Motivation","metadata":{},"score":"54.203117"}{"text":"In reranking , the complete target sentence is available and the model can account for global sentence - level context to judge the selection of target words which was determined by the decoder .Both s .. \" ...This paper explores log - based query expansion ( QE ) models for Web search .","label":"Motivation","metadata":{},"score":"54.643215"}{"text":"Contrary to the reported results , these additional featu ... \" ...We present a framework for statistical machine translation of natural languages based on direct maximum entropy models , which contains the widely used source -channel approach as a special case .","label":"Motivation","metadata":{},"score":"54.65175"}{"text":"This dissertation shows that maxent models can achieve accuracy rates of 84.7 % using standard features , rising to 85.3 % when using additional features based on Latent Semantic Analysis ( LSA ) information .Three feature selection techniques are compared in this domain : frequency cut - off , information gain ( mutual information ) and a new method that uses the variation of feature weights across several training sets .","label":"Motivation","metadata":{},"score":"54.652885"}{"text":"A brief description of the complete system is presented and special attention is dev ... \" .This paper describes the UPC 's bilingual n - gram approach to statistical machine translation , which implements the log - linear combination of a bilingual n - gram translation model with six additional feature functions .","label":"Motivation","metadata":{},"score":"54.718254"}{"text":"In this paper , we investigate the use of mixed type of sub - word units in the same recognition lexicon .Namely , morphemic or syllabic units combined with pronunciations called graphones , normal graphemic morphemes or syllables , along with full - words .","label":"Motivation","metadata":{},"score":"54.89307"}{"text":"Previous generative word alignment models have made structural assumptions such as the 1-to-1 , 1-to - N , or phrase - based consecutive word assumptions , while previous discriminative models have either made such ... \" .Word alignment is the problem of annotating parallel text with translational correspondence .","label":"Motivation","metadata":{},"score":"55.134644"}{"text":"These strategies interact to improve translation qual - ity in a Chinese to English task .On the one hand , we allow for an Ngram - based decoder ( MARIE ) to perform a reordered search over the source sentence , while combin - ing a translation tuples Ngram model , a tar - get language model , a word penalty and a word distance model .","label":"Motivation","metadata":{},"score":"55.374992"}{"text":"However , while exponential language models can give superior performance , there has been li ... \" .Abstract - Language model pruning is an essential technology for speech applications running on resource - constrained devices , and many pruning algorithms have been developed for conventional word n - gram models .","label":"Motivation","metadata":{},"score":"55.69841"}{"text":"In this paper we investigate the effects of applying such a technique to higherorder n - gram models trained on large corpora .We introduce a modi ... \" .In statistical language modeling , one technique to reduce the problematic effects of data sparsity is to partition the vocabulary into equivalence classes .","label":"Motivation","metadata":{},"score":"55.74684"}{"text":"Fur - ther , by utilizing trigger pairs taken from the same general sort of doculnent as is be - ing processed ( e.g. same subject matter or same discourse type ) as opposed to pre - dictors derived from a comprehensive gen - eral set of English texts we can signifi - cantly increase this information gain .","label":"Motivation","metadata":{},"score":"55.96151"}{"text":"Statistical machine translation ( SMT ) models have recently begun to include source context modeling , under the assumption that the proper lexical choice of the translation for an ambiguous word can be determined from the context in which it appears .","label":"Motivation","metadata":{},"score":"55.995758"}{"text":"Statistical machine translation ( SMT ) models have recently begun to include source context modeling , under the assumption that the proper lexical choice of the translation for an ambiguous word can be determined from the context in which it appears .","label":"Motivation","metadata":{},"score":"55.995758"}{"text":"Despite their simplicity , we find that initializing the dependency model with valence using our concave models can approach state of the art grammar induction results for English and Chinese .For other applications , such as unsupervised part - of - speech tagging and grammar induction , and indeed for more sophisticated word alignment models , the log - likelihood function optimized by EM is n .. \" ...","label":"Motivation","metadata":{},"score":"56.027252"}{"text":"The study has been carried out on two different translation tasks ( in terms of translation difficulty and amount of available training data ) , and allowing for distortion ( reordering ) in the decoding process .Thus it extends a previous work were both approaches were compared under monotone conditions .","label":"Motivation","metadata":{},"score":"56.047104"}{"text":"The resulting clusterings are then used in training partially class - based language models .We show that combining them with wordbased n - gram models in the log - linear model of a state - of - the - art statistical machine translation system leads to improvements in translation quality as indicated by the BLEU score . ...","label":"Motivation","metadata":{},"score":"56.047592"}{"text":"The translation model is estimated as an N - gram of bilingual units called tuples , and the feature functions include a target language model , a word penalty , and lexical features , depending on the language pair and task .","label":"Motivation","metadata":{},"score":"56.100437"}{"text":"By performing Latent Dirichlet Allocation using a block of preceding text , we achieve a topic - conditioned RNNLM .This approach has the key advantage of avoiding the data fragmentation associated with building multiple topic models on different data subsets .","label":"Motivation","metadata":{},"score":"56.18561"}{"text":"Unfortunately the relationship between alignment quality and statistical machine translation performance has not been well understood .In the recent literature the alignment task has frequently been decoupled from the ... \" .Automatic word alignment plays a critical role in statistical machine translation .","label":"Motivation","metadata":{},"score":"56.195858"}{"text":"g [ 32 ] and prepositional phrase attachment [ 32].Ours is the first approach , to our knowledge , which uses it for categorical data classification with mined frequent itemsets as constraints .It applied Good - Turing discounting to the observed constraint frequencies a .. \" ...","label":"Motivation","metadata":{},"score":"56.204086"}{"text":"In this paper , we propose methods of using new linguistic and contextual features that do not suffer from this problem and ... \" .Current methods of using lexical features in machine translation have difficulty in scaling up to realistic MT tasks due to a prohibitively large number of parameters involved .","label":"Motivation","metadata":{},"score":"56.274414"}{"text":"We present a new generative alignment model which avoids these structural limitations , and show that it is effective when trained using both unsupervised and semi - supervised training methods . ... lar to work using discriminative log - linear models for alignment , which is similar to discriminative log - linear models used for the SMT decoding ( translation ) problem ( Och and Ney , 2002 ; Och , 2003 ) .","label":"Motivation","metadata":{},"score":"56.36206"}{"text":"We take a decision fusion approach for the audio - visual ... \" .In this work we demonstrate an improvement in the state - of - theart large vocabulary continuous speech recognition ( LVCSR ) performance , under clean and noisy conditions , by the use of visual information , in addition to the traditional audio one .","label":"Motivation","metadata":{},"score":"56.59152"}{"text":"All results pre - sented were generated by using the N - gram - based statistical machine translation system which has been enhanced from the last year 's evaluation with a tagged target language model ( using Part - Of - Speech tags ) .","label":"Motivation","metadata":{},"score":"56.940266"}{"text":"The complexity is exponential in the size of individual grammar rules due to arbitrary re - orderings between the two languages .We develop a theory of binarization for synchronous context - free grammars and present a linear - time algorithm for binarizing synchronous rules when possible .","label":"Motivation","metadata":{},"score":"57.101955"}{"text":"In Statistical Machine Translation , the use of reordering for certain language pairs can pro - duce a significant improvement on translation accuracy .However , the search problem is shown to be NP - hard when arbitrary reorderings are allowed .","label":"Motivation","metadata":{},"score":"57.121994"}{"text":"In Statistical Machine Translation , the use of reordering for certain language pairs can pro - duce a significant improvement on translation accuracy .However , the search problem is shown to be NP - hard when arbitrary reorderings are allowed .","label":"Motivation","metadata":{},"score":"57.121994"}{"text":"Results obtained on 175 manually - labeled songs provided an increase in accuracy of about 2 % . by Carsten Brockmann , Jon Oberlander - In Proc . of the UM'05 Workshop on Adapting the Interaction , 2005 . \" ...For a successful and satisfying interaction , a dialogue participant may align their language to be more like that of their interlocutor .","label":"Motivation","metadata":{},"score":"57.348557"}{"text":"We report results for French - English and German - English in both directions .Our submissions use n - code , an open source system based on bilingual n - grams .In this approach , both the translation and target language models are estimated as conventional smoothed n - gram models ; an approach we extend here by estimating the translation probabilities in a continuous space using neural networks .","label":"Motivation","metadata":{},"score":"57.34919"}{"text":"Bilingual word alignment forms the foundation of most approaches to statistical machine translation .Current word alignment methods are predominantly based on generative models .In this paper , we demonstrate a discriminative approach to training simple word alignment models that are comparable in accuracy to the more complex generative models normally used .","label":"Motivation","metadata":{},"score":"57.52468"}{"text":"We use a Conditional Random Field ( CRF ) , a discriminative model , which is estimated on a small supervised training set .The CRF is conditioned on both the source and target texts , and thus allows for the use of arbitrary and overlapping features over these data .","label":"Motivation","metadata":{},"score":"57.54969"}{"text":"Recurrent neural network language models ( RNNLMs ) have recently demonstrated state - of - the - art performance across a variety of tasks .In this paper , we improve their performance by providing a contextual real - valued input vector in association with each word .","label":"Motivation","metadata":{},"score":"57.662315"}{"text":"Recurrent neural network language models ( RNNLMs ) have recently demonstrated state - of - the - art performance across a variety of tasks .In this paper , we improve their performance by providing a contextual real - valued input vector in association with each word .","label":"Motivation","metadata":{},"score":"57.662315"}{"text":"We demonstrate these improvements with both an RNN - LM and the Model M exponential language model , for three different tasks involving two different languages . . ..To further improve speed , multi - level classing has been explored in , e.g .... . by For German Lvcsr , M. Ali , Basha Shaik , Amr El - desoky Mousa , Ralf Schlüter , Hermann Ney . \" ...","label":"Motivation","metadata":{},"score":"57.678566"}{"text":"Word lexicon models extracted from the alignment have been proposed by Koehn , Och and Marcu [ 1 ] and Zens and Ney [5 ] ... . \" ...The IBM translation models have been hugely influential in statistical machine translation ; they are the basis of the alignment models used in modern translation systems .","label":"Motivation","metadata":{},"score":"57.988766"}{"text":"e is available .This combination can be done at the sentence or sub - word level , with better performance obtained using phone - level combinations .We note in pa ... . by A. Stolcke , H. Bratt , J. Butzberger , H. Franco , V. R. Rao Gadde , M. Plauché , C. Richey , E. Shriberg , K. Sönmez , F. Weng , J. Zheng - In Proceedings of the NIST Speech Transcription Workshop , 2000 . \" ...","label":"Motivation","metadata":{},"score":"57.991497"}{"text":"We find that the HMMs es - timated by EM generally assign a roughly equal number of word tokens to each hid - den state , while the empirical distribution of tokens to POS tags is highly skewed .This motivates a Bayesian approach using a sparse prior to bias the estimator toward such a skewed distribution .","label":"Motivation","metadata":{},"score":"58.003044"}{"text":"In conversational speech language modeling experiments , we see perplexity reductions .In standard models , the \" sparse \" component is the only component , and is thus tasked with modeling all of the sequent ... . \" ...Word - classing has been used in language modeling for two distinct purposes : to improve the likelihood of the language model , and to improve the runtime speed .","label":"Motivation","metadata":{},"score":"58.11926"}{"text":"This procedure poses additional difficulties when applied to the ngram - based approach , because the characteristics of the ngram - based translation model . by Josep M. Crego , Adrià De Gispert , José B. Mariño - in Proc .International Workshop Spoken Language Translation , 2005 . \" ...","label":"Motivation","metadata":{},"score":"58.211033"}{"text":"Translation results for the Spanish - to - English and English - to - Spanish tasks considered during the TC - STAR 's second evaluation campaign are presented and discussed .Finally , improvements achieved in translation accuracy with respect to the previous year 's system are also evaluated and discussed 1 .","label":"Motivation","metadata":{},"score":"58.369328"}{"text":"An example of the tuple extraction process is drawn ... .by Josep M. Crego , Marta R. Costa - jussà , José B. Mariño , José A. R. Fonollosa - In Proceedings of the International Workshop on Spoken Language Technology ( IWSLT'05 , 2005 . \" ...","label":"Motivation","metadata":{},"score":"58.40101"}{"text":"We could show improvements of translation quality on German - to - English and Arabic - to - English .In addition , for the Arabic - to - English task , training an extra bilingual language model on the POS tags instead of the surface word forms led to further improvements . by Matthias Huck , Martin Ratajczak , Patrick Lehnen , Hermann Ney , Lehrstuhl Für Informatik - In Conf . of the Assoc . for Machine Translation in the Americas ( AMTA , 2010 . \" ...","label":"Motivation","metadata":{},"score":"58.50983"}{"text":"The model is l ... \" .We present a novel translation model based on tree - to - string alignment template ( TAT ) which describes the alignment be - tween a source parse tree and a target string .A TAT is capable of generating both terminals and non - terminals and per - forming reordering at both low and high levels .","label":"Motivation","metadata":{},"score":"58.54378"}{"text":"On the other hand , the fundamental principle of MaxEnt is initially introduced in [ 6].MaxEnt LM uses the information obtained from various knowledge sources as feature constraints .In general , the knowledge sources could be different types of features having different constraints ( i .... . \" ...","label":"Motivation","metadata":{},"score":"58.612007"}{"text":"S tag sequence 2 .Figure 2 shows an example of tuple extraction following regular and unfold techniques .Fig .2 .Unfold vs. regular tuple extraction .The N - gram translation model estimated with unfolded units does no ... .","label":"Motivation","metadata":{},"score":"58.767624"}{"text":"Results on Chinese - to - English and Arabic - to - English tracks using supplied data are reported . ... guages are linked up in tuples , the context information provided by this translation model is bilingual . by Jose ́ B. Mariño , Rafael E. Banchs , Josep M. Crego , Adria ̀ De Gispert , Patrik Lambert , Jose ́ A. R. Fonollosa , Marta R. Costa - jussà , Maxim Khalilov - in Proc . of the TC - STAR Workshop on Speech - toSpeech Translation , 2006 . \" ...","label":"Motivation","metadata":{},"score":"58.870537"}{"text":"The unfolding technique produces a different bilingual N - gram language model with reordered source words .Usually , ... .by Josep M. Crego , Nizar Habash - In Proceedings of the Third Workshop on Statistical Machine Translation , 2008 . \" ...","label":"Motivation","metadata":{},"score":"58.95573"}{"text":"The classifier uses linguistic features and has been trained to distinguish human translations from machine translations .We show that this approach also performs well in identifying dysfluent sentences . by Jakob Uszkoreit , Thorsten Brants - In ACL International Conference Proceedings , 2008 . \" ...","label":"Motivation","metadata":{},"score":"58.98414"}{"text":"We swap them and we use the mod - ied source training corpora to realign and to build the nal translation system .We have evaluated our reordering ap - proach both in alignment and translation quality .In addition , we have used two state - of - the - art SMT systems : a Phrased - based and an Ngram - based .","label":"Motivation","metadata":{},"score":"59.0681"}{"text":"We study five types of lexicon models : a model which is extracted from word - aligned training data and - given the word alignment matrix - relies on pure relative frequencies [ 1 ] ; the IBM model 1 l ... \" .","label":"Motivation","metadata":{},"score":"59.21257"}{"text":"We also report preliminary experiments using an \" on - the - fly \" translation model . ...n IBM1 models and word sense disambiguation ( WSD ) information in rescoring .As for the SOUL models , these features are added after the n - best list generation step .","label":"Motivation","metadata":{},"score":"59.228592"}{"text":"The assumption clearly damages the recognition ability of standard speaker independent systems , as can seen by the severe drop in performance exhibited by systems between their speaker dependent mode and their speaker independent mode .The typical solution to this problem is to apply speaker adaptation to the models of the speaker independent system .","label":"Motivation","metadata":{},"score":"59.39353"}{"text":"Specifically , we study the benefit of the visual modality for both machines and humans , when combined with audio degraded by speech - babble noise at various signal - to - noise ratios ( SNRs ) .We first consider an automatic speechreading system with a pixel based visual front end that uses feature fusion for bimodal integration , and we compare its performance with an audio - only LVCSR system .","label":"Motivation","metadata":{},"score":"59.46783"}{"text":"Abstract - Language model pruning is an essential technology for speech applications running on resource - constrained devices , and many pruning algorithms have been developed for conventional word n - gram models .However , while exponential language models can give superior performance , there has been little work on the pruning of these models .","label":"Motivation","metadata":{},"score":"59.567467"}{"text":"..We note that even though no distinction is made between content - bearing and function words in the process of selecting trigger pairs , a vast majority ... .by Timothy J. Hazen , James R. Glass , Arthur C. Smith , Timothy J. Hazen - Proceedings of ICSLP 98 , 1998 . \" ...","label":"Motivation","metadata":{},"score":"59.68242"}{"text":"We describe procedures and experimental results using speech from diverse source languages to build an ASR system for a single target language .This work is intended to improve ASR in languages for which large amounts of training data are not available .","label":"Motivation","metadata":{},"score":"59.993073"}{"text":"We describe procedures and experimental results using speech from diverse source languages to build an ASR system for a single target language .This work is intended to improve ASR in languages for which large amounts of training data are not available .","label":"Motivation","metadata":{},"score":"59.993073"}{"text":"This paper addresses the problem of reordering in statistical machine translation ( SMT ) .We describe an elegant and efficient approach to couple reordering ( word order monotonization ) and decoding , which does not need for any additional model .","label":"Motivation","metadata":{},"score":"60.105267"}{"text":"This paper addresses the problem of reordering in statistical machine translation ( SMT ) .We describe an elegant and efficient approach to couple reordering ( word order monotonization ) and decoding , which does not need for any additional model .","label":"Motivation","metadata":{},"score":"60.105267"}{"text":"This allows the language model to adjust to the general topic being spoken ... . \" ...Prepositional phrases are a common source of ambiguity in natural language and many approaches have been devised to resolve this ambiguity automatically .In particular , several different machine learning approaches have now reached accuracy rates of around 84.5 % on the benchmark dataset .","label":"Motivation","metadata":{},"score":"60.3096"}{"text":"Phrase table smoothing with triplet lexicon models and with discriminative word lexicons are novel contributions .We also propose a new regularization technique for IBM model 1 by means of the Kullback - Leibler divergence with the empirical unigram distribution as regularization term .","label":"Motivation","metadata":{},"score":"60.44771"}{"text":"Standard and factored language models are analyzed in terms of applicability to the chord recognition task .Pitch class profile vectors that represent harmonic information are extracted from the given audio ... \" .This paper focuses on automatic extraction of acoustic chord sequences from a musical piece .","label":"Motivation","metadata":{},"score":"60.756546"}{"text":"We also discuss the more general , and computationally more difficult , problem of finding good parsing strategies for non - binarizable rules , and present an approximate polynomial - time algorithm for this problem . \" ...For many years , statistical machine translation relied on generative models to provide bilingual word alignments .","label":"Motivation","metadata":{},"score":"60.822968"}{"text":"We also obtained an unusually large improvement from modeling crossword pronunciation variants in \" multiword \" vocabulary items .The language model ( LM ) was enhanced with an \" anti - LM \" representing acoustically confusable word sequences .Finally , we applied a generalized ROVER algorithm to combine the N - best hypotheses from several systems based on different acoustic models .","label":"Motivation","metadata":{},"score":"60.856255"}{"text":"A human error analysis indicates that long - distance reorderings are captured effectively . by Sujan Kumar Saha , Partha Sarathi Ghosh , Sudeshna Sarkar , Pabitra Mitra . \" ...Abstract - Named entities are perhaps the most important indexing element in text for most of the information extraction and mining tasks .","label":"Motivation","metadata":{},"score":"60.956505"}{"text":"We report results for French - English and German - English in both directions .Our submissions use n - code , an open source system based on bilingual n - grams .In this approach , both the translation and target language models are est ... \" .","label":"Motivation","metadata":{},"score":"60.992058"}{"text":"This work presents translation results for the three data sets made available in the shared task Exploiting Parallel Texts for Statistical Machine Translation of the HLT - NAACL 2006 Workshop on Statisti - cal Machine Translation .All results pre - sented were generated by using the N - gram - based statisti ... \" .","label":"Motivation","metadata":{},"score":"61.41646"}{"text":"The use of articulatory features , such as place and manner of articulation , has been shown to reduce the word error rate of speech recognition systems under different conditions and in different settings .For example recognition systems based on features are more robust to noise and reverberation .","label":"Motivation","metadata":{},"score":"61.603107"}{"text":"The use of articulatory features , such as place and manner of articulation , has been shown to reduce the word error rate of speech recognition systems under different conditions and in different settings .For example recognition systems based on features are more robust to noise and reverberation .","label":"Motivation","metadata":{},"score":"61.603107"}{"text":"The low rank component corresponds to a continuous - space ... \" .This work introduces a new maximum entropy language model that decomposes the model parameters into a low rank component that learns regularities in the training data and a sparse component that learns exceptions ( e.g. multiword expressions ) .","label":"Motivation","metadata":{},"score":"61.60317"}{"text":"In recent years , neural network language models ( NNLMs ) have shown success in both peplexity and word error rate ( WER ) compared to conventional n - gram language models .Most NNLMs are trained with one hidden layer .","label":"Motivation","metadata":{},"score":"61.6452"}{"text":"In recent years , neural network language models ( NNLMs ) have shown success in both peplexity and word error rate ( WER ) compared to conventional n - gram language models .Most NNLMs are trained with one hidden layer .","label":"Motivation","metadata":{},"score":"61.6452"}{"text":"In this paper , we extend it with personalization features , address the scalability issues present with large data sets , and test its effectiveness on the Bing Mobile voice - search task .We find that Model M by itself reduce ... \" .","label":"Motivation","metadata":{},"score":"61.70515"}{"text":"Tools . by Josep M. Crego , Marta R. Costa - jussà , José B. Mariño , José A. R. Fonollosa - In Proceedings of the International Workshop on Spoken Language Technology ( IWSLT'05 , 2005 . \" ...This work summarizes a comparison between two approaches to Statistical Machine Translation ( SMT ) , namely Ngram - based and Phrase - based SMT .","label":"Motivation","metadata":{},"score":"61.75589"}{"text":"..he grande Figure 1 : Tuples extraction given a word to word aligned sentence pair .The decoder behaves as a phrase - based SMT decoder , when extracting phrases instead of tuples and using a phrase - based translation model instead of an Ngram - based translation model .","label":"Motivation","metadata":{},"score":"61.959732"}{"text":"Tools . \" ...In ( Chen , 2009 ) , we show that for a variety of language models belonging to the exponential family , the test set cross - entropy of a model can be accurately predicted from its training set cross - entropy and its parameter values .","label":"Motivation","metadata":{},"score":"62.09227"}{"text":"Results on two translation directions are reported , namely from Arabic and Chinese into English , thoroughly explaining all language - related preprocessing and translation schemes .nce , we allow the source words to be reordered before extracting translation units from training sentence pairs by following the word - to - word alignments .","label":"Motivation","metadata":{},"score":"62.16117"}{"text":"Most previous work exploiting unsupervised training data for inferring POS tagging models has focused on semi - supervised methods in the in which the learner is provided w .. \" ...The intersection of tree transducer - based translation models with n - gram language models results in huge dynamic programs for machine translation decoding .","label":"Motivation","metadata":{},"score":"62.394386"}{"text":"The system performs four recognition passes : ( 1 ) bigram recognition with phone - loop - adapted , within - word triphone acoustic models , ( 2 ) lattice generation with transcription - m ... \" .We describe SRI 's large vocabulary conversational speech recognition system as used in the March 2000 NIST Hub-5E evaluation .","label":"Motivation","metadata":{},"score":"62.518322"}{"text":"When this translation model is log - linearly combined with four specific feature functions , state of the art translations are achieved for Spanish - to - English and English - t ... \" .This paper describes a statistical machine trans - lation system that uses a translation model which is based on bilingual n - grams .","label":"Motivation","metadata":{},"score":"62.526955"}{"text":"Systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine translation output , but are often very computationally intensive .The complexity is exponential in the size of individual grammar rules due to arbitrary re - orderings between the two langu ... \" .","label":"Motivation","metadata":{},"score":"62.895107"}{"text":"We describe the two feature combination techniques and compare the experimental results .Experiments performed on the large - vocabulary task VerbMobil II ( German conversational speech ) show that the accuracy of automatic speech recognition systems can be improved by the combination of different acoustic features .","label":"Motivation","metadata":{},"score":"62.950096"}{"text":"This assumption ignores within - speaker correlations which are known to exist .The assumption clearly damages the recognition ability of standard speaker in ... \" .This dissertation addresses the independence of observations assumption which is typically made by today 's automatic speech recognition systems .","label":"Motivation","metadata":{},"score":"62.98368"}{"text":"We use a memory - based classification framework that enables the efficient estimation of these features .Despite the differences between the two supertagging approaches , they give similar improvements .We evaluate the performance of our approach on an English - to - Dutch translation task , and report statistically significant improvements of 4.48 % and 6.3 % BLEU scores in translation quality when adding CCG and LTAG supertags , respectively , as context - informed features .","label":"Motivation","metadata":{},"score":"63.124535"}{"text":"Visual speech information from the speaker 's mouth region has been successfully shown to improve noise robustness of automatic speech recognizers , thus promising to extend their usability in the human computer interface .In this paper , we review the main components of audio - visual automatic speech r ... \" .","label":"Motivation","metadata":{},"score":"63.261757"}{"text":"In this paper , we consider the use of multiple acoustic features of the speech signal for robust speech recognition .We investigate the combination of various auditory based ( Mel Frequency Cepstrum Coefficients , Perceptual Linear Prediction , etc . ) and articulatory based ( voicedness ) features .","label":"Motivation","metadata":{},"score":"63.652115"}{"text":"Ming Lei ( University of Science and Technology of China ) -- \" Minimum Generation Error Training with Weighted Euclidena Distance on LSP for HMM - Based Speech Synthesis \" .Yong Zhao ( Georgia Institute of Technology ) -- \" On Noise Estimation for Robust Speech Recognition Using Vector Taylor Series \" .","label":"Motivation","metadata":{},"score":"63.802723"}{"text":"In this paper , we propose several pruning algorithms for general exponential language models .We show that our best algorithm applied to an exponential n - gram model outperforms existing n - gram model pruning algorithms by up to 0.4 % absolute in speech recognition word - error rate on Wall Street Journal and Broadcast News data sets .","label":"Motivation","metadata":{},"score":"64.213806"}{"text":"We present how a combined application of these models in search and rescoring gives promising results .Experiments are reported on the GALE Chinese - English task with improvements of up to +0.9 % BLEU and-1.5 % TER absolute on a competitive baseline . ... rmance , we will also show the benefit of combining both approaches in order to boost translation quality even more .","label":"Motivation","metadata":{},"score":"64.61488"}{"text":"We propose a novel interpretation of interpolated Kneser - Ney as approxima ... \" .Interpolated Kneser - Ney is one of the best smoothing methods for n - gram language models .Previous explanations for its superiority have been based on intuitive and empirical justifications of specific properties of the method .","label":"Motivation","metadata":{},"score":"65.019516"}{"text":"We show that our best algorithm applied to an exponential n - gram model outperforms existing n - gram model pruning algorithms by up to 0.4 % absolute in speech recognition word - error rate on Wall Street Journal and Broadcast News data sets .","label":"Motivation","metadata":{},"score":"65.06143"}{"text":"Thus , one of the main challenges in large vocabulary continuous speech recognition ( LVCSR ) is recognizing an open vocabulary .In this paper , ... \" .For languages like German and Polish , higher numbers of word inflections lead to high out - of - vocabulary ( OOV ) rates and high language model ( LM ) perplexities .","label":"Motivation","metadata":{},"score":"65.5751"}{"text":"Combination of acoustic features can also be performed by log - linear model combination .The combination of 5 acoustic and language models ( within - word and across - word ac ... . by Sebastian Stüker , Florian Metze , Tanja Schultz , Alex Waibel - in Proc .","label":"Motivation","metadata":{},"score":"65.67342"}{"text":"In a first experiment , using hand selected weights , we examine the feasibility of applying crosslingual and multilingual detectors .The experiments in this work were performed with the JANUS Recognition Toolkit , Version 5 that features the IBIS one pass decoder [ 10].","label":"Motivation","metadata":{},"score":"65.948586"}{"text":"Works .Signal Processing , 2001 . \" ...We compare automatic recognition with human perception of audio - visual speech , in the large - vocabulary , continuous speech recognition ( LVCSR ) domain .Specifically , we study the benefit of the visual modality for both machines and humans , when combined with audio degraded by speech - babble noise at va ... \" .","label":"Motivation","metadata":{},"score":"66.23307"}{"text":"I. . ... has been little work on pruning for exponential ( or maximum entropy ) language models .In this paper , we show how many existing n - gram model pruning algorithms can be viewed as attempting to optimize estimated test set perplexity , and discuss how ideas from these techniques can be ada ...","label":"Motivation","metadata":{},"score":"66.311676"}{"text":"This leads to high out - of - vocabulary ( OOV ) rates and poor language model ( LM ) probabilities in the large vocabulary continuous speech recognition ( LVCSR ) systems .One of the main challeng ... \" .German is a morphologically rich language having a high degree of word inflections , derivations and compounding .","label":"Motivation","metadata":{},"score":"66.56769"}{"text":"But very few attempts were made to develop transliteration systems for Indian languages to English or other languages .We can mention a transliteration system for ... . \" ... Statistical Machine Translation ( SMT ) is based on alignment models which learn from bilingual corpora the word corre - spondences between source and target lan - guage .","label":"Motivation","metadata":{},"score":"66.65003"}{"text":"We just sum over seen stuff .560 Generalized iterativ ...Candidates must be pursuing a degree at a university .Papers will be judged on the basis of quality and need , which will be evaluated by the IEEE Signal Processing Society 's Speech Technical Committee .","label":"Motivation","metadata":{},"score":"66.67079"}{"text":"In ( Emami and Jelinek , 2005 ) a clustering algorithm is ... . ...w these clusterings are obtained and how much refinement is optimal for each pass .Note that unlikely in the parsing scenario Chapter 2 where the projection state space was obvious and we only needed to estimate the pa ... . by Asela Gunawardana , Tim Paek , Christopher Meek - Proc . IUI & apos;10 .","label":"Motivation","metadata":{},"score":"66.83034"}{"text":"Across various encoding schemes , and for multiple language pairs , we show speed - ups of up to 50 times over single - pass decoding while improving BLEU score .Moreover , our entire decoding cascade for trigram language models is faster than the corresponding bigram pass alone of a bigram - to - trigram decoder . \" ... Interpolated Kneser - Ney is one of the best smoothing methods for n - gram language models .","label":"Motivation","metadata":{},"score":"66.95079"}{"text":"This paper describes a statistical machine translation system that uses a translation model which is based on bilingual n - grams .When this translation model is log - linearly combined with four specific feature functions , state of the art translations are achieved for Spanish - to - English and English - to ... \" .","label":"Motivation","metadata":{},"score":"67.00099"}{"text":"Results are presented regarding translation accuracy and computational efficiency , showing significant improvements in translation quality for both translation directions at a very low computational cost .Index Terms - statistical machine translation , reordering , N - gram translation model 1 . .","label":"Motivation","metadata":{},"score":"67.02655"}{"text":"In this paper we describe MARIE , an Ngram - based statistical machine translation decoder .It is implemented using a beam search strategy , with distortion ( or reordering ) capabilities .The underlying translation model is based on an Ngram approach , extended to introduce reordering at the phrase level .","label":"Motivation","metadata":{},"score":"67.172104"}{"text":"Natasha Singh - Miller ( MIT , USA ) -- \" Trigger - Based Language Modeling Using a Loss - Sensitive Perceptron Algorithm \" .Bernd Geiser ( RWTH Aachen University , Germany ) -- \" Backwards Compatible Wideband Telephony in Mobile Networks : CELP Watermarking and Bandwidth Extension \" .","label":"Motivation","metadata":{},"score":"67.28385"}{"text":"Gazetteer lists are often used for the developme ... \" .Abstract - Named entities are perhaps the most important indexing element in text for most of the information extraction and mining tasks .Construction of a Named Entity Recognition ( NER ) system becomes challenging if proper resources are not available .","label":"Motivation","metadata":{},"score":"67.498505"}{"text":"Prepositional phrases are a common source of ambiguity in natural language and many approaches have been devised to resolve this ambiguity automatically .In particular , several different machine learning approaches have now reached accuracy rates of around 84.5 % on the benchmark dataset .","label":"Motivation","metadata":{},"score":"67.786705"}{"text":"For a successful and satisfying interaction , a dialogue participant may align their language to be more like that of their interlocutor .In the first part of this paper , we examine the alignment phenomenon from the viewpoint of personalityrelated , linguistic , sociolinguistic and psycholinguistic research , concluding that some people are stronger aligners than others .","label":"Motivation","metadata":{},"score":"68.164925"}{"text":"Cache models work by interpolating simple language models derived from the recent context with more elaborate , context - independent models .We use the SRILM toolkit [ 28 ] to compute n - gram langua ... \" ...Language modeling is critical and indispensable for many natural language ap - plications such as automatic speech recognition and machine translation .","label":"Motivation","metadata":{},"score":"68.44592"}{"text":"In contrast to previous orde ... \" .The intersection of tree transducer - based translation models with n - gram language models results in huge dynamic programs for machine translation decoding .We propose a multipass , coarse - to - fine approach in which the language model complexity is incrementally introduced .","label":"Motivation","metadata":{},"score":"68.54941"}{"text":".. a top - scoring MT system in the Chinese newswire track of the 2008 NIST evaluation .However , except for ( Fraser and Marcu , 2007b ) , none of these advances in alignment quality has improv ... . \" ...","label":"Motivation","metadata":{},"score":"68.565186"}{"text":"When this translation model is log - linearly combined with four specific feature functions , state of the art translations are achieved for Spanish - to - English and English - to - Spanish translation tasks .Some specific results obtained for the EPPS ( European Parliament Plenary Sessions ) data are presented and discussed .","label":"Motivation","metadata":{},"score":"68.91573"}{"text":"We apply this alignment model to both French - English and Romanian - English language pairs .An exception is Taskar et al .( 2005 ) who presented a word matching model for discriminative alignment which they they were able to solve optimally .","label":"Motivation","metadata":{},"score":"68.99576"}{"text":"Briefly , the system performs a log - linear combination of a translation model and additional feature functio ... \" .This paper provides a description of TALP - Ngram , the tuple - based statistical machine translation system developed at the TALP Research Center of the UPC ( Universitat Politècnica de Catalunya ) .","label":"Motivation","metadata":{},"score":"69.51864"}{"text":"We achieve significant improvements in recognizing OOVs and word error rate reductions for German and Polish LVCSR compared to the conventional full - word approach and state - of - the - art N - gram mixed type hybrid LM .Index Terms : open vocabulary , maximum entropy 1 . .","label":"Motivation","metadata":{},"score":"69.799095"}{"text":"Our best model produces the lowest alignment error rate yet reported on Canadian Hansards bilingual data . ...e probabalistic models developed at IBM by Brown et al .( 1993 ) , sometimes augmented by an HMMbased model or Och and Ney 's \" Model 6 \" ( Och and Ney , 2003 ) . \" ...","label":"Motivation","metadata":{},"score":"69.83876"}{"text":"Motivated by the success of DNNs in acoustic modeling , we explore deep neural network language models ( DNN LMs ) in this paper .Results on a Wall Street Journal ( WSJ ) task demonstrate that DNN LMs offer improvements over a single hidden layer NNLM .","label":"Motivation","metadata":{},"score":"69.917816"}{"text":"Language modeling is critical and indispensable for many natural language ap - plications such as automatic speech recognition and machine translation .Due to the complexity of natural language grammars , it is almost impossible to construct language models by a set of linguistic rules ; therefore statistical techniques have been dominant for language modeling over the last few decades .","label":"Motivation","metadata":{},"score":"70.060196"}{"text":"Kshitiz Kumar ( CMU , USA ) -- \" Environment - Invariant Compensation for Reverberation using Linear Post - Filtering for Minimum Distortion \" .Blaise Thomson ( University of Cambridge , UK ) -- \" Bayesian Update of Dialogue State for Robust Dialogue Systems \" .","label":"Motivation","metadata":{},"score":"70.06999"}{"text":"Translation accuracy and efficency results are reported for the IWSLT 2004 Chinese to English task . byAdrià De Gispert , José B. Mariño , Josep M. Crego - In Proceedings of 9th European Conference on Speech Communication and Technology , 2005 . \" ...","label":"Motivation","metadata":{},"score":"70.19458"}{"text":"In the recent literature the alignment task has frequently been decoupled from the translation task , and assumptions have been made about measuring alignment quality for machine translation which , it turns out , are not justified .In particular , none of the tens of papers published over the last five years has shown that significant decreases in Alignment Error Rate , AER ( Och and Ney , 2003 ) , result in significant increases in translation quality .","label":"Motivation","metadata":{},"score":"70.22606"}{"text":"3.6 Forced Alignments Jane has also pre ... . byLibin Shen , Jinxi Xu , Bing Zhang , Spyros Matsoukas , Ralph Weischedel - In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing , 2008 . \" ...","label":"Motivation","metadata":{},"score":"70.31327"}{"text":"For both machines and humans , we observe approximately a 6 dB effective SNR gain compared to the audio - only performance at 10 dB , however such gains significantly diverge at other SNRs .Furthermore , automatic audio - visual recognition outperforms human audioonly speech perception at low SNRs . by P. Beyerlein , W. Byrne , J. M. Huerta , S. Khudanpur , B. Marthi , J. Morgan , N. Peterek , J. Picone , W. Wang - In Proc .","label":"Motivation","metadata":{},"score":"70.32991"}{"text":"( Mark McLauchlan ) ii Table of Contents 1 . \" ...Abstract - Language model pruning is an essential technology for speech applications running on resource - constrained devices , and many pruning algorithms have been developed for conventional word n - gram models .","label":"Motivation","metadata":{},"score":"70.439964"}{"text":"( 2001 ) present a MaxEnt approach to integrat ... . by Hai - son Le , Thomas Lavergne , Re Allauzen , Marianna Apidianaki , Li Gong , Aurélien Max , Artem Sokolov , Guillaume Wisniewski , François Yvon . \" ...","label":"Motivation","metadata":{},"score":"70.71491"}{"text":"We examine models for unsupervised learning with concave log - likelihood functions .We begin with the most well - known example , IBM Model 1 for word alignment ( Brown et al . , 1993 ) , and study its properties , discussing why other models for unsupervised learning are so seldom concave .","label":"Motivation","metadata":{},"score":"70.869064"}{"text":"We examine models for unsupervised learning with concave log - likelihood functions .We begin with the most well - known example , IBM Model 1 for word alignment ( Brown et al . , 1993 ) , and study its properties , discussing why other models for unsupervised learning are so seldom concave .","label":"Motivation","metadata":{},"score":"70.869064"}{"text":"7sISI - University of Southern California ISI - TR-616 Acknowledgments This work was supporte ... . \" ...Bilingual word alignment forms the foundation of most approaches to statistical machine translation .Current word alignment methods are predominantly based on generative models .","label":"Motivation","metadata":{},"score":"71.11806"}{"text":"Such a scheme is typically implemented by means of the product HM ... . ... in et al . , 2001 ) , achieving a 7 % relative WER reduction over audio - only performance . by Hervé Glotin , Dimitra Vergyri , Chalapathy Neti , Gerasimos Potamianos , Juergen Luettin , 2001 . \" ...","label":"Motivation","metadata":{},"score":"71.157486"}{"text":"We show how these restrictions facilitate the training of the extended lexicon models .We finally evaluate systems that incorporate both types of models with different restrictions on a large - scale translation task for the Arabic - English language pair .","label":"Motivation","metadata":{},"score":"71.325775"}{"text":"This paper provides a description of TALP - Ngram , the tuple - based statistical machine translation system developed at the TALP Research Center of the UPC ( Universitat Politècnica de Catalunya ) .Briefly , the system performs a log - linear combination of a translation model and additional feature functio ... \" .","label":"Motivation","metadata":{},"score":"71.429985"}{"text":"We also consider ensembles of maxent classifiers created using bagging and noisy bagging , a more effective variant where additional random noise is added to each training set .The latter approach creates a more diverse set of classifiers and a maxent ensemble using noisy bagging achieves 85.53 % accuracy .","label":"Motivation","metadata":{},"score":"71.47446"}{"text":"7 Conclusions We have presented a framework for statistical MT for natural languages , which is more general than the widely used source - channel approach .It allows a baseli ... . by Gerasimos Potamianos , Chalapathy Neti , Guillaume Gravier , Ashutosh Garg , Andrew W. Senior - PROC .","label":"Motivation","metadata":{},"score":"71.56319"}{"text":"Triplet lexicon models are related to the well - known IBM-1 model ( Brown et al . , 1993 ) but extend it with a sec ... . \" ...In this paper , we investigate lexicon models for hierarchical phrase - based statistical machine translation .","label":"Motivation","metadata":{},"score":"72.06879"}{"text":"Conf . on Language Resources and Evaluation , LREC'06 , 2006 . \" ...The IBM Models ( Brown et al . , 1993 ) enjoy great popularity in the machine translation community because they offer high quality word alignments and a free implementation is available with the GIZA + + Toolkit ( Och and Ney , 2003 ) .","label":"Motivation","metadata":{},"score":"72.25465"}{"text":"Workshop on Spoken Language Translation , IWSLT'04 . \" ...This paper introduces TALP , a speech - to - speech statisti - cal machine translation system developed at the TALP Research Center ( Barcelona , Spain ) .TALP generates translations by searching for the best scoring path through a Finite - State Transducers ( FSTs ) , which models an X - gram of the bilingual langu ... \" .","label":"Motivation","metadata":{},"score":"73.01874"}{"text":"IEEE Intern .Conf . on Acoustics , Speech , and Signal Processing , 2005 . \" ...In this paper , we consider the use of multiple acoustic features of the speech signal for robust speech recognition .We investigate the combination of various auditory based ( Mel Frequency Cepstrum Coefficients , Perceptual Linear Prediction , etc . ) and articulatory based ( voicedness ) features .","label":"Motivation","metadata":{},"score":"73.238304"}{"text":"This paper investigates why the HMMs es - timated by Expectation - Maximization ( EM ) produce such poor results as Part - of - Speech ( POS ) taggers .We find that the HMMs es - timated by EM generally assign a roughly equal number of word tokens to each hid - den state , while the empirical distribution of tokens ... \" .","label":"Motivation","metadata":{},"score":"73.69331"}{"text":"Tools . by Yang Liu , Qun Liu , Shouxun Lin - in Proceedings of COLING - ACL , 2006 . \" ...We present a novel translation model based on tree - to - string alignment template ( TAT ) which describes the alignment be - tween a source parse tree and a target string .","label":"Motivation","metadata":{},"score":"74.01335"}{"text":"The model is very close to the IBM model 1 and can be seen as an extension of it by taking another word i .. by David Vilar , Daniel Stein , Matthias Huck , Hermann Ney , Lehrstuhl Für Informatik . \" ...","label":"Motivation","metadata":{},"score":"74.03955"}{"text":"I. . ... th gains of up to 1.5 % absolute with heavier pruning .IV .RELATED WORK Here , we discuss previous work on pruning for exponential language models .Count cutoffs are compared with smoothing techniques for exponential n - gram models in [ 2]. \" ...","label":"Motivation","metadata":{},"score":"74.93353"}{"text":"We have incorporated some gazetteer lists in the system to increase the performance of the system .These lists are collected from the web and are in English .To make these English lists useful in the Hindi NER task , we have proposed a two - phase transliteration methodology .","label":"Motivation","metadata":{},"score":"75.04153"}{"text":"OF THE 9TH EUROPEAN CONFERENCE ON SPEECH COMMUNICATION AND TECHNOLOGY , INTERSPEECH'05 , 2005 . \" ...In this paper we describe MARIE , an Ngram - based statistical machine translation decoder .It is implemented using a beam search strategy , with distortion ( or reordering ) capabilities .","label":"Motivation","metadata":{},"score":"75.552414"}{"text":"Each conference or workshop will announce its deadline on its web site .ICASSP 2012 recipients : .Tseung - Wei Tu , ( National Taiwan University ) -- \" Semantic Query Expansion and Contet - Based Discriminative Term Modeling for Spoken Document Retrieval \" .","label":"Motivation","metadata":{},"score":"75.66266"}{"text":"ICASSP 2011 recipients : .Nancy F. Chen , ( MIT ) -- \" Informative dialect recognition using context - dependent pronunciation modeling \" .Afsaneh Asaei ( Ecole Polytechnique Federale de Lausanne ) -- \" Model - based compressive sensing for multi - party distant speech recognition \" .","label":"Motivation","metadata":{},"score":"75.8344"}{"text":"The IBM translation models have been hugely influential in statistical machine translation ; they are the basis of the alignment models used in modern translation systems .Excluding IBM Model 1 , the IBM translation models , and practically all variants proposed in the literature , have relied on the optimization of likelihood functions or similar functions that are non - convex , and hence have multiple local optima .","label":"Motivation","metadata":{},"score":"76.0871"}{"text":"In many resource - poor languages gazetteer lists of proper size are not available , but sometimes relevant lists are available in English .Proper transliteration makes the English lists useful in the NER tasks for such languages .In this paper , we have described a Maximum Entropy based NER system for Hindi .","label":"Motivation","metadata":{},"score":"76.277054"}{"text":"Based on observations from the training data , we build statistical models and therefore , the success of a statistical model is crucially dependent on the training data .In other words , if we do n't have enough data for training , or the training data is not matched with the test data , we are not able to build accurate statistical models .","label":"Motivation","metadata":{},"score":"76.353714"}{"text":"The IBM Models ( Brown et al . , 1993 ) enjoy great popularity in the machine translation community because they offer high quality word alignments and a free implementation is available with the GIZA + + Toolkit ( Och and Ney , 2003 ) .","label":"Motivation","metadata":{},"score":"78.70621"}{"text":"We employed HMM adaptation techniques and Discriminative Model Combination to combine acoustic models from the individual source languages for recognition of speech in the target language .Experiments are described in which Czech Broadcast News is transcribed using acoustic models trained from small amounts of Czech read speech augmented by English , Spanish , Russian , and Mandarin acoustic models . .","label":"Motivation","metadata":{},"score":"78.724655"}{"text":"To translate a source sentence , we first employ a parser to pro - duce a source parse tree and then ap - ply TATs to transform the tree into a tar - get string .Our experiments show that the TAT - based model significantly outper - forms Pharaoh , a state - of - the - art decoder for phrase - based models . .","label":"Motivation","metadata":{},"score":"79.25998"}{"text":"The proposed transliteration based gazetteer preparation methodology is also applicable for other languages .Apart from Hindi , we have applied the transliteration approach in Bengali NER task and also achieved performance improvement .Index Terms - Gazetteer list preparation , named entity recognition , natural language processing , transliteration .","label":"Motivation","metadata":{},"score":"79.646866"}{"text":"Mitchell McLaren ( Queensland University of Technology , Australia ) -- \" Improved SVM Speaker Verification Through Data - Driven Background Dataset Selection \" .Jesus Andrés - Ferrer ( Universidad Politécnica de Valencia , Spain ) -- \" Extensions of absolute discounting ( Kneser - Ney method ) \" .","label":"Motivation","metadata":{},"score":"79.94008"}{"text":"Acknowledgement This work is supported by National High Technology Research and Development Program contract \" Generally Technical Research and Basic Database Establishment of Chinese Platform\"(Subj ... . by Er Fraser Daniel Marcu - In Technical Report ISI - TR-616 . html , ISI / University of Southern California , 2006 . \" ...","label":"Motivation","metadata":{},"score":"80.3406"}{"text":"Pitch class profile vectors that represent harmonic information are extracted from the given audio signal .The resulting chord sequence is obtained by running a Viterbi decoder on trained hidden Markov models and subsequent lattice rescoring , applying the language model weight .","label":"Motivation","metadata":{},"score":"81.142105"}{"text":"( Northeastern University , USA ) -- \" Discriminatively Trained Region Dependent Feature Transforms for Speech Recognition \" .","label":"Motivation","metadata":{},"score":"81.36792"}{"text":"This system has been in development at RWTH for the last two years and has been successfully applied in different machine translation evaluations .It includes extensions to ... \" .We present Jane , RWTH 's hierarchical phrase - based translation system , which has been open sourced for the scientific community .","label":"Motivation","metadata":{},"score":"83.35614"}{"text":"This paper describes TALPtuples , the 2007 N - gram - based statistical machine translation system developed at the TALP Research Center of the UPC ( Universitat Politècnica de Catalunya ) in Barcelona .Emphasis is put on improvements and extensions of the system of previous years .","label":"Motivation","metadata":{},"score":"83.71339"}{"text":"This paper describes TALPtuples , the 2007 N - gram - based statistical machine translation system developed at the TALP Research Center of the UPC ( Universitat Politècnica de Catalunya ) in Barcelona .Emphasis is put on improvements and extensions of the system of previous years .","label":"Motivation","metadata":{},"score":"83.71339"}{"text":"Our approach gives the same level of alignment accuracy as IBM Model 2 . ... ang , 2005 ; Marcu et al . , 2006 ) ) .Excluding IBM Model 1 , the IBM translation models , and practically all variants proposed in the literature , have relied on the optimization of likelihoo ... . by Nadi Tomeh , President Anne , Vilnat Université Paris - sud , Reviewers Eric , Gaussier Université , Joseph Fourier , Université Montréal , Examinator Hermann , Ney Rwth Aachen , Advisor François , Yvon Université Paris - sud , Co - advisor Alex , Re Allauzen Université Paris - sud , 2012 Tools . by Mark Johnson - In : Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ( EMNLP - CoNLL ) .","label":"Motivation","metadata":{},"score":"84.204025"}{"text":"Martin Layton ( University of Cambridge , UK ) -- \" Augmented Statistical Models for Speech Recognition \" .Yi Chen ( National Taiwan University , Taiwan ) -- \" Entropy - based Feature Parameter Weighting for Robust Speech Recognition \" .","label":"Motivation","metadata":{},"score":"85.09772"}{"text":"Soft keyboards offer touch - capable mobile and tabletop devices many advantages such as multiple language support and space for larger graphical displays .On the other hand , because soft keyboards lack haptic feedback , users often produce more typing errors .","label":"Motivation","metadata":{},"score":"85.67235"}{"text":"Soft keyboards offer touch - capable mobile and tabletop devices many advantages such as multiple language support and space for larger graphical displays .On the other hand , because soft keyboards lack haptic feedback , users often produce more typing errors .","label":"Motivation","metadata":{},"score":"85.67235"}{"text":"by Jose ́ B. Mariño , Adria ̀ De Gispert , Rafael E. Banchs , Patrik Lambert , Marta Ruiz , Josep Maŕıa Crego , Jose ́ A. R. Fonollosa - Proc . of the MT Summit X , 2005 . \" ...","label":"Motivation","metadata":{},"score":"85.820305"}{"text":"Some specific results obtained for the EPPS ( Euro - pean Parliament Plenary Sessions ) data are pre - sented and discussed .Finally , future research issues are depicted . by Josep M. Crego , Adrià De Gispert , José B. Mariño - in Proc .","label":"Motivation","metadata":{},"score":"95.424095"}