{"text":"We achieve this result by applying phrasal inversion transduction grammar alignment techniques to character strings to train a character - based translation model , and using this in the phrase - based MT framework .We also propose a look - ahead parsing algorithm and substring - informed prior probabilities to achieve more effective and efficient alignment .","label":"Uses","metadata":{},"score":"32.949883"}{"text":"Summing over all of the possible alignments , we get an equation for the expression we want to maximize ( Equations ( 6 ) and ( 15 ) in Brown et al .( 1993 ) ) .We are left with the problem of estimating the translation probabilities for all pairs of source and target words so that ( 3 ) is maximized .","label":"Uses","metadata":{},"score":"33.633682"}{"text":"By approximating the intractable space of all candidate translations produced by inter - secting an ngram language model with a synchronous grammar , we are able to train and decode models incorporating millions of sparse , heterogeneous features .Further , we demonstrate the power of the discriminative training paradigm by extracting structured syntactic features , and achieving increases in translation performance . \" ...","label":"Uses","metadata":{},"score":"33.688736"}{"text":"In this paper we present a dynamic programming algorithm for GNF rule extraction which efficiently ex - tracts sentence level SCFG rule sets with an arbitrary number of non - terminals .We analyze the performance of the obtained grammar for statistical machine translation on three language pairs . ...","label":"Uses","metadata":{},"score":"34.938293"}{"text":"We model this conversion by an extended treeto - string transducer that have multi - level trees on the source - side , which gives our system m ... \" .A syntax - directed translator first parses the source - language input into a parsetree , and then recursively converts the tree into a string in the target - language .","label":"Uses","metadata":{},"score":"35.27215"}{"text":"This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word - to - word alignments from an MT system , and syntactic structure from parse - trees of source and target language sentences .","label":"Uses","metadata":{},"score":"35.6784"}{"text":"This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word - to - word alignments from an MT system , and syntactic structure from parse - trees of source and target language sentences .","label":"Uses","metadata":{},"score":"35.6784"}{"text":"In ( Tillmann and Zhang , 2006 ) the model is optimized to produce a block orientation and the target sentence is used only for computing a sentence level BLEU .( Liang et al . , 2006 ) demonstrates a dis ... .","label":"Uses","metadata":{},"score":"35.89658"}{"text":"They pose this as an optimization problem and give a greedy algorithm ; the resulting grammar is reliably better under a variety of conditions on a Chinese - English task .Meanwhile , Zhang et al .engineer more efficient STSG decoding for the case in which the source is a parse forest and source units are tree fragments .","label":"Uses","metadata":{},"score":"36.483265"}{"text":"They pose this as an optimization problem and give a greedy algorithm ; the resulting grammar is reliably better under a variety of conditions on a Chinese - English task .Meanwhile , Zhang et al .engineer more efficient STSG decoding for the case in which the source is a parse forest and source units are tree fragments .","label":"Uses","metadata":{},"score":"36.483265"}{"text":"Our expe ... \" .In this paper , we propose a novel string - todependency algorithm for statistical machine translation .With this new framework , we employ a target dependency language model during decoding to exploit long distance word relations , which are unavailable with a traditional n - gram language model .","label":"Uses","metadata":{},"score":"36.515224"}{"text":"Learning these hierarchical , probabilistic devices from parallel corpora constitutes a major challenge , because of multiple latent model variables as well as the risk of data overfitting .This paper presents an effective method for learning a family of particular interest to MT , binary Synchronous Context - Free Grammars with inverted / monotone orientation ( a.k.a .","label":"Uses","metadata":{},"score":"36.93628"}{"text":"We use our theory to introduce a linear algorithm that can be used to derive from word - aligned , parallel corpora the minimal set of syntactically motivated transformation rules that explain human translation data . ...English sentences with a state - of - the - art statistical parser ( Collins , 1999 ) .","label":"Uses","metadata":{},"score":"37.706894"}{"text":"Our results provide the first known empir - ical evidence that lexical semantics are in - deed useful for SMT , despite claims to the contrary . \" ...In this paper , we propose a novel string - todependency algorithm for statistical machine translation .","label":"Uses","metadata":{},"score":"37.728455"}{"text":"We show that our Bayesian model is able to extract minimal set of hierarchical phrase rules without impacting the translation quality as measured by the BLEU score .This paper falls under the latter category and we use a non - parametric Bayesian approach for rule extraction for Hiero - style systems .","label":"Uses","metadata":{},"score":"38.314087"}{"text":"The key contribution is that phrases of many granularities are included directly in the model through the use of a novel formulation that memorizes phrases generated not only by terminal , but also non - terminal symbols .This allows for a completely probabilistic model that is able to create a phrase table that achieves competitive accuracy on phrase - based machine translation tasks directly from unaligned sentence pairs .","label":"Uses","metadata":{},"score":"38.791912"}{"text":"SCFG models are n't completely forgotten : Zhang & Li offer a new twist on reordering in binary - branching SCFG .Given a source parse , we could train a maximum entropy classifier to decide whether any binary production should be inverted ; this requires a lot of computation over sparse vectors .","label":"Uses","metadata":{},"score":"38.812515"}{"text":"SCFG models are n't completely forgotten : Zhang & Li offer a new twist on reordering in binary - branching SCFG .Given a source parse , we could train a maximum entropy classifier to decide whether any binary production should be inverted ; this requires a lot of computation over sparse vectors .","label":"Uses","metadata":{},"score":"38.812515"}{"text":"We frame the MT problem as a decipherment task , treating the foreign text as a cipher for English and present novel methods for training translation models from nonparallel text . ... annel probabilities ( Knight et al . , 2006 ) .","label":"Uses","metadata":{},"score":"38.85584"}{"text":"First , we can incorporate features on phrase pairs , in addition to word links .Second , we can optimize for an extraction - based loss function that relates directly to the end task of generating translations .Our model gives improvements in alignment quality relative to state - of - the - art unsuper - vised and supervised baselines , as well as providing up to a 1.4 improvement in BLEU score in Chinese - to - English trans - lation experiments . ... he history of phrase - based translation as a method for training translation models ( Marcu and Wong , 2002 ) .","label":"Uses","metadata":{},"score":"39.197113"}{"text":"Since in dependency grammar the nodes are words , their QDG model resembles a word - to - word model .Decoding with QDG was not obvious given past work , and is one of several novel contributions of the paper .","label":"Uses","metadata":{},"score":"39.31964"}{"text":"Since in dependency grammar the nodes are words , their QDG model resembles a word - to - word model .Decoding with QDG was not obvious given past work , and is one of several novel contributions of the paper .","label":"Uses","metadata":{},"score":"39.31964"}{"text":"Sentences can then be generated based on such grammar rules with a log - linear model .To acquire such grammar rules automatically in an unsupervised manner , we also propose a novel approach with a generative model , which maps from sub - expressions of logical forms to word sequences in natural language sentences .","label":"Uses","metadata":{},"score":"39.60486"}{"text":"Finally , we show that the best way to exploit source - totarget and target - to - source alignment models is to build two separate systems and combine their output translation lattices . ...n ITG to directly align phrases to nodes in a string - to - tree model .","label":"Uses","metadata":{},"score":"39.80385"}{"text":", 2004 ) does not prevent all non - ITG permutations , and we demonstrate that the hierarchical reordering model can produce analyses during decoding that are inconsistent with analyses made during training .Experimentally , we verify the utility of hierarchical re - ordering , and compare several theoretically - motivated variants in terms of both translation quality and the syntactic complexity of their output . ... their output .","label":"Uses","metadata":{},"score":"39.823174"}{"text":"We also define a direct probability model and use a linear - time dynamic programming algorithm to search for the best derivation .The model is then extended to the general log - linear framework in order to rescore with other features like n - gram language models .","label":"Uses","metadata":{},"score":"39.86933"}{"text":"A growing body of machine translation research aims to exploit lexical patterns ( e.g. , n - grams and phrase pairs ) with gaps ( Simard et al . , 2005 ; Chiang , 2005 ; Xiong et al . , 2011 ) .","label":"Uses","metadata":{},"score":"40.01258"}{"text":"A growing body of machine translation research aims to exploit lexical patterns ( e.g. , n - grams and phrase pairs ) with gaps ( Simard et al . , 2005 ; Chiang , 2005 ; Xiong et al . , 2011 ) .","label":"Uses","metadata":{},"score":"40.01258"}{"text":"In another aspect , a computer - implemented tree generation module may include a predetermined set of decision rules that , when applied to a tree ( e.g. , syntactic or discourse ) corresponding to a source language text segment , generate a tree corresponding to a target language text segment .","label":"Uses","metadata":{},"score":"40.50476"}{"text":"On the algorithmic side , Levenberg & Osborne look at language modeling under the condition that we have unbounded data streams in both source and target language , bounded computation , and the desire to bias our language model towards more recent language use without constantly retraining it .","label":"Uses","metadata":{},"score":"40.73603"}{"text":"On the algorithmic side , Levenberg & Osborne look at language modeling under the condition that we have unbounded data streams in both source and target language , bounded computation , and the desire to bias our language model towards more recent language use without constantly retraining it .","label":"Uses","metadata":{},"score":"40.73603"}{"text":"Our approach is designed to extract rules that are licensed by the word alignments and heuristically extracted phras ... \" .We present a novel approach for extracting a minimal synchronous context - free grammar ( SCFG ) for Hiero - style statistical machine translation using a non - parametric Bayesian framework .","label":"Uses","metadata":{},"score":"40.79008"}{"text":"This is due to the fact that the target side is built inside - out from sub - spans ( Heafield et al . , 2011 , 2013 ) .Watana ... . \" ...Phrase - based translation models usually memorize local translation literally and make independent assumption between phrases which makes it neither generalize well on unseen data nor model sentence - level effects between phrases .","label":"Uses","metadata":{},"score":"41.248596"}{"text":"Phrase - based translation models usually memorize local translation literally and make independent assumption between phrases which makes it neither generalize well on unseen data nor model sentence - level effects between phrases .In this pa - per we present a new method to model correlations between phrases as a Markov model and meanwhile employ a robust smoothing strategy to provide better gen - eralization .","label":"Uses","metadata":{},"score":"41.303387"}{"text":"In this case , the target tree T t will be taken to be the resulting tree of maximum probability .An advantage of such an approach is that it enables the learning of probabilistic transfer functions , H [ ] .","label":"Uses","metadata":{},"score":"41.543007"}{"text":"The use of a word - level alignment and the particular operators described below were chosen for this particular embodiment .However , alternative embodiments using different statistical models may benefit from different or additional operations .The following operators collectively make - up the decoder 's translation engine , and include the following : .","label":"Uses","metadata":{},"score":"41.59794"}{"text":"The probability of a source position being associated with a target position depends only on the length of the target sentence l : ' 1/(l+1 ) ' .Model 1 avoids distortion and fertility probabilities .The probability of an alignment and a source sentence is simply a function of the translation probabilities of corresponding words ( Equation ( 5 ) in Brown et al .","label":"Uses","metadata":{},"score":"41.62092"}{"text":"SMT training : alignment .Given values for the parameters , we can find the best alignment for any two corresponding sentences in the corpus .Given probabilities for alignments for two sentences , we can estimate the translation , fertility , and distortion parameters .","label":"Uses","metadata":{},"score":"41.83827"}{"text":"In the current embodiment , the target tree T t is generated in a sequence of deterministic steps with no recursion or branching .Alternatively , it is possible to associate a probability with each individual step and reconstruct the target tree T t by exploring multiple alternatives at the same time .","label":"Uses","metadata":{},"score":"42.09665"}{"text":"In traditional ITG models , the branches of a biparse tree are generated from a nonterminal distribution , ... . \" ...In this work , we tackle the task of machine translation ( MT ) without parallel training data .We frame the MT problem as a decipherment task , treating the foreign text as a cipher for English and present novel methods for training translation models from nonparallel text .","label":"Uses","metadata":{},"score":"42.344707"}{"text":"This is a hot topic : check out Liu & Gildea 's poster for an alternative Bayesian formulation of the same problem and language pair .Galron et al .look at tree - to - tree STSG ( from a Data - Oriented Parsing perspective ) , with an eye towards discriminatively learning STSG rules to optimize for translation accuracy .","label":"Uses","metadata":{},"score":"42.518936"}{"text":"This is a hot topic : check out Liu & Gildea 's poster for an alternative Bayesian formulation of the same problem and language pair .Galron et al .look at tree - to - tree STSG ( from a Data - Oriented Parsing perspective ) , with an eye towards discriminatively learning STSG rules to optimize for translation accuracy .","label":"Uses","metadata":{},"score":"42.518936"}{"text":"Open - source resource for EBMT .Statistical Machine Translation : the noisy channel model .The noisy channel ( source - channel ) approach ( familiar from speech recognition , used in the IBM models ) : target language sentence ( T ) as a hidden \" source \" for the source language input sentence ( S ) .","label":"Uses","metadata":{},"score":"42.565666"}{"text":"Furthermore , the noisy channel approach does not permit us to weight the different contributions of the language model and the translation model .Since the feature functions can be almost anything we like , they may return any sorts of values , so the sum may also take on any value , positive or negative .","label":"Uses","metadata":{},"score":"42.571053"}{"text":"This flexibility in the mappings dramatically enhances the richness with which relationships between the input and output trees are defined , and further enhances the flexibility of the transfer function H [ ] that is automatically learned .After the training set ( input - output tree pairs and mappings therebetween ) has been generated , the training process next determines in step 1303 the grouping and order of operations that generate a given output tree starting with its paired input tree .","label":"Uses","metadata":{},"score":"43.02378"}{"text":"2 ) on each of the different initial translations in parallel .For example , the greedy decoder code start with an initial , approximate translation selected from among multiple translated phrases stored in a memory .In the end , the best translation could be selected .","label":"Uses","metadata":{},"score":"43.11649"}{"text":"Different methods have been proposed for the alignment at the multiword terms level .However , use of these methods is limited to terms composed of exactly two words in the source and target languages .Some systems eliminating the aforementioned limitation use simple grammars in order to identify multiword terms in each language .","label":"Uses","metadata":{},"score":"43.21649"}{"text":"The resulting system shows substantial improvements in both alignment quality and translation quality over word - based Hidden Markov Models , while maintaining asymptotically equivalent runtime . ...e free parameters from above were tuned to optimize development set BLEU using grid search . 8 Conclusions and Future Work We have described an algorithm for efficient unsupervised alignment of phrases .","label":"Uses","metadata":{},"score":"43.26661"}{"text":"This paper presents a maximum entropy machine translation system using a minimal set of translation blocks ( phrase - pairs ) .The new model is a direct translation model ( DTM ) formulation which allows easy integration of additional / alternative views of both source and target sentences such as segmentation for a source language such as Arabic , part - of - speech of both source and target , etc .","label":"Uses","metadata":{},"score":"43.30173"}{"text":"Coming back to FIG .6 and the operation performed in step 608 , the respective terms corresponding to those preferred links identified in step 606 are extracted from the source and target sentences and stored in memory 312 .The association score corresponding to the term pair is the final value , after the flow optimization , of the flow running in the arc connecting these terms .","label":"Uses","metadata":{},"score":"43.865665"}{"text":"For example , by allowing any arbitrary groupings ( e.g. , one - to - one , one - to - many , many - to - one , many - to - many ) between leaves in the source and target trees , the flexibility , richness and robustness of the resulting mappings are enhanced .","label":"Uses","metadata":{},"score":"43.896805"}{"text":"This paper describes an efficient sampler for synchronous grammar induction under a nonparametric Bayesian prior .Inspired by ideas from slice sampling , our sampler is able to draw samples from the posterior distributions of models for which the standard dynamic programing based sampler proves intra ... \" .","label":"Uses","metadata":{},"score":"44.00926"}{"text":"Translation probabilities .( Note : translation probabilities are represented with t in Brown et al .( 1993 ) and some other SMT papers . )Dealing with differences in word order .Dealing with differences in number of words .","label":"Uses","metadata":{},"score":"44.025352"}{"text":"We present a novel translation model based on tree - to - string alignment template ( TAT ) which describes the alignment be - tween a source parse tree and a target string .A TAT is capable of generating both terminals and non - terminals and per - forming reordering at both low and high levels .","label":"Uses","metadata":{},"score":"44.130577"}{"text":"We present a novel translation model based on tree - to - string alignment template ( TAT ) which describes the alignment be - tween a source parse tree and a target string .A TAT is capable of generating both terminals and non - terminals and per - forming reordering at both low and high levels .","label":"Uses","metadata":{},"score":"44.130577"}{"text":"Related to case - based reasoning in AI .Related to translation memory systems .May store parsed sentences or generalized examples .Relatively theory - neutral ( in comparison to rule - based MT ) .The basic steps .Matching : identify sentence(s ) in database that match the input on the basis of fragments of the input .","label":"Uses","metadata":{},"score":"44.200478"}{"text":"SMT : estimating translation probabilities .There is no analytical solution to the problem of maximizing the left - hand side of Equation ( 3 ) ( see Brown et al .( 1993 ) , p. 271 ) .From Equation ( 2 ) , we can calculate the expression on the right .","label":"Uses","metadata":{},"score":"44.316086"}{"text":"This paper in - troduces two improvements to LR decod - ing that make it comparable in translation quality to CKY - based Hiero . ... t edge of each span , due to the fact that the target side is built inside - out from sub - spans ( Heafield et al . , 2011 ; Heafield et al . , 2013 ) .","label":"Uses","metadata":{},"score":"44.32228"}{"text":"We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .This method requires a source - language dependency parser , target language word segmentation and an unsupervised word alignment component .","label":"Uses","metadata":{},"score":"44.441235"}{"text":", 2004 ) .2 Inferring syntactic transformations We ass ... . \" ...We discuss the relevance of k - best parsing to recent applications in natural language processing , and develop efficient algorithms for k - best trees in the framework of hypergraph parsing .","label":"Uses","metadata":{},"score":"44.52523"}{"text":"We can not use non - local features with current major methods of sequence labeling such as CRFs due to concerns about complexity .We propose a new perceptron algorithm that can use non - local features .Our algorithm allows the use of all types of non - local features whose values are determined from the ... \" .","label":"Uses","metadata":{},"score":"44.550377"}{"text":"We present a statistical machine translation model that uses hierarchical phrases - phrases that contain subphrases .The model is formally a synchronous context - free grammar but is learned from a parallel text without any syntactic annotations .Thus it can be seen as combining fundamental ideas from both syntax - based translation and phrase - based translation .","label":"Uses","metadata":{},"score":"44.680374"}{"text":"But the constraine ... \" .Left - to - right ( LR ) decoding Watanabe et al .( 2006 ) is a promising decoding algorithm for hi - erarchical phrase - based translation ( Hiero ) that visits input spans in arbitrary order producing the output translation in left to right order .","label":"Uses","metadata":{},"score":"45.057022"}{"text":"This leads to far fewer language model calls , but while LR decod - i ... \" .Left - to - right ( LR ) decoding ( Watanabe et al . , 2006 ) is promising decoding algorithm for hierarchical phrase - based translation ( Hiero ) that visits input spans in arbitrary order producing the output translation in left to right order .","label":"Uses","metadata":{},"score":"45.152184"}{"text":"Determining a transfer function between trees of different types further may include , prior to generating the plurality of decision rules , associating one or more features with each of the learning cases based on context .The discourse - structure transfer module may include a plurality of decision rules generated from a training set of source language - target language tree pairs .","label":"Uses","metadata":{},"score":"45.181904"}{"text":"Since SCFG models have become mainstream , there 's been a greater emphasis on decoding .Following a recent strand of research on grammar transformations for SCFG , Xiao et al .observe that , in the space of possible transformations , many will pair source yields with huge numbers of target yields , which compete during decoding and thus result in more search errors .","label":"Uses","metadata":{},"score":"45.20501"}{"text":"Since SCFG models have become mainstream , there 's been a greater emphasis on decoding .Following a recent strand of research on grammar transformations for SCFG , Xiao et al .observe that , in the space of possible transformations , many will pair source yields with huge numbers of target yields , which compete during decoding and thus result in more search errors .","label":"Uses","metadata":{},"score":"45.20501"}{"text":"For arbitrary word - reordering , the decoding problem is NP - complete ( nondeterministic polynomial time complete ) ( Knight , \" Decoding complexity in word - replacement translation models \" , Computational Linguistics , 25(4 ) , 1999 ) .","label":"Uses","metadata":{},"score":"45.361145"}{"text":"Brown et al . , \" The mathematics of statistical machine translation : Parameter estimation \" , Computational Linguistics , 19(2 ) , 1993 , introduced a series of TMs based on word - for - word substitution and re - ordering , but did not include a decoding algorithm .","label":"Uses","metadata":{},"score":"45.482296"}{"text":"Inference in our combined model is not tractable because of numerous edge cycles in the model graph .However , we can emplo ... . \" ...We present a discriminative model that di - rectly predicts which set of phrasal transla - tion rules should be extracted from a sen - tence pair .","label":"Uses","metadata":{},"score":"45.516445"}{"text":"We describe an efficient decoder and show that using these treebased models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser . \" ...Previous work has used monolingual parallel corpora to extract and generate paraphrases .","label":"Uses","metadata":{},"score":"45.526817"}{"text":"This year there 's a lot of work investigating more expressive formalisms .Two papers model translation with restricted variants of synchronous tree - adjoining grammar ( STAG ) .Carreras & Collins model syntax atop phrase pairs with a parser using sister adjunction ( as in their 2008 parser ) .","label":"Uses","metadata":{},"score":"45.539833"}{"text":"This year there 's a lot of work investigating more expressive formalisms .Two papers model translation with restricted variants of synchronous tree - adjoining grammar ( STAG ) .Carreras & Collins model syntax atop phrase pairs with a parser using sister adjunction ( as in their 2008 parser ) .","label":"Uses","metadata":{},"score":"45.539833"}{"text":"The addition of a deterministic permutation parser can provide valuable hierarchical information to a phrase - based statistical machine translation ( PBSMT ) system .Permutation parsers have been used to implement hierarchical re - ordering models ( Galley and Manning , 2008 ) and to enforce inversion trans ... \" .","label":"Uses","metadata":{},"score":"45.551834"}{"text":"The procedure is similar to ( Chiang , 2007 ) except that we maintain tree structures on the target side , instead of strings .We use a statistical CFG parser to parse the English side of the training data , and extract dependency trees with Magerman 's rules ( 1995 ) .","label":"Uses","metadata":{},"score":"45.575172"}{"text":"But the constrained SCFG grammar used in LR - Hiero ( GNF ) with at most two non - terminals is unable to account for some complex phrasal reordering .Allowing more non - terminals in the rules results in a more expressive grammar .","label":"Uses","metadata":{},"score":"45.59928"}{"text":"If a translation system is to produce text that is not only grammatical but also coherent , it will have to ensure that the discourse structure of the target text reflects the natural renderings of the target language , and not that of the source language .","label":"Uses","metadata":{},"score":"45.742493"}{"text":"The model is like IBM Model 1 , except that the source positions are actually substrings of the source instead of single positions .Reasoning over the substring boundaries makes it resemble an HMM , and they use a sparse prior to avoid overfitting .","label":"Uses","metadata":{},"score":"45.758408"}{"text":"The model is like IBM Model 1 , except that the source positions are actually substrings of the source instead of single positions .Reasoning over the substring boundaries makes it resemble an HMM , and they use a sparse prior to avoid overfitting .","label":"Uses","metadata":{},"score":"45.758408"}{"text":"Search state representation : target words generated ( in sequence ) , source words covered , cost accumulated .Cost : combination of current cost and estimated future cost .For each sub - sentence hypothesis , we calculate a probability based on the learned translation , distortion , and fertility parameters and the language model ; this is the current cost .","label":"Uses","metadata":{},"score":"45.827057"}{"text":"2008 , Galley et al .2009 , Gimpel & Smith below , and Hassan et al . in the poster session ) .Decoding is NP - complete , and devising efficient beam search is a key point in the paper .","label":"Uses","metadata":{},"score":"45.95829"}{"text":"2008 , Galley et al .2009 , Gimpel & Smith below , and Hassan et al . in the poster session ) .Decoding is NP - complete , and devising efficient beam search is a key point in the paper .","label":"Uses","metadata":{},"score":"45.95829"}{"text":"We describe a novel leavingone - out approach to prevent ov ... \" .Several attempts have been made to learn phrase translation probabilities for phrasebased statistical machine translation that go beyond pure counting of phrases in word - aligned training data .","label":"Uses","metadata":{},"score":"45.97309"}{"text":"We investigate unsupervised techniques for acquiring monolingual sentence - level paraphrases from a corpus of temporally and topically clustered news articles collected from thousands of web - based news sources .Two techniques are employed : ( 1 ) simple string edit distance , and ( 2 ) a heuristic strategy ... \" .","label":"Uses","metadata":{},"score":"46.164734"}{"text":"We analyze a number of these algorithms in terms of their sentencelevel loss functions , which motivates several new approaches , including a Structured SV ... \" .There has been a proliferation of recent work on SMT tuning algorithms capable of handling larger feature sets than the traditional MERT approach .","label":"Uses","metadata":{},"score":"46.320473"}{"text":"We present Minimum Bayes - Risk ( MBR ) decoding for statistical machine translation .This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .We describe a hierarchy of loss functions that incorporate different levels of l ... \" .","label":"Uses","metadata":{},"score":"46.41484"}{"text":"We present Minimum Bayes - Risk ( MBR ) decoding for statistical machine translation .This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance .We describe a hierarchy of loss functions that incorporate different levels of l ... \" .","label":"Uses","metadata":{},"score":"46.41484"}{"text":"Tools . \" ...We present a statistical machine translation model that uses hierarchical phrases - phrases that contain subphrases .The model is formally a synchronous context - free grammar but is learned from a parallel text without any syntactic annotations .","label":"Uses","metadata":{},"score":"46.502754"}{"text":"No .5,477,451 , 1995 ; Wang et al . , \" Decoding algorithm in statistical machine translation \" , In Proc .ACL , 1997 ) is to examine a large subset of likely decodings and chose just from that .","label":"Uses","metadata":{},"score":"46.54412"}{"text":"Two techniques are employed : ( 1 ) simple string edit distance , and ( 2 ) a heuristic strategy that pairs initial ( presumably summary ) sentences from different news stories in the same cluster .We evaluate both datasets using a word alignment algorithm and a metric borrowed from machine translation .","label":"Uses","metadata":{},"score":"46.75491"}{"text":"6 that the whole process described in said Figure can be iterated several times over the entire corpus of text , in order to improve the final selection of relevant bilingual terms pairs .The basic principle is that the final selection of term pairs resulting from an iteration is bein used to modify the initial conditions of the following iteration .","label":"Uses","metadata":{},"score":"46.933327"}{"text":"Therefore , re - ordering must be modeled and constraine ... . \" ...Left - to - right ( LR ) decoding Watanabe et al .( 2006 ) is a promising decoding algorithm for hi - erarchical phrase - based translation ( Hiero ) that visits input spans in arbitrary order producing the output translation in left to right order .","label":"Uses","metadata":{},"score":"46.983994"}{"text":"In a preferred embodiment of the invention , a so - called grammar of the type \" noun - phrase \" is used to identify potential nodes that are grammatically relevant .In the field of optimization , an arc can be characterized by a capacity and the flow asspcoated to it .","label":"Uses","metadata":{},"score":"46.985"}{"text":"Gimpel & Smith use a relatively new formalism : quasi - synchronous dependency grammar ( QDG ) .In quasi - synchronous grammar , the generation of a target syntax tree is conditioned on ( but not necessarily isomorphic to ) a source syntax tree .","label":"Uses","metadata":{},"score":"47.044853"}{"text":"Gimpel & Smith use a relatively new formalism : quasi - synchronous dependency grammar ( QDG ) .In quasi - synchronous grammar , the generation of a target syntax tree is conditioned on ( but not necessarily isomorphic to ) a source syntax tree .","label":"Uses","metadata":{},"score":"47.044853"}{"text":"We report on investigations into hierarchical phrase - based translation grammars based on rules extracted from posterior distributions over alignments of the parallel text .Rather than restrict rule extraction to a single alignment , such as Viterbi , we instead extract rules based on posterior distributions provided by the HMM word - to - word alignment model .","label":"Uses","metadata":{},"score":"47.050316"}{"text":"For a text having a plurality of sequences of source terms aligned with sequences of target terms , the method is operated successively on each pairs of sequences with the following steps of : . a ) reading a first pair of aligned sequences of source and target terms ; .","label":"Uses","metadata":{},"score":"47.086807"}{"text":"The approach is built on top of a novel reduction - based weighted synchronous context free grammar formalism , which facilitates the trans ... \" .This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus .","label":"Uses","metadata":{},"score":"47.154266"}{"text":"Given the target sentence T , pick a length for the source sentence S .All reasonable lengths are equally likely .For each position j in S , decide how to connect it to T and what source word to place there .","label":"Uses","metadata":{},"score":"47.22686"}{"text":"Before giving you a guided tour through that spectrum , I want to highlight one paper that I found thought - provoking , but hard to classify .Zaidan & Callison - Burch question a basic assumption underlying most machine learning approaches to NLP : that we must optimize on an easily computable approximation to the true loss function .","label":"Uses","metadata":{},"score":"47.314686"}{"text":"We propose a theory that gives formal semantics to word - level alignments defined over parallel corpora .We use our theory to introduce a linear algorithm that can be used to derive from word - aligned , parallel corpora the minimal set of syntactically motivated transformation rules that explain human ... \" .","label":"Uses","metadata":{},"score":"47.413826"}{"text":"2 In what follows we compare two strategies for unsupervised construction of such a corpus , one employing string similarity and the other associating sentences that may overlap very little at the s .. \" ...We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .","label":"Uses","metadata":{},"score":"47.433365"}{"text":"FIG .13 , the first step 1301 is to generate a training set of input - output pairs of trees [ T s , T t ] and a mapping C between leaves each input - output tree pair .The input tree of the pair is of the type from which conversion is desired or , in other words , the source tree type T s .","label":"Uses","metadata":{},"score":"47.585865"}{"text":"We define a paraphrase probability that allows paraphrases extracted from a bilingual parallel corpus to be ranked using translation probabilities , and show how it can be refined to take contextual information into account .We evaluate our paraphrase extraction and ranking methods using a set of manual word alignments , and contrast the quality with paraphrases extracted from automatic alignments . ... ol .","label":"Uses","metadata":{},"score":"47.638638"}{"text":"For example , the set of basic operations that collectively are sufficient to render any input tree into its paired output tree provides a powerful yet compact tool for rewriting tree structures .The details of one or more embodiments are set forth in the accompanying drawings and the description below .","label":"Uses","metadata":{},"score":"47.651024"}{"text":"Experiments on Arabic - to - English translation indicated that a model trained with sparse binary features outperformed a conventional SMT system with a small number of features . ... ing on a small development set - less than 1 K sentences - was sufficient to achieve improved performance .","label":"Uses","metadata":{},"score":"47.681587"}{"text":"Permutation parsers have been used to implement hierarchical re - ordering models ( Galley and Manning , 2008 ) and to enforce inversion transduction grammar ( ITG ) constraints ( Feng et al . , 2010 ) .We present a number of theoretical results regarding the use of permutation parsers in PBSMT .","label":"Uses","metadata":{},"score":"47.75355"}{"text":"Kääriäinen makes this idea central .Instead of reasoning over the latent derivations of a generative model , his model directly optimizes a feature - based representation of the target sentence , where the features consist of any biphrase in the training set ( per standard heuristics ) .","label":"Uses","metadata":{},"score":"47.79803"}{"text":"Kääriäinen makes this idea central .Instead of reasoning over the latent derivations of a generative model , his model directly optimizes a feature - based representation of the target sentence , where the features consist of any biphrase in the training set ( per standard heuristics ) .","label":"Uses","metadata":{},"score":"47.79803"}{"text":"The source text comprises at least one sequence of source terms , a term being composed of at least one word , and the target text comprises at least one sequence of target terms .The system comprises a term extractor means which operates on at least one pair extracted from the aligned texts and consisting of a source sequence aligned with a target sequence .","label":"Uses","metadata":{},"score":"47.85831"}{"text":"We make use of the notion of fractional counts , the number of times we expect to see a given source word and target word together in the corpus . 'Then to get the translation probabilities , we normalize the fractional counts by the total fractional counts over all source words for the target word . '","label":"Uses","metadata":{},"score":"47.89235"}{"text":"Simple matching : look for sentences ' S_i ' containing one or more words matching words in ' S_r ' and in the same positions relative to one another .Category matching : given generalizations over words , look for sentences ' S_i ' containing one or more words or categories that match the words or categories in ' S_r ' and in the same positions relative to one another .","label":"Uses","metadata":{},"score":"48.00316"}{"text":"Of these , some concentrate on evaluating word - alignment , directly such as ( Zhang et al . , 2008 ) or indirectly by evaluating a heuristically trained hierarchical translation system from sampled phras ... . by Baskaran Sankaran , Gholamreza Haffari , Anoop Sarkar - In Proceedings of the Sixth Workshop on SMT , 2011 . \" ...","label":"Uses","metadata":{},"score":"48.075844"}{"text":"Three papers incorporate new feature types into strong baseline translation models , following a recent trend .Shen et al . devise some clever local features using source - side context , derivation span length , and dependency modeling to make impressive improvements on an already impressive baseline system in both Chinese - English and Arabic - English .","label":"Uses","metadata":{},"score":"48.114822"}{"text":"Three papers incorporate new feature types into strong baseline translation models , following a recent trend .Shen et al . devise some clever local features using source - side context , derivation span length , and dependency modeling to make impressive improvements on an already impressive baseline system in both Chinese - English and Arabic - English .","label":"Uses","metadata":{},"score":"48.114822"}{"text":"The alignment corresponding to this translation is shown at the top of .FIG .3 .In step 204 , the decoder estimates the probability of correctness of the current translation , P(c ) .After the initial alignment is generated in step 202 , the greedy decoder tries to improve it in step 206 .","label":"Uses","metadata":{},"score":"48.125954"}{"text":"Accordingly , in a stepwise fashion , starting from the initial gloss , the greedy decoder uses a process loop ( e.g. , as shown in .FIG .2 , steps 206 , 208 , 210 and 214 ) to iterate exhaustively over all alignments that are one operation away from the alignment under consideration .","label":"Uses","metadata":{},"score":"48.18473"}{"text":"In that case , the tree generation method may further include associating one or more features with each of the plurality of learning cases based on context .The associated features may include one or more of the following : operational and discourse features , correspondence - based features , and lexical features .","label":"Uses","metadata":{},"score":"48.248367"}{"text":"To each learning example , a set of features from the following classes was associated : .Operational and discourse features reflect the number of trees in the stack , the input list , and the types of the last five operations .","label":"Uses","metadata":{},"score":"48.362785"}{"text":"DeNeefe & Knight model target - side syntax via synchronous tree insertion grammar ( STIG ) .It 's similar to synchronous tree substitution grammar ( STSG ; previously realized in MT as GHKM ) with added left- and right - adjunction operations to model optional arguments .","label":"Uses","metadata":{},"score":"48.443977"}{"text":"DeNeefe & Knight model target - side syntax via synchronous tree insertion grammar ( STIG ) .It 's similar to synchronous tree substitution grammar ( STSG ; previously realized in MT as GHKM ) with added left- and right - adjunction operations to model optional arguments .","label":"Uses","metadata":{},"score":"48.443977"}{"text":"We propose a new perceptron algorithm that can use non - local features .Our algorithm allows the use of all types of non - local features whose values are determined from the sequence and the labels .The weights of local and non - local features are learned together in the training process with guaranteed convergence .","label":"Uses","metadata":{},"score":"48.531876"}{"text":"As shown in .One type of conventional MT decoder is the \" stack decoder \" such as described in U.S. Pat .No . 5,477,451 ( Brown et al . ) , entitled \" Method and System for Natural Language Translation . \" In a stack decoder , the universe of possible translations are organized into a graph structure and then exhaustively searched until an optimal solution ( translation ) is found .","label":"Uses","metadata":{},"score":"48.68178"}{"text":"In next step 804 , the previous results are used during the network optimization operation performed by the bilingual term extractor .Once bilingual term statistics have been collected for the entire corpus , these can be used to improve the single word statistics in step 808 .","label":"Uses","metadata":{},"score":"48.754364"}{"text":"Syntactic approaches seek to remedy these problems .Second , we propose probability estimates and a training procedure for weighting these rules .We contrast different approaches on real examples , show that our estimates based on multiple derivations favor phrasal re - orderings that are linguistically better motivated , and establish that our larger rules provide a 3.63 BLEU point increase over minimal rules . ... bility models estimated from a large number of derivations favor phrasal re - orderings that are linguistically well motivated .","label":"Uses","metadata":{},"score":"48.81904"}{"text":"If re - ordering is limited to rotations around nodes in a binary tree , then optimal decoding can be carried out by a high - polynomial algorithm ( Wu , \" A polynomial - time algorithm for statistical machine translation \" , In Proc .","label":"Uses","metadata":{},"score":"48.853725"}{"text":"However , as Table 2 shows , these are significant differences between discourse trees at the paragraph and text levels as well .For example , the Position - Independent figures show that only about 62 % of the sentences and only about 53 % of the hierarchical spans built across sentences could be matched between the two corpora .","label":"Uses","metadata":{},"score":"48.9845"}{"text":"6 .Among the term pairs identified in each iteration and stored in step 608 , some term pairs can of course have appeared in several sentence pairs .In the preferred embodiment of the present invention , this score is a function of the number of occurrences of the term pair in aligned sentences , and of the number of occurrences of the individual terms ( source and target ) .","label":"Uses","metadata":{},"score":"49.000908"}{"text":"The termination condition may be the occurrence of a completion of a predetermined number of iterations and/or the lapse of a predetermined amount of time .The MT decoding method may start with an approximate target language translation and iteratively improve the translation with each successive iteration .","label":"Uses","metadata":{},"score":"49.11874"}{"text":"Initial search state : no source words , no target words .Expand a state ( generate new hypotheses ) : select source - language phrases that could yield target - language phrases in the next output position .Hypotheses that overlap are combined ; reduces the search space .","label":"Uses","metadata":{},"score":"49.168983"}{"text":"We show for the first time that incorporating the predictions of a word sense disambigua - tion system within a typical phrase - based statistical machine translation ( SMT ) model consistently improves translation quality across all three different IWSLT Chinese - English test sets , as well as producing st ... \" .","label":"Uses","metadata":{},"score":"49.234642"}{"text":"In addition to the SMT decoder , the toolki ... \" .We describe an open - source toolkit for statistical machine translation whose novel contributions are ( a ) support for linguistically motivated factors , ( b ) confusion network decoding , and ( c ) efficient data formats for translation models and language models .","label":"Uses","metadata":{},"score":"49.470688"}{"text":"As a side effect , the phrase table size is reduced by more than 80 % . ... ase training with forced alignment .idea can be seen in Figure 1 .Since our initial phrases are extracted from the same training data , that we want to align , very long phrases can be found for segmentation .","label":"Uses","metadata":{},"score":"49.4729"}{"text":"Inference can be per - formed via dual decomposition , which reuses the efficient inference algorithms of the direc - tional models .Our bidirectional model en - forces a one - to - one phrase constraint while ac - counting for the uncertainty in the underlying directional models .","label":"Uses","metadata":{},"score":"49.528625"}{"text":"In this paper , we develop generative models of monolingual and parallel text that build sentences using gappy patterns of arbitrary length and with arbitrarily many gaps .We exploit Bayesian nonparametrics and collapsed Gibbs sampling to discover salient patterns in a corpus .","label":"Uses","metadata":{},"score":"49.66308"}{"text":"Yet SMT translation qual - ity still obviously suffers from inaccurate lexical choice .In this paper , we address this problem by investigating a new strat - egy for integrating WSD into an SMT sys - tem , that performs fully phrasal multi - word disambiguation .","label":"Uses","metadata":{},"score":"49.713745"}{"text":"then extract phrases by relaxing standard heuristic constraints .Given a posterior probability for every alignment point , they simply calculate the probability that a phrase would be extracted , and use this as their count in the typical frequency - based estimate .","label":"Uses","metadata":{},"score":"49.72049"}{"text":"then extract phrases by relaxing standard heuristic constraints .Given a posterior probability for every alignment point , they simply calculate the probability that a phrase would be extracted , and use this as their count in the typical frequency - based estimate .","label":"Uses","metadata":{},"score":"49.72049"}{"text":"FIG .5 , obtained with decoders that use a trigram language model , show that the greedy decoding algorithm is an advantageous alternative to the traditional stack decoding algorithm .In contrast , the translation speed increases with at least one order of magnitude .","label":"Uses","metadata":{},"score":"49.96611"}{"text":"the value of a flow running in an arc linking a source node to a target node is defined as the sum of statistical word alignment scores between all words in the source node and all words in the target node .","label":"Uses","metadata":{},"score":"49.992626"}{"text":"Statistical MT has made great progress in the last few years , but current translation models are weak on re - ordering and target language fluency .Syntactic approaches seek to remedy these problems .In this paper , we take the framework for acquiring multi - level syntactic translation rules of ( Galley ... \" .","label":"Uses","metadata":{},"score":"49.99713"}{"text":"Unsupervised word alignment is most often modeled as a Markov process that generates a sentence f conditioned on its translation e. A similar model generating e from f will make different alignment predictions .Statistical machine translation systems combine the pre - dictions of two directional models , typically using heuristic combination procedures like grow - diag - final .","label":"Uses","metadata":{},"score":"50.0"}{"text":"b ) building a network of nodes wherein each node includes at least one term from said first pair of aligned source / target sequences and each combination of adjacent source terms is a source node and each combination of adjacent target terms is a target node of the network ; .","label":"Uses","metadata":{},"score":"50.080616"}{"text":"The optimal flow resulting from the optimization step will designate certain arcs as he most likely links between the source and target terms in these sentences .In order to obtain an optimal flow for the two sentences from which relevant candidate of bilingual term pairs can be extracted , the proposed method makes use of algorithms that optimize flows in networks , such as the one described below with reference to FIG .","label":"Uses","metadata":{},"score":"50.095497"}{"text":"This high degree of general applicability is shown in .FIG .12 shows a block diagram of a specific application for the tree rewriter as a component of a larger system - namely , a discourse - based machine translation system .","label":"Uses","metadata":{},"score":"50.434"}{"text":"For the purpose of compactness , .FIG .14 does not illustrate the effect of ASSIGNTYPE actions .For the same purpose , some lines correspond to more than one action .For the corpus used , in order to enable a discourse - based transfer module to derive any English discourse tree starting from any Japanese discourse tree , it is sufficient to implement : . one SHIFT operation ; .","label":"Uses","metadata":{},"score":"50.452477"}{"text":"While the former is better able to memorize , the latter provides a more principled model that captures dependencies across phrasal boundaries .Some work has been done to combine insights from these two frameworks .A recent successful attempt showed the advantage of using phrasebased search on top of an N - gram - based model .","label":"Uses","metadata":{},"score":"50.494087"}{"text":"The results in Table 6 are averaged over a ten - fold cross - validation experiment .The results in Table 6 show that the model described here outperforms the baseline with respect to building English - like discourse structures for sentences , but it under - performs the baseline with respect to building English - like structures at the paragraph and text levels .","label":"Uses","metadata":{},"score":"50.49724"}{"text":"We discuss the relevance of k - best parsing to recent applications in natural language processing , and develop efficient algorithms for k - best trees in the framework of hypergraph parsing .To demonstrate the efficiency , scalability and accuracy of these algorithms , we present experiments on Bikel 's implementation of Collins ' lexicalized PCFG model , and on Chiang 's CFG - based decoder for hierarchical phrase - based translation .","label":"Uses","metadata":{},"score":"50.709446"}{"text":"i ) selecting scored bilingual terms as relevant candidates .The method of claim 13 , further comprising after step i ) : . j ) using the statistical results of step h ) for each pair of source and target terms to improve the single word statistics for those words which compose said terms ; . k ) updating the association scores used in step d ) according to the results of step j ) ; .","label":"Uses","metadata":{},"score":"50.77883"}{"text":"Instead , most have implicit connections to particular forms of ramp loss .We propose to minimize ramp loss directly and present a training algorithm that is easy to implement and that performs comparably to others .Most notably , our structured ramp loss minimization algorithm , RAMPION , is less sensitive to initialization and random seeds than standard approaches . by Taro Watanabe , Jun Suzuki , Hajime Tsukada , Hideki Isozaki - In Proc . of EMNLP , 2007 . \" ...","label":"Uses","metadata":{},"score":"50.78006"}{"text":"For one algorithm , see Berger et al . , 1996 .For a discussion of and reference to another , see Och and Ney , 2002 .Feature functions can also be functions of other variables , for example , the alignment between 'S ' and ' T ' .","label":"Uses","metadata":{},"score":"50.885124"}{"text":"P(M n ) , for each of the results of the sentence modification operations .That is , the probability for each new resulting translation is determined .At step 210 , the decoder determines whether any of the new translations are better than the current translation by comparing their respective probabilities of correctness .","label":"Uses","metadata":{},"score":"50.993645"}{"text":"On the other hand , we show that the problem of finding an optimal alignment can be ... \" .Many phrase alignment models operate over the combinatorial space of bijective phrase alignments .We prove that finding an optimal alignment in this space is NP - hard , while computing alignment expectations is # P - hard .","label":"Uses","metadata":{},"score":"51.029793"}{"text":"We review well - known algorithms , arguing that they do not optimize the loss functions they are assumed to optimize wh ... \" .This paper seeks to close the gap between training algorithms used in statistical machine translation and machine learning , specifically the framework of empirical risk minimization .","label":"Uses","metadata":{},"score":"51.0991"}{"text":"Decoding : a partial example .SMT : evaluation .Translation output candidate and translation references .For each n - gram in translation , clip the number of occurrences of the n - gram in the candidate by the maximum number of occurrences of the n - gram in the references , and divide this number by the total number of n - grams in the candidate .","label":"Uses","metadata":{},"score":"51.1201"}{"text":"Then they show how to learn the matrix and use it to reorder test sentences prior to translation , improving over the lexicalized reordering model of Moses on German - English .However , most of the new models at EMNLP are syntax - based .","label":"Uses","metadata":{},"score":"51.27623"}{"text":"Then they show how to learn the matrix and use it to reorder test sentences prior to translation , improving over the lexicalized reordering model of Moses on German - English .However , most of the new models at EMNLP are syntax - based .","label":"Uses","metadata":{},"score":"51.27623"}{"text":"2 illustrates a more detailed description of the machine - aided translation system , incorporating the terminology extraction component .FIG .3 is a flowchart illustrating the overall operation of the terminology extraction component .FIG .4 is an illustration of the network built between a pair of bilingual sentences , and the arcs between words or terms in these sentences .","label":"Uses","metadata":{},"score":"51.288277"}{"text":"Step 814 is equivalent to steps 606 through 610 of FIG .6 , and carries out the remaining of the term extraction process .The new set of relevant term pairs selected in step 818 can be ignored in the following iteration .","label":"Uses","metadata":{},"score":"51.372135"}{"text":"However , it is understood that other network flow processes , such as the \" maximum flow \" process , could be used for this purpose .Coming back to FIG .3 , the bilingual word statistics determinator 302 computes statistical scores between individual source words and target works in aligned sentences .","label":"Uses","metadata":{},"score":"51.380955"}{"text":"Furthermore alignment can be processed at different levels of the text depending on the size of the text units that are to be aligned , e.g. it can be done at the level of files , paragraphs , sentences , phrases , multiword terms or even single words .","label":"Uses","metadata":{},"score":"51.41384"}{"text":"After the last sequence is processed , alignment statistics are computed for all the stored bilingual terms according to a scoring function .The final selection of relevant bilingual terms is made according to the result of these alignment statistics .In one such embodiment , the word alignment statistics which enter in the computation of term association scores are updated before the following iteration .","label":"Uses","metadata":{},"score":"51.458275"}{"text":"I 'd like a single number that I can look at .Here are two concrete proposals for what such a number could be ( note : I 'm assuming you 're also going to provide performance numbers at the best possible selection of hyperparameters from development data or cross validation ...","label":"Uses","metadata":{},"score":"51.722557"}{"text":"The process is then iterated until some condition is met ( step 806 ) , as for example after a certain number of iterations of the process .In step 812 , the network building step ( similar to step 604 of FIG .","label":"Uses","metadata":{},"score":"51.736534"}{"text":"( 2009 ) extract rules directly from bilingual chart parses of the parallel corpus without using word alignments .We take a different approach in that we aim to start with ver ... . \" ...Machine transliteration is defined as automatic phonetic translation of names across languages .","label":"Uses","metadata":{},"score":"51.834663"}{"text":"The output of step 1303 is a set of learning cases - one learning case for each input - output tree pair in the training set .In essence , each learning case is an ordered set of extended shift - reduce operations that when applied to an input tree will generate the paired output tree .","label":"Uses","metadata":{},"score":"51.940178"}{"text":"For each of these embodiments , the iterations are carried along until an end criterion is met .The claimed system and method may be used in many areas which may benefit from bilingual words or terms lexicons , including foreign language teaching , multilingual terminological work , multilingual dictionary compiling , human - assisted machine translation , or machine - aided human translation , to name a few .","label":"Uses","metadata":{},"score":"51.99658"}{"text":"We assess these grammars in terms of their expressive power , measured by their ability to align the parallel text from which their rules are extracted , and the quality of the translations they yield .In Chinese - to - English translation , we find that rule extraction from posteriors gives translation improvements .","label":"Uses","metadata":{},"score":"52.15396"}{"text":"d many monolingual source - only and target - only patterns that are similar to those shown in Table 4 .Additionally we noted examples of source words triggering more target - side information than merely one word .There were several examples of patterns that encouraged inclusion of the subject in Engl ... . \" ...","label":"Uses","metadata":{},"score":"52.159332"}{"text":"The use of a set of basic modification operations , each able to be used as a standalone operator or in conjunction with the others , further enhances this flexibility .Moreover , the use of independent standalone operators as constituents of the decoding engine makes the decoder extensible and scalable .","label":"Uses","metadata":{},"score":"52.392296"}{"text":"Word - alignment information can be estimated from alignment models , such as the IBM alignment models ( Brown et al . , 19 ... . by Maryam Siahbani , Anoop Sarkar - In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing , 2014 . \" ...","label":"Uses","metadata":{},"score":"52.524452"}{"text":"Thus , the bilingual term alignment statistics obtained through a first iteration of the whole process of FIG .6 may be used to improve the single word alignment statistics which are used in the optimization step 606 .FIG .8 a shows how this feedback operation is implemented to improve the pocess .","label":"Uses","metadata":{},"score":"52.57069"}{"text":"For example , a threshold score can be determined and those candidates whose score exceeds the threshold are retained as good candidates .It is understood that various other score and threshold functions may be considered for use in steps 612 and 614 .","label":"Uses","metadata":{},"score":"52.68378"}{"text":"Many - to - many methods can be expected to achieve superior results on character - based alignment , as the aligner can use information about substrings , which may correspond to lett ... . \" ...We report on investigations into hierarchical phrase - based translation grammars based on rules extracted from posterior distributions over alignments of the parallel text .","label":"Uses","metadata":{},"score":"52.760593"}{"text":"In step 602 a pair of aligned sentences is input from the bilingual corpus of text 208 .The term \" aligned sentences \" refers to a source sentence and the corresponding translated target sentence .The method for aligning the source text with the target text is independent of the claimed method of the invention , and any known alignment methods may be used .","label":"Uses","metadata":{},"score":"52.764862"}{"text":"Bai et al .focus on the problem of acquiring multiword expressions ( i.e. idioms ) , showing why typical word alignment methods fail , and using a combination of statistical association measures and heuristics to fix the problem , with small gains in Chinese - English .","label":"Uses","metadata":{},"score":"52.801018"}{"text":"Bai et al .focus on the problem of acquiring multiword expressions ( i.e. idioms ) , showing why typical word alignment methods fail , and using a combination of statistical association measures and heuristics to fix the problem , with small gains in Chinese - English .","label":"Uses","metadata":{},"score":"52.801018"}{"text":"SMT : ( phrase - based ) decoding .We ca n't consider all possible target sentences ( if we do , MT is NP - complete ) , so some sort of heuristic is required .Decoding : search for the best target sentence .","label":"Uses","metadata":{},"score":"52.808266"}{"text":"In first step 702 an initial low is sent through the network .In next step 704 , a parallel network associated to the initial one is built .The core of the Klein 's algorithm consists in finding a cycle of arcs having a negative cost in this associated network , which operation is performed in step 706 .","label":"Uses","metadata":{},"score":"52.991646"}{"text":"On average , each text had about 460 words .The Japanese texts had a total of 335 paragraphs and 773 sentences .The English texts had a total of 337 paragraphs and 827 sentences .A discourse annotation protocol was developed for Japanese and English along the lines followed by Marcu et al . , \" Experiments in constructing a corpus of discourse trees , \" In Proc .","label":"Uses","metadata":{},"score":"53.10848"}{"text":"We describe a novel leavingone - out approach to prevent over - fitting that allows us to train phrase models that show improved translation performance on the WMT08 Europarl German - English task .In contrast to most previous work where phrase models were trained separately from other models used in translation , we include all components such as single word lexica and reordering models in training .","label":"Uses","metadata":{},"score":"53.22664"}{"text":"The decoder does n't quite beat Moses when used with a language model , but it 's an order of magnitude faster !Three other papers operate on STSG models , with an emphasis on learning techniques .Cohn & Blunsom reformulate tree - to - string STSG induction as a problem in non - parametric Bayesian inference , extending their TSG model for monolingual parsing , and removing the dependence on heuristics over noisy GIZA++ word alignments .","label":"Uses","metadata":{},"score":"53.422295"}{"text":"The decoder does n't quite beat Moses when used with a language model , but it 's an order of magnitude faster !Three other papers operate on STSG models , with an emphasis on learning techniques .Cohn & Blunsom reformulate tree - to - string STSG induction as a problem in non - parametric Bayesian inference , extending their TSG model for monolingual parsing , and removing the dependence on heuristics over noisy GIZA++ word alignments .","label":"Uses","metadata":{},"score":"53.422295"}{"text":"The numbers in the \" Weighted Average \" line report averages of the Sentence- , Paragraph- , and Text - specific figures , weighted according to the number of units at each level .The numbers in the \" All \" line reflect recall and precision figures computed across the entire trees , with no attention paid to sentence and paragraph boundaries .","label":"Uses","metadata":{},"score":"53.427643"}{"text":"d ) computing an association score for each pair of linked source and target nodes ; .f ) storing the relevant bilingual terms ; . g ) repeating steps a ) to f ) for all pairs of aligned sequences .","label":"Uses","metadata":{},"score":"53.51546"}{"text":"The millions of parameters were tuned only on a small development set consisting of less than 1 K sentences .Experiments on Arabic - to - Engli ... \" .We achieved a state of the art performance in statistical machine translation by using a large number of features with an online large - margin training algorithm .","label":"Uses","metadata":{},"score":"53.542656"}{"text":"2 is a flowchart of the operation of an embodiment of a greedy decoder for performing MT .As shown therein , the first step 200 is to receive an input sentence to be translated .Although in this example , the text segment being translated is a sentence , virtually any other text segment could be used , for example , clauses , paragraphs or entire treatises .","label":"Uses","metadata":{},"score":"53.577988"}{"text":"A few papers combine deep theoretical insight with convincing empirical results .Hopkins & Langmead improve on cube pruning , a popular approximate search technique for structured models with non - local features ( i.e. translation with an integrated language model ) .","label":"Uses","metadata":{},"score":"53.718422"}{"text":"for each position j in the source sentence , pick an associated alignment position in the target sentence ' a_j ' ( based on m , the source language words in the previous positions and the associated alignment positions in the target sentence for the previous positions ) .","label":"Uses","metadata":{},"score":"53.75118"}{"text":"Accordingly , the decoder could be designed to omit one or more of these slower operations in order to speed up decoding , but potentially at the cost of accuracy .Alternatively , or in addition , the decoder could be designed to use different or additional sentence modification operations according to the objectives of the system designer and/or end - user .","label":"Uses","metadata":{},"score":"53.782402"}{"text":"A distributed infrastructure is proposed which we use to train on up to 2 trillion tokens , resulting in language models having up to 300 billion n - grams .It is capable of providing smoothed probabi ... \" .This paper reports on the benefits of largescale statistical language modeling in machine translation .","label":"Uses","metadata":{},"score":"53.78375"}{"text":"The tree generation method further may include automatically determining the one or more decision rules based on a training set , for example , a plurality of input - output tree pairs and a mapping between each of the input - output tree pairs .","label":"Uses","metadata":{},"score":"53.985954"}{"text":"1B shows an example of word - level alignment .FIG .2 shows a flowchart of the operation of an embodiment of the greedy decoder .FIG .3 shows an example of the greedy decoder producing an English translation of a French sentence .","label":"Uses","metadata":{},"score":"54.193974"}{"text":"Rule table interpolation is applicable for different tasks , e.g. domain adaptation .The decoder distinguishes between lexical and coverage pruning and applies reordering constraints for efficiency . ... is an open source machine translation package with a Java implementation of the phrase - based machine translation paradigm .","label":"Uses","metadata":{},"score":"54.343533"}{"text":"As an example application , they perform minimum risk training on a small Chinese - English task , reporting gains in accuracy .For a related paper on minimum risk techniques , see the poster by Pauls et al . .Novel Modeling and Learning Approaches .","label":"Uses","metadata":{},"score":"54.39495"}{"text":"As an example application , they perform minimum risk training on a small Chinese - English task , reporting gains in accuracy .For a related paper on minimum risk techniques , see the poster by Pauls et al . .Novel Modeling and Learning Approaches .","label":"Uses","metadata":{},"score":"54.39495"}{"text":"FIELD OF THE INVENTION .The present application relates to computational linguistics and more particularly to machine translation techniques .More specifically , the present application describes techniques for performing decoding of a source text segment into a target text segment and for rewriting trees from a first linguistic space into another linguistic space .","label":"Uses","metadata":{},"score":"54.42849"}{"text":"Our results show that while both learning algorithms achieve similar results , with the perceptron converging more rapidly , the aggressive update strategy performs significantly worse than the more conservative strategy corroborating Liang et al .( 2006 ) 's findings .","label":"Uses","metadata":{},"score":"54.431896"}{"text":"Inspired by ideas from slice sampling , our sampler is able to draw samples from the posterior distributions of models for which the standard dynamic programing based sampler proves intractable on non - trivial corpora .We compare our sampler to a previously proposed Gibbs sampler and demonstrate strong improvements in terms of both training log - likelihood and performance on an end - to - end translation evaluation .","label":"Uses","metadata":{},"score":"54.510788"}{"text":"French ne voudrais pas voyager par chemin de fer We propose a principled and efficient phraseto - phrase alignment model , useful in machine translation as well as other related natural language processing problems .In a hidden semi - Markov model , word - to - phrase and phraseto - word translations are modeled directly by the system .","label":"Uses","metadata":{},"score":"54.545258"}{"text":"The model is formally a synchronous context - free grammar but is learned from a bitext without any syntactic information .Thus it can be seen as a shift to the formal machinery of ... \" .We present a statistical phrase - based translation model that uses hierarchical phrases- phrases that contain subphrases .","label":"Uses","metadata":{},"score":"54.600296"}{"text":"This functionality is useful both in its standalone form and as a component of a larger system , such as in a discourse - based machine translation system .Moreover , because the tree rewriter described here automatically learns how to rewrite trees from one language into another , the system is easy and convenient to use .","label":"Uses","metadata":{},"score":"54.642006"}{"text":"Press ( 1998 ) , for example , and a tighter integration with the lexicogrammar of the two languages may yield better cues for learning discourse - based translation models .Alternative embodiments of the tree rewriter are possible .For example , probabilities could be incorporated into the tree rewriting procedure .","label":"Uses","metadata":{},"score":"54.716644"}{"text":"Probabilistic phrase - based synchronous grammars are now considered promising devices for statistical machine translation because they can express reordering phenomena between pairs of languages .Learning these hierarchical , probabilistic devices from parallel corpora constitutes a major challenge , b ... \" .","label":"Uses","metadata":{},"score":"54.78482"}{"text":"4 .Bilingual arcs are then established between any node of the source sentence and any node of the target sentence .However , the number and the type of the arcs could vary and be defined as parameters .For example , it is possible to define that no arc is built from those source nodes which represent articles or propositions or other types of source nodes which may be considered as empty words .","label":"Uses","metadata":{},"score":"54.86483"}{"text":"These differences further demonstrate the need and desirability of developing computational models for discourse structure rewriting .Experiment .In order to assess the role of discourse structure in MT , a corpus of discourse trees was manually built for 40 Japanese texts and their corresponding translations .","label":"Uses","metadata":{},"score":"54.97945"}{"text":"( 1994 ) describes a system using linguistic patterns such as \" adjective+noun \" or \" noun+preposition+noun \" that characterize the structure of nominal terms in English and French .While addressing the previous problem , the efficiency of such systems is not maximum and noise is generated because only a small portion of the noun - phrases thus identified turn out to be terms , i.e. units which express a concept of the domain .","label":"Uses","metadata":{},"score":"55.02349"}{"text":"Background for example - based MT .Requires a database of parallel sentences ( the system 's KB ) .Relies on analogy between input sentence ' S_r ' and examples in the database ' S_i , S_j , ... ' : ' S_r ' : : ' T_i , T_j , ... ' : ?","label":"Uses","metadata":{},"score":"55.049"}{"text":"A second contribution concerns devising a lexicalized phrase reordering mechanism that has complimentary strengths to Chiang 's model .The latter conditions reordering decisions on the surrounding lexical context of phrases , whereas our mechanism works with the lexical content of phrase pairs ( akin to standard phrase - based systems ) .","label":"Uses","metadata":{},"score":"55.07038"}{"text":"Learning the Parameters of the Discourse - transfer Model .Each configuration of the transfer model is associated with a learning case .The cases were generated by a program that automatically derived the sequence of actions that mapped the Japanese trees in the corpus into the sibling English trees , using the correspondences at the elementary unit level that were constructed manually .","label":"Uses","metadata":{},"score":"55.22924"}{"text":"Both possibilities of iteration of the process , such as have been described in FIGS . 8 a and 8 b , can be used separately or combined in a single implementation of the invention .Turning now to FIG .9 , an experiment has been carried out with the proposed embodiment of the present invention on a text corpus consisting of 1000 English sentences aligned with their French translation , resulting in a list of 400 selected term pairs .","label":"Uses","metadata":{},"score":"55.25918"}{"text":"We also compare two different update strategies , one where we update towards an oracle translation candidate extracted from an N - best list vs a more aggressive approach in which we update towards an oracle extracted prior to training using a minloss decoder .","label":"Uses","metadata":{},"score":"55.333008"}{"text":"Because the trees compared differ from one language to the other in the number of elementary units , the order of these units , and the way the units are grouped recursively into discourse spans , two types of recall and precision figures were computed .","label":"Uses","metadata":{},"score":"55.371387"}{"text":"For an in - depth discussion of this algorithm see M. Klein , \" A primal method for minimal cost flows , with applications to the assignment and transportation problems \" , Management Science , 14 , 1967 , herein incorporated by reference .","label":"Uses","metadata":{},"score":"55.390503"}{"text":"BREAK operations are used in order to break the edt at the beginning of the input list into a predetermined number of units .These operations are used to ensure that the resulting tree has the same number of edts as T t .","label":"Uses","metadata":{},"score":"55.451996"}{"text":"In this paper , we demonstrate that accurate machine translation is possible without the concept of \" words , \" treating MT as a problem of transformation between character strings .We achieve this result by applying phrasal inversion transduction grammar alignment techniques to character strings to tr ... \" .","label":"Uses","metadata":{},"score":"55.458378"}{"text":"These stochastic decisions , starting with e , result in different choices of f and an alignment of f with e. e is mapped onto a particular pair with probability : .P . a .f .e . )i .","label":"Uses","metadata":{},"score":"55.707687"}{"text":"I love seeing websites that understand the value of providing a quality resource for free .It 's the old what goes around comes around routine . \" ...Unsupervised word alignment is most often modeled as a Markov process that generates a sentence f conditioned on its translation e. A similar model generating e from f will make different alignment predictions .","label":"Uses","metadata":{},"score":"55.709686"}{"text":"We advance the state - of - the - art for discrimi - natively trained machine translation systems by presenting novel probabilistic inference and search methods for synchronous gram - mars .By approximating the intractable space of all candidate translations produced by inter - secting an ngram language model w ... \" .","label":"Uses","metadata":{},"score":"55.89097"}{"text":"Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions . \" ...This paper is based on the work carried out in the framework of the Verbmobil project , which is a limited - domain speech translation task ( German - English ) .","label":"Uses","metadata":{},"score":"55.931858"}{"text":"Alternative embodiments for the greedy decoder are possible .For example , the greedy decoder could start with multiple different initial translations ( e.g. , different variations on the gloss used in step 202 in .FIG .2 ) and then run the greedy decoding algorithm ( i.e. , steps 204 - 214 in .","label":"Uses","metadata":{},"score":"55.946762"}{"text":"FIG .4 is a partial view of a network composed with the nodes of both the source sentence and the target sentence .All the nodes relating to the source sentence are represented in a first area 402 .Similarly , all the possible nodes relating to the target sentence are represented in a second area 404 .","label":"Uses","metadata":{},"score":"55.97789"}{"text":"The example shown in .FIG .6 illustrates the types of structures that may be present in a rhetorical structure tree for a text fragment .The leaves of the tree correspond to elementary discourse units ( \" edus \" ) and the internal nodes correspond to contiguous text spans .","label":"Uses","metadata":{},"score":"56.045902"}{"text":"A ten - fold cross - validation evaluation of the classifier yielded an accuracy of 70.2 % ( ±0.21 ) .In order to better understand the strengths and weaknesses of the classifier , the problem was broken into smaller components .","label":"Uses","metadata":{},"score":"56.10177"}{"text":"Accordingly , the present inventor recognized that an iterative , incremental decoding technique could produce optimal , or near optimal , results while considerably reducing the computational and space requirements .This decoder is referred to herein as a \" greedy \" decoder or , equivalently , as a \" fast decoder .","label":"Uses","metadata":{},"score":"56.270645"}{"text":"The inserted other word may have a high probability of having a zero - value fertility .Determining whether one or more of the modified target language translations represents an improved translation in comparison with the current target language translation may include calculating a probability of correctness for each of the modified target language translations .","label":"Uses","metadata":{},"score":"56.28781"}{"text":"A more detailed discussion of training a tree rewriter follows .In order to learn to rewrite discourse structure trees , a related problem , defined below in Definition 3.1 , is addressed .Solving the problem in definition 3.1 involves , in part , extending the shift - reduce parsing paradigm applied by Mangerman , \" Statistical decision - tree models for parsing , \" In Proc .","label":"Uses","metadata":{},"score":"56.330574"}{"text":"Iteration 2 . ' 21st century SMT .Log - linear model usually replaces the noisy channel model .Phrases , rather than words , are the basic units .Syntax may be incorporated , either in the form of a parser for the source language or as a synchronous grammar that is learned from the corpus .","label":"Uses","metadata":{},"score":"56.46518"}{"text":"The align / extract / MERT pipeline popularized by Moses and other NIST - style systems is incredibly hard to improve , but several papers manage just that .Hermjakob 's word aligner starts from lexical translation parameters learned by a statistical alignment model .","label":"Uses","metadata":{},"score":"56.53621"}{"text":"The align / extract / MERT pipeline popularized by Moses and other NIST - style systems is incredibly hard to improve , but several papers manage just that .Hermjakob 's word aligner starts from lexical translation parameters learned by a statistical alignment model .","label":"Uses","metadata":{},"score":"56.53621"}{"text":"c ) linking each source node ( Si ) with each target node ( Tj ) with an arc ; .d ) computing an association score for each pair of linked source and target nodes ; .e ) selecting at least one arc performed according to a network flow optimization algorithm such that the corresponding source / target linked terms are considered relevant bilingual terms ; .","label":"Uses","metadata":{},"score":"56.57646"}{"text":"Thus , while decoding is a clear - cut optimization task in which every problem instance has a right answer , it is hard to come up with good answers quickly .The following sets forth details of a fast greedy decoder and compares its performance with that of a traditional stack decoder .","label":"Uses","metadata":{},"score":"56.583523"}{"text":"We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models .Compared to the standard practice of intersecting predictions of independently - trained models , joint training provides a 32 % reduction in AER .","label":"Uses","metadata":{},"score":"56.677635"}{"text":"The proposed model outperforms the state - of - the - art EM - based model in the English to Chinese transliteration task .Tools . \" ...Many phrase alignment models operate over the combinatorial space of bijective phrase alignments .","label":"Uses","metadata":{},"score":"56.68946"}{"text":"On Chinese - English this improves decoding speed and ultimately translation accuracy , because the decoder can consider larger fragments much more efficiently .Finally , see Finch & Sumita 's comprehensive poster on bidirectional phrase - based decoding for a huge number of language pairs .","label":"Uses","metadata":{},"score":"56.80713"}{"text":"On Chinese - English this improves decoding speed and ultimately translation accuracy , because the decoder can consider larger fragments much more efficiently .Finally , see Finch & Sumita 's comprehensive poster on bidirectional phrase - based decoding for a huge number of language pairs .","label":"Uses","metadata":{},"score":"56.80713"}{"text":", 2012 ) is developed in C++ and supports phrase - based , hierarchical phrase - based and syntax - based models . \" ...French ne voudrais pas voyager par chemin de fer We propose a principled and efficient phraseto - phrase alignment model , useful in machine translation as well as other related natural language processing problems .","label":"Uses","metadata":{},"score":"56.889725"}{"text":"The mapping C between leaves of an input tree and its paired output tree defines a correspondence between a source text segment and its counterpart target language translation .Available types of mappings between leaves of a Japanese - English input - output pair that can be used are shown in equation ( 4 ) above , wherein j refers to a Japanese text segment and e refers to an English translation of that text segment .","label":"Uses","metadata":{},"score":"56.916573"}{"text":"The term extractor links each source node with each target node , and through a flow optimization method selects relevant links in the resulting network .The whole process can be iterated in order to improve the strength of the bilingual links .","label":"Uses","metadata":{},"score":"57.139816"}{"text":"then show how a mixed - genre system can effectively be adapted for a particular target domain , by using a small amount data to tune weights tied to genre and collection types in the training corpus , again with strong results in Arabic - English .","label":"Uses","metadata":{},"score":"57.272797"}{"text":"then show how a mixed - genre system can effectively be adapted for a particular target domain , by using a small amount data to tune weights tied to genre and collection types in the training corpus , again with strong results in Arabic - English .","label":"Uses","metadata":{},"score":"57.272797"}{"text":"take their previous triplet lexicon model ( a probabilistic feature using an outside source word as additional conditioning context ) and move it from a reranking step into the decoding step , with a nice experimental treatment showing improvements in large - scale Chinese - English and Arabic - English .","label":"Uses","metadata":{},"score":"57.28347"}{"text":"take their previous triplet lexicon model ( a probabilistic feature using an outside source word as additional conditioning context ) and move it from a reranking step into the decoding step , with a nice experimental treatment showing improvements in large - scale Chinese - English and Arabic - English .","label":"Uses","metadata":{},"score":"57.28347"}{"text":"It just runs .What I 'd really like to see in future \" yet another classifier \" papers is an analysis of sensitivity to hyperparameter selection .You could provide graphs and stuff , but these get hard to read .","label":"Uses","metadata":{},"score":"57.309494"}{"text":"Some of the differences between the two discourse trees in .FIGS . 8 and 9 have been traditionally addressed in MT systems at the syntactic level .For example , the re - ordering of units 1 and 2 can be dealt with using only syntactic models .","label":"Uses","metadata":{},"score":"57.355095"}{"text":"Marcu 's discourse annotation tool ( 1999 ) was used in order to manually construct the discourse structure of all Japanese and English texts in the corpus .Ten percent of the Japanese and English texts were rhetorically labeled by two annotators .","label":"Uses","metadata":{},"score":"57.377968"}{"text":"A large scale evaluation over 8 language pairs shows that performance does significantly improve . ... ases .The discontinuous MTUs that span beyond a phrasal length of 6 words are therefore never hypothesized .Acknowledgments We would like to thank the anonymous reviewers for their helpful feedback and suggestions .","label":"Uses","metadata":{},"score":"57.481926"}{"text":"Connecting Theory and Practice .A few papers combine deep theoretical insight with convincing empirical results .Hopkins & Langmead improve on cube pruning , a popular approximate search technique for structured models with non - local features ( i.e. translation with an integrated language model ) .","label":"Uses","metadata":{},"score":"57.600746"}{"text":"Using alignment techniques from phrasebased statistical machine translation , we show how paraphrases ... \" .Previous work has used monolingual parallel corpora to extract and generate paraphrases .We show that this task can be done using bilingual parallel corpora , a much more commonly available resource .","label":"Uses","metadata":{},"score":"57.648716"}{"text":"6 can be improved by iterating the whole process several times over the entire corpus of text .This will be described below with reference to FIGS . 8 a and 8 b. .FIG .7 details the operations performed in block function 606 to achieve a network flow optimization .","label":"Uses","metadata":{},"score":"57.670002"}{"text":"FIG .5 is an illustration of a network representation with two sentences extracted from a telecommunication bilingual corpus of text .The source sentence is composed of the following eleven source English words : . an outstanding operational feature used in FSS telecommunication is multiple access .","label":"Uses","metadata":{},"score":"57.672302"}{"text":"While the former is better able to memorize , the latter provides a more principled model that captures dependencies across phrasal boundaries .Some work has been done to combine insights from these two frameworks .A recent succe ... \" .","label":"Uses","metadata":{},"score":"57.790623"}{"text":"I occasionally feel that my colleagues on far reaches of either side of this spectrum are too dismissive of work on the other side ; we need both if we 're going to improve translation .Outside the Box .Before giving you a guided tour through that spectrum , I want to highlight one paper that I found thought - provoking , but hard to classify .","label":"Uses","metadata":{},"score":"57.854774"}{"text":"FIGS . 8 and 9 is multinuclear .For example , the ELABORATION - OBJECT - ATTRIBUTE - E relation that holds between units 2 and 1 in the English discourse structure corresponds to a restrictive relative .If one knows the mappings at the edu level , one can determine the mappings at the span ( discourse constituent ) level as well .","label":"Uses","metadata":{},"score":"57.9944"}{"text":"A machine translation decoder comprising : . a memory , the memory containing program instructions configured to be executed by a processor ; . a processor able to access and execute the program instructed stored in the memory ; .The decoder of .","label":"Uses","metadata":{},"score":"58.059895"}{"text":"The invention employs statistical techniques , and in particular embodiments allows a probability - based score to be derived to measure the correlation of bilingual word pairs .However , this technique is limited to the alignment of single words , one word in the source language and one word in the target language .","label":"Uses","metadata":{},"score":"58.123062"}{"text":"Pairwise ranking ( Shen et al ., 2004 ; Hopkins and May , ... . \" ...Jointly parsing two languages has been shown to improve accuracies on either or both sides .However , its search space is much bigger than the monolingual case , forcing existing approaches to employ complicated modeling and crude approximations .","label":"Uses","metadata":{},"score":"58.234974"}{"text":"Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions . by Franz Josef Och , Kenji Yamada , Alex Fraser , Daniel Gildea , Viren Jain , et al . , 2004 . \" ...","label":"Uses","metadata":{},"score":"58.31092"}{"text":"Mappings between leaves of input - output tree pairs can be one - to - one , one - to - many , many - to - one , or many - to - many .Automatically determining the one or more decision rules may include determining a sequence of operations that generates an output tree when applied to the paired input tree .","label":"Uses","metadata":{},"score":"58.346943"}{"text":"Performance at a default setting of the hyperparameter .For instance , SVM - light uses something like average inverse norm of the data vectors as the C parameter .Or you could just us 1 , like I do for logreg .","label":"Uses","metadata":{},"score":"58.388763"}{"text":"The differences of our algorithm from these algorithms are as follows .Daumé III and Marcu ( 2005 ) presented the method called LaSO ( Learning as Search Optimization ) , in which intractable exact infe ...I really enjoyed Mark Dredze 's talk at EMNLP on multiclass confidence weighted algorithms , where they take their CW binary predictors and extend them in two ( basically equivalent ) ways to a multiclass / structured setting ( warning : I have n't read the paper ! )","label":"Uses","metadata":{},"score":"58.42199"}{"text":"The system of claim 1 wherein said linking means further comprises means for selecting a group of source nodes not to be linked to target nodes according to predetermined criteria , such as ignoring source nodes already stored in said memory means .","label":"Uses","metadata":{},"score":"58.56907"}{"text":"c ) linking each node consisting of at least one source term with each node consisting of at least one target term ; .d ) computing an association score for each pair of linked source and target nodes ; .e ) selecting at least one link such that the corresponding source / target linked terms are considered relevant bilingual terms ; .","label":"Uses","metadata":{},"score":"58.64238"}{"text":"SMT training : IBM Model 1 .There are too many parameters to estimate on the right - hand side of Equation ( 1 ) , so we need to simplify .IBM Model 1 simplifications : .The probability of the source language length m is a constant ' epsilon ' .","label":"Uses","metadata":{},"score":"58.770576"}{"text":"Because the classifier does not learn correctly which spans to consider paragraphs and which spans not , the recall and precision results at the paragraph and text levels are negatively affected .The poorer results at the paragraph and text levels can be also explained by errors whose effect cumulates during the step - by - step tree - reconstruction procedure ; and by the fact that , for these levels , there is less data to learn from .","label":"Uses","metadata":{},"score":"58.82853"}{"text":"At the sentence level , it is assumed that if , for example , the syntactic structure of a relative clause is translated appropriately ( even though it is not appropriately attached ) , this is better than translating wrongly that clause .","label":"Uses","metadata":{},"score":"58.973137"}{"text":"Check out posters by He & Toutanova , Duan et al . , and Feng et al . to learn the latest techniques .Last but not least , if you need a strategy for language pairs with very little parallel data , the poster by Nakov & Ng will interest you .","label":"Uses","metadata":{},"score":"59.083675"}{"text":"Check out posters by He & Toutanova , Duan et al . , and Feng et al . to learn the latest techniques .Last but not least , if you need a strategy for language pairs with very little parallel data , the poster by Nakov & Ng will interest you .","label":"Uses","metadata":{},"score":"59.083675"}{"text":"TranslateAndInsert ( j , e 1 , e 2 ) .This operation changes the translation of the French word located at position j from e fj into e 1 and simultaneously inserts word e 2 at the position that yields the alignment of highest probability .","label":"Uses","metadata":{},"score":"59.307396"}{"text":"It 's still globally approximate , but exact for the local prediction problem that cube pruning solves ( i.e. , what are the n - best state splits of an item , given the n - best input states from previous deductions ? )","label":"Uses","metadata":{},"score":"59.365253"}{"text":"It 's still globally approximate , but exact for the local prediction problem that cube pruning solves ( i.e. , what are the n - best state splits of an item , given the n - best input states from previous deductions ? )","label":"Uses","metadata":{},"score":"59.365253"}{"text":"Also , the translator chose to re - package the information in the original Japanese sentence into two English sentences .Hence , the mappings in ( 4 ) provide an explicit representation of the way information is re - ordered and re - packaged when translated from Japanese into English .","label":"Uses","metadata":{},"score":"59.45147"}{"text":"Before detailing each component of FIG .3 and the method to operate them , FIGS .4 and 5 are first described as they illustrate the concept of network of the invention .In the present invention , a bilingual pair of aligned sentences is transferred into the bilingual terminology extraction system 205 .","label":"Uses","metadata":{},"score":"59.50048"}{"text":"However for achieving a high performance system , it is possible to ignore some links which are not considered as valid .The selection of those arcs corresponding to valid links is based on a principle which is known in the field of optimization and which consists in finding a minimal - cost flow in a network .","label":"Uses","metadata":{},"score":"59.504784"}{"text":"In addition to the standard pipeline , including phrase extraction and parameter optimization , Jane 2 contains several state - of - the - art extensions and tools .Forced alignment phrase training can considerably reduce rule table size while learning the translation scores in a more principled manner .","label":"Uses","metadata":{},"score":"59.548546"}{"text":"In step 206 of the decoding process , either all of the five sentence modification operations can be used or any subset thereof may be used to the exclusion of the others , depending on the preferences of the system designer and/or end - user .","label":"Uses","metadata":{},"score":"59.611694"}{"text":"If no negative cycle is found ( branch NO ) , which means that the flow is already optimized , the optimization process is ended .If a negative cycle is found , the overall flow is improved by sending the largest possible flow in said negative cycle ( step 710 ) .","label":"Uses","metadata":{},"score":"59.717377"}{"text":"The patient recovered at home .The patient recovered unexpectedly .The patient recovered in two days .Learning generalizations from the database ( Brown , 2001 ) .Given two or more source - language sentences in the database with shared material , find the different parts and the corresponding different parts in the target sentences , and treat these paired segments as a category , representing them in a rewritten database with category labels .","label":"Uses","metadata":{},"score":"59.75317"}{"text":"hrase - based derivation of a particular target sentence .Sentences per hour on a four - core server 20,000 Frequency of optimal solutions found 93.4 % Frequency of ɛ - optimal solutions found 99.2 % Table 1 : The solver , tuned for speed , regularly reports solut ... . \" ...","label":"Uses","metadata":{},"score":"60.040405"}{"text":"On test data extracted by the heuristic strategy , however , performance of the two training sets is similar , with AERs of 13.2 % and 14.7 % respectively .Analysis of 100 pairs of sentences from each set reveals that the edit distance data lacks many of the complex lexical and syntactic alternations that characterize monolingual paraphrase .","label":"Uses","metadata":{},"score":"60.06653"}{"text":"In this ... \" .This paper is based on the work carried out in the framework of the Verbmobil project , which is a limited - domain speech translation task ( German - English ) .In the nal evaluation , the statistical approach was found to perform best among ve competing approaches .","label":"Uses","metadata":{},"score":"60.092068"}{"text":"Using BLEU as a metric of translation accuracy , we find that our system performs significantly better than the Alignment Template System , a state - of - the - art phrasebased system . on accuracy , we find that our system performs significantly better than the Alignment Template System , a state - of - the - art phrasebased system . \" ...","label":"Uses","metadata":{},"score":"60.129265"}{"text":"The method of claim 14 , further comprising after step i ) : . m ) repeating steps a ) to k ) until an end criterion is met , while not taking into account , in the network building step b ) , those node and links associated with terms that have been selected in step i ) of the previous iteration .","label":"Uses","metadata":{},"score":"60.146545"}{"text":"then rhetRelOfTopStackInEngTree EVIDENCE .Table 5 : Rule examples for the Relation - Reduce classifier .Evaluation of the Discourse - based Transfer Module .By applying the General classifier or the other six classifiers successively , one can map any Japanese discourse tree into a tree whose structure comes closer to the natural rendering of English .","label":"Uses","metadata":{},"score":"60.17331"}{"text":"Table 1 above displays average kappa statistics that reflect the reliability of the annotation of elementary discourse units , k u , hierarchical discourse spans , k s , hierarchical nuclearity assignments , k n , and hierarchical rhetorical relation assignments , k r .","label":"Uses","metadata":{},"score":"60.26301"}{"text":"In conjunction with MT research and related areas in computational linguistics , researchers have developed and frequently use various types of tree structures to graphically represent the structure of a text segment ( e.g. , clause , sentence , paragraph or entire treatise ) .","label":"Uses","metadata":{},"score":"60.2845"}{"text":"CREATE - NEXT operations are used , for example , in order to create English ( target language ) discourse constituents that have no correspondent in the Japanese ( source language ) tree .FUSE operations are used in order to fuse the edt at the top of the stack into the tree that immediately precedes it .","label":"Uses","metadata":{},"score":"60.348366"}{"text":"However , it is understood that many other areas will benefit from the claimed system and method of the present invention .BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 is an illustration of a computer system including a machine - aided translation system .","label":"Uses","metadata":{},"score":"60.385887"}{"text":"Tree Rewriter .Almost all conventional MT systems process text one sentence at a time .Because of this limited focus , MT systems generally can not re - group and re - order the clauses and sentences of an input text to achieve the most natural rendering in a target language .","label":"Uses","metadata":{},"score":"60.46796"}{"text":"For the Hansard corpus , we took the human annotation of word alignment ... . \" ...We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models .","label":"Uses","metadata":{},"score":"60.559387"}{"text":"4 , a second triangle ( 404 ) models the target network .Similarly , the base of this triangle is composed with nodes T 1 through Tn representing the n words of the target sentence while its apex represents the ( T 1 TjTn ) sequence of words , i.e. the complete target sentence .","label":"Uses","metadata":{},"score":"60.592773"}{"text":"Recombination : recombine target - language fragments to form output .An example .I have n't read the book that you lent me .Matching .I have n't done the task that you assigned me .Je n'ai pas fait le tâche que tu m'as confié .","label":"Uses","metadata":{},"score":"60.706245"}{"text":"4 , Iteration 3 .In the fourth and final iteration , the decoder applies the translateOneOrTwoWords operation again to change the word \" that \" in the translation to \" it \" , resulting in the final translation solution \" it is not fair \" , having the probabilities shown in .","label":"Uses","metadata":{},"score":"60.81723"}{"text":"The influence of alignment quality on parsing improvement is also worth studying .From a linguistics point of view , we would like to see how linguistics distance affects this approach , e.g. , we sus ... . \" ...Several attempts have been made to learn phrase translation probabilities for phrasebased statistical machine translation that go beyond pure counting of phrases in word - aligned training data .","label":"Uses","metadata":{},"score":"60.83839"}{"text":"The techniques and methods described here may result in a MT decoder that performs with high accuracy , high speed and relatively low computational and space costs .The greedy decoder can be modified as desired to perform a full set of sentence modification operations or any subset thereof .","label":"Uses","metadata":{},"score":"60.840733"}{"text":"It can be fed either by the user when manually inputting translations , or through the bilingual sentence alignment system 204 , or through the automatic translation engine 206 .The bilingual terminology extraction system 205 is connected to the bilingual sentence database 208 for inputting bilingual aligned sentences therefrom .","label":"Uses","metadata":{},"score":"60.921333"}{"text":"4 , Iteration 2 .In the third iteration , the decoder applies the removeWordOfFertility 0 operation and drops one instance of the word \" is \" in the translation , resulting in a new translation solution \" that is not fair \" , having the probabilities shown in .","label":"Uses","metadata":{},"score":"60.980034"}{"text":"SWAP operations swap the edt at the beginning of the input list with an edt found one or more positions to the right .These operations are used for re - ordering discourse constituents .ASSIGNTYPE operations assign one or more of the following types to the tree t the top of the stack : Unit , MultiUnit , Sentence , Paragraph , MultiParagraph , and Text .","label":"Uses","metadata":{},"score":"60.99344"}{"text":"No .5,477,451 to Brown et al . , a test collection of 505 sentences was used , uniformly distributed across the lengths 6 , 8 , 10 , 15 , and 20 .Decoders were evaluated with respect to ( 1 ) speed , and ( 2 ) translation accuracy .","label":"Uses","metadata":{},"score":"61.11927"}{"text":"The differences at the paragraph and text levels have a purely rhetorical explanation .When the recall and precision figures were computed with respect to the nuclearity and relation assignments , the statuses and the rhetorical relations that labeled each pair of spans were also factored in .","label":"Uses","metadata":{},"score":"61.301247"}{"text":"That is , the classifiers were trained on 36 pairs of manually built and aligned discourse structures , and then the learned classifiers were used in order to map 4 unseen Japanese discourse trees into English - like trees .The similarity of the derived trees and the English trees built manually was measured using the metrics discussed above .","label":"Uses","metadata":{},"score":"61.42403"}{"text":"There is not much difference between MIRA ... . by Abraham Ittycheriah , Salim Roukos - In HLT - NAACL 2007 : Main Conference , 2007 . \" ...This paper presents a maximum entropy machine translation system using a minimal set of translation blocks ( phrase - pairs ) .","label":"Uses","metadata":{},"score":"61.60064"}{"text":"Overlapping words in different fragments can help to align those fragments .See que in this example .The positions of the fragments in the target sentences of the translation pairs can give a clue about their position in the final target sentence , especially for long fragments , even when this position is different from the corresponding source language position . '","label":"Uses","metadata":{},"score":"61.615284"}{"text":"An evaluation module calculates correlation scores for pairs of words chosen one from each corpus .Given a pair of text portions ( one in each language ) the evaluation module combines word pair correlation scores to obtain an alignment score for the text portions .","label":"Uses","metadata":{},"score":"61.6226"}{"text":"Advantages of dealing with phrases .Sentences have internal structure .In translation phrasal units in one language correspond to phrasal units in the other language .Languages have massive amounts of partial idiomaticity ; the meaning ( and translation ) of a group of words may not be predictable from the component words and the structure of the phrase .","label":"Uses","metadata":{},"score":"61.624847"}{"text":"All such modifications are encompassed within the following claims .Marcu , \" Building Up Rhetorical Structure Trees \" , Proceedings of the National Convference on Artificial Intelligence and Innovative Applications of Artificial Intelligence Conference , vol .2 , Aug. 4 , 1996 , pp .","label":"Uses","metadata":{},"score":"61.70248"}{"text":"3 , once all pairs of bilingual sentences have been operated through the term extractor 304 , the system has accumulated a number of pairs of candidate terms which have been extracted and stored in memory 312 .It is the role of the bilingual terms statistic determinator 306 to compute statistics for all these term pairs and decide which can be deemed valid terms .","label":"Uses","metadata":{},"score":"61.8811"}{"text":"NULL . ) where the factors separated by x symbols denote fertility , translation , head permutation , non - head permutation , null - fertility , and null - translation probabilities .It is assumed that the language model P(e ) is a smoothed n - gram model of English .","label":"Uses","metadata":{},"score":"61.909344"}{"text":"Iteratively modifying the translation may include incrementally improving the translation with each iteration , for example , by applying one or more modification operations on the translation .The process loop may terminate upon occurrence of a termination condition .The process loop may control the decoding engine to incrementally improve the current target language translation with each iteration .","label":"Uses","metadata":{},"score":"61.98003"}{"text":"JoinWords ( i 1 , i 2 ) .This operation eliminates from the alignment the English word at position i 1 ( or i 2 ) and links the French words generated by e i1 ( or e i2 ) to e i2 ( or e i1 ) .","label":"Uses","metadata":{},"score":"62.109886"}{"text":"N - gram scores are combined using a weighted average of the logarithms of the scores for each n : the geometric mean .Candidate sentences much shorter than the shortest reference sentence are penalized ; the corpus score is multiplied by a brevity penalty factor . receiving as input a text segment in a source language to be translated into a target language ; . generating an initial translation as an initial current target language translation ; . estimating a probability of correctness of the initial translation , the probability based on alignment links between words and phrases in the source language and words and phrases in the target language ; . applying one or more modification operators to the initial current target language translation by a computer to generate one or more modified target language translations ; . estimating a probability of correctness of the one or more modified target language translations , the probability based on alignment links between words and phrases in the source language and words and phrases in the target language ; . setting by the computer a modified target language translation with a higher probability based on the comparison as the modified current target language translation ; and . repeating said applying , said determining and said setting for the modified current target language translation until occurrence of a termination condition and . outputting the modified current target language translation by the computer in response to the occurrence of the termination condition .","label":"Uses","metadata":{},"score":"62.14276"}{"text":"The intermediate nodes represent multiwords and are both apex nodes and base nodes for several sub - triangles .Furthermore , node S 1 S 2 S 3 is also a base node for all sub - triangles built from S 1 S 2 S 3 .","label":"Uses","metadata":{},"score":"62.332333"}{"text":"The process loop may terminate upon a determination that a probability of correctness of a modified translation is no greater than a probability of correctness of a previous translation , and/or upon completion of a predetermined number of iterations ; and/or after lapse of a predetermined period of time .","label":"Uses","metadata":{},"score":"62.53112"}{"text":"DRAWING DESCRIPTIONS .These and other aspects of the invention will now be described in detail with reference to the accompanying drawings , wherein : .FIG .1A shows a block diagram of machine translation from a user 's perspective .","label":"Uses","metadata":{},"score":"62.615334"}{"text":"It was also very enlightening , but that 's another story .Many thanks to Hal for offering this forum to share the results !151 comments : .One thing that bothers me about MT research is the differing baseline strengths , and the less - than - full additivity of improvements ( or their effectiveness being limited to a certain amount of training data ) .","label":"Uses","metadata":{},"score":"62.666813"}{"text":"What is realized in Japanese using a CONTRAST relation can be realized in English using , for example , a COMPARISON OR A CONCESSION relation .FIGS . 8 and 9 present in the style of Mann , supra , the discourse structures of text fragments ( 1 ) and ( 3 ) , above .","label":"Uses","metadata":{},"score":"62.68721"}{"text":"FIGS . 8 and 9 , there are 11 sub - sentential Japanese spans ) .In computing Position - Independent ( P - I ) recall and precision figures , even when a Japanese span \" floated \" during the translation to a position in the English tree , the P - I recall and precision figures were not affected .","label":"Uses","metadata":{},"score":"62.699997"}{"text":"Où est la peinture que Frank nous a prêté ?Alignment / adaptation .I have n't ... the ... that you ... me .Je n'ai pas ... le ... que tu m'as ... .Matching .The problem : Given an input source language sentence ' S_r ' , find one or more translation pairs ' S_i , T_i ' such that ' S_i ' matches ' S_r ' .","label":"Uses","metadata":{},"score":"62.712105"}{"text":"FIG .4 shows another example of the greedy decoder in action in which an acceptable solution is reached in four iterations .As shown therein , the input sentence to be translated is \" ce ne est pas juste .\" The decoder uses the initial gloss \" that not is not fair . \" In the second iteration , the decoder changes the first instance of the word \" not \" in the translation to \" is \" by applying the translateOneOrTwoWords operation , resulting in a new translation solution \" that is not fair \" , having the probabilities shown in .","label":"Uses","metadata":{},"score":"62.71849"}{"text":"The system of claim 6 , wherein said linking means further comprises means for selecting a group of source nodes not to be linked to target nodes according to predetermined criteria .The system of claim 7 , further comprising a word statistics means for computing association scores for each pair of source and target terms wherein said source terms are composed of one word .","label":"Uses","metadata":{},"score":"62.86232"}{"text":"We perform empirical comparisons of eight different tuning strategies , including MERT , in a variety of settings .Among other results , we find that a simple and efficient batch version of MIRA performs at least as well as training online , and consistently outperforms other options . ... oad categories .","label":"Uses","metadata":{},"score":"62.894478"}{"text":"5 illustrates a particular instance of this network for a bilingual pair of specific sentences .FIG .6 is a flowchart illustrating part of the operation of the extraction component .FIG .7 is a flowchart illustrating the operation performed during the flow optimization process .","label":"Uses","metadata":{},"score":"62.91957"}{"text":"Correspondence - based features reflect the nuclearity , rhetorical relations , and types of the Japanese trees that correspond to the English - like partial trees derived up to a given time .Lexical features specify whether the Japanese spans that correspond to the structures derived up to a given time use potential discourse markers , such as dakara ( because ) and no ni ( although ) .","label":"Uses","metadata":{},"score":"62.949215"}{"text":"l ) repeating steps a ) to k ) with the updated single word statistics until an end criterion is met .The method of claim 3 further comprising after step i ) : . m ) repeating steps a ) to k ) until an end criterion is met , while not taking into account , in the network building step b ) , those nodes and links associated with terms that have been selected in step i ) of the previous iteration .","label":"Uses","metadata":{},"score":"62.98922"}{"text":"13 is a flowchart of a procedure for building a tree rewriter .FIG .14 shows an example of incremental tree reconstruction .FIG .15 is a graph of the learning curve for the Relation - Reduce classifier .DETAILED DESCRIPTION .","label":"Uses","metadata":{},"score":"62.99696"}{"text":"For example , the first sentence of the English tree in .FIG .9 can be obtained from the original Japanese sequence by following the sequence of actions ( 5 ) , below , whose effects are shown in .FIG .","label":"Uses","metadata":{},"score":"63.138504"}{"text":"Finally , among the cited problems of each method , none of the previous systems allow for the extraction of a one - to - many term alignment , such as for example the term \" baseband \" in English corresponding to the term \" bande de base \" in French .","label":"Uses","metadata":{},"score":"63.15455"}{"text":"This model provides a general framework without heuristic or restricti ... \" .Machine transliteration is defined as automatic phonetic translation of names across languages .In this paper , we propose synchronous adaptor grammar , a novel nonparametric Bayesian learning approach , for machine transliteration .","label":"Uses","metadata":{},"score":"63.21405"}{"text":"A terminology extraction system which allows for automatic creation of bilingual terminology has a source text which comprises at least one sequence of source terms , aligned with a target text which also comprises at least one sequence of target terms .","label":"Uses","metadata":{},"score":"63.272675"}{"text":"The status and rhetorical relation associated with each edt is undefined .At each step , the transfer module applies an operation that is aimed at building from the units in T s the discourse tree T t .In the context of the discourse - transfer module , 7 types of operations are implemented : .","label":"Uses","metadata":{},"score":"63.61906"}{"text":"The plurality of predefined operations may represent a closed set that includes the shift operation , the reduce operation , the break operation , the create - next operation , the fuse operation , the swap operation and the assignType operation .","label":"Uses","metadata":{},"score":"63.6649"}{"text":"l'accès multiple est une caractéristique d'exploitation très importante des télécommunications du SFS .The arcs 502 , 504 and 506 relate sequences of words in the source and target sentences that are the translation of one another .For example , arc 502 connects the English sequence : . outstanding operational feature . to the French sequence . caractéristique d'exploitation très importante .","label":"Uses","metadata":{},"score":"63.723473"}{"text":"The method of claim 1 further comprising after step g ) the step of : . h ) computing alignment statistics for the stored bilingual terms according to a scoring function ; .i ) selecting scored bilingual terms as relevant candidates .","label":"Uses","metadata":{},"score":"63.730896"}{"text":"Li & Eisner show how to compute a huge number of statistics efficiently over a combinatorially large number of hypotheses represented in a hypergraph .The statistics include expected hypothesis length , feature expectation , entropy , cross - entropy , KL divergence , Bayes risk , variance of hypothesis length , gradient of entropy and Bayes risk , covariance and Hessian matrix .","label":"Uses","metadata":{},"score":"63.742027"}{"text":"Li & Eisner show how to compute a huge number of statistics efficiently over a combinatorially large number of hypotheses represented in a hypergraph .The statistics include expected hypothesis length , feature expectation , entropy , cross - entropy , KL divergence , Bayes risk , variance of hypothesis length , gradient of entropy and Bayes risk , covariance and Hessian matrix .","label":"Uses","metadata":{},"score":"63.742027"}{"text":"The results reported in Table 2 were as a baseline for the model .The baseline corresponds to applying no knowledge of discourse .Table 6 below displays the absolute improvement ( in percentage points ) in recall and precision figures obtained when the General classifier was used to map Japanese trees into English - looking trees .","label":"Uses","metadata":{},"score":"63.74211"}{"text":"Describing the first area 402 , a drawn representation of the source network is illustrated as a triangle in which the base is composed with as many nodes ( S 1 through Sm ) as the number of words in the source sentence .","label":"Uses","metadata":{},"score":"63.75565"}{"text":"Aligning the English phrase to be paraphrased was the German - English section of the Europarl corpus , version 2 ( Koehn , 2002 ) .Because we wanted to test our method independently of the quality of word alignment algorithms , we also developed a gold standard of word alignments for the set of phrases that we wanted to paraphr ... .","label":"Uses","metadata":{},"score":"63.951767"}{"text":"Extraction set mod - els ... \" .We present a discriminative model that di - rectly predicts which set of phrasal transla - tion rules should be extracted from a sen - tence pair .Our model scores extraction sets : nested collections of all the overlap - ping phrase pairs consistent with an under - lying word alignment .","label":"Uses","metadata":{},"score":"64.14267"}{"text":"The Discourse - based Transfer Model .FIG .10 is a block diagram of a tree rewriter in the process of being trained .As shown therein , the tree rewriter 700 takes as input two different types of trees , for example , a tree of type A and another tree of type B , and automatically learns how to rewrite type A trees into type B trees .","label":"Uses","metadata":{},"score":"64.217026"}{"text":"claim 1 wherein the termination condition comprises a determination that a probability of correctness of a modified target language translation is no greater than a probability of correctness of the initial current target language translation .The method of .claim 1 wherein the termination condition comprises a completion of a predetermined number of iterations .","label":"Uses","metadata":{},"score":"64.43042"}{"text":"Put another way , a greedy algorithm typically starts out with an approximate solution and then tries to improve it incrementally until a satisfactory solution is reached .Implementations of the greedy decoder may include various combinations of the following features .","label":"Uses","metadata":{},"score":"64.81178"}{"text":"The first rule accounts for rhetorical mappings in which the order of the nucleus and satellite of an ATTRIBUTION relation is changed when translated from Japanese into English .The second rule was learned in order to map EXAMPLE Japanese satellites into EVIDENCE English satellites .","label":"Uses","metadata":{},"score":"64.96004"}{"text":"Jointly parsing two languages has been shown to improve accuracies on either or both sides .However , its search space is much bigger than the monolingual case , forcing existing approaches to employ complicated modeling and crude approximations .Here we propose a much simpler alternative , bilingually - constrained monolingual parsing , where a source - language parser learns to exploit reorderings as additional observation , but not bothering to build the target - side tree as well .","label":"Uses","metadata":{},"score":"65.02778"}{"text":"A bilingual terminology database 207 which stores the source terms and their appropriate translation is connected to the bilingual terminology extraction system 205 to receive the term pairs .However , it can be fed manually through the bilingual terminology database management system 202 by an operator .","label":"Uses","metadata":{},"score":"65.14693"}{"text":"As noted above , the discourse - structure transfer module 904 is a specific instance of a tree rewriter that has been trained to rewrite trees from the desired input type into the desired output type .More specifically , the discourse - structure transfer module 904 rewrites the discourse structure of the input text so as to reflect a discourse rendering that is natural to the target text .","label":"Uses","metadata":{},"score":"65.17104"}{"text":"However , the TEMPORAL - AFTER relation that holds between units [ 3 ] and [ 4 ] in the Japanese tree is realized as a CONTRAST relation between unit [ 3 ] and span [ 4 , 5 ] in the English tree .","label":"Uses","metadata":{},"score":"65.18974"}{"text":"REDUCE operations pop the two discourse trees located at the top of the stack ; combine them into a new tee updating the statuses and rhetorical relation names of the trees involved in the operation ; and push the new tree on the top of the stack .","label":"Uses","metadata":{},"score":"65.35121"}{"text":"Consider , for example , the Japanese sentence shown in .FIG . 7 ( \" text ( 1 ) \") .The following ( \" text ( 2 ) \") is a word - by - word \" gloss \" of text ( 1 ): . 7 ] In contrast , a two - sentence translation of the Japanese sentence produced by a professional translator ( \" text ( 3 ) \") reads as follows : . 5 ] [ However , it looks as if that prediction will be quickly shattered .","label":"Uses","metadata":{},"score":"65.44623"}{"text":"They span a wider range of values than the Position - Dependent figures , which enables a better characterization of the differences between Japanese and English discourse structures .These figures offer a detailed picture of how discourse structures and relations are mapped from one language to the other across all discourse levels , from sentence to text .","label":"Uses","metadata":{},"score":"65.53655"}{"text":"The confusion matrix for the \" Main Action Type \" classifier ( see Table 4 ) shows that the system has trouble mostly identifying BREAK and CREATE - NEXT actions .The system has difficulty learning what type of nuclearity ordering to prefer ( the \" Nuclearity - Reduce \" classifier ) and what relation to choose for the English - like structure ( the \" Relation - Reduce \" classifier ) .","label":"Uses","metadata":{},"score":"65.628456"}{"text":"4 , Iteration 4 .To determine the performance of the greedy decoder , a series of experiments was performed .In all experiments , decoding was performed using only the top 10 translations of a word , as determined during training , and a list of 1024 words of fertility 0 , which was also extracted automatically from the test corpus .","label":"Uses","metadata":{},"score":"65.75183"}{"text":"That being said , there are many interesting papers at the poster session , so do take a look at them !I occasionally feel that my colleagues on far reaches of either side of this spectrum are too dismissive of work on the other side ; we need both if we 're going to improve translation .","label":"Uses","metadata":{},"score":"65.790115"}{"text":"Finally , the French words are permuted .In permuting , IBM Model 4 distinguishes between French words that are heads ( the leftmost French word generated from a particular English word ) , non - heads ( non - leftmost , generated only by very fertile English words ) , and NULL - generated .","label":"Uses","metadata":{},"score":"65.91092"}{"text":"13 is a flow chart illustrating a process 1300 that can be used to train a tree rewriter to automatically learn the transfer function between two different types of tree structures , e.g. , a tree of type A and a tree of type B. .","label":"Uses","metadata":{},"score":"66.52875"}{"text":"In .FIG .6 , nuclei are represented by straight lines while satellites are represented by arcs .The present inventor recognized that significant differences exist between the rhetorical structures of translations of a text in different languages ( e.g. , Japanese and English ) .","label":"Uses","metadata":{},"score":"66.543"}{"text":"Feature ... \" .We describe a methodology for rapid experimentation in statistical machine translation which we use to add a large number of features to a baseline system exploiting features from a wide range of levels of syntactic representation .Feature . by Thorsten Brants , Ashok C. Popat , Peng Xu , Franz J. Och , Jeffrey Dean - In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning , 2007 . \" ...","label":"Uses","metadata":{},"score":"66.6735"}{"text":"To translate a source sentence , we first employ a parser to pro - duce a source parse tree and then ap - ply TATs to transform the tree into a tar - get string .Our experiments show that the TAT - based model significantly outper - forms Pharaoh , a state - of - the - art decoder for phrase - based models . .","label":"Uses","metadata":{},"score":"66.68507"}{"text":"that : que . do ( does , did , done ): faîre ( fait , AVOIR fait , fait ) .It is possible to learn a primitive bilingual dictionary from the corpus .Recombination .Given the target sentence fragments from the matched translation pairs , assemble the fragments into the complete target sentence .","label":"Uses","metadata":{},"score":"66.752556"}{"text":"This operation changes the translation of one or two French words , those located at positions j 1 and j 2 , from ef j1 and ef j2 into e 1 and e 2 .If ef j is a word of fertility 1 and e k is NULL , then ef j is deleted from the translation .","label":"Uses","metadata":{},"score":"66.853546"}{"text":"4 shows an example of output that a user sees as the greedy decoder produces an English translation of a French sentence .FIG .5 is a table showing a comparison between different decoders using a trigram language model .FIG .","label":"Uses","metadata":{},"score":"66.94246"}{"text":"Abstract .A terminology extraction system which allows for automatic creation of bilingual terminology has a source text which comprises at least one sequence of source terms , aligned with a target text which also comprises at least one sequence of target terms .","label":"Uses","metadata":{},"score":"67.045334"}{"text":"Details of step 1305 are discussed below under the heading \" Learning the parameters of the discourse - transfer model .\" Details of step 1307 are discussed below under the heading \" Learning the parameters of the discourse - transfer model .","label":"Uses","metadata":{},"score":"67.06065"}{"text":"Details of a discourse parser that can be used as discourse parser 902 are set forth in Daniel Marcu , \" A Decision - Based Approach to Rhetorical Parsing , \" Proceedings of ACL'99 ( 1999 ) , which is incorporated herein .","label":"Uses","metadata":{},"score":"67.416855"}{"text":"S_1 ' : I do n't know where it went . 'T_1 ' : የት እንደሄደ አላውቕም። ' S_2 ' : She did n't say where it went . 'T_2 ' : የት እንደሄደ አልነገረችም። .At the boundaries between fragments there may be errors due to distinctions made in the target language but not made in the source language ( boundary friction ) ; see the translation of the in this example , which in French varies with the gender of the noun .","label":"Uses","metadata":{},"score":"67.496"}{"text":"In step 610 , a test is performed to determine if there is another sentence pair to be analyzed .If it is the case the process loops back to step 602 ( branch YES ) , otherwise all pair of sentences have been analyzed and the process proceeds to step 612 ( branch NO ) .","label":"Uses","metadata":{},"score":"67.61572"}{"text":"( Span [ 1 , 6 ] subsumes 2 sentences , so it is not sub - sentential . )The Japanese discourse tree has only 4 spans that could be matched in the same positions with English spans , namely spans [ 1 , 2 ] , [ 4 ] , [ 5 ] , and [ 1 , 5 ] .","label":"Uses","metadata":{},"score":"67.68496"}{"text":"The patient recovered recovered unexpectedly . ...The patient recovered recovered in two days .Alignment .With no other knowledge , we have to rely on what is shared between multiple pairs of sentences .I have n't done the task that you assigned me .","label":"Uses","metadata":{},"score":"67.77843"}{"text":"FIG .9 is a sample of bilingual term pairs obtained in an experimental implementation of the invention .DETAILED DESCRIPTION OF THE INVENTION .Referring now to the drawings , and more particularly to FIG .1 , an environment in which a preferred embodiment of the present invention operates is illustrated .","label":"Uses","metadata":{},"score":"67.929115"}{"text":"For the purpose of comparison , each classifier is paired with a majority baseline .The results in Table 3 show that the most difficult subtasks to learn are that of determining the number of units a Japanese unit should be broken into and that of determining the distance to the unit that is to be swapped .","label":"Uses","metadata":{},"score":"68.24706"}{"text":"by Graham Neubig , Taro Watanabe , Eiichiro Sumita , Shinsuke Mori , Tatsuya Kawahara . \" ...We present an unsupervised model for joint phrase alignment and extraction using nonparametric Bayesian methods and inversion transduction grammars ( ITGs ) .The key contribution is that phrases of many granularities are included directly in the model through the use of a novel formulation that memori ... \" .","label":"Uses","metadata":{},"score":"68.29898"}{"text":"It is capable of providing smoothed probabilities for fast , single - pass decoding .We introduce a new smoothing method , dubbed Stupid Backoff , that is inexpensive to train on large data sets and approaches the quality of Kneser - Ney Smoothing as the amount of training data increases . ... oblem of machine translation is to automatically produce a target - language ( e.g. , English ) translation ê . \" ...","label":"Uses","metadata":{},"score":"68.383896"}{"text":"This paper investigates the task of training discriminatively a phrase based SMT system with millions of features using the structured perceptron and the Margin Infused Relax Algorithm ( MIRA ) , two popular online learning algorithms .We also compare two different update strategies , one where we updat ... \" .","label":"Uses","metadata":{},"score":"68.63347"}{"text":"Matching : some problems .They gave up the plan that was proposed .They gave up the plan .They gave the plan up .They gave it up .Varying gap lengths between matched elements .They approved the recommendation .","label":"Uses","metadata":{},"score":"68.70117"}{"text":"They ask : why not optimize for human judgement ?How hard is this exactly ?I would say , in terms of this scale of loss functions , that their metric is a 2 .Yet , it turns out to be cheap and fast to compute .","label":"Uses","metadata":{},"score":"68.75128"}{"text":"Our evaluation shows an 1.1 - 3.2 % BLEU improvement over competitive baselines for Chinese - English and Arabic - English translation .Tools . by Hieu Hoang , Alexandra Birch , Chris Callison - burch , Richard Zens , Marcello Federico , Nicola Bertoldi , Chris Dyer , Brooke Cowan , Wade Shen , Christine Moran , Ondřej Bojar , Alexandra Constantin , Evan Herbst , 2007 . \" ...","label":"Uses","metadata":{},"score":"69.146545"}{"text":"The word alignment in .FIG .1B is shorthand for a hypothetical stochastic process by which an English string gets converted into a French string .There are several sets of decisions to be made .First , every English word is assigned a fertility .","label":"Uses","metadata":{},"score":"69.23677"}{"text":"How hard is this exactly ?I would say , in terms of this scale of loss functions , that their metric is a 2 .Yet , it turns out to be cheap and fast to compute .The paper does n't report results of an actual optimization run , but it 's in the works ... hopefully you 'll learn more at the conference .","label":"Uses","metadata":{},"score":"69.333405"}{"text":"FIG .12 translates the entire text as whole , potentially resulting in a translation that has a different number and/or arrangement of sentences than the original , but which better captures the underlying discourse , or rhetoric , of the original text .","label":"Uses","metadata":{},"score":"69.4179"}{"text":"Various peripheral components may be connected to the computer platform 104 , such as a terminal 126 , a data storage device 130 , and a printing device 134 .Those skilled in the art will readily understand that the invention may be implemented within other systems without many changes .","label":"Uses","metadata":{},"score":"69.55862"}{"text":"Whether this is actually true or not , I have this gut feeling that logreg is much less sensitive to hyperparameter selection than are SVMs .This is not at all based on any science , and the experience that it 's based on it somewhat unfair ( comparing megam to libSVM , for instance , which use very different optimization methods , and libSVM does n't do early stopping while megam does ) .","label":"Uses","metadata":{},"score":"70.161995"}{"text":"In other words , here 's a caricature of how I believe logreg and SVM behave : .That is , if you really tune the regularizer ( lambda ) well , then SVMs will win out .But for the majority of the settings , they 're either the same or logreg is a bit better .","label":"Uses","metadata":{},"score":"70.53935"}{"text":"Phrases .Training word - word alignments in both directions .Combining the results of both alignments : union , intersection , smarter combination .Consistent phrase pair : all words aligned only with one another , not with any phrase - external words .","label":"Uses","metadata":{},"score":"71.13344"}{"text":"The method of .claim 1 wherein applying one or more modification operators comprises applying two or more of the following : ( i ) .The method of .claim 1 wherein estimating a probability of correctness of the one or more modified target language translations comprises calculating a probability of correctness for each of the one or more modified target language translations .","label":"Uses","metadata":{},"score":"71.41007"}{"text":"15 shows a typical learning curve , the one that corresponds to the \" Reduce Relation \" classifier .The learning curves suggest that more training data may improve performance .However , they also suggest that better features may be needed in order to improve performance significantly .","label":"Uses","metadata":{},"score":"71.44159"}{"text":"Those skilled in the art will recognize that the present invention is applicable with other optimization algorithms .The example algorithm cited in the present invention is for illustrative purposes only and is not intended to be exhaustive or to limit the invention .","label":"Uses","metadata":{},"score":"71.61972"}{"text":"FIG .1B ) .A word alignment assigns a single home ( English string position ) to each French word .If two French words align to the same English word , then that English word is said to have a fertility of two .","label":"Uses","metadata":{},"score":"71.62313"}{"text":"Each node is characterized by a status ( NUCLEUS or SATELLITE ) and a rhetorical relation , which is a relation that holds between two non - overlapping text spans .The distinction between nuclei and satellites comes from the empirical observation that the nucleus expresses what is more essential to the writer 's intention than the satellite ; and that the nucleus of a rhetorical relation is comprehensible independent of the satellite , but not vice versa .","label":"Uses","metadata":{},"score":"71.650475"}{"text":"As the experiments described below demonstrate , the greedy decoder can produce translations faster than any other decoder .The greedy decoder is an instance of an \" anytime algorithm\"-the longer it runs , the better the translation it finds .One potential tradeoff of the greedy decoder relates to the size of the solution space that it explores , which is relatively small .","label":"Uses","metadata":{},"score":"72.038635"}{"text":"In the past , this process was a manual operation performed by human terminologists in order to build terminology databases .The automation of such a process is commonly referred to as alignment .Alignment is usually performed through statistical methods .","label":"Uses","metadata":{},"score":"72.13539"}{"text":"Initial experimental results on English - to - Chinese translation are presented . ... , respectively , and get the completed Chinese string in ( e ) . \" ...We present Jane 2 , an open source toolkit supporting both the phrase - based and the hierarchical phrase - based paradigm for statistical machine translation .","label":"Uses","metadata":{},"score":"72.240555"}{"text":"The annotation procedure yielded over the entire corpus 2641 Japanese edus and 2363 English edus .The reliability of the annotation was computer using Marcu et al .( 1999 ) 's method for computing kappa statistics ( Siegel et al .","label":"Uses","metadata":{},"score":"72.358864"}{"text":"When it starts from the gloss of the French sentence \" Bien entendu , il parle de une belle victoire .\" , for example , the greedy decoder alters the initial alignment incrementally as shown in .FIG .3 , eventually producing the translation \" Quite naturally , he talks about a great victory . \" In this process , the decoder explores a total of 77421 distinct alignments / translations , of which \" Quite naturally , he talks about a great victory .","label":"Uses","metadata":{},"score":"73.06264"}{"text":"That 's a great point to bring up .I offer the thoughts above as general inspiration but clearly there are questions like the one you bring up where the most important thing will be working in honest good faith .This is very interesting information .","label":"Uses","metadata":{},"score":"73.150345"}{"text":"The decoder of .claim 27 further comprising a module for determining a probability of correctness for a translation .The decoder of .claim 29 wherein the probability module for determining a probability of correctness comprises a language model and a translation module .","label":"Uses","metadata":{},"score":"73.274345"}{"text":"claim 15 wherein the source language text segment comprises a clause , a sentence , a paragraph , or a treatise .The method of .claim 15 wherein the method starts with an approximate target language translation and iteratively improves the translation with each successive iteration .","label":"Uses","metadata":{},"score":"73.36424"}{"text":"Performance within a range .Let 's say that if I do careful hyperparameter selection then I get an accuracy of X. I.e. , if I 'm willing to suffer 5 % multiplicative loss , how lazy can I be about hp selection ?","label":"Uses","metadata":{},"score":"73.594696"}{"text":"RemoveWordOfFertility 0 ( i ) .This operation deletes the word of fertility 0 at position i in the current alignment .SwapSegments ( i 1 , i 2 , j 1 , j 2 ) .This operation creates a new alignment from the old one by swapping non - overlapping English word segments [ i 1 , i 2 ] and [ j 1 , j 2 ] .","label":"Uses","metadata":{},"score":"73.714676"}{"text":"claim 15 wherein the termination condition comprises a determination that a probability of correctness of a modified translation is no greater than a probability of correctness of a previous translation .The method of .claim 15 wherein the termination condition comprises a completion of a predetermined number of iterations .","label":"Uses","metadata":{},"score":"73.890564"}{"text":"e . p .i . ) class .i1 . )i .l . k . i .d . ik .i . k . class . ik . ) x . m .p .p .m .","label":"Uses","metadata":{},"score":"74.07222"}{"text":"claim 1 wherein applying one or more modification operators comprises modifying an alignment between the source language text segment and the initial current target language translation by swapping non - overlapping target language word segments in the initial current target language translation .","label":"Uses","metadata":{},"score":"74.09883"}{"text":"Machine translation ( MT ) is the automatic translation , for example , using a computer system , from a first language ( e.g. , French ) into another language ( e.g. , English ) .Systems that perform MT techniques are said to \" decode \" the source language into the target language .","label":"Uses","metadata":{},"score":"74.70236"}{"text":"This work focuses on the description of its phrase - based ... \" .We present Jane 2 , an open source toolkit supporting both the phrase - based and the hierarchical phrase - based paradigm for statistical machine translation .It is implemented in C++ and provides efficient decoding algorithms and data structures .","label":"Uses","metadata":{},"score":"74.70653"}{"text":"So , we increase the Moses distortion limit from 6 ( the default ) to 10 and use Moses ' default lexicalized reordering model ( Koehn et al . , 2005 ) .We parsed the Chinese text using the Stanford parser ... . \" ...","label":"Uses","metadata":{},"score":"74.8629"}{"text":"claim 1 wherein the termination condition comprises a lapse of a predetermined amount of time .A computer - implemented machine translation decoding method comprising : . receiving as input a text segment in a source language to be translated into a target language ; . generating an initial translation by the computer as an initial current target language translation ; . estimating a probability of correctness of the initial translation by the computer , the probability based on alignment links between words and phrases in the source language and words and phrases in the target language ; . applying one or more modification operators by the computer to the initial current target language translation to generate one or more modified target language translations ; . estimating a probability of correctness of the one or more modified target language translations , the probability based on alignment links between words and phrases in the source language and words and phrases in the target language ; . iteratively modifying the current target language translation of the source language text segment based on the determination ; and . repeating said applying , said determining and said iteratively modifying until occurrence of a termination condition .","label":"Uses","metadata":{},"score":"75.012955"}{"text":"In fact , relations between nodes are built through bilingual arcs as can be seen on FIG .4 where only two such arcs ( 406 , 408 ) are drawn for clarity .The arc 406 links a node representing the source word Si to a node representing the target word Tj .","label":"Uses","metadata":{},"score":"75.048965"}{"text":"FIG .7 is an example of a Japanese source sentence .FIG .8 is the discourse structure of the Japanese source sentence in .FIG .7 .FIG .9 is the discourse structure of an English target sentence translated from the Japanese source sentence of .","label":"Uses","metadata":{},"score":"75.141556"}{"text":"Pick a single regularization parameter ( or parameter selection scheme , ala SVM - light ) to use for all of them and report results using that value .If this is about the same as the \" I carefully tuned \" setting , I 'm happy .","label":"Uses","metadata":{},"score":"75.16002"}{"text":"The head of one English word is assigned a French string position based on the position assigned to the previous English word .Non - heads .NULL - generated .After heads and non - heads are placed , NULL - generated words are permuted into the remaining vacant slots randomly .","label":"Uses","metadata":{},"score":"75.23114"}{"text":"Conferences can be exhausting , and back - to - back conferences can be really exhausting , so I want to convince you to pace yourself and save some energy for EMNLP at the end of the week , because we have some really interesting MT papers .","label":"Uses","metadata":{},"score":"75.62011"}{"text":"The differences in recall and precision are explained both by differences in the way information is packaged into paragraphs in the two languages and the way it is structured rhetorically both within and about the paragraph level .These results strongly suggest that if one attempts to translate Japanese into English on a sentence - by - sentence basis , it is likely that the resulting text will be unnatural from a discourse perspective .","label":"Uses","metadata":{},"score":"75.85878"}{"text":"I 'll focus mainly on oral presentations , because unlike poster sessions , the parallel format of the oral sessions entails a hard choice between mutually exclusive options , and part of my motivation is to help you make that choice .","label":"Uses","metadata":{},"score":"76.14195"}{"text":"That 's it .No tuning , no nothing .( Note that , as I said before , I have n't ever run experiments to verify this .But if it is , then it 's an interesting theoretical question : hinge loss and log loss do n't look that different , despite the fact that John seems to not like how log loss diverges : why should this be true ? )","label":"Uses","metadata":{},"score":"76.36191"}{"text":"The method of .claim 20 wherein the gloss comprises a word - for - word gloss or a phrase - for - phrase gloss .The method of . claim 19 wherein the approximate target language translation comprises a predetermined translation selected from among a plurality of predetermined translations .","label":"Uses","metadata":{},"score":"76.70217"}{"text":"claim 1 wherein applying one or more modification operators comprises changing in the initial current target language translation the translation of one or two words .The method of .The method of .claim 1 wherein applying one or more modification operators comprises deleting from the initial current target language translation a word having a zero - value fertility .","label":"Uses","metadata":{},"score":"76.86499"}{"text":"In addition to the kappa statistics , table 1 also displays in parentheses the average number of data points per document , over which the kappa statistics were computed .For each pair of Japanese - English discourse structures , an alignment file was also built manually , which specified in the notation discussed on page 1 the correspondence between the edus of the Japanese text and the edus of the English translation .","label":"Uses","metadata":{},"score":"76.90605"}{"text":"If a word has fertility greater than one , it is called very fertile .After each English word in the new string , the fertility of an invisible English NULL element with probability p 1 ( typically about 0.02 ) is incremented .","label":"Uses","metadata":{},"score":"77.12449"}{"text":"claim 29 wherein the process loop terminates upon a determination that a probability of correctness of a modified translation is no greater than a probability of correctness of a previous translation .The method of .claim 27 wherein the process loop terminates upon completion of a predetermined number of iterations .","label":"Uses","metadata":{},"score":"77.28171"}{"text":"It was a pretty compelling case .Now , I 'm going to pick on basically every \" yet another classifier \" paper I 've read in the past ten years ( read : ever ) .Here 's the deal .","label":"Uses","metadata":{},"score":"77.82402"}{"text":"SUMMARY OF THE INVENTION .It is an object of the invention to improve over existing bilingual word or term extraction methods and systems by taking into account different term lengths and by improving the accuracy of the extraction .It is another object of the invention to provide a system and a method for automatically creating multilingual terminology .","label":"Uses","metadata":{},"score":"78.79051"}{"text":"n .i .e . i . ) x .i .l . k . i .t . ik .e . i . ) x .i .l .d .i1 .c .p .","label":"Uses","metadata":{},"score":"79.82322"}{"text":"claim 1 wherein the text segment comprises a clause , a sentence , a paragraph or a treatise .The method of .claim 1 wherein generating an initial translation comprises generating a gloss .The method of .claim 3 wherein the gloss is a word - for - word gloss or a phrase - for - phrase gloss .","label":"Uses","metadata":{},"score":"79.92868"}{"text":"I have n't opened the present that you sent me .Je n'ai pas ouvert le cadeau que tu m'as envoyé .An additional helpful resource is a bilingual dictionary , even if incomplete .task : tâche .you : tu .","label":"Uses","metadata":{},"score":"80.022064"}{"text":"11 .FIG .10 shows a block diagram of the tree rewriter .FIG .11 shows a block diagram of how a tree rewriter can be used as a subsystem of a larger system .FIG .12 shows a block diagram of a discourse - based machine translation system with the tree rewriter as a subsystem .","label":"Uses","metadata":{},"score":"80.20526"}{"text":"UK Patent Application 2,279,164 discloses a system for processing a bilingual database wherein aligned corpora ( i.e. collections of texts ) are generated or received from an external source .Each corpus comprises a set of text portions aligned with corresponding portions of the other corpus so that aligned portions are nominally translations of one another in two natural languages .","label":"Uses","metadata":{},"score":"80.31382"}{"text":"The sense of wanting to help , but not knowing how or where , is something a lot of us are going through .Please come visit my site customer relationship when you got time .Nice , I think it could be interesting to add some more entries following this one , and probably it 's not only me having this opinion .","label":"Uses","metadata":{},"score":"80.49481"}{"text":"2 illustrates a more detailed description of the machine - aided translation system 103 .A user interface 201 may include a text editor for inputting manual translation of a source text , or for editing an automatic translation of said text .","label":"Uses","metadata":{},"score":"80.63159"}{"text":"Thus it can be seen as a shift to the formal machinery of syntaxbased translation systems without any linguistic commitment .In our experiments using BLEU as a metric , the hierarchical phrasebased model achieves a relative improvement of 7.5 % over Pharaoh , a state - of - the - art phrase - based system . ... as a metric , the hierarchical phrasebased model achieves a relative improvement of 7.5 % over Pharaoh , a state - of - the - art phrase - based system .","label":"Uses","metadata":{},"score":"81.838"}{"text":"Data sparsity and lexical categories .Learning generalizations from the database ( Brown , 2001 ) .Some ' S'-'T ' pairs : .The doctor treated the patient .El médico trató al paciente .The doctor examined the patient .","label":"Uses","metadata":{},"score":"81.92462"}{"text":"Of ACL ' 97 , pages 482 - 489 , Madrid , Spain ( 1997 ) , and Marcu , \" A decision - based approach to rhetorical parsing , \" In Proc .Of ACL ' 99 , pages 365 - 372 , Maryland ( 1999 ) .","label":"Uses","metadata":{},"score":"82.246185"}{"text":"The tree rewriter has applications not only in machine translation , but also in summarization , discourse parsing , syntactic parsing , information retrieval , automatic test scoring and other applications that generate or use trees .In machine translation , for example , the tree rewriter can be used to rewrite a syntactic / rhetorical tree specific to one language into a syntactic / rhetorical tree for another language .","label":"Uses","metadata":{},"score":"83.469376"}{"text":"FIG .12 , the discourse - based MT system 910 receives as input a source language text 900 and produces as output a target language text 908 , which is a discourse - based translation of the source language text 900 .","label":"Uses","metadata":{},"score":"83.81954"}{"text":"TECHNICAL FIELD .The present invention relates to a method and apparatus for creating bilingual terminology .Specifically , the invention relates to machine translation systems , terminology management systems , and any other systems which make use of multilingual terminology .","label":"Uses","metadata":{},"score":"84.13176"}{"text":"The bilingual word statistics will be used in the term extractor 304 described hereafter , and can be updated in an iterative process as described in the description for FIG .8 a below .The detailed operations performed in the term extractor 304 are now described with reference to FIG .","label":"Uses","metadata":{},"score":"84.16014"}{"text":"( As an aside , Mark , if you 're reading this , I can imagine the whole CW thing getting a bit confused if you 're using feature hashing : have you tried this ?Or has someone else ? )","label":"Uses","metadata":{},"score":"84.31615"}{"text":"Je n'ai pas ouvert le cadeau que tu m'as envoyé .He has n't read the book .Il n'a pas lu le livre .Why do n't you return the DVD that I lent you ?Pourquoi tu ne me rends pas le DVD que je t'ai prêté ?","label":"Uses","metadata":{},"score":"84.54544"}{"text":"For an in - depth discussion of this bilingual score function , see Dunning ( T.)-Accurate methods for the statistics of surprise and coincidence , Computational Linguistics , Vol .19 , Number 1 , March 1993 , herein incorporated by reference .","label":"Uses","metadata":{},"score":"84.99509"}{"text":"This is such a great resource that you are providing and you give it away for free .I love seeing websites that understand the value of providing a quality resource for free .It 's the old what goes around comes around routine .","label":"Uses","metadata":{},"score":"85.06108"}{"text":"Neither of these is totally ideal , but I think they 'd be a lot better than the current situation of really having no idea !Maybe there are other proposals out there that I do n't know about , or maybe other readers have good ideas .","label":"Uses","metadata":{},"score":"86.621"}{"text":"It was also very enlightening , but that 's another story .Many thanks to Hal for offering this forum to share the results !Welcome to everyone to ACL !It 's pretty rare for me to end up conferencing in a country I 've been before , largely because I try to avoid it .","label":"Uses","metadata":{},"score":"86.75073"}{"text":"It must have taken a lot of hours for you to write these yourself .Hats off from me for your hard work .Please come visit my site Sports injuries give me any valuable feedbacks .That is some inspirational stuff ...","label":"Uses","metadata":{},"score":"87.97306"}{"text":"This is very interesting information .I am doing some research for a class in school .and i liked the post .do you know where I can find other information regarding this ?I am finding other information on this but nothing that I can use really in my paper for my final .","label":"Uses","metadata":{},"score":"89.772156"}{"text":"And oh - my - gosh , there 's actually veggie chicken rice , though it does n't seem like it holds up to the same standards as real chicken rice ( if it did , that would be impressive ) .","label":"Uses","metadata":{},"score":"90.115"}{"text":"I would love some feedback on my site hotel when you got time .I usually do n't leave comments ! ! !Trust me !But I liked your blog ... especially this post !Would you mind terribly if I put up a backlink from my site to your site ?","label":"Uses","metadata":{},"score":"90.50505"}{"text":"The preferred embodiment of the invention uses a computer 's internal random access memory ( RAM ) as the memory device 312 .A bilingual word statistics determinator 302 is coupled to the memory device 312 and to term extractor 304 .","label":"Uses","metadata":{},"score":"90.580795"}{"text":"The computer platform 104 includes certain hardware units 112 including one or more central processing units ( CPU ) 116 , a random access memory ( RAM ) 114 , and an input / output ( IO ) interface 118 .The computer platform 104 includes an operating system 108 , and may include microinstruction code 110 .","label":"Uses","metadata":{},"score":"90.63752"}{"text":"Description .RELATED APPLICATION .This application claims the benefit of , and incorporates herein , U.S. Provisional Patent Application No .60/203,643 , filed May 11 , 2000 .ORIGIN OF INVENTION .The research and development described in this application were supported by the NSA under grant number MDA904 - 97 - 0262 and by DARPA / ITO under grant number MDA904 - 99-C-2535 .","label":"Uses","metadata":{},"score":"90.9077"}{"text":"and i liked the post .do you know where I can find other information regarding this ?I am finding other information on this but nothing that I can use really in my paper for my final .do you have any suggestions ?","label":"Uses","metadata":{},"score":"91.18051"}{"text":"The bilingual terminology extraction system 205 is also connected to the bilingual terminology database 207 for outputting bilingual pairs of words or multiword terms automatically produced by the terminology extraction system .FIG .3 illustrates a mere detailed description of the bilingual terminology extraction system 205 .","label":"Uses","metadata":{},"score":"92.2465"}{"text":"Now , I realize that most of the above list is not particularly friendly to my happy cow friends .Here 's a list of restaurants that happy cow provides .There are quite a few vegetarian options , probably partially because of the large Muslim population here .","label":"Uses","metadata":{},"score":"92.2802"}{"text":", indian roti with curry ) .The food court at Vivocity , despite being a food court , is very good .You should have some hand - pressed sugar cane juice -- very sweet , but very tasty ( goes well with some spicy hotpot ) .","label":"Uses","metadata":{},"score":"93.10783"}{"text":"Do n't wear a nice shirt unless you plan on doing laundry .Chicken rice .This sounds lame .Sure , chicken is kind of tasty .Rice is kind of tasty .But the key is that the rice is cooked in or with melted chicken fat .","label":"Uses","metadata":{},"score":"95.82358"}{"text":", bean stuff ) and frog leg porridge .Okay , so this list is all food .But frankly , what else are you going to do here ?Go to malls ?There 's definitely nice architecture to be seen ; I would recommend the Mosque off of Arab street ; of course you have to go to the Esplanade ( the durian - looking building ) ; etc .","label":"Uses","metadata":{},"score":"98.142"}{"text":"Cheers ! !Please come visit my site home accent give me any valuable feedbacks .I usually do n't leave comments ! ! !Trust me !But I liked your blog ... especially this post !Would you mind terribly if I put up a backlink from my site to your site ?","label":"Uses","metadata":{},"score":"99.67752"}{"text":"information will be very useful for me .Thanks for all your help and wishing you all the success in your business Thanks for all your help and wishing you all the success in your business Please come visit my site Find Business Madison when you got time .","label":"Uses","metadata":{},"score":"102.5535"}{"text":"claim 15 wherein the method implements a greedy algorithm .The method of .claim 15 wherein iteratively modifying the translation comprises incrementally improving the translation with each iteration .The method of .claim 15 wherein iteratively modifying the translation comprises performing at each iteration one or more modification operations on the translation .","label":"Uses","metadata":{},"score":"102.8875"}{"text":"For the vegan minded , there is a good blog about being vegan in Singapore ( first post is about a recent local talk by Campbell , the author of The China Study , which I recommend everyone at least reads ) .","label":"Uses","metadata":{},"score":"103.3055"}{"text":"Thank you for your good humor and for allowing yourself to be convinced that this was the right show for you to work on .Please come visit my site Santa Ana Yellow Page Business Directory when you got time .information will be very useful for me .","label":"Uses","metadata":{},"score":"103.53992"}{"text":"I am deeply in love with every single piece of information you post here .Will be back often to read more updates !Please come visit my site sexy video 's when you got time .information will be very useful for me .","label":"Uses","metadata":{},"score":"103.986946"}{"text":"Thanks for all the enthusiasm to offer such helpful information here .Please come visit my site Apartment living when you got time .Excellent article , i just share it with my friend of Italy .I Stumble UP your blog post , you will notice an increase of traffic within 24 hours for targeted people .","label":"Uses","metadata":{},"score":"104.077286"}{"text":"Enjoy your time here !Quick update : Totally forgot about coffee .If you need your espresso kick , Highlander coffee ( 49 Kampong Bahru Road ) comes the most recommended , but is a bit of a hike from the conference area .","label":"Uses","metadata":{},"score":"104.12732"}{"text":"This is just another reason why I like your website .I like your style of writing you tell your stories without out sending us to 5 other sites to complete the story .Please come visit my site Virginia Beach Yellow Page Business Directory when you got time .","label":"Uses","metadata":{},"score":"104.189514"}{"text":"Please come visit my site Santa Ana Web Link when you got time .Excellent article , i just share it with my friend of Italy .I Stumble UP your blog post , you will notice an increase of traffic within 24 hours for targeted people .","label":"Uses","metadata":{},"score":"104.27658"}{"text":"Yet Kun \" ( or something like that ) is along Purvis street .Especially for dessert , there 's Ah Chew , a Chinese place around Liang Seah street in the Bugis area ( lots of other stuff there too ) .","label":"Uses","metadata":{},"score":"105.344086"}{"text":"Well , nice article buddy ...Someone will love to read this infor if I tell her about this .She 's really interested in this subject .Thanks again ...Please come visit my site Baltimore Business Directory when you got time .","label":"Uses","metadata":{},"score":"107.33754"}{"text":"For real Chinese tea , here .( Funny aside : when I did this , they first asked \" have you had tea before ? \"Clearly the meaning is \" have you had real Chinese tea prepared traditionally and tasted akin to a wine tasting ? \" But I do n't think I would ever ask someone \" have you had wine before ? \" But I also ca n't really think of a better way to ask this ! )","label":"Uses","metadata":{},"score":"108.215256"}{"text":"Please come visit my site City Guide Santa Ana when you got time .Awesome !I have read a lot on this topic , but you definitely give it a good vibe .This is a great post .Will be back to read more !","label":"Uses","metadata":{},"score":"108.9041"}{"text":"As a result , he was an excellent \" tour guide . \"With his help , here 's a list of mostly food related stuff that you should definitely try while here ( see also the ACL blog ): .Pepper crab .","label":"Uses","metadata":{},"score":"116.934204"}{"text":"The doctor anesthetized the patient .El médico anestesió al paciente .The doctor examined the child .El médico examinó al niño .The cardiologist treated the patient .The doctor examined the patient 's liver .The cardiologist treated the patient 's heart .","label":"Uses","metadata":{},"score":"118.253426"}{"text":"I usually do n't leave comments ! ! !Trust me !But I liked your blog ... especially this post !Would you mind terribly if I put up a backlink from my site to your site ?Please come visit my site Business Yellow Pages Indianapolis when you got time .","label":"Uses","metadata":{},"score":"118.40963"}{"text":"El médico trató al paciente .ሐኪሙ ሕመምተኛውን አከመው ።The doctor examined the patient .El médico examinó al paciente .The CAT2 CAT1 the patient 's liver . ...The CAT2 CAT1 the patient 's heart .The patient recovered in the hospital . ...","label":"Uses","metadata":{},"score":"123.62729"}