{"text":"field_names : - form - lemma - coarse_tag - parent_ord - afun .These are the fields used by the models .Their meaning depends on the treebank used for training the models .We typically used PDT for Czech models and CoNLL for English models .","label":"Background","metadata":{},"score":"40.0151"}
{"text":"No models are currently provided for languages other than Czech or English .If you want to use the parser for another language , you have to train your own model .METHODS .Creates an instance of MSTperl , capable of parsing sentences , using the config file model_dir / model_name . config ( required ) , the unlabelled parsing model file model_dir / model_name . model ( required ) and the labelling model file model_dir / model_name . lmodel ( required only for labelled parsing ) .","label":"Background","metadata":{},"score":"40.047108"}
{"text":"[14 ] F. Smadja , Retrieving collocations from text : Xtract , Computational Linguistics , 19(1 ) , 1993 , 143 - 177 .[15 ] G. W. Snedecor and G. C. William , Statistical Methods , Iowa State University Press , Ames , Iowa , 1989 , p. 127 .","label":"Background","metadata":{},"score":"43.646954"}
{"text":"Page 2 . rule - based method ( Mikheev , 1997 ) and the decision tree - based method ( Orphanos and Christodoulakis , 1999 ) .In this paper , we propose a method to pre- dict POS tags of unknown English words as a post - processing of POS tagging using Sup- port Vector Machines ( SVMs ) .","label":"Background","metadata":{},"score":"44.299152"}
{"text":"It is difficult to train for a large amount of training data , and testing time increases in more complex mod- els .Another point to be improved is the search algorithm for POS tagging .a deterministic method is used as a search algorithm .","label":"Background","metadata":{},"score":"46.49829"}
{"text":"This paper describes POS prediction for unknown words usingSupportVector We achieve high accuracy in POS tag prediction using substrings and surrounding context as the features .Furthermore , we method with a practical English POS tagger , and achieve accuracy of 97.1 % , higher than conventional approaches . accuracyof part - of - speech Machines .","label":"Background","metadata":{},"score":"46.501682"}
{"text":"For Czech , the coarse tag devised by Collins is used . )The fields specified in the config file as the parent_ord and the label , e.g. : .parent_ord : parent_ord label : afun . are the fields computed by the unlabelled parser ( parent_ord ) and the labeller ( label ) .","label":"Background","metadata":{},"score":"46.790863"}
{"text":"This paper aims to minimize these serious errors while retaining the overall performance of POS tagging .Two gradient loss functions are proposed to reflect the different types of errors .They are designed to assign a larger cost to serious errors and a smaller one to minor errors .","label":"Background","metadata":{},"score":"47.055737"}
{"text":"On the other hand , the words themselves have much less contribution while the POS con- text have moderate contribution to the final accuracy .In general , features that rarely appear in the training data are statistically unreliable , and often decrease the performance of the sys- tem .","label":"Background","metadata":{},"score":"47.37114"}
{"text":"a large number of features and hardly over- fit .Consequently , SVMs can be applied suc- cessfully to natural language processing ap- plications ( Joachims , 1998 ; Kudoh and Mat- sumoto , 2000 ) .In this paper , we show how to apply SVMs to more general POS tagging as well as unknown word guessing , and report some experimental results .","label":"Background","metadata":{},"score":"47.38364"}
{"text":"Among several methods of multi - class classification for SVMs ( We- ston and Watkins , 1999 ) , we employ the one- versus - rest approach .Page 3 .Capital ?( 2 ) Word context : The lexical forms of the two words on both sides of the unknown word .","label":"Background","metadata":{},"score":"47.424507"}
{"text":"The conversion and grammar extraction process imports linguistic generalisations that are missing the in original treebank .This supports the extraction of a linguistically sound grammar with maximal generalisation , as well as grammar induction techniques to capture unseen data in stochastic parsing .","label":"Background","metadata":{},"score":"47.49122"}
{"text":"The conversion and grammar extraction process imports linguistic generalisations that are missing the in original treebank .This supports the extraction of a linguistically sound grammar with maximal generalisation , as well as grammar induction techniques to capture unseen data in stochastic parsing .","label":"Background","metadata":{},"score":"47.49122"}
{"text":"This method has the merit of having a small computational cost , but it has the demerit of not using the information of the succeeding POS tags .A tag dictionary which provides the lists of POS tags for known words ( i.e. , that appeared in training data ) is used .","label":"Background","metadata":{},"score":"47.49345"}
{"text":"B. 1 dependency grammars .Connexor was founded by some of the Helsinki group and offers for sale parsing tools for several languages .For English , it uses an improved version of ENGCG ( ) POS tagging with a nifty little java applet for a dependency tree display of grammatical relations ( some of which look more like semantic relations ) .","label":"Background","metadata":{},"score":"47.64571"}
{"text":"Parsing - based Methods The parsing - based methods rely on the syntactic analysis .These methods can extract linguistic related word collocations from the parsed trees and can differentiate between different types of linguistic relations .Normally these 00166 . indd 311/29/2007 2:52:45 PM .","label":"Background","metadata":{},"score":"48.22748"}
{"text":"While prior feature - based dynamic programming parsers have restricted training and evaluation to artificially short sentences , we present the first general , featurerich discriminative parser , based on a conditional random field model , which has been successfully scaled to the full WSJ parsing data .","label":"Background","metadata":{},"score":"48.430725"}
{"text":"[ 7 ] D. Hindle and M. Rooth , Structural ambiguity and lexical relations , Computational Linguistics , 19(1 ) , 1993 , 102 - 119 .[ 8 ] J. S. Justeson and S. M. Katz , Technical terminology : Some linguistic properties and an algorithm for identification in text , Natural Language Engineering , 1(1 ) , 1995 , 9 - 27 .","label":"Background","metadata":{},"score":"48.536575"}
{"text":"Furthermore , we integrate this method with a practical English POS tagger , and achieve accuracy of 97.1 % , higher than conventional approaches . aist - nara .ac.jp Abstract The ( POS ) tagging for unknown words is substantially lower than that for known words .","label":"Background","metadata":{},"score":"48.619423"}
{"text":"Finally , we present multilingual experiments which show that parsing with hierarchical state - splitting is fast and accurate in multiple languages and domains , even without any language - specific tuning . ... g ( Matsuzaki et al . , 2005 ; Petrov et al . , 2006 ) .","label":"Background","metadata":{},"score":"48.66539"}
{"text":"Considering the high accuracy rate of up - to - date statis- tical POS taggers , unknown words account for a non - negligible portion of the errors .This paper describes POS prediction for unknown words using Support Vector Machines .","label":"Background","metadata":{},"score":"48.746307"}
{"text":"Cucerzan and Yarowsky proposed paradigmatic similarity measures and showed a good result for highly inflectional languages using a large amount of unannotated text ( Cucerzan and Yarowsky , 2000 ) .Other methods for unknown word guessing have been studied , such as the Brants used the lin-","label":"Background","metadata":{},"score":"48.98388"}
{"text":"In Proceedings of V. Vapnik .The Nature of Statistical Learning Theory .Springer .R. Weischedel , M. Meteer , R. Schwartz , L. Ramshaw and J. Palmucci .Cop- ing with Ambiguity and Unknown Words through Probabilistic Models . tional Linguistics , 19(2 ) , pages 359 - 382 . Computa-","label":"Background","metadata":{},"score":"49.02912"}
{"text":"In particular we note the effects of two comparatively recent techniques for parser improvement .Then a reranking phase uses more detailed features , features which would ( mostly ) be ... . \" ...We formulate dependency parsing as a graphical model with the novel ingredient of global constraints .","label":"Background","metadata":{},"score":"49.76265"}
{"text":"The on - line The BNC2 Manual : Guidelines to Wordclass Tagging is very useful , especially in criteria for hard cases . A. 2 English Constraint Grammar tag set(s ) .The VISL project tags with Constraint Grammar tags , along with tense , case , and number information and grammatical function in the sentence . \"","label":"Background","metadata":{},"score":"49.807766"}
{"text":"They used that POS tag for the succeeding words .They report that about 2 % of accuracy decrease is caused by incorrectly attached POS tags by their method .We use a similar two pass method without using a dictionary .","label":"Background","metadata":{},"score":"49.88797"}
{"text":"The accuracy may be im- proved by incorporating some beam search scheme .Furthermore , our method outputs only the best answer and can not output the second or third best answer .There is a way to translate the outputs of SVMs as proba- bilities ( Platt , 1999 ) , which may be applied directly to remedy this problem .","label":"Background","metadata":{},"score":"49.94716"}
{"text":"Morphosyntactic Tagging of Slovene : Evaluating Taggers and Tagsets .Proceedings of the Second International Conference on Language Resources and Evaluation(LREC-2000 ) , pages 1099 - 1104 .T. Erjavec and J. Zavrel .In T. Joachims .Text Categorization with Support Vector Machines : Learning with Many Relevant Features .","label":"Background","metadata":{},"score":"50.029697"}
{"text":"G. Orphanos and D. Christodoulakis .POS Disambiguation and Unknown Word Guessing with Decision Trees .In Proceed- ings of the Ninth Conference of the Euro- pean Chapter of the Association for Com- putationalLinguistics(EACL-99 ) , 134 - 141 .pages J. Platt .","label":"Background","metadata":{},"score":"50.747925"}
{"text":"SVM classifiers are created for each POS tag using all words in the training set , then POS tags to unknown words predict using those classifiers . \" In this context , dealing with unknown words ( words do not appear in the lexicon referred as unknown words ) is also an important task , since growing NLP systems are used in more and more new applications .","label":"Background","metadata":{},"score":"50.92533"}
{"text":"The latter three are commonly used when collocations are extracted from technical domain .However , it should be noted that the word \" term \" has a different meaning in information retrieval , where it refers to words and phrases .","label":"Background","metadata":{},"score":"51.038525"}
{"text":"In fact , if you have the ICE - GB corpus installed , you can check the diagram for any sentence in the Oxford English Grammar .In addition , the Survey of English Usage offers an online tutorial in English syntax of the double - layered kind used in ICE .","label":"Background","metadata":{},"score":"51.39229"}
{"text":"We then describe our method for unknown word guessing and POS tagging in sections 3 and 4 .In section 5 , we describe the results of some experiments .While several of such separating hyperplanes exist ( Figure 1 , left ) , SVMs find the opti- mal hyperplane that maximizes the margin ( the distance between the hyperplane and the nearest points ) ( Figure 1 , right ) .","label":"Background","metadata":{},"score":"51.652237"}
{"text":"In this paper we introduce a joint arc - factored model for syntactic and semantic dependency parsing .The semantic role labeler predicts the full syntactic paths that connect predicates with their arguments .This process ... .Carreras Pérez , Xavier ; Collins , Michael ( 2009 ) Conference report Open Access .","label":"Background","metadata":{},"score":"51.69447"}
{"text":"200 characters per pasting .B. 3 sites with both kinds of outputs .The Stanford NLP Group 's java - based Parser can compute and report a dependency equivalent of its constituent - structure - based parses .Their set of dependency relations is becoming widely known and is described here .","label":"Background","metadata":{},"score":"51.756744"}
{"text":"The distinction between open class words and closed class words together with syntactical features of the language used in this research to predict lexical categories of unknown words in the tagging process .An experiment is performed to investigate the ability of the approach to parse unknown words using syntactical knowledge without human intervention .","label":"Background","metadata":{},"score":"51.832336"}
{"text":"This is done by finding two optimal classes in the collocation net and mapping the less - frequently occurring word and feature bigrams to them through the word- clustering mechanism provided in the collocation net as follows : . indd 711/29/2007 2:52:46 PM .","label":"Background","metadata":{},"score":"51.856365"}
{"text":"In this way , all the information extracted from the linguistic analysis is kept in the collocation net .Our approach applies to both frequently and less - frequently occurring words by providing a clustering mechanism and resolve the data sparseness problem through the collocation net .","label":"Background","metadata":{},"score":"51.859577"}
{"text":"Such worries have merit .The standard \" Charniak parser \" checks in at a labeled precisionrecall f - measure of 89.7 % on the Penn WSJ test set , but only 82.9 % on the test set from the Brown treebank corpus .","label":"Background","metadata":{},"score":"52.273407"}
{"text":"Moreover , all the information extracted from the linguistic analysis is kept in the collocation net .Compared with the traditional collocation dictionary , the collocation net provides a much more powerful facility since it can determine and measure the collocation relationship between any two words quantitatively .","label":"Background","metadata":{},"score":"52.795746"}
{"text":"In addition , the experimental result on text chunking shows that fewer serious errors help to improve the performance of subsequent NLP tasks .\" There are several techniques available and approved for realizing this classification task .Referred to section 3.1 SVMs can be used for such a task as applied by ( Nakagawa et al . , 2001 ) .","label":"Background","metadata":{},"score":"53.030415"}
{"text":"Koo , Terry ; Carreras Pérez , Xavier ; Collins , Michael ( 2008 )Conference report Open Access .We present a simple and effective semisupervised method for training dependency parsers .We focus on the problem of lexical representation , introducing features that incorporate word clusters derived from a large unannotated ... .","label":"Background","metadata":{},"score":"53.064568"}
{"text":"In particular , we show that the reranking parser described in Charniak and Johnson ( 2005 ) improves performance of the parser on Brown to 85.2 % .Furthermore , use of the self - training techniques described in ( Mc - Closky et al . , 2006 ) raise this to 87.8 % ( an error reduction of 28 % ) again without any use of labeled Brown data .","label":"Background","metadata":{},"score":"53.12444"}
{"text":"An example class ( \" finance / tax \" ) in the 2nd level of the collocation net . indd 13 11/29/2007 2:52:47 PM .Page 14 .14 Guodong Zhou et al . 1stReading Figure 1 compares the effect of different a 's in full parsing re - ranking .","label":"Background","metadata":{},"score":"53.303085"}
{"text":"The Noah 's Ark Research Group at Carnegie Mellon has a demo of TurboParser , which implements a syntactic parsing and graphing of sentences in Stanford Dependency relations and , along with it a FrameNet semantic parsing .The parse appears to be done directly into grammatical relations and not by conversion from a phrase stucture parse ( as with the Stanford Parser Core engine ) .","label":"Background","metadata":{},"score":"53.377636"}
{"text":"Introduction As a first step prior to parsing , traditional Part of Speech ( POS ) tagging assigns limited morpho - syntactic information to lexical items .These labels can be more or less fine - grained depending on the tagset , but syntactic information is often absent or limited .","label":"Background","metadata":{},"score":"53.404022"}
{"text":"Introduction As a first step prior to parsing , traditional Part of Speech ( POS ) tagging assigns limited morpho - syntactic information to lexical items .These labels can be more or less fine - grained depending on the tagset , but syntactic information is often absent or limited .","label":"Background","metadata":{},"score":"53.404022"}
{"text":", 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs of a statistical parser ( Collins , 2000 ) and ranking sentence plans ( Walker , Rambow and Rogati , 2001 ) .","label":"Background","metadata":{},"score":"53.42891"}
{"text":", 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs of a statistical parser ( Collins , 2000 ) and ranking sentence plans ( Walker , Rambow and Rogati , 2001 ) .","label":"Background","metadata":{},"score":"53.42891"}
{"text":"The POS tags for following words are obtained from a two - pass approach proposed by Nakagawa et al .[ 23].[ Show abstract ] [ Hide abstract ] ABSTRACT : All types of part - of - speech ( POS ) tagging errors have been equally treated by existing taggers .","label":"Background","metadata":{},"score":"53.496788"}
{"text":"This paper follows Firth 's Contextual Theory of Meaning to discover the collocations , which are grammatically bound .Collocations are important for a number of applications : natural language generation , computational lexicography , parsing , proper noun discovery , corpus linguistic research , machine translation , information retrieval , etc .","label":"Background","metadata":{},"score":"53.50355"}
{"text":"In the second pass , POS tagging is performed using the POS tags predicted in the first pass for the succeeding context ( i.e. , using the same features as sec- tion 3 ) .This method has the advantage of handling known and unknown words in the same way .","label":"Background","metadata":{},"score":"53.710457"}
{"text":"Finally , some conclusions are drawn in Section 6 . indd 411/29/2007 2:52:45 PM .Page 5 .Building a Collocation Net 5 1stReading 2 .Collocation Net The collocation net is a kind of two - level structure , which stores rich information about the collocation candidates and others extracted from the linguistic analysis of a large raw corpus .","label":"Background","metadata":{},"score":"53.83023"}
{"text":"Page 12 .12 Guodong Zhou et al . 1stReading Table 2 .Examples of N - best collocations ( Here , the collocations are sorted according to EPMI first and then EAMI . )No .Table 3 gives some of them .","label":"Background","metadata":{},"score":"54.14659"}
{"text":"Their paper ( on page 5 ) says the annotator agreement is 92.2 % .They also break accuracy out per tag , which LingPipe 's output also does ; you can see this yourself if you run it .LingPipe 's Baseline POS Tagger .","label":"Background","metadata":{},"score":"54.16961"}
{"text":"For syntactic bracketing , we use a phrase structure annotation .Similar phrase structure annotation schemes were also used by the , the and the .This annotation is preferable to a pure dependency annotation because with a phrase structure annotation we can encode richer structural information than with dependency annotation , as illustrated below : The corpus for the Korean Treebank project consists of texts from military language training manuals .","label":"Background","metadata":{},"score":"54.264427"}
{"text":"First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar without a treebank .In our experiments , hierarchical pruning greatly accelerates parsing with no loss in empirical accuracy .","label":"Background","metadata":{},"score":"54.80452"}
{"text":"This suggests the data sparseness problem in building a collocation net and proper handling can improve the performance .For clarity , Table 5 lists the effect of the best full parsing re - ranking system using the collocation net .It shows that the use of the collocation net can increase the F - measure by 1.9 in F - measure .","label":"Background","metadata":{},"score":"55.418655"}
{"text":"4.1Using Only the Preceding POS Tags The first method uses only the POS tags of the preceding words .In probabilistic models such as HMM , the generative probabilities of all sequences are considered and the most likely path is selected by the Viterbi algorithm .","label":"Background","metadata":{},"score":"55.422264"}
{"text":"On a broader perspective our approach contributes to a better understanding on where corpuslinguistics and theoretical linguistics can meet and enrich each other .The need of large - scale corpora for higherlevel syntactic frameworks is addressed in Sadler et al ( 2000 ) , Frank ( 2000 ) , Frank et al ( 2001 ) , who develop methods to enrich treebanks with higher - level ... . by","label":"Background","metadata":{},"score":"55.46486"}
{"text":"On a broader perspective our approach contributes to a better understanding on where corpuslinguistics and theoretical linguistics can meet and enrich each other .The need of large - scale corpora for higherlevel syntactic frameworks is addressed in Sadler et al ( 2000 ) , Frank ( 2000 ) , Frank et al ( 2001 ) , who develop methods to enrich treebanks with higher - level ... . by","label":"Background","metadata":{},"score":"55.46486"}
{"text":"For defining transfer rules , we use the ' lexico - structural transfer ' framework , which is based on a lexicalized predicate - argument structure .In this framework , the transfer lexicon does not simply relate words ( or context - free rewrite rules ) from one language to words ( or context - free rewrite rules ) from another language .","label":"Background","metadata":{},"score":"55.56997"}
{"text":"In this paper , a collocation candidate is represented as a 3tuple : a left side , a right side and a collocation relation type , which represents the collocation relationship between the left side and the right side .Both the left and right sides can be either a word and feature bigram or a class of word and feature bigrams . is the number of the collocation relation types in CR .","label":"Background","metadata":{},"score":"55.62746"}
{"text":"16 ] J. Yang , Towards the automatic acquisition of lexical selection rules , MT Summit VII , Singapore , 1999 , pp .397 - 403 .[17 ] D. Yuret , Discovery of linguistic relations using lexical attraction , Ph .","label":"Background","metadata":{},"score":"55.734726"}
{"text":"A second group of papers does parsing by a sequence of independent , discriminative decisions , either greedily or with use of a small beam ( Ratnaparkhi , 1997 ; Henderson , 2004 ) .This paper extends th ...","label":"Background","metadata":{},"score":"55.941135"}
{"text":"Following the model described in Palmer , Rambow and Nasr ( 1998 ) for English / French translation , our system has a plug - and - play architecture that is composed of state - of - the - art off - the - shelf components in parsing ( and morphological analysis ) and generation .","label":"Background","metadata":{},"score":"56.037632"}
{"text":"Page 10 .In this way , we have a large set of collocation candidates with their frequencies .( 4 ) Examine whether the collocation net is to be re - built .For example , whether the average probability ratio between the best parsed tree hypothesis and the second best parsed tree hypothesis for each sentence converges or begins to dropd .","label":"Background","metadata":{},"score":"56.178734"}
{"text":"This method can be extended to more general POS tagging by predicting the POS tags of all words in a given sentence .Differing from unknown word guessing as a post - processing of POS tagging , the POS tags for succeed- ing words are usually not known during POS tagging .","label":"Background","metadata":{},"score":"56.20381"}
{"text":"HLT / EMNLP .The Treex::Tool::Parser::MSTperl package serves as a wrapper for the underlying packages and should be sufficient for the basic tasks .For any special needs , feel free to use the underlying packages directly .Please note that the parser does non - projective parsing and is therefore best for parsing of non - projective languages ( e.g. Czech or Dutch ) .","label":"Background","metadata":{},"score":"56.250565"}
{"text":"We describe an extension of semisupervised structured conditional models ( SS - SCMs ) to the dependency ... .Collins , Michael ; Globerson , Amir ; Koo , Terry ; Carreras Pérez , Xavier ; Bartlett , Peter ( 2008 - 08 )","label":"Background","metadata":{},"score":"56.58917"}
{"text":"The performance at the different degree of polynomial kernel is shown in Table 6 .The best degree seems to be 1 or 2 for this task , and the best degree tends to increase when the training data increases .5.2 The accuracies of POS tagging are shown in Table 7 .","label":"Background","metadata":{},"score":"56.602036"}
{"text":"It is written in C # for Windows and is free with a harmless registration .Ram hungry , but a nice piece of work .Provides multiple parses .No new versions since 2008 .The venerable Survey of English Usage at University College London weighs in with its contribution to the International Corpus of English , namely the International Corpus of English , or at least the British part of it .","label":"Background","metadata":{},"score":"56.668777"}
{"text":"68 - 73 .[ 10 ] C. D. Manning and H. Schutze , Foundations of Statistical Natural Language Processing , MIT Press , 1999 , p. 185 . indd 1511/29/2007 2:52:48 PM .Page 16 .16 Guodong Zhou et al . 1st","label":"Background","metadata":{},"score":"56.69655"}
{"text":"The patterns feel awfully comfortable . )Our performance was 85.4 % accuracy on their train / test split using the default parameters for tagging in LingPipe .In contrast , the Stanford CRF tagger with default features was 85.9 % accurate , whereas Gimpel et al . 's tagger achieved 89.4 % accuracy .","label":"Background","metadata":{},"score":"56.72657"}
{"text":"Page 6 . 6 Guodong Zhou et al . 1stReading related to Chi .That is , each word and feature bigram or class in the collocation net is represented by the distribution of its related collocation candidates .In this way , all the information extracted via the linguistic analysis is stored in the collocation net .","label":"Background","metadata":{},"score":"56.829636"}
{"text":"However , for languages like Japanese and Chinese , it is difficult to apply our meth- ods straightforwardly because words are not separated by spaces in those languages .One problem of our methods is computa- tional cost .It took about 16.5 hours for training with 100,000 tokens and 4 hours for testing with 285,000 tokens in POS tagging using POS tags on both sides on an Alpha 21164A 500MHz processor .","label":"Background","metadata":{},"score":"56.878307"}
{"text":"We could also introduce new variables , e.g. , nonterminal refinements ( Matsuzaki et al . , 2005 ) , or secondary links Mij ( not constrai ... . by Jin - dong Kim , Tomoko Ohta , Sampo Pyysalo , Yoshinobu Kano - In Proceedings of Natural Language Processing in Biomedicine ( BioNLP )","label":"Background","metadata":{},"score":"57.0291"}
{"text":"( van Halteren , 1996 ) ) .RankBoost can also use a variety of local and long distance features more easily than n - gram - based approaches ( cf .( Chen , Bangalore and Vijay - Shanker , 1999 ) ) because it makes sparse data less of an issue . \" ...","label":"Background","metadata":{},"score":"57.030144"}
{"text":"( van Halteren , 1996 ) ) .RankBoost can also use a variety of local and long distance features more easily than n - gram - based approaches ( cf .( Chen , Bangalore and Vijay - Shanker , 1999 ) ) because it makes sparse data less of an issue . \" ...","label":"Background","metadata":{},"score":"57.030144"}
{"text":"In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the coverage of harid - crafted grammars .","label":"Background","metadata":{},"score":"57.06788"}
{"text":"In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the coverage of harid - crafted grammars .","label":"Background","metadata":{},"score":"57.06788"}
{"text":"T. Kudoh and Y. Matsumoto .Use of Support Vector Learning for Chunk Iden- tificationIn Proceedings of the Fourth Conference on Computational Natural Lan- guage Learning(CoNLL-2000 ) , pages 142- 144 . A. Mikheev .Automatic Rule Induc- tion for Unknown - Word Guessing .","label":"Background","metadata":{},"score":"57.101414"}
{"text":"Computational Linguis- tics , 21(4 ) , pages 543 - 565 . E. Charniak , C. Hendrickson , N. Jacobson and M. Perkowitz .Part - of - Speech Tagging .In Proceedings of 1993 .Equations for .Page 7 . the Eleventh National Conference on Artifi- cial Intelligence(AAAI-93 ) , pages 784 - 789 .","label":"Background","metadata":{},"score":"57.24421"}
{"text":"This site introduces three main projects on Korean NLP currently being conducted at Penn : Korean XTAG , Korean Treebank , and Korean / English machine translation .These projects are partially funded by the Army Research Lab via a subcontract from , and by NSF Grant SBR 8920230 .","label":"Background","metadata":{},"score":"57.513264"}
{"text":"Differing provisions from the publisher 's actual policy or licence agreement may be applicable .\" Scott M. Thede and Mary Harper [ 5 ] in their paper presented an approach using morphology and syntactic parsing rules in post - mortem method for determining the probable lexical classes of words .","label":"Background","metadata":{},"score":"57.536522"}
{"text":"Support Vec- tor Networks Machine Learning , 20 , pages 273 - 297 .S. Cucerzan and D. Yarowsky .Lan- guage Independent , Minimally Supervised Induction of Lexical Probabilities .Proceedings of the 38th Annual Meet- ing of the Association for Computational Linguistics(ACL-2000 ) , pages 270 - 277 .","label":"Background","metadata":{},"score":"57.53737"}
{"text":"Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation .On the other hand , our grammars are much more compact and substantially more accurate than previous work on automatic annotation .Despite its simplicity , our best grammar achieves an F1 of 90.2 % on the Penn Treebank , higher than fully lexicalized systems . ... reebank , higher than fully lexicalized systems .","label":"Background","metadata":{},"score":"57.58023"}
{"text":"Also , Bernard Bou 's Java - based GrammarScope uses the Stanford package and can display both Phrase Structure trees and grammatical relations as colors .VERY nice once you get the hang of it ( you can paste sentences in from the clipboard as well as feed it text files ) .","label":"Background","metadata":{},"score":"57.745808"}
{"text":"We apply this idea to dependency and constituent parsing , generating results that surpass state - of - theart ... \" .We present a novel parser combination scheme that works by reparsing input sentences once they have already been parsed by several different parsers .","label":"Background","metadata":{},"score":"57.93589"}
{"text":"Finally , the collocation dictionary normally does not differentiate the strength of various collocations .This paper combines the parsing - based approach and the statistics - based approach , and proposes a novel structure of collocation net .Through the collocation net , the data sparseness problem is resolved by providing a clustering mechanism and the collocation relationship between any two words can be easily determined and measured from the collocation net .","label":"Background","metadata":{},"score":"57.954407"}
{"text":"Building a Collocation Net Given a large raw corpus and a general - purpose full parser , a collocation net can be built iteratively as follows : ( 1 ) Parse all the sentences in the large raw corpus into parsed trees using a general - purpose full parser .","label":"Background","metadata":{},"score":"58.306526"}
{"text":"Structural linguistics concentrates on the general abstractions about properties of phrases and sentences .In contrast , Contextual Theory of Meaning that follows Firth , Halliday and Sinclair , emphasizes the importance of context : the context of social setting , the context of discourse and the context of surrounding words .","label":"Background","metadata":{},"score":"58.336823"}
{"text":"The University Centre for Computer Corpus Research in Language at the University of Lancaster developed the CLAWS ( Constituent Likelihood Automatic Word - tagging System ) tagger program with several levels of delicacy .You can submit a paragraph of up to 300 words to the tagger and it will return a tagged version fairly quickly .","label":"Background","metadata":{},"score":"58.402115"}
{"text":"( 3 ) ( 4 )y For linearly non - separable cases , feature vectors are mapped into a higher dimensional space by a nonlinear function Φ(x ) and lin- early separated there . since all data points appear as a form of in- ner product , we only need the inner product of two points in the higher dimensional space .","label":"Background","metadata":{},"score":"58.62674"}
{"text":"Most of these algorithms avoid the known hardness results by defining parameters beyond the ... .Koo , Terry ; Globerson , Amir ; Carreras Pérez , Xavier ; Collins , Michael ( 2007 ) Conference report Open Access .This paper provides an algorithmic framework for learning statistical models involving directed spanning trees , or equivalently non - projective dependency structures .","label":"Background","metadata":{},"score":"58.627235"}
{"text":"The paper presents the design and implementation of the BioNLP'09 Shared Task , and reports the final results with analysis .The shared task consists of three sub - tasks , each of which addresses bio - molecular event extraction at a different level of specificity .","label":"Background","metadata":{},"score":"58.731537"}
{"text":"The paper presents the design and implementation of the BioNLP'09 Shared Task , and reports the final results with analysis .The shared task consists of three sub - tasks , each of which addresses bio - molecular event extraction at a different level of specificity .","label":"Background","metadata":{},"score":"58.731537"}
{"text":"This corpus is not only marked up for part of speech ; each part is also assigned a syntactic function following the Quirk et al . scheme of SVOA etc .So it displays its texts in trees ( oriented side- , top- , or bottom - up as you please ) with dual labelling of each node ( see sample ) .","label":"Background","metadata":{},"score":"58.862675"}
{"text":", Loci of contextual effects on visual word recognition , in Attention and Performance V , edited by P. Rabbitt and S. Dornie .Academic Press , 1975 , pp .98 - 116 .[ 12 ] I. C. Ross and J. W. Tukey , Introduction to these volumes , in John Wilder Tukey ( ed . ) , Index to Statistics and Probability , R&D Press , Los Altos , 1975 , pp . iv - x .","label":"Background","metadata":{},"score":"59.267616"}
{"text":"This can be easily done through computing the EAMI and EPMI of all the collocation candidates extracted from the corpus , as described in Section 3 .Then all the collocation candidates whose EPMIs are larger than a threshold ( e.g. 0 ) are kept as collocations and sorted according to their EPMIs .","label":"Background","metadata":{},"score":"59.52691"}
{"text":"We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .","label":"Background","metadata":{},"score":"59.617004"}
{"text":"We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .","label":"Background","metadata":{},"score":"59.617004"}
{"text":"We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .","label":"Background","metadata":{},"score":"59.617004"}
{"text":"We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .","label":"Background","metadata":{},"score":"59.617004"}
{"text":"edu.sg This paper presents an approach to build a novel two - level collocation net , which enables calculation of the collocation relationship between any two words , from a large raw corpus .The first level consists of atomic classes ( each atomic class consists of one word and feature bigram ) , which are clustered into the second level class set .","label":"Background","metadata":{},"score":"59.82075"}
{"text":"Inspired by work in discriminative dependency parsing , the key idea in our approach is to allow highly ... .Carreras Pérez , Xavier ; Surdeanu , Mihai ; Màrquez Villodre , Lluís ( 2010 ) Conference report Open Access .We describe an online learning dependency parser for the CoNLL - X Shared Task , based on the bottom - up projective algorithm of Eisner ( 2000 ) .","label":"Background","metadata":{},"score":"59.85299"}
{"text":"Comput .Linguist . , 2010 . \" ...Information - extraction ( IE ) systems seek to distill semantic relations from naturallanguage text , but most systems use supervised learning of relation - specific examples and are thus limited by the availability of training data .","label":"Background","metadata":{},"score":"59.870102"}
{"text":"Table 5 .Application of the collocation net in parse tree re - ranking .P(%)R(%)F1 Before re - ranking After re - ranking 88.26 90.12 88.05 89.98 88.15 90.06 6 .Conclusion This paper proposes a novel structure of two - level collocation net and a method capable of automatically building the collocation net given a large raw corpus .","label":"Background","metadata":{},"score":"59.897846"}
{"text":"For unknown words , all possible POS tags are taken as the candidates .This method requires no exceptional pro- cessings to handle unknown words .Page 4 .Same features as shown in Table 1 are used .In general , the POS tags of the succeed- ing words are unknown .","label":"Background","metadata":{},"score":"59.9581"}
{"text":"Carreras Pérez , Xavier ; Collins , Michael ; Koo , Terry ( Coling 2008 Organizing Committee , 2008 )Conference report Open Access .We describe a parsing approach that makes use of the perceptron algorithm , in conjunction with dynamic programming methods , to recover full constituent - based parse trees .","label":"Background","metadata":{},"score":"59.99365"}
{"text":"Advances in Large Margin Classifiers .MIT Press . A. Ratnaparkhi .Entropy Model for Part - of - Speech Tag- ging .In Proceedings of Conference on Empirical Methods in Natural Language Processing(EMNLP-1 ) , pages 133 - 142 .A Maximum D. Roth and D. Zelenko . of Speech Tagging Using a Network of Linear Separators .","label":"Background","metadata":{},"score":"60.01777"}
{"text":"Unfortunately , words are assigned on average a much higher number of Supertags than traditional POS .In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) ... \" .Srinivas ( 97 ) enriches traditional morpho - syntactic POS tagging with syntactic information by introducing Supertags .","label":"Background","metadata":{},"score":"60.29464"}
{"text":"Unfortunately , words are assigned on average a much higher number of Supertags than traditional POS .In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) ... \" .Srinivas ( 97 ) enriches traditional morpho - syntactic POS tagging with syntactic information by introducing Supertags .","label":"Background","metadata":{},"score":"60.29464"}
{"text":"Discriminative feature - based methods are widely used in natural language processing , but sentence parsing is still dominated by generative methods .While prior feature - based dynamic programming parsers have restricted training and evaluation to artificially short sentences , we present the first gene ... \" .","label":"Background","metadata":{},"score":"60.382973"}
{"text":"More on the Korean XTAG system description can be found in our TAG+5 workshop paper .The Treebank will also be used to extract lexicalized grammars , e.g. a Korean Tree Adjoining Grammar , which can be used for other applications , such as natural language generation .","label":"Background","metadata":{},"score":"60.40146"}
{"text":"Table 2 gives some of the examples .It shows that our method can not only extract the collocations that occur frequently in the corpus but also extract the collocations that seldom occur in the corpus .Another advantage is that our method can determine the collocation relationship between any two words and measure its strength degree .","label":"Background","metadata":{},"score":"60.417137"}
{"text":"In this work , we present 1 . an effective method for pruning in split PCFGs 2 . a comparison of objective functions for infe ... . \" ...The l - bfgs limited - memory quasi - Newton method is the algorithm of choice for optimizing the parameters of large - scale log - linear models with L2 regularization , but it can not be used for an L1-regularized loss due to its non - differentiability whenever some parameter is zero .","label":"Background","metadata":{},"score":"60.443993"}
{"text":"Their corpus was very easy to parse ( thanks , I really appreciate it ) .It only took me about an hour or so to download the data , parse it , and evaluate LingPipe 's baseline POS tagger on it .","label":"Background","metadata":{},"score":"60.44799"}
{"text":"In this paper we study spectral learning methods for non - deterministic split head - automata grammars , a powerful hidden - state formalism for dependency parsing .We present a learning algorithm that , like other spectral ... .Balle Pigem , Borja de ; Carreras Pérez , Xavier ; Luque , Franco M. ; Quattoni , Ariadna Julieta ( 2013 - 10 - 07 ) Article Restricted access - publisher 's policy .","label":"Background","metadata":{},"score":"60.497795"}
{"text":"negligible problem where training data is lim- ited ( Brants , 2000 ) .One known approach for unknown word guessing is to use suffixes or surrounding context of unknown words ( Thede , 1998 ) .ear interpolation of fixed length suffix model for unknown word handling in his part - of- speech tagger TnT ( Brants , 2000 ) .","label":"Background","metadata":{},"score":"60.729446"}
{"text":"Our system is a hybrid system that profits from a stochastic parser that was independently trained on domain - general corpora and a hand - crafted linguistic knowledge base in the form of a predicate - argument lexicon and linguistically sophisticated transfer rules .","label":"Background","metadata":{},"score":"60.863876"}
{"text":"[ Online demos seem to be down 03/2015].SVMTool is a recent tagger using Support Vector Machines that claims very good accuracy .It is trained on WSJ corpus .The Cognitive Computing Group at UIUC offers a demo tagger with color coding in its suite of NLP tools ( which include Semantic Role ( like FrameNet ) labeling and Shallow Parsing into main phrases .","label":"Background","metadata":{},"score":"60.95197"}
{"text":"Part - of - Speech Tagging 6 Conclusion and Future Work In this paper , we applied SVMs to unknown word guessing and showed that they per- form quite well using context and substring information .Furthermore , extending the method to POS tagging , the resulting tag- ger achieves higher accuracy than the state- of - the - art HMM - based tagger . to other machine learning algorithms , SVMs have the advantage of considering the com- binations of features automatically by intro- ducing a kernel function and seldom over - fit Comparing with a large set of features .","label":"Background","metadata":{},"score":"61.13995"}
{"text":"This naive grammar ... . \" ...We present several improvements to unlexicalized parsing with hierarchically state - split PCFGs .First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar wi ... \" .","label":"Background","metadata":{},"score":"61.266502"}
{"text":"..We just list two of them which seem to be most relevant : C4 uses a reduced tagset while C3 uses the PTB tagset . 9 Instead , we re - ran 8 All use Section 2 - 21 of the PTB for training , and Section 22 or 23 for testing .","label":"Background","metadata":{},"score":"61.47415"}
{"text":"..We just list two of them which seem to be most relevant : C4 uses a reduced tagset while C3 uses the PTB tagset . 9 Instead , we re - ran 8 All use Section 2 - 21 of the PTB for training , and Section 22 or 23 for testing .","label":"Background","metadata":{},"score":"61.47415"}
{"text":"Treex - Parser - MSTperl-0.11949 .NAME .VERSION .version 0.11949 Treex::Tool::Parser::MSTperl - a non - projective dependency natural language parser ( pure Perl implementation of the MST parser ) .SYNOPSIS .Analysis of a Czech sentence \" Martin jde po ulici . \"","label":"Background","metadata":{},"score":"61.64469"}
{"text":"For more extensive description , see Annotating Predicate Argument Structure The full ( 318 page ) manual for PennTreebank II markup is available as a PDF .The first 10 % Penn TreeBank sentences are available with both standard PennTree and also Dependency parsing as part of the free dataset for the Python - based Natural Language Tool Kit ( NLTK ) .","label":"Background","metadata":{},"score":"61.743927"}
{"text":"[20 ] G. D. Zhou and K. T. Lua , Interpolation of N - gram and MI - based trigger pair language modeling in mandarin speech recognition , Computer , Speech and Language , 13(2 ) , 1999 , 123 - 135 . indd 1611/29/2007 2:52:48 PM .","label":"Background","metadata":{},"score":"61.821266"}
{"text":"Grammars are core elements of many NLP applications .In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the cove ... \" .","label":"Background","metadata":{},"score":"62.12282"}
{"text":"Grammars are core elements of many NLP applications .In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the cove ... \" .","label":"Background","metadata":{},"score":"62.12282"}
{"text":"Table 4 shows an example class \" finance / tax \" in the second level of the collocation net .In order to further evaluate the usefulness of the collocation net , we have used it in full parsing re - ranking using the standard PARSEVAL metrics .","label":"Background","metadata":{},"score":"62.139557"}
{"text":"Bailly , Raphaël ; Carreras Pérez , Xavier ; Luque , Franco M. ; Quattoni , Ariadna Julieta ( Association for Computational Linguistics , 2013 ) Conference lecture Open Access .We derive a spectral method for unsupervised learning ofWeighted Context Free Grammars .","label":"Background","metadata":{},"score":"62.16667"}
{"text":"For VISL parsing , see below .Connexor 's Machinese Phrase Tagger also uses a Constraint Grammar tagger .Its tags are spelled out as words , but the full strings of symbols can be found in the Machinese Syntax parser - grapher .","label":"Background","metadata":{},"score":"62.39331"}
{"text":"[ 4 ] M. Collins , Head - driven statistical models for natural language parsing , Ph.D. Dissertation , University of Pennsylvania , 1999 .[5 ] T. Dunning , Accurate methods for the statistics of surprise and coincidence , Computational Linguistics , 19(1 ) , 1993 , 61 - 74 .","label":"Background","metadata":{},"score":"62.54848"}
{"text":"Each type of learning method brings its own ' inductive bias ' to the task and will produce a classifier with slightly different characteristics , so that different methods will tend to produce different errors . ... eras , 1999 ) for combining ensembles of neural networks .","label":"Background","metadata":{},"score":"62.59334"}
{"text":"Each type of learning method brings its own ' inductive bias ' to the task and will produce a classifier with slightly different characteristics , so that different methods will tend to produce different errors . ... eras , 1999 ) for combining ensembles of neural networks .","label":"Background","metadata":{},"score":"62.59334"}
{"text":"Since their introduction , ranking SVM models have become a powerful tool for training content - based retrieval systems .All we need for training a model are retrieval examples in the form of triplet constraints , i.e. examples ... .Suzuki , Jun ; Isozaki , Hideki ; Carreras Pérez , Xavier ; Collins , Michael ( 2009 ) Conference report Open Access .","label":"Background","metadata":{},"score":"62.71059"}
{"text":"This is a joint project with and .Given that Korean and English are very different from each other in structure and morphology , many challenging problems arise , demanding sophisticated linguistic analysis .Each half has roughly 50,000 word tokens , and 5000 sentences .","label":"Background","metadata":{},"score":"62.779564"}
{"text":"Tools . by Slav Petrov , Leon Barrett , Romain Thibaux , Dan Klein - In ACL ' 06 , 2006 . \" ...We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .","label":"Background","metadata":{},"score":"62.7927"}
{"text":"Currently , there are two categories of approaches used to discover collocations and co - occurrences : statistics - based and parsing - based . indd 211/29/2007 2:52:45 PM .Page 3 .Building a Collocation Net 3 1stReading 1.1 .","label":"Background","metadata":{},"score":"62.822346"}
{"text":"This has led to concer ... \" .Statistical parsers trained and tested on the Penn Wall Street Journal ( WSJ ) treebank have shown vast improvements over the last 10 years .Much of this improvement , however , is based upon an ever - increasing number of features to be trained on ( typically ) the WSJ treebank data .","label":"Background","metadata":{},"score":"62.88669"}
{"text":"non - parallel , multilingual corpus . 1 Introduction Probabilistic grammars have become an important tool in natural language processing .An attractive property of probabilistic grammars is that the ... . by Fei Wu , Daniel S. Weld - in Proc . 48th Annu .","label":"Background","metadata":{},"score":"62.89431"}
{"text":"Keywords : Collocation net ; Data sparseness problem ; Clustering .Introduction In any natural language , there always exist many highly associated relationships between words .The two words \" strong \" and \" powerful \" are perhaps the canonical example .","label":"Background","metadata":{},"score":"63.353657"}
{"text":"We examined the be- havior when reducing the sparse features .Ta-ble 5 shows the result for 10,000 training to- kens .Ignoring the features that appeared only once , the accuracy is a bit improved .Page 5 .Page 6 .","label":"Background","metadata":{},"score":"63.423557"}
{"text":"Part In Proceedings of H. Schmid . of - Speech Tagging Using Decision Trees .In Proceedings of the International Con- ference on New Methods in Language Processing(NeMLaP-1 ) , pages 44 - 49 .Probabilistic Part- S. Thede .Predicting Part - of - Speech Information about Unknown Words using Statistical Methods .","label":"Background","metadata":{},"score":"63.49153"}
{"text":"In the k - means clustering algorithm , k is fine - tuned to 1000 to achieve proper granity and the frequency distributions of C FDCC are mapped to each class in C2 of the two - level collocation net using cross- validation in this paper .","label":"Background","metadata":{},"score":"63.510437"}
{"text":"To do real projective parsing , it would be necessary to change the core algorithm of the parser ( Eisner would have to be used in stead of Chu - Liu - Edmonds ) .Please note that the parser does dependency parsing , producing a dependency tree as its output .","label":"Background","metadata":{},"score":"63.657295"}
{"text":"On WSJ15 , we attain a state - of - the - art F - score of 90.9 % , a 14 % relative reduction in error over previous models , while being two orders of magnitude faster .On sentences of length 40 , our system achieves an F - score of 89.0 % , a 36 % relative reduction in error over a generative baseline . ...","label":"Background","metadata":{},"score":"63.717186"}
{"text":"The contribution of each feature has the same tendency as the case of the unknown word guessing in section 5.1 .The biggest difference of features be- tween our method and the TnT is the use of word context .Although using a lot of features such as word context is difficult in Markov model , it is easy in SVMs as seen in section 5.1 .","label":"Background","metadata":{},"score":"63.824856"}
{"text":"For grammar development system , it uses the XTAG system which we have customized for Korean TAG development .The XTAG system was originally developed for English TAG and it consists of a parser , an X - windows grammar development interface and a POS tagger .","label":"Background","metadata":{},"score":"63.82641"}
{"text":"In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .Because of the highly lexicalized nature of the LTAG formalism , we experimentally show that notions other than sentence length play a factor in observed parse times .","label":"Background","metadata":{},"score":"63.889683"}
{"text":"In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .Because of the highly lexicalized nature of the LTAG formalism , we experimentally show that notions other than sentence length play a factor in observed parse times .","label":"Background","metadata":{},"score":"63.889683"}
{"text":"This paper presents WOE , an open IE system which improves dramatically on TextRunner 's precision and recall .The key to WOE 's performance is a novel form of self - supervised learning for open extractors - using heuristic matches between Wikipedia infobox attribute values and corresponding sentences to construct training data .","label":"Background","metadata":{},"score":"63.910458"}
{"text":"Similarly to AMI , the problem with the above equation is that it only works on frequently occurring word and feature bigrams .In order to resolve this problem , we also propose a modified version of PMI , called estimated pair - wise mutual information ( EPMI ) , to calculate the information change of a collocation candidate when one or two word and feature bigrams do not occur frequently .","label":"Background","metadata":{},"score":"64.15881"}
{"text":"Lexicographers use the terms \" collocation \" and \" co - occurrence \" to describe various constraints on pairs of words .This paper will concentrate on \" collocation \" rather than \" co - occurrence \" although there is much overlap between these two terms .","label":"Background","metadata":{},"score":"64.315216"}
{"text":"More on the introduction to LTAG and the current status of our Korean LTAG grammar is documented in our technical report .A Treebank is a corpus annotated with morphological and syntactic information .Each word in the corpus is annotated with morpho - syntactic tags and each sentence is bracketed to represent its structural analysis .","label":"Background","metadata":{},"score":"64.53119"}
{"text":"5 Evaluation Experiments for unknown word guessing and POS tagging are performed using the Penn Treebank WSJ corpus having 50 POS tags .Four training data sets were constructed by randomly selecting approximately 1,000 , 10,000 , 100,000 and 1,000,000 tokens .","label":"Background","metadata":{},"score":"64.631805"}
{"text":"Building a Collocation Net 11 1stReading from Tij ; CC is the number of collocation candidates extracted from Tij and EPMI(CCi ) is the estimated pair - wise mutual information , which measures the change of information when the collocation candidate CCi is collocated .","label":"Background","metadata":{},"score":"64.65231"}
{"text":"( i.e. the current directory ) .The model_name parameter is required .Performs labelled parsing of the sentence .The sentence is represented as ( a reference to ) an array of words of the sentence .A word is represented as ( a reference to ) an array of fields , required by the config .","label":"Background","metadata":{},"score":"64.66339"}
{"text":"We could also implement their approach using LingPipe 's CRFs .It 's just that it 'd take a bit longer than an hour all in .Run it Yourself .You can get their code from their project home page , linked above .","label":"Background","metadata":{},"score":"64.770386"}
{"text":"We extract different LTAGs from the Penn Treebank .We show that certain strategies yield an improved extracted LTAG in terms of compactness , broad coverage , and supertagging accuracy .Furthermore , we perform a preliminary investigation in smoothing these grammars by means of an external linguistic resource , namely , the tree families of an XTAG grammar , a hand built grammar of English . by Hans Van Halteren , Jakub Zavrel , Walter Daelemans - Computational Linguistics , 2000 . \" ... this paper , we combine different systems employing known representations .","label":"Background","metadata":{},"score":"65.10557"}
{"text":"We extract different LTAGs from the Penn Treebank .We show that certain strategies yield an improved extracted LTAG in terms of compactness , broad coverage , and supertagging accuracy .Furthermore , we perform a preliminary investigation in smoothing these grammars by means of an external linguistic resource , namely , the tree families of an XTAG grammar , a hand built grammar of English . by Hans Van Halteren , Jakub Zavrel , Walter Daelemans - Computational Linguistics , 2000 . \" ... this paper , we combine different systems employing known representations .","label":"Background","metadata":{},"score":"65.10557"}
{"text":"Even with second - order features or latent variables , which would make exact parsing considerably slower or NP - hard , BP needs only O(n3 ) time with a small constant factor .Furthermore , such features significantly improve parse accuracy over exact first - order methods .","label":"Background","metadata":{},"score":"65.30629"}
{"text":"[ 2 ] K. W. Church and A. G. William , A comparison of the enhanced good turing and deleted estimation methods for estimating probabilities of English bigrams , Computer , Speech and Language , 5(1 ) , 1991 , 19 - 54 .","label":"Background","metadata":{},"score":"65.404015"}
{"text":"In co ... \" .We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .Starting with a simple Xbar grammar , we learn a new grammar whose nonterminals are subsymbols of the original nonterminals .","label":"Background","metadata":{},"score":"65.49728"}
{"text":"However , in part - of - speech tagging , we fre- quently encounter words that do not exist in training data .Such unknown words are usually handled by an exceptional process- ing , because the statistical information or rules for those words are unknown .","label":"Background","metadata":{},"score":"65.77968"}
{"text":"These can be searched by word , phrase , or subtree phrasal configurations .Clipslogo The latest incarnation of the Memory Based Tagger and Timbl learning software provides a shallow parser demo trained on either the Wall Street Journal corpus ( for general English ) or on a bio - medical corpus .","label":"Background","metadata":{},"score":"65.85144"}
{"text":"Thirdly , hypothesis testing - based methods are used to determine whether two words occur in the same context more than chance .For example , t - test [ 1 , 3 ] assumes normal distribution and looks at the difference between the observed and expected means , scaled by the variance of the sample data .","label":"Background","metadata":{},"score":"65.9949"}
{"text":"Shay , 2009 . \" ...We present a family of priors over probabilistic grammar weights , called the shared logistic normal distribution .This family extends the partitioned logistic normal distribution , enabling factored covariance between the probabilities of different derivation events in the probabilistic grammar , prov ... \" .","label":"Background","metadata":{},"score":"66.26564"}
{"text":"Information - extraction ( IE ) systems seek to distill semantic relations from naturallanguage text , but most systems use supervised learning of relation - specific examples and are thus limited by the availability of training data .Open IE systems such as TextRunner , on the other hand , aim to handle the unbounded number of relations found on the Web .","label":"Background","metadata":{},"score":"66.54514"}
{"text":"In our experimentation , only six most frequently occurring collocation relation types are considered .Table 1 shows them with their occurrence frequencies in the Reuters corpus .Table 1 .Six most frequently occurring collocation relation types ( in predicate + argument/ adjunct or head noun + modifier format ) .","label":"Background","metadata":{},"score":"66.554276"}
{"text":"Page 15 .Building a Collocation Net 15 1stReading ( EPMI ) as the strength degree .Obviously , the two - level collocation net can be easily extended to more levels through cascading such a two - level structure .","label":"Background","metadata":{},"score":"66.76287"}
{"text":"From the second to fourth columns , some features are deleted so as to see the contribution of the features to the accuracy .The decrease of accuracy caused by the errors in POS tagging by TnT is about 1 % .","label":"Background","metadata":{},"score":"67.0007"}
{"text":"Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .We believe that is largely in part due to the absence of large corpora accurately bracketed in terms of a perspicuous yet broad coverage LTAG .","label":"Background","metadata":{},"score":"67.05463"}
{"text":"Different criteria are used to determine the word co - occurrences .First of all , frequency - based method [ 12 , 8 , 18 ] uses the frequencies of the word pairs with the optional help of part - of - speech filter , stop word list and/or acceptable patterns .","label":"Background","metadata":{},"score":"67.06191"}
{"text":"If no , re - build the collocation net by adjusting the probability of each PTH and going to Step ( 2 ) .( 13 ) dIn this paper , the threshold for the average probability ratio is set to 0.99 . indd 1011/29/2007 2:52:47 PM .","label":"Background","metadata":{},"score":"67.28754"}
{"text":"This was just a straight out of the box , default settings eval .In general , one should n't trust results that report post - hoc best settings values as they 're almost always going to overestimate real performance for all the usual reasons .","label":"Background","metadata":{},"score":"67.52498"}
{"text":"Gives multiple parsings .In addition , it now can graph dependency relations and is a good way to learn to read the ENGCG function labels .Also has POS - tagged corpora .B. 2 phrase structure grammars .The Penn Treebank is a large corpus of articles from the Wall Street Journal that have been tagged with Penn Treebank tags and then parsed into properly bracketed trees according to a simple set of phrase structure rules conforming to Chomsky 's Government and Binding syntax .","label":"Background","metadata":{},"score":"67.8306"}
{"text":"The second one contains deprels assigned to the words ( or , to be more accurate , to the edges between each word and its parent ) , as strings .Similar to parse_labelled ( ) , but only unlabelled parsing is performed ( a labelling model is not used ) and only the parents are returned .","label":"Background","metadata":{},"score":"68.076996"}
{"text":"Reading methods are combined with the frequency - based method to reject the ones whose frequencies are below the predefined threshold [ 16].Generally , both the statistics and parsing - based approaches are only effective on frequently occurring words and not effective on less frequently occurring words due to the data sparseness problem .","label":"Background","metadata":{},"score":"68.10475"}
{"text":"We ... \" .this paper , we combine different systems employing known representations .The observation that suggests this approach is that systems that are designed differently , either because they use a different formalism or because they contain different knowledge , will typically produce different errors .","label":"Background","metadata":{},"score":"68.11505"}
{"text":"We ... \" .this paper , we combine different systems employing known representations .The observation that suggests this approach is that systems that are designed differently , either because they use a different formalism or because they contain different knowledge , will typically produce different errors .","label":"Background","metadata":{},"score":"68.11505"}
{"text":"Page 13 .Building a Collocation Net 13 1stReading Section 24 as development data and Section 23 as testing data ) while 20-best parse trees for each sentence are considered in re - ranking .This is done by building a collocation net on the golden parse trees in the training data and adjusting the probability of each parse tree candidate using the collocation net to achieve full parsing re - ranking , same as Equation ( 13 ) applied in Section 4 .","label":"Background","metadata":{},"score":"68.27511"}
{"text":"Their paper describes their tagging scheme as well as their CRF - based tagger .It uses Stanford 's CRF tagger with baseline features as a performance comparison .The code for their tagger 's also in the distribution .I 'm not sure what the license is - it 's listed as \" other open source \" ( I did n't even know Google Code let you do that - I thought it was \" free beer \" or nothing with them ) .","label":"Background","metadata":{},"score":"68.30316"}
{"text":"Table 1\"^ \" and \" $ \" mean the beginning and the end of the word respectively .SVM classifiers are created for each POS tag using all words in the training data .Then POS tags of unknown words are predicted us- ing those classifiers .","label":"Background","metadata":{},"score":"68.31793"}
{"text":"In shell ( or in any other way ) : .( the pdt_form model uses only the wordforms to build dependency trees ) .In Perl : .This should return : . DESCRIPTION .This is a Perl implementation of the MST Parser described in McDonald et al .","label":"Background","metadata":{},"score":"68.333885"}
{"text":".. sister adjunction can be used to create parse trees for all input strings , with only a slight penalty in accuracy .The results are graphed in Figure 14 .They use a different set of Supertags and so we used their result simply to get an approxima ... . \" ...","label":"Background","metadata":{},"score":"68.59154"}
{"text":".. sister adjunction can be used to create parse trees for all input strings , with only a slight penalty in accuracy .The results are graphed in Figure 14 .They use a different set of Supertags and so we used their result simply to get an approxima ... . \" ...","label":"Background","metadata":{},"score":"68.59154"}
{"text":"The l - bfgs limited - memory quasi - Newton method is the algorithm of choice for optimizing the parameters of large - scale log - linear models with L2 regularization , but it can not be used for an L1-regularized loss due to its non - differentiability whenever some parameter is zero .","label":"Background","metadata":{},"score":"68.62831"}
{"text":"Section 3 describes estimated pair - wise mutual information ( EPMI ) and estimated average mutual information ( EAMI ) to determine and measure the collocation relationship between any two words while Section 4 presents a method for automatically building a collocation net given a large law corpus .","label":"Background","metadata":{},"score":"68.80087"}
{"text":"5.1Unknown Word Guessing The accuracy of the unknown word guessing is shown in Table 3 together with the degree of polynomial kernel used for the experiments .Our method has higher accuracy compared to TnT for every training data set .Accuracies with various settings are shown in Table 4 .","label":"Background","metadata":{},"score":"68.85557"}
{"text":"This framework was applied previously in English / French and English / Arabic MT ( Nasr et . al .1997 ; Palmer , Rambow and Nasr 1998 ) .This web page is maintained by Chung - hye Han Last changed : $ Date : 2004/08/18 20:31:03 $ .","label":"Background","metadata":{},"score":"68.86655"}
{"text":"The texts in the manuals were originally in printed form , and in order to use them for our Treebank , we converted the manuals into a machine - readable form .This corpus contains 54,366 words and 5078 sentences . ...","label":"Background","metadata":{},"score":"69.09143"}
{"text":"FreeLing has been developed by the TALP Research Center at the Polytechnic University of Catelona .It includes a tagger with on - line ( limited ) demo and is downloable for Linux / Unix .LingPipe Uses large Brown tag set ( 82 lex tags plus punc ) and is trained on Brown corpus .","label":"Background","metadata":{},"score":"69.5436"}
{"text":"Bailly , Raphaël ; Carreras Pérez , Xavier ; Quattoni , Ariadna Julieta ( 2013 ) Conference report Open Access .Finite - State Transducers ( FST ) are a standard tool for modeling paired input output sequences and are used in numerous applications , ranging from computational biology to natural language processing .","label":"Background","metadata":{},"score":"69.74611"}
{"text":"Old Time Religion Gene Moutoux of Eastern High School in Louisville , KY , ret.,has put up extensive tutorial examples of sentences diagrammed according to Reed - Kellogg principles ( 1877 et seq . )For more than a century , this was sentence diagramming in America .","label":"Background","metadata":{},"score":"69.882454"}
{"text":"Log - linear and maximum - margin models are two commonly - used methods in supervised machine learning , and are frequently used in structured prediction problems .Efficient learning of parameters in these models is therefore ... .Lluis Martorell , Xavier ; Carreras Pérez , Xavier ; Màrquez Villodre , Lluís ( 2013 - 05 )","label":"Background","metadata":{},"score":"69.88524"}
{"text":"Al- though the approach is applicable to any type of language model , we focus on the case of statistical disambiguators that are trained on annotated corpora .The examples of the task that are present in the corpus and its annotation are fed into a learning algorithm , which induces a model of the desired input - output mapping in the form of a classifier .","label":"Background","metadata":{},"score":"70.30191"}
{"text":"Al- though the approach is applicable to any type of language model , we focus on the case of statistical disambiguators that are trained on annotated corpora .The examples of the task that are present in the corpus and its annotation are fed into a learning algorithm , which induces a model of the desired input - output mapping in the form of a classifier .","label":"Background","metadata":{},"score":"70.30191"}
{"text":"Although lexical amb ...Twitter POS Tagging with LingPipe and ARK Tweet Data .The Data .We will train and test on anything that 's easy to parse .Up today is a basic English part - of - speech tagging for Twitter developed by Kevin Gimpel et al .","label":"Background","metadata":{},"score":"70.37991"}
{"text":"Version 2 ! draws dependency arcs and other CoreNLP tasks ( NER , coreference ) .Bou has also written a Java - based grapher tydevi ( typed dependencies viewer ) that uses the Stanford parser to draw static diagrams with curved labelled nodes .","label":"Background","metadata":{},"score":"70.44304"}
{"text":"It tags each word of continuous text with a PennTree POS .Special feature : it has a much slower bidirectional mode as well as \" left three words \" mode of operation .Bidirectional scored very well on the Tagger Contest .","label":"Background","metadata":{},"score":"70.46951"}
{"text":"[ 18 ] J. Zhao and C. N. Huang , Aquasi - dependency model for the structural analysis of Chinese BaseNPs , COLING - ACL'1998 , University de Montreal , Canada , 1998 , pp . 1 - 7 . [19 ] G. D. Zhou and K. T. Lua , Word association and MI - trigger - based language modeling , COLING - ACL'1998 , University of Montreal , Canada , 1998 , pp .","label":"Background","metadata":{},"score":"70.73842"}
{"text":"WOE can operate in two modes : when restricted to POS tag features , it runs as quickly as TextRunner , but when set to use dependency - parse features its precision and recall rise even higher . ... h recall .","label":"Background","metadata":{},"score":"70.77876"}
{"text":"Bailly , Raphaël ; Carreras Pérez , Xavier ; Quattoni , Ariadna Julieta ( 2012 ) Conference report Open Access .Finite - State Transducers ( FST ) are a standard tool for modeling paired inputoutput sequences and are used in numerous applications , ranging from computational biology to natural language processing .","label":"Background","metadata":{},"score":"70.988785"}
{"text":"Likelihood ratio [ 5 ] assumes binomial distribution and tells how more likely the independence hypothesis is than the dependence hypothesis .Fourthly , mutual information - based method [ 13 , 17 , 19 , 20 ] tells the change of information when two words co - occur .","label":"Background","metadata":{},"score":"71.08028"}
{"text":"In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) and in Kinyon ( 00b ) , which allows to factor the information contained in several Supertags into a single structure and to encode functional information in a systematic manner .","label":"Background","metadata":{},"score":"71.10652"}
{"text":"In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) and in Kinyon ( 00b ) , which allows to factor the information contained in several Supertags into a single structure and to encode functional information in a systematic manner .","label":"Background","metadata":{},"score":"71.10652"}
{"text":"It too will produce analysis in terms of grammatical dependency relations ( in RASP set of relations ) .Try the demo with \" GR \" ticked .VISL under Eckhard Bick has extensive tools for tagging , parsing , and graphing , and not just for English .","label":"Background","metadata":{},"score":"71.19394"}
{"text":"We show how a Supertagger can be used to drastically reduce the syntactic lexical ambiguity for a given input and can be used in combination with an LTAG parser to radically improve parsing efficiency .We then turn our attention to from parsing efficiency to parsing accuracy and provide a method by which we can effectively combine the output of a Supertagger and a statistical LTAG parser using a co - training algorithm for bootstrapping new labeled data .","label":"Background","metadata":{},"score":"72.67133"}
{"text":"We show how a Supertagger can be used to drastically reduce the syntactic lexical ambiguity for a given input and can be used in combination with an LTAG parser to radically improve parsing efficiency .We then turn our attention to from parsing efficiency to parsing accuracy and provide a method by which we can effectively combine the output of a Supertagger and a statistical LTAG parser using a co - training algorithm for bootstrapping new labeled data .","label":"Background","metadata":{},"score":"72.67133"}
{"text":"Estimation is with simple additive smoothing ( i.e. , MAP estimates given symmetric Dirichlet priors ) for the initial state and transition probabilities and Witten - Bell smoothing for the character LMs .Our main motivation for doing things this way is that ( a ) it 's online , letting us train an example at a time , and ( b ) it 's reasonably fast when it runs .","label":"Background","metadata":{},"score":"72.69295"}
{"text":"For convenience , each word and feature bigram in the first level is also regarded as a class ( atomic class ) .That is to say , each first level atomic class contains only one bigram while each second level class contains one or more word and feature bigrams clustered from first level atomic classes .","label":"Background","metadata":{},"score":"72.80347"}
{"text":"A sentence \" The sheep eat grass . \" to be parsed by using such a config would be then represented e.g. as : . , \" . \" ] , ] ; .MSTperl returns two array refs .The first one describes the dependency tree structure by listing a parent node for each word of the sentence , represented by an integer .","label":"Background","metadata":{},"score":"73.076004"}
{"text":"PennTree tags .The complete , detailed PennTree Guide to Part of Speech Tagging is here ( 31 pages ) .TreeTagger produces vertical POS format tagging only with an enhanced Penntree tag set .( Tagger is trainable HMM - type .","label":"Background","metadata":{},"score":"73.17971"}
{"text":"ADJ_ADJ(eligible ) can be measured as a collocation with EAMI of 1.01517e-05 and EPMI of 1.174579 although this collocation candidate does not exist in the corpus .The main reason is that the collocation net provides a word - clustering mechanism to resolve the problem of data sparseness .","label":"Background","metadata":{},"score":"73.434555"}
{"text":"Although lexical amb ...Tools . \" ...The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .","label":"Background","metadata":{},"score":"73.48285"}
{"text":"Support Vector Machines for Multi - Class Pattern Recognition .In Proceedings of the Seventh European Symposium On Artificial Neural Networks(ESANN-99 ) .Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .","label":"Background","metadata":{},"score":"73.57051"}
{"text":"The Stanford Parser is used to derive dependencies from CJ50 and gold parse trees .Figure 8 shows the detailed P / R curves .We can see that although today ... .by Jenny Rose Finkel , Alex Kleeman , Christopher D. Manning - In Proc .","label":"Background","metadata":{},"score":"73.968895"}
{"text":"This family extends the partitioned logistic normal distribution , enabling factored covariance between the probabilities of different derivation events in the probabilistic grammar , providing a new way to encode prior knowledge about an unknown grammar .We describe a variational EM algorithm for learning a probabilistic grammar based on this family of priors .","label":"Background","metadata":{},"score":"74.13258"}
{"text":"The results show that the performance is comparable to TnT in the first case and better in the second case .Between the first case and the second case , the accuracy for known words are al- most equal , but the accuracy of the first case for unknown words is lower than that of the second case .","label":"Background","metadata":{},"score":"74.192825"}
{"text":"DGA - the dependency Grammar Annotator- is a little Java - based tool for drawing dependency trees with labels .The online demo offers one set of labels and relations ; to customize the list , you have to download the DGA and change the Configuration file .","label":"Background","metadata":{},"score":"74.334015"}
{"text":"The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .We believe that is largely in part due to the absence of large corpora accurately bracketed in terms of a perspicuous yet broad coverage LTAG .","label":"Background","metadata":{},"score":"74.372406"}
{"text":"We will study more possibilities in the near future .indd 611/29/2007 2:52:46 PM .Page 7 .Building a Collocation Net 7 1stReading 3.1 .EAMI : Estimated Average Mutual Information Traditionally in information theory , average mutual information ( AMI ) measures the co - occurrence relationship between two words as follows : .","label":"Background","metadata":{},"score":"74.40009"}
{"text":"The TAG formalism in general , and lexicalized TAG in particular , are well - suited for linguistic applications .An LTAG consists of a finite set of elementary trees anchoring lexical items and composition operations of substitution and adjunction .The elementary trees represent extended projections of lexical items and encapsulate syntactic / semantic arguments of the lexical anchor .","label":"Background","metadata":{},"score":"74.678894"}
{"text":"Available for Linux and a demo version for Windows . )Version 3.1 is quite impressive and is an entry in the Great PennTree Tagger Contest ( below ) .Here is n n - line interface .Downloaded version also has chunker .","label":"Background","metadata":{},"score":"74.890175"}
{"text":"We present an algorithm Orthant - Wise Limited - memory Quasi - Newton ( owlqn ) , based on l - bfgs , that can efficiently optimize the L1-regularized log - likelihood of log - linear models with millions of parameters .","label":"Background","metadata":{},"score":"74.9908"}
{"text":"By categorizing a user and related connections , one can be placed in an imaginary category specific subset of users , called Thought Bubbles .Following the trace of people who are also active within the same specific Thought Bubble , should reveal interesting and helpful connections between similar minded users .","label":"Background","metadata":{},"score":"75.079"}
{"text":"The POS tags on both sides of the unknown word were tagged by TnT. Test data for POS tagging consists of about 285,000 tokens differing from the training data .The number of known / unknown words and the percentage of unknown word in the test data are shown in Table 2 .","label":"Background","metadata":{},"score":"75.46054"}
{"text":"In this paper we propose to use supertags to expose syntactic dependencies which are unavailable with POS tags .We first propose a novel method of app ... \" .Supertagging is the tagging process of assigning the correct elementary tree of LTAG , or the correct supertag , to each word of an input sentence .","label":"Background","metadata":{},"score":"75.499176"}
{"text":"In this paper we propose to use supertags to expose syntactic dependencies which are unavailable with POS tags .We first propose a novel method of app ... \" .Supertagging is the tagging process of assigning the correct elementary tree of LTAG , or the correct supertag , to each word of an input sentence .","label":"Background","metadata":{},"score":"75.499176"}
{"text":"As a parsing algorithm , BP is both asymptotically and empirically efficient .E ... \" .We formulate dependency parsing as a graphical model with the novel ingredient of global constraints .We show how to apply loopy belief propagation ( BP ) , a simple and effective tool for approximate learning and inference .","label":"Background","metadata":{},"score":"76.172745"}
{"text":"We also present a proof that owl - qn is guaranteed to converge to a globally optimal parameter vector . \" ...Statistical parsers trained and tested on the Penn Wall Street Journal ( WSJ ) treebank have shown vast improvements over the last 10 years .","label":"Background","metadata":{},"score":"76.311745"}
{"text":"COPYRIGHT AND LICENSE .Copyright © 2012 by Institute of Formal and Applied Linguistics , Charles University in Prague .This module is free software ; you can redistribute it and/or modify it under the same terms as Perl itself .Module Install Instructions .","label":"Background","metadata":{},"score":"77.222435"}
{"text":"Jump to version 0.11336 ( RUR on 2013 - 12 - 03 ) 0.11319 ( RUR on 2013 - 11 - 28 ) 0.08268 ( RUR on 2012 - 02 - 24 ) 0.08055 ( TKR on 2012 - 02 - 07 ) 0.07298 ( TKR on 2011 - 11 - 15 ) 0.11306 ( RUR on 2013 - 11 - 24 ) 0.11299 ( RUR on 2013 - 11 - 24 ) .","label":"Background","metadata":{},"score":"77.56102"}
{"text":"We will discuss this in more detail in Section 3 .Moreover , we also extend the EPMI and EAMI to determine and measure the collocation relationship between any two words .In this way , we can not only determine the most possible collocation relationship between any two words but also measure the strength of the collocation relationship between them .","label":"Background","metadata":{},"score":"77.6843"}
{"text":"For the following example sentence , ... Greenville/(Unknown Word ) days / NNSbefore / IN thefeatures \" Greenville \" These features are almost same as those used by Ratnaparkhi ( Ratnaparkhi , 1996 ) , but combination of POS tags is not used because polynomial kernel can automatically consider them .","label":"Background","metadata":{},"score":"77.68664"}
{"text":"aPart of the work was done when the author was at the Institute for Infocomm Research , Singapore . indd 1 11/29/2007 2:52:45 PM .Page 2 . 2 Guodong Zhou et al . 1stReading For example , we always say \" strong tea \" instead of \" strong computer \" and \" powerful computer \" instead of \" powerful tea \" .","label":"Background","metadata":{},"score":"78.18941"}
{"text":"Page 9 .For example , parse tree re - ranking can be performed by considering the EPMI of the included collocation candidates in parse trees .Collocation relationship between any two words Given any two words wi and wj , the EPMI and EAMI between them are defined as the EPMI and EAMI of the optimal collocation candidate related to the two words .","label":"Background","metadata":{},"score":"78.480484"}
{"text":"You can check it out anonymously using Subversion : .The code 's in a single file , stored under the src subdirectory of the package : . package com.lingpipe.twpos ; import com.aliasi.classify .LingPipe 's pretty fast for this sort of thing , with the entire program above , including I / O , corpus parsing , training , and testing taking a total of 5 seconds on my now ancient workstation .","label":"Background","metadata":{},"score":"79.000145"}
{"text":"RankBoost ( Freund et al ., 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs ... \" .this paper , we investigate an approach to such a choice based on reranking a set of candidate supertags and their confidence scores .","label":"Background","metadata":{},"score":"80.25843"}
{"text":"RankBoost ( Freund et al ., 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs ... \" .this paper , we investigate an approach to such a choice based on reranking a set of candidate supertags and their confidence scores .","label":"Background","metadata":{},"score":"80.25843"}
{"text":"Here , Chm can be either C1i itself or any class in L2 while Cgn can be either C1j itself or any class in L2 .That is , C1i / C1j can be either mapped to itself when the word and feature bigram occurs frequently or mapped to any class in L2 when the word and feature bigram does not occur frequently .","label":"Background","metadata":{},"score":"80.40303"}
{"text":"TnT - A Statistical Part- of - Speech Tagger .6th Applied NLP Conference(ANLP-2000 ) , pages 224 - 231 .In Proceedings of the E. Brill .Transformation - Based Error-Driven Learning and Natural Language Processing : A Case Study in Part - of-","label":"Background","metadata":{},"score":"80.614685"}
{"text":"Many variant layouts available .Antelope logo Proxem Antelope is a package of taggers , chunkers , parsers , and graphers that can draw trees that are both PennTree constituent style and marked for grammatical relations ( using the Stanford parser ) .","label":"Background","metadata":{},"score":"80.825264"}
{"text":"The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .We believe that is largely in part due to the absence of large cor ... \" .","label":"Background","metadata":{},"score":"80.97337"}
{"text":"\" [ Show abstract ] [ Hide abstract ] ABSTRACT : The concept of so called Thought Bubbles deals with the problem of finding appropriate new connections within Social Networks , especially Twitter .As a byproduct of exploring new users , Tweets are classified and rated and are used to generate a kind of news feed , which will extend the personal Twitter feed .","label":"Background","metadata":{},"score":"88.70273"}
{"text":"We first propose a novel method of applying Sparse Network of Winnow ( SNoW ) to sequential models .Then we use . \" ...In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .","label":"Background","metadata":{},"score":"88.754974"}
{"text":"We first propose a novel method of applying Sparse Network of Winnow ( SNoW ) to sequential models .Then we use . \" ...In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .","label":"Background","metadata":{},"score":"88.754974"}
{"text":"The shared task was run over 12 weeks , drawing initial interest from 42 teams .Of these teams , 24 submitted final results .The evaluation results are encouraging , indicating that state - of - the - art performance is approaching a practically applicable level and revealing some remaining challenges . ... parsers . \" ...","label":"Background","metadata":{},"score":"92.50008"}
{"text":"They test out very well .No demos .Great PennTree Tagger Contest : Results of the second heat : Here are slightly edited taggings of Lincoln 's Gettysburg Address by SVM Tool , OpenNLP , TreeTagger , Stanford Tagger , CCG , and FreeLing tagger , with CLAWS added for comparison , though with different tag set .","label":"Background","metadata":{},"score":"92.619736"}
{"text":"Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .Publisher conditions are provided by RoMEO .Differing provisions from the publisher 's actual policy or licence agreement may be applicable .","label":"Background","metadata":{},"score":"93.27754"}
{"text":"The others are : .George L. Dillon University of Washington 4 November 1999 Revised 10 March 2000 Again , 16 April 2000 Again , 12 February 2001 Again , 18 November 2001 , January 2003 , 2004 , March 2005 , May 2007 , December 2009 , November 2010 , March 2015 Full - text .","label":"Background","metadata":{},"score":"103.28444"}
