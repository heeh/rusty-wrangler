{"text":"Data is drawn from FrameNet , WordNet and SUMO , together they provide intensive dictionary information , case frames of verbs , lexical relations among verb , encyclopedic world knowledge and the systemic semantic categories of English verbs .The constructed knowledge base explains the meaning of verbs throughout in the lexical semantic layer and the clausal conceptual layer .","label":"Uses","metadata":{},"score":"32.825554"}
{"text":"Lexical data included in the ontological knowledge base on the other hand not only serves as a dictionary database but also links to the SFG concepts Process which enable axiomatic exploration to the whole systemic framework defined in the knowledge base .","label":"Uses","metadata":{},"score":"37.727394"}
{"text":"Each Process type is instantiated with English verbs .Lexical data has been imported from WordNet ( Fellbaum , 1988 ) including more than 11,000 verb lemma and 13,650 sense entries , a total of 24,890 lemma - sense pairs .This research presents the semantics of verbs in an ontological knowledge representation .","label":"Uses","metadata":{},"score":"41.226337"}
{"text":"The four systemic Process types - Material Process , Mental Process , Verbal Process and Relational Process - form the four semantic categories and this research aims at categorizing the 11,000 verbs from WordNet into these four categories .This research also aims at defining an explicit and delicate description of the Experiential Meaning in SFG .","label":"Uses","metadata":{},"score":"43.421715"}
{"text":"All exploited resources are ontologically mapped and consolidated into a unified resource .This allows the process of semantic categorization to be automated by various ontology engineering methodologies including ontology mapping , conceptual relations , semantic similarity and clustering , the application of axiom and inferences .","label":"Uses","metadata":{},"score":"45.19992"}
{"text":"For the VerbOcean , the verbs have to be in the base form .We used the \" MontyLingua \" tool to convert the verbs into their base form .NEGATION_rules by UAIC .Negation rules check in the dependency trees on verbs descending branches to see if some categories of words that change the meaning are found .","label":"Uses","metadata":{},"score":"50.504517"}
{"text":"For the VerbOcean , the verbs have to be in the base form .We used the \" MontyLingua \" tool to convert the verbs into their base form .NEGATION_rules by UAIC .Negation rules check in the dependency trees on verbs descending branches to see if some categories of words that change the meaning are found .","label":"Uses","metadata":{},"score":"50.504517"}
{"text":"For the VerbOcean , the verbs have to be in the base form .We used the \" MontyLingua \" tool to convert the verbs into their base form .NEGATION_rules by UAIC .Negation rules check in the dependency trees on verbs descending branches to see if some categories of words that change the meaning are found .","label":"Uses","metadata":{},"score":"50.504517"}
{"text":"For the VerbOcean , the verbs have to be in the base form .We used the \" MontyLingua \" tool to convert the verbs into their base form .NEGATION_rules by UAIC .Negation rules check in the dependency trees on verbs descending branches to see if some categories of words that change the meaning are found .","label":"Uses","metadata":{},"score":"50.504517"}
{"text":"C55 2008 x , 132 leaves : ill .30 cm .Thesis ( Ph .D.)--City University of Hong Kong , 2008 .Includes bibliographical references ( leaves 111 - 116 ) .Type : .This research constructs a linguistic resource in the form of a knowledge base which automatically classifies English verbs into semantic categories referred to as types of Processes in Systemic Functional Grammar ( SFG ) ( Halliday , 1994 & 2004 ) .","label":"Uses","metadata":{},"score":"50.618774"}
{"text":"The problem is resolved by interoperation of two linguistic resources , WordNet and FrameNet ( Baker et al , 1998 ) , and two ontologies : Generalized Upper Model ( Bateman , 1995 ) and Suggested Upper Merged Ontology ( Niles and Pease , 2001 ) .","label":"Uses","metadata":{},"score":"51.946213"}
{"text":"We used the \" MontyLingua \" tool to convert the verbs into their base form .NEGATION_rules by UAIC .Negation rules check in the dependency trees on verbs descending branches to see if some categories of words that change the meaning are found .","label":"Uses","metadata":{},"score":"56.276875"}
{"text":"We used the \" MontyLingua \" tool to convert the verbs into their base form .NEGATION_rules by UAIC .Negation rules check in the dependency trees on verbs descending branches to see if some categories of words that change the meaning are found .","label":"Uses","metadata":{},"score":"56.276875"}
{"text":"We used the \" MontyLingua \" tool to convert the verbs into their base form .NEGATION_rules by UAIC .Negation rules check in the dependency trees on verbs descending branches to see if some categories of words that change the meaning are found .","label":"Uses","metadata":{},"score":"56.276875"}
{"text":"We used the \" MontyLingua \" tool to convert the verbs into their base form .NEGATION_rules by UAIC .Negation rules check in the dependency trees on verbs descending branches to see if some categories of words that change the meaning are found .","label":"Uses","metadata":{},"score":"56.276875"}
{"text":"We used the \" MontyLingua \" tool to convert the verbs into their base form .NEGATION_rules by UAIC .Negation rules check in the dependency trees on verbs descending branches to see if some categories of words that change the meaning are found .","label":"Uses","metadata":{},"score":"56.276875"}
{"text":"WordNet .PeMoZa2.2way .Verb Entailment from Wordnet .We use several relations from wordnet , such as synonyms , hyponym , hypernym et al . .The system is based on machine learning approach .The ablation test was obtained with 2 less features using WordNet in the training and testing steps .","label":"Uses","metadata":{},"score":"58.88375"}
{"text":"WordNet .PeMoZa2.2way .Verb Entailment from Wordnet .We use several relations from wordnet , such as synonyms , hyponym , hypernym et al . .The system is based on machine learning approach .The ablation test was obtained with 2 less features using WordNet in the training and testing steps .","label":"Uses","metadata":{},"score":"58.88375"}
{"text":"VerbOcean . Siel_093.3way .Similarity / anthonymy / unrelatedness between verbs .WikiPedia .BIU1.2way .Lexical rules extracted from Wikipedia definition sentences , title parenthesis , redirect and hyperlink relations .Rules extracted from WP using Latent Semantic Analysis ( LSA ) .","label":"Uses","metadata":{},"score":"59.37319"}
{"text":"VerbOcean . Siel_093.3way .Similarity / anthonymy / unrelatedness between verbs .WikiPedia .BIU1.2way .Lexical rules extracted from Wikipedia definition sentences , title parenthesis , redirect and hyperlink relations .Rules extracted from WP using Latent Semantic Analysis ( LSA ) .","label":"Uses","metadata":{},"score":"59.37319"}
{"text":"VerbOcean . Siel_093.3way .Similarity / anthonymy / unrelatedness between verbs .WikiPedia .BIU1.2way .Lexical rules extracted from Wikipedia definition sentences , title parenthesis , redirect and hyperlink relations .Rules extracted from WP using Latent Semantic Analysis ( LSA ) .","label":"Uses","metadata":{},"score":"59.37319"}
{"text":"VerbOcean . Siel_093.3way .Similarity / anthonymy / unrelatedness between verbs .WikiPedia .BIU1.2way .Lexical rules extracted from Wikipedia definition sentences , title parenthesis , redirect and hyperlink relations .Rules extracted from WP using Latent Semantic Analysis ( LSA ) .","label":"Uses","metadata":{},"score":"59.37319"}
{"text":"VerbOcean . Siel_093.3way .Similarity / anthonymy / unrelatedness between verbs .WikiPedia .BIU1.2way .Lexical rules extracted from Wikipedia definition sentences , title parenthesis , redirect and hyperlink relations .Rules extracted from WP using Latent Semantic Analysis ( LSA ) .","label":"Uses","metadata":{},"score":"59.37319"}
{"text":"VerbOcean . Siel_093.3way .Similarity / anthonymy / unrelatedness between verbs .WikiPedia .BIU1.2way .Lexical rules extracted from Wikipedia definition sentences , title parenthesis , redirect and hyperlink relations .Rules extracted from WP using Latent Semantic Analysis ( LSA ) .","label":"Uses","metadata":{},"score":"59.37319"}
{"text":"VerbOcean . Siel_093.3way .Similarity / anthonymy / unrelatedness between verbs .WikiPedia .BIU1.2way .Lexical rules extracted from Wikipedia definition sentences , title parenthesis , redirect and hyperlink relations .Rules extracted from WP using Latent Semantic Analysis ( LSA ) .","label":"Uses","metadata":{},"score":"59.37319"}
{"text":"VerbOcean . Siel_093.3way .Similarity / anthonymy / unrelatedness between verbs .WikiPedia .BIU1.2way .Lexical rules extracted from Wikipedia definition sentences , title parenthesis , redirect and hyperlink relations .Rules extracted from WP using Latent Semantic Analysis ( LSA ) .","label":"Uses","metadata":{},"score":"59.37319"}
{"text":"VerbOcean . Siel_093.3way .Similarity / anthonymy / unrelatedness between verbs .WikiPedia .BIU1.2way .Lexical rules extracted from Wikipedia definition sentences , title parenthesis , redirect and hyperlink relations .Rules extracted from WP using Latent Semantic Analysis ( LSA ) .","label":"Uses","metadata":{},"score":"59.37319"}
{"text":"QUANTA1.2way .We use Named Entity similarity as a feature .Stopword list .FBKirst1.2way .A list of the 572 most frequent English words has been collected in order to prevent assigning high costs to the deletion / insertion of terms that are unlikely to bring relevant information to detect entailment , and to avoid substituting these terms with any content word .","label":"Uses","metadata":{},"score":"60.07123"}
{"text":"QUANTA1.2way .We use Named Entity similarity as a feature .Stopword list .FBKirst1.2way .A list of the 572 most frequent English words has been collected in order to prevent assigning high costs to the deletion / insertion of terms that are unlikely to bring relevant information to detect entailment , and to avoid substituting these terms with any content word .","label":"Uses","metadata":{},"score":"60.07123"}
{"text":"QUANTA1.2way .We use Named Entity similarity as a feature .Stopword list .FBKirst1.2way .A list of the 572 most frequent English words has been collected in order to prevent assigning high costs to the deletion / insertion of terms that are unlikely to bring relevant information to detect entailment , and to avoid substituting these terms with any content word .","label":"Uses","metadata":{},"score":"60.07123"}
{"text":"QUANTA1.2way .We use Named Entity similarity as a feature .Stopword list .FBKirst1.2way .A list of the 572 most frequent English words has been collected in order to prevent assigning high costs to the deletion / insertion of terms that are unlikely to bring relevant information to detect entailment , and to avoid substituting these terms with any content word .","label":"Uses","metadata":{},"score":"60.07123"}
{"text":"QUANTA1.2way .We use Named Entity similarity as a feature .Stopword list .FBKirst1.2way .A list of the 572 most frequent English words has been collected in order to prevent assigning high costs to the deletion / insertion of terms that are unlikely to bring relevant information to detect entailment , and to avoid substituting these terms with any content word .","label":"Uses","metadata":{},"score":"60.07123"}
{"text":"QUANTA1.2way .We use Named Entity similarity as a feature .Stopword list .FBKirst1.2way .A list of the 572 most frequent English words has been collected in order to prevent assigning high costs to the deletion / insertion of terms that are unlikely to bring relevant information to detect entailment , and to avoid substituting these terms with any content word .","label":"Uses","metadata":{},"score":"60.07123"}
{"text":"QUANTA1.2way .We use Named Entity similarity as a feature .Stopword list .FBKirst1.2way .A list of the 572 most frequent English words has been collected in order to prevent assigning high costs to the deletion / insertion of terms that are unlikely to bring relevant information to detect entailment , and to avoid substituting these terms with any content word .","label":"Uses","metadata":{},"score":"60.07123"}
{"text":"QUANTA1.2way .We use Named Entity similarity as a feature .Stopword list .FBKirst1.2way .A list of the 572 most frequent English words has been collected in order to prevent assigning high costs to the deletion / insertion of terms that are unlikely to bring relevant information to detect entailment , and to avoid substituting these terms with any content word .","label":"Uses","metadata":{},"score":"60.07123"}
{"text":"QUANTA1.2way .We use Named Entity similarity as a feature .Stopword list .FBKirst1.2way .A list of the 572 most frequent English words has been collected in order to prevent assigning high costs to the deletion / insertion of terms that are unlikely to bring relevant information to detect entailment , and to avoid substituting these terms with any content word .","label":"Uses","metadata":{},"score":"60.07123"}
{"text":"WordNet .PeMoZa2.2way .Verb Entailment from Wordnet .WordNet .QUANTA1.2way .We use several relations from wordnet , such as synonyms , hyponym , hypernym et al . .Other .Rhodes.3way .Lexicon based match : we chose .","label":"Uses","metadata":{},"score":"61.352562"}
{"text":"WordNet .PeMoZa2.2way .Verb Entailment from Wordnet .WordNet .QUANTA1.2way .We use several relations from wordnet , such as synonyms , hyponym , hypernym et al . .WordNet .Sagan1.3way .The system is based on machine learning approach .","label":"Uses","metadata":{},"score":"64.26141"}
{"text":"Boeing3.3way .Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H .","label":"Uses","metadata":{},"score":"64.3875"}
{"text":"Boeing3.3way .Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H .","label":"Uses","metadata":{},"score":"64.3875"}
{"text":"Boeing3.3way .Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H .","label":"Uses","metadata":{},"score":"64.3875"}
{"text":"Boeing3.3way .Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H .","label":"Uses","metadata":{},"score":"64.3875"}
{"text":"Boeing3.3way .Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H .","label":"Uses","metadata":{},"score":"64.3875"}
{"text":"Boeing3.3way .Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H .","label":"Uses","metadata":{},"score":"64.3875"}
{"text":"Boeing3.3way .Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H .","label":"Uses","metadata":{},"score":"64.3875"}
{"text":"Boeing3.3way .Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H .","label":"Uses","metadata":{},"score":"64.3875"}
{"text":"Boeing3.3way .Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H .","label":"Uses","metadata":{},"score":"64.3875"}
{"text":"Sagan1.3way .The system is based on machine learning approach .The ablation test was obtained with 2 less features using WordNet ( namely , string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps .","label":"Uses","metadata":{},"score":"64.61469"}
{"text":"Sagan1.3way .The system is based on machine learning approach .The ablation test was obtained with 2 less features using WordNet ( namely , string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps .","label":"Uses","metadata":{},"score":"64.61469"}
{"text":"Sagan1.3way .The system is based on machine learning approach .The ablation test was obtained with 2 less features using WordNet ( namely , string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps .","label":"Uses","metadata":{},"score":"64.61469"}
{"text":"Sagan1.3way .The system is based on machine learning approach .The ablation test was obtained with 2 less features using WordNet ( namely , string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps .","label":"Uses","metadata":{},"score":"64.61469"}
{"text":"WordNet .PeMoZa2.2way .Verb Entailment from Wordnet .WordNet .QUANTA1.2way .We use several relations from wordnet , such as synonyms , hyponym , hypernym et al . .WordNet .Rhodes.3way .Lexicon based match : we chose .","label":"Uses","metadata":{},"score":"65.2222"}
{"text":"WordNet .Sagan1.3way .The system is based on machine learning approach .The ablation test was obtained with 2 less features using WordNet ( namely , string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps .","label":"Uses","metadata":{},"score":"66.84619"}
{"text":"WordNet .Sagan1.3way .The system is based on machine learning approach .The ablation test was obtained with 2 less features using WordNet ( namely , string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps .","label":"Uses","metadata":{},"score":"66.84619"}
{"text":"WordNet .PeMoZa2.2way .Verb Entailment from Wordnet .WordNet .QUANTA1.2way .We use several relations from wordnet , such as synonyms , hyponym , hypernym et al . .WordNet .Rhodes1.3way .Lexicon based match : we chose a very simple metric : matching between words in T and H based on a path of distance at most 2 in the WordNet graph , using any links ( hyponymy , hypernymy , meronymy , pertainymy , etc . ) .","label":"Uses","metadata":{},"score":"69.88004"}
{"text":"WordNet .PeMoZa2.2way .Verb Entailment from Wordnet .WordNet .QUANTA1.2way .We use several relations from wordnet , such as synonyms , hyponym , hypernym et al . .WordNet .Rhodes1.3way .Lexicon based match : we chose a very simple metric : matching between words in T and H based on a path of distance at most 2 in the WordNet graph , using any links ( hyponymy , hypernymy , meronymy , pertainymy , etc . ) .","label":"Uses","metadata":{},"score":"69.88004"}
{"text":"WordNet .PeMoZa2.2way .Verb Entailment from Wordnet .WordNet .QUANTA1.2way .We use several relations from wordnet , such as synonyms , hyponym , hypernym et al . .WordNet .Rhodes.3way .Lexicon based match : we chose a very simple metric : matching between words in T and H based on a path of distance at most 2 in the WordNet graph , using any links ( hyponymy , hypernymy , meronymy , pertainymy , etc . ) .","label":"Uses","metadata":{},"score":"70.57062"}
{"text":"WordNet .PeMoZa2.2way .Verb Entailment from Wordnet .WordNet .QUANTA1.2way .We use several relations from wordnet , such as synonyms , hyponym , hypernym et al . .WordNet .Rhodes.3way .Lexicon based match : we chose a very simple metric : matching between words in T and H based on a path of distance at most 2 in the WordNet graph , using any links ( hyponymy , hypernymy , meronymy , pertainymy , etc . ) .","label":"Uses","metadata":{},"score":"70.57062"}
{"text":"Named Entity match : measure based onthe number of Nes in the hypothesis that match in the corresponding text .For named entity recognition , the RASP Parser ( Briscoe et al . , 2006 ) nertag component has been used . syntactic and semantic parsing .","label":"Uses","metadata":{},"score":"70.82747"}
{"text":"Named Entity match : measure based on the number of Nes in the hypothesis that match in the corresponding text .For named entity recognition , the RASP Parser ( Briscoe et al . , 2006 ) nertag component has been used . syntactic and semantic parsing .","label":"Uses","metadata":{},"score":"72.67366"}
{"text":"Named Entity match : measure based on the number of Nes in the hypothesis that match in the corresponding text .For named entity recognition , the RASP Parser ( Briscoe et al . , 2006 ) nertag component has been used . syntactic and semantic parsing .","label":"Uses","metadata":{},"score":"72.67366"}
{"text":"Named Entity match : measure based on the number of Nes in the hypothesis that match in the corresponding text .For named entity recognition , the RASP Parser ( Briscoe et al . , 2006 ) nertag component has been used . syntactic and semantic parsing .","label":"Uses","metadata":{},"score":"72.67366"}
{"text":"Named Entity match : measure based on the number of Nes in the hypothesis that match in the corresponding text .For named entity recognition , the RASP Parser ( Briscoe et al . , 2006 ) nertag component has been used . syntactic and semantic parsing .","label":"Uses","metadata":{},"score":"72.67366"}
{"text":"Named Entity match : measure based on the number of Nes in the hypothesis that match in the corresponding text .For named entity recognition , the RASP Parser ( Briscoe et al . , 2006 ) nertag component has been used . syntactic and semantic parsing .","label":"Uses","metadata":{},"score":"72.67366"}
{"text":"Named Entity match : measure based on the number of Nes in the hypothesis that match in the corresponding text .For named entity recognition , the RASP Parser ( Briscoe et al . , 2006 ) nertag component has been used . syntactic and semantic parsing .","label":"Uses","metadata":{},"score":"72.67366"}
{"text":"Named Entity match : measure based on the number of Nes in the hypothesis that match in the corresponding text .For named entity recognition , the RASP Parser ( Briscoe et al . , 2006 ) nertag component has been used . syntactic and semantic parsing .","label":"Uses","metadata":{},"score":"72.67366"}
{"text":"Named Entity match : measure based on the number of Nes in the hypothesis that match in the corresponding text .For named entity recognition , the RASP Parser ( Briscoe et al . , 2006 ) nertag component has been used . syntactic and semantic parsing .","label":"Uses","metadata":{},"score":"72.67366"}
{"text":"UAIC20091.3way .Relations between named entities .Wikipedia + NER 's ( LingPipe , GATE ) + Perl patterns .UAIC20091.3way .WordNet .AUEBNLP1.3way .Synonyms . WordNet .BIU1.2way .Synonyms , hyponyms ( 2 levels away from the original term ) , hyponym_instance and derivations .","label":"Uses","metadata":{},"score":"74.28647"}
{"text":"UAIC20091.3way .Relations between named entities .Wikipedia + NER 's ( LingPipe , GATE ) + Perl patterns .UAIC20091.3way .WordNet .AUEBNLP1.3way .Synonyms . WordNet .BIU1.2way .Synonyms , hyponyms ( 2 levels away from the original term ) , hyponym_instance and derivations .","label":"Uses","metadata":{},"score":"74.28647"}
{"text":"UAIC20091.3way .Relations between named entities .Wikipedia + NER 's ( LingPipe , GATE ) + Perl patterns .UAIC20091.3way .WordNet .AUEBNLP1.3way .Synonyms . WordNet .BIU1.2way .Synonyms , hyponyms ( 2 levels away from the original term ) , hyponym_instance and derivations .","label":"Uses","metadata":{},"score":"74.28647"}
{"text":"UAIC20091.3way .Relations between named entities .Wikipedia + NER 's ( LingPipe , GATE ) + Perl patterns .UAIC20091.3way .WordNet .AUEBNLP1.3way .Synonyms . WordNet .BIU1.2way .Synonyms , hyponyms ( 2 levels away from the original term ) , hyponym_instance and derivations .","label":"Uses","metadata":{},"score":"74.28647"}
{"text":"UAIC20091.3way .Relations between named entities .Wikipedia + NER 's ( LingPipe , GATE ) + Perl patterns .UAIC20091.3way .WordNet .AUEBNLP1.3way .Synonyms . WordNet .BIU1.2way .Synonyms , hyponyms ( 2 levels away from the original term ) , hyponym_instance and derivations .","label":"Uses","metadata":{},"score":"74.28647"}
{"text":"UAIC20091.3way .Relations between named entities .Wikipedia + NER 's ( LingPipe , GATE ) + Perl patterns .UAIC20091.3way .WordNet .AUEBNLP1.3way .Synonyms . WordNet .BIU1.2way .Synonyms , hyponyms ( 2 levels away from the original term ) , hyponym_instance and derivations .","label":"Uses","metadata":{},"score":"74.28647"}
{"text":"UAIC20091.3way .Relations between named entities .Wikipedia + NER 's ( LingPipe , GATE ) + Perl patterns .UAIC20091.3way .WordNet .AUEBNLP1.3way .Synonyms . WordNet .BIU1.2way .Synonyms , hyponyms ( 2 levels away from the original term ) , hyponym_instance and derivations .","label":"Uses","metadata":{},"score":"74.28647"}
{"text":"UAIC20091.3way .Relations between named entities .Wikipedia + NER 's ( LingPipe , GATE ) + Perl patterns .UAIC20091.3way .WordNet .AUEBNLP1.3way .Synonyms . WordNet .BIU1.2way .Synonyms , hyponyms ( 2 levels away from the original term ) , hyponym_instance and derivations .","label":"Uses","metadata":{},"score":"74.28647"}
{"text":"UAIC20091.3way .Relations between named entities .Wikipedia + NER 's ( LingPipe , GATE ) + Perl patterns .UAIC20091.3way .WordNet .AUEBNLP1.3way .Synonyms . WordNet .BIU1.2way .Synonyms , hyponyms ( 2 levels away from the original term ) , hyponym_instance and derivations .","label":"Uses","metadata":{},"score":"74.28647"}
{"text":"WordNet .DLSIUAES1.3way .Similarity between lemmata , computed by WordNet - based metrics .WordNet .JU_CSE_TAC1.2way .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .","label":"Uses","metadata":{},"score":"84.104126"}
{"text":"WordNet .DLSIUAES1.3way .Similarity between lemmata , computed by WordNet - based metrics .WordNet .JU_CSE_TAC1.2way .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .","label":"Uses","metadata":{},"score":"84.104126"}
{"text":"WordNet .DLSIUAES1.3way .Similarity between lemmata , computed by WordNet - based metrics .WordNet .JU_CSE_TAC1.2way .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .","label":"Uses","metadata":{},"score":"84.104126"}
{"text":"WordNet .DLSIUAES1.3way .Similarity between lemmata , computed by WordNet - based metrics .WordNet .JU_CSE_TAC1.2way .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .","label":"Uses","metadata":{},"score":"84.104126"}
{"text":"WordNet .DLSIUAES1.3way .Similarity between lemmata , computed by WordNet - based metrics .WordNet .JU_CSE_TAC1.2way .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .","label":"Uses","metadata":{},"score":"84.104126"}
{"text":"WordNet .DLSIUAES1.3way .Similarity between lemmata , computed by WordNet - based metrics .WordNet .JU_CSE_TAC1.2way .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .","label":"Uses","metadata":{},"score":"84.104126"}
{"text":"WordNet .DLSIUAES1.3way .Similarity between lemmata , computed by WordNet - based metrics .WordNet .JU_CSE_TAC1.2way .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .","label":"Uses","metadata":{},"score":"84.104126"}
{"text":"WordNet .DLSIUAES1.3way .Similarity between lemmata , computed by WordNet - based metrics .WordNet .JU_CSE_TAC1.2way .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .","label":"Uses","metadata":{},"score":"84.104126"}
{"text":"WordNet .DLSIUAES1.3way .Similarity between lemmata , computed by WordNet - based metrics .WordNet .JU_CSE_TAC1.2way .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .","label":"Uses","metadata":{},"score":"84.104126"}
{"text":"VerbOcean .VerbOcean relations are used to calculate relatedness between verbs in T and H .VerbOcean .Extraction of 18232 entailment rules for all the English verbs connected by the \" stronger - than \" relation .For instance , if \" kill [ stronger - than ] injure \" , then the rule \" kill ENTAILS injure \" is added to the rules repository .","label":"Uses","metadata":{},"score":"84.91618"}
{"text":"VerbOcean .VerbOcean relations are used to calculate relatedness between verbs in T and H .VerbOcean .Extraction of 18232 entailment rules for all the English verbs connected by the \" stronger - than \" relation .For instance , if \" kill [ stronger - than ] injure \" , then the rule \" kill ENTAILS injure \" is added to the rules repository .","label":"Uses","metadata":{},"score":"84.91618"}
{"text":"VerbOcean .VerbOcean relations are used to calculate relatedness between verbs in T and H .VerbOcean .Extraction of 18232 entailment rules for all the English verbs connected by the \" stronger - than \" relation .For instance , if \" kill [ stronger - than ] injure \" , then the rule \" kill ENTAILS injure \" is added to the rules repository .","label":"Uses","metadata":{},"score":"84.91618"}
{"text":"VerbOcean .VerbOcean relations are used to calculate relatedness between verbs in T and H .VerbOcean .Extraction of 18232 entailment rules for all the English verbs connected by the \" stronger - than \" relation .For instance , if \" kill [ stronger - than ] injure \" , then the rule \" kill ENTAILS injure \" is added to the rules repository .","label":"Uses","metadata":{},"score":"84.91618"}
{"text":"VerbOcean .VerbOcean relations are used to calculate relatedness between verbs in T and H .VerbOcean .Extraction of 18232 entailment rules for all the English verbs connected by the \" stronger - than \" relation .For instance , if \" kill [ stronger - than ] injure \" , then the rule \" kill ENTAILS injure \" is added to the rules repository .","label":"Uses","metadata":{},"score":"84.91618"}
{"text":"VerbOcean .VerbOcean relations are used to calculate relatedness between verbs in T and H .VerbOcean .Extraction of 18232 entailment rules for all the English verbs connected by the \" stronger - than \" relation .For instance , if \" kill [ stronger - than ] injure \" , then the rule \" kill ENTAILS injure \" is added to the rules repository .","label":"Uses","metadata":{},"score":"84.91618"}
{"text":"VerbOcean .VerbOcean relations are used to calculate relatedness between verbs in T and H .VerbOcean .Extraction of 18232 entailment rules for all the English verbs connected by the \" stronger - than \" relation .For instance , if \" kill [ stronger - than ] injure \" , then the rule \" kill ENTAILS injure \" is added to the rules repository .","label":"Uses","metadata":{},"score":"84.91618"}
{"text":"VerbOcean .VerbOcean relations are used to calculate relatedness between verbs in T and H .VerbOcean .Extraction of 18232 entailment rules for all the English verbs connected by the \" stronger - than \" relation .For instance , if \" kill [ stronger - than ] injure \" , then the rule \" kill ENTAILS injure \" is added to the rules repository .","label":"Uses","metadata":{},"score":"84.91618"}
{"text":"VerbOcean .VerbOcean relations are used to calculate relatedness between verbs in T and H .VerbOcean .Extraction of 18232 entailment rules for all the English verbs connected by the \" stronger - than \" relation .For instance , if \" kill [ stronger - than ] injure \" , then the rule \" kill ENTAILS injure \" is added to the rules repository .","label":"Uses","metadata":{},"score":"84.91618"}
