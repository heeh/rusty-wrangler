{"text":"Then , I will provide a method for the decomposition of lexical categories and outline a theory of lexical semantics embodying a notion of cocompositionality and type coercion , as well as several levels of semantic description , where the semantic load is spread more evenly throughout the lexicon .","label":"Uses","metadata":{},"score":"35.763344"}{"text":"This thesis is an investigation of the representation of lexical semantic information from a computational linguistic perspective .An implemented representation language is described which is not specic to lexical semantics , but is based on the use of typed feature structures augmented with default operations .","label":"Uses","metadata":{},"score":"36.01316"}{"text":"The process of acquiring this grammar is one of generalization so that the resulting grammar predicts likely sentences beyond those contained in the training set .From the grammar we construct a novel probabilistic language model called the phrase class n - gram model ( pcng ) , which is a natural generalization of the word class n - gram model [ 11 ] to phrase classes .","label":"Uses","metadata":{},"score":"36.514374"}{"text":"Rather than assuming a fixed set of primitives , I will assume a fixed number of generative devices that can be seen as constructing semantic expressions .I develop a theory of Qualia Structure , a representation language for lexical items , which renders much lexical ambiguity in the lexicon unnecessary , while still explaining the systematic polysemy that words carry .","label":"Uses","metadata":{},"score":"37.564438"}{"text":"The authors discuss Concrete Minimalism ( Culicover 1999 ) as a linguistic theory tightly linked to the dynamical approach .They present in general terms how language acquisition can be modeled by an adaptive , dynamical system : forms and meanings are represented as trajectories in the linguistic space ; trajectories are acquired individually ; similar trajectories are grouped into flows , and generalizations emerge from these groupings .","label":"Uses","metadata":{},"score":"37.625427"}{"text":"They argue that ' ' the major grammatical . constraint that guides the direction of change is the computational .complexity of the sound - meaning correspondence ' ' ( p. 22 ) .Part III ( Chapter 7 ) presents ' ' Concrete Minimalism ' ' as a link .","label":"Uses","metadata":{},"score":"38.293198"}{"text":"This thesis is an investigation of the representation of lexical semantic information from a computational linguistic perspective .An implemented representation language is described which is not specic to lexical semantics , but is based on the use of typed feature structures augmented with default ... \" .","label":"Uses","metadata":{},"score":"38.387688"}{"text":"These criteria ensure that the default unification operation has properties familiar from monotonic unification , such as determinacy , the way information is accumulated , the conditions when unification fails , and order independence .We will justify these assumptions with respect to particular linguistic examples in 4 . \" ... this paper we suggest some strategies for reuniting phonology and the rest of grammar in the context of a uniform constraint formalism .","label":"Uses","metadata":{},"score":"39.690506"}{"text":"In this paper , we propose an account of linking patterns that does away with intermediary mechanisms such as thematic or actor / undergoer hierarchies .Instead , constraints on word classes , defined by both syntactic and semantic criteria , encode generalizations between semantic roles and syntactic arguments .","label":"Uses","metadata":{},"score":"39.842674"}{"text":"This paper is concerned with establishing broadly - based system - theoretic foundations and practical techniques for the problem of system identification that are rigorous , intuitively clear and conceptually powerful .A general formulation is first given in which two order relations are postulated on a ... \" .","label":"Uses","metadata":{},"score":"40.734764"}{"text":"The authors evaluate this work to be ' ' a model of qualitatively understanding of how language acquisition may be represented as a self - organization of a dynamical system''(p.189 ) .However , I see two dimensions , besides the unified framework , that the book can be appreciated and evaluated upon : the linguistic theory ( Concrete Minimalism ) and the learning theory ( Dynamical Systems ) .","label":"Uses","metadata":{},"score":"41.10872"}{"text":"Phonology in Constraint - Based Grammar Classical generative phonology is couched within the same set of assumptions that dominated standard transformational grammar .While this work has an increasingly declarative flavour , most versions retain procedural devices for repairing representations that fail to meet certain constraints , or for constraints to override each other .","label":"Uses","metadata":{},"score":"41.752777"}{"text":"Positive results are shown in terms of perplexity of the acquired phrase class n - gram models and in terms of reduction of ... . \" ...We present an efficient incremental algorithm for learning deterministic finite state automata ( DFA ) from labeled examples and membership queries .","label":"Uses","metadata":{},"score":"41.94896"}{"text":"First , we develop a grammar inference process which is able to learn a grammar describing a large set of training ... \" .This thesis focuses on the automatic acquisition of language structure and the subsequent use of the learned language structure to improve the performance of a speech recognition system .","label":"Uses","metadata":{},"score":"42.230976"}{"text":"this paper we suggest some strategies for reuniting phonology and the rest of grammar in the context of a uniform constraint formalism .We explain why this is a desirable goal , and we present some conservative extensions to current practice in computational linguistics and in non - linear phonology which we believe are necessary and sufficient for achieving this goal .","label":"Uses","metadata":{},"score":"42.28611"}{"text":"They argue against an innate skeletal .grammar with default values of all the parameters , as PPT assumes , and . propose that ' ' the learner does have something structured that it . draws upon in establishing correspondences between sounds and meaning , . namely , the infinite inventory of meanings , the capacity to generalize .","label":"Uses","metadata":{},"score":"42.875336"}{"text":"However , I see two . dimensions , besides the unified framework , that the book can be . appreciated and evaluated upon : the linguistic theory ( Concrete .Minimalism ) and the learning theory ( Dynamical Systems ) .I found .","label":"Uses","metadata":{},"score":"43.66313"}{"text":"Grammar rules and lexical rules can be specied in the same formalism and thus the paradigmatic treatment of lexical semantics can be integrated with an account at the syntagmatic level .The use of the language is illustrated with some examples of the representation of verbs , the treatment of logical metonymy and of sense extension .","label":"Uses","metadata":{},"score":"43.81988"}{"text":"This chapter elaborates on the authors ' previous papers , ( Culicover et al .2003 ) , ( Culicover and Nowak 2003 ) , and present them within a unified framework .The authors argue that the same dynamical system architecture and self - organization mechanism are suitable for both language acquisition and language change .","label":"Uses","metadata":{},"score":"44.424675"}{"text":"The central thesis of this chapter is that current formal grammatical descriptions of adult language do not offer the proper vocabulary for describing the course of language acquisition ' ' ( p. 23 ) .The authors presents a critical analysis of Principles and Parameters Theory ( PPT ) , considering several issues regarding parameters , parsing and triggers , mistakes , idioms and irregularities .","label":"Uses","metadata":{},"score":"44.42815"}{"text":"In her .PhD thesis , she proposes a relational learning framework for the . induction of grammars able to capture both aspects of syntax and . semantics .She uses a domain ontology during the learning process as a .grammar semantic constraint .","label":"Uses","metadata":{},"score":"44.674202"}{"text":"In her PhD thesis , she proposes a relational learning framework for the induction of grammars able to capture both aspects of syntax and semantics .She uses a domain ontology during the learning process as a grammar semantic constraint .Abstract .","label":"Uses","metadata":{},"score":"44.946213"}{"text":"In addressing these issues , I will discuss what I think are some of the central prob ... \" .this paper , I will discuss four major topics relating to current research in lexical semantics : methodology , descriptive coverage , adequacy of the representation , and the computational usefulness of representations .","label":"Uses","metadata":{},"score":"45.072754"}{"text":"The grammar model integrates d ... \" .The ParseTalk model of concurrent , object - oriented natural language parsing is introduced .It builds upon the complete lexical distribution of grammatical knowledge and incorporates inheritance mechanisms in order to express generalizations over sets of lexical items .","label":"Uses","metadata":{},"score":"45.19525"}{"text":"The first , in which the constraints were minimal , was unsuccessful .The second , with significant constraints , was successful within the bounds of the task we had set .We will explicate dependency grammars in Section 2 .For the moment we simply note that they are a very restricted class of grammars which do not fit exactly into the Chomsky hierarchy , but whose appearance is most like the context - free grammars .","label":"Uses","metadata":{},"score":"45.246613"}{"text":"Computational results are given to demonstrate that the theory is complete and fully operational .Finally the formulation of identification proposed in this paper is analysed in terms of Klir 's epistemological hierarchy and both are discussed in terms of the rich philosophical literature on the acquisition of knowledge .","label":"Uses","metadata":{},"score":"45.246998"}{"text":"Section 6.2 presents a computer simulation of .language change ( extending the material from ( Culicover et al .2003 ) ) , . while Section 3 presents several extensions to the model ( including .bias , and variations across lexical populations ) and discusses the . computational complexity issue ( a summary of the discussion in .","label":"Uses","metadata":{},"score":"45.25522"}{"text":"goal of the first volume ( Culicover , 1999 ) was to investigate the . properties of language as bounding conditions on the learning . mechanism , the current book explores the actual architecture of the . learner and the linguistic theory most compatible with the facts of .","label":"Uses","metadata":{},"score":"45.61666"}{"text":"This concluding chapter crowns the .monumental work on two volumes about Foundations of Syntax .The . chapter has two parts .Part one ( Section 7.1 ) presents the major formal design features of .language and how they can be represented in a dynamical system that . conforms with Concrete Minimalism .","label":"Uses","metadata":{},"score":"45.82435"}{"text":"They present Clagen , a genetic algorithm system that . identifies optimal clustering in a corpus , based on distributional . information .Quantitative and qualitative analyses show that the .clustering method discovers mainly semantic co - occurrence restrictions .in the data , but no syntactic structure .","label":"Uses","metadata":{},"score":"46.375916"}{"text":"( p. 246 ) and showing in greater detail how language , and in particular .syntax can be represented as a dynamical system ( lexical categories , . phrasal categories ( endocentric , exocentric , movement and recursion ) .Part two ( Section 7.2 - 7.8 ) shows how Concrete Minimalism allows for . ''","label":"Uses","metadata":{},"score":"46.441875"}{"text":"In Chapter 1 , ' 'The Dynamical Perspective ' ' , the authors argue in favor of a minimalist , dynamical approach to language acquisition , language evolution and language processing .It is minimalist since it looks for the minimal formal machinery and prior knowledge that the learner has access to in order to acquire language .","label":"Uses","metadata":{},"score":"46.52256"}{"text":"The main conclusion is that Concrete .Minimalism coupled with a theory of markedness can explain these . phenomena and it should be preferred , as a simpler approach .CRITICAL EVALUATION . ''Dynamical Grammar ' ' can be recommended on several levels , being in .","label":"Uses","metadata":{},"score":"46.887455"}{"text":"The mechanisms contained in the system were systematically varied in order to explore what features of the grammar the learner acquires given different assumptions .Chapter 3 , which focuses on the distributional approach to language learning , concludes that the ability to statistically acquire regularities in language is not sufficient for grammar learning .","label":"Uses","metadata":{},"score":"46.919685"}{"text":"Our approach is discussed and compared with several other approaches f,'om the MT literature .The results presented in this article have been implemented and integrated into the Verbmobil system . \" ...In this paper , we propose an account of linking patterns that does away with intermediary mechanisms such as thematic or actor / undergoer hierarchies .","label":"Uses","metadata":{},"score":"47.001923"}{"text":"The grammar representation must support the processing of out - of - vocabulary ( OOV ) words and define a method for representing such words .The content developer can specify the action to be taken upon encountering OOV words . 1.5 Disfluency and Noise Management ( should specify ) .","label":"Uses","metadata":{},"score":"47.304955"}{"text":"The DCTG - GP system improves on other grammar - based GP systems by permitting non - trivial semantic aspects of the language to be defined with the grammar .It also automatically analyzes grammar rules in order to determine their minimal depth and termination characteristics , which are required when generating random program trees of varied shapes and sizes .","label":"Uses","metadata":{},"score":"47.458588"}{"text":"It is also possible to output FOL formulas translated from the DRSs .CCGbank pairs syntactic derivations with sets of word - word dependencies which approximate the underlying predicate - argument structure .The translation process and linguistic analyses are explained in the manual .","label":"Uses","metadata":{},"score":"47.486866"}{"text":"It is also possible to output FOL formulas translated from the DRSs .CCGbank pairs syntactic derivations with sets of word - word dependencies which approximate the underlying predicate - argument structure .The translation process and linguistic analyses are explained in the manual .","label":"Uses","metadata":{},"score":"47.486866"}{"text":"It is also possible to output FOL formulas translated from the DRSs .CCGbank pairs syntactic derivations with sets of word - word dependencies which approximate the underlying predicate - argument structure .The translation process and linguistic analyses are explained in the manual .","label":"Uses","metadata":{},"score":"47.486866"}{"text":"The parser does this with a handcrafted semantic grammar .While the robust parser can be written once and used many times for different tasks , the difficulty is due to the requirement that a new semantic grammar be developed for every application domain .","label":"Uses","metadata":{},"score":"48.164543"}{"text":"1999 ) as a linguistic theory tightly linked to the dynamical . approach .They present in general terms how language acquisition can .be modeled by an adaptive , dynamical system : forms and meanings are . represented as trajectories in the linguistic space ; trajectories are . acquired individually ; similar trajectories are grouped into flows , . and generalizations emerge from these groupings .","label":"Uses","metadata":{},"score":"48.178833"}{"text":"From the annotations , Fast Learner can learn the language expressions for the components in the automatically generated semantic grammar template .Syntactic Constraints : Domain specific language must comply with the syntactic constraints of a language .Some simple syntactic clues , for example , part - of - speech constraints , can be used to reduce the search space in grammar learning .","label":"Uses","metadata":{},"score":"48.355755"}{"text":"The IDAS natural - language generation system uses a KL - ONE type classifier to perform content determination , surface realisation , and part of text planning .Generation - by - classification allows IDAS to use a single representation and reasoning component for both domain and linguistic knowledge , which ... \" .","label":"Uses","metadata":{},"score":"48.731857"}{"text":"In particular we present the results of two experiments .The first , in which the constraints were minimal , was unsuccessful .The second , with significant constr ... \" .Introduction We present a scheme for learning probabilistic dependency grammars from positive training examples plus constraints on rules .","label":"Uses","metadata":{},"score":"48.83218"}{"text":"CRITICAL EVALUATION ' ' Dynamical Grammar ' ' can be recommended on several levels , being in my opinion one of those revolutionary and fundamental books that have an interdisciplinary impact , moving the research on language acquisition and language change to a next level .","label":"Uses","metadata":{},"score":"48.972336"}{"text":"Using a type system it is possible to specify , for example , that lexical entries hav ... .by Udo Hahn , Susanne Schacht , Norbert Br√∂ker - INTERNATIONAL JOURNAL OF HUMAN - COMPUTER STUDIES , 1994 . \" ...The ParseTalk model of concurrent , object - oriented natural language parsing is introduced .","label":"Uses","metadata":{},"score":"49.234306"}{"text":"language learning means in this approach : finding couplings between . trajectories of the syntactic and the semantic system .This is . equivalent to finding correspondence rules between form and . meaning .Generalization is seen as a self - organization of the language . space based on repeated experience .","label":"Uses","metadata":{},"score":"49.347507"}{"text":"Within computational linguistics and natural language processing ( NLP ) , many approaches to the representation of word meaning have been advocated , without any emergence of a .. Date : Sun , 22 Aug 2004 20:41:13 -0400 ( EDT )From : Smaranda Muresan Subject : Dynamical Grammar : Minimalism , acquisition , and change .","label":"Uses","metadata":{},"score":"49.36548"}{"text":"The grammar representation must support the post - processing of N - best output of recognition hypotheses .This requirement will be coordinated with the Dialog subgroup .Efficiency Issues ( cf . section 2.2 ) .6.1 Native Grammar Formats ( must specify ) .","label":"Uses","metadata":{},"score":"49.37611"}{"text":"The authors also analyze the amount and type of knowledge in the input data itself .They present Clagen , a genetic algorithm system that identifies optimal clustering in a corpus , based on distributional information .Quantitative and qualitative analyses show that the clustering method discovers mainly semantic co - occurrence restrictions in the data , but no syntactic structure .","label":"Uses","metadata":{},"score":"49.427597"}{"text":"Resource Sensitivity in Binding and Anaphora , ed . by Kruijff and Oehrle .Kluwer , 215 - 229 .Combinatory Categorial Grammar ( CCG ) is an efficiently parseable , yet linguistically expressive grammar formalism .It has a completely transparent interface between surface syntax and underlying semantic representation , including predicate - argument structure , quantification and information structure .","label":"Uses","metadata":{},"score":"49.45166"}{"text":"It presents new surface generation techniques that improve on both aspects of surface generation : ( 1 ) lexical choice , which consists of choosing words and their associated syntactic structures and ( 2 ) syntactic realization , which consists of combining these partial structures into grammatical sentences .","label":"Uses","metadata":{},"score":"49.48595"}{"text":"They are universal building blocks that can be written once and then shared by many applications .In their ASRU 2001 paper , \" Grammar Learning for Spoken Language Understanding , \" they reported some exciting results .On MiPad data , the grammar generated with their technologies already outperformed the manually developed grammar --- the understanding error rates have been consistently reduced by 40 % to 60 % .","label":"Uses","metadata":{},"score":"49.684326"}{"text":"However , this algorithm requir ... . \" ...DCTG - GP is a genetic programming system that uses definite clause translation grammars .A DCTG is a logical version of an attribute grammar that supports the definition of context - free languages , and it allows semantic information associated with a language to be easily accomodated by the grammar .","label":"Uses","metadata":{},"score":"49.737026"}{"text":"It is also possible to output FOL formulas translated from the DRSs .CCGbank pairs syntactic derivations with sets of word - word dependencies which .approximate the underlying predicate - argument structure .original annotation .The LDC distribution also contains machine - readable versions .","label":"Uses","metadata":{},"score":"49.746628"}{"text":"capacity to extract formal regularities from the language that it is . exposed to ' ' ( p. 42 ) .Part II presents several computer simulations for testing various .hypotheses about language acquisition ( Chapter 3 , 4 and 5 ) and . language change ( Chapter 6 ) .","label":"Uses","metadata":{},"score":"49.746975"}{"text":"\" ...This thesis investigates the impact of the pragmatic situation on surface generation .It presents new surface generation techniques that improve on both aspects of surface generation : ( 1 ) lexical choice , which consists of choosing words and their associated syntactic structures and ( 2 ) syntactic rea ... \" .","label":"Uses","metadata":{},"score":"49.951164"}{"text":"An implemented representation language is described which is not specic to lexical semantics , but is based on the use of typed feature structures augmented with default operations .This language , which is formally specied , allows the lexical semantic representations to be tightly integrated with the syntactic component of the lexical sign , capturing generalisations by use of inheritance , while allowing for exceptions with the default mechanism .","label":"Uses","metadata":{},"score":"50.0093"}{"text":"The grammar representation might allow for certain syntactic conveniences .An example format for permutation is : .Large Vocabulary and Dictation .Special consideration for large vocabularies shall include the following : . 2.1Large Vocabulary Definition ( must specify ; cf . section 1.3 ) .","label":"Uses","metadata":{},"score":"50.03981"}{"text":"Associated attributes of such grammars shall be made available to the speech recognizer for improving interpretation characteristics .Specifications for large vocabulary will not preclude the definition of small grammars . 2.2 Efficiency ( must specify ; cf . section 6 ) .","label":"Uses","metadata":{},"score":"50.19141"}{"text":"Part one ( Section 7.1 ) presents the major formal design features of language and how they can be represented in a dynamical system that conforms with Concrete Minimalism .Part two ( Section 7.2 - 7.8 ) shows how Concrete Minimalism allows for ' ' descriptively adequate syntactic descriptions , and following Occam 's Razor , is to be preferred to other syntactic theories that invoke more abstract structure ' ' ( p. 22 ) .","label":"Uses","metadata":{},"score":"50.41517"}{"text":"Default inheritance and default unication are discussed in detail .Grammar rules and lexical rules can be specied in the same formalism and thus the paradigmatic treatment of lexical semantics can be integrated with an account at the syntagmatic level .The use of the language is illustrated with some examples of the representation of verbs , the treatment of logical metonymy and of sense extension .","label":"Uses","metadata":{},"score":"50.42872"}{"text":"How about a start marker to indicate the n - ary of the grams .Comments can follow HTML style .Examples : .( Feedback : N - gram span is implicit within the format . ) \" word \" \" word list \" .","label":"Uses","metadata":{},"score":"50.47294"}{"text":"An aspect of Concrete Minimalism that might be found appealing by both . linguists and computational linguists is the tendency towards a . simpler syntax .In this view , the grammar explicitly states .correspondences between form and meaning .The simulations with .","label":"Uses","metadata":{},"score":"50.783722"}{"text":"OVERVIEW . ''Dynamical Grammar ' ' is the second volume of a two - volume work on . ''Foundation of Syntax ' ' , offering a new perspective , minimalist and .dynamical , on language acquisition and language change .","label":"Uses","metadata":{},"score":"50.981567"}{"text":"Acero agrees : \" We believe that the learning of statistical grammar can further improve the performance , and there are still many things in our agenda to reduce interactions between the toolkit and grammar developers .\"Based on the technologies , they have created SGStudio ( Semantic Grammar Studio ) that enables non - speech experts to develop semantic grammars for speech recognition and understanding .","label":"Uses","metadata":{},"score":"51.225746"}{"text":"The central thesis of this . chapter is that current formal grammatical descriptions of adult .language do not offer the proper vocabulary for describing the course . of language acquisition ' ' ( p. 23 ) .The authors presents a critical . analysis of Principles and Parameters Theory ( PPT ) , considering .","label":"Uses","metadata":{},"score":"51.24964"}{"text":"I foresee this work to open several doors not only to work in linguistic theory and cognitive science , but also to computational linguistics focusing on grammar induction and language understanding .Moreover , this book is a clear example of how valuable the interdisciplinary work is for studying language acquisition and language change .","label":"Uses","metadata":{},"score":"51.471535"}{"text":"1.2 CFG Specification ( must specify ) .CFG 's must be represented by specification in a well known format .Each CFG rule will be a regular expression . 1.3 N - Gram Grammar Enabled ( should specify ) .The grammar representation should enable the definition of an N - Gram Grammar ( NGG ) .","label":"Uses","metadata":{},"score":"51.595634"}{"text":"their associated conceptual structures , ii ) the learner is .Conservative in formulating hypotheses and in generalization , iii ) the .learner is Attentive to detail , iv ) the learner formulates a set . correlations that expresses the pairings of strings and their .","label":"Uses","metadata":{},"score":"51.635185"}{"text":"Generation - by - classification allows IDAS to use a single representation and reasoning component for both domain and linguistic knowledge , which is difficult for systems based on unification or systemic generation techniques . \" ...This thesis is an investigation of the representation of lexical semantic information from a computational linguistic perspective .","label":"Uses","metadata":{},"score":"51.70274"}{"text":"I foresee .this work to open several doors not only to work in linguistic theory .and cognitive science , but also to computational linguistics focusing . on grammar induction and language understanding .Moreover , this book . is a clear example of how valuable the interdisciplinary work is for . studying language acquisition and language change .","label":"Uses","metadata":{},"score":"52.291534"}{"text":"In part II , we will study the relation of probabilistic finite - state automata with other well known devices that generate strings as hidden Markov models and n - grams , and provide theorems , algorithms and properties that represent a current state of the art of these objects . \" ...","label":"Uses","metadata":{},"score":"52.369926"}{"text":"The resulting DRSs can be translated to ordinary first - order logic formulas and be processing by standard theorem provers for first - order logic .Boxer 's performance on the shared task for comparing semantic represtations was promising .It was able to produce complete DRSs for all seven texts .","label":"Uses","metadata":{},"score":"52.42123"}{"text":"The authors discuss in these cases the possible reasons of failure : not enough information , the task is difficult , the learner needs to be enhanced .Regarding word order , they explore word order correlates of argument structure , scrambling , inversion , wh - movement and null arguments .","label":"Uses","metadata":{},"score":"52.474983"}{"text":"Volume One of Foundations of Syntax .Culicover , Peter W. and Andrzej Nowak ( 2003 ) . ''Markedness , Antisymmetry and Complexity of Constructions ' ' .In Pierre Pica and Johann Rooryk , eds .Variation Yearbook .John Benjamins , Amsterdam .","label":"Uses","metadata":{},"score":"52.54562"}{"text":"More recent . prominent .proponents of the approach are Jacobson and Baldridge .CCG relies on combinatory logic , which has the same expressive power as the lambda calculus , but builds its expressions differently .One of the key publications of CCG is ' '","label":"Uses","metadata":{},"score":"52.671783"}{"text":"2003 ) , ( Culicover and .Nowak 2003 ) , and present them within a unified framework .The authors .argue that the same dynamical system architecture and . self - organization mechanism are suitable for both language acquisition .","label":"Uses","metadata":{},"score":"53.058987"}{"text":"Specifically , this research focuses on the impact on lexical choice of one part of the pragmatic situation : the speaker 's argumentative intent , i.e. , the goal of the speaker to convince the hearer of a certain conclusion .The argumentative intent can be realized by a variety of evaluative expressions appearing at various ranks in the syntactic structure .","label":"Uses","metadata":{},"score":"53.076706"}{"text":"The LDC distribution also contains machine - readable versions of the data , which contain the syntactic derivations and the corresponding lists of word - word dependencies , as well as a file that is searchable by Doug Rohde 's TGrep2 ( version 1.15 ) .","label":"Uses","metadata":{},"score":"53.077034"}{"text":"The LDC distribution also contains machine - readable versions of the data , which contain the syntactic derivations and the corresponding lists of word - word dependencies , as well as a file that is searchable by Doug Rohde 's TGrep2 ( version 1.15 ) .","label":"Uses","metadata":{},"score":"53.077034"}{"text":"The LDC distribution also contains machine - readable versions of the data , which contain the syntactic derivations and the corresponding lists of word - word dependencies , as well as a file that is searchable by Doug Rohde 's TGrep2 ( version 1.15 ) .","label":"Uses","metadata":{},"score":"53.077034"}{"text":"The thorough definition of this subject will be the charter of another subgroup .8.8 Grammar File Inclusion ( must specify ) .The grammar representation must support the inclusion of other grammar files referenced by name via a Universal Resource Identifier ( URI ) .","label":"Uses","metadata":{},"score":"53.15899"}{"text":"Resource Sensitivity in Binding and Anaphora , ed . by Kruijff and Oehrle .Kluwer , 215 - 229 .LINGUIST List 15.2358 .Mon Aug 23 2004 .Review : Ling Theories : Culicover & Nowak ( 2003 ) .What follows is a review or discussion note contributed to our Book Discussion Forum .","label":"Uses","metadata":{},"score":"53.413292"}{"text":"5.1 Confidence Scoring ( must specify ) .The grammar representation must provide information for the post - processing of recognition confidence scores with regard to error rejection processing .Such information can include the language model perplexity ( high perplexity would typically reduce confidence , and hence rejection threshold ) or direct cues to tighten or relax the normal rejection constraints to provide content based control of performance .","label":"Uses","metadata":{},"score":"53.50197"}{"text":"notions of ' ' phrase ' ' and ' ' head of a phrase ' ' , a.s.o . .CAMiLLe has two representation systems : one for meaning and one for . sentences , corresponding to classical semantics and syntax .","label":"Uses","metadata":{},"score":"53.66136"}{"text":"The grammar representation must support the weighting of grammar rules in the CFG format .Weighting is implicit in the N - Gram format . 8.7 Phonetic Pronunciation ( must specify ) .The grammar representation must support the inclusion of phonetic pronunciation rules .","label":"Uses","metadata":{},"score":"53.723957"}{"text":"language evolution and language processing .It is minimalist since it .looks for the minimal formal machinery and prior knowledge that the .learner has access to in order to acquire language .It is dynamical .because it considers the architecture of language faculty to be a . dynamical system .","label":"Uses","metadata":{},"score":"53.731613"}{"text":"Clagen suggest that in order to learn grammar , there is a need for .additional information , which the authors argue to be the meaning .Chapter 4 and 5 explore whether access to meaning is not only . necessary , but also sufficient for grammar learning , given that in the . system there exists mechanisms for finding associations between . meaning and form .","label":"Uses","metadata":{},"score":"53.745823"}{"text":"The scope of issues discussed includes semantics and contexts as well as natural language syntax .Therefore the activities of the Grammar Representation Subgroup are to be coordinated with the activities of both the Natural Language Subgroup and the Dialog Subgroup .","label":"Uses","metadata":{},"score":"53.750053"}{"text":"The grammar representation must support the naming of grammars .Reference to full grammars and rules within grammars shall be supported by a suitable multi - part naming mechanism .Easy name resolution and overloading shall be supported .A namespace mechanism to avoid naming conflicts shall be supported .","label":"Uses","metadata":{},"score":"53.89891"}{"text":"There is not a good generalization mechanism to correctly cover a large variety of language constructions unseen in the training data . \"Instead of ambiguous automatic grammar inference , we adopt a very practical approach by integrating multiple sources of easy - to - get information \" , says Wang .","label":"Uses","metadata":{},"score":"54.071144"}{"text":"Computational and formal models of language acquisition have provided some preliminary , yet promising insights of how children learn the language of their community .Further , these formal models also provide an operational framework for the numerous practical applications of language learning .","label":"Uses","metadata":{},"score":"54.18818"}{"text":"It is inappropriate to cite W3C Working Drafts as other than \" work in progress . \"Introduction .The main goal of this subgroup is to define a speech recognition grammar specification language that will be generally useful across a variety of speech platforms used in the context of a dialog and synthesis markup environment .","label":"Uses","metadata":{},"score":"54.47372"}{"text":"The parser 's computation model relies upon the actor paradigm , with concurrency entering through asynchronous message passing .Besides theoretical claims , we present an interactive grammar / parser workbench , a graphical development environment with various types of browsers , tracers , inspectors and debuggers that has been adapted to the requirements of large - scale grammar engineering in a distributed , object - oriented specification and programming framework .","label":"Uses","metadata":{},"score":"54.521236"}{"text":"Barring criterion 6 , all of the above ... \" .this paper allows any defaults to be overridden by defaults which are associated with more specific types : thus priority ordering reflects the type hierarchy ordering .( In 6.2 , we will mention other possibilities for imposing a priority order on defaults . )","label":"Uses","metadata":{},"score":"54.573433"}{"text":"It has a completely transparent interface between surface syntax and underlying semantic representation , including predicate - argument structure , quantification and information structure .Combinatory Categorial Grammar ( CCG ) is an efficiently parseable , yet linguistically expressive grammar formalism .","label":"Uses","metadata":{},"score":"54.712032"}{"text":"Semantic specifications are to be coordinated with the Natural Language , Dialog and Universal Access subgroups .In many cases semantic definitions required by these other groups will be implemented as part of the specification language of associated grammars .4.1 Semantics Support ( must specify ) .","label":"Uses","metadata":{},"score":"54.784485"}{"text":"p. 190 ) give valuable insight on what might be the minimal information .a learner needs in order to acquire language .This book presents .consistent positive results that support the authors ' general . approach .What I found also very useful , is the discussion of the . limitations of the current implementation and how future research can .","label":"Uses","metadata":{},"score":"54.79241"}{"text":"An aspect of Concrete Minimalism that might be found appealing by both linguists and computational linguists is the tendency towards a simpler syntax .In this view , the grammar explicitly states correspondences between form and meaning .The simulations with CAMiLLe , and the detailed presentation of its properties ( p. 103","label":"Uses","metadata":{},"score":"54.8336"}{"text":"an interdisciplinary impact , moving the research on language . acquisition and language change to a next level .The book provides an .excellent discussion of related work in linguistics , cognitive science . and computational linguistics .The authors evaluate this work to be ' ' a model of qualitatively .","label":"Uses","metadata":{},"score":"55.0008"}{"text":"No assumption is more fundamental in the theory ( and practice ) of syntax than that natural languages should always be described in terms of constituent structure , at least wherever possible .To be sure , certain kinds of cases are well - known where constituent structure of the familiar sort runs into problems , e.g. . \" ...","label":"Uses","metadata":{},"score":"55.068375"}{"text":"The . sentence is not just a string of words , but it has a structure .associated with it , which emerges from contracting the strings of .words to their heads .The authors present the characteristics of .parsing , and briefly discuss the treatment of embedded clauses , . representation of phrase structure , transformations , emphasizing that .","label":"Uses","metadata":{},"score":"55.171707"}{"text":"It has a completely transparent interface between surface syntax and underlying semantic representation , including predicate - argument structure , quantification and information structure .CCG relies on combinatory logic , which has the same expressive power as the lambda calculus , but builds its expressions differently .","label":"Uses","metadata":{},"score":"55.234646"}{"text":"It has a completely transparent interface between surface syntax and underlying semantic representation , including predicate - argument structure , quantification and information structure .CCG relies on combinatory logic , which has the same expressive power as the lambda calculus , but builds its expressions differently .","label":"Uses","metadata":{},"score":"55.234646"}{"text":"It has a completely transparent interface between surface syntax and underlying semantic representation , including predicate - argument structure , quantification and information structure .CCG relies on combinatory logic , which has the same expressive power as the lambda calculus , but builds its expressions differently .","label":"Uses","metadata":{},"score":"55.234646"}{"text":"It has a completely transparent interface between surface syntax and underlying semantic representation , including predicate - argument structure , quantification and information structure .CCG relies on combinatory logic , which has the same expressive power as the lambda calculus , but builds its expressions differently .","label":"Uses","metadata":{},"score":"55.234646"}{"text":"proponents of the approach are Jacobson and Baldridge .CCG relies on combinatory logic , which has the same expressive power as the lambda calculus , but builds its expressions differently .The first linguistic and psycholinguistic arguments for basing the grammar on combinators were put forth by Mark Steedman and Anna Szabolcsi .","label":"Uses","metadata":{},"score":"55.364487"}{"text":"DCTG - GP is a genetic programming system that uses definite clause translation grammars .A DCTG is a logical version of an attribute grammar that supports the definition of context - free languages , and it allows semantic information associated with a language to be easily accomodated by the grammar .","label":"Uses","metadata":{},"score":"55.38453"}{"text":"The simulations in Chapter 3 , 4 and 5 search for the minimal mechanisms the learner needs in order to acquire language .The conclusion is that neither distributional , nor grammatical approaches can alone justify language acquisition , that each of them plays a role .","label":"Uses","metadata":{},"score":"55.46984"}{"text":"The mechanisms . contained in the system were systematically varied in order to explore .what features of the grammar the learner acquires given different . assumptions .Chapter 3 , which focuses on the distributional approach to language .learning , concludes that the ability to statistically acquire .","label":"Uses","metadata":{},"score":"55.62972"}{"text":"Semantic Tagging ( must specify ) .The grammar representation must support the tagging of syntax for semantic interpretation .Semantic values shall be returned as attribute - values pairs .4.3 Attributes ( must specify ) .The grammar representation must include attributes that can be attached to data returned from the speech recognizer .","label":"Uses","metadata":{},"score":"55.6522"}{"text":"Explanation in Linguistic Theory , .CSLI Press , Stanford , CA .2003 .Elman J. L. ( 1993 ) . ''Learning and Development in Neural Networks : The .Importance of Starting Small ' ' .Cognition , 48:71 - 99 .","label":"Uses","metadata":{},"score":"55.749313"}{"text":"Generalization is seen as a self - organization of the language space based on repeated experience .Parsing is what permits CAMiLLe to identify syntactic structure .The sentence is not just a string of words , but it has a structure associated with it , which emerges from contracting the strings of words to their heads .","label":"Uses","metadata":{},"score":"55.81628"}{"text":"The representation of constraints defining the set of allowable sentences in the language .Language .The collection or set of sentences associated with a particular domain .Language may refer to natural or program language .N - Best .Top N hypotheses ; from speech recognition , in this case , but could be from natural language processing .","label":"Uses","metadata":{},"score":"55.834526"}{"text":"One of the issues in any learning model is how it scales with problem size .The problem of learning finite state machine ( FSMs ) from examples with recurrent neural networks has been extensively explored .However , these results are somewhat disappointing in the sense that the machines that can be learned are too small to be competitive with existing grammatical inference algorithms .","label":"Uses","metadata":{},"score":"56.036316"}{"text":"Another issue is whether we want to allow the symbols to be word phrases , so I suppose we could require quote marks around symbol strings for this ( as shown ) .Acknowledgments .Subgroup Members .Automatic learning of speech recognition grammars from example sentences to ease the development of spoken language systems .","label":"Uses","metadata":{},"score":"56.094917"}{"text":"Boxer takes as input CCG ( Combinatory Categorial Grammar ) derivations and produces DRSs ( Discourse Representation Structures , from Hans Kamp 's Discourse Representation Theory ) as output .It is distributed with the C&C tools .Boxer produces standard DRS syntax , uses a neo - Davidsonian analysis for events ( with thematic roles from VerbNet ) , incorporates Van der Sandt 's algorithm for presupposition , is 100 % compatible with first - order logic ( FOL ) , and normalises cardinal and date expressions .","label":"Uses","metadata":{},"score":"56.550713"}{"text":"CCG relies on combinatory logic , which has the same expressive power as the lambda calculus , but builds its expressions differently .The first linguistic and psycholinguistic arguments for basing the grammar on combinators were put forth by Mark Steedman and Anna Szabolcsi .","label":"Uses","metadata":{},"score":"56.668587"}{"text":"The learning algorithm is intermittently provided with lab ... \" .We present an efficient incremental algorithm for learning deterministic finite state automata ( DFA ) from labeled examples and membership queries .This algorithm is an extension of Angluin 's ID procedure to an incremental framework .","label":"Uses","metadata":{},"score":"56.678978"}{"text":"The Syntactic Process ' ' by Mark Steedman .The VisCCG tool for working with grammars is available as part of the OpenCCG source code and distribution .Boxer takes as input CCG ( Combinatory Categorial Grammar ) derivations and produces DRSs ( Discourse Representation Structures , from Hans Kamp 's Discourse Representation Theory ) as output .","label":"Uses","metadata":{},"score":"56.76364"}{"text":"277 278 Bos 1 . ... nstrained by temporal relations .There is only one way to state that an individual is participating in an event - namely by relating it to the event using a binary relation expressing some thematic role .","label":"Uses","metadata":{},"score":"56.79725"}{"text":"It is also possible to output FOL formulas translated from the DRSs .Boxer takes as input CCG ( Combinatory Categorial Grammar ) derivations and produces DRSs ( Discourse Representation Structures , from Hans Kamp 's Discourse Representation Theory ) as output .","label":"Uses","metadata":{},"score":"56.990944"}{"text":"It is also possible to output FOL formulas translated from the DRSs .Boxer takes as input CCG ( Combinatory Categorial Grammar ) derivations and produces DRSs ( Discourse Representation Structures , from Hans Kamp 's Discourse Representation Theory ) as output .","label":"Uses","metadata":{},"score":"56.990944"}{"text":"Linguistic Theory , Explanation and the Dynamics of Grammar ' ' .In John Moore and Maria Kolinsky , eds .Explanation in Linguistic Theory , CSLI Press , Stanford , CA .2003 .Elman J. L. ( 1993 ) . ''","label":"Uses","metadata":{},"score":"57.228065"}{"text":"Boxer is an open - domain software component for semantic analysis of text , based on Combinatory Categorial Grammar ( CCG ) and Discourse Representation Theory ( DRT ) .Used together with the C&C tools , Boxer reaches more than 95 % coverage on newswire texts .","label":"Uses","metadata":{},"score":"57.24848"}{"text":"Boxer is an open - domain software component for semantic analysis of text , based on Combinatory Categorial Grammar ( CCG ) and Discourse Representation Theory ( DRT ) .Used together with the C&C tools , Boxer reaches more than 95 % coverage on newswire texts .","label":"Uses","metadata":{},"score":"57.24848"}{"text":"The book is addressed mainly to linguists , psycholinguists and cognitive scientists .However , computational linguists interested in language learning can greatly benefit from the material presented in this book .SYNOPSIS The book comprises three parts : Foundations ( Chapter 1 - 2 ) , Simulations ( Chapter 3 - 6 ) and Grammar ( Chapter 7 ) .","label":"Uses","metadata":{},"score":"57.312798"}{"text":"The specification may optionally define the feature .Future Revision .The feature needs additional study before specification . 0.4 Subgroup Coordination .The requirements and specification of the Grammar Representation Subgroup will be coordinated with overlapping requirements and specification of the Natural Language , Dialogue , and Universal Access subgroups .","label":"Uses","metadata":{},"score":"57.6212"}{"text":"research , as the authors themselves point to , resides in the .generalization mechanism ( i.e. , should the learner be conservative , or .it should allow overgeneralization , but then supply an error .correction mechanism ) .Overall I found this book to be a thought provoking reading , rich in .","label":"Uses","metadata":{},"score":"57.627228"}{"text":"Smaranda Muresan , Natural Language Processing Group , Department of Computer Science , Columbia University .OVERVIEW ' ' Dynamical Grammar ' ' is the second volume of a two - volume work on ' ' Foundation of Syntax ' ' , offering a new perspective , minimalist and dynamical , on language acquisition and language change .","label":"Uses","metadata":{},"score":"57.663643"}{"text":"In particular , we will discuss the prominent computational approaches for learning different classes of formal languages and discuss how these fit in the broad context of natural language learning . ... achine learning , machine perception , robotics , planning , knowledge representation , and reasoning .","label":"Uses","metadata":{},"score":"57.888912"}{"text":"Specification of the natural language syntax in the grammar representation shall conform to the following requirements : . 1.1Context - Free Grammar Support ( must specify ) .The grammar representation must support the definition of a Context - Free Grammar ( CFG ) and , by subsumption , a Finite - State Grammar ( FSG ) .","label":"Uses","metadata":{},"score":"57.943764"}{"text":"Part III ( Chapter 7 ) presents ' ' Concrete Minimalism ' ' as a link between syntactic theory and the dynamical perspective on language acquisition and language change .This concluding chapter crowns the monumental work on two volumes about Foundations of Syntax .","label":"Uses","metadata":{},"score":"57.9505"}{"text":".. on 4.4 ) .This and similar kernels are related to the pair - HMMs defined in [ 4]. byGlenn Carroll , Glenn Carroll , Eugene Charniak , Eugene Charniak - Working Notes of the Workshop Statistically - Based NLP Techniques , 1992 . \" ...","label":"Uses","metadata":{},"score":"58.01333"}{"text":"We propose the RPNI2 algorithm , an incremental extension of the RPNI algorithm .We study the convergence and complexities of both algorithms from a theoretical and practical point of view .These results are assessed on the Feldman task .1 Introduction Regular inference is the problem of learning a regular language from a positive sample , that is , a finite set of strings supposed to be drawn from a target language .","label":"Uses","metadata":{},"score":"58.0794"}{"text":"The problem has attracted a fair amount of attention , ( [ 1,4 ] are good surveys . ) but no good solutions have been found .Our choice of learning from only positive training examples needs only a little more justification .","label":"Uses","metadata":{},"score":"58.115574"}{"text":"The Syntactic Process ' ' by Mark Steedman .There are various efficient parsers available for CCG . is an open source natural language processing library written in .Java , which provides parsing and realization services based on Mark Steedman 's .","label":"Uses","metadata":{},"score":"58.131626"}{"text":"Grammar constraint rules must be re - definable in part or entirety while the system is operating .Several mechanisms are possible including , but not limited to , unconstrained redefinition of inferior grammar rules , prior declaration of volatile rules , partitioning of the rule space into static and dynamic arenas , etc . .","label":"Uses","metadata":{},"score":"58.13844"}{"text":"Learner ) , a system which implements the theory of Concrete Minimalism . in the form of a dynamical system .Chapter 5 presents experiments done .with this system .As nicely stated in Part III , the key properties of .","label":"Uses","metadata":{},"score":"58.17996"}{"text":"The authors argue for the first solution and present a brief discussion .Another zone of further research , as the authors themselves point to , resides in the generalization mechanism ( i.e. , should the learner be conservative , or it should allow overgeneralization , but then supply an error correction mechanism ) .","label":"Uses","metadata":{},"score":"58.56419"}{"text":"OOV .Out Of Vocabulary ( words ) .State .The current condition or value of variables and attributes of a system . ...XML grammar rule item .None . ...N - gram token specifier .ARY , P , PBO .","label":"Uses","metadata":{},"score":"58.676662"}{"text":"the study / experimentation of language acquisition and language . evolution theories ( see also Briscoe ( 2002 ) ) , I think closer .collaborations between linguists , cognitive scientists on one hand , . and computational linguists on the other hand , can lead to further . developments .","label":"Uses","metadata":{},"score":"58.69137"}{"text":"It is proved under very general assumptions that , if deterministic models are required then nearly all behaviours require models of nearly maximum complexity .A general theory of approximation between models and behaviour is then developed based on subjective probability concepts and semantic information theory The role of structural constraints such as causality , locality , finite memory , etc . , are then discussed as rules of the game .","label":"Uses","metadata":{},"score":"58.706524"}{"text":"A general formulation is first given in which two order relations are postulated on a class of models : a constant one of complexity ; and a variable one of approximation induced by an observed behaviour .An admissible model is such that any less complex model is a worse approximation .","label":"Uses","metadata":{},"score":"58.772545"}{"text":"A modified form of the well known MIT format is an example format for representation of N - gram grammars ( cf .Appendix ) .8.2 Mixed - Mode Grammars ( should specify ) .The grammar representation should support the simultaneous mixing of finite - state , context - free , and N - gram grammars . 8.3 Language Extensions ( should specify ) .","label":"Uses","metadata":{},"score":"58.7948"}{"text":"This provides us with the necessary principles of global organization for the lexicon , enabling us to fully integrate our natural language lexicon into a conceptual whole . ... a Davidsonian - style representation for the discussion below .11 More precisely , the process e p should reflect that it is the substance contained in the object x that is affected .","label":"Uses","metadata":{},"score":"58.85266"}{"text":"Linguistics and Philosophy 22 , 1999 .Natural Language and Linguistic Theory 5 , 403 - 439 .Semantics and Contextual Expression , ed . by Bartsch , van Benthem , and van Emde Boas .Foris , 294 - 318 .","label":"Uses","metadata":{},"score":"58.949345"}{"text":"Linguistics and Philosophy 22 , 1999 .Natural Language and Linguistic Theory 5 , 403 - 439 .Semantics and Contextual Expression , ed . by Bartsch , van Benthem , and van Emde Boas .Foris , 294 - 318 .","label":"Uses","metadata":{},"score":"58.949345"}{"text":"CAMiLLe has two representation systems : one for meaning and one for sentences , corresponding to classical semantics and syntax .The authors present the dynamical view of these systems , and explain what language learning means in this approach : finding couplings between trajectories of the syntactic and the semantic system .","label":"Uses","metadata":{},"score":"59.14798"}{"text":"The first linguistic and psycholinguistic arguments for basing the grammar on combinators were put forth by Mark Steedman and Anna Szabolcsi .More recent proponents of the approach are Jacobson and Baldridge .For example , the [ [ combinator ] ] B ( the compositor ) is useful in creating long - distance dependencies , as in \" Who do you think Mary is talking about ? \" and the combinator W ( the duplicator ) is useful as the lexical interpretation of reflexive pronouns , as in \" Mary talks about herself \" .","label":"Uses","metadata":{},"score":"59.199677"}{"text":"The first linguistic and psycholinguistic arguments for basing the grammar on combinators were put forth by Mark Steedman and Anna Szabolcsi .More recent proponents of the approach are Jacobson and Baldridge .For example , the [ [ combinator ] ] B ( the compositor ) is useful in creating long - distance dependencies , as in \" Who do you think Mary is talking about ? \" and the combinator W ( the duplicator ) is useful as the lexical interpretation of reflexive pronouns , as in \" Mary talks about herself \" .","label":"Uses","metadata":{},"score":"59.199677"}{"text":"MIT Press ] ] .Combinatory Categorial Grammar ( CCG ) is an efficiently parseable , yet linguistically expressive grammar formalism .It has a completely transparent interface between surface syntax and underlying semantic representation , including predicate - argument structure , quantification and information structure .","label":"Uses","metadata":{},"score":"59.433163"}{"text":"Natural Language Syntax .Large Vocabulary / Dictation .Grammar Contexts .Semantics .Post - Processing Issues .Efficiency Issues .XML Compatibility .Grammar Specification Language Syntax .Each topic area consists of several issues that will be discussed in detail in the following sections .","label":"Uses","metadata":{},"score":"59.49738"}{"text":"Each condition provides a partial specification of the mapping between semantic roles and syntactic arguments .We argue that this constraint - based , verb - class - based view of linking offers several empirical advantages : partial regularities and exceptions are easily accomodated , fine - grained semantic distinctions relevant to linking are countenanced , and cross - cutting similarities between semantic and syntactic verb classes are economically captured . by Johan Bos - Semantics in Text Processing .","label":"Uses","metadata":{},"score":"59.55421"}{"text":"The book is addressed mainly to linguists , psycholinguists and . cognitive scientists .However , computational linguists interested in .language learning can greatly benefit from the material presented in .this book .SYNOPSIS .The book comprises three parts : Foundations ( Chapter 1 - 2 ) , Simulations .","label":"Uses","metadata":{},"score":"59.587044"}{"text":"Chapter 4 starts with a presentation of CAMiLLe 's properties derived .both from the theory of Concrete Minimalism and from computational . considerations( p. 103 ) : e.g. , access to meaning in the form of .Jackendoff 's Conceptual Structures ; capacity to form categories , while .","label":"Uses","metadata":{},"score":"59.73143"}{"text":"Books .Curry , Haskell B. and Richard Feys ( 1958 ) , Combinatory Logic , Vol .North - Holland .Steedman , Mark ( 1996 ) , Surface Structure and Interpretation .The MIT Press .Journal Articles .Jacobson , Pauline ( 1999 ) , \" Towards a variable - free semantics . \"","label":"Uses","metadata":{},"score":"59.784023"}{"text":"Books .Curry , Haskell B. and Richard Feys ( 1958 ) , Combinatory Logic , Vol .North - Holland .Steedman , Mark ( 1996 ) , Surface Structure and Interpretation .The MIT Press .Journal Articles .Jacobson , Pauline ( 1999 ) , \" Towards a variable - free semantics . \"","label":"Uses","metadata":{},"score":"59.784023"}{"text":"Books .Curry , Haskell B. and Richard Feys ( 1958 ) , Combinatory Logic , Vol .North - Holland .Steedman , Mark ( 1996 ) , Surface Structure and Interpretation .The MIT Press .Journal Articles .Jacobson , Pauline ( 1999 ) , \" Towards a variable - free semantics . \"","label":"Uses","metadata":{},"score":"59.784023"}{"text":"The questions that arise are : would additional mechanisms . will be needed and would they be sufficient , or the learner would need .this information to start with .The authors argue for the first . solution and present a brief discussion .","label":"Uses","metadata":{},"score":"59.912743"}{"text":"Resource Sensitivity in Binding and Anaphora , ed . by Kruijff and Oehrle .Kluwer , 215 - 229 .","label":"Uses","metadata":{},"score":"59.95874"}{"text":"In this paper , we extend the characterization of the search space of regular inference [ DMV94 ] to sequential presentations of learning data .We propose the RPNI2 algorithm , an incremental extension of the RPNI algorithm .We study the convergence and complexities of both algorithms from a theoretical ... \" .","label":"Uses","metadata":{},"score":"60.023926"}{"text":"The algorithm is guaranteed to converge to a minimum state DFA corresponding to the target when the set of examples observed by the learner includes a live complete set .We prove the convergence of this algorithm and analyze its time and space complexities .","label":"Uses","metadata":{},"score":"60.444344"}{"text":"Part I presents a minimalist , dynamical approach to language . acquisition ( Chapter 1 ) and discusses how the link between linguistic . theory and language acquisition can be rethought in this dynamical . view ( Chapter 2 ) .In Chapter 1 , ' '","label":"Uses","metadata":{},"score":"60.552372"}{"text":"For the lexicon , experiments are done for nouns , compound nouns , verbs .and verbal inflection and synonymy / ambiguity .Authors point out in .the Section ' ' Dummy Semantics ' ' that a realistic simulation would need .","label":"Uses","metadata":{},"score":"60.697166"}{"text":"Steedman , Mark ( 1987 ) , \" Combinatory grammars and parasitic gaps \" .Natural Language and Linguistic Theory 5 , 403 - 439 .Articles in books or collections .Szabolcsi , Anna ( 1989 ) , \" Bound variables in syntax ( are there any ? )","label":"Uses","metadata":{},"score":"60.788555"}{"text":"Steedman , Mark ( 1987 ) , \" Combinatory grammars and parasitic gaps \" .Natural Language and Linguistic Theory 5 , 403 - 439 .Articles in books or collections .Szabolcsi , Anna ( 1989 ) , \" Bound variables in syntax ( are there any ? )","label":"Uses","metadata":{},"score":"60.788555"}{"text":"Steedman , Mark ( 1987 ) , \" Combinatory grammars and parasitic gaps \" .Natural Language and Linguistic Theory 5 , 403 - 439 .Articles in books or collections .Szabolcsi , Anna ( 1989 ) , \" Bound variables in syntax ( are there any ? )","label":"Uses","metadata":{},"score":"60.788555"}{"text":"The Syntactic Process ' ' by Mark Steedman .There are various efficient parsers available for CCG .One of the key publications of CCG is ' 'The Syntactic Process ' ' by Mark Steedman .There are various efficient parsers available for CCG .","label":"Uses","metadata":{},"score":"60.807358"}{"text":"Johann Rooryk , eds .Variation Yearbook .John Benjamins , .Amsterdam .Culicover , Peter W. , Andrzej Nowak , and Wojciech Borkowski ( 2003 ) .Linguistic Theory , Explanation and the Dynamics of Grammar ' ' .In .","label":"Uses","metadata":{},"score":"60.883736"}{"text":"The natural language learning problem has attracted the attention of researchers for several decades .Computational and formal models of language acquisition have provided some preliminary , yet promising insights of how children learn the language of their community .Further , these formal models als ... \" .","label":"Uses","metadata":{},"score":"61.152718"}{"text":"but whose appearance is most like the context - free grammars .We assume that the goal of learning a context - free grammar needs no justification .but no good solutions have been found .Our choice of learning from only positive training examples needs only a little more justification .","label":"Uses","metadata":{},"score":"61.19819"}{"text":"CSLI Lecture Notes 24 , ed . by Sag and Szabolcsi .Stanford , CSLI Publications .Resource Sensitivity in Binding and Anaphora , ed . by Kruijff and Oehrle .Kluwer , 215 - 229 .In Proceedings of ACL 2002 .","label":"Uses","metadata":{},"score":"61.544975"}{"text":"CSLI Lecture Notes 24 , ed . by Sag and Szabolcsi .Stanford , CSLI Publications .Resource Sensitivity in Binding and Anaphora , ed . by Kruijff and Oehrle .Kluwer , 215 - 229 .In Proceedings of ACL 2002 .","label":"Uses","metadata":{},"score":"61.544975"}{"text":"CSLI Lecture Notes 24 , ed . by Sag and Szabolcsi .Stanford , CSLI Publications .Resource Sensitivity in Binding and Anaphora , ed . by Kruijff and Oehrle .Kluwer , 215 - 229 .In Proceedings of ACL 2002 .","label":"Uses","metadata":{},"score":"61.544975"}{"text":"..e experiment are given .It is assumed that the reader has some background in formal languages [ 18].GA and GP have been successfully applied towards the inference of formal languages ( eg .[ 6 , 9 , 25 , 26 , 36 , 40 ] ) .","label":"Uses","metadata":{},"score":"61.578026"}{"text":"Grammar Contexts .Multiple grammar contexts shall be supported with the following requirements : . 3.1 External Grammars ( must specify ) .The grammar representation must support the inclusion of grammars defined outside of the current context .Access to grammar contexts shall be provided by a suitable reference mechanism .","label":"Uses","metadata":{},"score":"61.849464"}{"text":"Theory , and Language Acquisition ' ' .Oxford University Press .Volume One of Foundations of Syntax .Culicover , Peter W. and Andrzej Nowak ( 2003 ) . ''Markedness , .Antisymmetry and Complexity of Constructions ' ' .","label":"Uses","metadata":{},"score":"62.054222"}{"text":"Foris , 294 - 318 .Szabolcsi , Anna ( 1992 ) , \" Combinatory grammar and projection from the lexicon . \"Lexical Matters .CSLI Lecture Notes 24 , ed . by Sag and Szabolcsi .Stanford , CSLI Publications .","label":"Uses","metadata":{},"score":"62.16019"}{"text":"Foris , 294 - 318 .Szabolcsi , Anna ( 1992 ) , \" Combinatory grammar and projection from the lexicon . \"Lexical Matters .CSLI Lecture Notes 24 , ed . by Sag and Szabolcsi .Stanford , CSLI Publications .","label":"Uses","metadata":{},"score":"62.16019"}{"text":"Foris , 294 - 318 .Szabolcsi , Anna ( 1992 ) , \" Combinatory grammar and projection from the lexicon . \"Lexical Matters .CSLI Lecture Notes 24 , ed . by Sag and Szabolcsi .Stanford , CSLI Publications .","label":"Uses","metadata":{},"score":"62.16019"}{"text":"A binary reference format can be defined for this purpose .Native formats will be useful when content is specifically written for particular platforms . 6.2 Grammar Libraries ( should specify ) .The grammar representation should support the use of grammar libraries , alternatively called grammar objects , that can contain prepackaged collections of sub - grammars to be included in higher level grammar constructs .","label":"Uses","metadata":{},"score":"62.21802"}{"text":"How the system will deal with null arguments , transformations , word - ordering will be presented in Chapter 5 .Chapter 5 discusses some experiments with CAMiLLe , showing initial results and pointing to future research .The authors organize the chapter into three main parts corresponding to experiments regarding the lexicon , the phrase structure , and the word order .","label":"Uses","metadata":{},"score":"62.342457"}{"text":"This differs from the work in automatic grammar inference , which tries to learn grammars automatically from a corpus of training sentences .Most research in grammar inference has focused on toy problems , and application of such approaches on grammar structure learning for natural language has not been satisfactory for natural language understanding applications .","label":"Uses","metadata":{},"score":"62.36416"}{"text":"Boxer produces standard DRS syntax , uses a neo - Davidsonian analysis for events ( with thematic roles from VerbNet ) , incorporates Van der Sandt 's algorithm for presupposition , is 100 % compatible with first - order logic ( FOL ) , and normalises cardinal and date expressions .","label":"Uses","metadata":{},"score":"62.593616"}{"text":"Boxer produces standard DRS syntax , uses a neo - Davidsonian analysis for events ( with thematic roles from VerbNet ) , incorporates Van der Sandt 's algorithm for presupposition , is 100 % compatible with first - order logic ( FOL ) , and normalises cardinal and date expressions .","label":"Uses","metadata":{},"score":"62.593616"}{"text":"Boxer produces standard DRS syntax , uses a neo - Davidsonian analysis for events ( with thematic roles from VerbNet ) , incorporates Van der Sandt 's algorithm for presupposition , is 100 % compatible with first - order logic ( FOL ) , and normalises cardinal and date expressions .","label":"Uses","metadata":{},"score":"62.593616"}{"text":"Boxer produces standard DRS syntax , uses a neo - Davidsonian analysis for events ( with thematic roles from VerbNet ) , incorporates Van der Sandt 's algorithm for presupposition , is 100 % compatible with first - order logic ( FOL ) , and normalises cardinal and date expressions .","label":"Uses","metadata":{},"score":"62.593616"}{"text":"Boxer produces standard DRS syntax , uses a neo - Davidsonian analysis for events ( with thematic roles from VerbNet ) , incorporates Van der Sandt 's algorithm for presupposition , is 100 % compatible with first - order logic ( FOL ) , and normalises cardinal and date expressions .","label":"Uses","metadata":{},"score":"62.593616"}{"text":"Boxer produces standard DRS syntax , uses a neo - Davidsonian analysis for events ( with thematic roles from VerbNet ) , incorporates Van der Sandt 's algorithm for presupposition , is 100 % compatible with first - order logic ( FOL ) , and normalises cardinal and date expressions .","label":"Uses","metadata":{},"score":"62.593616"}{"text":"Boxer produces standard DRS syntax , uses a neo - Davidsonian analysis for events ( with thematic roles from VerbNet ) , incorporates Van der Sandt 's algorithm for presupposition , is 100 % compatible with first - order logic ( FOL ) , and normalises cardinal and date expressions .","label":"Uses","metadata":{},"score":"62.593616"}{"text":"Terminology .BNF .Backus - Naur Format .Context .A context is a subset of the full domain .A context can possess state .CFG .Context - Free Grammar .Domain .The scope of task semantics over which the associated language and associated attribute - values are meaningful .","label":"Uses","metadata":{},"score":"62.79452"}{"text":"Grammar Specification Language Syntax .This is a general requirements section into which all other requirements will eventually migrate as the representation syntax is defined to satisfy those requirements . 8.1 Understandability ( must specify ) .The grammar representation must be easy to understand , using well known methods for specifying the various elements .","label":"Uses","metadata":{},"score":"62.82854"}{"text":"Cognition , 48:71 - 99 .MacWhinney B. ( 1995 ) . ''The CHILDES Project : Tools for Analyzing Talk ' ' .Hillsdale , NJ : Lawrence Erlbaum Associates , 1995 .ABOUT THE REVIEWER : ABOUT THE REVIEWER Smaranda Muresan is a PhD Candidate in the Natural Language Processing Group , Department of Computer Science , Columbia University .","label":"Uses","metadata":{},"score":"62.920013"}{"text":"An . interesting point is the reinforcement of Elman 's discovery ( Elman .1993 ) that too much and complex information at the outset may confuse .the learner , leading him to spurious generalizations .The last two sections of this chapter,''Extending CAMiLLe ' ' and . ''","label":"Uses","metadata":{},"score":"63.122566"}{"text":"The phenomena covered are some of the most prominent ones studied in the context of PPT : head - complement order , V raising to I , V2 and Inversion , Null arguments , Wh - movement and Scrambling .The authors present an analytic discussion of both traditional approaches and the Concrete Minimalism account of these phenomena .","label":"Uses","metadata":{},"score":"63.132828"}{"text":"This document is part of a set of requirements studies for voice browsers , and provides details of the requirements for grammars for speech recognition .Status of this document .This document describes the requirements for grammars used for speech recognition , as a precursor to starting work on specifications .","label":"Uses","metadata":{},"score":"63.34098"}{"text":"It is also possible to output FOL formulas translated from the DRSs .Version 1.0 comprises 1,000 texts with CCG analyses for each sentence and semantic representations for each text .This is a very incomplete list of publications .North - Holland .","label":"Uses","metadata":{},"score":"63.4049"}{"text":"It is also possible to output FOL formulas translated from the DRSs .Version 1.0 comprises 1,000 texts with CCG analyses for each sentence and semantic representations for each text .This is a very incomplete list of publications .North - Holland .","label":"Uses","metadata":{},"score":"63.4049"}{"text":"ProFIT allows the programmer or grammar developer to declare an inheritance hierarchy , features and templates .Sorted feature terms can be used in ProFIT programs together with Prolog terms to provide a clearer description language for linguistic structures .ProFIT compiles all sorted feature terms into a Prolog term representation , so that the built - in Prolog term unification can be used for the unification of sorted feature structures , and no special unification algorithm is needed .","label":"Uses","metadata":{},"score":"63.502754"}{"text":"ProFIT thus provides a direct step from grammars developed with sorted feature terms to Prolog programs usable for practical NLP systems . \" ... this paper allows any defaults to be overridden by defaults which are associated with more specific types : thus priority ordering reflects the type hierarchy ordering .","label":"Uses","metadata":{},"score":"63.553127"}{"text":"The MIT Press .Linguistics and Philosophy 22 , 1999 .Natural Language and Linguistic Theory 5 , 403 - 439 .Semantics and Contextual Expression , ed . by Bartsch , van Benthem , and van Emde Boas .Foris , 294 - 318 .","label":"Uses","metadata":{},"score":"64.267586"}{"text":"Language Evolution through Language Acquisition : Formal and Computational Models ' ' .Cambridge University Press , Cambridge , UK , 2002 .Culicover , Peter W. ( 1999 ) . ''Syntactic Nuts : Hard Cases , Syntactic Theory , and Language Acquisition ' ' .","label":"Uses","metadata":{},"score":"64.587524"}{"text":"The . authors present their system , Aqui , which is a dynamical system in .which there is no meaning associated with words or sentences .The . authors also analyze the amount and type of knowledge in the input .","label":"Uses","metadata":{},"score":"64.73182"}{"text":"Learning a set of rules fo ... . \" ...One of the issues in any learning model is how it scales with problem size .The problem of learning finite state machine ( FSMs ) from examples with recurrent neural networks has been extensively explored .","label":"Uses","metadata":{},"score":"64.76986"}{"text":"NAME . 0.3Priorities .The following priorities are used to indicate the level of importance of each requirement in this document .Must Specify .The specification must define the feature .Should Specify .The specification should define the feature , if possible .","label":"Uses","metadata":{},"score":"65.12872"}{"text":"several positive results , as well as problematic phenomena where .further experimentation is needed .The authors discuss in these cases .the possible reasons of failure : not enough information , the task is .difficult , the learner needs to be enhanced .","label":"Uses","metadata":{},"score":"65.68103"}{"text":"Razor , is to be preferred to other syntactic theories that invoke more . abstract structure ' ' ( p. 22 ) .In this approach , linear order is . considered a primitive in the grammar .The phenomena covered are some . of the most prominent ones studied in the context of PPT : . head - complement order , V raising to I , V2 and Inversion , Null . arguments , Wh - movement and Scrambling .","label":"Uses","metadata":{},"score":"66.1712"}{"text":"The Groningen Meaning Bank .The Groningen Meaning Bank is an annotated corpus of public domain texts .Version 1.0 comprises 1,000 texts with CCG analyses for each sentence and semantic representations for each text .Publications .This is a very incomplete list of publications .","label":"Uses","metadata":{},"score":"66.194176"}{"text":"The Groningen Meaning Bank .The Groningen Meaning Bank is an annotated corpus of public domain texts .Version 1.0 comprises 1,000 texts with CCG analyses for each sentence and semantic representations for each text .Publications .This is a very incomplete list of publications .","label":"Uses","metadata":{},"score":"66.194176"}{"text":"The Groningen Meaning Bank .The Groningen Meaning Bank is an annotated corpus of public domain texts .Version 1.0 comprises 1,000 texts with CCG analyses for each sentence and semantic representations for each text .Publications .This is a very incomplete list of publications .","label":"Uses","metadata":{},"score":"66.194176"}{"text":"Automatic generation of template grammar from semantic schema : The semantic schema defines the entity relations of a specific domain .It serves as the specification for a language - enabled application .Their technology can automatically generate a Context Free Semantic Grammar template that inherits the semantic information specified in a semantic schema .","label":"Uses","metadata":{},"score":"66.27593"}{"text":"Appendix - Additional Examples .N - Gram Grammar Format .An example format is derived from the MIT N - gram format as follows : .Here is a brief description of the MIT bigram file format : .To adapt this to arbitrary N - grams we need to either indicate N or define a section end marker .","label":"Uses","metadata":{},"score":"66.282776"}{"text":"Authors point out in the Section ' ' Dummy Semantics ' ' that a realistic simulation would need larger data sets , which are hard to build .They present as an alternative the use of dummy semantics .For lexicon , they present experiments with flat dummy semantics , but they avow that this is not sufficient to learn structure and hint in a footnote that a different kind of dummy semantics will be needed : bracketed strings .","label":"Uses","metadata":{},"score":"66.5357"}{"text":"Jacobson interprets personal pronouns as the combinator I , and their binding is aided by a complex combinator Z , as in \" Mary lost her way \" .Z is definable using W and B. .CCG is known to define the same language class as tree - adjoining grammar , linear indexed grammar , and head grammar , and is said to be mildly context - sensitive .","label":"Uses","metadata":{},"score":"66.57694"}{"text":"Jacobson interprets personal pronouns as the combinator I , and their binding is aided by a complex combinator Z , as in \" Mary lost her way \" .Z is definable using W and B. .CCG is known to define the same language class as tree - adjoining grammar , linear indexed grammar , and head grammar , and is said to be mildly context - sensitive .","label":"Uses","metadata":{},"score":"66.57694"}{"text":"Jacobson interprets personal pronouns as the combinator I , and their binding is aided by a complex combinator Z , as in \" Mary lost her way \" .Z is definable using W and B. .CCG is known to define the same language class as tree - adjoining grammar , linear indexed grammar , and head grammar , and is said to be mildly context - sensitive .","label":"Uses","metadata":{},"score":"66.57694"}{"text":"Jacobson interprets personal pronouns as the combinator I , and their binding is aided by a complex combinator Z , as in \" Mary lost her way \" .Z is definable using W and B. .CCG is known to define the same language class as tree - adjoining grammar , linear indexed grammar , and head grammar , and is said to be mildly context - sensitive .","label":"Uses","metadata":{},"score":"66.57694"}{"text":"Jacobson interprets personal pronouns as the combinator I , and their binding is aided by a complex combinator Z , as in \" Mary lost her way \" .Z is definable using W and B. .CCG is known to define the same language class as tree - adjoining grammar , linear indexed grammar , and head grammar , and is said to be mildly context - sensitive .","label":"Uses","metadata":{},"score":"66.57694"}{"text":"Jacobson interprets personal pronouns as the combinator I , and their binding is aided by a complex combinator Z , as in \" Mary lost her way \" .Z is definable using W and B. .CCG is known to define the same language class as tree - adjoining grammar , linear indexed grammar , and head grammar , and is said to be mildly context - sensitive .","label":"Uses","metadata":{},"score":"66.57694"}{"text":"ProFIT is an extension of Standard Prolog with Features , Inheritance and Templates .ProFIT allows the programmer or grammar developer to declare an inheritance hierarchy , features and templates .Sorted feature terms can be used in ProFIT programs together with Prolog terms to provide a clearer descr ... \" .","label":"Uses","metadata":{},"score":"66.705414"}{"text":"We introduce a new method of constructing kernels on sets whose elements are discrete structures like strings , trees and graphs .The method can be applied iteratively to build a kernel on an infinite set from kernels involving generators of the set .","label":"Uses","metadata":{},"score":"66.75609"}{"text":"We introduce a new method of constructing kernels on sets whose elements are discrete structures like strings , trees and graphs .The method can be applied iteratively to build a kernel on an infinite set from kernels involving generators of the set .","label":"Uses","metadata":{},"score":"66.75609"}{"text":"We give an overview of the declarative transfer fo,'malism to- gether with its procedural realization .Our approach is discussed and compared with several other ap ... \" .This article presents a new semanticbased transfer approach developed and applied within the Verbmobil Machine Translation project .","label":"Uses","metadata":{},"score":"66.77099"}{"text":"The learner constructs an initial hypothesis from the given set of labeled examples and the teacher 's responses to membership queries .If an additional example observed by the learner is inconsistent with the current hypothesis then the hypothesis is modified minimally to make it consistent with the new example .","label":"Uses","metadata":{},"score":"66.86411"}{"text":"Occupied with the work to speech - enable applications , I 've never had enough time to use up my three - week vacation these years , \" says Wang .According to Wang , many state - of - the - art conversational systems use semantic - based robust understanding .","label":"Uses","metadata":{},"score":"66.87048"}{"text":"Boxer is developed by Johan Bos and generates formal semantic representations for CCG grammars .Boxer takes as input CCG ( Combinatory Categorial Grammar ) derivations and produces DRSs ( Discourse Representation Structures , from Hans Kamp 's Discourse Representation Theory ) as output .","label":"Uses","metadata":{},"score":"67.46944"}{"text":"Boxer is developed by Johan Bos and generates formal semantic representations for CCG grammars .Boxer takes as input CCG ( Combinatory Categorial Grammar ) derivations and produces DRSs ( Discourse Representation Structures , from Hans Kamp 's Discourse Representation Theory ) as output .","label":"Uses","metadata":{},"score":"67.46944"}{"text":"Boxer is developed by Johan Bos and generates formal semantic representations for CCG grammars .Boxer takes as input CCG ( Combinatory Categorial Grammar ) derivations and produces DRSs ( Discourse Representation Structures , from Hans Kamp 's Discourse Representation Theory ) as output .","label":"Uses","metadata":{},"score":"67.46944"}{"text":"In all versions , the file structure corresponds exactly to that of the original Treebank .Version 1.0 comprises 1,000 texts with CCG analyses for each sentence and semantic representations for each text .This is a very incomplete list of publications .","label":"Uses","metadata":{},"score":"67.61967"}{"text":"Attribute Processing ( must specify ) .A grammar referencing another grammar having attributes must be capable of performing a [ currently undefined ] set of operations upon the referenced attributes .Examples of such processing include boolean operations , string manipulation and attribute renaming .","label":"Uses","metadata":{},"score":"67.627754"}{"text":"mechanisms the learner needs in order to acquire language .The . conclusion is that neither distributional , nor grammatical approaches .can alone justify language acquisition , that each of them plays a . role .In all simulations , artificial data sets , as well as transcripts .","label":"Uses","metadata":{},"score":"67.74017"}{"text":"Attribute fields shall be included in the naming format . 8.5Native Natural Language ( must specify ) .The grammar representation must support the specification of a native language or locale .This specification can be embedded within a grammar rule to change the native language in mid - sentence .","label":"Uses","metadata":{},"score":"67.879715"}{"text":"More recent proponents of the approach are Jacobson and Baldridge .For example , the combinator B ( the compositor ) is useful in creating long - distance dependencies , as in \" Who do you think Mary is talking about ? \" and the combinator W ( the duplicator ) is useful as the lexical interpretation of reflexive pronouns , as in \" Mary talks about herself \" .","label":"Uses","metadata":{},"score":"68.29585"}{"text":"More recent proponents of the approach are Jacobson and Baldridge .For example , the combinator B ( the compositor ) is useful in creating long - distance dependencies , as in \" Who do you think Mary is talking about ? \" and the combinator W ( the duplicator ) is useful as the lexical interpretation of reflexive pronouns , as in \" Mary talks about herself \" .","label":"Uses","metadata":{},"score":"68.29585"}{"text":"More recent proponents of the approach are Jacobson and Baldridge .For example , the combinator B ( the compositor ) is useful in creating long - distance dependencies , as in \" Who do you think Mary is talking about ? \" and the combinator W ( the duplicator ) is useful as the lexical interpretation of reflexive pronouns , as in \" Mary talks about herself \" .","label":"Uses","metadata":{},"score":"68.29585"}{"text":"The requirements are being released as working drafts but are not intended to become proposed recommendations .This specification is a Working Draft of the Voice Browser working group for review by W3C members and other interested parties .This is the first public version of this document .","label":"Uses","metadata":{},"score":"68.809944"}{"text":"XML Compatibility .7.1 XML Embedding ( must specify ) .The grammar representation must support easy embedding of grammars into XML . 7.2 Pure XML Format ( must specify ) .A pure XML format for specification of grammars , including CFG 's , must be supported .","label":"Uses","metadata":{},"score":"69.13217"}{"text":"Wang has been working on Spoken Language Understanding for the MiPad project since he was hired to Microsoft Research .He has developed a robust parser and the understanding grammars for several projects . \"Grammar development is painful and error - prone .","label":"Uses","metadata":{},"score":"70.03476"}{"text":"Chapter 4 and 5 explore whether access to meaning is not only necessary , but also sufficient for grammar learning , given that in the system there exists mechanisms for finding associations between meaning and form .Chapter 4 presents CAMiLLe ( Conservative Attentive Minimalist Language Learner ) , a system which implements the theory of Concrete Minimalism in the form of a dynamical system .","label":"Uses","metadata":{},"score":"70.42157"}{"text":"It can also be used to define kernels in the form of joint Gibbs probability distributions .Kernels can be built from hidden Markov random elds , generalized regular expressions , pair - HMMs , or ANOVA decompositions .Uses of the method lead to open problems involving the theory of infinitely divisible positive definite functions .","label":"Uses","metadata":{},"score":"70.54066"}{"text":"The CHILDES Project : Tools for Analyzing .Talk ' ' .Hillsdale , NJ : Lawrence Erlbaum Associates , 1995 .ABOUT THE REVIEWER .Smaranda Muresan is a PhD Candidate in the Natural Language Processing .Group , Department of Computer Science , Columbia University .","label":"Uses","metadata":{},"score":"70.72383"}{"text":"It is inappropriate to use W3C Working Drafts as reference material or to cite them as other than \" work in progress \" .Publication as a Working Draft does not imply endorsement by the W3C membership , nor of members of the Voice Browser working groups .","label":"Uses","metadata":{},"score":"70.813736"}{"text":"421sComputational Linguist ... . by Manfred Krifka - Semantics and Contextual Expression , Foris , Dordrecht , 1989 . \" ...No assumption is more fundamental in the theory ( and practice ) of syntax than that natural languages should always be described in terms of constituent structure , at least wherever possible .","label":"Uses","metadata":{},"score":"71.1552"}{"text":"8.9 Comments ( must specify ) .The grammar representation must include a commenting mechanism .This mechanism can be provided by HTML or XML commenting formats . 8.10 Character Encodings ( must specify ) .The grammar representation must support the use of character encoding for foreign language support .","label":"Uses","metadata":{},"score":"71.66362"}{"text":"Neural Networks , 1 , 4 - 27 ) which has feedback but no hidden state neurons can learn a special type of FSM called a finite memory machine ( FMM ) under certain constraints .These machines have a large number of states ( simulations are for 256 and 512 state FMMs ) but have minimal order , relatively small depth and little logic when the FMM is implemented as a sequential machine , . by E. Vidal , F. Thollard , C. De La Higuera , F. Casacuberta , R. C. Carrasco .","label":"Uses","metadata":{},"score":"71.89228"}{"text":"( New page : Combinatory Categorial Grammar ( CCG ) is an efficiently parseable , yet linguistically expressive grammar formalism .It has a completely transparent interface between surface syntax and unde ... ) .Combinatory Categorial Grammar ( CCG ) is an efficiently parseable , yet linguistically expressive grammar formalism .","label":"Uses","metadata":{},"score":"72.42073"}{"text":"Next , taking HPSG as an exemplar of the grammar frameworks we have in mind , we show how the phonology attribute can be enriched , so that it can encode multi - tiered , hierarchical phonological representations .Finally , we exemplify the approach in some detail for the nonconcatenative morphology of Sierra Miwok and for schwa alternation in French .","label":"Uses","metadata":{},"score":"72.61923"}{"text":"The last two sections of this chapter,''Extending CAMiLLe ' ' and ' ' Preconditions for language acquisition by CAMiLLe ' ' , are a remarkable discussion of the overall results of the simulations , showing the characteristics of CAMiLLe , its performances and future directions .","label":"Uses","metadata":{},"score":"73.12998"}{"text":"This book presents consistent positive results that support the authors ' general approach .What I found also very useful , is the discussion of the limitations of the current implementation and how future research can address them : e.g. , CAMiLLe does not currently generalize to basic categories .","label":"Uses","metadata":{},"score":"73.28882"}{"text":"They present as an .alternative the use of dummy semantics .For lexicon , they present . experiments with flat dummy semantics , but they avow that this is not . sufficient to learn structure and hint in a footnote that a different . kind of dummy semantics will be needed : bracketed strings .","label":"Uses","metadata":{},"score":"73.54549"}{"text":"The tools are written in C++ and have been designed to be efficient enough for large - scale NLP tasks .StatCCG is a statistical CCG parser ( trained on CCGbank ) written by Julia Hockenmaier .Boxer takes as input CCG ( Combinatory Categorial Grammar ) derivations and produces DRSs ( Discourse Representation Structures , from Hans Kamp 's Discourse Representation Theory ) as output .","label":"Uses","metadata":{},"score":"74.05286"}{"text":"The tools are written in C++ and have been designed to be efficient enough for large - scale NLP tasks .StatCCG .StatCCG is a statistical CCG parser ( trained on CCGbank ) written by Julia Hockenmaier .Executables are available here .","label":"Uses","metadata":{},"score":"74.30233"}{"text":"The tools are written in C++ and have been designed to be efficient enough for large - scale NLP tasks .StatCCG .StatCCG is a statistical CCG parser ( trained on CCGbank ) written by Julia Hockenmaier .Executables are available here .","label":"Uses","metadata":{},"score":"74.30233"}{"text":"The tools are written in C++ and have been designed to be efficient enough for large - scale NLP tasks .StatCCG .StatCCG is a statistical CCG parser ( trained on CCGbank ) written by Julia Hockenmaier .Executables are available here .","label":"Uses","metadata":{},"score":"74.30233"}{"text":"XML character encoding can be used for XML grammar specifications .8.11 Recognizer Timeout Periods ( should specify ) .The grammar representation should support the specification of time limits inherently related to grammar characteristics .Such inherent characteristics can include the expected ( typically maximum ) times required to normally speak a sentence from the grammar .","label":"Uses","metadata":{},"score":"74.59663"}{"text":"There are various efficient parsers available for CCG .Software .OpenCCG : The OpenNLP CCG library .OpenCCG , the OpenNLP CCG Library , is an open source natural language processing library written in Java , which provides parsing and realization services based on Mark Steedman 's Combinatory Categorial Grammar ( CCG ) formalism .","label":"Uses","metadata":{},"score":"74.87077"}{"text":"There are various efficient parsers available for CCG .Software .OpenCCG : The OpenNLP CCG library .OpenCCG , the OpenNLP CCG Library , is an open source natural language processing library written in Java , which provides parsing and realization services based on Mark Steedman 's Combinatory Categorial Grammar ( CCG ) formalism .","label":"Uses","metadata":{},"score":"74.87077"}{"text":"There are various efficient parsers available for CCG .Software .OpenCCG : The OpenNLP CCG library .OpenCCG , the OpenNLP CCG Library , is an open source natural language processing library written in Java , which provides parsing and realization services based on Mark Steedman 's Combinatory Categorial Grammar ( CCG ) formalism .","label":"Uses","metadata":{},"score":"74.87077"}{"text":"How the system will deal with . null arguments , transformations , word - ordering will be presented in .Chapter 5 .Chapter 5 discusses some experiments with CAMiLLe , showing initial .results and pointing to future research .The authors organize the . chapter into three main parts corresponding to experiments regarding .","label":"Uses","metadata":{},"score":"75.88539"}{"text":"Univ . of Edinburgh .Alternative Phrases : Theoretical Analysis and Practical Applications , PhD thesis , University of Edinburgh .Data and Models for Statistical Parsing with Combinatory Categorial Grammar , PhD thesis , University of Edinburgh .Computational Analysis of the Syntax and Interpretation of ' Free ' Word - order in Turkish .","label":"Uses","metadata":{},"score":"77.35162"}{"text":"Univ . of Edinburgh .Alternative Phrases : Theoretical Analysis and Practical Applications , PhD thesis , University of Edinburgh .Data and Models for Statistical Parsing with Combinatory Categorial Grammar , PhD thesis , University of Edinburgh .Computational Analysis of the Syntax and Interpretation of ' Free ' Word - order in Turkish .","label":"Uses","metadata":{},"score":"77.35162"}{"text":"Univ . of Edinburgh .Alternative Phrases : Theoretical Analysis and Practical Applications , PhD thesis , University of Edinburgh .Data and Models for Statistical Parsing with Combinatory Categorial Grammar , PhD thesis , University of Edinburgh .Computational Analysis of the Syntax and Interpretation of ' Free ' Word - order in Turkish .","label":"Uses","metadata":{},"score":"77.35162"}{"text":"The library makes use of multi - modal extensions to CCG developed by .( the precursor to OpenCCG ) .For the latest news about OpenCCG , check out the .The VisCCG tool for working with grammars is available as part of the OpenCCG source code and distribution .","label":"Uses","metadata":{},"score":"77.44302"}{"text":"For example , the [ [ combinator ] ] B ( the compositor ) is useful in creating long - distance dependencies , as in \" Who do you think Mary is talking about ? \" and the combinator W ( the duplicator ) is useful as the lexical interpretation of reflexive pronouns , as in \" Mary talks about herself \" .","label":"Uses","metadata":{},"score":"78.39714"}{"text":"Briscoe , Ted ( editor ) ( 2002 ) . ''Language Evolution through Language .Acquisition : Formal and Computational Models ' ' .Cambridge University .Press , Cambridge , UK , 2002 .Culicover , Peter W. ( 1999 ) . ''","label":"Uses","metadata":{},"score":"78.89902"}{"text":"\" Microsoft is a platform company .It is extremely important to provide developers with easy - to - use tools for our platforms , so that speech - enabled applications and web services can become mainstream , \" says Alex Acero , Wang 's manager , who is also involved in the project .","label":"Uses","metadata":{},"score":"81.06201"}{"text":"remarkable discussion of the overall results of the simulations , . showing the characteristics of CAMiLLe , its performances and future . directions .Chapter 6 reports on simulations of language change and language .evolution from the dynamical perspective .This chapter elaborates on .","label":"Uses","metadata":{},"score":"81.774155"}{"text":"If you are interested in leading a book discussion , look for books announced on LINGUIST as \" available for review . \" Then contact Sheila Dooley Collberg at collberg linguistlist.org .Directory .Smaranda Muresan , Natural Language Processing Group , Department of .","label":"Uses","metadata":{},"score":"83.469475"}{"text":"IRCS Report 95 - 17 .PhD thesis .University of Pennsylvania .MSc thesis , School of Cognitive Science , Division of Informatics , University of Edinburgh .Ph .D Dissertation , Department of Computer and Information Science , University of Pennsylvania .","label":"Uses","metadata":{},"score":"84.1338"}{"text":"IRCS Report 95 - 17 .PhD thesis .University of Pennsylvania .MSc thesis , School of Cognitive Science , Division of Informatics , University of Edinburgh .Ph .D Dissertation , Department of Computer and Information Science , University of Pennsylvania .","label":"Uses","metadata":{},"score":"84.1338"}{"text":"IRCS Report 95 - 17 .PhD thesis .University of Pennsylvania .MSc thesis , School of Cognitive Science , Division of Informatics , University of Edinburgh .Ph .D Dissertation , Department of Computer and Information Science , University of Pennsylvania .","label":"Uses","metadata":{},"score":"84.1338"}{"text":"In Proceedings of the Workshop on Grammar Engineering Across Frameworks .Stanford , CA .In Proceedings of COLING-2008 .Manchester , UK .In Proceedings of ACL / HLT-2008 .Columbus , OH .Proceedings of COLING 2004 .In Proceedings of ENLG 2003 .","label":"Uses","metadata":{},"score":"91.19725"}{"text":"In Proceedings of the Workshop on Grammar Engineering Across Frameworks .Stanford , CA .In Proceedings of COLING-2008 .Manchester , UK .In Proceedings of ACL / HLT-2008 .Columbus , OH .Proceedings of COLING 2004 .In Proceedings of ENLG 2003 .","label":"Uses","metadata":{},"score":"91.19725"}{"text":"In Proceedings of the Workshop on Grammar Engineering Across Frameworks .Stanford , CA .In Proceedings of COLING-2008 .Manchester , UK .In Proceedings of ACL / HLT-2008 .Columbus , OH .Proceedings of COLING 2004 .In Proceedings of ENLG 2003 .","label":"Uses","metadata":{},"score":"91.19725"}{"text":"Current development efforts , led by Michael White , are focused on making the realizer practical to use in dialogue systems .For the latest news about OpenCCG , check out the OpenCCG page on SourceForge .You can also look at some of the projects using OpenCCG .","label":"Uses","metadata":{},"score":"91.509605"}{"text":"Current development efforts , led by Michael White , are focused on making the realizer practical to use in dialogue systems .For the latest news about OpenCCG , check out the OpenCCG page on SourceForge .You can also look at some of the projects using OpenCCG .","label":"Uses","metadata":{},"score":"91.509605"}{"text":"Current development efforts , led by Michael White , are focused on making the realizer practical to use in dialogue systems .For the latest news about OpenCCG , check out the OpenCCG page on SourceForge .You can also look at some of the projects using OpenCCG .","label":"Uses","metadata":{},"score":"91.509605"}