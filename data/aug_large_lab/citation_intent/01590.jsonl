{"text":"The chapter illustrates an extraction of a DVTAG from the Penn Treebank and the authors discuss the resultant number of predicted tags and the plausibility of an extracted model as a proxy for human language processing .Part Five describes several applications of supertagging .","label":"Background","metadata":{},"score":"34.546577"}{"text":"The chapter illustrates an extraction of a DVTAG from the Penn Treebank and the authors discuss the resultant number of predicted tags and the plausibility of an extracted model as a proxy for human language processing .Part Five describes several applications of supertagging .","label":"Background","metadata":{},"score":"34.546577"}{"text":"Deep Linguistic Processing of Language Variants .AntónioBranco and Costa Francisco .Pruning the Search Space of a Hand - Crafted Parsing System with a Probabilistic Parser .Creating a Systemic Functional Grammar Corpus from the Penn Treebank .Matthew Honnibal and James R. Curran .","label":"Background","metadata":{},"score":"35.153038"}{"text":"This paper shows how finite approximations of long distance dependency ( LDD ) resolution can be obtained automatically for wide - coverage , robust , probabilistic Lexical - Functional Grammar ( LFG ) resources acquired from treebanks .We extract LFG subcategorisation frames and paths linking LDD reentrancies from f - structures generated automatically for the Penn - II treebank trees and use them in an LDD resolution algorithm to parse new text .","label":"Background","metadata":{},"score":"35.54076"}{"text":"Our approach involves building a probabilistic context - free grammar for each author and using this grammar as a language model for classification .We evaluate the performance of our method on a wide range of datasets to demonstrate its efficacy . ... 000 ; Holmes and Forsyth , 1995 ; Joachims , 1998 ; Mosteller and Wallace , 1984 ) .","label":"Background","metadata":{},"score":"36.58895"}{"text":"Our approach involves building a probabilistic context - free grammar for each author and using this grammar as a language model for classification .We evaluate the performance of our method on a wide range of datasets to demonstrate its efficacy . ... 000 ; Holmes and Forsyth , 1995 ; Joachims , 1998 ; Mosteller and Wallace , 1984 ) .","label":"Background","metadata":{},"score":"36.58895"}{"text":"In particular , we demonstrated in Petrov et al .( 2006 ) that a hierarchically split PCFG could exceed the accuracy of lexic ... . by Ben Taskar , Dan Klein , Michael Collins , Daphne Koller , Christopher Manning - In Proceedings of EMNLP , 2004 . \" ...","label":"Background","metadata":{},"score":"36.87023"}{"text":"In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the coverage of harid - crafted grammars .","label":"Background","metadata":{},"score":"37.457344"}{"text":"In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the coverage of harid - crafted grammars .","label":"Background","metadata":{},"score":"37.457344"}{"text":"A discriminative reranker requires a source of candidate parses for each sentence .This paper describes a simple yet novel method for constructing sets of 50-best parses based on a coarse - to - fine generative parser ( Charniak , 2000 ) .","label":"Background","metadata":{},"score":"37.571396"}{"text":"Srinivas , B. and Joshi , A.K. ( 1998 ) .Supertagging : An approach to almost parsing .Computational Linguistics : 22:1 - 29 .Steedman , M. J. ( 2000 ) .The Syntactic Process .The MIT Press , Cambridge , M.A. .","label":"Background","metadata":{},"score":"38.361755"}{"text":"Srinivas , B. and Joshi , A.K. ( 1998 ) .Supertagging : An approach to almost parsing .Computational Linguistics : 22:1 - 29 .Steedman , M. J. ( 2000 ) .The Syntactic Process .The MIT Press , Cambridge , M.A. .","label":"Background","metadata":{},"score":"38.361755"}{"text":"On a broader perspective our approach contributes to a better understanding on where corpuslinguistics and theoretical linguistics can meet and enrich each other .The need of large - scale corpora for higherlevel syntactic frameworks is addressed in Sadler et al ( 2000 ) , Frank ( 2000 ) , Frank et al ( 2001 ) , who develop methods to enrich treebanks with higher - level ... . by","label":"Background","metadata":{},"score":"39.041092"}{"text":"On a broader perspective our approach contributes to a better understanding on where corpuslinguistics and theoretical linguistics can meet and enrich each other .The need of large - scale corpora for higherlevel syntactic frameworks is addressed in Sadler et al ( 2000 ) , Frank ( 2000 ) , Frank et al ( 2001 ) , who develop methods to enrich treebanks with higher - level ... . by","label":"Background","metadata":{},"score":"39.041092"}{"text":"In particular , it allows one to efficiently learn a model which discriminates among the entire space of parse trees , as opposed to reranking the top few candidates .Our models can condition on arbitrary features of input sentences , thus incorporating an important kind of lexical information without the added algorithmic complexity of modeling headedness .","label":"Background","metadata":{},"score":"39.328934"}{"text":", 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs of a statistical parser ( Collins , 2000 ) and ranking sentence plans ( Walker , Rambow and Rogati , 2001 ) .","label":"Background","metadata":{},"score":"39.442173"}{"text":", 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs of a statistical parser ( Collins , 2000 ) and ranking sentence plans ( Walker , Rambow and Rogati , 2001 ) .","label":"Background","metadata":{},"score":"39.442173"}{"text":"We extract different LTAGs from the Penn Treebank .We show that certain strategies yield an improved extracted LTAG in terms of compactness , broad coverage , and supertagging accuracy .Furthermore , we perform a preliminary investigation in smoothing these grammars by means of an external linguistic resource , namely , the tree families of an XTAG grammar , a hand built grammar of English . by Hans Van Halteren , Jakub Zavrel , Walter Daelemans - Computational Linguistics , 2000 . \" ... this paper , we combine different systems employing known representations .","label":"Background","metadata":{},"score":"39.54274"}{"text":"We extract different LTAGs from the Penn Treebank .We show that certain strategies yield an improved extracted LTAG in terms of compactness , broad coverage , and supertagging accuracy .Furthermore , we perform a preliminary investigation in smoothing these grammars by means of an external linguistic resource , namely , the tree families of an XTAG grammar , a hand built grammar of English . by Hans Van Halteren , Jakub Zavrel , Walter Daelemans - Computational Linguistics , 2000 . \" ... this paper , we combine different systems employing known representations .","label":"Background","metadata":{},"score":"39.54274"}{"text":"The authors then compare the system to other extraction algorithms for CFG and LTAG and describe a variety of applications using output from LexTract .In Chapter 3 ( \" Developing Tree - Adjoining Grammars with Lexical Descriptions , \" Fei Xia , Martha Palmer , and K. Vijay - Shanker ) , the authors present LexOrg , a system that produced LTAG grammars from abstract specifications ( 73 ) .","label":"Background","metadata":{},"score":"39.992874"}{"text":"The authors then compare the system to other extraction algorithms for CFG and LTAG and describe a variety of applications using output from LexTract .In Chapter 3 ( \" Developing Tree - Adjoining Grammars with Lexical Descriptions , \" Fei Xia , Martha Palmer , and K. Vijay - Shanker ) , the authors present LexOrg , a system that produced LTAG grammars from abstract specifications ( 73 ) .","label":"Background","metadata":{},"score":"39.992874"}{"text":"Multi - Component Tree Adjoining Grammars , Dependency Graph Models , and Linguistic Analyses .Joan Chen - Main and Aravind Joshi .Perceptron Training for a Wide - Coverage Lexicalized - Grammar Parser .Stephen Clark and James Curran .Filling Statistics with Linguistics - Property Design for the Disambiguation of German LFG Parses .","label":"Background","metadata":{},"score":"40.737442"}{"text":"The work extends an algorithm developed for lexicalized context - free grammars to LTAGs , resulting in a significant increase in the efficiency of an LTAG parsing algorithm .In Chapter 5 ( \" Combining Supertagging and Lexicalized Tree - Adjoining Grammar Parsing , \" Anoop Sarkar ) , the author explores two factors that impact TAG parser efficiency : syntactic lexical ambiguity and sentence complexity .","label":"Background","metadata":{},"score":"41.226013"}{"text":"The work extends an algorithm developed for lexicalized context - free grammars to LTAGs , resulting in a significant increase in the efficiency of an LTAG parsing algorithm .In Chapter 5 ( \" Combining Supertagging and Lexicalized Tree - Adjoining Grammar Parsing , \" Anoop Sarkar ) , the author explores two factors that impact TAG parser efficiency : syntactic lexical ambiguity and sentence complexity .","label":"Background","metadata":{},"score":"41.226013"}{"text":"In this paper , we present a novel approach for authorship attribution , the task of identifying the author of a document , using probabilistic context - free grammars .Our approach involves building a probabilistic context - free grammar for each author and using this grammar as a language model for class ... \" .","label":"Background","metadata":{},"score":"41.309814"}{"text":"In this paper , we present a novel approach for authorship attribution , the task of identifying the author of a document , using probabilistic context - free grammars .Our approach involves building a probabilistic context - free grammar for each author and using this grammar as a language model for class ... \" .","label":"Background","metadata":{},"score":"41.309814"}{"text":"We could also introduce new variables , e.g. , nonterminal refinements ( Matsuzaki et al . , 2005 ) , or secondary links Mij ( not constrai ... . by Jin - dong Kim , Tomoko Ohta , Sampo Pyysalo , Yoshinobu Kano - In Proceedings of Natural Language Processing in Biomedicine ( BioNLP )","label":"Background","metadata":{},"score":"42.809174"}{"text":"( van Halteren , 1996 ) ) .RankBoost can also use a variety of local and long distance features more easily than n - gram - based approaches ( cf .( Chen , Bangalore and Vijay - Shanker , 1999 ) ) because it makes sparse data less of an issue . \" ...","label":"Background","metadata":{},"score":"42.850266"}{"text":"( van Halteren , 1996 ) ) .RankBoost can also use a variety of local and long distance features more easily than n - gram - based approaches ( cf .( Chen , Bangalore and Vijay - Shanker , 1999 ) ) because it makes sparse data less of an issue . \" ...","label":"Background","metadata":{},"score":"42.850266"}{"text":"A number of previous efforts have tackled this tradeoff by starting with a commitment to linguistically motivated analyses and then finding appropriate ways to soften that commitment .We present an approach that explores the tradeoff from the other direction , starting with a context - free translation model learned directly from aligned parallel text , and then adding soft constituent - level constraints based on parses of the source language .","label":"Background","metadata":{},"score":"42.891445"}{"text":"A number of previous efforts have tackled this tradeoff by starting with a commitment to linguistically motivated analyses and then finding appropriate ways to soften that commitment .We present an approach that explores the tradeoff from the other direction , starting with a context - free translation model learned directly from aligned parallel text , and then adding soft constituent - level constraints based on parses of the source language .","label":"Background","metadata":{},"score":"42.891445"}{"text":"While each paper includes an introduction to the formalism or methods included , the book might not be readily accessible to an audience outside of the computational linguistics community or to those unfamiliar with the intricacies of parsing tasks .However , most chapters provide references to introductory materials for the motivated reader .","label":"Background","metadata":{},"score":"42.962055"}{"text":"While each paper includes an introduction to the formalism or methods included , the book might not be readily accessible to an audience outside of the computational linguistics community or to those unfamiliar with the intricacies of parsing tasks .However , most chapters provide references to introductory materials for the motivated reader .","label":"Background","metadata":{},"score":"42.962055"}{"text":"This has led to concer ... \" .Statistical parsers trained and tested on the Penn Wall Street Journal ( WSJ ) treebank have shown vast improvements over the last 10 years .Much of this improvement , however , is based upon an ever - increasing number of features to be trained on ( typically ) the WSJ treebank data .","label":"Background","metadata":{},"score":"43.264374"}{"text":"Empirically , optimal k - best lists can be extracted significantly faster than with other approaches , over a range of grammar types . \" ...We present a novel approach to grammatical error correction based on Alternating Structure Optimization .As part of our work , we introduce the NUS Corpus of Learner English ( NUCLE ) , a fully annotated one million words corpus of learner English available for research purposes .","label":"Background","metadata":{},"score":"43.81898"}{"text":"Empirically , optimal k - best lists can be extracted significantly faster than with other approaches , over a range of grammar types . \" ...We present a novel approach to grammatical error correction based on Alternating Structure Optimization .As part of our work , we introduce the NUS Corpus of Learner English ( NUCLE ) , a fully annotated one million words corpus of learner English available for research purposes .","label":"Background","metadata":{},"score":"43.81898"}{"text":"Shen demonstrates techniques for overcoming problems of sparse data , taking advantage of the rich feature sets provided by supertags , and forcing the learning algorithm to zero in on the most difficult classification cases .Chapter 7 ( \" A Nonstatistical Parsing - Based Approach to Supertagging , \" Pierre Boullier ) proposes a disambiguation model using structural constraints as opposed to statistical modeling .","label":"Background","metadata":{},"score":"44.11869"}{"text":"Shen demonstrates techniques for overcoming problems of sparse data , taking advantage of the rich feature sets provided by supertags , and forcing the learning algorithm to zero in on the most difficult classification cases .Chapter 7 ( \" A Nonstatistical Parsing - Based Approach to Supertagging , \" Pierre Boullier ) proposes a disambiguation model using structural constraints as opposed to statistical modeling .","label":"Background","metadata":{},"score":"44.11869"}{"text":"SuperARVs are gleaned from the Penn Treebank , and the authors test two parsing methods .The first method performs SuperARV disambiguation prior to dependency parsing and the second method performs disambiguation and linking in conjunction with one another .The parsers are evaluated using the Wall Street Journal and a speech recognition task .","label":"Background","metadata":{},"score":"44.186943"}{"text":"SuperARVs are gleaned from the Penn Treebank , and the authors test two parsing methods .The first method performs SuperARV disambiguation prior to dependency parsing and the second method performs disambiguation and linking in conjunction with one another .The parsers are evaluated using the Wall Street Journal and a speech recognition task .","label":"Background","metadata":{},"score":"44.186943"}{"text":"Specifically , we develop three infinite tree models , each of which enforces different independence assumptions , and for each model we define a simple direct assignment sampling inference procedure . ... ch of the left and right .As is standard , we used WSJ sections 2 - 21 for training , section 22 for development , and section 23 for testing .","label":"Background","metadata":{},"score":"44.280205"}{"text":"Specifically , we develop three infinite tree models , each of which enforces different independence assumptions , and for each model we define a simple direct assignment sampling inference procedure . ... ch of the left and right .As is standard , we used WSJ sections 2 - 21 for training , section 22 for development , and section 23 for testing .","label":"Background","metadata":{},"score":"44.280205"}{"text":"Finally , we present multilingual experiments which show that parsing with hierarchical state - splitting is fast and accurate in multiple languages and domains , even without any language - specific tuning . ... g ( Matsuzaki et al . , 2005 ; Petrov et al . , 2006 ) .","label":"Background","metadata":{},"score":"44.395287"}{"text":"We investigate how to best train a parser on the French Treebank ( Abeillé et al . , 2003 ) , viewing the task as a trade - off between generalizability and interpretability .We compare , for French , a supervised lexicalized parsing algorithm with a semi - supervised unlexicalized algorithm ( Petrov et al . , 2006 ) along the lines of ( Crabbé and Candito , 2008 ) .","label":"Background","metadata":{},"score":"44.63333"}{"text":"We investigate how to best train a parser on the French Treebank ( Abeillé et al . , 2003 ) , viewing the task as a trade - off between generalizability and interpretability .We compare , for French , a supervised lexicalized parsing algorithm with a semi - supervised unlexicalized algorithm ( Petrov et al . , 2006 ) along the lines of ( Crabbé and Candito , 2008 ) .","label":"Background","metadata":{},"score":"44.63333"}{"text":"The chapter tests this Syntactic Lexicalization Hypothesis ( 373 ) in the phonological domain .The author illustrates the effectiveness of elementary trees in describing the total syntactic representations for a variety of linguistic phenomena .Chapter 17 ( \" Constraining the Form of Supertags with the Strong Connectivity Hypothesis , \" Alessandro Mazzei , Vincenzo Lombardo , and Partick Sturt ) provides a model of incremental sentence processing using supertags .","label":"Background","metadata":{},"score":"45.298325"}{"text":"The chapter tests this Syntactic Lexicalization Hypothesis ( 373 ) in the phonological domain .The author illustrates the effectiveness of elementary trees in describing the total syntactic representations for a variety of linguistic phenomena .Chapter 17 ( \" Constraining the Form of Supertags with the Strong Connectivity Hypothesis , \" Alessandro Mazzei , Vincenzo Lombardo , and Partick Sturt ) provides a model of incremental sentence processing using supertags .","label":"Background","metadata":{},"score":"45.298325"}{"text":"Each of the five sections provides knowledge critical to the reader 's ability to understand and use supertags .Chapters in Part One describe methods for building LTAG grammars , which are precursors to many supertagging systems , from treebanked data or user - entered specifications .","label":"Background","metadata":{},"score":"45.38744"}{"text":"Each of the five sections provides knowledge critical to the reader 's ability to understand and use supertags .Chapters in Part One describe methods for building LTAG grammars , which are precursors to many supertagging systems , from treebanked data or user - entered specifications .","label":"Background","metadata":{},"score":"45.38744"}{"text":"Discriminative reranking is one method for constructing high - performance statistical parsers ( Collins , 2000 ) .A discriminative reranker requires a source of candidate parses for each sentence .This paper describes a simple yet novel method for constructing sets of 50-best parses based on a co ... \" .","label":"Background","metadata":{},"score":"45.493637"}{"text":"New Delhi : Prentice Hall of India .Joshi , A. K. ( 1985 ) .Tree Adjoining Grammars : How Much Context - Sensitivity Is Required to Provide Reasonable Structural Descriptions ?Natural Language Parsing : Psychological , Computational and Theoretical Perspectives , pp .","label":"Background","metadata":{},"score":"45.557667"}{"text":"New Delhi : Prentice Hall of India .Joshi , A. K. ( 1985 ) .Tree Adjoining Grammars : How Much Context - Sensitivity Is Required to Provide Reasonable Structural Descriptions ?Natural Language Parsing : Psychological , Computational and Theoretical Perspectives , pp .","label":"Background","metadata":{},"score":"45.557667"}{"text":"The chapter also details distinctions between this approach , previous work in the area of dependency parsing , and the Lightweight Dependency Analyzer ( LDA ; Bangalore , 2000 ) .Part Three gives an overview of supertags and supertag utilization in alternative formalisms .","label":"Background","metadata":{},"score":"45.56253"}{"text":"The chapter also details distinctions between this approach , previous work in the area of dependency parsing , and the Lightweight Dependency Analyzer ( LDA ; Bangalore , 2000 ) .Part Three gives an overview of supertags and supertag utilization in alternative formalisms .","label":"Background","metadata":{},"score":"45.56253"}{"text":"Second , we compare various inference procedures for state - split PCFGs from the standpoint of risk minimization , paying particular attention to their practical tradeoffs .Finally , we present multilingual experiments which show that parsing with hierarchical state - splitting is fast and accurate in multiple languages and domains , even without any language - specific tuning . .","label":"Background","metadata":{},"score":"45.66161"}{"text":"Joshi , A.K. and Srinivas , B. ( 1994 ) .Disambiguation of super parts of speech ( supertags ) : Almost parsing .In Proceedings of the 1994 International Conference on Computational Linguistics ( COLING ) , Kyoto , Japan .","label":"Background","metadata":{},"score":"46.073345"}{"text":"Joshi , A.K. and Srinivas , B. ( 1994 ) .Disambiguation of super parts of speech ( supertags ) : Almost parsing .In Proceedings of the 1994 International Conference on Computational Linguistics ( COLING ) , Kyoto , Japan .","label":"Background","metadata":{},"score":"46.073345"}{"text":"The book would be a valuable resource for linguists interested in computational grammars and parsing , and to machine learning researchers interested in linguistic formalisms and the design of complex syntactic features .REFERENCES Bangalore , S. ( 2000 ) .A lightweight dependency analyzer for partial parsing .","label":"Background","metadata":{},"score":"46.31313"}{"text":"The book would be a valuable resource for linguists interested in computational grammars and parsing , and to machine learning researchers interested in linguistic formalisms and the design of complex syntactic features .REFERENCES Bangalore , S. ( 2000 ) .A lightweight dependency analyzer for partial parsing .","label":"Background","metadata":{},"score":"46.31313"}{"text":"non - parallel , multilingual corpus . 1 Introduction Probabilistic grammars have become an important tool in natural language processing .An attractive property of probabilistic grammars is that the ... . by Fei Wu , Daniel S. Weld - in Proc . 48th Annu .","label":"Background","metadata":{},"score":"46.656258"}{"text":"A second group of papers does parsing by a sequence of independent , discriminative decisions , either greedily or with use of a small beam ( Ratnaparkhi , 1997 ; Henderson , 2004 ) .This paper extends th ...June 28th , 2007 .","label":"Background","metadata":{},"score":"46.77053"}{"text":"In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .Because of the highly lexicalized nature of the LTAG formalism , we experimentally show that notions other than sentence length play a factor in observed parse times .","label":"Background","metadata":{},"score":"47.01787"}{"text":"In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .Because of the highly lexicalized nature of the LTAG formalism , we experimentally show that notions other than sentence length play a factor in observed parse times .","label":"Background","metadata":{},"score":"47.01787"}{"text":"Lexicalized parsing focuses on identifying dependencies .w.o .GFs with GFs TüBa - D / Z 2611 2610 2197 Tiger 2535 2534 1592 T ..Existing k - best extraction methods can efficiently search for top derivations , but only after an exhaustive 1-best pass .","label":"Background","metadata":{},"score":"47.089302"}{"text":"Lexicalized parsing focuses on identifying dependencies .w.o .GFs with GFs TüBa - D / Z 2611 2610 2197 Tiger 2535 2534 1592 T ..Existing k - best extraction methods can efficiently search for top derivations , but only after an exhaustive 1-best pass .","label":"Background","metadata":{},"score":"47.089302"}{"text":"We investigate how to best train a parser on the French Treebank ( Abeillé et al . , 2003 ) , viewing the task as a trade - off between generalizability and interpretability .We compare , for French , a supervised lexicalized parsing algorithm w ... \" .","label":"Background","metadata":{},"score":"47.36676"}{"text":"We investigate how to best train a parser on the French Treebank ( Abeillé et al . , 2003 ) , viewing the task as a trade - off between generalizability and interpretability .We compare , for French , a supervised lexicalized parsing algorithm w ... \" .","label":"Background","metadata":{},"score":"47.36676"}{"text":"Chapter 2 ( \" From Treebanks to Tree - Adjoining Grammars , \" Fei Xia and Martha Palmer ) describes LexTract , a system that produces both CFGs and LTAGs from treebanks .Xia and Palmer first describe the three user - supplied input tables required by the system ; these tables provide the information to construct elementary trees , which mark heads and distinguish between arguments and adjuncts .","label":"Background","metadata":{},"score":"47.558693"}{"text":"Chapter 2 ( \" From Treebanks to Tree - Adjoining Grammars , \" Fei Xia and Martha Palmer ) describes LexTract , a system that produces both CFGs and LTAGs from treebanks .Xia and Palmer first describe the three user - supplied input tables required by the system ; these tables provide the information to construct elementary trees , which mark heads and distinguish between arguments and adjuncts .","label":"Background","metadata":{},"score":"47.558693"}{"text":"We present several improvements to unlexicalized parsing with hierarchically state - split PCFGs .First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar without a treebank .","label":"Background","metadata":{},"score":"47.779053"}{"text":"In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) and in Kinyon ( 00b ) , which allows to factor the information contained in several Supertags into a single structure and to encode functional information in a systematic manner .","label":"Background","metadata":{},"score":"47.79058"}{"text":"In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) and in Kinyon ( 00b ) , which allows to factor the information contained in several Supertags into a single structure and to encode functional information in a systematic manner .","label":"Background","metadata":{},"score":"47.79058"}{"text":"The target labels of the SRL system are PropBank roles , annotated over the Penn Treebank .Chen extracts LTAGs from the treebank to build supertaggers and an LDA , which uses PropBank information expressed as part of the syntactic constituent label .","label":"Background","metadata":{},"score":"47.86992"}{"text":"The target labels of the SRL system are PropBank roles , annotated over the Penn Treebank .Chen extracts LTAGs from the treebank to build supertaggers and an LDA , which uses PropBank information expressed as part of the syntactic constituent label .","label":"Background","metadata":{},"score":"47.86992"}{"text":"We report statistics on TEXTRUNNER 's 11,000,000 highest probability tuples , and show that they contain over 1,000,000 concrete facts and over 6,500,000 more abstract assertions . \" ...We present several improvements to unlexicalized parsing with hierarchically state - split PCFGs .","label":"Background","metadata":{},"score":"48.167854"}{"text":"The paper presents the design and implementation of the BioNLP'09 Shared Task , and reports the final results with analysis .The shared task consists of three sub - tasks , each of which addresses bio - molecular event extraction at a different level of specificity .","label":"Background","metadata":{},"score":"48.17372"}{"text":"The paper presents the design and implementation of the BioNLP'09 Shared Task , and reports the final results with analysis .The shared task consists of three sub - tasks , each of which addresses bio - molecular event extraction at a different level of specificity .","label":"Background","metadata":{},"score":"48.17372"}{"text":"The conversion and grammar extraction process imports linguistic generalisations that are missing the in original treebank .This supports the extraction of a linguistically sound grammar with maximal generalisation , as well as grammar induction techniques to capture unseen data in stochastic parsing .","label":"Background","metadata":{},"score":"48.28191"}{"text":"The conversion and grammar extraction process imports linguistic generalisations that are missing the in original treebank .This supports the extraction of a linguistically sound grammar with maximal generalisation , as well as grammar induction techniques to capture unseen data in stochastic parsing .","label":"Background","metadata":{},"score":"48.28191"}{"text":".. by Aoife Cahill , Michael Burke , Josef Van Genabith , Andy Way - In Proceedings of the 42nd Meeting of the ACL , 2004 . \" ...This paper shows how finite approximations of long distance dependency ( LDD ) resolution can be obtained automatically for wide - coverage , robust , probabilistic Lexical - Functional Grammar ( LFG ) resources acquired from treebanks .","label":"Background","metadata":{},"score":"48.643593"}{"text":"In particular we note the effects of two comparatively recent techniques for parser improvement .Then a reranking phase uses more detailed features , features which would ( mostly ) be ... . \" ...We formulate dependency parsing as a graphical model with the novel ingredient of global constraints .","label":"Background","metadata":{},"score":"48.771698"}{"text":"This paper presents a comparative study of probabilistic treebank parsing of German , using the Negra and TüBa - D / Z treebanks .Experiments with the Stanford parser , which uses a factored PCFG and dependency model , show that , contrary to previous claims for other parsers , lexicalization of PCFG models ... \" .","label":"Background","metadata":{},"score":"48.947147"}{"text":"This paper presents a comparative study of probabilistic treebank parsing of German , using the Negra and TüBa - D / Z treebanks .Experiments with the Stanford parser , which uses a factored PCFG and dependency model , show that , contrary to previous claims for other parsers , lexicalization of PCFG models ... \" .","label":"Background","metadata":{},"score":"48.947147"}{"text":"We present several improvements to unlexicalized parsing with hierarchically state - split PCFGs .First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar wi ... \" .","label":"Background","metadata":{},"score":"49.07731"}{"text":"SUMMARY Part One describes supertag creation and the arrangement of supertags in an inventory , focusing on the development of tree adjoining grammars ( TAGs ) .Because TAGs are difficult to construct manually , automatic extraction of grammars from large - scale lexical resources is an appealing alternative where feasible .","label":"Background","metadata":{},"score":"49.715294"}{"text":"SUMMARY Part One describes supertag creation and the arrangement of supertags in an inventory , focusing on the development of tree adjoining grammars ( TAGs ) .Because TAGs are difficult to construct manually , automatic extraction of grammars from large - scale lexical resources is an appealing alternative where feasible .","label":"Background","metadata":{},"score":"49.715294"}{"text":"This paper aims to provide some understanding and solid baseline numbers for the ... \" .Previous work on German parsing has provided confusing and conflicting results concerning the difficulty of the task and whether techniques that are useful for English , such as lexicalization , are effective for German .","label":"Background","metadata":{},"score":"49.795033"}{"text":"This paper aims to provide some understanding and solid baseline numbers for the ... \" .Previous work on German parsing has provided confusing and conflicting results concerning the difficulty of the task and whether techniques that are useful for English , such as lexicalization , are effective for German .","label":"Background","metadata":{},"score":"49.795033"}{"text":"1997 , for English ; Pedersen et . al .2004 , for Arabic ) .The authors discuss a parser implementation using Computational Paninian Grammar and compare this implementation and its performance with those of LTAG .Part Four is dedicated to exploring linguistic and psycholinguistic issues related to supertagging .","label":"Background","metadata":{},"score":"49.927326"}{"text":"1997 , for English ; Pedersen et . al .2004 , for Arabic ) .The authors discuss a parser implementation using Computational Paninian Grammar and compare this implementation and its performance with those of LTAG .Part Four is dedicated to exploring linguistic and psycholinguistic issues related to supertagging .","label":"Background","metadata":{},"score":"49.927326"}{"text":"First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar without a treebank .In our experiments , hierarchical pruning greatly accelerates parsing with no loss in empirical accuracy .","label":"Background","metadata":{},"score":"49.95819"}{"text":"The authors present a system incorporating supertagging into a CCG parser .The chapter also illustrates a model for CCG supertag disambiguation that yields multiple supertags per word ; this allows the system to find more supertags for a given span if the parser fails to cover the entire span with the supertags currently under consideration .","label":"Background","metadata":{},"score":"49.964005"}{"text":"The authors present a system incorporating supertagging into a CCG parser .The chapter also illustrates a model for CCG supertag disambiguation that yields multiple supertags per word ; this allows the system to find more supertags for a given span if the parser fails to cover the entire span with the supertags currently under consideration .","label":"Background","metadata":{},"score":"49.964005"}{"text":"Stamatatos et al .( 1999 ) and Luyckx and Daelemans ( 2008 ) use a combination of word - level statistics and part - of - speech counts or n - grams .Baayen ... .by Anna N. Rafferty , Christopher D. Manning - In ACL WorkShop on Parsing German , 2008 . \" ...","label":"Background","metadata":{},"score":"50.337414"}{"text":"Stamatatos et al .( 1999 ) and Luyckx and Daelemans ( 2008 ) use a combination of word - level statistics and part - of - speech counts or n - grams .Baayen ... .by Anna N. Rafferty , Christopher D. Manning - In ACL WorkShop on Parsing German , 2008 . \" ...","label":"Background","metadata":{},"score":"50.337414"}{"text":"Comput .Linguist . , 2010 . \" ...Information - extraction ( IE ) systems seek to distill semantic relations from naturallanguage text , but most systems use supervised learning of relation - specific examples and are thus limited by the availability of training data .","label":"Background","metadata":{},"score":"50.371628"}{"text":"These latent variables allow some dependence in the CFG .The chapter presents evaluation results and a discussion of variations in the values associated with each latent variable .Chapter 15 ( \" Computational Paninian Grammar Framework , \" Akshar Bharati and Rajeev Sangal ) describes a supertag implementation in Paninian Grammar .","label":"Background","metadata":{},"score":"50.527462"}{"text":"These latent variables allow some dependence in the CFG .The chapter presents evaluation results and a discussion of variations in the values associated with each latent variable .Chapter 15 ( \" Computational Paninian Grammar Framework , \" Akshar Bharati and Rajeev Sangal ) describes a supertag implementation in Paninian Grammar .","label":"Background","metadata":{},"score":"50.527462"}{"text":"Unfortunately , words are assigned on average a much higher number of Supertags than traditional POS .In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) ... \" .Srinivas ( 97 ) enriches traditional morpho - syntactic POS tagging with syntactic information by introducing Supertags .","label":"Background","metadata":{},"score":"50.57659"}{"text":"Unfortunately , words are assigned on average a much higher number of Supertags than traditional POS .In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) ... \" .Srinivas ( 97 ) enriches traditional morpho - syntactic POS tagging with syntactic information by introducing Supertags .","label":"Background","metadata":{},"score":"50.57659"}{"text":"While prior feature - based dynamic programming parsers have restricted training and evaluation to artificially short sentences , we present the first general , featurerich discriminative parser , based on a conditional random field model , which has been successfully scaled to the full WSJ parsing data .","label":"Background","metadata":{},"score":"50.797737"}{"text":"Despite its simplicity , our best grammar achieves an F1 of 90.2 % on the Penn Treebank , higher than fully lexicalized systems . ...e into smaller steps ) .In this paper , we investigate the learning of a grammar consistent with a treebank at the level of evaluation symbols ... . by Michele Banko , Michael J Cafarella , Stephen Soderland , Matt Broadhead , Oren Etzioni - IN IJCAI , 2007 . \" ...","label":"Background","metadata":{},"score":"50.986115"}{"text":"In particular , we show that the reranking parser described in Charniak and Johnson ( 2005 ) improves performance of the parser on Brown to 85.2 % .Furthermore , use of the self - training techniques described in ( Mc - Closky et al . , 2006 ) raise this to 87.8 % ( an error reduction of 28 % ) again without any use of labeled Brown data .","label":"Background","metadata":{},"score":"51.162327"}{"text":"We apply this idea to dependency and constituent parsing , generating results that surpass state - of - theart ... \" .We present a novel parser combination scheme that works by reparsing input sentences once they have already been parsed by several different parsers .","label":"Background","metadata":{},"score":"51.20755"}{"text":"Topics .Papers are invited on substantial , original , and unpublished research concerning deep linguistic processing .Possible topics include : . grammar engineering ( e.g. frameworks for grammar evaluation , best practice in grammar engineering , cross - linguistic / formalism generalisations & comparisons , semantic representation ) . treebanking ( e.g. frameworks for treebank evaluation / normalisation , grammar extraction / induction , the interface between grammar engineering and treebanking , treebanking methodologies , cross - linguistic / formalism generalisations & comparisons ) .","label":"Background","metadata":{},"score":"51.414963"}{"text":"Tree - based modeling still lacks many of the standard tools taken for granted in ( finite - state ) string - based modeling .The theory of tree transducer automata provides a possible framework to draw on , as it has been worked out in an extensive literature .","label":"Background","metadata":{},"score":"51.46399"}{"text":"With recent developments in computer hardware , parsing / generation algorithms and statistical learning theory , the way has been opened for deep linguistic processing to be successfully applied to an ever - growing range of languages , domains and applications .","label":"Background","metadata":{},"score":"51.61988"}{"text":"In contrast with previous work , we are able to split various terminals to different degrees , as appropriate to the actual complexity in the data .Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation .","label":"Background","metadata":{},"score":"51.637207"}{"text":"In contrast with previous work , we are able to split various terminals to different degrees , as appropriate to the actual complexity in the data .Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation .","label":"Background","metadata":{},"score":"51.637207"}{"text":"Such worries have merit .The standard \" Charniak parser \" checks in at a labeled precisionrecall f - measure of 89.7 % on the Penn WSJ test set , but only 82.9 % on the test set from the Brown treebank corpus .","label":"Background","metadata":{},"score":"51.705406"}{"text":"In contrast to statistical systems choosing one or n - best tags during parsing , the system outlined here ensures that all supertags needed to parse a sentence will be available for processing ; this approach therefore gives 100 % recall .","label":"Background","metadata":{},"score":"51.73144"}{"text":"In contrast to statistical systems choosing one or n - best tags during parsing , the system outlined here ensures that all supertags needed to parse a sentence will be available for processing ; this approach therefore gives 100 % recall .","label":"Background","metadata":{},"score":"51.73144"}{"text":"Grammars are core elements of many NLP applications .In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the cove ... \" .","label":"Background","metadata":{},"score":"52.60359"}{"text":"Grammars are core elements of many NLP applications .In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the cove ... \" .","label":"Background","metadata":{},"score":"52.60359"}{"text":"Our formulation uses a factorization analogous to the standard dynamic programs for parsing .In particular , it allows one to efficiently learn a model which discriminates ... \" .We present a novel discriminative approach to parsing inspired by the large - margin criterion underlying support vector machines .","label":"Background","metadata":{},"score":"52.754875"}{"text":"This proposal subsumes and clarifies findings that high - constraint contexts can facilitate lexical processing , and connects these findings to well - known models of parallel constraint - based comprehension .In addition , the theory leads to a number of specific predictions about the role of expectation in syntactic comprehension , including the reversal of locality - based difficulty patterns in syntactically constrained contexts , and conditions under which increased ambiguity facilitates processing .","label":"Background","metadata":{},"score":"52.805237"}{"text":"The reported experiments Lemmatization and lexicalized statistical parsing of morphologically rich languages : the case of French .Seddah , Djamé and Chrupała , Grzegorz and Cetinoglu , Ozlem and van Genabith , Josef and Candito , Marie ( 2010 )Lemmatization and lexicalized statistical parsing of morphologically rich languages : the case of French .","label":"Background","metadata":{},"score":"52.893234"}{"text":"Starting with a simple Xbar grammar , we learn a new grammar whose nonterminals are subsymbols of the original nonterminals .In co ... \" .We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .","label":"Background","metadata":{},"score":"52.976334"}{"text":"Starting with a simple Xbar grammar , we learn a new grammar whose nonterminals are subsymbols of the original nonterminals .In co ... \" .We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .","label":"Background","metadata":{},"score":"52.976334"}{"text":"This paper presents WOE , an open IE system which improves dramatically on TextRunner 's precision and recall .The key to WOE 's performance is a novel form of self - supervised learning for open extractors - using heuristic matches between Wikipedia infobox attribute values and corresponding sentences to construct training data .","label":"Background","metadata":{},"score":"53.048126"}{"text":"This highlights two facts : ( i ) lemmatization helps to reduce lexicon data - sparseness issues for French , ( ii ) it also makes the parsing process sensitive to correct assignment of POS tags to unknown words .Tools . by Slav Petrov , Leon Barrett , Romain Thibaux , Dan Klein - In ACL ' 06 , 2006 . \" ...","label":"Background","metadata":{},"score":"53.067017"}{"text":"This manual labor scales linearly with the number of target relations .This paper introduces Open IE ( OIE ) , a new extraction paradigm where the system makes a single data - driven pass over its corpus and extracts a large set of relational tuples without requiring any human input .","label":"Background","metadata":{},"score":"53.082047"}{"text":"Information - extraction ( IE ) systems seek to distill semantic relations from naturallanguage text , but most systems use supervised learning of relation - specific examples and are thus limited by the availability of training data .Open IE systems such as TextRunner , on the other hand , aim to handle the unbounded number of relations found on the Web .","label":"Background","metadata":{},"score":"53.553246"}{"text":"Head - Driven Phrase Structure Grammar .Chicago : University of Chicago Press .Srinivas , B. ( 1996 ) .\" Almost Parsing \" Technique for Language Modeling .In Proceedings of ICSLP96 Conference , Philadelphia , PA , pp .","label":"Background","metadata":{},"score":"53.562523"}{"text":"Head - Driven Phrase Structure Grammar .Chicago : University of Chicago Press .Srinivas , B. ( 1996 ) .\" Almost Parsing \" Technique for Language Modeling .In Proceedings of ICSLP96 Conference , Philadelphia , PA , pp .","label":"Background","metadata":{},"score":"53.562523"}{"text":"The reported experiments Tools . \" ...In adding syntax to statistical MT , there is a tradeoff between taking advantage of linguistic analysis , versus allowing the model to exploit linguistically unmotivated mappings learned from parallel training data .A number of previous efforts have tackled this tradeoff by starting with a commitment ... \" .","label":"Background","metadata":{},"score":"53.583412"}{"text":"Chapter 13 ( \" Extracting Supertags from HPSG - Based Treebanks , \" Günter Neumann and Berthold Crysmann ) describes supertagging in the context of Head - Driven Phrase Structure Grammar ( HPSG ; Pollard and Sag , 1994 ) .The authors extract a Lexicalized Tree Insertion Grammar ( LTIG ) from a German Treebank included in Verbmobil .","label":"Background","metadata":{},"score":"53.686665"}{"text":"Chapter 13 ( \" Extracting Supertags from HPSG - Based Treebanks , \" Günter Neumann and Berthold Crysmann ) describes supertagging in the context of Head - Driven Phrase Structure Grammar ( HPSG ; Pollard and Sag , 1994 ) .The authors extract a Lexicalized Tree Insertion Grammar ( LTIG ) from a German Treebank included in Verbmobil .","label":"Background","metadata":{},"score":"53.686665"}{"text":"In order to capture inherent relations occurring in corpus texts that can be critical in real - world applications , many NP relations are included in the set of grammatical relations used .We provide a comparison of our system with Minipar and the Link parser .","label":"Background","metadata":{},"score":"53.920162"}{"text":"The chapter also details a co - training design using a supertagging parser and a statistically - trained LTAG parser .Chapter 6 ( \" Discriminative Learning of Supertagging , \" Libin Shen ) gives an overview of a system for supertagging based on discriminative learning , which overcomes the problem of noise generated by a trigram supertagger .","label":"Background","metadata":{},"score":"53.931076"}{"text":"The chapter also details a co - training design using a supertagging parser and a statistically - trained LTAG parser .Chapter 6 ( \" Discriminative Learning of Supertagging , \" Libin Shen ) gives an overview of a system for supertagging based on discriminative learning , which overcomes the problem of noise generated by a trigram supertagger .","label":"Background","metadata":{},"score":"53.931076"}{"text":"Workshop on Statistical Parsing of Morphologically - Rich Languages at NAACL HLT 2010 , 5 June 2010 , Los Angeles , CA , USA .Abstract .This paper shows that training a lexicalized parser on a lemmatized morphologically - rich treebank such as the French Treebank slightly improves parsing results .","label":"Background","metadata":{},"score":"54.008995"}{"text":"This paper investigates the role of resource allocation as a source of processing difficulty in human sentence comprehension .The paper proposes a simple informationtheoretic characterization of processing difficulty as the work incurred by resource reallocation during parallel , incremental , probabi ... \" .","label":"Background","metadata":{},"score":"54.657494"}{"text":"Shifting to a new domain requires the user to name the target relations and to ma ... \" .Traditionally , Information Extraction ( IE ) has focused on satisfying precise , narrow , pre - specified requests from small homogeneous corpora ( e.g. , extract the location and time of seminars from a set of announcements ) .","label":"Background","metadata":{},"score":"54.878624"}{"text":"Our experiments show that our approach outperforms two baselines trained on non - learner text and learner text , respectively .Our approach also outperforms two commercial grammar checking software packages . \" ...We investigate whether wording , stylistic choices , and online behavior can be used to predict the age category of blog authors .","label":"Background","metadata":{},"score":"54.896996"}{"text":"Our experiments show that our approach outperforms two baselines trained on non - learner text and learner text , respectively .Our approach also outperforms two commercial grammar checking software packages . \" ...We investigate whether wording , stylistic choices , and online behavior can be used to predict the age category of blog authors .","label":"Background","metadata":{},"score":"54.896996"}{"text":"Introduction As a first step prior to parsing , traditional Part of Speech ( POS ) tagging assigns limited morpho - syntactic information to lexical items .These labels can be more or less fine - grained depending on the tagset , but syntactic information is often absent or limited .","label":"Background","metadata":{},"score":"55.11103"}{"text":"Introduction As a first step prior to parsing , traditional Part of Speech ( POS ) tagging assigns limited morpho - syntactic information to lexical items .These labels can be more or less fine - grained depending on the tagset , but syntactic information is often absent or limited .","label":"Background","metadata":{},"score":"55.11103"}{"text":"Each type of learning method brings its own ' inductive bias ' to the task and will produce a classifier with slightly different characteristics , so that different methods will tend to produce different errors . ... eras , 1999 ) for combining ensembles of neural networks .","label":"Background","metadata":{},"score":"55.28556"}{"text":"Each type of learning method brings its own ' inductive bias ' to the task and will produce a classifier with slightly different characteristics , so that different methods will tend to produce different errors . ... eras , 1999 ) for combining ensembles of neural networks .","label":"Background","metadata":{},"score":"55.28556"}{"text":"These abstract specifications inform key modules within LexOrg .The chapter also includes experimental results and comparison to related systems .Part Two describes implementations of supertag parsers and the use of supertagging in other parsing applications .Chapter 4 ( \" Complexity of Parsing for Some Lexicalized Formalisms , \" Giorgio Satta ) describes an innovative parsing algorithm for processing LTAGs more efficiently .","label":"Background","metadata":{},"score":"55.31603"}{"text":"These abstract specifications inform key modules within LexOrg .The chapter also includes experimental results and comparison to related systems .Part Two describes implementations of supertag parsers and the use of supertagging in other parsing applications .Chapter 4 ( \" Complexity of Parsing for Some Lexicalized Formalisms , \" Giorgio Satta ) describes an innovative parsing algorithm for processing LTAGs more efficiently .","label":"Background","metadata":{},"score":"55.31603"}{"text":"Aleš Horák , Karel Pala , Marie Duží and Pavel Materna .The Spanish Resource Grammar : Pre - processing Strategy and Lexical Acquisition .Partial Parse Selection for Robust Deep Processing .Yi Zhang , Valia Kordoni and Erin Fitzgerald .","label":"Background","metadata":{},"score":"55.8702"}{"text":"We ... \" .this paper , we combine different systems employing known representations .The observation that suggests this approach is that systems that are designed differently , either because they use a different formalism or because they contain different knowledge , will typically produce different errors .","label":"Background","metadata":{},"score":"56.150208"}{"text":"We ... \" .this paper , we combine different systems employing known representations .The observation that suggests this approach is that systems that are designed differently , either because they use a different formalism or because they contain different knowledge , will typically produce different errors .","label":"Background","metadata":{},"score":"56.150208"}{"text":"However , in the case of LexOrg , this information comes in the form of abstract specifications encoding specific linguistic information .The chapter describes a method of eliciting this linguistic information from the user whereby users are required to enter feature equations , rather than tree templates .","label":"Background","metadata":{},"score":"56.257935"}{"text":"However , in the case of LexOrg , this information comes in the form of abstract specifications encoding specific linguistic information .The chapter describes a method of eliciting this linguistic information from the user whereby users are required to enter feature equations , rather than tree templates .","label":"Background","metadata":{},"score":"56.257935"}{"text":"Research into non - parametric priors , such as the Dirichlet process , has enabled instead the use of infinite models , in which the number of hidden categories is not fixed , but can grow with the amount of training data .","label":"Background","metadata":{},"score":"56.288002"}{"text":"Research into non - parametric priors , such as the Dirichlet process , has enabled instead the use of infinite models , in which the number of hidden categories is not fixed , but can grow with the amount of training data .","label":"Background","metadata":{},"score":"56.288002"}{"text":"A Lexicalized Tree Adjoining Grammar for English .Technical Report IRCS 98 - 18 , University of Pennsylvania .ABOUT THE REVIEWER William Corvey is a PhD student in the Department of Linguistics and the Institute of Cognitive Science at the University of Colorado at Boulder .","label":"Background","metadata":{},"score":"56.310356"}{"text":"Shay , 2009 . \" ...We present a family of priors over probabilistic grammar weights , called the shared logistic normal distribution .This family extends the partitioned logistic normal distribution , enabling factored covariance between the probabilities of different derivation events in the probabilistic grammar , prov ... \" .","label":"Background","metadata":{},"score":"56.41712"}{"text":"Tools . \" ...In adding syntax to statistical MT , there is a tradeoff between taking advantage of linguistic analysis , versus allowing the model to exploit linguistically unmotivated mappings learned from parallel training data .A number of previous efforts have tackled this tradeoff by starting with a commitment ... \" .","label":"Background","metadata":{},"score":"56.552807"}{"text":"We present a novel approach to grammatical error correction based on Alternating Structure Optimization .As part of our work , we introduce the NUS Corpus of Learner English ( NUCLE ) , a fully annotated one million words corpus of learner English available for research purposes .","label":"Background","metadata":{},"score":"56.77541"}{"text":"We present a novel approach to grammatical error correction based on Alternating Structure Optimization .As part of our work , we introduce the NUS Corpus of Learner English ( NUCLE ) , a fully annotated one million words corpus of learner English available for research purposes .","label":"Background","metadata":{},"score":"56.77541"}{"text":"Discriminative feature - based methods are widely used in natural language processing , but sentence parsing is still dominated by generative methods .While prior feature - based dynamic programming parsers have restricted training and evaluation to artificially short sentences , we present the first gene ... \" .","label":"Background","metadata":{},"score":"56.815483"}{"text":"RankBoost ( Freund et al ., 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs ... \" .this paper , we investigate an approach to such a choice based on reranking a set of candidate supertags and their confidence scores .","label":"Background","metadata":{},"score":"57.491535"}{"text":"RankBoost ( Freund et al ., 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs ... \" .this paper , we investigate an approach to such a choice based on reranking a set of candidate supertags and their confidence scores .","label":"Background","metadata":{},"score":"57.491535"}{"text":"This paper defines a generative probabilistic model of parse trees , which we call PCFG - LA .This model is an extension of PCFG in which non - terminal symbols are augmented with latent variables .Finegrained CFG rules are automatically induced from a parsed corpus by training a PCFG - LA model using an E ... \" .","label":"Background","metadata":{},"score":"57.618397"}{"text":"We show how a Supertagger can be used to drastically reduce the syntactic lexical ambiguity for a given input and can be used in combination with an LTAG parser to radically improve parsing efficiency .We then turn our attention to from parsing efficiency to parsing accuracy and provide a method by which we can effectively combine the output of a Supertagger and a statistical LTAG parser using a co - training algorithm for bootstrapping new labeled data .","label":"Background","metadata":{},"score":"57.648273"}{"text":"We show how a Supertagger can be used to drastically reduce the syntactic lexical ambiguity for a given input and can be used in combination with an LTAG parser to radically improve parsing efficiency .We then turn our attention to from parsing efficiency to parsing accuracy and provide a method by which we can effectively combine the output of a Supertagger and a statistical LTAG parser using a co - training algorithm for bootstrapping new labeled data .","label":"Background","metadata":{},"score":"57.648273"}{"text":"Part Three illustrates supertag implementations in a variety of linguistic formalisms to suit the needs of many systems .Finally , Parts Four and Five provide empirical and application - based justification for the supertagging approach .The text remains coherent , despite covering a wide range of topics .","label":"Background","metadata":{},"score":"57.68924"}{"text":"Part Three illustrates supertag implementations in a variety of linguistic formalisms to suit the needs of many systems .Finally , Parts Four and Five provide empirical and application - based justification for the supertagging approach .The text remains coherent , despite covering a wide range of topics .","label":"Background","metadata":{},"score":"57.68924"}{"text":"Session 4 : Grammar Engineering .Validation and Regression Testing for a Cross - linguistic Grammar Resource .Emily M. Bender , Laurie Poulson , Scott Drellishak and Chris Evans .Local Ambiguity Packing and Discontinuity in German .Berthold Crysmann .","label":"Background","metadata":{},"score":"57.700165"}{"text":"In this paper we propose to use supertags to expose syntactic dependencies which are unavailable with POS tags .We first propose a novel method of app ... \" .Supertagging is the tagging process of assigning the correct elementary tree of LTAG , or the correct supertag , to each word of an input sentence .","label":"Background","metadata":{},"score":"57.923107"}{"text":"In this paper we propose to use supertags to expose syntactic dependencies which are unavailable with POS tags .We first propose a novel method of app ... \" .Supertagging is the tagging process of assigning the correct elementary tree of LTAG , or the correct supertag , to each word of an input sentence .","label":"Background","metadata":{},"score":"57.923107"}{"text":"Historically , unsupervised learning techniques have lacked a principled technique for selecting the number of unseen components .Research into non - parametric priors , such as the Dirichlet process , has enabled instead the use of infinite models , in which the number of hidden categories is not fixed , ... \" .","label":"Background","metadata":{},"score":"58.12709"}{"text":"Historically , unsupervised learning techniques have lacked a principled technique for selecting the number of unseen components .Research into non - parametric priors , such as the Dirichlet process , has enabled instead the use of infinite models , in which the number of hidden categories is not fixed , ... \" .","label":"Background","metadata":{},"score":"58.12709"}{"text":"We report on experiments over a 9,000,000 Web page corpus that compare TEXTRUNNER with KNOWITALL , a state - of - the - art Web IE system .TEXTRUNNER achieves an error reduction of 33 % on a comparable set of extractions .","label":"Background","metadata":{},"score":"58.431717"}{"text":"Moot first provides an introduction to type - logical grammars , which parse via theorem proving .The chapter then proceeds by detailing extraction of a type - logical treebank from the Spoken Dutch Corpus ; the resulting lexicon forms the basis of a supertagging vocabulary .","label":"Background","metadata":{},"score":"58.440704"}{"text":"Moot first provides an introduction to type - logical grammars , which parse via theorem proving .The chapter then proceeds by detailing extraction of a type - logical treebank from the Spoken Dutch Corpus ; the resulting lexicon forms the basis of a supertagging vocabulary .","label":"Background","metadata":{},"score":"58.440704"}{"text":"Despite its simplicity , our best grammar achieves an F1 of 90.2 % on the Penn Treebank , higher than fully lexicalized systems . ... reebank , higher than fully lexicalized systems .However , as demonstrated in Charniak ( 1996 ) and Klein and Manning ( 2003 ) , a PCFG which simply takes the empirical rules and probabilities off of a treebank does not perform well .","label":"Background","metadata":{},"score":"58.456932"}{"text":"The HMM approach to supertagging is motivated by the efficiency of decoding algorithms and by an improvement in performance for both German and English data .The authors present implementation details of the system components and use the applications for evaluation .","label":"Background","metadata":{},"score":"58.468483"}{"text":"The HMM approach to supertagging is motivated by the efficiency of decoding algorithms and by an improvement in performance for both German and English data .The authors present implementation details of the system components and use the applications for evaluation .","label":"Background","metadata":{},"score":"58.468483"}{"text":"The Stanford Parser is used to derive dependencies from CJ50 and gold parse trees .Figure 8 shows the detailed P / R curves .We can see that although today ... .by Jenny Rose Finkel , Alex Kleeman , Christopher D. Manning - In Proc .","label":"Background","metadata":{},"score":"58.60491"}{"text":"This model is an extension of PCFG in which non - terminal symbols are augmented with latent variables .Finegrained CFG rules are automatically induced from a parsed corpus by training a PCFG - LA model using an EM - algorithm .","label":"Background","metadata":{},"score":"58.6283"}{"text":"Chapter 19 ( \" Applications of HMM - Based Supertagging , \" Karin Harbusch , Jens Bäcker , and Saša Hasan ) describes two applications of Hidden Markov Model ( HMM)-based supertagging : a dialog system using supertags and a system for disambiguation on small device keyboards .","label":"Background","metadata":{},"score":"58.75256"}{"text":"Chapter 19 ( \" Applications of HMM - Based Supertagging , \" Karin Harbusch , Jens Bäcker , and Saša Hasan ) describes two applications of Hidden Markov Model ( HMM)-based supertagging : a dialog system using supertags and a system for disambiguation on small device keyboards .","label":"Background","metadata":{},"score":"58.75256"}{"text":"Many probabilistic models for natural language are now written in terms of hierarchical tree structure .Tree - based modeling still lacks many of the standard tools taken for granted in ( finite - state ) string - based modeling .The theory of tree transducer automata provides a possible framework to ... \" .","label":"Background","metadata":{},"score":"58.80313"}{"text":"Chapter 8 ( \" Nonlexical Chart Parsing for TAG , \" Alexis Nasr and Owen Rambow ) describes a Generative Dependency Grammar ( GDG ) parser for supertags .GDG is a type of nonlexicalized chart parser that produces dependency parse output from supertagged input .","label":"Background","metadata":{},"score":"58.834892"}{"text":"Chapter 8 ( \" Nonlexical Chart Parsing for TAG , \" Alexis Nasr and Owen Rambow ) describes a Generative Dependency Grammar ( GDG ) parser for supertags .GDG is a type of nonlexicalized chart parser that produces dependency parse output from supertagged input .","label":"Background","metadata":{},"score":"58.834892"}{"text":"parser / generator development ( e.g. algorithm development , grammar reversibility , efficiency , evaluation ) . machine learning for deep linguistic processing ( e.g. parse selection / ranking , supertagging , deep lexical acquisition , grammar induction ) .applications of deep linguistic processing ( e.g. information extraction , question answering , machine translation , dialogue systems , CALL ) .","label":"Background","metadata":{},"score":"59.12264"}{"text":"Bharati , A. , Bhatia , M. , Chaitanya , V. , and Sangal , R. ( 1996 ) .Paninian Grammar Framework Applied to English .Technical Report TRCS-96 - 238 , CSE , IIT Kanpur .Bharati , A. , Chaitanya , V. , and Sangal , R. ( 1995 ) .","label":"Background","metadata":{},"score":"59.328896"}{"text":"Bharati , A. , Bhatia , M. , Chaitanya , V. , and Sangal , R. ( 1996 ) .Paninian Grammar Framework Applied to English .Technical Report TRCS-96 - 238 , CSE , IIT Kanpur .Bharati , A. , Chaitanya , V. , and Sangal , R. ( 1995 ) .","label":"Background","metadata":{},"score":"59.328896"}{"text":"The authors present parser evaluation on both the Verbmobil and NEGRA corpora .Chapter 14 ( \" Probabilistic Context - Free Grammars with Latent Annotations , \" Takuya Matsuzaki , Yusuke Miyao , and Jun'ichi Tsujii ) gives a method for extending localization in context - free grammars .","label":"Background","metadata":{},"score":"59.422043"}{"text":"The authors present parser evaluation on both the Verbmobil and NEGRA corpora .Chapter 14 ( \" Probabilistic Context - Free Grammars with Latent Annotations , \" Takuya Matsuzaki , Yusuke Miyao , and Jun'ichi Tsujii ) gives a method for extending localization in context - free grammars .","label":"Background","metadata":{},"score":"59.422043"}{"text":"..We just list two of them which seem to be most relevant : C4 uses a reduced tagset while C3 uses the PTB tagset . 9 Instead , we re - ran 8 All use Section 2 - 21 of the PTB for training , and Section 22 or 23 for testing .","label":"Background","metadata":{},"score":"59.49607"}{"text":"..We just list two of them which seem to be most relevant : C4 uses a reduced tagset while C3 uses the PTB tagset . 9 Instead , we re - ran 8 All use Section 2 - 21 of the PTB for training , and Section 22 or 23 for testing .","label":"Background","metadata":{},"score":"59.49607"}{"text":"This family extends the partitioned logistic normal distribution , enabling factored covariance between the probabilities of different derivation events in the probabilistic grammar , providing a new way to encode prior knowledge about an unknown grammar .We describe a variational EM algorithm for learning a probabilistic grammar based on this family of priors .","label":"Background","metadata":{},"score":"59.706787"}{"text":".. ations are used to define grammatical roles .The original treebanks , in particular the Penn Treebank , were for English , and provided only phrase structure trees , and hence this is the native ou ... . by Slav Petrov , Leon Barrett , Romain Thibaux , Dan Klein - In ACL ' 06 , 2006 . \" ...","label":"Background","metadata":{},"score":"59.738754"}{"text":"Tools . \" ...The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .","label":"Background","metadata":{},"score":"60.919586"}{"text":".. sister adjunction can be used to create parse trees for all input strings , with only a slight penalty in accuracy .The results are graphed in Figure 14 .They use a different set of Supertags and so we used their result simply to get an approxima ... . \" ...","label":"Background","metadata":{},"score":"60.970863"}{"text":".. sister adjunction can be used to create parse trees for all input strings , with only a slight penalty in accuracy .The results are graphed in Figure 14 .They use a different set of Supertags and so we used their result simply to get an approxima ... . \" ...","label":"Background","metadata":{},"score":"60.970863"}{"text":"Although lexical amb ... New !We welcome discussion of this book review on the list , and particularly invite the author(s ) or editor(s ) of this book to join in .If you are interested in reviewing a book for LINGUIST , look for the most recent posting with the subject \" Reviews : AVAILABLE FOR REVIEW \" , and follow the instructions at the top of the message .","label":"Background","metadata":{},"score":"60.974777"}{"text":"We also present a proof that owl - qn is guaranteed to converge to a globally optimal parameter vector . \" ...Statistical parsers trained and tested on the Penn Wall Street Journal ( WSJ ) treebank have shown vast improvements over the last 10 years .","label":"Background","metadata":{},"score":"61.553406"}{"text":"The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .We believe that is largely in part due to the absence of large corpora accurately bracketed in terms of a perspicuous yet broad coverage LTAG .","label":"Background","metadata":{},"score":"62.16578"}{"text":"The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .We believe that is largely in part due to the absence of large corpora accurately bracketed in terms of a perspicuous yet broad coverage LTAG .","label":"Background","metadata":{},"score":"62.16578"}{"text":"Chapter 10 ( \" Constraint Dependency Grammars : SuperARVs , Language Modeling , and Parsing , \" Mary P. Harper and Wen Wang ) describes supertagging with constraint dependency grammars ( Mayurama , 1990 ) .Parsing is viewed as a constraint satisfaction problem .","label":"Background","metadata":{},"score":"62.302425"}{"text":"Chapter 10 ( \" Constraint Dependency Grammars : SuperARVs , Language Modeling , and Parsing , \" Mary P. Harper and Wen Wang ) describes supertagging with constraint dependency grammars ( Mayurama , 1990 ) .Parsing is viewed as a constraint satisfaction problem .","label":"Background","metadata":{},"score":"62.302425"}{"text":"Therefore , while CFGs are defined by a set of primitives and context - free rules , an LTAG specification instead contains elementary trees and derivation trees .The book contains nineteen chapters , including the Introduction , divided into five sections .","label":"Background","metadata":{},"score":"62.94715"}{"text":"Therefore , while CFGs are defined by a set of primitives and context - free rules , an LTAG specification instead contains elementary trees and derivation trees .The book contains nineteen chapters , including the Introduction , divided into five sections .","label":"Background","metadata":{},"score":"62.94715"}{"text":"154 - 160 .Lambek , J. ( 1958 ) .The mathematics of sentence structure .American Mathematical Monthly , 65:154 - 170 .Mayurama , H. ( 1990 ) .Constraint Dependency Grammar .Technical Report # RT0044 , IBM , Tokyo , Japan .","label":"Background","metadata":{},"score":"63.33365"}{"text":"154 - 160 .Lambek , J. ( 1958 ) .The mathematics of sentence structure .American Mathematical Monthly , 65:154 - 170 .Mayurama , H. ( 1990 ) .Constraint Dependency Grammar .Technical Report # RT0044 , IBM , Tokyo , Japan .","label":"Background","metadata":{},"score":"63.33365"}{"text":"In this work , we present 1 . an effective method for pruning in split PCFGs 2 . a comparison of objective functions for infe ... . \" ...The l - bfgs limited - memory quasi - Newton method is the algorithm of choice for optimizing the parameters of large - scale log - linear models with L2 regularization , but it can not be used for an L1-regularized loss due to its non - differentiability whenever some parameter is zero .","label":"Background","metadata":{},"score":"63.80425"}{"text":"EDITORS : Srinivas Bangalore and Aravind K. Joshi TITLE :Supertagging SUBTITLE :Using Complex Lexical Descriptions in Natural Language Processing PUBLISHER : MIT Press YEAR : 2010 .William Corvey , Department of Linguistics , University of Colorado at Boulder .","label":"Background","metadata":{},"score":"64.50795"}{"text":"EDITORS : Srinivas Bangalore and Aravind K. Joshi TITLE :Supertagging SUBTITLE :Using Complex Lexical Descriptions in Natural Language Processing PUBLISHER : MIT Press YEAR : 2010 .William Corvey , Department of Linguistics , University of Colorado at Boulder .","label":"Background","metadata":{},"score":"64.50795"}{"text":"Through experimentation with a range of y ... \" .We investigate whether wording , stylistic choices , and online behavior can be used to predict the age category of blog authors .Our hypothesis is that significant changes in writing style distinguish pre - social media bloggers from post - social media bloggers .","label":"Background","metadata":{},"score":"64.58336"}{"text":"Through experimentation with a range of y ... \" .We investigate whether wording , stylistic choices , and online behavior can be used to predict the age category of blog authors .Our hypothesis is that significant changes in writing style distinguish pre - social media bloggers from post - social media bloggers .","label":"Background","metadata":{},"score":"64.58336"}{"text":"Although lexical amb ...Tools . \" ...The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .","label":"Background","metadata":{},"score":"64.74669"}{"text":"Anusarak : A Device to Overcome the Language Barrier .PhD thesis , Department of CSE , IIT Kanpur , January , 1994 .Pedersen , M. J. , Eades , D. , Amin , S.K. and Prakash , L. ( 2004 ) .","label":"Background","metadata":{},"score":"64.79904"}{"text":"Anusarak : A Device to Overcome the Language Barrier .PhD thesis , Department of CSE , IIT Kanpur , January , 1994 .Pedersen , M. J. , Eades , D. , Amin , S.K. and Prakash , L. ( 2004 ) .","label":"Background","metadata":{},"score":"64.79904"}{"text":"A Lexicalized Tree Adjoining Grammar for English .Technical Report IRCS 98 - 18 , University of Pennsylvania .ABOUT THE REVIEWER .ABOUT THE REVIEWER : William Corvey is a PhD student in the Department of Linguistics and the Institute of Cognitive Science at the University of Colorado at Boulder .","label":"Background","metadata":{},"score":"64.818405"}{"text":"INT'L CONF .ON LANGUAGE RESOURCES AND EVALUATION ( LREC , 2006 . \" ...This paper describes a system for extracting typed dependency parses of English sentences from phrase structure parses .In order to capture inherent relations occurring in corpus texts that can be critical in real - world applications , many NP relations are included in the set of grammatical relations ... \" .","label":"Background","metadata":{},"score":"64.819626"}{"text":"We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .","label":"Background","metadata":{},"score":"65.72932"}{"text":"We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .","label":"Background","metadata":{},"score":"65.72932"}{"text":"We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .","label":"Background","metadata":{},"score":"65.72932"}{"text":"We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .","label":"Background","metadata":{},"score":"65.72932"}{"text":"CFGs derive phrases via the application of rules ; to form larger LTAG trees , elementary trees may be composed by operations , particularly adjoining ( 9 ) .In LTAG , these parse trees are called \" derived trees , \" as they are the result of attaching several elementary trees together .","label":"Background","metadata":{},"score":"65.94594"}{"text":"CFGs derive phrases via the application of rules ; to form larger LTAG trees , elementary trees may be composed by operations , particularly adjoining ( 9 ) .In LTAG , these parse trees are called \" derived trees , \" as they are the result of attaching several elementary trees together .","label":"Background","metadata":{},"score":"65.94594"}{"text":"LUNCH .INVITED TALK .Across Languages and Grammar Paradigms - New Perspectives on Resource Acquisition , Grammar Engineering and Application .Deep Linguistic Processing for Spoken Dialogue Systems .James Allen , Myroslava Dzikovska , Mehdi Manshadi and Mary Swift .","label":"Background","metadata":{},"score":"66.11565"}{"text":"Simple primitives have the advantage of being straightforward to annotate , but require more complex operations to compose larger structures ; more complicated primitives require more advanced local annotation of linguistic features but require only general operations for composition .The approach taken in this text is the latter , to \" complicate locally , simplify globally ( CLSG ) \" ( 2 ) .","label":"Background","metadata":{},"score":"66.69539"}{"text":"Simple primitives have the advantage of being straightforward to annotate , but require more complex operations to compose larger structures ; more complicated primitives require more advanced local annotation of linguistic features but require only general operations for composition .The approach taken in this text is the latter , to \" complicate locally , simplify globally ( CLSG ) \" ( 2 ) .","label":"Background","metadata":{},"score":"66.69539"}{"text":"We also show that internet writing characteristics are important features for age prediction , but that lexical content is also needed to produce significantly more accurate results .Our best results allow for 81.57 % accuracy . by Marie C , Benoît Crabbé , Djamé Seddah , Université Paris , Université Paris . \" ...","label":"Background","metadata":{},"score":"67.37095"}{"text":"We also show that internet writing characteristics are important features for age prediction , but that lexical content is also needed to produce significantly more accurate results .Our best results allow for 81.57 % accuracy . by Marie C , Benoît Crabbé , Djamé Seddah , Université Paris , Université Paris . \" ...","label":"Background","metadata":{},"score":"67.37095"}{"text":"Al- though the approach is applicable to any type of language model , we focus on the case of statistical disambiguators that are trained on annotated corpora .The examples of the task that are present in the corpus and its annotation are fed into a learning algorithm , which induces a model of the desired input - output mapping in the form of a classifier .","label":"Background","metadata":{},"score":"67.48188"}{"text":"Al- though the approach is applicable to any type of language model , we focus on the case of statistical disambiguators that are trained on annotated corpora .The examples of the task that are present in the corpus and its annotation are fed into a learning algorithm , which induces a model of the desired input - output mapping in the form of a classifier .","label":"Background","metadata":{},"score":"67.48188"}{"text":"Experiments with the Stanford parser , which uses a factored PCFG and dependency model , show that , contrary to previous claims for other parsers , lexicalization of PCFG models boosts parsing performance for both treebanks .The experiments also show that there is a big difference in parsing performance , when trained on the Negra and on the TüBa - D / Z treebanks .","label":"Background","metadata":{},"score":"68.658966"}{"text":"Experiments with the Stanford parser , which uses a factored PCFG and dependency model , show that , contrary to previous claims for other parsers , lexicalization of PCFG models boosts parsing performance for both treebanks .The experiments also show that there is a big difference in parsing performance , when trained on the Negra and on the TüBa - D / Z treebanks .","label":"Background","metadata":{},"score":"68.658966"}{"text":"On WSJ15 , we attain a state - of - the - art F - score of 90.9 % , a 14 % relative reduction in error over previous models , while being two orders of magnitude faster .On sentences of length 40 , our system achieves an F - score of 89.0 % , a 36 % relative reduction in error over a generative baseline . ...","label":"Background","metadata":{},"score":"69.74245"}{"text":"In : S. Shah and S. Hussain , Proceedings of the Eighth International Multitopic Conference .The Eighth International Multitopic Conference ( INMIC 2004 ) , Lahore , Pakistan , ( 573 - 578 ) .24 - 26 December , 2004 .","label":"Background","metadata":{},"score":"69.99272"}{"text":"In : S. Shah and S. Hussain , Proceedings of the Eighth International Multitopic Conference .The Eighth International Multitopic Conference ( INMIC 2004 ) , Lahore , Pakistan , ( 573 - 578 ) .24 - 26 December , 2004 .","label":"Background","metadata":{},"score":"69.99272"}{"text":"As a parsing algorithm , BP is both asymptotically and empirically efficient .E ... \" .We formulate dependency parsing as a graphical model with the novel ingredient of global constraints .We show how to apply loopy belief propagation ( BP ) , a simple and effective tool for approximate learning and inference .","label":"Background","metadata":{},"score":"71.16807"}{"text":"We present an algorithm Orthant - Wise Limited - memory Quasi - Newton ( owlqn ) , based on l - bfgs , that can efficiently optimize the L1-regularized log - likelihood of log - linear models with millions of parameters .","label":"Background","metadata":{},"score":"71.395966"}{"text":"First , LTAGs and CFGs contain distinct primitive elements .Whereas the domain of locality of a CFG is expressed as a rule , an LTAG instead encodes elementary trees , which associate a verb with its arguments .This is done in order to localize all dependencies within a single domain ; the editors show that constraint specification is often spread over several domains of locality in CFGs , which is counter to the CLSG approach .","label":"Background","metadata":{},"score":"71.648506"}{"text":"First , LTAGs and CFGs contain distinct primitive elements .Whereas the domain of locality of a CFG is expressed as a rule , an LTAG instead encodes elementary trees , which associate a verb with its arguments .This is done in order to localize all dependencies within a single domain ; the editors show that constraint specification is often spread over several domains of locality in CFGs , which is counter to the CLSG approach .","label":"Background","metadata":{},"score":"71.648506"}{"text":"WOE can operate in two modes : when restricted to POS tag features , it runs as quickly as TextRunner , but when set to use dependency - parse features its precision and recall rise even higher . ... h recall .","label":"Background","metadata":{},"score":"71.82269"}{"text":"Sanae Fujita , Francis Bond , Stephan Oepen and Takaaki Tanaka .COFFEE BREAK .Session 2 : Applications of Deep Linguistic Processing .Deep Grammars in a Tree Labeling Approach to Syntax - based Statistical Machine Translation .Question Answering based on Semantic Roles .","label":"Background","metadata":{},"score":"72.43254"}{"text":"The l - bfgs limited - memory quasi - Newton method is the algorithm of choice for optimizing the parameters of large - scale log - linear models with L2 regularization , but it can not be used for an L1-regularized loss due to its non - differentiability whenever some parameter is zero .","label":"Background","metadata":{},"score":"72.60061"}{"text":"We first propose a novel method of applying Sparse Network of Winnow ( SNoW ) to sequential models .Then we use . \" ...In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .","label":"Background","metadata":{},"score":"74.34279"}{"text":"We first propose a novel method of applying Sparse Network of Winnow ( SNoW ) to sequential models .Then we use . \" ...In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .","label":"Background","metadata":{},"score":"74.34279"}{"text":"Even with second - order features or latent variables , which would make exact parsing considerably slower or NP - hard , BP needs only O(n3 ) time with a small constant factor .Furthermore , such features significantly improve parse accuracy over exact first - order methods .","label":"Background","metadata":{},"score":"75.12328"}{"text":"We examine the performance of three techniques on three treebanks ( Negra , Tiger , and TüBa - D / Z ) : ( i ) Markovization , ( ii ) lexicalization , and ( iii ) state splitting .We additionally explore parsing with the inclusion of grammatical function information .","label":"Background","metadata":{},"score":"76.44302"}{"text":"We examine the performance of three techniques on three treebanks ( Negra , Tiger , and TüBa - D / Z ) : ( i ) Markovization , ( ii ) lexicalization , and ( iii ) state splitting .We additionally explore parsing with the inclusion of grammatical function information .","label":"Background","metadata":{},"score":"76.44302"}{"text":"The shared task was run over 12 weeks , drawing initial interest from 42 teams .Of these teams , 24 submitted final results .The evaluation results are encouraging , indicating that state - of - the - art performance is approaching a practically applicable level and revealing some remaining challenges . ... parsers . \" ...","label":"Background","metadata":{},"score":"76.49643"}{"text":"Supertags are formed from dependency trees taken from the German NEGRA and TIGER corpora .These supertags are designed to be especially information - rich , and thus increase the size of the supertag vocabulary .The authors note that this increase in vocabulary size does not cause a proportional increase in supertagger error , and this motivates an exploration of methods of feature encoding to maximize the performance of a rule - based weighted constrained dependency parser using rich supertags .","label":"Background","metadata":{},"score":"77.37181"}{"text":"Supertags are formed from dependency trees taken from the German NEGRA and TIGER corpora .These supertags are designed to be especially information - rich , and thus increase the size of the supertag vocabulary .The authors note that this increase in vocabulary size does not cause a proportional increase in supertagger error , and this motivates an exploration of methods of feature encoding to maximize the performance of a rule - based weighted constrained dependency parser using rich supertags .","label":"Background","metadata":{},"score":"77.37181"}{"text":"Anette Frank ( University of Heidelberg ) is to give an invited talk at the workshop with the provisional title Across languages and grammar paradigms - New perspectives on resource acquisition , grammar engineering and applications .Schedule .Opening Remarks .","label":"Background","metadata":{},"score":"78.65854"}{"text":"Workshop Description .We characterise this style of computational linguistic research as deep linguistic processing , due to it aspiring to model the complexity of natural language in rich linguistic representations .Background .Deep linguistic processing has traditionally been concerned with grammar development .","label":"Background","metadata":{},"score":"80.29446"}{"text":"This comparison at least suggests that German is not harder to parse than its West - Germanic neighbor language English . ... ing an appropriate parsing model for German .Section 3 introduces the Negra and TüBa - D / Z treebanks and 2 German is not the first language for which this question has been raised .","label":"Background","metadata":{},"score":"88.20809"}{"text":"This comparison at least suggests that German is not harder to parse than its West - Germanic neighbor language English . ... ing an appropriate parsing model for German .Section 3 introduces the Negra and TüBa - D / Z treebanks and 2 German is not the first language for which this question has been raised .","label":"Background","metadata":{},"score":"88.20809"}