{"text":"In this survey , we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation , multitask learning and sample selection bias , as well as co - variate shift .We also explore some potential future issues in transfer learning research . .","label":"Future","metadata":{},"score":"22.312958"}
{"text":"The typical assumption that both training and testing data are drawn from the same distribution no longer applies .This paper evaluates domain adaptation techniques for SMT systems in the context of end - user feedback in a real world application .","label":"Future","metadata":{},"score":"24.755463"}
{"text":"Blitzer , J. , Crammer , K. , Kulesza , A. , Pereira , F. , & Wortman , J. ( 2007a ) .Learning bounds for domain adaptation .In Advances in neural information processing systems ( NIPS ) .Blitzer , J. , Dredze , M. , & Pereira , F. ( 2007b ) .","label":"Future","metadata":{},"score":"25.083202"}
{"text":"MATH CrossRef MathSciNet .Mansour , Y. , Mohri , M. , & Rostamizadeh , A. ( 2009 ) .Domain adaptation with multiple sources .In Advances in neural information processing systems .Marcus , M. , Marcinkiewicz , M. , & Santorini , B. ( 1993 ) .","label":"Future","metadata":{},"score":"26.485882"}
{"text":"Rather than learning separate models for each domain , we explore systems that learn across multiple domains .We develop a new multi - domain online learning framework based on parameter combination from multiple classifiers .Our algorithms draw from multi - task learning and domain adaptation to adapt multiple source domain classifiers to a new target domain , learn across multiple similar domains , and learn across a large number of disparate domains .","label":"Future","metadata":{},"score":"28.53426"}
{"text":"In this paper we address the problem of multiple citation concept alignment by combining and modifying the CRF based pairwise word alignment system of Blunsom & Cohn ( 2006 ) and a posterior decoding based multiple sequence alignment algorithm of Schwartz & Pachter ( 2007 ) .","label":"Future","metadata":{},"score":"28.778385"}
{"text":"In recent years , transfer learning has emerged as a new learning framework to address this problem .This survey focuses on categorizing and reviewing the current progress on transfer learning for classification , regression and clustering problems .In this survey , we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation , multitask learning and sample selection bias , as well as co - variate shift .","label":"Future","metadata":{},"score":"28.925598"}
{"text":"We incorporate instance weighting into a mixture - model framework , and find that it yields consistent improvements over a wide range of baselines .There has also been some work on adapting the word alignment model prior to phrase extraction ( Civera and Juan , 2007 ; Wu et al . , 2005 ) , and on dyn ... .","label":"Future","metadata":{},"score":"29.029135"}
{"text":"This extends previous work on discriminative weighting b ... \" .We describe a new approach to SMT adaptation that weights out - of - domain phrase pairs according to their relevance to the target domain , determined by both how similar to it they appear to be , and whether they belong to general language or not .","label":"Future","metadata":{},"score":"29.445034"}
{"text":"We introduce an approximate inference method using Tree - based Reparameterization ( TRP ) to reduce computational cost .In experiments , our proposed model obtained significant improvements compare to baseline models that use Support Vector Machines .We introduce a technique for identifying the most salient participants in a discussion .","label":"Future","metadata":{},"score":"29.616095"}
{"text":"In recent years , transfer learning has emerged as a new learning framework to address this problem .This survey focuses on categorizing and reviewing the current progress on transfer learning for classification , regression , and clustering problems .In this survey , we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation , multitask learning and sample selection bias , as well as covariate shift .","label":"Future","metadata":{},"score":"29.672909"}
{"text":"In this paper , we present a three - step multi - lingual dependency parser based on a deterministic shift - reduce parsing algorithm .Different from last year , we separate the root - parsing strategy as sequential labeling task and try to link the neighbor word dependences via a near neighbor parsing .","label":"Future","metadata":{},"score":"29.673223"}
{"text":"59 - 766 ) .Satpal , S. , & Sarawagi , S. ( 2007 ) .Domain adaptation of conditional probability models via feature subsetting .In European conference on principles and practice of knowledge discovery in databases .Schweikert , G. , Widmer , C. , Schölkopf , B. , & Rätsch , G. ( 2008 ) .","label":"Future","metadata":{},"score":"29.778618"}
{"text":"49 - 57 , 2006 .[ 6 ] L. Bruzzone and M. Marconcini , \" Domain Adaptation Problems : A DASVM Classification Technique and a Circular Validation Strategy , \" IEEE Trans .Pattern Analysis and Machine Intelligence , vol .","label":"Future","metadata":{},"score":"29.978796"}
{"text":"Experimental results demonstrate that the proposed method outperforms both traditional inductive classifiers and the state - of - the - art boosting - based transfer algorithms on most domains , including text categorization and web page ratings .In particular , it can achieve around 10 % higher accuracy than other approaches for the text categorization problem .","label":"Future","metadata":{},"score":"30.249481"}
{"text":"Numerical studies show that the proposed method compares favorably with existing model selection methods in regression for extrapolation and in classification with imbalanced data . by Wenyuan Dai , Gui - rong Xue , Qiang Yang , Yong Yu - In Proceedings of the 22nd AAAI Conference on Artificial Intelligence , 2007 . \" ...","label":"Future","metadata":{},"score":"30.40499"}
{"text":"86 - 91 , July - Sept .[26 ] G. Schweikert , C. Widmer , B. Schölkopf , and G. Rätsch , \" An Empirical Analysis of Domain Adaptation Algorithms for Genomic Sequence Analysis , \" Proc .Advances in Neural Information Processing Systems , pp .","label":"Future","metadata":{},"score":"30.438164"}
{"text":"In such cases , knowledge transfer , if done successfully , would greatly improve the performance of learning by avoiding much expensive data labeling efforts .In recent years , transfer learning has emerged as a new learning framework to address this problem .","label":"Future","metadata":{},"score":"30.76328"}
{"text":"Frustratingly hard domain adaptation for parsing .In Shared task - conference on natural language learning - CoNLL 2007 shared task .Dredze , M. , Crammer , K. , & Pereira , F. ( 2008 ) .Confidence - weighted linear classification .","label":"Future","metadata":{},"score":"30.80273"}
{"text":"[ 9 ] B. Chen , W. Lam , I.W. Tsang , and T.L. Wong , \" Extracting Discriminative Concepts for Domain Adaptation in Text Mining , \" Proc .ACM SIGKDD Int'l Conf .Knowledge Discovery and Data Mining , pp .","label":"Future","metadata":{},"score":"31.018486"}
{"text":"For example , this may be the case when it is expensive to label the data in a domain of interest , although in a related but different domain there may be plenty of labeled data available .In this paper , we propose a novel transfer - learning algorithm for text classification based on an EM - based Naive Bayes classifiers .","label":"Future","metadata":{},"score":"31.148214"}
{"text":"Our results suggest that our bootstrapping methods have considerable potential , and could be used to semi - automate an approach based on incremental manual annotation .In this paper , we consider the computational modelling of human plausibility judgements for verb - relation - argument triples , a task equivalent to the computation of selectional preferences .","label":"Future","metadata":{},"score":"31.34739"}
{"text":"We achieve most gains from the use of larger training corpora and basic modeling , but also show promising results from integrating more linguistic annotation . \" ...In this paper , we investigate lexicon models for hierarchical phrase - based statistical machine translation .","label":"Future","metadata":{},"score":"31.377924"}
{"text":"Since state - of - the - art statistical machine translation systems model the translation process as a log - linear combination of simpler model ... \" .We present an adaptation technique for statistical machine translation , which applies the well - known Bayesian learning paradigm for adapting the model parameters .","label":"Future","metadata":{},"score":"31.560284"}
{"text":"In this paper , we propose a locally weighted ensemble framework to combine multiple models for transfer learning , where the weights are dynamically assigned according to a model 's predictive power on each test example .It can integrate the advantages of various learning algorithms and the labeled information from multiple training domains into one unified classification model , which can then be applied on a different domain .","label":"Future","metadata":{},"score":"31.768894"}
{"text":"In Conference on computational natural language learning ( CONLL ) .Jiang , J. , & Zhai , C. ( 2007a ) .Instance weighting for domain adaptation in nlp .In Association for computational linguistics ( ACL ) .Jiang , J. , & Zhai , C. ( 2007b ) .","label":"Future","metadata":{},"score":"31.985043"}
{"text":"We describe new lookup algorithms for hierarchical phrase - based translation that reduce the empirical computation time by nearly two orders of magnitude , making on - the - fly lookup feasible for source phrases with gaps .This paper presents an empirical study on how different selections of input translation systems affect translation quality in system combination .","label":"Future","metadata":{},"score":"32.13576"}
{"text":"An adaptation technique is used to avoid this problem .The second problem is domain estimation .For adaptation , the domain must be given in advance .However , in many cases , the domain is not given or changes dynamically .","label":"Future","metadata":{},"score":"32.223804"}
{"text":"5 ] and applied in their respective translation systems for phrase table smoothing .Chiang et al .[ 15 ] suggested morphology - based and provenance - based improvements to the Koehn - Och - Marcu method recently ... \" ...","label":"Future","metadata":{},"score":"32.30857"}
{"text":"In the domain adaptation track , we use two models to parse unlabeled data in the target domain to supplement the labeled out - of - domain training set , in a scheme similar to one iteration of co - training .","label":"Future","metadata":{},"score":"32.39681"}
{"text":"A key idea is to introduce non - standard CCG combinators that relax certain parts of the grammar --- for example allowing flexible word order , or insertion of lexical items --- with learned costs .We also present a new , online algorithm for inducing a weighted CCG .","label":"Future","metadata":{},"score":"32.45184"}
{"text":"By extending a recent model , we obtain a completely corpus - driven model for this task which achieves significant correlations with human judgements .It rivals or exceeds deeper , resource - driven models while exhibiting higher coverage .Moreover , we show that our model can be combined with deeper models to obtain better predictions than from either model alone .","label":"Future","metadata":{},"score":"32.650703"}
{"text":"However , increasing a model 's order can lead to an increase in the number of model parameters , making the model more susceptible to sparse data problems .This paper shows how the notion of output transformation can be used to explore a variety of alternative model structures .","label":"Future","metadata":{},"score":"32.67582"}
{"text":"[ 15 ] J. Huang , A.J. Smola , A. Gretton , K.M. Borgwardt , and B. Schölkopf , \" Correcting Sample Selection Bias by Unlabeled Data , \" Proc .Advances in Neural Information Processing Systems 19 , pp .601 - 608 , 2007 .","label":"Future","metadata":{},"score":"32.71951"}
{"text":"The idea is to decompose the word alignment process into two steps , model training and alignment inference , and perform Bayesian adaptation on the latter .We propose a flexible and efficient domain adaptation method that yields consistent improvements in machine translation ( for 11 language pairs ) .","label":"Future","metadata":{},"score":"33.023926"}
{"text":"Exploiting spectral clustering and active learning ( Dasgupta et al . , 2009 ) .Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsStructural Correspondence Learning Blitzer et al . , 2007 : Introduce pivot features that appear frequently in source and target domains .","label":"Future","metadata":{},"score":"33.08814"}
{"text":"We show the optimality of a locally weighted ensemble framework as a general approach to combine multiple models for domain transfer .We then propose an implementation of the local weight assignments by mapping the structures of a model onto the structures of the test domain , and then weighting each model locally according to its consistency with the neighborhood structure around the test example .","label":"Future","metadata":{},"score":"33.11928"}
{"text":"The effectiveness of our algorithm is analyzed theoretically and empirically to show that our iterative algorithm can converge well to an accurate model . ...y data , and discussed when transfer learning would improve the performance and when decrease .","label":"Future","metadata":{},"score":"33.18511"}
{"text":"In this paper , we investigate lexicon models for hierarchical phrase - based statistical machine translation .We explore sourceto - target models with phrase - level as well as sentence - level scoring and target - to - source models with scoring on phrase level only .","label":"Future","metadata":{},"score":"33.255077"}
{"text":"We address the problem of training the free parameters of a statistical machine translation system .We show significant improvements over a state - of - the - art minimum error rate training baseline on a large Chinese - English translation task .","label":"Future","metadata":{},"score":"33.334866"}
{"text":"In Advances in neural information processing systems ( NIPS ) .Tax , D. M. J. , van Breukelen , M. , Duina , R. P. W. , & Kittler , J. ( 2000 ) .Combining multiple classifiers by averaging or by multiplying ?","label":"Future","metadata":{},"score":"33.4317"}
{"text":"In Advances in neural information processing systems ( NIPS ) .Dredze , M. , & Crammer , K. ( 2008 ) .Online methods for multi - domain learning and adaptation .In Empirical methods in natural language processing ( EMNLP ) .","label":"Future","metadata":{},"score":"33.726402"}
{"text":"This paper explores a parsimonious approach to Data - Oriented Parsing .While allowing , in principle , all possible subtrees of trees in the treebank to be productive elements , our approach aims at finding a manageable subset of these trees that can accurately describe empirical distributions over phrase - structure trees .","label":"Future","metadata":{},"score":"33.913788"}
{"text":"We describe an incremental parser that was trained to minimize cost over sentences rather than over individual parsing actions .This is an attempt to use the advantages of the two top - scoring systems in the CoNLL - X shared task .","label":"Future","metadata":{},"score":"33.96663"}
{"text":"Therefore , the proposed method is computationally highly efficient and simple to implement .We also elucidate theoretical properties of the proposed method such as the convergence rate and approximation error bounds .Numerical experiments show that the proposed method is comparable to the best existing method in accuracy , while it is computationally more efficient than competing approaches .","label":"Future","metadata":{},"score":"33.983788"}
{"text":"In this paper we suggest that this problem of selecting a good model can be recast as a recommendation problem , where the goal is to recommend a good model for a particular task based on how well a limited probe set of models appears to perform .","label":"Future","metadata":{},"score":"34.136726"}
{"text":"Recent efforts have tried to overcome this issue by using statistics from speech lattices instead of only the 1-best transcripts ; however , these efforts have invariably used the classical vector space retrieval model .This paper presents a novel approach to lattice - based spoken document retrieval using statistical language models : a statistical model is estimated for each document , and probabilities derived from the document models are directly used to measure relevance .","label":"Future","metadata":{},"score":"34.36921"}
{"text":"The appropriate output transformation for a given task can be selected by applying a hill - climbing approach to held - out data .On the NP Chunking task , our hill - climbing system finds a model structure that outperforms both first - order and second - order models with the same input feature set .","label":"Future","metadata":{},"score":"34.779266"}
{"text":"Moreover , the feature transfer approach has proven to be extremely useful in the deep learning framework for unsupervised classification tasks [ 23].In this setting some recent work proposed also to ... . \" ... Abstract .The problem of training classifiers from limited data is one that particularly affects large - scale and social applications , and as a result , although carefully trained machine learning forms the backbone of many current techniques in research , it sees dramatically fewer applications for en ... \" .","label":"Future","metadata":{},"score":"34.795338"}
{"text":"( 2005 ) , obtain very high accuracy on standard dependency parsing tasks and can be trained and applied without marginalization , ' ' summing trees ' ' permits some alternative techniques of interest .Using the summing algorithm , we present experimental results on four nonprojective languages , for maximum conditional likelihood estimation , minimum Bayes - risk parsing , and hidden variable training .","label":"Future","metadata":{},"score":"34.845116"}
{"text":"Neural Information Processing Systems , Dec. 2008 .[ 41 ] A. Argyriou , C.A. Micchelli , M. Pontil , and Y. Ying , \" A Spectral Regularization Framework for Multi - Task Structure Learning , \" Proc . 20th Ann .","label":"Future","metadata":{},"score":"34.96647"}
{"text":"In many real - world applications such as robot control [ 10 ] , bioinformatics [ 1 ] , spam filtering [ 3 ] , brain - computer interfacing [ 9 ] , or econometrics [ 5 ] , covariate shift is conceivable and thus learn ... .","label":"Future","metadata":{},"score":"34.98355"}
{"text":"In Advances in neural information processing systems ( NIPS ) ( pp .353 - 360 ) .Daumé , H. ( 2007 ) .Frustratingly easy domain adaptation .In Association for computational linguistics ( ACL ) .Daumé , H. ( 2009 ) .","label":"Future","metadata":{},"score":"34.988583"}
{"text":"In this paper we present new experiments to test this claim .We use the PARSEVAL metric , the Leaf - Ancestor metric as well as a dependency - based evaluation , and present novel approaches measuring the effect of controlled error insertion on treebank trees and parser output .","label":"Future","metadata":{},"score":"35.02353"}
{"text":"Finally , we show a qualitative evaluation of the results of automatically adding extracted MWEs to existing linguistic resources .We argue that such a process improves qualitatively , if a more compositional approach to grammar / lexicon automated extension is adopted .","label":"Future","metadata":{},"score":"35.09507"}
{"text":"Based on an extension to Harris 's distributional hypothesis , we use selectional preferences to gather evidence of inference directionality and plausibility .Experiments show empirical evidence that our approach can classify inference rules significantly better than several baselines .This paper assesses the role of multi - label classification in modelling polysemy for language acquisition tasks .","label":"Future","metadata":{},"score":"35.256985"}
{"text":".. hts from an ensemble of related prediction tasks .The metapriors can be transferred among different tasks .Jebara [ 43 ] proposed to select features for multitask learning with SVMs .3.2.2 Unsupervised Feature Construction In [ 22 ] , Raina et al .","label":"Future","metadata":{},"score":"35.264675"}
{"text":"We present and evaluate here several methods that integrate LSA - based information with a standard language model : a semantic cache , partial reranking , and different forms of interpolation .We found that all methods show significant improvements , compared to the 4-gram baseline , and most of them to a simple cache model as well .","label":"Future","metadata":{},"score":"35.476906"}
{"text":"In this paper , we describe a two - stage multilingual dependency parser used for the multilingual track of the CoNLL 2007 shared task .The system consists of two components : an unlabeled dependency parser using Gibbs sampling which can incorporate sentence - level ( global ) features as well as token - level ( local ) features , and a dependency relation labeling module based on Support Vector Machines .","label":"Future","metadata":{},"score":"35.522087"}
{"text":"Significant improvement over the previous results in the literature is reported as well as a new benchmark dataset is introduced .Semi - supervised algorithms perform better than their supervised version by a wide margin especially when the amount of labeled data is limited .","label":"Future","metadata":{},"score":"35.588184"}
{"text":"This paper describes a corpus - based study of plural descriptions , and proposes a psycholinguistically - motivated algorithm for plural reference generation .The descriptive strategy is based on partitioning , and incorporates corpus - derived heuristics .An exhaustive evaluation shows that the output closely matches human data .","label":"Future","metadata":{},"score":"35.663624"}
{"text":"We analyze the effect of resampling techniques , including under - sampling and over - sampling used in active learning .Experimental results show that under - sampling causes negative effects on active learning , but over - sampling is a relatively good choice .","label":"Future","metadata":{},"score":"35.717056"}
{"text":"In this paper we propose a simplification - translation - restoration ( STR ) framework for domain adaptation in SMT by simplifying domain sp ... \" .Integration of domain specific knowledge into a general purpose statistical machine translation ( SMT ) system poses challenges due to insufficient bilingual corpora .","label":"Future","metadata":{},"score":"35.78395"}
{"text":"Neural Information Processing Systems , pp .25 - 32 , 2008 .[42 ] S.I. Lee , V. Chatalbashev , D. Vickrey , and D. Koller , \" Learning a Meta - Level Prior for Feature Relevance from Multiple Related Tasks , \" Proc . 24th Int'l Conf .","label":"Future","metadata":{},"score":"35.78642"}
{"text":"This paper presents a novel unsupervised support vector machine ( U - SVM ) classifier for answer selection , which is independent of language and does not require hand - tagged training pairs .The key ideas are the following : 1 . unsupervised learning of training data for the classifier by clustering web search results ; and 2 . selecting the answer from the candidates by classifying the question .","label":"Future","metadata":{},"score":"35.806652"}
{"text":"1108 - 1113 , July 2007 .[ 77 ] V.W. Zheng , Q. Yang , W. Xiang , and D. Shen , \" Transferring Localization Models over Time , \" Proc . 23rdAssoc .for the Advancement of Artificial Intelligence ( AAAI ) Conf .","label":"Future","metadata":{},"score":"36.141743"}
{"text":"We evaluate the proposed algorithms on the 2007 CONLL Shared Task , and report errors analysis .Experimental results show that the system score is better than the average score among the participating systems .In the paper we describe a dependency parser that uses exact search and global learning ( Crammer et al . , 2006 ) to produce labelled dependency trees .","label":"Future","metadata":{},"score":"36.20344"}
{"text":"The second approach combines unsupervised hidden markov modelling with language models .Empirical evaluation of both systems pointed out that the hidden markov model managed best to learn the task of segmenting and labelling biological field book entries from a derived database only .","label":"Future","metadata":{},"score":"36.20617"}
{"text":"[ 4 ] K.M. Borgwardt , A. Gretton , M.J. Rasch , H.-P. Kriegel , B. Schölkopf , and A.J. Smola , \" Integrating Structured Biological Data by Kernel Maximum Mean Discrepancy , \" Bioinformatics , vol .22 , no .","label":"Future","metadata":{},"score":"36.52945"}
{"text":"The increasing use of large open - domain document sources is exacerbating the problem of ambiguity in named entities .This paper explores the use of a range of syntactic and semantic features in unsupervised clustering of documents that result from ad hoc queries containing names .","label":"Future","metadata":{},"score":"36.576885"}
{"text":"608 - 614 , July 2007 .[51 ] L. Mihalkova and R.J. Mooney , \" Transfer Learning by Mapping with Minimal Target Data , \" Proc .Assoc .for the Advancement of Artificial Intelligence ( AAAI ' 08 )","label":"Future","metadata":{},"score":"36.723907"}
{"text":"Moreover , KL - divergence is used to decide the trade - off parameters in our algorithm .In the experiment , our algorithm outperforms the traditional supervised and semi - supervised learning algorithms when the distributions of the training and test sets are increasingly different . by Jing Gao , Wei Fan , Jing Jiang , Jiawei Han - In International Conference on Knowledge Discovery and Data Mining , Las Vegas , NV , 2008 . \" ...","label":"Future","metadata":{},"score":"36.775715"}
{"text":"Computational Linguistics , 19 ( 2 ) , 313 - 330 .Marx , Z. , Rosenstein , M. T. , Dietterich , T. G. , & Kaelbling , L. P. ( 2008 ) .Two algorithms for transfer learning .In Inductive transfer : 10 years later .","label":"Future","metadata":{},"score":"36.791817"}
{"text":"This allows the use of a much wider range of parallel corpora for training , and can be combined with a standard phrase - table using conventional smoothing methods .Experimental results demonstrate BLEU improvements for triangulated models over a standard phrase - based system .","label":"Future","metadata":{},"score":"36.807648"}
{"text":"We introduce a general framework for answer extraction which exploits semantic role annotations in the FrameNet paradigm .We view semantic role assignment as an optimization problem in a bipartite graph and answer extraction as an instance of graph matching .Experimental results on the TREC datasets demonstrate improvements over state - of - the - art models .","label":"Future","metadata":{},"score":"36.851486"}
{"text":"Key enablers of this high performance are features derived from previous natural language processing work in noun compound bracketing .For example , token association features beyond simple N - gram counts provide powerful indicators of segmentation .We present two machine learning approaches to information extraction from semi - structured documents that can be used if no annotated training data are available , but there does exist a database filled with information derived from the type of documents to be processed .","label":"Future","metadata":{},"score":"36.855595"}
{"text":"Cross - domain learning , domain adaptation , transfer learning , support vector machine , multiple kernel learning .CITATION .Lixin Duan , Ivor W. Tsang , Dong Xu , \" Domain Transfer Multiple Kernel Learning \" , IEEE Transactions on Pattern Analysis & Machine Intelligence , vol.34 , no . 3 , pp .","label":"Future","metadata":{},"score":"37.002987"}
{"text":"For our models and training sets , more peaked measures of confidence , measured by Renyi entropy , outperformed smoother ones .We discuss how our feature set could be extended with cross - lingual or cross - domain features , to incorporate knowledge from parallel or comparable corpora during bootstrapping .","label":"Future","metadata":{},"score":"37.104954"}
{"text":"Our results provide the first known empirical evidence that lexical semantics are indeed useful for SMT , despite claims to the contrary .This paper presents a tree - to - tree transduction method for text rewriting .Our model is based on synchronous tree substitution grammar , a formalism that allows local distortion of the tree topology and can thus naturally capture structural mismatches .","label":"Future","metadata":{},"score":"37.237762"}
{"text":"We also compare the translation accuracy for all variations .We achieved a state of the art performance in statistical machine translation by using a large number of features with an online large - margin training algorithm .The millions of parameters were tuned only on a small development set consisting of less than 1 K sentences .","label":"Future","metadata":{},"score":"37.243874"}
{"text":"We expect that our method could be further improved via well - tuned parameter validations for different languages .Tools . \" ...A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution .","label":"Future","metadata":{},"score":"37.37806"}
{"text":"In this paper , a novel method is proposed for use of web search results to improve the existing query spelling correction models solely based on query logs by leveraging the rich information on the web related to the query and its top - ranked candidate .","label":"Future","metadata":{},"score":"37.437176"}
{"text":"We achieve average results , which is partly due to difficulties in mapping to the dependency representation used for the shared task .Following ( Blitzer et al . , 2006 ) , we present an application of structural correspondence learning to non - projective dependency parsing ( McDonald et al . , 2005 ) .","label":"Future","metadata":{},"score":"37.62949"}
{"text":"We present a new generative alignment model which avoids these structural limitations , and show that it is effective when trained using both unsupervised and semi - supervised training methods .Experiments show strong improvements in word alignment accuracy and usage of the generated alignments in hierarchical and phrasal SMT systems increases the BLEU score .","label":"Future","metadata":{},"score":"37.69451"}
{"text":"This paper focuses on the domain estimation problem in statistical machine translations .In the proposed method , a training corpus , which is a bilingual corpus , is automatically clustered to sub - corpuses .Each sub - corpus is regarded as a domain .","label":"Future","metadata":{},"score":"37.820404"}
{"text":"Our best result , 91.44 % accuracy , reflects a 25 % reduction in error rate compared with the previous state of the art .We present a new approach to automatic summarization based on neural nets , called NetSum .We extract a set of features from each sentence that helps identify its importance in the document .","label":"Future","metadata":{},"score":"37.91758"}
{"text":"Keywords .Online learning Domain adaptation Classifier combination Transfer learning Multi - task learning .Editors : Nicolo Cesa - Bianchi , David R. Hardoon , and Gayle Leen .Preliminary versions of the work contained in this article appeared in the proceedings of the conference on Empirical Methods in Natural Language Processing ( Dredze and Crammer 2008 ) .","label":"Future","metadata":{},"score":"38.05105"}
{"text":"We present a method for improving word alignment for statistical syntax - based machine translation that employs a syntactically informed alignment model closer to the translation model than commonly - used word alignment models .This leads to extraction of more useful linguistic patterns and improved BLEU scores on translation experiments in Chinese and Arabic .","label":"Future","metadata":{},"score":"38.087547"}
{"text":"This modularity allows one to incorporate out - of - domain data without the need to modify existing training algorithms .We show how ideas in sequential Bayesian methods can be naturally applied to the word alignment problem and demonstrate various positive results on EMEA and NIST datasets . ... large monolingual corpora ( Marton et al .","label":"Future","metadata":{},"score":"38.09777"}
{"text":"The need for domain adaptation arises in almost all NLP tasks : part - of - speech tagging , semantic role labeling , statistical parsing and statistical machine translation , to name but a few .The goal of this workshop is to provide a meeting - point for research that approaches the problem of adaptation from the varied perspectives of machine - learning and a variety of NLP tasks such as parsing , machine - translation , word sense disambiguation , etc .","label":"Future","metadata":{},"score":"38.105682"}
{"text":"In addition , we utilize the RankBoost - based reranking algorithm to rerank the N - best outputs of the HMM - based tagger using various $ n$-gram , morphological , and dependency features .Two methods are proposed to improve the generalization performance of the reranking algorithm .","label":"Future","metadata":{},"score":"38.14287"}
{"text":"489 - 496 , July 2007 .[49 ] J. Gao , W. Fan , J. Jiang , and J. Han , \" Knowledge Transfer via Multiple Model Local Structure Mapping , \" Proc . 14th ACM SIGKDD Int'l Conf .","label":"Future","metadata":{},"score":"38.156055"}
{"text":"We present a comparative error analysis of the two dominant approaches in data - driven dependency parsing : global , exhaustive , graph - based models , and local , greedy , transition - based models .We show that , in spite of similar performance overall , the two models produce different types of errors , in a way that can be explained by theoretical properties of the two models .","label":"Future","metadata":{},"score":"38.23671"}
{"text":"In this study we show that analogical learning offers as well an elegant and effective solution to the problem of identifying potential translations of unknown words .We present a probabilistic model of diachronic phonology in which individual word forms undergo stochastic edits along the branches of a phylogenetic tree .","label":"Future","metadata":{},"score":"38.247063"}
{"text":"In this paper , we propose an alternative estimator of the generalization error for the squared loss function when training and test distributions are different .The proposed generalization error estimator is shown to be exactly unbiased for finite samples if the learning target function is realizable and asymptotically unbiased in general .","label":"Future","metadata":{},"score":"38.252415"}
{"text":"We believe that the key to future success will be to exploit large collections of unlabeled data in addition to labeled data .Not only because unlabeled data is easier to obtain , but existing labeled resources are often not even close to the envisioned target application domain .","label":"Future","metadata":{},"score":"38.25645"}
{"text":"This method not only models the relationships between tasks explicitly , but also gives an algorithm for the informed use of several source tasks in transfer learning .They learn a meta - kernel that serves as a similarity function between tasks .","label":"Future","metadata":{},"score":"38.32074"}
{"text":"Experimental results show that , by training different specific language models weighted according to the actual input instead of using a single target language model , significant gains in terms of perplexity and BLEU can be achieved .A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution .","label":"Future","metadata":{},"score":"38.324078"}
{"text":"We apply the proposed approach to enhance opinion sum - marization in a two - stage framework .Experimental results show that the proposed approach effectively ( 1 ) discriminates low - quality reviews from high - quality ones and ( 2 ) enhances the task of opinion summarization by detecting and filtering low - quality reviews .","label":"Future","metadata":{},"score":"38.377235"}
{"text":"Self - training for biomedical parsing .In Association for computational linguistics ( ACL ) .Obozinski , G. , Taskar , B. , & Jordan , M. ( 2006 ) .Multi - task feature selection .In ICML-06 workshop on structural knowledge transfer for machine learning .","label":"Future","metadata":{},"score":"38.400772"}
{"text":"In Conference on information and knowledge management ( CIKM ) .Kittler , J. , Hatef , M. , Duin , R. , & Matas , J. ( 1998 ) .On combining classifiers .IEEE Transactions on Pattern Analysis and Machine Intelligence , 20 ( 3 ) , 226 - 239 .","label":"Future","metadata":{},"score":"38.501858"}
{"text":"Our error analysis for this task suggests that the primary source of error are differences in annotation guidelines among treebanks .Our suspicions are supported by the observation that no team was able to improve target domain performance substantially over a state of the art baseline .","label":"Future","metadata":{},"score":"38.57514"}
{"text":"It is well - known that domain specific language models perform well in automatic speech recognition .Domain specific language and translation models in statistical machine translations perform well .However , there are two problems with using domain specific models .","label":"Future","metadata":{},"score":"38.916138"}
{"text":"This paper focuses on the problem of language model adapta - tion in the context of Chinese - English cross - lingual dialogs , as set - up by the challenge task of the IWSLT 2009 Evalu - ation Campaign .Mixtures of n - gram language models are investigated , which are obtained by clustering bilingual train - ing d ... \" .","label":"Future","metadata":{},"score":"38.94221"}
{"text":"[ 30 ] J. Sun , X. Wu , S. Yan , L.-F. Cheong , T.-S. Chua , and J. Li , \" Hierarchical Spatio - Temporal Context Modeling for Action Recognition , \" Proc .IEEE Int'l Conf .Computer Vision and Pattern Recognition , pp .","label":"Future","metadata":{},"score":"39.035194"}
{"text":"We present experimental results from the CoNLL 2003 named entity recognition ( NER ) task to demonstrate the performance of the proposed algorithm .In this paper , we address a unique problem in Chinese language processing and report on our study on extending a Chinese thesaurus with region - specific words , mostly from the financial domain , from various Chinese speech communities .","label":"Future","metadata":{},"score":"39.180008"}
{"text":"We present an information extraction system that decouples the tasks of finding relevant regions of text and applying extraction patterns .We create a self - trained relevant sentence classifier to identify relevant regions , and use a semantic affinity measure to automatically learn domain - relevant extraction patterns .","label":"Future","metadata":{},"score":"39.21746"}
{"text":"Current phrase - based SMT systems perform poorly when using small training sets .This is a consequence of unreliable translation estimates and low coverage over source and target phrases .This paper presents a method which alleviates this problem by exploiting multiple translations of the same source phrase .","label":"Future","metadata":{},"score":"39.249832"}
{"text":"283 - 291 , Aug. 2008 .[50 ] L. Mihalkova , T. Huynh , and R.J. Mooney , \" Mapping and Revising Markov Logic Networks for Transfer Learning , \" Proc . 22ndAssoc .for the Advancement of Artificial Intelligence ( AAAI ) Conf .","label":"Future","metadata":{},"score":"39.284954"}
{"text":"Neural Information Processing Systems , pp .985 - 992 , 2008 .[ 69 ] E. Eaton , M. desJardins , and T. Lane , \" Modeling Transfer Relationships between Learning Tasks for Improved Inductive Transfer , \" Proc .European Conf .","label":"Future","metadata":{},"score":"39.341965"}
{"text":"We also point out the high variance in all of these estimators , and that they require many more iterations to approach convergence than usually thought .This paper describes a probabilistic model for coordination disambiguation integrated into syntactic and case structure analysis .","label":"Future","metadata":{},"score":"39.355362"}
{"text":"We describe our submission to the domain adaptation track of the CoNLL07 shared task in the open class for systems using external resources .Our main finding was that it was very difficult to map from the annotation scheme used to prepare training and development data to one that could be used to effectively train and adapt the RASP system unlexicalised parse ranking model .","label":"Future","metadata":{},"score":"39.37728"}
{"text":"For example , we sometimes have a classification task i ... \" .A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution .","label":"Future","metadata":{},"score":"39.38058"}
{"text":"Evgeniou , T. , & Pontil , M. ( 2004 ) .Regularized multi - task learning .In Conference on knowledge discovery and data mining ( KDD ) .Florian , R. , Ittycheriah , A. , Jing , H. , & Zhang , T. ( 2003 ) .","label":"Future","metadata":{},"score":"39.433945"}
{"text":"A notable gap in research on statistical dependency parsing is a proper conditional probability distribution over nonprojective dependency trees for a given sentence .We exploit the Matrix Tree Theorem ( Tutte , 1984 ) to derive an algorithm that efficiently sums the scores of all nonprojective trees in a sentence , permitting the definition of a conditional log - linear model over trees .","label":"Future","metadata":{},"score":"39.517418"}
{"text":"The proposed method autonomously chooses from where and how much to transfer information by solving a convex optimization problem which ensures to have the minimal leave - one - out error on the available training set .We analyze several properties of the described approach and perform an extensive experimental comparison with other existing transfer solutions , consistently showing the value of our algorithm .","label":"Future","metadata":{},"score":"39.560715"}
{"text":"We present experiments with a dependency parsing model defined on rich factors .Our model represents dependency trees with factors that include three types of relations between the tokens of a dependency and their children .We extend the projective parsing algorithm of Eisner ( 1996 ) for our case , and train models using the averaged perceptron .","label":"Future","metadata":{},"score":"39.592644"}
{"text":"14 , no . 1 , pp . 1 - 37 , 2008 .[ 4 ] H. Al Mubaid and S.A. Umair , \" A New Text Categorization Technique Using Distributional Clustering and Learning Logic , \" IEEE Trans .Knowledge and Data Eng . , vol .","label":"Future","metadata":{},"score":"39.636894"}
{"text":"1156 - 1165 , Sept. 2006 .[5 ] K. Sarinnapakorn and M. Kubat , \" Combining Subclassifiers in Text Categorization : A DST - Based Solution and a Case Study , \" IEEE Trans .Knowledge and Data Eng . , vol .","label":"Future","metadata":{},"score":"39.648743"}
{"text":"In addition , we present work on experiments with named entities and other multi - word units , showing a statistically significant improvement of generation accuracy .Given multiple translations of the same source sentence , how to combine them to produce a translation that is better than any single system output ?","label":"Future","metadata":{},"score":"39.745678"}
{"text":"However , the assumption made by existing approaches , that the marginal and conditional probabilities are directly related between sou ... \" .When labeled examples are limited and difficult to obtain , transfer learning employs knowledge from a source domain to improve learning accuracy in the target domain .","label":"Future","metadata":{},"score":"39.849457"}
{"text":"We describe an approach to improve Statistical Machine Translation ( SMT ) performance using multi - lingual , parallel , sentence - aligned corpora in several bridge languages .Our approach consists of a simple method for utilizing a bridge language to create a word alignment system and a procedure for combining word alignment systems from multiple bridge languages .","label":"Future","metadata":{},"score":"39.8671"}
{"text":"We can not use non - local features due to concerns about complexity with current major methods of sequence labeling such as CRFs .We propose a new perceptron algorithm that can use non - local features .Our algorithm allows the use of all types of non - local features whose values are determined from the sequence and the labels .","label":"Future","metadata":{},"score":"39.937656"}
{"text":"This framework integrates multiple MT systems ' output at the word- , phrase- and sentence- levels .By boosting common word and phrase translation pairs , pruning unused phrases , and exploring decoding paths adopted by other MT systems , this framework achieves better translation quality with much less re - decoding time .","label":"Future","metadata":{},"score":"39.949627"}
{"text":"[ 73 ] A. Argyriou , A. Maurer , and M. Pontil , \" An Algorithm for Transfer Learning in a Heterogeneous Environment , \" Proc .European Conf .Machine Learning and Knowledge Discovery in Databases ( ECML / PKDD ' 08 ) , pp .","label":"Future","metadata":{},"score":"40.000557"}
{"text":"Our model is inspired by theories of local coherence and formulated within the framework of Integer Linear Programming .Experimental results show significant improvements over a state - of - the - art discourse agnostic approach .Shallow semantic parsing , the automatic identification and labeling of sentential constituents , has recently received much attention .","label":"Future","metadata":{},"score":"40.006172"}
{"text":"1421 - 1426 , July 2008 .[ 78 ] S.J. Pan , D. Shen , Q. Yang , and J.T. Kwok , \" Transferring Localization Models across Space , \" Proc . 23rdAssoc .for the Advancement of Artificial Intelligence ( AAAI ) Conf .","label":"Future","metadata":{},"score":"40.047226"}
{"text":"It surveys current research in this area , giving an overview of the state of the art and outlining the open problems .The survey covers transfer in both inductive learning and reinforcement learning , and discusses the issues of negative transfer and task mapping in depth . .","label":"Future","metadata":{},"score":"40.063164"}
{"text":"We integrate these probabilities into the framework of fully - lexicalized parsing based on large - scale case frames .This approach simultaneously addresses two tasks of coordination disambiguation : the detection of coordinate conjunctions and the scope disambiguation of coordinate structures .","label":"Future","metadata":{},"score":"40.109436"}
{"text":"Deterministic parsing has emerged as an effective alternative for complex parsing algorithms which search the entire search space to get the best probable parse tree .In this paper , we present an online large margin based training framework for deterministic parsing using Nivre 's Shift - Reduce parsing algorithm .","label":"Future","metadata":{},"score":"40.189095"}
{"text":"We present results that show that incorporating lexical and structural semantic information is effective for word sense disambiguation .We evaluated the method by using precise information from a large treebank and an ontology automatically created from dictionary sentences .Exploiting these information improves precision 2 - 3 % , especially 5.7 % for verb , over a model using only bag of words and n - gram features .","label":"Future","metadata":{},"score":"40.19648"}
{"text":"17 ] Y.-G. Jiang , J. Wang , S.-F. Chang , and C.-W. Ngo , \" Domain Adaptive Semantic Diffusion for Large Scale Context - Based Video Annotation , \" Proc .IEEE Int'l Conf .Computer Vision , pp .1420 - 1427 , 2009 .","label":"Future","metadata":{},"score":"40.245293"}
{"text":"Machine - learning techniques are based on the assumption that training and test data are driven from the same probability distribution , and , therefore , they perform much better when training and test data sets are alike .Background Domain similarity Preliminary experiments Domain complexity Modeling accuracy loss for cross - domain SC Model construction and validation Graph - based algorithmsHow to compare data sets ?","label":"Future","metadata":{},"score":"40.25855"}
{"text":"The construction of such scheme is motivated by the problem of predict ... \" .In this paper we present a new scheme of a kernel - based regularization learning algorithm , in which the kernel and the regularization parameter are adaptively chosen on the base of previous experience with similar learning tasks .","label":"Future","metadata":{},"score":"40.295174"}
{"text":"Woods , K. , Kegelmeyer , W. P. Jr. , & Bowyer , K. ( 1997 ) .Combination of multiple classifiers using local accuracy estimates .IEEE Transactions on Pattern Analysis and Machine Intelligence , 19 ( 4 ) , 405 - 410 .","label":"Future","metadata":{},"score":"40.411297"}
{"text":"We show empirical results in which a small amount of adaptation data is able to improve both the non - adapted system and a system which optimises the abovementioned weights on the adaptation set only , while gaining both in reliability and speed . by Germán Sanchis - trilles , Mauro Cettolo , Nicola Bertoldi , Marcello Federico . \" ...","label":"Future","metadata":{},"score":"40.43226"}
{"text":"We treat the graph as a Markov chain and compute a word - specific stationary distribution via a generalized PageRank algorithm .Semantic relatedness of a word pair is scored by a novel divergence measure , ZKL , that outperforms existing measures on certain classes of distributions .","label":"Future","metadata":{},"score":"40.472507"}
{"text":"1383 - 1388 , July 2008 .[79 ] V.W. Zheng , S.J. Pan , Q. Yang , and J.J. Pan , \" Transferring Multi - Device Localization Models Using Latent Multi - Task Learning , \" Proc . 23rdAssoc .","label":"Future","metadata":{},"score":"40.473934"}
{"text":"We present the idea of estimating semantic distance in one , possibly resource - poor , language using a knowledge source in another , possibly resource - rich , language .We do so by creating cross - lingual distributional profiles of concepts , using a bilingual lexicon and a bootstrapping algorithm , but without the use of any sense - annotated data or word - aligned corpora .","label":"Future","metadata":{},"score":"40.50135"}
{"text":"Rather than using syntactic features to augment existing statistical classifiers ( as in previous work ) , we build on the idea that questions and their ( correct ) answers relate to each other via loose but predictable syntactic transformations .We propose a probabilistic quasi - synchronous grammar , inspired by one proposed for machine translation ( D. Smith and Eisner , 2006 ) , and parameterized by mixtures of a robust non - lexical syntax / alignment model with a(n optional ) lexical - semantics - driven log - linear model .","label":"Future","metadata":{},"score":"40.60933"}
{"text":"For example , we sometimes have a classification task in one domain of interest , but we only have sufficient training data in another domain of interest , where the latter data may be in a different feature space or follow a different data distribution .","label":"Future","metadata":{},"score":"40.621574"}
{"text":"For example , we sometimes have a classification task in one domain of interest , but we only have sufficient training data in another domain of interest , where the latter data may be in a different feature space or follow a different data distribution .","label":"Future","metadata":{},"score":"40.621574"}
{"text":"[34 ] D. Xu and S.-F. Chang , \" Video Event Recognition Using Kernel Methods with Multilevel Temporal Alignment , \" IEEE Trans .Pattern Analysis and Machine Intelligence , vol .30 , no .11 , pp .1985 - 1997 , Nov. 2008 .","label":"Future","metadata":{},"score":"40.69535"}
{"text":"Machine Learning ( ECML ' 07 ) , pp .699 - 707 , 2007 .[ 11 ] X. Yin , J. Han , J. Yang , and P.S. Yu , \" Efficient Classification across Multiple Database Relations : A Crossmine Approach , \" IEEE Trans .","label":"Future","metadata":{},"score":"40.796005"}
{"text":"In this study , we present a system that generates lexical analogies automatically from text data .Our system discovers semantically related pairs of words by using dependency relations , and applies novel machine learning algorithms to match these word - pairs to form lexical analogies .","label":"Future","metadata":{},"score":"40.855713"}
{"text":"The online method adapts the translation model by redistributing the weight of each predefined submodels .Information retrieval model is used for the weighting scheme in both methods .Experimental results show that without using any additional resource , both methods can improve SMT performance significantly .","label":"Future","metadata":{},"score":"40.9657"}
{"text":"Furthermore , we explore the performance of information drawn from different levels of linguistic description , using feature sets based on morphology , syntax , semantics , and n -gram distribution .Finally , we demonstrate that ensemble classifiers are a powerful and adequate way to combine different types of linguistic evidence : a simple , majority voting ensemble classifier improves the accuracy from 62.5 % ( best single classifier ) to 84 % .","label":"Future","metadata":{},"score":"40.984856"}
{"text":"We consider alternatives for extending our recommendation technique to sets of classifiers , including a modification to the AdaBoost algorithm that incorporates recommendation .Evaluating on an action recognition problem , we present two viable methods for extending model recommendation to sets . ... and is loosely related to multi - task learning .","label":"Future","metadata":{},"score":"41.04326"}
{"text":"In particular , it is important to see if the classification could accommodate new words from heterogeneous data sources , and whether simple similarity measures and clustering methods could cope with such variation .We use the cosine function for similarity and test it on automatically classifying 120 target words from four regions , using different datasets for the extraction of feature vectors .","label":"Future","metadata":{},"score":"41.106056"}
{"text":"Standard thesaurus - based measures of word pair similarity are based on only a single path between those words in the thesaurus graph .By contrast , we propose a new model of lexical semantic relatedness that incorporates information from every explicit or implicit path connecting the two words in the entire graph .","label":"Future","metadata":{},"score":"41.10637"}
{"text":"The last condition makes the OPTIM solution more stable .What about the measure of similarity between graph nodes ?Background Comparison Preliminary experiments Document similarity Modeling accuracy loss for cross - domain SC Strategy for choosing the best parameters Graph - based algorithmsDocument representation We consider 2 types of document representation : feature - based , that involves weighted document features .","label":"Future","metadata":{},"score":"41.197678"}
{"text":"To solve this problem , we propose an adaptive kernel approach that maps the marginal distribution of targetdomain and source - domain data into a common kernel space , and utilize a sample selection strategy to draw conditional probabilities between the two domains closer .","label":"Future","metadata":{},"score":"41.21851"}
{"text":"We show how partition functions and marginals for directed spanning trees can be computed by an adaptation of Kirchhoff 's Matrix - Tree Theorem .To demonstrate an application of the method , we perform experiments which use the algorithm in training both log - linear and max - margin dependency parsers .","label":"Future","metadata":{},"score":"41.22141"}
{"text":"4 ) Scoring : Adaptation in the scoring step is the most direct way to improve results since it is the step closest to the final translation model .In fact , one could argue that ... .by Germán Sanchis - trilles , Francisco Casacuberta , Informáticos Computación . \" ...","label":"Future","metadata":{},"score":"41.364754"}
{"text":"Finally , it shows that feature - based and tree kernel - based methods much complement each other and the composite kernel can well integrate both flat and structured features .Syntactic reordering approaches are an effective method for handling word - order differences between source and target languages in statistical machine translation ( SMT ) systems .","label":"Future","metadata":{},"score":"41.67519"}
{"text":"We test this hypothesis on action recognition , and find that even when every model has been directly rated on a training set , recommendation finds better selections for the corresponding test set than the best performers on the training set .","label":"Future","metadata":{},"score":"41.75963"}
{"text":"Using the WordNet hierarchy , we embed the construction of Abney and Light in the topic model and show that automatically learned domains improve WSD accuracy compared to alternative contexts .This paper focuses on the evaluation of methods for the automatic acquisition of Multiword Expressions ( MWEs ) for robust grammar engineering .","label":"Future","metadata":{},"score":"41.85278"}
{"text":"Unsupervised clustering is guided by either the development or the test set .Different mixture weight estimation schemes are proposed and compared , at the level of either single or all source sentences .Experimental results show that , by training different specific language models weighted according to the actual input instead of using a single target language model , translation quality is improved , as measured by BLEU and TER . \" ...","label":"Future","metadata":{},"score":"41.86872"}
{"text":"In Uncertainty in artificial intelligence ( UAI ) .Daumé , H. , & Marcu , D. ( 2006 ) .Domain adaptation for statistical classifiers .Journal of Artificial Intelligence Research ( JAIR ) , 26 , 101 - 126 .","label":"Future","metadata":{},"score":"41.8692"}
{"text":"In several real - world applications collecting many annotated data is costly and not always possible .However a small training set does not allow to cover the high intraclass variability typical of visual objects .In this condition , machine learning methods provide very few guarantees .","label":"Future","metadata":{},"score":"41.8809"}
{"text":"The experiments focus on Chinese - English and two domain - specific corpora .The paper presents a novel approach for combining multiple domain - trained translation models to achieve improved translation quality for both domain - specific as well as combined sets of sentences .","label":"Future","metadata":{},"score":"41.902782"}
{"text":"We briefly describe each model , highlighting points where they differ .We include a quantitative comparison of the phrase pairs that each model has to work with , as well as the reasons why some phrase pairs are not learned by the syntax - based model .","label":"Future","metadata":{},"score":"41.919296"}
{"text":"We find that the use of a decision tree improves on the basic approach only for the deep parser - based approach .We also show that combining both the shallow and deep decision tree features is effective .Our evaluation is carried out using a large test set of grammatical and ungrammatical sentences .","label":"Future","metadata":{},"score":"41.92828"}
{"text":"Experimental results are presented for composite translations computed from large numbers of different research systems as well as a set of translation systems derived from one of the best - ranked machine translation engines in the 2006 NIST machine translation evaluation .","label":"Future","metadata":{},"score":"42.03147"}
{"text":"We show that the proposed model performs at least as well as an approach based on statistical machine translation on two problems of name transliteration , and provide evidence that the combination of the two approaches promises further improvement .In this paper we propose an instance based method for lexical entailment and apply it to automatic ontology population from text .","label":"Future","metadata":{},"score":"42.16762"}
{"text":"In Association for computational linguistics ( ACL ) .Caruana , R. ( 1997 ) .Multitask learning .Machine Learning , 28 , 41 - 75 .CrossRef .Chan , Y. S. , & Ng , H. T. ( 2006 ) .","label":"Future","metadata":{},"score":"42.172615"}
{"text":"In this paper , we try to address this gap and explore the problem of book summarization .We introduce a new data set specifically designed for the evaluation of systems for book summarization , and describe summarization techniques that explicitly account for the length of the documents .","label":"Future","metadata":{},"score":"42.372314"}
{"text":"We propose two characteristics to model accuracy loss : domain similarity and domain complexity or , more precisely , domain complexity variance .Domain similarity approximate similarity between distributions for frequent features .Background Domain similarity Preliminary experiments Domain complexity Modeling accuracy loss for cross - domain SC Model construction and validation Graph - based algorithmsHow to compare data sets ?","label":"Future","metadata":{},"score":"42.49679"}
{"text":"In this paper , we define the tasks of the different tracks and describe how the data sets were created from existing treebanks for ten languages .In addition , we characterize the different approaches of the participating systems , report the test results , and provide a first analysis of these results .","label":"Future","metadata":{},"score":"42.533897"}
{"text":"We propose two characteristics to model accuracy loss : domain similarity and domain complexity or , more precisely , domain complexity variance .Background Domain similarity Preliminary experiments Domain complexity Modeling accuracy loss for cross - domain SC Model construction and validation Graph - based algorithmsHow to compare data sets ?","label":"Future","metadata":{},"score":"42.547203"}
{"text":"for the Advancement of Artificial Intelligence ( AAAI ) Conf .Artificial Intelligence , pp .540 - 545 , July 2007 .[34 ] M. Sugiyama , S. Nakajima , H. Kashima , P.V. Buenau , and M. Kawanabe , \" Direct Importance Estimation with Model Selection and its Application to Covariate Shift Adaptation , \" Proc . 20th Ann .","label":"Future","metadata":{},"score":"42.641846"}
{"text":"The paper reports a hybridization experiment , where an existing ML dependency parser ( LingPars ) , was allowed access to Constraint Grammar analyses provided by a rule - based parser ( EngGram ) for the same data .Descriptive compatibility issues and their influence on performance are discussed , such as tokenization problems , category bundling and dependency head conventions .","label":"Future","metadata":{},"score":"42.667454"}
{"text":"We also address the issue whether a corpus annotated by means of AL -- using a particular classifier and a particular feature set -- can be re - used to train classifiers different from the ones employed by AL , supplying alternative feature sets as well .","label":"Future","metadata":{},"score":"42.743496"}
{"text":"One line of research focuses on the amount of evidence that infants need to generalize principles that are either found or not found among human languages .The other line focuses on how infants generalize from input that has at least two possible structural descriptions .","label":"Future","metadata":{},"score":"42.75615"}
{"text":"Experimental results using the TREC dataset are shown to significantly outperform strong state - of - the - art baselines .Previous machine learning techniques for answer selection in question answering ( QA ) have required question - answer training pairs .","label":"Future","metadata":{},"score":"42.879795"}
{"text":"Improvements of up to 0.5 BLEU were observed with respect to a very competitive baseline trained on more than 280 M words of human translated parallel data . ...l texts , to filter them and to add them to the translation model training data .","label":"Future","metadata":{},"score":"42.884518"}
{"text":"Mixtures of n - gram language models are investigated , which are obtained by clustering bilingual training data ... \" .This paper focuses on the problem of language model adaptation in the context of Chinese - English cross - lingual dialogs , as set - up by the challenge task of the IWSLT 2009 Evaluation Campaign .","label":"Future","metadata":{},"score":"42.898117"}
{"text":"We demonstrate significant gains using features derived from a dependency parse representation over those derived from a constituency - based tree parse .By also capturing inter - argument dependencies using a log - linear re - ranking model we achieve very promising results on this difficult task identifying both arguments correctly for over 74 % of the connectives on held - out test data using gold - standard parses .","label":"Future","metadata":{},"score":"42.90447"}
{"text":"I. . ... andard word alignment and translation models described in Section IV - A1 .The system also used two large language models , both trained on the same data : a 4-gram language model using modified Kneser - Ney smoothing , and a suffix array language model with arbitrary history l .. \" ...","label":"Future","metadata":{},"score":"42.95797"}
{"text":"Current phrase - based SMT technologies are good at capturing local reordering but not global reordering .This paper introduces syntactic knowledge to improve global reordering capability of SMT system .Syntactic knowledge such as boundary words , POS information and dependencies is used to guide phrase reordering .","label":"Future","metadata":{},"score":"42.972687"}
{"text":"Three different classifiers are trained to predict weighted soft - constraints on parts of the complex output .From these constraints , a standard weighted constraint satisfaction problem can be formed , the solution to which is a valid dependency tree .","label":"Future","metadata":{},"score":"43.003334"}
{"text":"Transfer learning by distribution matching for targeted advertising .In Advances in neural information processing systems ( pp .145 - 152 ) .Blitzer , J. , McDonald , R. , & Pereira , F. ( 2006 ) .Domain adaptation with structural correspondence learning .","label":"Future","metadata":{},"score":"43.02237"}
{"text":"constraints [ 9].Other work in multi - task learning uses neural network architectures to structurally force all the tasks to share intermediate representations [ 1,6]. byErheng Zhong , Kun Zhang , Jiangtao Ren , Deepak Turaga , Olivier Verscheure . \" ...","label":"Future","metadata":{},"score":"43.04663"}
{"text":".. oposes a locally weighted ensemble framework to combine multiple models for transfer learning by dynamically assigning weights of a model according to a model 's predictive power on each test example .[20 ] improves the effectiveness of unsupervised dimension reduction with the help of related prior knowledge from other cl ... . \" ...","label":"Future","metadata":{},"score":"43.219215"}
{"text":"4.2 Collocation Correction with Phrase - based SMT We implement our approach in the fram ... . \" ...We report on efforts to build large - scale translation systems for eight European language pairs .We achieve most gains from the use of larger training corpora and basic modeling , but also show promising results from integrating more linguistic annotation .","label":"Future","metadata":{},"score":"43.320255"}
{"text":"We describe a set of syntactic reordering rules that exploit systematic differences between Chinese and English word order .The resulting system is used as a preprocessor for both training and test sentences , transforming Chinese sentences to be much closer to English in terms of their word order .","label":"Future","metadata":{},"score":"43.334503"}
{"text":"[ 76 ] S.J. Pan , J.T. Kwok , Q. Yang , and J.J. Pan , \" Adaptive Localization in a Dynamic WiFi Environment through Multi - View Learning , \" Proc . 22ndAssoc .for the Advancement of Artificial Intelligence ( AAAI ) Conf .","label":"Future","metadata":{},"score":"43.374977"}
{"text":"The problem of training classifiers from limited data is one that particularly affects large - scale and social applications , and as a result , although carefully trained machine learning forms the backbone of many current techniques in research , it sees dramatically fewer applications for end - users .","label":"Future","metadata":{},"score":"43.46395"}
{"text":"1022 - 1036 , May 2011 .[20 ] M. Naphade , J.R. Smith , J. Tesic , S.-F. Chang , W. Hsu , L. Kennedy , A. Hauptmann , and J. Curtis , \" Large - Scale Concept Ontology for Multimedia , \" IEEE Multimedia , vol .","label":"Future","metadata":{},"score":"43.62742"}
{"text":"Thus while human judgement is not straightforward and it is difficult to create a Pan - Chinese lexicon manually , it is observed that combining simple clustering methods with the appropriate data sources appears to be a promising approach toward its automatic construction .","label":"Future","metadata":{},"score":"43.692276"}
{"text":"We begin with the context of the current research , and then move to a formal problem description and an overview of the four main subproblems : translational equivalence modeling , mathematical modeling , parameter estimation , and decoding .Along the way , we present a taxonomy of some different approaches within these areas .","label":"Future","metadata":{},"score":"43.69976"}
{"text":"This paper addresses the problem of detecting low - quality product reviews .Three types of biases in the existing evaluation standard of product reviews are discovered .To assess the quality of product reviews , a set of specifications for judging the quality of reviews is first defined .","label":"Future","metadata":{},"score":"43.758083"}
{"text":"Artificial Intelligence , pp .1427 - 1432 , July 2008 .[81 ] V.C. Raykar , B. Krishnapuram , J. Bi , M. Dundar , and R.B. Rao , \" Bayesian Multiple Instance Learning : Automatic Feature Selection and Inductive Transfer , \" Proc .","label":"Future","metadata":{},"score":"43.78031"}
{"text":"These local consistency estimates become weights for the source tasks , and are used in a weighted ensemble to classify the test example .They learn a metakernel that serves as a similarity function between tasks .Given this and a set of kernels that perform well in source tasks , they perf ... . by","label":"Future","metadata":{},"score":"43.794395"}
{"text":"Our approach recovers non - local dependencies at the level of Lexical - Functional Grammar f - structures , using automatically acquired subcategorisation frames and f - structure paths linking antecedents and traces in NLDs .Currently our algorithm achieves 92.2 % f - score for trace insertion and 84.3 % for antecedent recovery evaluating on gold - standard CTB trees , and 64.7 % and 54.7 % , respectively , on CTBtrained state - of - the - art parser output trees .","label":"Future","metadata":{},"score":"43.854126"}
{"text":"Background Domain similarity Preliminary experiments Domain complexity Modeling accuracy loss for cross - domain SC Model construction and validation Graph - based algorithmsHow to compare data sets ?Machine - learning techniques are based on the assumption that training and test data are driven from the same probability distribution , and , therefore , they perform much better when training and test data sets are alike .","label":"Future","metadata":{},"score":"43.861633"}
{"text":"12 , pp .1638 - 1651 , Dec. 2007 .[ 7 ] S.J. Pan , V.W. Zheng , Q. Yang , and D.H. Hu , \" Transfer Learning for WiFi - Based Indoor Localization , \" Proc .Workshop Transfer Learning for Complex Task of the 23rd","label":"Future","metadata":{},"score":"43.882027"}
{"text":"Recent work from our lab suggests that infants not only keep close track of statistical properties of their input , but they use their statistical sensitivity to select among hypotheses about the underlying structures that might have given rise to those statistics .","label":"Future","metadata":{},"score":"44.011726"}
{"text":"Instead of collecting more and more parallel training corpora , this paper aims to improve SMT performance by exploiting full potential of the existing parallel corpora .Two kinds of methods are proposed : offline data optimization and online model optimization .","label":"Future","metadata":{},"score":"44.011967"}
{"text":"This motivates a Bayesian approach using a sparse prior to bias the estimator toward such a skewed distribution .We investigate Gibbs Sampling ( GS ) and Variational Bayes ( VB ) estimators and show that VB converges faster than GS for this task and that VB significantly improves 1-to-1 tagging accuracy over EM .","label":"Future","metadata":{},"score":"44.02853"}
{"text":"Example The laptop is great , it is extremely fast .The book is great , it is very engaging .Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsStructural Correspondence Learning Blitzer et al . , 2007 : Introduce pivot features that appear frequently in source and target domains .","label":"Future","metadata":{},"score":"44.03795"}
{"text":"Example The laptop is great , it is extremely fast .The book is great , it is very engaging .Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsStructural Correspondence Learning Blitzer et al . , 2007 : Introduce pivot features that appear frequently in source and target domains .","label":"Future","metadata":{},"score":"44.03795"}
{"text":"Example The laptop is great , it is extremely fast .The book is great , it is very engaging .Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsStructural Correspondence Learning Blitzer et al . , 2007 : Introduce pivot features that appear frequently in source and target domains .","label":"Future","metadata":{},"score":"44.03795"}
{"text":"We present the PORTAGE statistical machine translation system which participated in the shared task of the ACL 2007 Second Workshop on Statistical Machine Translation .The focus of this description is on improvements which were incorporated into the system over the last year .","label":"Future","metadata":{},"score":"44.20581"}
{"text":"We perform both identification and resolution automatically , with two sets of easily computable features .Experimental results show that our proposed learning approach achieves anaphoric zero pronoun resolution accuracy comparable to a previous state - of - the - art , heuristic rule - based approach .","label":"Future","metadata":{},"score":"44.29341"}
{"text":"Under the DTMKL framework , we also propose two novel methods by using SVM and prelearned classifiers , respectively .Comprehensive experiments on three domain adaptation data sets ( i.e. , TRECVID , 20 Newsgroups , and email spam data sets ) demonstrate that DTMKL - based methods outperform existing cross - domain learning and multiple kernel learning methods .","label":"Future","metadata":{},"score":"44.321426"}
{"text":"Lease , M. , & Charniak , E. ( 2005 ) .Parsing biomedical literature .In International joint conference on natural language processing ( IJCNLP ) .Littlestone , N. , & Warmuth , M. K. ( 1994 ) .The weighted majority algorithm .","label":"Future","metadata":{},"score":"44.453712"}
{"text":"In the majority of cases SVM demonstrates the best performance .Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsSupervised Machine Learning Learn sentiment phenomena from an annotated corpus .","label":"Future","metadata":{},"score":"44.633358"}
{"text":"However , previous approaches ignore this dependency .We propose a novel approach for this task , namely training Semi Markov models discriminatively using a Max - Margin method .This method allows us to model the sequence dependency of the problem and to incorporate properties of a whole paragraph , such as coherence , which can not be used in previous methods .","label":"Future","metadata":{},"score":"44.6718"}
{"text":"In common with other approaches to sequence modeling using perceptrons , and in contrast with comparable generative models , this model permits and transparently exploits arbitrary features of input strings .The simplicity of perceptron training lends more versatility than comparable approaches , allowing the model to be applied to a variety of problem types for which a learned edit model might be useful .","label":"Future","metadata":{},"score":"44.733032"}
{"text":"Scalable term selection is proposed to optimize the term set at a given dimensionality according to an expected average vector length .Discriminability and coverage are separately measured ; by adjusting the ratio of their weights in a combined criterion , the expected average vector length can be reached , which means a good compromise between the specificity and the exhaustivity of the term subset .","label":"Future","metadata":{},"score":"44.820847"}
{"text":"19 ] Y. Liu , D. Xu , I.W. Tsang , and J. Luo , \" Textual Query of Personal Photos Facilitated by Large - Scale Web Data , \" IEEE Trans .Pattern Analysis and Machine Intelligence , vol .33 , no .","label":"Future","metadata":{},"score":"44.992138"}
{"text":"Naskar , Andy Way , Josef Van Genabith . \" ...This paper presents a set of experiments on Domain Adaptation of Statistical Machine Translation systems .The experiments focus on Chinese - English and two domain - specific corpora .The paper presents a novel approach for combining multiple domain - trained translation models to achieve improved transla ... \" .","label":"Future","metadata":{},"score":"45.01927"}
{"text":"However , this naive approach tends to perform poorly since density estimation is a hard task particularly in high dimensional cases .In this paper , we propose a direct importance estimation method that does not involve density estimation .Our method is equipped with a natural cross validation procedure and hence tuning parameters such as the kernel width can be objectively optimized .","label":"Future","metadata":{},"score":"45.111248"}
{"text":"This lexicon provides the initial lexical probabilities for EM training of a HMM model .We evaluate the method by applying it in the Biology domain and show that we achieve results that are comparable with some taggers developed for this domain .","label":"Future","metadata":{},"score":"45.210567"}
{"text":"In task ( 1 ) , cross - lingual measures are superior to conventional monolingual measures based on a wordnet .In task ( 2 ) , cross - lingual measures are able to solve more problems correctly , and despite scores being affected by many tied answers , their overall performance is again better than the best monolingual measures .","label":"Future","metadata":{},"score":"45.296097"}
{"text":"For the sake of adaptation , mixture weight estimation is performed either at the level of single source sentence or test set .Estimated weights are then transferred to the target language mixture model .Experimental results show that , by training different specific language models weighted according to the actual input instead of using a single target language model , signifi - cant gains in terms of perplexity and BLEU can be achieved . \" ...","label":"Future","metadata":{},"score":"45.379547"}
{"text":"We consistently observed significant improvements on several test sets in multiple languages covering different genres .This paper proposes a method using the existing Rule - based Machine Translation ( RBMT ) system as a black box to produce synthetic bilingual corpus , which will be used as training data for the Statistical Machine Translation ( SMT ) system .","label":"Future","metadata":{},"score":"45.400406"}
{"text":"We train a discriminative classifier over a wide variety of features derived from WordNet structure , corpus - based evidence , and evidence from other lexical resources .Our learned similarity measure outperforms previously proposed automatic methods for sense clustering on the task of predicting human sense merging judgments , yielding an absolute F - score improvement of 4.1 % on nouns , 13.6 % on verbs , and 4.0 % on adjectives .","label":"Future","metadata":{},"score":"45.413082"}
{"text":"18 , no .6 , pp .770 - 783 , June 2006 .[ 18 ] X. Zhu and X. Wu , \" Class Noise Handling for Effective Cost - Sensitive Learning by Cost - Guided Iterative Classification Filtering , \" IEEE Trans .","label":"Future","metadata":{},"score":"45.42417"}
{"text":"Using a set of one - vs - all Support Vector Machines ( SVMs ) , we evaluate these LTAG - based features .Our experiments show that LTAG - based features can improve SRL accuracy significantly .When compared with the best known set of features that are used in state of the art SRL systems we obtain an improvement in F - score from 82.34 % to 85.25 % .","label":"Future","metadata":{},"score":"45.492294"}
{"text":"State - of - the - art performance on Hebrew Treebank parsing is demonstrated using the new method .The benefits of joint inference are modest with the current component models , but appear to increase as components themselves improve .This paper proposes a new bootstrapping approach to unsupervised part - of - speech induction for resource - scarce languages .","label":"Future","metadata":{},"score":"45.52197"}
{"text":"Feature function weights in the log - linear model are set using Och 's minimum ... . \" ...Abstract - This paper describes an approach for computing a consensus translation from the outputs of multiple machine translation ( MT ) systems .","label":"Future","metadata":{},"score":"45.52441"}
{"text":"When tested on a corpus of Wikipedia articles , our hierarchically informed model predicts the correct insertion paragraph more accurately than baseline methods .In this paper we consider the problem of automatically identifying the arguments of discourse connectives ( e.g. and , because , nevertheless ) in the Penn Discourse TreeBank(PDTB ) .","label":"Future","metadata":{},"score":"45.53487"}
{"text":"This demonstrates that information provided by labeled data is more valuable .This demonstrates that information provided by labeled data is more valuable .For non - similar domains , when source domain is more complex than the target one , best results are achieved with smaller γ close to 0.5 .","label":"Future","metadata":{},"score":"45.59289"}
{"text":"[52 ] J. Davis and P. Domingos , \" Deep Transfer via Second - Order Markov Logic , \" Proc .Assoc .for the Advancement of Artificial Intelligence ( AAAI ' 08 )Workshop Transfer Learning for Complex Tasks , July 2008 .","label":"Future","metadata":{},"score":"45.600998"}
{"text":"First , it automatically determines a dy - namic context - sensitive tree span for relation extraction by extending the widely - used Shortest Path - enclosed Tree ( SPT ) to include necessary context information outside SPT .Second , it proposes a context - sensitive convolution tree kernel , which enumerates both context - free and context - sensitive sub - trees by considering their ancestor node paths as their contexts .","label":"Future","metadata":{},"score":"45.6239"}
{"text":"We argue that bootstrapping a parser is most promising when the model uses a rich set of redundant features , as in recent models for scoring dependency parses ( McDonald et al . , 2005 ) .Drawing on Abney 's ( 2004 ) analysis of the Yarowsky algorithm , we perform bootstrapping by entropy regularization : we maximize a linear combination of conditional likelihood on labeled data and confidence ( negative Renyi entropy ) on unlabeled data .","label":"Future","metadata":{},"score":"45.6427"}
{"text":"Constructing informative priors using transfer learning .In International conference on machine learning ( ICML ) .Raina , R. , Battle , A. , Lee , H. , Packer , B. , & Ng , A. ( 2007 ) .Self - taught learning : transfer learning from unlabeled data .","label":"Future","metadata":{},"score":"45.723312"}
{"text":"In our approach , proper nouns are expanded into new queries aimed at maximizing the probability of retrieving transliterations from existing search engines .The method involves learning the sublexical relationships between names and their transliterations .At run - time , a given name is automatically extended into queries with relevant morphemes , and transliterations in the returned search snippets are extracted and ranked .","label":"Future","metadata":{},"score":"45.94243"}
{"text":"Cross - domain learning methods have shown promising results by leveraging labeled patterns from the auxiliary domain to learn a robust classifier for the target domain which has only a limited number of labeled samples .To cope with the considerable change between feature distributions of different domains , we propose a new cross - domain kernel learning framework into which many existing kernel methods can be readily incorporated .","label":"Future","metadata":{},"score":"45.982307"}
{"text":"Therefore , we use ancestor - descendant relation in addition to parent - child relation , so that the added redundancy helps errors be corrected .Experimental results show that the proposed method achieves higher accuracy .We propose a sequence - alignment based method for detecting and disambiguating coordinate conjunctions .","label":"Future","metadata":{},"score":"46.091637"}
{"text":"We derive a kernel logistic regression classifier for differing training and test distributions .hts are normalized .The third method is kernel mean matching ( Huang et al . , 2007 ) .We tune the regularization parameters of the logistic regression methods , the B parameter of kernel mean ma ... .","label":"Future","metadata":{},"score":"46.131035"}
{"text":"Our approach is based on the analysis of the paths between two protein names in the dependency parse trees of the sentences .Given two dependency trees , we define two separate similarity functions ( kernels ) based on cosine similarity and edit distance among the paths between the protein names .","label":"Future","metadata":{},"score":"46.16517"}
{"text":"The interesting observations might inspire further investigations .Active learning is a promising way to solve the knowledge bottleneck problem faced by supervised word sense disambiguation ( WSD ) methods .Unfortunately , in real - world data , the distribution of the senses of a word is often skewed , which causes a problem for learning methods for WSD .","label":"Future","metadata":{},"score":"46.228786"}
{"text":"Furthermore , the combination of parse trees can compensate for the reordering errors caused by single parse tree .Finally , experimental results show that the performance of our system is superior to that of the state - of - the - art phrase - based SMT system .","label":"Future","metadata":{},"score":"46.244434"}
{"text":"Finally , we investigate when to stop active learning , and adopt two strategies , max - confidence and min - error , as stopping conditions for active learning .According to experimental results , we suggest a prediction solution by considering max - confidence as the upper bound and min - error as the lower bound of stopping conditions .","label":"Future","metadata":{},"score":"46.246273"}
{"text":"In Association for computational linguistics ( ACL ) .Chelba , C. , & Acero , A. ( 2004 ) .Adaptation of maximum entropy classifier : Little data can help a lot .In Empirical methods in natural language processing ( EMNLP ) .","label":"Future","metadata":{},"score":"46.250587"}
{"text":"Online passive - aggressive algorithms .Journal of Machine Learning Research ( JMLR ) , 7 , 551 - 585 .MathSciNet .Crammer , K. , Dredze , M. , & Pereira , F. ( 2008 ) .Exact confidence - weighted learning .","label":"Future","metadata":{},"score":"46.32634"}
{"text":"The results were achieved by using only information about heads and daughters as features to guide the parser which obeys strict incrementality .A memory - based learner was used to predict the next action of the parser .This paper presents an online algorithm for dependency parsing problems .","label":"Future","metadata":{},"score":"46.36162"}
{"text":"Dekel , O. , Long , P. M. , & Singer , Y. ( 2006 ) .Online multitask learning .In Conference on learning theory ( COLT ) .Do , C. B. , & Ng , A. ( 2006 ) .","label":"Future","metadata":{},"score":"46.511635"}
{"text":"This paper presents a novel approach for exploiting the global context for the task of word sense disambiguation ( WSD ) .This is done by using topic features constructed using the latent dirichlet allocation ( LDA ) algorithm on unlabeled data .","label":"Future","metadata":{},"score":"46.537937"}
{"text":"The first stage consists in tuning a single - parser system for each language by optimizing parameters of the parsing algorithm , the feature model , and the learning algorithm .The second stage consists in building an ensemble system that combines six different parsing strategies , extrapolating from the optimal parameters settings for each language .","label":"Future","metadata":{},"score":"46.545147"}
{"text":"Lower values are being noticed for domains which are more similar .Lower values are being noticed for domains which are more similar .This is a strength of the model as our main purpose is to identify the closest domains .","label":"Future","metadata":{},"score":"46.580116"}
{"text":"All models are used during search , i.e. they are incorporated directly into the log - linear model combination of the decoder .Phrase table smoothing with triplet lexicon models and with discriminative word lexicons are novel contributions .We also propose a new regularization technique for IBM model 1 by means of the Kullback - Leibler divergence with the empirical unigram distribution as regularization term .","label":"Future","metadata":{},"score":"46.60123"}
{"text":"Dai , W. , Xue , G. R. , Yang , Q. , & Yu , Y. ( 2007 ) .Transferring naive Bayes classifiers for text classification .In American national conference on artificial intelligence ( AAAI ) .Dai , W. , Chen , Y. , Xue , G. R. , Yang , Q. , & Yu , Y. ( 2009 ) .","label":"Future","metadata":{},"score":"46.766205"}
{"text":"On a transfer learning task of newsgroup message categorization , the proposed locally weighted ensemble framework achieves 97 % accuracy when the best single model predicts correctly only on 73 % of the test examples .In summary , the improvement in accuracy is over 10 % and up to 30 % across different problems . .","label":"Future","metadata":{},"score":"46.91841"}
{"text":"Experimental results on the test data of the previous campaign are presented . ... to Canadian universities for research and education purposes . \" ...Current phrase - based SMT systems perform poorly when using small training sets .This is a consequence of unreliable translation estimates and low coverage over source and target phrases .","label":"Future","metadata":{},"score":"47.21128"}
{"text":"ACL Workshop on SMT , 2007 . \" ...We present the PORTAGE statistical machine translation system which participated in the shared task of the ACL 2007 Second Workshop on Statistical Machine Translation .The focus of this description is on improvements which were incorporated into the system over the last year .","label":"Future","metadata":{},"score":"47.296997"}
{"text":"For the latter case , clustering of IWSLT data was in fact induced through a comparable Italian - English parallel corpus provided with dialog act annotations .For the sake of adaptation , mixture weight estimation is performed either at the level of single source sentence or test set .","label":"Future","metadata":{},"score":"47.36103"}
{"text":"In scientific literature , sentences that cite related work can be a valuable resource for applications such as summarization , synonym identification , and entity extraction .In order to determine which equivalent entities are discussed in the various citation sentences , we propose aligning the words within these sentences according to semantic similarity .","label":"Future","metadata":{},"score":"47.43457"}
{"text":"The evaluation showed that PDMM is more effective than PMM .We address the problem of smoothing translation probabilities in a bilingual N - gram - based statistical machine translation system .It is proposed to project the bilingual tuples onto a continuous space and to estimate the translation probabilities in this representation .","label":"Future","metadata":{},"score":"47.47798"}
{"text":"For non - similar domains , when source domain is more complex than the target one , best results are achieved with smaller γ close to 0.5 .Number of labeled and unlabeled neighbours is not equal , there is a clear tendency to prefer results with smaller number of unlabeled and higher number of labeled examples .","label":"Future","metadata":{},"score":"47.51286"}
{"text":"CrossRef .Thrun , S. , & O'Sullivan , J. ( 1998 ) .Clustering learning tasks and the selective cross - task transfer of knowledge .In S. Thrun & L. Pratt ( Eds . ) , Learning to learn .","label":"Future","metadata":{},"score":"47.516354"}
{"text":"Most current word prediction systems make use of n - gram language models ( LM ) to estimate the probability of the following word in a phrase .In the past years there have been many attempts to enrich such language models with further syntactic or semantic information .","label":"Future","metadata":{},"score":"47.525383"}
{"text":"A popular approach is based on unsupervised training , also called self - enhancing .Both only use monolingual data to adapt the translation model .In this paper we extend the previous work and provide new insight in the existing methods .","label":"Future","metadata":{},"score":"47.566826"}
{"text":"In phrase - based models , this problem can be addressed by storing the training data in memory and using a suffix array as an efficient index to quickly lookup and extract rules on the fly .Hierarchical phrase - based translation introduces the added wrinkle of source phrases with gaps .","label":"Future","metadata":{},"score":"47.70244"}
{"text":"Using the RankNet learning algorithm , we train a pair - based sentence ranker to score every sentence in the document and identify the most important sentences .We apply our system to documents gathered from CNN.com , where each document includes highlights and an article .","label":"Future","metadata":{},"score":"47.921738"}
{"text":"One effective way to do that is to post - edit the translations produced by a vanilla RBMT system using a specially - trained statistical machine translation ( SMT ) system .Our experiments indicate that this method is just as effective as manual customization of system dictionaries in reducing the need for manual post - editing . ... entence - length feature .","label":"Future","metadata":{},"score":"47.992893"}
{"text":"Parser actions are determined by a classifier , based on features that represent the current state of the parser .We apply this parsing framework to both tracks of the CoNLL 2007 shared task , in each case taking advantage of multiple models trained with different learners .","label":"Future","metadata":{},"score":"48.118767"}
{"text":"Our method compares favorably with state - of - the - art algorithms that recover WH - traces .Recent studies focussed on the question whether less - configurational languages like German are harder to parse than English , or whether the lower parsing scores are an artifact of treebank encoding schemes and data structures , as claimed by Kübler et al .","label":"Future","metadata":{},"score":"48.123306"}
{"text":"18 , no .10 , pp .1435 - 1440 , Oct. 2006 .[28 ] W. Dai , G. Xue , Q. Yang , and Y. Yu , \" Transferring Naive Bayes Classifiers for Text Classification , \" Proc . 22nd","label":"Future","metadata":{},"score":"48.20276"}
{"text":"These category labels are used as features in a CRF - based NE tagger .We demonstrate using the CoNLL 2003 dataset that the Wikipedia category labels extracted by such a simple method actually improve the accuracy of NER .This paper presents a large - scale system for the recognition and semantic disambiguation of named entities based on information extracted automatically from a large encyclopedic collection and Web search results , over a space of more than 1.4 million entities .","label":"Future","metadata":{},"score":"48.256184"}
{"text":"We address classification problems for which the training instances are governed by a distribution that is allowed to differ arbitrarily from the test distribution - problems also referred to as classification under covariate shift .We derive a solution that is purely discriminative : neither training nor test distribution are modeled explicitly .","label":"Future","metadata":{},"score":"48.292305"}
{"text":"Our proposal takes advantage of the one - sided error guarantees of the BF and simple inequalities that hold between related $ n$-gram statistics in order to further reduce the BF storage requirements and the error rate of the derived probabilities .","label":"Future","metadata":{},"score":"48.301132"}
{"text":"for the Advancement of Artificial Intelligence ( AAAI ) Conf .Artificial Intelligence , pp .677 - 682 , July 2008 .[ 68 ] M.M.H. Mahmud and S.R. Ray , \" Transfer Learning Using Kolmogorov Complexity : Basic Theory and Empirical Evaluations , \" Proc . 20th Ann .","label":"Future","metadata":{},"score":"48.333977"}
{"text":"Bickel and Scheffe ... . \" ...A common assumption in supervised learning is that the input points in the training set follow the same probability distribution as the input points that will be given in the future test phase .However , this assumption is not satisfied , for example , when the outside of the training region is extrapo ... \" .","label":"Future","metadata":{},"score":"48.610607"}
{"text":"We present a nonparametric Bayesian model of tree structures based on the hierarchical Dirichlet process ( HDP ) .Our HDP - PCFG model allows the complexity of the grammar to grow as more training data is available .In addition to presenting a fully Bayesian model for the PCFG , we also develop an efficient variational inference procedure .","label":"Future","metadata":{},"score":"48.82294"}
{"text":"The experiments are carried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser .We use a generative history - based model to predict the most likely derivation of a dependency parse .","label":"Future","metadata":{},"score":"48.841473"}
{"text":"Meeting of the Assoc .Computational Linguistics , pp .432 - 439 , 2007 .[ 9 ] J. Ramon , K. Driessens , and T. Croonenborghs , \" Transfer Learning in Reinforcement Learning Problems through Partial Policy Recycling , \" Proc . 18th","label":"Future","metadata":{},"score":"48.873215"}
{"text":"5 , pp .770 - 787 , May 2010 .[ 8 ] S.-F. Chang , J. He , Y.-G. Jiang , E.E. Khoury , C.-W. Ngo , A. Yanagawa , and E. Zavesky , \" Columbia University / VIREO - CityU / IRIT TRECVID2008 High - Level Feature Extraction and Interactive Video Search , \" Proc .","label":"Future","metadata":{},"score":"48.90532"}
{"text":"To characterise the arguments in a given grammatical relationship we experiment with three models of selectional preference .Two use WordNet and one uses the entries from a distributional thesaurus as classes for representation .In previous work on selectional preference acquisition , the classes used for representation are selected according to the coverage of argument tokens rather than being selected according to the coverage of argument types .","label":"Future","metadata":{},"score":"48.999073"}
{"text":"The context of a whole corpus of automatic translations rather than a single sentence is taken into account in order to achieve high alignment quality .The confusion network is rescored with a special language model , and the consensus translation is extracted as the best path .","label":"Future","metadata":{},"score":"49.080074"}
{"text":"Abstract .Transfer learning is the improvement of learning in a new task through the transfer of knowledge from a related task that has already been learned .While most machine learning algorithms are designed to address single tasks , the development of algorithms that facilitate transfer learning i ... \" .","label":"Future","metadata":{},"score":"49.08728"}
{"text":"c2000 Masashi Sugiyama , Matthias Krauledat , and Klaus - Robert Müller . \" ...We address classification problems for which the training instances are governed by a distribution that is allowed to differ arbitrarily from the test distribution - problems also referred to as classification under covariate shift .","label":"Future","metadata":{},"score":"49.116047"}
{"text":"We extract effective expressions from the important segments to define various viewpoints .In text mining a viewpoint defines the important associations between key entities and it is crucial that the correct viewpoints are identified .We show the effectiveness of the method by using real datasets from a car rental service center .","label":"Future","metadata":{},"score":"49.13665"}
{"text":"This assumption may not hold in many situations in practice , but we may be forced to rely on a different - distribution data to learn a prediction model .For example , this may be th ... \" .A basic assumption in traditional machine learning is that the training and test data distributions should be identical .","label":"Future","metadata":{},"score":"49.487442"}
{"text":"Semantic inference is a core component of many natural language applications .In response , several researchers have developed algorithms for automatically learning inference rules from textual corpora .However , these rules are often either imprecise or underspecified in directionality .","label":"Future","metadata":{},"score":"49.622505"}
{"text":"Lexical chains have been successfully employed to evaluate lexical cohesion of text segments and to predict topic boundaries .Our approach is based in the notion of semantic cohesion .It uses spectral embedding to estimate semantic association between content nouns over a span of multiple text segments .","label":"Future","metadata":{},"score":"49.6661"}
{"text":"A mixture of language models is employed , which is obtained by clustering the bilingual training data .Unsupervised clustering is guided by either the development or the test set .Different mixture weight esti ... \" .The problem of language model adaptation in statistical machine translation is considered .","label":"Future","metadata":{},"score":"49.68377"}
{"text":"Proportion of 50 against 150 seems to be an ideal , covering most of the cases .Tools . \" ...Statistical machine translation ( SMT ) treats the translation of natural language as a machine learning problem .By examining many samples of human - produced translation , SMT algorithms automatically learn how to translate .","label":"Future","metadata":{},"score":"49.802765"}
{"text":"For an in - domain text , we identify the critical segments and modify them to alleviate the data sparseness problem in the out - domain SMT system .After we receive the translation result , these critical segments are then restored according to the provided in - domain knowledge .","label":"Future","metadata":{},"score":"49.92398"}
{"text":"That motivates us to exploit graph - based cross - domain algorithms .Reviews are rated either as positive or negative .Reviews are rated either as positive or negative .Data within each domain are balanced , they contain 1000 positive and 1000 negative reviews .","label":"Future","metadata":{},"score":"49.931847"}
{"text":"Experimental results on sentence compression bring significant improvements over a state - of - the - art model .Many emerging applications require documents to be repeatedly updated .Such documents include newsfeeds , webpages , and shared community resources such as Wikipedia .","label":"Future","metadata":{},"score":"50.018513"}
{"text":"The assumption might be violated when a task from one new domain comes , while there are only labeled d ... \" .Traditional machine learning makes a basic assumption : the training and test data should be under the same distribution .","label":"Future","metadata":{},"score":"50.20816"}
{"text":"In this paper , we propose a new method called importance weighted cross validation ( IWCV ) , for which we prove its unbiasedness even under the covariate shift .The IWCV procedure is the only one that can be applied for unbiased classification under covariate shift , whereas alternatives to IWCV exist for regression .","label":"Future","metadata":{},"score":"50.255585"}
{"text":"Transfer learning is the improvement of learning in a new task through the transfer of knowledge from a related task that has already been learned .While most machine learning algorithms are designed to address single tasks , the development of algorithms that facilitate transfer learning is a topic of ongoing interest in the machine - learning community .","label":"Future","metadata":{},"score":"50.38864"}
{"text":"In text categorization , term selection is an important step for the sake of both categorization accuracy and computational efficiency .Different dimensionalities are expected under different practical resource restrictions of time or space .Traditionally in text categorization , the same scoring or ranking criterion is adopted for all target dimensionalities , which considers both the discriminability and the coverage of a term , such as $ \\chi^2 $ or IG .","label":"Future","metadata":{},"score":"50.622223"}
{"text":"We describe our experimental results on legal and government data , and present the human evaluation effort for post - editing in addition to traditional automated scoring techniques ( BLEU scores ) .The human effort is based primarily on the amount of time and number of edits required by a professional post - editor to improve the quality of machine - generated translations to meet industry standards .","label":"Future","metadata":{},"score":"50.747986"}
{"text":"But this method does not work well for web query spelling correction , because there is no lexicon that can cover the vast amount of terms occurring across the web .Recent work showed that using search query logs helps to solve this problem to some extent .","label":"Future","metadata":{},"score":"50.78584"}
{"text":"We exploit a series of binarization methods to restructure the Penn Treebank style trees such that syntactified phrases smaller than Penn Treebank constituents can be acquired and exploited in translation .We find that by employing the EM algorithm for determining the binarization of a parse tree among a set of alternative binarizations gives us the best translation result .","label":"Future","metadata":{},"score":"50.85008"}
{"text":"Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsDiscussion Machine learning methods demonstrate a very good performance and when the size of the data is substantial they outperform lexical approaches .","label":"Future","metadata":{},"score":"50.874466"}
{"text":"We propose two characteristics to model accuracy loss : domain similarity and domain complexity or , more precisely , domain complexity variance .Domain similarity approximate similarity between distributions for frequent features .Domain complexity compares tails of distributions .Background Domain similarity Preliminary experiments Domain complexity Modeling accuracy loss for cross - domain SC Model construction and validation Graph - based algorithmsDomain similarity We are not interested in all terms but rather on those bearing sentiment .","label":"Future","metadata":{},"score":"50.87465"}
{"text":"Other work in multi - task learning uses neural network architectures to structurally force all the tasks to share intermediate representations [ 1,6]. ... ] .Other work in multi - task learning uses neural network architectures to structurally force all the tasks to share intermediate representations [ 2 , 73].","label":"Future","metadata":{},"score":"50.980713"}
{"text":"The deep processing approach uses the XLE LFG parser and English grammar : two versions are presented , one which uses the XLE directly to perform the classification , and another one which uses a decision tree trained on features consisting of the XLE 's output statistics .","label":"Future","metadata":{},"score":"50.98175"}
{"text":"The savings can be quite substantial ( up to 90 % ) and cause no reduction in BLEU score .In some cases , an improvement in BLEU is obtained at the same time although the effect is less pronounced if state - of - the - art phrasetable smoothing is employed .","label":"Future","metadata":{},"score":"50.98414"}
{"text":"Ann .Int'l ACM SIGIR Conf .Research and Development in Information Retrieval , pp .627 - 634 , July 2008 .[66 ] S.J. Pan , J.T. Kwok , and Q. Yang , \" Transfer Learning via Dimensionality Reduction , \" Proc . 23rd","label":"Future","metadata":{},"score":"51.29979"}
{"text":"We focus on two important subtasks of opinion extraction : ( a ) extracting aspect - evaluation relations , and ( b ) extracting aspect - of relations , and we approach each task using methods which combine contextual and statistical clues .","label":"Future","metadata":{},"score":"51.367783"}
{"text":"We define the objective function of our hybrid model , which is written in log - linear form , by discriminatively combining discriminative structured predictor(s ) with generative model(s ) that incorporate unlabeled data .Then , unlabeled data is used in a generative manner to increase the sum of the discriminant functions for all outputs during the parameter estimation .","label":"Future","metadata":{},"score":"51.38154"}
{"text":"A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution .However , in many real - world applications , this assumption may not hold .","label":"Future","metadata":{},"score":"51.39895"}
{"text":"A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution .However , in many real - world applications , this assumption may not hold .","label":"Future","metadata":{},"score":"51.39895"}
{"text":"Its space requirements fall significantly below lossless information - theoretic lower bounds but it produces false positives with some quantifiable probability .Here we present a general framework for deriving smoothed language model probabilities from BFs .We investigate how a BF containing n -gram statistics can be used as a direct replacement for a conventional n -gram model .","label":"Future","metadata":{},"score":"51.512245"}
{"text":"During label prediction , the system automatically selects for each feature an appropriate level of smoothing .We report on several experiments that we conducted with our system .In the shared task evaluation , it scored better than average .We present Pro3Gres , a deep - syntactic , fast dependency parser that combines a hand - written competence grammar with probabilistic performance disambiguation and that has been used in the biomedical domain .","label":"Future","metadata":{},"score":"51.559235"}
{"text":"This article describes a machine translation system based on an automatic post - editing strategy : initially translate the input text into the target - language using a rule - based MT system , then automatically post - edit the output using a statistical phrase - based system .","label":"Future","metadata":{},"score":"51.930664"}
{"text":"This article describes a machine translation system based on an automatic post - editing strategy : initially translate the input text into the target - language using a rule - based MT system , then automatically post - edit the output using a statistical phrase - based system .","label":"Future","metadata":{},"score":"51.930664"}
{"text":"The task can be especially difficult when the training examples are from one or severa ... \" .The effectiveness of knowledge transfer using classification algorithms depends on the difference between the distribution that generates the training examples and the one from which test examples are to be drawn .","label":"Future","metadata":{},"score":"52.0008"}
{"text":"In both the English all - words task and the English lexical sample task , the method achieved significant improvement over the simple naive Bayes classifier and higher accuracy than the best offical scores on Senseval-3 for both task .We develop latent Dirichlet allocation with WordNet ( LDAWN ) , an unsupervised probabilistic topic model that includes word sense as a hidden variable .","label":"Future","metadata":{},"score":"52.144722"}
{"text":"Evaluation on a list of 500 proper names shows that the method achieves high precision and recall , and outperforms commercial machine translation systems .It has been widely observed that different NLP applications require different sense granularities in order to best exploit word sense distinctions , and that for many applications WordNet senses are too fine - grained .","label":"Future","metadata":{},"score":"52.169792"}
{"text":"There has been little effort reported on this in the research community .We argue that semantics is important for record extraction or finer - grained language processing tasks .We derive a data record template including semantic language models from unstructured text and represent them with a discourse level Conditional Random Fields ( CRF ) model .","label":"Future","metadata":{},"score":"52.225956"}
{"text":"We also present an analysis of what is and is not learned by our system .This paper describes ETK ( Ensemble of Transformation based Keys ) a new algorithm for inducing search keys for name filtering .ETK has the low computational cost and ability to filter by phonetic similarity characteristic of phonetic keys such as Soundex , but is adaptable to alternative similarity models .","label":"Future","metadata":{},"score":"52.278397"}
{"text":"Abstract - Learning a visual object category from few samples is a compelling and challenging problem .In several real - world applications collecting many annotated data is costly and not always possible .However a small training set does not allow to cover the high intraclass variability typical of vi ... \" .","label":"Future","metadata":{},"score":"52.362007"}
{"text":"We also show that our techniques can be applied to full - scale parsing applications by demonstrating its effectiveness in learning state - split grammars .We explore the use of Wikipedia as external knowledge to improve named entity recognition ( NER ) .","label":"Future","metadata":{},"score":"52.453594"}
{"text":"We investigate methods to improve the recall in coreference resolution by also trying to resolve those definite descriptions where no earlier mention of the referent shares the same lexical head ( coreferent bridging ) .The problem , which is notably harder than identifying coreference relations among mentions which have the same lexical head , has been tackled with several rather different approaches , and we attempt to provide a meaningful classification along with a quantitative comparison .","label":"Future","metadata":{},"score":"52.490734"}
{"text":".. dels to generalize from a source domain with abundant data to a different target domain with limited data .Supervised domain adaptation techniques assume that limited parallel data is available from the target domain , while unsupervised domain adaptation techniques rely solely on target ... . \" ...","label":"Future","metadata":{},"score":"52.51653"}
{"text":"The assumption might be violated when a task from one new domain comes , while there are only labeled data from a similar old domain .Labeling the new data can be costly and it would also be a waste to throw away all the old data .","label":"Future","metadata":{},"score":"52.847122"}
{"text":"The disambiguation component employs a vector space model and a process of maximizing the agreement between the contextual information extracted from Wikipedia and the context of a document , as well as the agreement among the category tags associated with the candidate entities .","label":"Future","metadata":{},"score":"52.955856"}
{"text":"Their ability to automatically induce features results in multilingual parsing which is robust enough to achieve accuracy well above the average for each individual language in the multilingual track of the CoNLL-2007 shared task .This robustness led to the third best overall average labeled attachment score in the task , despite using no discriminative methods .","label":"Future","metadata":{},"score":"53.00273"}
{"text":"We compare V - measure to a number of popular cluster evaluation measures and demonstrate that it satisfies several desirable properties of clustering solutions , using simulated clustering results .Finally , we use V - measure to evaluate two clustering tasks : document clustering and pitch accent type clustering .","label":"Future","metadata":{},"score":"53.122574"}
{"text":"We present two techniques for training the MST parser : tree - normalized and graph - normalized conditional training .We describe the reranker features which include non - projective edge attributes .We provide an analysis of the errors made by our system and suggest changes to the models and features that might rectify the current system .","label":"Future","metadata":{},"score":"53.24573"}
{"text":"Statistical machine translation ( SMT ) treats the translation of natural language as a machine learning problem .By examining many samples of human - produced translation , SMT algorithms automatically learn how to translate .SMT has made tremendous strides in less than two decades , and many popular techniques have only emerged within the last few years .","label":"Future","metadata":{},"score":"53.3518"}
{"text":"Background Comparison Preliminary experiments Document similarity Modeling accuracy loss for cross - domain SC Strategy for choosing the best parameters Graph - based algorithmsBest accuracy improvement achieved by the algorithms We tested the performance of each algorithm for several values of their parameters .","label":"Future","metadata":{},"score":"53.67157"}
{"text":"To predict elec - tion results , we apply SVM - based super - vised learning .To improve performance , we propose a novel technique which generalizes n - gram feature patterns .Experimental results show that Crystal significantly outperforms several baselines as well as a non - generalized n - gram ap - proach .","label":"Future","metadata":{},"score":"53.76661"}
{"text":"A situation where training and test samples follow different input distributions is called covariate shift .Under covariate shift , standard learning methods such as maximum likelihood estimation are no longer consistent - weighted variants according to the ratio of test and training input densities ar ... \" .","label":"Future","metadata":{},"score":"53.796906"}
{"text":"We found that our method could benefit from the two - preprocessing stages .To speed up training , in this year , we employ the MFN - SVM ( modified finite - Newton method support vector machines ) which can be learned in linear time .","label":"Future","metadata":{},"score":"53.800198"}
{"text":"The SMT models specialized for one domain often perform poorly when applied to other domains .The typica ... \" .Abstract .Statistical Machine Translation ( SMT ) is currently used in real - time and commercial settings to quickly produce initial translations for a document which can later be edited by a human .","label":"Future","metadata":{},"score":"53.91773"}
{"text":"The resulting IE system achieves good performance on the MUC-4 terrorism corpus and ProMed disease outbreak stories .This approach requires only a few seed extraction patterns and a collection of relevant and irrelevant documents for training .This paper proposes a tree kernel with context - sensitive structured parse tree information for re - lation extraction .","label":"Future","metadata":{},"score":"53.958244"}
{"text":"We demonstrate the effectiveness of our technique largely surpassing both the random and most frequent baselines and outperforming current state - of - the - art unsupervised approaches on a benchmark ontology available in the literature .To date , work on Non - Local Dependencies ( NLDs ) has focused almost exclusively on English and it is an open research question how well these approaches migrate to other languages .","label":"Future","metadata":{},"score":"53.984467"}
{"text":"This paper reports on the benefits of large - scale statistical language modeling in machine translation .A distributed infrastructure is proposed which we use to train on up to 2 trillion tokens , resulting in language models having up to 300 billion n - grams .","label":"Future","metadata":{},"score":"53.996384"}
{"text":"In particular , we wish to determine the best location in a text for a given piece of new information .For this process to succeed , the insertion algorithm should be informed by the existing document structure .Lengthy real - world texts are often hierarchically organized into chapters , sections , and paragraphs .","label":"Future","metadata":{},"score":"53.998802"}
{"text":"Int'l Conf .Machine Learning , pp .808 - 815 , July 2008 .The 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ( EMNLP - CoNLL 2007 ) .The main track of the conference received 398 paper submissions ( not counting 21 that were withdrawn or rejected without review ) .","label":"Future","metadata":{},"score":"54.162086"}
{"text":"CrossRef June 11 , 2010 : Panelist : John Blitzer , Walter Daelemans , Hal Daume , Jing Jiang , Khalil Sima'an .Check out our Workshop Program .June 11 , 2010 : Chairs added to the program .June 10 , 2010 : Title of invited keynote by John Blitzer : Unsupervised Domain Adaptation : From Practice to Theory .","label":"Future","metadata":{},"score":"54.18061"}
{"text":"Smoothing probabilities is most important for tasks with a limited amount of training material .We consider here the Btec task of the 2006 Iwslt evaluation .Improvements in all official automatic measures are reported when translating from Italian to English .","label":"Future","metadata":{},"score":"54.20717"}
{"text":"An analysis of a large corpus of annotated learner English confirms this assumption .We evaluate our approach on real - world learner data and show that L1-induced paraphrases outperform traditional approaches based on edit distance , homophones , and WordNet synonyms . ... where f denotes a foreign phrase in the L1 language .","label":"Future","metadata":{},"score":"54.264023"}
{"text":"Background Preliminary experiments In - domain study Modeling accuracy loss for cross - domain SC Cross - domain experiments Graph - based algorithmsFeature selection Filtering of features worsen the accuracy for all domains .Background Preliminary experiments In - domain study Modeling accuracy loss for cross - domain SC Cross - domain experiments Graph - based algorithmsFeature selection Filtering of features worsen the accuracy for all domains .","label":"Future","metadata":{},"score":"54.320717"}
{"text":"Sentence compression holds promise for many applications ranging from summarisation to subtitle generation and information retrieval .The task is typically performed on isolated sentences without taking the surrounding context into account , even though most applications would operate over entire documents .","label":"Future","metadata":{},"score":"54.37233"}
{"text":"It was shown that richer domains with more rare words are more complex for SC .We also observed that the accuracy loss is higher in cross - domain settings when source domain is more complex than the target one .Leave - one - out - cross validation for the data set of 42 examples .","label":"Future","metadata":{},"score":"54.43593"}
{"text":"Three binary linear classifiers were trained to predict the existence of a preposition , etc , on unlabeled data and we used singular value decomposition to induce new features .During the training , the parser was trained with these additional features in addition to these described in ( McDonald et al . , 2005 ) .","label":"Future","metadata":{},"score":"54.447083"}
{"text":"Morphological analysis and disambiguation are crucial stages in a variety of natural language processing applications , especially when languages with complex morphology are concerned .We present a system which disambiguates the output of a morphological analyzer for Hebrew .It consists of several simple classifiers and a module which combines them under linguistically motivated constraints .","label":"Future","metadata":{},"score":"54.534355"}
{"text":"Evaluation on the ACE RDC corpora shows that our dynamic context - sensitive tree span is much more suitable for relation extraction than SPT and our tree kernel outperforms the state - of - the - art Collins and Duffy 's convolution tree kernel .","label":"Future","metadata":{},"score":"54.696022"}
{"text":"Mixtures of n - gram language models are investigated , which are obtained by clustering bilingual train - ing data according to different available human annotations , respectively , at the dialog level , turn level , and dialog act level .","label":"Future","metadata":{},"score":"54.727764"}
{"text":"Furthermore , even for domain - specific test sets , our approach works almost as well as dedicated domain - specific models and perfect classification . by Patrik Lambert , Holger Schwenk , Christophe Servan , Sadaf Abdul - rauf . \" ...","label":"Future","metadata":{},"score":"54.78567"}
{"text":"Takafumi Kanamori , Shohei Hido , Masashi Sugiyama , Bianca Zadrozny - Journal of Machine Learning Research , 2009 . \" ...We address the problem of estimating the ratio of two probability density functions , which is often referred to as the importance .","label":"Future","metadata":{},"score":"54.8312"}
{"text":"Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsLexical approaches Use of dictionaries of sentiment words with a given semantic orientation .Dictionaries are built either manually or ( semi-)automatically .","label":"Future","metadata":{},"score":"54.993042"}
{"text":"A common assumption in supervised learning is that the training and test input points follow the same probability distribution .However , this assumption is not fulfilled , e.g. , in interpolation , extrapolation , active learning , or classification with imbalanced data .","label":"Future","metadata":{},"score":"55.084503"}
{"text":"A common assumption in supervised learning is that the training and test input points follow the same probability distribution .However , this assumption is not fulfilled , e.g. , in interpolation , extrapolation , active learning , or classification with imbalanced data .","label":"Future","metadata":{},"score":"55.084503"}
{"text":"Abstract - This paper describes an approach for computing a consensus translation from the outputs of multiple machine translation ( MT ) systems .The consensus translation is computed by weighted majority voting on a confusion network , similarly to the well - established ROVER approach of Fiscus for combining speech recognition hypotheses .","label":"Future","metadata":{},"score":"55.139336"}
{"text":"DeSR implements an incremental deterministic Shift / Reduce parsing algorithm , using specific rules to handle non - projective dependencies .For the multilingual track we adopted a second order averaged perceptron and performed feature selection to tune a feature model for each language .","label":"Future","metadata":{},"score":"55.192833"}
{"text":"Under covariate shift , standard learning methods such as maximum likelihood estimation are no longer consistent - weighted variants according to the ratio of test and training input densities are consistent .Therefore , accurately estimating the density ratio , called the importance , is one of the key issues in covariate shift adaptation .","label":"Future","metadata":{},"score":"55.238594"}
{"text":"Part of speech tagging is a fundamental component in many NLP systems .When taggers developed in one domain are used in another domain , the performance can degrade considerably .We present a method for developing taggers for new domains without requiring POS annotated text in the new domain .","label":"Future","metadata":{},"score":"55.3138"}
{"text":"Background Domain similarity Preliminary experiments Domain complexity Modeling accuracy loss for cross - domain SC Model construction and validation Graph - based algorithmsMeasures of domain similarity χ2 taken from Corpus Linguistics where it was demonstrated to have the best correlation with the gold standard .","label":"Future","metadata":{},"score":"55.370827"}
{"text":"In particular , we present a novel method for combining morphological and distributional information for seed selection .Experimental results demonstrate that our approach works well for English and Bengali , thus providing suggestive evidence that it is applicable to both morphologically impoverished langauges and highly inflectional langauges .","label":"Future","metadata":{},"score":"55.427704"}
{"text":"T Þ. Finally , in the unsupervised transfer learning setting , similar to inductive transfer learning setting , the target task is different from but related to the source ... . \" ...Traditional machine learning makes a basic assumption : the training and test data should be under the same distribution .","label":"Future","metadata":{},"score":"55.50228"}
{"text":"Background Comparison Preliminary experiments Document similarity Modeling accuracy loss for cross - domain SC Strategy for choosing the best parameters Graph - based algorithmsDocument representation We consider 2 types of document representation : feature - based , that involves weighted document features .","label":"Future","metadata":{},"score":"55.873856"}
{"text":"Background Comparison Preliminary experiments Document similarity Modeling accuracy loss for cross - domain SC Strategy for choosing the best parameters Graph - based algorithmsDocument representation We consider 2 types of document representation : feature - based , that involves weighted document features .","label":"Future","metadata":{},"score":"55.873856"}
{"text":"The type - based models perform better than the models which use tokens for selecting the classes .Furthermore , the models which use the automatically acquired thesaurus entries produced the best results .The correlation for the thesaurus models is stronger than any of the individual features used in previous research on the same dataset .","label":"Future","metadata":{},"score":"55.97512"}
{"text":"It is generally acknowledged that the performance of rule - based machine translation ( RMBT ) systems can be greatly improved through domain - specic system adaptation .To that end , RBMT users often choose to invest signicant re - sources into the development of ad hoc MT dictionaries .","label":"Future","metadata":{},"score":"55.986046"}
{"text":"It is generally acknowledged that the performance of rule - based machine translation ( RMBT ) systems can be greatly improved through domain - specic system adaptation .To that end , RBMT users often choose to invest signicant re - sources into the development of ad hoc MT dictionaries .","label":"Future","metadata":{},"score":"55.986046"}
{"text":"Unknown words are a well - known hindrance to natural language applications .In particular , they drastically impact machine translation quality .An easy way out commercial translation systems usually offer their users is the possibility to add unknown words and their translations into a dedicated lexicon .","label":"Future","metadata":{},"score":"56.087215"}
{"text":"HashTBO made it possible to ship a trigram contextual speller in Microsoft Office 2007 .In morphologically rich languages , should morphological and syntactic disambiguation be treated sequentially or as a single problem ?We describe several efficient , probabilistically - interpretable ways to apply joint inference to morphological and syntactic disambiguation using lattice parsing .","label":"Future","metadata":{},"score":"56.10241"}
{"text":"We introduce a new smoothing method , dubbed Stupid Backoff , that is inexpensive to train on large data sets and approaches the quality of Kneser - Ney Smoothing as the amount of training data increases .We present an extension of phrase - based statistical machine translation models that enables the straight - forward integration of additional annotation at the word - level --- may it be linguistic markup or automatically generated word classes .","label":"Future","metadata":{},"score":"56.18137"}
{"text":"Our key assumption is that collocation errors are often caused by semantic similarity in the first language ( L1language ) of the writer .An analysis ... \" .We present a novel approach for automatic collocation error correction in learner English which is based on paraphrases extracted from parallel corpora .","label":"Future","metadata":{},"score":"56.412937"}
{"text":"The estimated domain ( sub - corpus ) specific language and translation models are used for the translation .The IWSLT05 Japanese to English evaluation set that we used in our experiments gave 2.7 points ( 52.4 to 55.1 ) higher Blue score using this method .","label":"Future","metadata":{},"score":"56.569183"}
{"text":"However , this assumption is not satisfied , for example , when the outside of the training region is extrapolated .The situation where the training input points and test input points follow different distributions while the conditional distribution of output values given input points is unchanged is called the covariate shift .","label":"Future","metadata":{},"score":"56.59935"}
{"text":"CITATION .Sinno Jialin Pan , Qiang Yang , \" A Survey on Transfer Learning \" , IEEE Transactions on Knowledge & Data Engineering , vol.22 , no .10 , pp .1345 - 1359 , October 2010 , doi:10.1109/TKDE.2009.191 .","label":"Future","metadata":{},"score":"56.921047"}
{"text":"We present experiments showing that multilingual , parallel text in Spanish , French , Russian , and Chinese can be utilized in this framework to improve translation performance on an Arabic - to - English task .Automatic word alignment is the problem of automatically annotating parallel text with translational correspondence .","label":"Future","metadata":{},"score":"56.981544"}
{"text":"The technology of opinion extraction allows users to retrieve and analyze people 's opinions scattered over Web documents .We define an opinion unit as a quadruple consisting of the opinion holder , the subject being evaluated , the part or the attribute in which it is evaluated , and the value of the evaluation that expresses a positive or negative assessment .","label":"Future","metadata":{},"score":"57.083878"}
{"text":"Our overall conclusion is that at least two measures , MI and PE , seem to differentiate MWEs from non - MWEs .We then investigate the influence of the size and quality of different corpora , using the BNC and the Web search engines Google and Yahoo .","label":"Future","metadata":{},"score":"57.101204"}
{"text":"d test distributions started gaining much attention very recently .The instance weighting approaches [ 25 , 18 , 5 ] try to re - weight each training example with Ptest(x ) and maximize the re - weighted log likelihood .Ptrain(x ) Another line o .. \" ...","label":"Future","metadata":{},"score":"57.11403"}
{"text":"[ 2 ] J. Blitzer , M. Dredze , and F. Pereira , \" Biographies , Bollywood , Boom - Boxes and Blenders : Domain Adaptation for Sentiment Classification , \" Proc .Ann .Meeting Assoc . for Computational Linguistics , pp .","label":"Future","metadata":{},"score":"57.2827"}
{"text":"The reordering approach improved the BLEU score for the MOSES system from 28.52 to 30.86 on the NIST 2006 evaluation data .We also conducted a series of experiments to analyze the accuracy and impact of different types of reordering rules .","label":"Future","metadata":{},"score":"57.289917"}
{"text":"For instance , self - training the Charniak parser alone was not effective for adaptation ( it has been common wisdom that self - training is generally not effective ) , but self - training with a re - ranker was surprisingly highly effective ( McClosky et al . , 2006 ) .","label":"Future","metadata":{},"score":"57.387505"}
{"text":"Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .They only determine parsing actions stepwisely by a trained classifier .To globally model parsing actions of all steps that are taken on the input sentence , we propose two kinds of probabilistic parsing action models that can compute the probability of the whole dependency tree .","label":"Future","metadata":{},"score":"57.4515"}
{"text":"TrAdaBoost allows users to utilize a small amount of newly labeled data to leverage the old data to construct a high - quality classification model for the new data .We show that this method can allow us to learn an accurate model using only a tiny amount of new data and a large amount of old data , even when the new data are not sufficient to train a model alone .","label":"Future","metadata":{},"score":"57.57044"}
{"text":"Example The laptop is great , it is extremely fast .The book is great , it is very engaging .Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsDiscussion Machine learning methods demonstrate a very good performance and when the size of the data is substantial they outperform lexical approaches .","label":"Future","metadata":{},"score":"57.764076"}
{"text":"The parser is evaluated on the OVIS and WSJ corpora , and shows improvements on efficiency , parse accuracy and testset likelihood .Friday , June 29 , 2007 .A lexical analogy is a pair of word - pairs that share a similar semantic relation .","label":"Future","metadata":{},"score":"57.773804"}
{"text":"for the Advancement of Artificial Intelligence ( AAAI ) Conf .Artificial Intelligence , July 2008 .[ 8 ] J. Blitzer , M. Dredze , and F. Pereira , \" Biographies , Bollywood , Boom - Boxes and Blenders : Domain Adaptation for Sentiment Classification , \" Proc .","label":"Future","metadata":{},"score":"57.80497"}
{"text":"The results of the experiments show that , contrary to Kübler et al .( 2006 ) , the question whether or not German is harder to parse than English remains undecided .In this paper , we study the problem of automatically segmenting written text into paragraphs .","label":"Future","metadata":{},"score":"57.95409"}
{"text":"The translation results show significant improvement of our approach over the out - domain and the naïve in - domain SMT systems . by Baskaran Sankaran , Majid Razmara , Atefeh Farzindar , Wael Khreich , Anoop Sarkar . \" ...Abstract .","label":"Future","metadata":{},"score":"57.968884"}
{"text":"Dictionaries are built either manually or ( semi-)automatically .Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsLexical approaches Use of dictionaries of sentiment words with a given semantic orientation .","label":"Future","metadata":{},"score":"58.080402"}
{"text":"To reduce the cost of training data construction , our method accepts training examples in which complete word - by - word alignment labels are missing , but instead only the boundaries of coordinated conjuncts are marked .We report promising empirical results in detecting and disambiguating coordinated noun phrases in the GENIA corpus , despite a relatively small number of training examples and minimal features are employed .","label":"Future","metadata":{},"score":"58.18274"}
{"text":"With the synthetic bilingual corpus , we can build an SMT system even if there is no real bilingual corpus .In our experiments using BLEU as a metric , the system achieves a relative improvement of 11.7 % over the best RBMT system that is used to produce the synthetic bilingual corpora .","label":"Future","metadata":{},"score":"58.231716"}
{"text":"317 - 332 , Sept. 2008 .[ 70 ] M.T. Rosenstein , Z. Marx , and L.P. Kaelbling , \" To Transfer or Not to Transfer , \" Proc .Conf .Neural Information Processing Systems ( NIPS ' 05 )","label":"Future","metadata":{},"score":"58.449997"}
{"text":"For review data ML approach performs better than lexical one when training and test data belong to the same domain .But it needs substantial amount of annotated data .Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsSemi - supervised and unsupervised approaches Require small amount of annotated data or no data at all .","label":"Future","metadata":{},"score":"58.466152"}
{"text":"The parser first identifies dependencies using a discriminative classifier and then labels those dependencies as a sequence labeling problem .The features for two stages are proposed .For four languages have different values of ROOT , we design some special features for ROOT labeler .","label":"Future","metadata":{},"score":"58.51258"}
{"text":"In order to compensate for the low recall , we used massive collection of HTML documents .Thus , we could prepare enough polar sentence corpus .This paper discusses automatic determination of case in Arabic .This task is a major source of errors in full diacritization of Arabic .","label":"Future","metadata":{},"score":"58.602535"}
{"text":"We participated in the CoNLL Shared Task-2007 and evaluated our system for ten languages .We got an average multilingual labeled attachment score of 74.54 % ( with 65.50 % being the average and 80.32 % the highest ) and an average multilingual unlabeled attachment score of 80.30 % ( with 71.13 % being the average and 86.55 % the highest ) .","label":"Future","metadata":{},"score":"58.647396"}
{"text":"Therefore , there is increasing interest in methods to perform an adaptation of the translation model .A p ... \" .Most of the freely available parallel data to train the translation model of a statistical machine translation system comes from very specific sources ( European parliament , United Nations , etc ) .","label":"Future","metadata":{},"score":"58.83228"}
{"text":"Yet SMT translation quality still obviously suffers from inaccurate lexical choice .In this paper , we address this problem by investigating a new strategy for integrating WSD into an SMT system , that performs fully phrasal multi - word disambiguation .","label":"Future","metadata":{},"score":"58.850845"}
{"text":"Our approach combines a set of hand - written patterns together with a probabilistic model .Because the patterns heavily utilize regular expressions , the pertinent tree structures are covered using a limited number of patterns .The probabilistic model is essentially a probabilistic context - free grammar ( PCFG ) approach with the patterns acting as the terminals in production rules .","label":"Future","metadata":{},"score":"58.921154"}
{"text":"For review data ML approach performs better than lexical one when training and test data belong to the same domain .Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsSupervised Machine Learning Learn sentiment phenomena from an annotated corpus .","label":"Future","metadata":{},"score":"59.100876"}
{"text":"We discuss the problem of active learning in linear regression scenarios .Traditional active ... \" .The goal of active learning is to determine the locations of training input points so that the generalization error is minimized .We discuss the problem of active learning in linear regression scenarios .","label":"Future","metadata":{},"score":"59.188927"}
{"text":"In this paper , we propose a new importance estima ... \" .We address the problem of estimating the ratio of two probability density functions , which is often referred to as the importance .The importance values can be used for various succeeding tasks such as covariate shift adaptation or outlier detection .","label":"Future","metadata":{},"score":"59.97279"}
{"text":"In order to incorporate HTML structure on the graph , three types of cliques are defined based on the HTML tree structure .We propose a method with Conditional Random Fields ( CRFs ) to categorize the nodes on the graph .","label":"Future","metadata":{},"score":"60.06952"}
{"text":"Recognizing polarity requires a list of polar words and phrases .For the purpose of building such lexicon automatically , a lot of studies have investigated ( semi- ) unsupervised method of learning polarity of words and phrases .In this paper , we explore to use structural clues that can extract polar sentences from Japanese HTML documents , and build lexicon from the extracted polar sentences .","label":"Future","metadata":{},"score":"60.168507"}
{"text":"Textual records of business - oriented conversations between customers and agents need to be analyzed properly to acquire useful business insights that improve productivity .For such an analysis , it is critical to identify appropriate textual segments and expressions to focus on , especially when the textual data consists of complete transcripts , which are often lengthy and redundant .","label":"Future","metadata":{},"score":"60.18656"}
{"text":"Abstract .State - of - the - art statistical NLP systems for a variety of tasks learn from labeled training data that is often domain specific .However , there may be multiple domains or sources of interest on which the system must perform .","label":"Future","metadata":{},"score":"60.265118"}
{"text":"As a test , we used MavenRank to identify the most influential members of the US Senate using data from the US Congressional Record and used committee ranking to evaluate the output .Our results show that MavenRank scores are largely driven by committee status in most topics , but can capture speaker centrality in topics where speeches are used to indicate ideological position instead of influence legislation .","label":"Future","metadata":{},"score":"60.5072"}
{"text":"Up to six state - of - the - art statistical phrase - based translation systems from different project partners were combined in the experiments .Significant improvements in translation quality from Spanish to English and from English to Spanish in comparison with the best of the individual MT systems were achieved under official evaluation conditions .","label":"Future","metadata":{},"score":"61.277718"}
{"text":"We learn our model using a Monte Carlo EM algorithm and present quantitative results validating the model .We present a maximally streamlined approach to learning HMM - based acoustic models for automatic speech recognition .In our approach , an initial monophone , single - Gaussian HMM is iteratively refined using a split - merge EM procedure which makes no assumptions about subphone structure or context - dependent structure and which uses only a single Gaussian per HMM state .","label":"Future","metadata":{},"score":"61.34835"}
{"text":"In the multilingual exercise of the CoNLL-2007 shared task ( Nivre et al.,2007 ) , our system obtains the best accuracy for English , and the second best accuracies for Basque and Czech .We present our system used in the CoNLL 2007 shared task on multilingual parsing .","label":"Future","metadata":{},"score":"62.23644"}
{"text":"Kullback - Leibler divergence ( DKL ) and its symmetric analogue Jensen - Shannon divergence ( DJS ) were borrowed from Information Theory .Background Domain similarity Preliminary experiments Domain complexity Modeling accuracy loss for cross - domain SC Model construction and validation Graph - based algorithmsMeasures of domain similarity χ2 taken from Corpus Linguistics where it was demonstrated to have the best correlation with the gold standard .","label":"Future","metadata":{},"score":"62.411842"}
{"text":"Given a prediction message , Crystal first identifies which party the message predicts to win and then aggregates prediction analysis results of a large amount of opinions to project the election results .We collect past election prediction messages from the Web and automatically build a gold standard .","label":"Future","metadata":{},"score":"62.503845"}
{"text":"We therefore especially encourage submissions on semi - supervised approaches of domain adaptation with a deep analysis of models , data and results , although we do not exclude papers on supervised adaptation .Invited speaker .John Blitzer , University of California at Berkeley , USA : Unsupervised Domain Adaptation : From Practice to Theory .","label":"Future","metadata":{},"score":"62.95917"}
{"text":"Query segmentation is the process of taking a user 's search - engine query and dividing the tokens into individual phrases or semantic units .Identification of these query segments can potentially improve both document retrieval precision , by first returning pages which contain the exact query segments , and document retrieval recall , by allowing query expansion or substitution via the segmented units .","label":"Future","metadata":{},"score":"63.174168"}
{"text":"The study on SA suggested that adjectives , verbs and adverbs are the main indicators of sentiment , so , we keep only unigrams and bigrams that contain those POS as features .Background Domain similarity Preliminary experiments Domain complexity Modeling accuracy loss for cross - domain SC Model construction and validation Graph - based algorithmsDomain similarity We are not interested in all terms but rather on those bearing sentiment .","label":"Future","metadata":{},"score":"63.781174"}
{"text":"All 109 final papers were allowed 9 pages plus bibliography .In a separate track , 22 specially designated short papers reported results in the CoNLL Shared Task competition , an annual tradition .9 of these were presented as short talks .","label":"Future","metadata":{},"score":"63.813477"}
{"text":"In deterministic approaches to this task , dependency trees are constructed by series of actions of attaching a bunsetsu chunk to one of the nodes in the tree being constructed .Conventional techniques select the node based on whether the new bunsetsu chunk and each node in the trees are in a parent - child relation or not .","label":"Future","metadata":{},"score":"64.08643"}
{"text":"The interpolated model achieves an absolute improvement of 0.0245 BLEU score ( 13.1 % relative ) as compared with the individual model trained on the real bilingual corpus .This paper investigates why the HMMs estimated by Expectation - Maximization ( EM ) produce such poor results as Part - of - Speech ( POS ) taggers .","label":"Future","metadata":{},"score":"64.22208"}
{"text":"Inclusions from other languages can be a significant source of errors for monolingual parsers .We show this for English inclusions , which are sufficiently frequent to present a problem when parsing German .We describe an annotation - free approach for accurately detecting such inclusions , and develop two methods for interfacing this approach with a state - of - the - art parser for German .","label":"Future","metadata":{},"score":"64.31658"}
{"text":"Additionally , we compare the maximum a - posteriori decision rule and the minimum Bayes risk decision rule .We show that not only from a theoretical point but also in terms of translation quality the minimum Bayes risk decision rule is preferable .","label":"Future","metadata":{},"score":"66.33595"}
{"text":"A careful error analysis suggests that when we account for annotation errors in the gold standard , the error rate drops to 0.9 % , with the hand - written rules outperforming the machine learning - based system .We present in this paper methods to improve HMM - based part - of - speech ( POS ) tagging of Mandarin .","label":"Future","metadata":{},"score":"68.61338"}
{"text":"The result is a solution of an optimisation problem .The process stops when convergence is achieved .Unlike RANK , OPTIM requires the closeness of initial sentiment values and output ones for unlabeled nodes .The last condition makes the OPTIM solution more stable .","label":"Future","metadata":{},"score":"68.994675"}
{"text":"Example lightweight +3 , good +4 , ridiculous -2 Lightweight , stores a ridiculous amount of books and good battery life .Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsSupervised Machine Learning Learn sentiment phenomena from an annotated corpus .","label":"Future","metadata":{},"score":"71.00605"}
{"text":"SentiWordNet does not provide good results for this task , probably due to high level of noise which comes from its automatic construction .SentiWordNet does not provide good results for this task , probably due to high level of noise which comes from its automatic construction .","label":"Future","metadata":{},"score":"71.34598"}
{"text":"There are 5 minutes allocated in between talks for changing speaker and as spare room .Due to the tight schedule , we strongly recommend each speaker to take no more than 22 minutes for the oral presentation .We advise a maximum of 22 slides .","label":"Future","metadata":{},"score":"71.46409"}
{"text":"Tags from Present Day English source text are projected to Middle English text using alignments on parallel Biblical text .We explore the use of multiple alignment approaches and a bigram tagger to reduce the noise in the projected tags .Finally , we train a maximum entropy tagger on the output of the bigram tagger on the target Biblical text and test it on tagged Middle English text .","label":"Future","metadata":{},"score":"71.89879"}
{"text":"Trigram language models are compessed using a Golomb coding method inspired by the original Unix spell program .Compression methods trade off space , time and accuracy ( loss ) .The proposed HashTBO method optimizes space at the expense of time and accuracy .","label":"Future","metadata":{},"score":"71.96752"}
{"text":"This paper presents a method for categorizing named entities in Wikipedia .In Wikipedia , an anchor text is glossed in a linked HTML text .We formalize named entity categorization as a task of categorizing anchor texts with linked HTML texts which glosses a named entity .","label":"Future","metadata":{},"score":"75.04659"}
{"text":"Units can be either sentences or words .PSP states for positive sentences percentage , PWP - for positive words percentage .Lexical approach was exploited to calculate semantic orientation of sentiment units with the use of SentiWordNet and SOCAL dictionary .","label":"Future","metadata":{},"score":"75.195305"}
{"text":"Example This is a great camera .A great amount of money was spent for promoting this camera .One might think this is a great camera .Well think again , because .....Rejection or advice ?Example Go read the book .","label":"Future","metadata":{},"score":"75.72738"}
{"text":"Saturday , June 30 , 2007 .In the last decade , there have been significant developments in the design of approximate randomized algorithms for high - dimensional data .These include : hashing - based algorithms for similarity search problems , computing succinct approximate \" sketches \" of high - dimensional objects , etc .","label":"Future","metadata":{},"score":"78.558945"}
{"text":"PDMM is an expansion of an existing probabilistic generative model : Parametric Mixture Model(PMM ) by hierarchical Bayes model .PMM models multiple - topic documents by mixing model parameters of each single topic with an equal mixture ratio .PDMM models multiple - topic documents by mixing model parameters of each single topic with mixture ratio following Dirichlet distribution .","label":"Future","metadata":{},"score":"81.680374"}
{"text":"Irony , humour .Example If you are reading this because it is your darling fragrance , please wear it at home exclusively and tape the windows shut .Generally positive words .However , it can not hold up .Background Preliminary experiments Introduction Modeling accuracy loss for cross - domain SC State - of - the - art research Graph - based algorithmsWhy challenging ?","label":"Future","metadata":{},"score":"87.51483"}
{"text":"Camera - ready papers length : 8 pages ( including references ) .April 11 , 2010 : Submission closed .April 4 , 2010 : Deadline extended to Sunday April 11 , 2010 - 23:59 CET .March 31 , 2010 : Final Call for papers published .","label":"Future","metadata":{},"score":"91.17381"}
{"text":"We describe how the proposed scheme can be used for this problem and report the results of the tests with real clinical data as well as compare them with existing literature . by Pyry Matikainen , Rahul Sukthankar , Martial Hebert , Pyry Matikainen , Rahul Sukthankar , Martial Hebert .","label":"Future","metadata":{},"score":"112.175316"}
