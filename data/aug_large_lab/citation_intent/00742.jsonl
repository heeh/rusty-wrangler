{"text":"This training can be carried out on either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .This set of techniques requires a training corpus which has already been disambiguated .","label":"Background","metadata":{},"score":"30.48794"}
{"text":"This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .","label":"Background","metadata":{},"score":"30.85223"}
{"text":"Unlike existing preordering models , we train feature - rich discriminative classifiers that directly predict the target - side word order .Our approach combines the strengths of lexical reordering and syntactic preordering models by performing long - distance reorderings using the structure of the parse tree , while utilizing a discriminative model with a rich set of features , including lexical features .","label":"Background","metadata":{},"score":"31.493698"}
{"text":"To improve their performance , most systems are able to return partial analyses if a full sentence analysis can not be obtained .Including both full and partial analyses , such parsers get about 65 % of syntactic structures correct .To compound the problem , if we are successful in parsing , we may get a very large number of parses for a single sentence if we rely on grammatical constraints alone .","label":"Background","metadata":{},"score":"31.735554"}
{"text":"This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on sbobet either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .","label":"Background","metadata":{},"score":"33.01783"}
{"text":"This paper presents a novel approach to the unsupervised learning of syntactic analyses of natural language text .Most previous work has focused on maximizing likelihood according to generative PCFG models .In contrast , we employ a simpler probabilistic model over trees based directly on constituent identity and linear context , and use an EM - like iterative procedure to induce structure .","label":"Background","metadata":{},"score":"33.814934"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky [ 13 ] .","label":"Background","metadata":{},"score":"34.098717"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky [ 13 ] .","label":"Background","metadata":{},"score":"34.098717"}
{"text":"Because each refinement introduces only limited complexity , both learning and inference can be done in an incremental fashion .In this dissertation , we describe several coarse - to - fine systems .In the domain of syntactic parsing , complexity is in the grammar .","label":"Background","metadata":{},"score":"34.416573"}
{"text":"We present methods to control the lexicon size when learning a Combinatory Categorial Grammar semantic parser .Existing methods incrementally expand the lexicon by greedily adding entries , considering a single training datapoint at a time .We propose using corpus - level statistics for lexicon learning decisions .","label":"Background","metadata":{},"score":"34.513"}
{"text":"In addition , our discriminative approach integrally admits features beyond local tree configurations .We present a multi - scale training method along with an efficient CKY - style dynamic program .On a variety of domains and languages , this method produces the best published parsing accuracies with the smallest reported grammars .","label":"Background","metadata":{},"score":"34.63405"}
{"text":"A prerequisite for developing broad coverage parsers for more languages is the annotation of text with the desired linguistic representations ( also known as \" treebanking \" ) .However , syntactic annotation is a labor in ... \" .Broad coverage , high quality parsers are available for only a handful of languages .","label":"Background","metadata":{},"score":"35.069695"}
{"text":"In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .This representation can then be applied to new instances in order to disambiguate them .","label":"Background","metadata":{},"score":"35.21125"}
{"text":"This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on .either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .","label":"Background","metadata":{},"score":"35.43814"}
{"text":"This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on .either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .","label":"Background","metadata":{},"score":"35.43814"}
{"text":"This factorization provides conceptual simplicity , straightforward opportunities for separately improving the component models , and a level of performance comparable to similar , non - factored models .Determining the semantic role of sentence constituents is a key task in determining sentence meanings lying behind a veneer of variant syntactic expression .","label":"Background","metadata":{},"score":"35.634525"}
{"text":"Syntactic parsing is a fundamental problem in computational linguistics and natural language processing .Traditional approaches to parsing are highly complex and problem specific .Recently , Sutskever et al .( 2014 ) presented a task - agnostic method for learning to map input sequences to output sequences that achieved strong results on a large scale machine translation problem .","label":"Background","metadata":{},"score":"35.9886"}
{"text":"Transformation - based learning creates a set of possible transformations ( transformation templates ) .Starting with the initial tag assignments ( of the most common part of speech for each word ) , we try all possible transformations , and select the one which produces the maximum improvement in accuracy ( measured against a hand - tagged corpus ) .","label":"Background","metadata":{},"score":"36.14656"}
{"text":"This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .","label":"Background","metadata":{},"score":"36.474655"}
{"text":"This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .","label":"Background","metadata":{},"score":"36.474655"}
{"text":"This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .","label":"Background","metadata":{},"score":"36.474655"}
{"text":"Consequently , advances in this field could facilitate progress towards strong AI and yield understanding of how computers - and possibly humans - can learn in the absence of explicit feedback .One way to guide a language learning process is by starting from very short sentences , whose parse trees can be easily guessed , then gradually incorporating longer inputs .","label":"Background","metadata":{},"score":"36.554646"}
{"text":"It could play a key role in NLP tasks like Information Extraction , Question Answering and Summarization .We propose a machine learning algorithm for semantic role parsing , extending the work of Gildea and Jurafsky ( 2002 ) , Surdeanu et al .","label":"Background","metadata":{},"score":"36.58087"}
{"text":"Nonetheless , the resulting grammars encode many linguistically interpretable patterns and give the best published parsing accuracies on three German treebanks .We demonstrate that log - linear grammars with latent variables can be practically trained using discriminative methods .Central to efficient discriminative training is a hierarchical pruning procedure which allows feature expectations to be efficiently approximated in a gradient - based procedure .","label":"Background","metadata":{},"score":"36.902454"}
{"text":"The model is formally a latent variable CRF grammar over trees , learned by iteratively splitting grammar productions ( not categories ) .Different regions of the grammar are refined to different degrees , yielding grammars which are three orders of magnitude smaller than the single - scale baseline and 20 times smaller than the split - and - merge grammars of Petrov et al .","label":"Background","metadata":{},"score":"36.991825"}
{"text":"Our best results show a 26-fold speedup compared to a sequential C implementation .We present a simple method for transferring dependency parsers from source languages with labeled training data to target languages without labeled training data .We first demonstrate that delexicalized parsers can be directly transferred between languages , producing significantly higher accuracies than unsupervised parsers .","label":"Background","metadata":{},"score":"37.43271"}
{"text":"Specifically , an ini- tial hypothesis lattice is constrcuted using local features .Candidate sentences are then assigned syntactic language model scores .These global syntactic scores are combined with local low - level scores in a log - linear model .","label":"Background","metadata":{},"score":"37.525963"}
{"text":"In particular , it may be convenient to state them in terms of finite state patterns , which makes recognition very fast .The downside is that , because they do not provide as much syntactic structure , they leave more work for subsequent ( semantic ) processing to do .","label":"Background","metadata":{},"score":"37.553772"}
{"text":"First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar without a treebank .In our experiments , hierarchical pruning greatly accelerates parsing with no loss in empirical accuracy .","label":"Background","metadata":{},"score":"37.67352"}
{"text":"Our method does not assume any knowledge about the target language ( in particular no tagging dictionary is assumed ) , making it applicable to a wide array of resource - poor languages .We use graph - based label propagation for cross - lingual knowledge transfer and use the projected labels as features in an unsupervised model ( Berg - Kirkpatrick et al .","label":"Background","metadata":{},"score":"38.0312"}
{"text":"This paper investigates the role of resource allocation as a source of processing difficulty in human sentence comprehension .This proposal subsumes and clarifies findings that high - constraint contexts can facilitate lexical processing , and connects these findings to well - known models of parallel constraint - based comprehension .","label":"Background","metadata":{},"score":"38.11718"}
{"text":"In particular , we introduce set - valued features to encode the predicted morphological properties and part - of - speech confusion sets of the words being parsed .We also investigate the use of joint parsing and part - of - speech tagging in the neural paradigm .","label":"Background","metadata":{},"score":"38.239395"}
{"text":"( Or both . )To the extent that we are successful we will have an analyzer which will be relatively fast ( because it is making deterministic choices ) and robust with respect to variations in global grammatical structure ( since we are relying more heavily on local clues ) .","label":"Background","metadata":{},"score":"38.670006"}
{"text":"We highlight the use of this resource via two experiments , including one that reports competitive accuracies for unsupervised grammar induction without gold standard part - of - speech tags .We present an online learning algorithm for training structured prediction models with extrinsic loss functions .","label":"Background","metadata":{},"score":"38.915905"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .","label":"Background","metadata":{},"score":"39.007324"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .","label":"Background","metadata":{},"score":"39.007324"}
{"text":"Previous sentence segmentation systems have typically been very local , using low - level prosodic and lexical features to independently decide whether or not to segment at each word boundary position .In this work , we leverage global syntactic information from a syn- tactic parser , which is better able to capture long distance depen- dencies .","label":"Background","metadata":{},"score":"39.132576"}
{"text":"To achieve these results we need to mitigate the lack of domain knowledge in the model by providing it with a large amount of automatically parsed data .We extend and improve upon recent work in structured training for neural network transition - based dependency parsing .","label":"Background","metadata":{},"score":"39.14071"}
{"text":"Automatically summarizing vast amounts of on - line quantitative data with a short natural language paragraph has a wide range of real - world applications .However , this specific task raises a number of difficult issues that are quite distinct from the generic task of language generation : conciseness , ... \" .","label":"Background","metadata":{},"score":"39.215816"}
{"text":"The advantages and disadvantages of these systems are examined , including precision / recall trade - offs , error analysis , and extensibility .The same categorical phenomena which are attributed to hard grammatical constraints in some languages continue to show up as statistical preferences in other languages , motivating a grammatical model that can account for soft constraints .","label":"Background","metadata":{},"score":"39.352104"}
{"text":"We also show that our techniques can be applied to full - scale parsing applications by demonstrating its effectiveness in learning state - split grammars .Treebank parsing can be seen as the search for an optimally refined grammar consistent with a coarse training treebank .","label":"Background","metadata":{},"score":"39.608604"}
{"text":"For example , noun phrases might be split into subcategories for subjects and objects , singular and plural , and so on .This splitting process admits an efficient incremental inference scheme which reduces parsing times by orders of magnitude .Furthermore , it produces the best parsing accuracies across an array of languages , in a fully language - general fashion .","label":"Background","metadata":{},"score":"39.616234"}
{"text":"Unlike previous work on projecting syntactic resources , we show that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers .The projected parsers from our system result in state - of - the - art performance when compared to previously studied unsupervised and projected parsing systems across eight different languages .","label":"Background","metadata":{},"score":"39.821644"}
{"text":"This yields a series of transformations which can be used to tag new text .There is a trade - off between the size of the space of possible transformation and the training time ... allowing a larger space can improve potential performance but greatly slow down training .","label":"Background","metadata":{},"score":"39.945328"}
{"text":"We present a system for deciding whether a given sentence can be inferred from text .Each sentence is represented as a directed graph ( extracted from a dependency parser ) in which the nodes represent words or phrases , and the links represent syntactic and semantic relationships .","label":"Background","metadata":{},"score":"39.947723"}
{"text":"Second , how can we efficiently infer optimal structures within them ?Hierarchical coarse - to - fine methods address both questions .Coarse - to - fine approaches exploit a sequence of models which introduce complexity gradually .At the top of the sequence is a trivial model in which learning and inference are both cheap .","label":"Background","metadata":{},"score":"40.018074"}
{"text":"However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .This set of techniques requires a training corpus which has already been disambiguated .","label":"Background","metadata":{},"score":"40.23683"}
{"text":"Unlike previous work , our final model does not require any additional resources at run - time .Compared to a state - of - the - art approach , we achieve more than 20 % relative error reduction .Additionally , we annotate a corpus of search queries with part - of - speech tags , providing a resource for future work on syntactic query analysis .","label":"Background","metadata":{},"score":"40.270855"}
{"text":"The annotations are produced automatically with statistical models that are specifically adapted to historical text .The corpus will facilitate the study of linguistic trends , especially those related to the evolution of syntax .Syntactic analysis of search queries is important for a variety of information- retrieval tasks ; however , the lack of annotated data makes training query analysis models difficult .","label":"Background","metadata":{},"score":"40.301224"}
{"text":"Because of the sparseness of counts of such dependencies , smoothing and the ability to use multiple sources of knowledge are important challenges .( shrink ) .Unsupervised grammar induction systems commonly judge potential constituents on the basis of their effects on the likelihood of the data .","label":"Background","metadata":{},"score":"40.49016"}
{"text":"However , this specific task raises a number of difficult issues that are quite distinct from the generic task of language generation : conciseness , complex sentences , floating concepts , historical background , paraphrasing power and implicit content .This model requires a new type of linguistic knowledge : revision operations , which specifyies the various ways a draft can ... . \" ...","label":"Background","metadata":{},"score":"40.732918"}
{"text":"Unfortunately , existing algorithms are both computationally intensive and difficult to implement .Previous algorithms are expensive due to two factors : the exponential number of rules that mus ... \" .Excellent results have been reported for DataOriented Parsing ( DOP ) of natural language texts ( Bod , 1993c ) .","label":"Background","metadata":{},"score":"40.94737"}
{"text":"4 , 35 - -56 ( 1990 ) ] This is the case even if supervised training is used [ F. Pereira and Y. Schabes , in ACL ' 1992].Stochastic lexicalized tree - adjoining grammar ( SLTAG ) has been recently suggested as the basis for training algorithm [ Y. Schabes , in COLING ' 1992].","label":"Background","metadata":{},"score":"40.991913"}
{"text":"We are making deterministic choices , so we must try to determine the correct noun and verb groups ( for example ) without benefit of the constraints provided by the ' upper ' syntactic structure .This can be done by using a part - of - speech tagger to resolve part - of - speech ambiguities .","label":"Background","metadata":{},"score":"41.027367"}
{"text":"Experimental results are given , showing that the two new algorithms have improved performance over the Viterbi algorithm on many criteria , especially the ones that they optimize . \" ...This paper investigates the role of resource allocation as a source of processing difficulty in human sentence comprehension .","label":"Background","metadata":{},"score":"41.05549"}
{"text":"However , syntactic annotation is a labor intensive and time - consuming process , and it is difficult to find linguistically annotated text in sufficient quantities .In this article , we explore using parallel text to help solving the problem of creating syntactic annotation in more languages .","label":"Background","metadata":{},"score":"41.24543"}
{"text":"We present experiments with sequence models on part - of - speech tagging and named entity recognition tasks , and with syntactic parsers on dependency parsing and machine translation reordering tasks .Low - latency solutions for syntactic parsing are needed if parsing is to become an integral part of user - facing natural language applications .","label":"Background","metadata":{},"score":"41.35634"}
{"text":"We present results on the Recognizing Textual Entailment dataset ( Dagan et al . , 2005 ) , ( ... ) and show that our approach outperforms Bag- Of - Words and TF - IDF models .( shrink ) .While symbolic parsers can be viewed as deduction systems , this view is less natural for probabilistic parsers .","label":"Background","metadata":{},"score":"41.44968"}
{"text":"Previous algorithms are expensive due to two factors : the exponential number of rules that must be generated and the use of a Monte Carlo p arsing algorithm .In this paper we solve the first problem by a novel reduction of the DOP model toga small , equivalent probabilistic context - free grammar .","label":"Background","metadata":{},"score":"41.561592"}
{"text":"We present a nonparametric Bayesian model of tree structures based on the hierarchical Dirichlet process ( HDP ) .Our HDP - PCFG model allows the complexity of the grammar to grow as more training data is available .In addition to presenting a fully Bayesian model for the PCFG , we also develop an efficient variational inference procedure .","label":"Background","metadata":{},"score":"41.861176"}
{"text":"Each stage will make use of the analysis performed by the previous stages .Partial Parsers : Strategies ...Symbolic Learners .Each stage of analysis can be performed either by symbolic rules ( typically , finite - state patterns ) or by a probabilistic model ( such as an HMM ) .","label":"Background","metadata":{},"score":"41.87125"}
{"text":"This process entails identifying groups of words in a sentence ... \" .The natural language processing community has recently experienced a growth of interest in domain independent shallow semantic parsing - the process of assigning a WHO did WHAT to WHOM , WHEN , WHERE , WHY , HOW etc . structure to plain text .","label":"Background","metadata":{},"score":"41.9261"}
{"text":"Our methods result in state - of - the - art performance on the task of executing sequences of natural language instructions , achieving up to 25 % error reduction , with lexicons that are up to 70 % smaller and are qualitatively less noisy .","label":"Background","metadata":{},"score":"42.072735"}
{"text":"We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .Starting with a simple Xbar grammar , we learn a new grammar whose nonterminals are subsymbols of the original nonterminals .","label":"Background","metadata":{},"score":"42.243774"}
{"text":"In our approach ... \" .In this paper we present a general parsing strategy that arose from the development of an Earicy - type parsing algorithm for TAGs ( Schabes and Joshi 1988 ) and from recent linguistic work in TAGs ( Abeille 1988 ) .","label":"Background","metadata":{},"score":"42.51994"}
{"text":"We show that the automatically induced latent variable grammars of Petrov et al .2006 vary widely in their underlying representations , depending on their EM initialization point .We use this to our advantage , combining multiple automatically learned grammars into an unweighted product model , which gives significantly improved performance over state - of - the - art individual grammars .","label":"Background","metadata":{},"score":"42.701324"}
{"text":"The resulting grammars are extremely compact com- pared to other high - performance parsers , yet the parser gives the best published accuracies on several languages , as well as the best generative parsing numbers in English .In addi- tion , we give an associated coarse - to - fine inference scheme which vastly improves inference time with no loss in test set accuracy .","label":"Background","metadata":{},"score":"42.85084"}
{"text":"This partitions local subtrees of depth one ( corresponding to CFG rules ) into left and right contexts ( relative to head ) .The annotation al .. \" ...Interactive spoken dialogue provides many new challenges for natural language understanding systems .","label":"Background","metadata":{},"score":"43.030663"}
{"text":"Parsing algorithms can be represented directly as deduction systems , and a single deduction engine can interpret such deduction systems so as to implement the corresponding parser .The method generaliz ... \" .We present a system for generating parsers based directly on the metaphor of parsing as deduction .","label":"Background","metadata":{},"score":"43.044796"}
{"text":"Our research further demonstrates the breadth of the applicability of neural network methods to dependency parsing , as well as the ease with which new features can be added to neural parsing models .We present structured perceptron training for neural network transition - based dependency parsing .","label":"Background","metadata":{},"score":"43.26877"}
{"text":"What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .An example of this is the dynamic matching technique [ 10 ] which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .","label":"Background","metadata":{},"score":"43.56163"}
{"text":"What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .An example of this is the dynamic matching technique [ 10 ] which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .","label":"Background","metadata":{},"score":"43.56163"}
{"text":"Beyond the \" core grammar \" generally discussed by linguists , there are a large number of relatively rare constructs .If we simply add productions for all these rare constructs , they end up ' firing ' when we do n't want them , producing lots of bad parses .","label":"Background","metadata":{},"score":"43.66271"}
{"text":"Despite its simplicity , a product of eight automatically learned grammars improves parsing accuracy from 90.2 % to 91.8 % on English , and from 80.3 % to 84.5 % on German .Pruning can massively accelerate the computation of feature expectations in large models .","label":"Background","metadata":{},"score":"43.983253"}
{"text":"An example of this is the dynamic matching techniqueRadford et al .( 1996 ) which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .A similarity matrix is thus formed which is subject to cluster analysis to determine groups of semantically related instances of terms .","label":"Background","metadata":{},"score":"44.188896"}
{"text":"An example of this is the dynamic matching techniqueRadford et al .( 1996 ) which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .A similarity matrix is thus formed which is subject to cluster analysis to determine groups of semantically related instances of terms .","label":"Background","metadata":{},"score":"44.188896"}
{"text":"Combining multiple grammars that were self - trained on disjoint sets of unlabeled data results in a final test accuracy of 92.5\\% on the WSJ test set and 89.6\\% on our Broadcast News test set .This work shows how to improve state - of - the - art monolingual natural language processing models using unannotated bilingual text .","label":"Background","metadata":{},"score":"44.24205"}
{"text":"By allowing instance - level constraints to have spacelevel inductive implications , we are able to successfully incorporate constraints for a wide range of data set types .Our method greatly improves on the previously studied constrained -means algorithm , generally requiring less than half as many constraints to achieve a given accuracy on a range of real - world data , while also being more robust when over - constrained .","label":"Background","metadata":{},"score":"44.25815"}
{"text":"Our algorithm is based on Support Vector Machines which we show give large improvement in performance over earlier classifiers .We show performance improvements through a number of new features designed to improve generalization to unseen data , such as automatic clustering of verbs .","label":"Background","metadata":{},"score":"44.37232"}
{"text":"However , I conclude by suggesting that there are also limits to this process .The status of some words may not be able to be adequately captured by assigning them to one of a small number of categories .While conventions can be used in such cases to improve tagging consistency , they lack a strong linguistic basis .","label":"Background","metadata":{},"score":"44.40342"}
{"text":"use large lexicons ( generally machine readable dictionaries ) and the information associated with the senses ( such as part - of - speech tags , topical guides and selectional preferences ) to indicate the correct sense .Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .","label":"Background","metadata":{},"score":"44.737034"}
{"text":"use large lexicons ( generally machine readable dictionaries ) and the information associated with the senses ( such as part - of - speech tags , topical guides and selectional preferences ) to indicate the correct sense .Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .","label":"Background","metadata":{},"score":"44.737034"}
{"text":"We present several models to this end ; in particular a partially observed conditional random field model , where coupled token and type constraints provide a partial signal for training .Averaged across eight previously studied Indo - European languages , our model achieves a 25 % relative error reduction over the prior state of the art .","label":"Background","metadata":{},"score":"44.779236"}
{"text":"We compare distributionally induced and actual part - of - speech tags as input data , and examine extensions to the basic ( ... ) model .We discuss errors made by the system , compare the system to previous models , and discuss upper bounds , lower bounds , and stability for this task .","label":"Background","metadata":{},"score":"44.79013"}
{"text":"Early proposals of language models such as Markov models , N - gram models [ C. E. Shannon , Bell Syst .Tech .J. 27(3 ) , 379 - -423 ( 1948 ) ] although efficient in practice , have been quickly refuted in theory since they are unable to capture long distance dependencies or to describe hierarchically the syntax of natural languages .","label":"Background","metadata":{},"score":"44.840324"}
{"text":"A second model then attempts to improve upon this initial ranking , using additional features of the tree as evidence .The strength of our approach is that it allows a tree to be represented as an arbitrary set of features , without concerns about how these features interact or overlap and without the need to define a derivation or a generative model which takes these features into account .","label":"Background","metadata":{},"score":"45.203022"}
{"text":"The words that are replaced or repeated are no longer part of the intended utterance , and so need to be identified .Segmenting turns and resolving repairs are strongly intertwined with a third task : identifying discourse markers .Because of the interactions , and interactions with POS tagging and speech recognition , we need to address these tasks together and early on in the processing stream .","label":"Background","metadata":{},"score":"45.24817"}
{"text":"We discuss our background assumptions , describe an initial study on the \" projectability \" of syntactic relations , and then present two experiments in which stochastic parsers are developed with minimal human intervention via projection from English .4 The parallel corpus is aligned at the word level using the GIZA++ implementation of the IBM statistical translation models ( Brown et al . ... . by Sameer Pradhan , Kadri Hacioglu , Valerie Krugler , Wayne Ward , James H. Martin , Daniel Jurafsky , 2005 . \" ...","label":"Background","metadata":{},"score":"45.332596"}
{"text":"In Proceedings of the 14th International Conference on Computational Linguistics ( COLING-92 ) , pages 454 - 460 , Nantes , France , 1992 .This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .","label":"Background","metadata":{},"score":"45.5502"}
{"text":"The base parser produces a set of candidate parses for each input sentence , with associated probabilities that define an initial ranking of these parses .A second model then attempts to improve upon this i ... \" .This article considers approaches which rerank the output of an existing probabilistic parser .","label":"Background","metadata":{},"score":"45.749325"}
{"text":"Latent variable grammars take an observed ( coarse ) treebank and induce more fine - grained grammar categories , that are better suited for modeling the syntax of natural languages .Estimation can be done in a generative or a discriminative framework , and results in the best published parsing accuracies over a wide range of syntactically divergent languages and domains .","label":"Background","metadata":{},"score":"45.752846"}
{"text":"Starting from a mono - phone model , we learn increasingly refined models that capture phone internal structures , as well as context - dependent variations in an automatic way .Our approaches reduces error rates compared to other baseline approaches , while streamlining the learning procedure .","label":"Background","metadata":{},"score":"45.845726"}
{"text":"Unsupervised parsing is thus an important research direction .This kind of structure learning is a hard basic research problem : after decades of efforts , objective performance evaluation numbers are still unacceptably low , at least according to supervised metrics .","label":"Background","metadata":{},"score":"46.04882"}
{"text":"Finally , we present multilingual experiments which show that parsing with hierarchical state - splitting is fast and accurate in multiple languages and domains , even without any language - specific tuning .This work describes systems for detecting semantic categories present in news video .","label":"Background","metadata":{},"score":"46.05639"}
{"text":"State - of - the - art natural language processing models are anything but compact .Syntactic parsers have huge grammars , machine translation systems have huge transfer tables , and so on across a range of tasks .With such complexity come two challenges .","label":"Background","metadata":{},"score":"46.207787"}
{"text":"Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .","label":"Background","metadata":{},"score":"46.380486"}
{"text":"Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .","label":"Background","metadata":{},"score":"46.380486"}
{"text":"Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .","label":"Background","metadata":{},"score":"46.380486"}
{"text":"Good hand - written grammars / parsers can produce a full ( but not necessarily fully correct ) analysis of about 70 % of sentences for newspaper text ( the rate is considerably better for simpler and more uniform text , such as some types of manuals and other specialized texts ) .","label":"Background","metadata":{},"score":"46.43555"}
{"text":"In our method the first , monolingual view consists of supervised predictors learned separately for each language .The second , bilingual view consists of log - linear predictors learned over both languages on bilingual text .Our training procedure estimates the parameters of the bilingual model using the output of the monolingual model , and we show how to combine the two models to account for dependence between views .","label":"Background","metadata":{},"score":"46.585236"}
{"text":"Partial Parsers : Overview .How can we process unrestricted text without laboriously building such a complex grammar and parser ?One possibility is to do partial parsing ( J&M 10.5 ) : instead of building a full parse for each sentence , we just identify a few more basic structures , such as .","label":"Background","metadata":{},"score":"46.654068"}
{"text":"We reformulate the task as a combined chunking and classification problem , thus allowing our algorithm to be applied to new languages or genres of text for which statistical syntactic parsers may not be available . \" ...Probabilistic Context - Free Grammars ( PCFGs ) and variations on them have recently become some of the most common formalisms for parsing .","label":"Background","metadata":{},"score":"46.67687"}
{"text":"We apply our method to train parsers that excel when used as part of a reordering component in a statistical machine translation system .We use a corpus of weakly - labeled reference reorderings to guide parser training .Our best parsers contribute significant improvements in subjective translation quality while their intrinsic attachment scores typically regress .","label":"Background","metadata":{},"score":"46.764297"}
{"text":"The best setup correctly identifies 79 % of breaks in the test corpus .Â© 1998 Academic Press Limited 1 . ... cause syntactic parses themselves are unhelpful .These have been shown to significantly outperform rule - driven parsers .","label":"Background","metadata":{},"score":"46.776672"}
{"text":"We describe experiments on learning latent variable grammars for various German treebanks , using a language - agnostic statistical approach .In our method , a minimal initial grammar is hierarchically refined using an adaptive split - and - merge EM procedure , giving compact , accurate grammars .","label":"Background","metadata":{},"score":"47.047073"}
{"text":"This paper presents a new method for producing a dictionary of subcategorization frames from unlabelled text corpora .Further , it is argued that this method can be used to learn all subcategorization frames , whereas previous methods are not extensible to a general solution to the problem .","label":"Background","metadata":{},"score":"47.181225"}
{"text":"Our first- , second- , and third - order models achieve accuracies comparable to those of their unpruned counterparts , while exploring only a fraction of the search space .We observe speed - ups of up to two orders of magnitude compared to exhaustive search .","label":"Background","metadata":{},"score":"47.184616"}
{"text":"This paper presents an algorithm for automatically assigning phrase breaks to unrestricted text for use in a text - to - speech synthesizer .Text is first converted into a sequence of part - of - speech tags .Next a Markov model is used to give the most likely sequence of phrase breaks for the input part - of ... \" .","label":"Background","metadata":{},"score":"47.213852"}
{"text":"Empirically , we show that using Quadratic Extrapolation speeds up PageRank computation by 50- 300 % on a Web graph of 80 million nodes , with minimal overhead .( shrink ) .Grammatical theory has long wrestled with the fact that causative constructions exhibit properties of both single words and complex phrases .","label":"Background","metadata":{},"score":"47.240677"}
{"text":"It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .This lack of resources has led several researchers to explore the use of unannotated , raw , corpora to perform unsupervised disambiguation .","label":"Background","metadata":{},"score":"47.397892"}
{"text":"It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .This lack of resources has led several researchers to explore the use of unannotated , raw , corpora to perform unsupervised disambiguation .","label":"Background","metadata":{},"score":"47.397892"}
{"text":"Although the experiments in this article are on natural language parsing ( NLP ) , the approach should be applicable to many other NLP problems which are naturally framed as ranking tasks , for example , speech recognition , machine translation , or natural language generation . by Stuart M. Shieber , Yves Schabes , Fernando C. N. Pereira - JOURNAL OF LOGIC PROGRAMMING , 1995 . \" ...","label":"Background","metadata":{},"score":"47.505432"}
{"text":"A mixture grammar fit with the EM algorithm shows improvement over a single PCFG , both in parsing accuracy and in test data likelihood .We argue that this improvement comes from the learning of specialized grammars that capture non - local correlations .","label":"Background","metadata":{},"score":"47.636024"}
{"text":"Unlike ( Collins , 1999 ; Johnson , 2002 ) , in our approach resolution of LDDs is done at f - structure ( attribute - value structure representations of basic predicate - argument or dependency structure ) without empty productions , traces and coindexation in CFG parse trees . ... tation .","label":"Background","metadata":{},"score":"47.64821"}
{"text":"Words having no semantic tags ( determiners , prepositions , auxiliary verbs , etc . ) are ignored . constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .","label":"Background","metadata":{},"score":"47.729744"}
{"text":"Words having no semantic tags ( determiners , prepositions , auxiliary verbs , etc . ) are ignored . constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .","label":"Background","metadata":{},"score":"47.729744"}
{"text":"These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system [ 12 ] which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"47.95366"}
{"text":"These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system [ 12 ] which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"47.95366"}
{"text":"We evaluate the models by comparing their output to an established web directory .The generative model outperforms K - means with another 8 % F - score increase .( shrink ) .For such purposes , we argue that dependency schemes must follow a simple design and provide semantically contentful information , as well as offer an automatic procedure to extract the relations .","label":"Background","metadata":{},"score":"48.137657"}
{"text":"Methodologies in ontological semantics are sets of techniques and instructions for acquiring and .NLP - friendliness does not mean just an aspect of formality - it has also to do with literal friendliness ...Natural Language Parsing as Statistical Pattern Recognition ( 1994 ) .","label":"Background","metadata":{},"score":"48.70376"}
{"text":"Further , each lexical item is associated with as many supertags as the number of different syntactic contexts in which the lexical item can appear .This makes the number of different descriptions for each lexical item much larger , than when the descriptions are less complex ; thus increasing the local ambiguity for a parser .","label":"Background","metadata":{},"score":"48.92344"}
{"text":"Many named entities contain other named entities inside them .In this paper , we present a new technique for recognizing nested named entities , by using a discriminative constituency parser .To train the model , we transform each sentence into a tree , with constituents for each named entity ( and no other syntactic structure ) .","label":"Background","metadata":{},"score":"48.983154"}
{"text":"Text is first converted into a sequence of part - of - speech tags .Next a Markov model is used to give the most likely sequence of phrase breaks for the input part - of - speech tags .In the Markov model , states represent types of phrase break and the transitions between states represent the likelihoods of sequences of phrase types occurring .","label":"Background","metadata":{},"score":"49.142006"}
{"text":"These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .","label":"Background","metadata":{},"score":"49.21469"}
{"text":"These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .","label":"Background","metadata":{},"score":"49.21469"}
{"text":"These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .","label":"Background","metadata":{},"score":"49.21469"}
{"text":"These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .","label":"Background","metadata":{},"score":"49.21469"}
{"text":"These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .","label":"Background","metadata":{},"score":"49.21469"}
{"text":"These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .","label":"Background","metadata":{},"score":"49.21469"}
{"text":"[ 1 ] The problem is that words often have more than one meaning , sometimes fairly similar and sometimes completely different .The meaning of a word in a particular usage can only be determined by examining its context .This is , in general , a trivial task for the human language processing system , for example consider the following two sentences , each with a different sense of the word bank : .","label":"Background","metadata":{},"score":"49.507256"}
{"text":"[ 1 ] The problem is that words often have more than one meaning , sometimes fairly similar and sometimes completely different .The meaning of a word in a particular usage can only be determined by examining its context .This is , in general , a trivial task for the human language processing system , for example consider the following two sentences , each with a different sense of the word bank : .","label":"Background","metadata":{},"score":"49.507256"}
{"text":"Primary acoustic , speech , and vision systems were trained to discriminate instances of the categories .Higher - level systems exploited correlations among the categories , incorporated sequential context , and combined the joint evidence from the three information sources .","label":"Background","metadata":{},"score":"49.719627"}
{"text":"To appear in Journal of Natural Language Engineering , 4(3 ) .use large lexicons ( generally machine readable dictionaries ) and the information associated with the senses ( such as part - of - speech tags , topical guides and selectional preferences ) to indicate the correct sense .","label":"Background","metadata":{},"score":"50.19478"}
{"text":"To appear in Journal of Natural Language Engineering , 4(3 ) .use large lexicons ( generally machine readable dictionaries ) and the information associated with the senses ( such as part - of - speech tags , topical guides and selectional preferences ) to indicate the correct sense .","label":"Background","metadata":{},"score":"50.19478"}
{"text":"Learning symbolic rules has the benefit ( over probabilistic models ) that the results are inspectable and in some cases can even be improved based on linguistic insights .One of the most popular symbolic learners is Transformation - Based Learning , introduced by Brill .","label":"Background","metadata":{},"score":"50.32371"}
{"text":"The general problem with these methods is their reliance on disambiguated corpora which are expensive and difficult to obtain .This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .","label":"Background","metadata":{},"score":"50.408436"}
{"text":"The general problem with these methods is their reliance on disambiguated corpora which are expensive and difficult to obtain .This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .","label":"Background","metadata":{},"score":"50.408436"}
{"text":"[ 2 ] However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .","label":"Background","metadata":{},"score":"50.513813"}
{"text":"[ 2 ] However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .","label":"Background","metadata":{},"score":"50.513813"}
{"text":"The article also introduces a new algorithm for the boosting approach which takes advantage of the sparsity of the feature space in the parsing data .Experiments show significant efficiency gains for the new algorithm over the obvious implementation of the boosting approach .","label":"Background","metadata":{},"score":"50.898376"}
{"text":"By solving these simultaneously , we obtain better results on each task than addressing them separately .Our model is able to identify 72 % of turn - internal intonational boundaries with a precision of 71 % , 97 % of discourse markers with 96 % precision , and detect and correct 66 % of repairs with 74 % precision . .","label":"Background","metadata":{},"score":"51.005592"}
{"text":"In other words , it is an ideal research problem .To further this research agenda , data sets have been constructed to assess textual inference systems .This paper examines how the task of textual inference has been and should be defined and discusses what kind of evaluation data is appropriate for the task.1 .","label":"Background","metadata":{},"score":"51.223625"}
{"text":"It uses a phrase - based alignment representation , exploits external lexical resources , and capitalizes on ( ... ) a new set of supervised training data .We compare the performance of MANLI to existing NLI and MT aligners on an NLI alignment task over the well - known Recognizing Textual Entailment data .","label":"Background","metadata":{},"score":"51.236015"}
{"text":"In ontological semantics , a theory is viewed as a set of statements determining the format of descriptions of the phenomena with which the theory deals .A theory is associated with a methodology used to obtain the descriptions .Implementations are computer systems that use the descriptions to solve specific problems in text processing .","label":"Background","metadata":{},"score":"51.30349"}
{"text":"To manage this complexity , we translate into target language clusterings of increasing vocabulary size .This approach gives dramatic speed - ups while additionally increasing final translation quality .The intersection of tree transducer - based translation models with n - gram language models results in huge dynamic programs for machine translation decoding .","label":"Background","metadata":{},"score":"51.421623"}
{"text":"Unsupervised Parsing and Grammar Induction .Overview .Unsupervised parsing is the task of inducing syntactic structure from text , producing parse trees for input sentences and also a grammar - rules and their probabilities - that can be used to parse previously unseen data .","label":"Background","metadata":{},"score":"51.449024"}
{"text":"With 100 K unlabeled and 2 K labeled questions , uptraining is able to improve parsing accuracy to 84 % , closing the gap between in - domain and out - of - domain performance .We study self - training with products of latent variable grammars in this paper .","label":"Background","metadata":{},"score":"51.62151"}
{"text":"The English data can be grammatically analyzed within the stochastic OT framework ( Boersma 1998 , Boersma and Hayes 2001 ) in a way which provides a principled and unifying explanation for their relation to the crosslinguistic categorical person effects studied by Aissen ( 1999 ) .","label":"Background","metadata":{},"score":"51.638374"}
{"text":"Standard inference can be used at test time .Our approach is able to scale to very large problems and yields significantly improved target domain accuracy .It is well known that parsing accuracies drop significantly on out - of - domain data .","label":"Background","metadata":{},"score":"51.749435"}
{"text":"Reference ...ASA 124th Meeting New Orleans 1992 October . 3aSP2 .Statistical grammar inference .Yves Schabes .Dept . of Comput .Inform .Sci . , Univ . of Pennsylvania , Philadelphia , PA 19104 - 6389 .Language can be talked , written , printed , or encoded in numerous different ways .","label":"Background","metadata":{},"score":"51.847263"}
{"text":"Our generative self - trained grammars reach F scores of 91.6 on the WSJ test set and surpass even discriminative reranking systems without self - training .Additionally , we show that multiple self - trained grammars can be combined in a product model to achieve even higher accuracy .","label":"Background","metadata":{},"score":"51.936592"}
{"text":"3.3.3 Questions about Word Identities .Instead , we view the word identities as a further refinement of the POS tags .We start the clustering algorithm wit ... . ... ssible values of P w i c(w i i\\Gamman+1 ) are bucketed .","label":"Background","metadata":{},"score":"52.015366"}
{"text":"Ontological semantics is an integrated complex of theories , methodologies , descriptions and implementations .In ontological semantics , a theory is viewed as a set of statements determin ... \" .This book introduces ontological semantics , a comprehensive approach to the treatment of text meaning by computer .","label":"Background","metadata":{},"score":"52.08925"}
{"text":"We associate a pattern set name with a set of such pattern - action rules , and treat pat ( pattern - set - name ) as an annotator .As an example , we look at a small set of patterns to identify noun and verb groups .","label":"Background","metadata":{},"score":"52.17083"}
{"text":"this paper , we have proposed novel methods for robust parsing that integrate the flexibility of linguistically motivated lexical descriptions with the robustness of statistical techniques .Our thesis is that the computation of linguistic structure can be localized if lexical items are associated with rich descriptions ( Supertags ) that impose complex constraints in a local context .","label":"Background","metadata":{},"score":"52.229214"}
{"text":"The traditional use of these probabilities is to improve the probabilities of grammar rules .In this thesis we show that these values are useful for solving many other problems in Statistical Natural Language Processing .We give a framework for describing parsers .","label":"Background","metadata":{},"score":"52.30088"}
{"text":"We use both HMMs and hand - written finite - state rules in Jet , but have not incorporated any symbolic learners .JET : an Architecture for Cascaded Annotation .The design of Jet is typical of systems whose main model of processing is a cascade of analyzers , each of which adds some structural information to the text .","label":"Background","metadata":{},"score":"52.327408"}
{"text":"Approaches .Knowledge based .Under this approach disambiguation is carried out using information from an explicit lexicon or knowledge base .The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet [ 5 ] and LDOCE [ 6 ] .","label":"Background","metadata":{},"score":"52.556904"}
{"text":"Approaches .Knowledge based .Under this approach disambiguation is carried out using information from an explicit lexicon or knowledge base .The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet [ 5 ] and LDOCE [ 6 ] .","label":"Background","metadata":{},"score":"52.556904"}
{"text":"Current approaches to semantic inference in question answering and textual entailment have approximated the entailment problem as that of computing the best alignment of the hypothesis to the text , using a locally decomposable matching score .( shrink ) .This report details experimental results of using stochastic disambiguation models for parsing sentences from the Redwoods treebank ( Oepen et al . , 2002 ) .","label":"Background","metadata":{},"score":"52.7867"}
{"text":"We extract LFG subcategorisation frames and paths linking LDD reentrancie ... \" .This paper shows how finite approximations of long distance dependency ( LDD ) resolution can be obtained automatically for wide - coverage , robust , probabilistic Lexical - Functional Grammar ( LFG ) resources acquired from treebanks .","label":"Background","metadata":{},"score":"52.87281"}
{"text":"Unification - based / constraint - based grammar formalisms : .Stuart M. Shieber .An Introduction to Unification - Based Approaches to Grammar , volume 4 of CSLI Lecture Notes Series .Center for the Study of Language and Information , Stanford , CA , 1986 .","label":"Background","metadata":{},"score":"52.975327"}
{"text":"Line 31 : .Line 31 : .An example of this is the dynamic matching techniqueRadford et al .( 1996 ) which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .","label":"Background","metadata":{},"score":"53.18687"}
{"text":"The algorithm uses a similarity graph to encourage similar n - grams to have similar POS tags .We demonstrate the efficacy of our approach on a domain adaptation task , where we assume that we have access to large amounts of unlabeled data from the target domain , but no additional labeled data .","label":"Background","metadata":{},"score":"53.24408"}
{"text":"However , most parsing algorithms , including the Viterbi algorithm , attempt to optimize the same metric , namely the probability of getting the correct labelled tree .By choosing a parsing algorithm appropriate for the evaluation metric , better performance can be achieved .","label":"Background","metadata":{},"score":"53.27045"}
{"text":"This representation can then be applied to new instances in order to disambiguate them .Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .","label":"Background","metadata":{},"score":"53.275513"}
{"text":"This representation can then be applied to new instances in order to disambiguate them .Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .","label":"Background","metadata":{},"score":"53.275513"}
{"text":"However , none of such proposals perform as well as the simpler Markov models because of the difficulty of capturing lexical information [ Jelinek et al . , Tech .Rep. RC 16374 ( 72684 ) , IBM , Yorktown Heights , NY 10598 ( 1990 ) ] [ K. Lari and S. J. Young , Comput .","label":"Background","metadata":{},"score":"53.34823"}
{"text":"In Proceedings of the Eighth International Workshop on Parsing Technologies , pages 171 - 182 , Nancy , France , April 2003 .Natural - language generation : .Stuart M. Shieber , Yves Schabes , and Fernando C. N. Pereira .","label":"Background","metadata":{},"score":"53.678055"}
{"text":"Agent decision - making in open mixed networks .Artificial Intelligence , 174(18):1460 - 1480 , 2010 .Algorithms .Combinatorial optimization .Wheeler Ruml , J. Thomas Ngo , Joe Marks , and Stuart M. Shieber .Easily searched encodings for number partitioning .","label":"Background","metadata":{},"score":"53.76085"}
{"text":"Lecture 6 Outline .February 27 , 2003 .Facing reality : problems of grammatical coverage and ambiguity .Until the mid-90 's , the primary approach to developing a syntactic analyzer was to have linguists develop the necessary grammar and dictionary .","label":"Background","metadata":{},"score":"54.059814"}
{"text":"( shrink ) .We present a generative distributional model for the unsupervised induction of natural language syntax which explicitly models constituent yields and contexts .Parameter search with EM produces higher quality analyses than previously exhibited by unsupervised systems , giving the best published unsupervised parsing results on the ATIS corpus .","label":"Background","metadata":{},"score":"54.23472"}
{"text":"Decision lists [ 14 ] are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .The learning proceeds in this way until all corpus instances are classified .","label":"Background","metadata":{},"score":"54.254272"}
{"text":"Decision lists [ 14 ] are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .The learning proceeds in this way until all corpus instances are classified .","label":"Background","metadata":{},"score":"54.254272"}
{"text":"Moreover , including this model as a component in an existing system yields significant performance gains on the Recognizing Textual Entailment challenge .( shrink ) .We describe an approach to textual inference that improves alignments at both the typed dependency level and at a deeper semantic level .","label":"Background","metadata":{},"score":"54.288776"}
{"text":"It has a feature cat , which records the syntactic category , and may have other features , such as number .When we use the console to try a sentence , Jet creates a 1-line document and submits it for processing .","label":"Background","metadata":{},"score":"54.46052"}
{"text":"This paper presents empirical studies and closely corresponding theoretical models of the performance of a chart parser exhaustively parsing the Penn Treebank with the Treebank 's own CFG grammar .We show how performance is dramatically affected by rule representation and tree transformations , but little by top - down vs. bottom - up strategies .","label":"Background","metadata":{},"score":"54.51293"}
{"text":"Despite the much simplified training process , our acoustic model achieves state - of - the - art results on phone classification ( where it outperforms almost all other methods ) and competitive performance on phone recognition ( where it outperforms standard CD triphone / subphone / GMM approaches ) .","label":"Background","metadata":{},"score":"54.672142"}
{"text":"On the task of assigning semantic labels to the PropBank ( Kingsbury , Palmer , & Marcus , 2002 ) corpus , our final system has a precision of 84 % and a recall of 75 % , which are the best results currently reported for this task .","label":"Background","metadata":{},"score":"54.749947"}
{"text":"Machine translation : .Alex Kulesza and Stuart M. Shieber .A learning approach to improving sentence - level MT evaluation .In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation , Baltimore , MD , 4 - 6 October 2004 .","label":"Background","metadata":{},"score":"54.917023"}
{"text":"In three out of four sets of experiments , our model outperforms a standard semi - CRF on the more traditional top - level entities .( shrink ) .We greatly extend past work in natural logic , which has focused solely on semantic containment and monotonicity , to incorporate both semantic exclusion and implicativity .","label":"Background","metadata":{},"score":"55.10012"}
{"text":"Shalom Lappin and Stuart M. Shieber .Machine learning theory and practice as a source of insight into universal grammar .Journal of Linguistics , 43(2):393 - 427 , 2007 .Elif Yamangil and Stuart M. Shieber .Bayesian synchronous tree - substitution grammar induction and its application to sentence compression .","label":"Background","metadata":{},"score":"55.10458"}
{"text":"Computational Intelligence , 7(4):220 - 228 , 1992 .Tree - adjoining grammar : .Yves Schabes and Stuart M. Shieber .An alternative conception of tree - adjoining derivation .Computational Linguistics , 20(1):91 - 124 , 1994 .Stuart M. Shieber .","label":"Background","metadata":{},"score":"55.35368"}
{"text":"Another example is the work of Pedersen [ 11 ] who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .","label":"Background","metadata":{},"score":"55.7457"}
{"text":"Another example is the work of Pedersen [ 11 ] who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .","label":"Background","metadata":{},"score":"55.7457"}
{"text":"Stuart M. Shieber .Evidence against the context - freeness of natural language .Linguistics and Philosophy , 8:333 - 343 , 1985 .Reprinted in Walter J. Savitch , Emmon Bach , William Marsh , and Gila Safran - Navah , eds . , The Formal Complexity of Natural Language , pages 320 - 334 , Dordrecht , Holland : D. Reidel Publishing Company , 1987 .","label":"Background","metadata":{},"score":"55.781696"}
{"text":"French translation : Formalismes Syntaxiques pour le Traitement Automatique du Langage Naturel , Philip Miller and ThÃ©rÃ¨se Torris , editors , HermeÃ¨s , Paris , 1990 .[ bib ] .Stuart M. Shieber .Constraint - Based Grammar Formalisms .MIT Press , 1992 .","label":"Background","metadata":{},"score":"55.86255"}
{"text":"This is exactly the kind of constraint that integer linear programming ( ILP ) is ideal for , but , surprisingly , previous work applying ILP to coreference resolution has not encoded this type ( ... ) of constraint .We present results on two commonly used datasets which show that enforcement of transitive closure consistently improves performance , including improvements of up to 3.6 % using the b3 scorer , and up to 16.5 % using cluster f - measure .","label":"Background","metadata":{},"score":"56.24975"}
{"text":"We present a novel approach which employs a randomized sequence of pruning masks .Formally , we apply auxiliary variable MCMC sampling to generate this sequence of masks , thereby gaining theoretical guarantees about convergence .Because each mask is generally able to skip large portions of an underlying dynamic program , our approach is particularly compelling for high - degree algorithms .","label":"Background","metadata":{},"score":"56.318707"}
{"text":"These days WordNet is the usual dictionary in question .WSD has been investigated in computational linguistics as a specific task for well over 40 years , though the acronym is newer .Contents .One of the first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .","label":"Background","metadata":{},"score":"56.583435"}
{"text":"These days WordNet is the usual dictionary in question .WSD has been investigated in computational linguistics as a specific task for well over 40 years , though the acronym is newer .Contents .One of the first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .","label":"Background","metadata":{},"score":"56.583435"}
{"text":"The penalty for a recognition failure is often small : if two con- figurations are confused , they are often similar to each other , and the illusion works well enough , for instance , to drive a graphics animation of the moving hand .","label":"Background","metadata":{},"score":"56.849625"}
{"text":"Given this fixed network representation , we learn a final layer using the structured perceptron with beam - search decoding .On the Penn Treebank , our parser reaches 94.26 % unlabeled and 92.41 % labeled attachment accuracy , which to our knowledge is the best accuracy on Stanford Dependencies to date .","label":"Background","metadata":{},"score":"57.02275"}
{"text":"Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , [ 9 ] decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .","label":"Background","metadata":{},"score":"57.062668"}
{"text":"Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , [ 9 ] decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .","label":"Background","metadata":{},"score":"57.062668"}
{"text":"The best accuracies were in the 80 - 84\\% range for F1 and LAS ; even part - of - speech accuracies were just above 90\\% .Coarse - to - fine inference has been shown to be a robust approximate method for improving the efficiency of structured prediction models while preserving their accuracy .","label":"Background","metadata":{},"score":"57.08101"}
{"text":"Technology for local textual inference is central to producing a next generation of intelligent yet robust human language processing systems .One can think of it as Information Retrieval++ .But textual inference is ( ... ) useful more broadly .Textual inference is a difficult problem ( as the results from early evaluations have shown ) : current systems do statistically better than random guessing , but not by very much .","label":"Background","metadata":{},"score":"57.17816"}
{"text":"On full - scale treebank parsing experiments , the discriminative latent models outperform both the comparable generative latent models as well as the discriminative non - latent baselines .We present a maximally streamlined approach to learning HMM - based acoustic models for automatic speech recognition .","label":"Background","metadata":{},"score":"57.267006"}
{"text":"The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .To appear in Journal of Natural Language Engineering , 4(3 ) .Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .","label":"Background","metadata":{},"score":"57.386566"}
{"text":"The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .To appear in Journal of Natural Language Engineering , 4(3 ) .Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .","label":"Background","metadata":{},"score":"57.386566"}
{"text":"Participants were to build a single parsing system that is robust to domain changes and can handle noisy text that is commonly encountered on the web .There was a constituency and a dependency parsing track and 11 sites submitted a total of 20 systems .","label":"Background","metadata":{},"score":"57.711685"}
{"text":"DTG involve two composition operations called subsertion and sister - adjunction .The most distinctive feature of DTG is that , unlike TAG , there is complete uniformity in the way that the two DTG operatio ... \" .DTG are designed to share some of the advantages of TAG while overcoming some of its limitations .","label":"Background","metadata":{},"score":"57.73734"}
{"text":"This system reconciles abstract structure and concrete data in natural language processing since it is is lexically sensitive and yet hierarchical .The need for a lexical and still hierarchical statistical language model is partially corroborated by preliminary experiments which show that SLTAG enable better statistical modeling than its hierarchical counterpart , stochastic context - free grammars .","label":"Background","metadata":{},"score":"57.802597"}
{"text":"On sentences of length 40 , our system achieves an F - score of 89.0 % , a 36 % relative reduction in error over a generative baseline .( shrink ) .I examine what would be necessary to move part - of - speech tagging performance from its current level of about 97.3 % token accuracy ( 56 % sentence accuracy ) to close to 100 % accuracy .","label":"Background","metadata":{},"score":"57.8428"}
{"text":"Other written cues - such as capitalization and punctuation - also align well with syntactic structure in many languages , simplifying the grammar induction challenge .Tools . \" ...Tree - adjoining grammars ( TAG ) have been proposed as a formalism for generation based on the intuition that the extended domain of syntactic locality that TAGs provide should aid in localizing semantic dependencies as well , in turn serving as an aid to generation from semantic representations .","label":"Background","metadata":{},"score":"58.050194"}
{"text":"Eve ... \" .Interactive spoken dialogue provides many new challenges for natural language understanding systems .One of the most critical challenges is simply determining the speaker 's intended utterances : both segmenting a speaker 's turn into utterances and determining the intended words in each utterance .","label":"Background","metadata":{},"score":"58.184578"}
{"text":"The conclusions we will reach are given in ( 1 ) .( shrink ) .This paper separates conditional parameter estima- tion , which consistently raises test set accuracy on statistical NLP tasks , from conditional model struc- tures , such as the conditional Markov model used for maximum - entropy tagging , which tend to lower accuracy .","label":"Background","metadata":{},"score":"58.48159"}
{"text":", The editor .or No way ! ) ; and so on , building up to more sophisticated constructions at longer lengths .Divide - and - Conquer : Markup .The space of possible hidden structures of longer sentences can be constrained using various annotations that naturally occur in text .","label":"Background","metadata":{},"score":"58.549423"}
{"text":"Line 31 : .An example of this is the dynamic matching techniqueRadford et al .( 1996 ) which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .","label":"Background","metadata":{},"score":"58.58529"}
{"text":"The prospects for further gains from semisupervised learning also seem quite limited .Rather , I suggest and begin to demonstrate that the largest opportunity for further progress comes from improving the taxonomic basis of the linguistic resources from which taggers are trained .","label":"Background","metadata":{},"score":"58.644585"}
{"text":"In Lummi , for example , the person ( ... ) of the subject argument can not be lower than the person of a nonsubject argument .If this would happen in the active , passivization is obligatory ; if it would happen in the passive , the active is obligatory ( Jelinek and Demers 1983 ) .","label":"Background","metadata":{},"score":"58.67196"}
{"text":"( shrink ) .NER systems typically use sequence models for tractable inference , but this makes them unable to capture the long distance structure present in text .We use a Conbel .Discriminative feature - based methods are widely used in natural language processing , but sentence parsing is still dominated by generative methods .","label":"Background","metadata":{},"score":"58.85673"}
{"text":"Discussions .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .","label":"Background","metadata":{},"score":"59.001846"}
{"text":"Discussions .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .","label":"Background","metadata":{},"score":"59.001846"}
{"text":"A good example of this is Luk 's system A. Luk .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 . which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"59.11429"}
{"text":"A good example of this is Luk 's system A. Luk .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 . which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"59.11429"}
{"text":"( shrink ) .Solving the credit attribution problem requires associating each word in a document with the most appropriate tags and vice versa .This allows Labeled LDA to directly learn word - tag correspondences .We demonstrate Labeled LDA 's improved expressiveness over traditional LDA with visualizations of a corpus of tagged web pages from del.icio.us .","label":"Background","metadata":{},"score":"59.25525"}
{"text":"An experiment in semantic tagging using hidden markov model tagging .In Vossen , P. , Adriaens , G. , Calzolari , N. , Sanfilippo , A. , and Wilks , Y. , editors , Proceedings of the ACL / EACL'97 Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources .","label":"Background","metadata":{},"score":"59.514244"}
{"text":"An experiment in semantic tagging using hidden markov model tagging .In Vossen , P. , Adriaens , G. , Calzolari , N. , Sanfilippo , A. , and Wilks , Y. , editors , Proceedings of the ACL / EACL'97 Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources .","label":"Background","metadata":{},"score":"59.514244"}
{"text":"This ' universal ' treebank is made freely available in order to facilitate research on multilingual dependency parsing .We consider the construction of part - of - speech taggers for resource - poor languages .Recently , manually constructed tag dictionaries from Wiktionary and dictionaries projected via bitext have been used as type constraints to overcome the scarcity of annotated data in this setting .","label":"Background","metadata":{},"score":"59.639282"}
{"text":"adjacent phrases , but they typically lack the ability to perform the kind of long - distance reorderings possible with syntax - based systems .We show that this model can successfully handle the key examples often used to motivate syntax - based systems , such as the rotation of a prepositional phrase around a noun phrase .","label":"Background","metadata":{},"score":"60.123146"}
{"text":"Computational Intelligence , 10(4):371 - 385 , November 1994 .Computational semantics : .Jerry Hobbs and Stuart M. Shieber .An algorithm for generating quantifier scopings .Computational Linguistics , 13(1 - 2):47 - 63 , January - June 1987 .","label":"Background","metadata":{},"score":"60.154095"}
{"text":"It makes it easy to describe parsers that compute a wide variety of interesting quantities , including the inside and outside probabilities , as well as related quantities such as Viterbi probabilities and n - best lists .We also present three novel uses for the inside and outside probabilities .","label":"Background","metadata":{},"score":"60.259087"}
{"text":"The most distinctive feature of DTG is that , unlike TAG , there is complete uniformity in the way that the two DTG operations relate lexical items : subsertion always corresponds to complementation and sister - adjunction to modification .Furthermore , DTG , unlike TAG , can provide a uniform analysis for whmovement in English and Kashmiri , despite the fact that the wh element in Kashmiri appears in sentence - second position , and not sentence - initial position as in English . \" ...","label":"Background","metadata":{},"score":"60.33824"}
{"text":"Ellipsis and higher - order unification .Linguistics and Philosophy , 14:399 - 452 , 1991 .Synchronous grammars : .Stuart M. Shieber .Restricting the weak - generative capacity of synchronous tree - adjoining grammars .Computational Intelligence , 10(4):371 - 385 , November 1994 .","label":"Background","metadata":{},"score":"60.594223"}
{"text":"Across various hierarchical encoding schemes and for multiple language pairs , we show speed - ups of up to 50 times over single - pass decoding while improving BLEU score .Moreover , our entire decoding cascade for trigram language models is faster than the corresponding bigram pass alone of a bigram - to - trigram decoder .","label":"Background","metadata":{},"score":"60.606186"}
{"text":"Tree - adjoining grammars ( TAG ) have been proposed as a formalism for generation based on the intuition that the extended domain of syntactic locality that TAGs provide should aid in localizing semantic dependencies as well , in turn serving as an aid to generation from semantic representations .","label":"Background","metadata":{},"score":"60.88479"}
{"text":"When these probabilities are multiplied together and normalized , they produce the probabili ... \" .Probabilistic Context - Free Grammars ( PCFGs ) and variations on them have recently become some of the most common formalisms for parsing .It is common with PCFGs to compute the inside and outside probabilities .","label":"Background","metadata":{},"score":"61.12944"}
{"text":"One notable exception is Brill 's TransformationBased Error Driven system ( Brill , 1993 ) , which induces a set of transformations designed to maximize the Consistent ... . by Aoife Cahill , Michael Burke , Josef Van Genabith , Andy Way - In Proceedings of the 42nd Meeting of the ACL , 2004 . \" ...","label":"Background","metadata":{},"score":"61.233833"}
{"text":"To facilitate future research in unsupervised induction of syntactic structure and to standardize best - practices , we propose a tagset that consists of twelve universal part - of - speech categories .In addition to the tagset , we develop a mapping from 25 different treebank tagsets to this universal set .","label":"Background","metadata":{},"score":"61.328102"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Revision as of 03:31 , 25 June 2012 .Word Sense Disambiguation ( WSD ) is the process of identifying the sense of a polysemic word .","label":"Background","metadata":{},"score":"61.662914"}
{"text":"Across eight European languages , our approach results in an average absolute improvement of 10.4 % over a state - of - the - art baseline , and 16.7 % over vanilla hidden Markov models induced with the Expectation Maximization algorithm .","label":"Background","metadata":{},"score":"62.04053"}
{"text":"The theory of ontological semantics is built as a society of microtheories covering such diverse ground as specific language phenomena , world knowledge organization , processing heuristics and issues relating to knowledge representation and implementation system architecture .The theory briefly sketched above is a top - level microtheory , the ontological semantics theory per se .","label":"Background","metadata":{},"score":"62.053356"}
{"text":"Noun groups ( nouns with their left modifiers ) .Verb groups ( auxiliaries + head verb ) .The goal is to identify types of constructs which can be reliably identified based on local evidence .The constructs listed are relatively simple --- they are not recursive and avoid attachment ambiguity .","label":"Background","metadata":{},"score":"62.06893"}
{"text":"( shrink ) .We propose a model of natural language inference which identifies valid inferences by their lexical and syntactic features , without full semantic interpretation .We extend past work in natural logic , which has focused on semantic containment and monotonicity , by incorporating both semantic exclusion and implicativity .","label":"Background","metadata":{},"score":"62.856266"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Revision as of 04:20 , 25 June 2012 .Word Sense Disambiguation ( WSD ) is the process of identifying the sense of a polysemic word .","label":"Background","metadata":{},"score":"62.91416"}
{"text":"Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation .On the other hand , our grammars are much more compact and substantially more accurate than previous work on automatic annotation .Despite its simplicity , our best grammar achieves an F1 of 89.9 % on the Penn Treebank , higher than most fully lexicalized systems .","label":"Background","metadata":{},"score":"62.925537"}
{"text":"Using ithe optimizations , experiments yield a 97 % crossing brackets rate and 88 % zero crossing brackets rate .This differs significantly from the results reported by Bod , and is compara- ble to results from a duplication of Pereira and Schabes 's ( 1992 ) experiment on the same data .","label":"Background","metadata":{},"score":"62.944225"}
{"text":"( shrink ) .We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown , by making use of simple , linguistically motivated state splits , which break down false independence assumptions latent in a vanilla treebank grammar .","label":"Background","metadata":{},"score":"63.24161"}
{"text":"Multi - agent systems .Ya'akov Gal , Barbara J. Grosz , Avi Pfeffer , Stuart M. Shieber , and Alex Allain .The influence of task contexts on the decision - making of humans and computers .In Proceedings of the Sixth International and Interdisciplinary Conference on Modeling and Using Context , 2007 .","label":"Background","metadata":{},"score":"63.36477"}
{"text":"We show that dependency parsers have more difficulty parsing questions than constituency parsers .In particular , deterministic shift - reduce dependency parsers , which are of highest interest for practical applications because of their linear running time , drop to 60 % labeled accuracy on a question test set .","label":"Background","metadata":{},"score":"63.403942"}
{"text":"We have explored these ideas in the context of Lexicalized Tree - Adjoining Grammar ( LTAG ) framework .The supertags in LTAG combine both phrase structure information and dependency information in a single representation .Supertag disambiguation results in a representation that is effectively a parse ( almost parse ) , and the parser needs ' only ' combine the individual supertags .","label":"Background","metadata":{},"score":"63.595253"}
{"text":"The information in these resources has been used in several ways , for example Wilks and Stevenson Y. Wilks and M. Stevenson .The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .","label":"Background","metadata":{},"score":"63.66214"}
{"text":"The information in these resources has been used in several ways , for example Wilks and Stevenson Y. Wilks and M. Stevenson .The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .","label":"Background","metadata":{},"score":"63.66214"}
{"text":"Distinguishing word senses in untagged text .In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .","label":"Background","metadata":{},"score":"63.67144"}
{"text":"Distinguishing word senses in untagged text .In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .","label":"Background","metadata":{},"score":"63.67144"}
{"text":"Distinguishing word senses in untagged text .In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .","label":"Background","metadata":{},"score":"63.67144"}
{"text":"Distinguishing word senses in untagged text .In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .","label":"Background","metadata":{},"score":"63.67144"}
{"text":"We then apply a series of transformations to the corpus .Each transformation has the general form . if ( some condition on the previous and following tags ) then change the current tag from X to Y .the condition can take the form ' the previous tag is z ' , or ' the tag of the word 2 back is w ' , etc .","label":"Background","metadata":{},"score":"63.69969"}
{"text":"Central to Jet is the notion of an annotated document .The Document consists of a text ( which normally does not change ) and a set of annotations .Each annotation consists of a type , a span ( a start and end point in the document ) , and a set of zero or more features .","label":"Background","metadata":{},"score":"63.71574"}
{"text":"In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 .","label":"Background","metadata":{},"score":"64.53127"}
{"text":"In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 .","label":"Background","metadata":{},"score":"64.53127"}
{"text":"Linking constructions involving dá ( DE ) are ubiquitous in Chinese , and can be translated into English in many different ways .This is a major source of machine translation error , even when syntaxsensitive translation models are used .This paper explores how getting more information about the syntactic , semantic , and discourse context of uses of dá ( DE ) can facilitate producing an appropriate English translation strategy .","label":"Background","metadata":{},"score":"64.88044"}
{"text":"Probabilistic synchronous tree - adjoining grammars for machine translation : The argument from bilingual dictionaries .In Dekai Wu and David Chiang , editors , Proceedings of the Workshop on Syntax and Structure in Statistical Translation , Rochester , New York , 26 April 2007 .","label":"Background","metadata":{},"score":"65.042175"}
{"text":"The correct locus ( or loci ) of binding theory has been a matter of much discussion .Theories can be seen as varying along at least two dimensions .The second is the level of grammar on which binding is de ned .","label":"Background","metadata":{},"score":"65.10115"}
{"text":"Translation .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .Computer Recognition of English Word Senses , Amsterdam : North - Holland .Word sense disambiguation using conceptual density .","label":"Background","metadata":{},"score":"65.227356"}
{"text":"Translation .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .Computer Recognition of English Word Senses , Amsterdam : North - Holland .Word sense disambiguation using conceptual density .","label":"Background","metadata":{},"score":"65.227356"}
{"text":"1 Introduction In this paper , we present a robust parsing approach called supertagging that integrates the flexibility of linguistically motivated lexical descriptions with the robustness of statistical techniques .The idea underlying the approach is that the ... . ... ing and briefly discuss Feature - based Lexicalized Tree - Adjoining Grammars ( LTAGs ) as a representative of the class of lexicalized grammars . by Yves Schabes , Anne Abeille , Aravind K. Joshi - IN PROCEEDINGS OF THE 12 TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL LINGUISTICS ( COLING&apos;88 , 1988 . \" ...","label":"Background","metadata":{},"score":"65.37245"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 ( shrink ) .","label":"Background","metadata":{},"score":"65.57237"}
{"text":"Journal of Logic Programming , 24(1 - 2):3 - 36 , July - August 1995 .Stuart M. Shieber .The problem of logical - form equivalence .Computational Linguistics , 19(1):179 - 190 , 1993 .Stuart M. Shieber and Yves Schabes .","label":"Background","metadata":{},"score":"66.1844"}
{"text":"Automating the layout of network diagrams with specified visual organization .Transactions on Systems , Man and Cybernetics , 24(3):440 - 454 , March 1994 .Shawn Edmondson , Jon Christensen , Joe Marks , and Stuart M. Shieber .A general cartographic labeling algorithm .","label":"Background","metadata":{},"score":"66.20053"}
{"text":"The problem of WSD was first introduced by Warren Weaver in 1949 [ 3 ] .In 1975 Kelly and Stone [ 4 ] published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .","label":"Background","metadata":{},"score":"66.40295"}
{"text":"The problem of WSD was first introduced by Warren Weaver in 1949 [ 3 ] .In 1975 Kelly and Stone [ 4 ] published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .","label":"Background","metadata":{},"score":"66.40295"}
{"text":"The paper examines a range of established results bearing on these predictions , and shows that they are largely consistent with the surprisal theory . ... by Rebecca Hwa , Philip Resnik , Amy Weinberg , Clara Cabezas , Okan Kolak - Natural Language Engineering , 2005 . \" ...","label":"Background","metadata":{},"score":"66.57261"}
{"text":"alized composition and coordination ) can be easily implemented using such deduction parsing methods .3 The increased expressive power of ... . by Srinivas Bangalore , Aravind K. Joshi - Computational Linguistics , 1999 . \" ... this paper , we have proposed novel methods for robust parsing that integrate the flexibility of linguistically motivated lexical descriptions with the robustness of statistical techniques .","label":"Background","metadata":{},"score":"66.747665"}
{"text":"We additionally discuss an active learning algorithm which increases the value of constraints even further .( shrink ) .We discuss various estimates and give efficient algorithms for computing them .The algorithm is also correct for a wide range of parser control strategies and maintains a worst - case cubic time bound .","label":"Background","metadata":{},"score":"66.93024"}
{"text":"The new Viewer adds three features for more powerful search : wildcards , morphological inflections , and capitalization .These additions allow the discovery of patterns that were previously difficult to find and further facilitate the study of linguistic trends in printed text .","label":"Background","metadata":{},"score":"67.72083"}
{"text":"tagJet .pruneTags .Jet patterns .In addition to these annotators , Jet allows you to build an annotator from a set of rules involving finite - state patterns .Each pattern is a regular ( finite - state ) expression involving literals ( which match specific tokens ) and annotations .","label":"Background","metadata":{},"score":"67.92575"}
{"text":"Jet applies to each sentence a series of actions , as specified by the processSentence keyword in the parameter file .Most of these actions specify annotators -- programs which add annotations to the document .Examples of annotators are .( applied automatically to text typed at the console ) divides text into tokens , adding token annotations .","label":"Background","metadata":{},"score":"68.10087"}
{"text":"Stuart M. Shieber .Sentence disambiguation by a shift - reduce parsing technique .In Proceedings of the Eighth International Joint Conference on Artificial Intelligence , pages 699 - 703 , Karlsruhe , West Germany , 8 - 12 August 1983 .","label":"Background","metadata":{},"score":"68.12055"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 The information in these resources has been used in several ways , for example Wilks and Stevenson Y. Wilks and M. Stevenson .","label":"Background","metadata":{},"score":"69.01927"}
{"text":"Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 . which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"69.40633"}
{"text":"Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 . which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"69.40633"}
{"text":"Behavior Control : Finally we show how all these elements can be incorporated into a goal keeping robot .We develop simple behaviors that can be used in a layered architecture and enable the robot to block most balls that are being shot at the goal .","label":"Background","metadata":{},"score":"69.42868"}
{"text":"( shrink ) .The alignment problem - establishing links between corresponding phrases in two related sentences - is as important in natural language inference ( NLI ) as it is in machine translation ( MT ) .But the tools and techniques of MT alignment do not readily transfer to NLI , where one can not assume semantic equivalence , and for which large volumes of bitext are lacking .","label":"Background","metadata":{},"score":"69.46388"}
{"text":"Computational linguistics .Fernando C. N. Pereira and Stuart M. Shieber .Prolog and Natural - Language Analysis , volume 10 of CSLI Lecture Notes Series .Center for the Study of Language and Information , 1987 .Italian translation : Prolog e Analisi del Linguaggio Naturale , Tecniche Nuove , Milan , 1992 . html ] .","label":"Background","metadata":{},"score":"69.47757"}
{"text":"Computers fail to track these in fast video , but sleight of hand fools humans as well : what happens too quickly we just can not see .We show a 3D tracker for these types of motions that relies on the recognition of familiar configurations in 2D images ( classification ) , and fills the gaps in - between ( interpolation ) .","label":"Background","metadata":{},"score":"69.71745"}
{"text":"Meanwhile , Graphics Processor Units ( GPUs ) have become widely available , offering the opportunity to alleviate this bottleneck by exploiting the fine - grained data parallelism found in the CKY algorithm .In this paper , we explore the design space of parallelizing the dynamic programming computations carried out by the CKY algorithm .","label":"Background","metadata":{},"score":"70.1795"}
{"text":"Joe Marks , Wheeler Ruml , Stuart M. Shieber , and Tom Ngo .A seed - growth heuristic for graph bisection .In R. Battiti and A. A. Bertossi , editors , Proceedings of Algorithms and Experiments ' 98 , pages 76 - 87 , Trento , Italy , 9 - 11 February 1998 .","label":"Background","metadata":{},"score":"70.62169"}
{"text":"This work aims at a middle way .( shrink ) .However , few of these factors have been formally examined .Findings include the following .This decrease seems to be due to longer word duration .( 2 )","label":"Background","metadata":{},"score":"71.27304"}
{"text":"Kathy Ryall , Joe Marks , and Stuart M. Shieber .An interactive constraint - based system for drawing graphs .In Proceedings of the 10th Annual Symposium on User Interface Software and Technology ( UIST ) , 1997 .Automated graphic design .","label":"Background","metadata":{},"score":"71.34323"}
{"text":"Ball Tracking :The reliable tracking of the ball is vital in robot soccer .Therefore a Kalman - filter based system for estimating the ball position and velocity in the presence of occlusions is developped . -Sensor Fusion : The robot perceives its environment through several independent sensors ( camera , odometer , etc . ) , which have different delays .","label":"Background","metadata":{},"score":"71.51315"}
{"text":"We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task .For languages from different families the improvements often exceed 2 BLEU .Many of these gains are also significant in human evaluations .We present a new collection of treebanks with homogeneous syntactic dependency annotation for six languages : German , English , Swedish , Spanish , French and Korean .","label":"Background","metadata":{},"score":"71.61116"}
{"text":"Induction of probabilistic synchronous tree - insertion grammars for machine translation .In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas ( AMTA 2006 ) , Boston , Massachusetts , 8 - 12 August 2006 .","label":"Background","metadata":{},"score":"71.650406"}
{"text":"( shrink ) .This paper examines feature selection for log linear models over rich constraint - based grammar ( HPSG ) representations by building decision trees over features in corresponding probabilistic context free grammars ( PCFGs ) .We compare the performance of the learned PCFG grammars and log linear models over the same features .","label":"Background","metadata":{},"score":"72.120094"}
{"text":"Unifying synchronous tree - adjoining grammars and tree transducers via bimorphisms .In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics ( EACL-06 ) , Trento , Italy , 3 - 7 April 2006 .","label":"Background","metadata":{},"score":"72.206375"}
{"text":"( shrink ) .Automatically clustering web pages into semantic groups promises improved search and browsing on the web .In this paper , we demonstrate how user - generated tags from largescale social bookmarking websites such as del.icio.us can be used as a complementary data source to page text and anchor text for improving automatic clustering of web pages .","label":"Background","metadata":{},"score":"72.70053"}
{"text":"( 1998 ) .We apply the boosting method to parsing the Wall Street Journal treebank .The method combined the log - likelihood under a baseline model ( that of Collins [ 1999 ] ) with evidence from an additional 500,000 features over parse trees that were not included in the original model .","label":"Background","metadata":{},"score":"72.85329"}
{"text":"In Proceedings of the 14th International Conference on Computational Linguistics ( COLING-92 ) , pages 454 - 460 , Nantes , France , 1992 .The information in these resources has been used in several ways , for example Wilks and Stevenson Y. Wilks and M. Stevenson .","label":"Background","metadata":{},"score":"73.23453"}
{"text":"Many different metrics exist for evaluating parsing results , including Viterbi , Crossing Brackets Rate , Zero Crossing Brackets Rate , and several others .However , most parsing algorithms , including the Viterbi algorithm , attempt to optimize the same metric , namely the probability of getting th ... \" .","label":"Background","metadata":{},"score":"73.2717"}
{"text":"Electronic Commerce Research and Applications , 2008 .Philosophy of artificial intelligence .Stuart M. Shieber .The Turing Test .MIT Press , 2004 .Stuart M. Shieber .The Turing test as interactive proof .NoÃ»s , 41(4):686 - 713 , December 2007 .","label":"Background","metadata":{},"score":"74.92938"}
{"text":"( shrink ) .This paper studies the properties and performance of models for estimating local probability distributions which are used as components of larger probabilistic systems - history - based generative parsing models .However , we can connect these results with the commonly used general class of deleted interpolation models by showing that certain types of memory - based learning , including the kind ( ... ) that performed so well in our experiments , are instances of this class .","label":"Background","metadata":{},"score":"74.96666"}
{"text":"We present a new edition of the Google Books Ngram Corpus , which describes how often words and phrases were used over a period of five centuries , in eight languages ; it reflects 6 % of all books ever published .","label":"Background","metadata":{},"score":"75.14926"}
{"text":"Variations on incremental interpretation .Journal of Psycholinguistic Research , 22(2):287 - 318 , March 1993 .Applied natural - language processing .Stuart M. Shieber and Rani Nelken .Abbreviated text input using language modeling .Natural Language Engineering , 13(2):165 - 183 , June 2007 .","label":"Background","metadata":{},"score":"75.359146"}
{"text":"We use separate buckets for each n - gram model being interpolated .In performing this bucketing , we create an array containing how many n - grams occur for each value of P w i c(w i i\\Gamman+1 ) up to ... . \" ...","label":"Background","metadata":{},"score":"75.48311"}
{"text":"Stuart M. Shieber .A call for collaborative interfaces .Computing Surveys , 28A ( electronic ) , 1996 .B. Andalman , K. Ryall , W. Ruml , J. Marks , and S. M. Shieber .Design gallery browsers based on 2D and 3D graph drawing .","label":"Background","metadata":{},"score":"75.81633"}
{"text":"Comma restoration using constituency information .In Proceedings of the 2003 Human Language Technology Conference and Conference of the North American Chapter of the Association for Computational Linguistics , pages 221 - 227 , Edmonton , AB , Canada , 2003 .","label":"Background","metadata":{},"score":"75.852776"}
{"text":"Stuart M. Shieber , Yves Schabes , and Fernando C. N. Pereira .Principles and implementation of deductive parsing .Journal of Logic Programming , 24(1 - 2):3 - 36 , July - August 1995 .Mark - Jan Nederhof , Giorgio Satta , and Stuart M. Shieber .","label":"Background","metadata":{},"score":"75.98538"}
{"text":"erative clustering .First , we show formally that the common heuristic agglomerative clustering algorithms - Ward 's method , single - link , complete - link , and a variant of group - average - are each equivalent to a hierarchical model - based method .","label":"Background","metadata":{},"score":"75.99061"}
{"text":"Finally , ( ... ) we address the question of the suitability of the Stanford scheme for parser evaluation .( shrink ) .( shrink ) .We discuss trade - offs and empirical performance .( shrink ) .While Ã Â´ Ã Â¿ Âµ methods for parsing probabilistic context - free grammars ( PCFGs ) are well known , a tabular parsing framework for arbitrary PCFGs which allows for botton - up , topdown , and other parsing strategies , has not yet been provided .","label":"Background","metadata":{},"score":"76.55408"}
{"text":"( shrink ) .We present a novel algorithm for the fast computation of PageRank , a hyperlink - based estimate of the \" importance \" of Web pages .The original PageRank algorithm uses the Power Method to compute successive iterates that converge to the principal eigenvector of the Markov matrix representing the Web link graph .","label":"Background","metadata":{},"score":"79.971695"}
{"text":"Griffin Weber , Lucila Ohno - Machado , and Stuart Shieber .Representation in stochastic search for phylogenetic tree reconstruction .Journal of Biomedical Informatics , 39(1):43 - 50 , February 2006 .Computer privacy and security .David C. Parkes , Michael O. Rabin , Stuart M. Shieber , and Christopher Thorpe .","label":"Background","metadata":{},"score":"80.00157"}
{"text":"Second , we show how a model - based viewpoint can suggest variations on these basic agglomerative algorithms .We ( ... ) introduce adjusted complete - link , Mahalanobis - link , and line - link as variants , and demonstrate their utility .","label":"Background","metadata":{},"score":"80.36103"}
{"text":"Craig Silverstein and Stuart M. Shieber .Predicting individual book use for off - site storage using decision trees .Library Quarterly , 66(3):266 - 293 , July 1996 .Stuart M. Shieber .Equity for open - access journal publishing .","label":"Background","metadata":{},"score":"80.619446"}
{"text":"The use of synchronous TAGs for generation provides solutions to several problems with previous approaches to TAG generation .Furthermore , the semantic monotonicity requirement previously advocated for generation gram- mars as a computational aid is seen to be an inherent property of synchronous TAGs . \" ...","label":"Background","metadata":{},"score":"82.920654"}
{"text":"We also introduce a model of the diversity of ideas , topic entropy , using it to show that COLING is a more diverse conference than ACL , but that both conferences as well as EMNLP are becoming broader over time .","label":"Background","metadata":{},"score":"84.25986"}
{"text":"The van pulled up outside the bank and three masked men got out .We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .","label":"Background","metadata":{},"score":"91.32747"}
{"text":"The van pulled up outside the bank and three masked men got out .We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .","label":"Background","metadata":{},"score":"91.32747"}
{"text":"This Master 's thesis describes parts of the control software used by the soccer robots of the Free University of Berlin , the so called FU - Fighters .The FU - Fighters compete in the Middle Sized League of RoboCup and reached the semi - finals during the 2004 RoboCup World Cup in Lisbon , Portugal .","label":"Background","metadata":{},"score":"102.11148"}
{"text":"( shrink ) .","label":"Background","metadata":{},"score":"125.44665"}
