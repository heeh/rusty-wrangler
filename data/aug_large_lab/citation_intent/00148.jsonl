{"text":"( PDF ) . A. Gravano , R. Levitan , L. Willson , S. Benus , J. Hirschber , and A. Nenkova .Acoustic and prosodic correlates of social behavior .In Proceedings of Interspeech 2011 , 2011 .( PDF ) .","label":"Extends","metadata":{},"score":"34.44998"}{"text":"In contrast to our work , they utilize prosodic features in combination with acoustic confidence scores .They report a best - classifier accuracy of 89 % , which is a 14 % improvement over their baseline of 74 % .This result can be compared with our binary autoSLU - success predictor ( rcorrect vs. rincorrect ) discussed in Section 5 .","label":"Extends","metadata":{},"score":"35.73306"}{"text":"Our results suggest that the use of more general features does not negatively impact performance .( Krahmer , Swerts , Theune , & Weegels , 1999a ) and ( Krahmer , Swerts , Theune , & Weegels , 1999b ) look at different features related to responses to problematic system turns .","label":"Extends","metadata":{},"score":"37.462635"}{"text":"We also report precision and recall for each category on the held - out test set .The results are shown in Tables 2 and 3 .Table 2 shows that the classification accuracy rate is a result of a high rate of correct classification for the rcorrect and no - recog class , at the cost of a lower rate for rmismatch and rpartial - match .","label":"Extends","metadata":{},"score":"38.118988"}{"text":"Although we have only built detectors for 15 semantic concepts so far , the method seems easily portable to other concepts .The paper reports experiments with multi- ple features , different kernels and several analysis windows .Preliminary experiments on documentaries and films yielded promising results , despite the difficulties posed by the mix- tures of audio events that characterize real sounds .","label":"Extends","metadata":{},"score":"38.277885"}{"text":"While we do not use amplitude or F0 features , we do have an asr - duration feature which is logged by the recognizer .Without any of the other prosodic features , the auto - SLU - success predictor has an accuracy of 92.4 % , a 29.4 % improvement over the baseline of 63 % .","label":"Extends","metadata":{},"score":"38.370926"}{"text":"We also discuss the model 's limitations , to open the ground for the next stage of the work , i.e. , complementing the model with diagnostic information . ... event , and longer - lasting ( Thayer 1989 ) .","label":"Extends","metadata":{},"score":"38.42132"}{"text":"These features are the Acoustic / asr features , slu features and Dialogue Manager and Discourse History features , given in Figure 7 .Hand - labelled features were not used .We evaluate the four - way auto - SLU - success classifier by reporting accuracy , precision , recall and the categorization confusion matrix .","label":"Extends","metadata":{},"score":"39.527992"}{"text":"25 , pp .4 - 28 , 2011 .[59 ] B. Schuller , B. Vlasenko , R. Minguez , G. Rigoll , and A. Wendemuth , \" Comparing One and Two - Stage Acoustic Modeling in the Recognition of Emotion in Speech , \" Proc .","label":"Extends","metadata":{},"score":"39.590065"}{"text":"When this hand - labelled feature is added to the automatic features , it improved the performance of the PDP by almost 7.6 % .This finding led us to develop an SLU - success predictor ( Walker , Wright , & Langkilde , 2000c ) and a new version of the PDP that we report on here .","label":"Extends","metadata":{},"score":"39.860313"}{"text":"Walker , M. A. , Wright , J. , & Langkilde , I. ( 2000c ) .Using natural language processing and discourse features to identify understanding errors in a spoken dialogue system .In Proceedings of the Seventeenth International Conference on Machine Learning .","label":"Extends","metadata":{},"score":"39.91674"}{"text":"For each of these situations , we also compare results for the automatic feature set ( as described earlier ) with and without the auto - SLU - success feature and with the hand - labelled feature SLU - success .Table 5 summarizes the overall accuracy results .","label":"Extends","metadata":{},"score":"40.029198"}{"text":"437 - 444 , 2005 .[ 64 ] M. Wöllmer , F. Eyben , J. Keshet , A. Graves , B. Schuller , and G. Rigoll , \" Robust Discriminative Keyword Spotting for Emotionally Colored Spontaneous Speech Using Bidirectional LSTM Networks , \" Proc .","label":"Extends","metadata":{},"score":"40.63929"}{"text":"Hirschberg , J. B. , Litman , D. J. , & Swerts , M. ( 2001a ) .Detecting misrecognitions and corrections in spoken dialogue systems from ' aware ' sites .In Proceedings of the Workshop on Prosody in Speech Recognition and Understanding .","label":"Extends","metadata":{},"score":"40.795692"}{"text":"4497 - 4500 , 2008 .[45 ] M. Wöllmer , F. Eyben , S. Reiter , B. Schuller , C. Cox , E. Douglas - Cowie , and R. Cowie , \" Abandoning Emotion Classes - Towards Continuous Emotion Recognition with Modelling of Long - Range Dependencies , \" Proc .","label":"Extends","metadata":{},"score":"40.84715"}{"text":"Our final system that combines this method with the phonotactic method achieved the best result , and it was significantly better than the majority and official baseline of the sub - challenge .What kind of impact do you foresee this work having ?","label":"Extends","metadata":{},"score":"41.046158"}{"text":"Levow , G.-A. Characterizing and recognizing spoken corrections in human - computer dialogue .In Proceedings of the 36th Annual Meeting of the Association of Computational Linguistics , pp .736 - 742 .Litman , D. J. , Hirschberg , J. B. , & Swerts , M. ( 2000 ) .","label":"Extends","metadata":{},"score":"41.248848"}{"text":"Our results suggest that the use of more general features does not negatively impact performance .[ Krahmer , Swerts , Theune , WeegelsKrahmer et al.1999a ] and [ Krahmer , Swerts , Theune , WeegelsKrahmer et al.1999b ] look at different features related to responses to problematic system turns .","label":"Extends","metadata":{},"score":"41.25627"}{"text":"Although we have only built detectors for 15 semantic concepts so far , the method seems easily portable to other concepts .The paper reports experiments with multiple features , different kernels and several analysis windows .Preliminary experiments on documentaries and films yielded promising results , despite the difficulties posed by the mixtures of audio events that characterize real sounds .","label":"Extends","metadata":{},"score":"41.339027"}{"text":"Acoustics , Speech , and Signal Processing , pp .4585 - 4588 , 2009 .[ 39 ] B. Schuller , S. Steidl , A. Batliner , F. Burkhardt , L. Devillers , C. Müller , and S. Narayanan , \" The INTERSPEECH 2010 Paralinguistic Challenge , \" Proc . 11th","label":"Extends","metadata":{},"score":"41.519234"}{"text":"New components can be added to openSMILE via an easy binary plugin interface and a comprehensive API .Fully HTK compatible MFCC , PLP , ( log-)energy , and delta regression coefficient computation .Fast : 27k features can be extracted with an RTF of 0.08 .","label":"Extends","metadata":{},"score":"41.643883"}{"text":"Other features represent other aspects of the slu processing of the utterance .The inconsistency feature is an intra - utterance measure of semantic diversity , according to a task model of the domain ( Abella & Gorin , 1999 ) .","label":"Extends","metadata":{},"score":"41.87764"}{"text":"Litman , D. J. , Walker , M. A. , & Kearns , M. J. ( 1999 ) .Automatic detection of poor speech recognition at the dialogue level .In Proceedings of the Thirty Seventh Annual Meeting of the Association of Computational Linguistics , pp .","label":"Extends","metadata":{},"score":"41.896984"}{"text":"13 - 34 , 2010 .[ 7 ] H. Gunes , B. Schuller , M. Pantic , and R. Cowie , \" Emotion Representation , Analysis and Synthesis in Continuous Space : A Survey , \" Proc .Int'l Workshop Emotion Synthesis , rePresentation , and Analysis in Continuous spacE , pp .","label":"Extends","metadata":{},"score":"41.958267"}{"text":"Our first experiments were car- ried out using the LIBSVM toolkit [ 3 ] , for the 15 concepts .Then we performed in parallel experiments using the HMM toolkit from HTK [ 11 ] and feature dimensionality reduction techniques , for a restricted number of concepts .","label":"Extends","metadata":{},"score":"42.089073"}{"text":"The next section motivates our two - stage AED approach that first distinguishes between speech and non - speech audio events .Section 4 describes our multiple experiments with one - against - all detectors .Finally , section 5 presents the main conclusions and future plans .","label":"Extends","metadata":{},"score":"42.10551"}{"text":"Measuring acoustic - prosodic entrainment with respect to multiple levels and dimensions .In Proceedings of Interspeech 2011 , 2011 .( PDF ) .[ Levitan et al . , 2011 ] .R. Levitan , A. Gravano , and J. Hirschberg .","label":"Extends","metadata":{},"score":"42.1499"}{"text":"1760 - 1774 , 2009 .[ 73 ] A. Batliner , J. Buckow , R. Huber , V. Warnke , E. Nöth , and H. Niemann , \" Prosodic Feature Evaluation : Brute Force or Well Designed ? , \" Proc .","label":"Extends","metadata":{},"score":"42.245094"}{"text":"Examination of the rules learned by their classifier suggests that durational features are important .While we do not use amplitude or F0 features , we do have an asr - duration feature which is logged by the recognizer .Without any of the other prosodic features , the auto - SLU - success predictor has an accuracy of 92.4 % , a 29.4 % improvement over the baseline of 63 % .","label":"Extends","metadata":{},"score":"42.32734"}{"text":"Acknowledgments Thanks to Ron Prass , Diane Litman , Richard Sutton , Mazin Rahim and Michael Kearns for discussions on various aspects of this work .References Abella , A. , & Gorin , A. ( 1999 ) .Construct algebra : An analytical method for dialog management .","label":"Extends","metadata":{},"score":"42.37537"}{"text":"Here , our goals are similar in that we attempt to understand the factors that predict task completion .Secondly , this work builds on earlier research on learning to identify dialogues in which the user experienced poor speech recognizer performance [ Litman , Walker , KearnsLitman et al.1999 ] .","label":"Extends","metadata":{},"score":"42.58217"}{"text":"87 ] B. Schuller , D. Seppi , A. Batliner , A. Maier , and S. Steidl , \" Towards More Reality in the Recognition of Emotional Speech , \" Proc .IEEE Int'l Conf .Acoustics , Speech , and Signal Processing , vol .","label":"Extends","metadata":{},"score":"42.646503"}{"text":"A hierarchical model for web summarization .In Proceedings of the Annual Meeting of the Association of Computational Linguistics ( ACL - HLT ) Short Papers , Portland , Oregon , June 2011 .( PDF ) .[ Rosenthal and McKeown , 2011 ] .","label":"Extends","metadata":{},"score":"42.72982"}{"text":"The third row uses the same automatic features but adds in auto - SLU - success .This feature is obtained for both the training and the test set , using the cross - validation method discussed in Section 3 .The fourth and fifth rows show results using the subset of features that are both fully automatic and task - independent as described in Section 4 .","label":"Extends","metadata":{},"score":"42.81275"}{"text":"[ 22 ] B. Schuller , G. Rigoll , and M. Lang , \" Speech Emotion Recognition Combining Acoustic Features and Linguistic Information in a Hybrid Support Vector Machine - Belief Network Architecture , \" Proc .IEEE Int'l Conf .Acoustics , Speech , and Signal Processing , pp .","label":"Extends","metadata":{},"score":"43.34169"}{"text":"This paper reports results from experiments that test whether it is possible to learn to automatically predict that a dialogue will be problematic on the basis of information the system has : ( 1 ) early in the dialogue ; and ( 2 ) in real time .","label":"Extends","metadata":{},"score":"43.558273"}{"text":"In Proceedings of the First Meeting of the North American Chapter of the Association for Computational Linguistics .Litman , D. J. , & Pan , S. ( 2000 ) .Predicting and adapting to poor speech recognition in a spoken dialogue system .","label":"Extends","metadata":{},"score":"43.67707"}{"text":"Due to the large amount of features that can be extracted , consider- ing them all can lead to lengthy training processes due to slow convergence of the classification algorithms .In this work we used HMMs and SVMs for building a one - against - all classifier for each semantic concept .","label":"Extends","metadata":{},"score":"43.69536"}{"text":"99 - 110 , 2008 .[ 80 ] B. Schuller , R. Müller , G. Rigoll , and M. Lang , \" Applying Bayesian Belief Networks in Approximate String Matching for Robust Keyword - Based Retrieval , \" Proc .IEEE Int'l Conf .","label":"Extends","metadata":{},"score":"43.82426"}{"text":"[ Hirschberg , Litman , SwertsHirschberg et al.1999 ] apply RIPPER to predict recognition errors in a corpus of 2067 utterances .In contrast to our work , they utilize prosodic features in combination with acoustic confidence scores .They report a best - classifier accuracy of 89 % , which is a 14 % improvement over their baseline of 74 % .","label":"Extends","metadata":{},"score":"44.067123"}{"text":"The first possibility is for the training set to also consist of solely automatic features .This method has the potential advantage that the trained PDP will compensate , if necessary , for whatever noise exists in the auto - SLU - success predictions ( Wright , 2000 ) .","label":"Extends","metadata":{},"score":"44.288857"}{"text":"Here , our goals are similar in that we attempt to understand the factors that predict task completion .Secondly , this work builds on earlier research on learning to identify dialogues in which the user experienced poor speech recognizer performance ( Litman et al . , 1999 ) .","label":"Extends","metadata":{},"score":"44.418587"}{"text":"When analyzing the performance of the fully automatic feature set , we examined which hand - labelled features made large performance improvements , under the assumption that future work should focus on developing automatic features that approximate the information provided by these hand - labelled features .","label":"Extends","metadata":{},"score":"44.45107"}{"text":"This paper evaluates dialogue - based student performance in a controlled experiment using versions of a tutoring system with and without automatic adaptation to the student affective state of uncertainty .Our performance metrics include correctness , uncertainty , and learning impasse severities , whi ... \" .","label":"Extends","metadata":{},"score":"44.499542"}{"text":"478 - 481 , 2010 .[ 68 ] M. Shaikh , H. Prendinger , and I. Mitsuru , \" Assessing Sentiment of Text by Semantic Dependency and Contextual Valence Analysis , \" Proc .Second Int'l Conf .Affective Computing and Intelligent Interaction , pp .","label":"Extends","metadata":{},"score":"44.594543"}{"text":"We also offer ready - to - use speech analysis services and software products based on our proprietary extensions to the openSMILE core .Expert technical support is also available to help you get started and integrate openSMILE in your developments quickly .","label":"Extends","metadata":{},"score":"44.603325"}{"text":"This classifier can identify slu errors 47.0 % better than the baseline .An experiment was run to see if the cross - validation method described in Section 3 performs worse than using the whole data on the same test set .","label":"Extends","metadata":{},"score":"44.64927"}{"text":"The research reported here is the first that we know of to automatically analyze a corpus of logs from a spoken dialogue system for the purpose of learning to predict problematic situations .This work builds on two strands of earlier research .","label":"Extends","metadata":{},"score":"44.820225"}{"text":"We discuss the theoretical , methodological , and applied implications of our findings toward text - based emotion detection during tutoring .INDEX TERMS .CITATION .S. K. D'Mello , A. Graesser , \" Language and Discourse Are Powerful Signals of Student Emotions during Tutoring \" , IEEE Transactions on Learning Technologies , vol.5 , no .","label":"Extends","metadata":{},"score":"44.84826"}{"text":"53 , no .6 , pp .1078 - 1083 , June 2006 .[79 ] B. Schuller , F. Eyben , and G. Rigoll , \" Static and Dynamic Modelling for the Recognition of Non - Verbal Vocalisations in Conversational Speech , \" Proc .","label":"Extends","metadata":{},"score":"44.96189"}{"text":"One of the features that we wished to use was the string representing the recognizer 's hypothesis .This is supported in ripper because there is no a priori limitation on the size of the set .The usefulness of the textual features is exemplified in Section 6.3 .","label":"Extends","metadata":{},"score":"44.970535"}{"text":"The openSMILE webpage is now hosted on our homepage , and all support is also provided by us .Most research efforts dealing with recognition of emotion - related states from the human speech signal concentrate on acoustic analysis .However , the last decade 's research results show that the task can not be solved to complete satisfaction , especially when it comes to real life speech data and in particular to the assessment of speakers ' valence .","label":"Extends","metadata":{},"score":"45.028797"}{"text":"Conf . on Multi- media and Expo , 2003 .[11 ] Young , S. et al . \" HTK - Hidden Markov Model Toolkit \" , Manual , 2006 .Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .","label":"Extends","metadata":{},"score":"45.047657"}{"text":"The improved ability to predict problematic dialogues is important for fielding the hmihy system without the need for the oversight of a human customer care agent .These results are promising and we expect to be able to improve upon them , possibly by incorporating prosody into the feature set ( Hirschberg et al . , 1999 ) or expanding on the slu feature sets .","label":"Extends","metadata":{},"score":"45.20598"}{"text":"Page 2 .CORPORA AND EVALUATION METRICS The first corpus we considered for the task of audio events detection was a small pilot corpus of 422 sound effects files , totaling 6.8h , provided by B&G , one of the partners of the project .","label":"Extends","metadata":{},"score":"45.236465"}{"text":"Also see our products page to learn about proprietary extensions to openSMILE , such as advanced signal processing and new acoustic features , networking support and distributed processing , android client / server integration , pre - trained models , and intelligent voice activity detection .","label":"Extends","metadata":{},"score":"45.41918"}{"text":"However , our auto - SLU - success feature is automatically available at the time the prediction is being made , whereas they are making the predictions retroactively .In addition , they train their system on the hand - labelled feature rather than the predicted one which they leave as further work .","label":"Extends","metadata":{},"score":"45.45842"}{"text":"However , our auto - SLU - success feature is automatically available at the time the prediction is being made , whereas they are making the predictions retroactively .In addition , they train their system on the hand - labelled feature rather than the predicted one which they leave as further work .","label":"Extends","metadata":{},"score":"45.45842"}{"text":"Previous studies ( Walker et al . , 2000c ) have also shown slu features to be useful .We had also hypothesized that features from the Dialogue Manager and the discourse history might be useful predictors of slu errors , however these features rarely appear in the rules with the exception of sys - label .","label":"Extends","metadata":{},"score":"45.644592"}{"text":"5 , pp .559 - 590 , 2006 , doi:10.1016/j.specom.2005.09.008 .[20 ] K. Forbes - Riley and D.J. Litman , \" Benefits and Challenges of Real - Time Uncertainty Detection and Adaptation in a Spoken Dialogue Computer Tutor , \" Speech Comm . , vol .","label":"Extends","metadata":{},"score":"45.68851"}{"text":"Conf .Int'l Speech Comm .Assoc . , pp .2037 - 2040 , 2002 .[ 32 ] B. Schuller , R. Müller , M. Lang , and G. Rigoll , \" Speaker Independent Emotion Recognition by Early Fusion of Acoustic and Linguistic Features within Ensembles , \" Proc .","label":"Extends","metadata":{},"score":"45.692257"}{"text":"18 - 37 , Jan. 2010 , doi:10.1109/T - AFFC.2010.1 .[ 2 ] Z. Zeng et al . , \" A Survey of Affect Recognition Methods : Audio , Visual , and Spontaneous Expressions , \" IEEE Trans .","label":"Extends","metadata":{},"score":"45.86228"}{"text":"The results for these ini- tial experiments on all considered audio events are presented in Table 2 .The results obtained on the test set using the best combination of features on the development set are shown in Table 3 .These results confirm that detecting audio events in real life data is much more challenging than the classification of isolated events .","label":"Extends","metadata":{},"score":"45.929802"}{"text":"INTRODUCTION The framework for this work is the European project VIDI- VIDEO , whose goal is to boost the performance of video search engines by forming a 1000 element thesaurus .Instead of carefully modeling each different semantic concept , the ap- proach is to apply machine learning techniques to train many , possibly weaker detectors , describing different aspects of the audio - video content .","label":"Extends","metadata":{},"score":"46.289665"}{"text":"( PDF ) .[Thadani and McKeown , 2011a ] .Kapil Thadani and Kathleen McKeown .Optimal and syntactically informed decoding for monolingual phrase - based alignment .In the Annual Meeting of the Association of Computational Linguistics ( ACL - HLT ) Short Papers , Portland , Oregon , June 2011 .","label":"Extends","metadata":{},"score":"46.413033"}{"text":"ICSLP 2002 , Denver , September 2002 .[ 9 ] Trancoso , I. et al . , \" Training audio events detectors with a sound effects corpus \" , Proc .Interspeech 2008 , Bris- bane , September 2008 .[ 10 ] Xu , M. et al . \" Creating audio keywords for event detec- tion in soccer video \" , Proc .","label":"Extends","metadata":{},"score":"46.43038"}{"text":"Conf .Int'l Speech Comm .Assoc . , pp .2802 - 2805 , 2010 .[43 ] B. Schuller , B. Vlasenko , F. Eyben , G. Rigoll , and A. Wendemuth , \" Acoustic Emotion Recognition : A Benchmark Comparison of Performances , \" Proc .","label":"Extends","metadata":{},"score":"46.45659"}{"text":"552 - 557 , 2009 .[ 44 ] A. Batliner , B. Schuller , S. Schaeffler , and S. Steidl , \" Mothers , Adults , Children , Pets - Towards the Acoustics of Intimacy , \" Proc .IEEE Int'l Conf .","label":"Extends","metadata":{},"score":"46.494175"}{"text":"J. Sabourin , B. Mott , and J. Lester , \" Modeling Learner Affect with Theoretically Grounded Dynamic Bayesian Networks , \" Proc . 4th Int'l Conf .Affective Computing and Intelligent Interaction , Springer , 2011 , pp .286 - 295 .","label":"Extends","metadata":{},"score":"46.538174"}{"text":"49 - 54 .Swerts , M. , Litman , D. J. , & Hirschberg , J. B. ( 2000 ) .Corrections in spoken dialogue systems .In Proceedings of the 6th International Conference of Spoken Language Processing ( ICSLP-2000 ) .","label":"Extends","metadata":{},"score":"46.684486"}{"text":"Once it predicts that a dialogue will be problematic , it is correct 79.7 % of the time .6.3 Examination of the Rulesets A subset of the rules from the system that uses automatic features for Exchanges 1&2 are given in Figure 11 ( row 3 , table 5 ) .","label":"Extends","metadata":{},"score":"46.748985"}{"text":"[ 67 ] F. Metze , A. Batliner , F. Eyben , T. Polzehl , B. Schuller , and S. Steidl , \" Emotion Recognition Using Imperfect Speech Recognition , \" Proc . 11thAnn .Conf .Int'l Speech Comm .","label":"Extends","metadata":{},"score":"47.062927"}{"text":"At this stage we only considered the use of PLP or MFCC ( 19 coefficients + energy + deltas ) and 3 additional features : brightness , bandwidth and ZCR .The \" world \" model was build using between 92 and 96 files , of which an average of 31 were used as the development set .","label":"Extends","metadata":{},"score":"47.102"}{"text":"This is a two way distinction between positive and negative error correction .She uses two cascaded classifiers , the first is a decision tree trained using 80 % of the data and validating on 10 % .Examples that have confidence scores below a threshold go into an exception training set for a second classifier .","label":"Extends","metadata":{},"score":"47.252895"}{"text":"This is a two way distinction between positive and negative error correction .She uses two cascaded classifiers , the first is a decision tree trained using 80 % of the data and validating on 10 % .Examples that have confidence scores below a threshold go into an exception training set for a second classifier .","label":"Extends","metadata":{},"score":"47.252895"}{"text":"Learning optimal dialogue strategies : A case study of a spoken dialogue agent for email .In Proceedings of the 36th Annual Meeting of the Association of Computational Linguistics , COLING / ACL 98 , pp .1345 - 1352 .Walker , M. A. , Kamm , C. A. , & Litman , D. J. ( 2000a ) .","label":"Extends","metadata":{},"score":"47.27024"}{"text":"This paper addresses only the last category .The original speech / non - speech ( SNS1 ) detector is based on an MLP ( Multi - Layer Perceptron ) trained with PLP fea- tures , extracted from a corpus of broadcast news .","label":"Extends","metadata":{},"score":"47.736115"}{"text":"Identifying user corrections automatically in spoken dialogue system .In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics .Kirchhoff , K. ( 2001 ) .A comparison of classification techniques for the automatic detection of error corrections in human - computer dialogues .","label":"Extends","metadata":{},"score":"47.73748"}{"text":"They observe that corrections that are more distant from the error they correct , are more likely to exhibit prosodic differences .Their system automatically differentiates corrections from non - corrections with an error rate of 15.72 % .Dialogue context is used in the study by ( Hirschberg , Litman , & Swerts , 2001a ) , whereby they incorporate whether the user is aware of a mistake at the current utterance to help predict misunderstandings and misrecognition of the previous utterances .","label":"Extends","metadata":{},"score":"47.74448"}{"text":"As described above , one of these features is the output of the auto - SLU - success predictor , the auto - SLU - success feature , which predicts whether or not the current utterance was correctly understood ( Walker et al . , 2000c ) .","label":"Extends","metadata":{},"score":"47.94683"}{"text":"Prosodic cues to recognition errors .In Proc . of the Automatic Speech Recognition and Understanding Workshop .Hirschberg , J. B. , Litman , D. J. , & Swerts , M. ( 2000 ) .Generalizing prosodic prediction of speech recognition errors .","label":"Extends","metadata":{},"score":"47.948536"}{"text":"Acoustics , Speech , and Signal Processing , pp .3949 - 3952 , 2009 .[ 65 ] S. Steidl , A. Batliner , D. Seppi , and B. Schuller , \" On the Impact of Children 's Emotional Speech on Acoustic and Language Models , \" EURASIP J. Audio , Speech , and Music Processing , vol .","label":"Extends","metadata":{},"score":"48.046604"}{"text":"596 - 600 , 2007 .[ 63 ] T. Athanaselis , S. Bakamidis , I. Dologlu , R. Cowie , E. Douglas - Cowie , and C. Cox , \" ASR for Emotional Speech : Clarifying the Issues and Enhancing Performance , \" Neural Networks , vol .","label":"Extends","metadata":{},"score":"48.13022"}{"text":"These rows give a topline against which to compare the results in rows 2 , 3 , 4 and 5 .Results using all the automatic features plus the hand - labelled SLU - success are given in row 6 .In these experiments , the hand - labelled SLU - success feature is used for training and testing .","label":"Extends","metadata":{},"score":"48.21158"}{"text":"They observe that corrections that are more distant from the error they correct , are more likely to exhibit prosodic differences .Their system automatically differentiates corrections from non - corrections with an error rate of 15.72 % .Dialogue context is used in the study by [ Hirschberg , Litman , SwertsHirschberg et al.2001a ] , whereby they incorporate whether the user is aware of a mistake at the current utterance to help predict misunderstandings and misrecognition of the previous utterances .","label":"Extends","metadata":{},"score":"48.28468"}{"text":"Acoustics , Speech , and Signal Processing , pp .1520 - 6149 .[54 ] D. Ververidis and C. Kotropoulos , \" Fast Sequential Floating Forward Selection Applied to Emotional Speech Features Estimated on DES and SUSAS Data Collection , \" Proc .","label":"Extends","metadata":{},"score":"48.356007"}{"text":"858 - 862 , 2009 .[ 15 ] R. Cowie , E. Douglas - Cowie , B. Apolloni , J. Taylor , A. Romano , and W. Fellenz , \" What a Neural Net Needs to Know about Emotion Words , \" J. Computational Intelligence and Applications , pp .","label":"Extends","metadata":{},"score":"48.431816"}{"text":"The first was to use the hand - labelled feature in the training set , the second to perform separate experiments to predict the feature for the training set .As the features in the training set are automatically predicted , it is hoped that the system would pick up the idiosyncrasies of the noisy data .","label":"Extends","metadata":{},"score":"48.526184"}{"text":"The first was to use the hand - labelled feature in the training set , the second to perform separate experiments to predict the feature for the training set .As the features in the training set are automatically predicted , it is hoped that the system would pick up the idiosyncrasies of the noisy data .","label":"Extends","metadata":{},"score":"48.526184"}{"text":"This is shown to be effective in ( Litman & Pan , 2000 ) , where they use a problematic dialogue detector in order to adapt the dialogue strategy for a train enquiry system .However , it is clear that the decision to transfer the call to a human customer care agent can not be made on the basis of only local information because the system can often recover from a single error .","label":"Extends","metadata":{},"score":"48.75746"}{"text":"M. Rodrigo and R. Baker , \" Comparing the Incidence and Persistence of Learners ' Affect During Interactions with Different Educational Software Packages , \" New Perspective on Affect and Learning Technologies , R.A. Calvo , and S.K. D'Mello eds . , Springer , 2011 , pp .","label":"Extends","metadata":{},"score":"49.027733"}{"text":"Once it predicts that a dialogue will be problematic , it is correct 56.6 % of the time .The performance of the system that uses automatic features for Exchanges 1&2 is summarized in Table 7 .These results show that , given the first two exchanges , this ruleset predicts that 20 % of the dialogues will be problematic , while 33 % of them actually will be .","label":"Extends","metadata":{},"score":"49.165237"}{"text":"Text , Speech , and Dialogue , pp .629 - 636 .[ 27 ] H. Ai , D. Litman , K. Forbes - Riley , M. Rotaru , J. Tetreault , and A. Purandare , \" Using System and User Performance Features to Improve Emotion Detection in Spoken Tutoring Dialogs , \" Proc .","label":"Extends","metadata":{},"score":"49.2097"}{"text":"Workshop on Multimedia informa- tion retrieval , pages 109 - 115 , 2003 .[5]Chu , W. et al . \"A study of semantic context detection by using SVM and GMM approaches \" , Proc .IEEE Int .Conf . on Multimedia and Expo , 2004 .","label":"Extends","metadata":{},"score":"49.210606"}{"text":"Ideally , the result in row 3 , for automatic features plus autoSLU - success , should fall between the figures in rows 2 and 6 , and be closer to the results in row 6 .With Exchanges 1&2 , adding auto - SLU - success results in an increase of 1.1 % which is not significant ( compare rows 2 and 3 ) .","label":"Extends","metadata":{},"score":"49.42189"}{"text":"We show that a Problematic Dialogue Predictor using automatically - obtainable features from the first two exchanges in the dialogue can predict problematic dialogues 13.2 % more accurately than the baseline .Extracted Text .However , current spoken dialogue systems are deficient in their strategies for preventing , identifying and repairing problems that arise in the conversation .","label":"Extends","metadata":{},"score":"49.601883"}{"text":"Our main results are that changing the modality from text to speech caused changes in the learning gains , time and superficial dialogue characteristics of human tutoring , but for computer tutoring it made less difference . \" ...This paper investigates the reliability of detecting a learner 's affective states in an attempt to augment an Intelligent Tutoring System ( AutoTutor ) with the ability to incorporate such states into its pedagogical strategies to improve learning .","label":"Extends","metadata":{},"score":"49.604347"}{"text":"This paper focuses on the detection of non - speech events , and as such only searches for events in audio segments that have been previously classified as non - speech .Preliminary experiments with a small corpus of sound effects have shown the potential of this type of corpus for training purposes .","label":"Extends","metadata":{},"score":"49.691147"}{"text":"[Chang and Collins , 2011 ] .Yin - Wen Chang and Michael Collins .Exact decoding of phrase - based translation models through lagrangian relaxation .In Proceedings of EMNLP 2011 , 2011 .( PDF ) .[ Coyne et al . , 2011a ] .","label":"Extends","metadata":{},"score":"49.707085"}{"text":"9 - 11 , 2011 , pp .1115 - 1136 .C. Mills and S.K. D'Mello , \" Emotions During Writing on Topics that Align or Misalign with Personal Beliefs , \" Proc .11th Int'l Conf .Intelligent Tutoring Systems , LNCS 7315 , Springer , 2012 , pp .","label":"Extends","metadata":{},"score":"49.713913"}{"text":"136 - 141 , 2011 .[19 ] D. Litman and K. Forbes - Riley , \" Recognizing Student Emotions and Attitudes on the Basis of Utterances in Spoken Tutoring Dialogues with Both Human and Computer Tutors , \" Speech Comm . , vol .","label":"Extends","metadata":{},"score":"49.72188"}{"text":"Conf .Int'l Speech Comm .Assoc . , pp .597 - 600 , 2008 .[47 ] M. Grimm , K. Kroschel , H. Harris , C. Nass , B. Schuller , G. Rigoll , and T. Moosmayr , \" On the Necessity and Feasibility of Detecting a Driver 's Emotional State while Driving , \" Proc .","label":"Extends","metadata":{},"score":"49.77125"}{"text":"Affective Computing and Intelligent Interaction , pp .126 - 138 , 2007 .[51 ] M. Grimm , K. Kroschel , and S. Narayanan , \" Support Vector Regression for Automatic Recognition of Spontaneous Emotions in Speech , \" Proc .","label":"Extends","metadata":{},"score":"49.780464"}{"text":"In Proceedings of ACL / HLT 2011 , 2011 .( PDF ) .[ Ma and McKeown , 2011 ] .Wei - Yun Ma and Kathleen McKeown .System combination for machine translation based on text - to - text generation .","label":"Extends","metadata":{},"score":"49.811867"}{"text":"S.K. D'Mello , and A.C. Graesser , \" AutoTutor and Affective AutoTutor :Learning by Talking with Cognitively and Emotionally Intelligent Computers that Talk Back , \" to be published in ACM Trans .Interactive Intelligent Systems .K. Forbes - Riley and D. Litman , \" Benefits and Challenges of Real - Time Uncertainty Detection and Adaptation in a Spoken Dialogue Computer Tutor , \" Speech Communication , vol .","label":"Extends","metadata":{},"score":"49.960106"}{"text":"In addition , the rg - grammar feature also encodes expectations about user utterances at that point in the dialogue , which may correlate to differences in the ease with which any one recognizer could correctly understand the user 's response .","label":"Extends","metadata":{},"score":"49.986282"}{"text":"Levow obtains an accuracy rate of 75 % with a baseline of 50 % .[ Swerts , Litman , HirschbergSwerts et al.2000 ] and [ Hirschberg , Litman , SwertsHirschberg et al.2001b ] perform similar studies for automatically identifying corrections using prosody , ASR features and dialogue context .","label":"Extends","metadata":{},"score":"50.102543"}{"text":"In future work , we plan to integrate the learned rulesets into the hmihy dialogue system and evaluate the impact that this would have on the system 's overall performance .There are several ways we might be able to show this .","label":"Extends","metadata":{},"score":"50.209206"}{"text":"[20 ] T. Wu , F. Khan , T. Fisher , L. Shuler , and W. Pottenger , \" Posting Act Tagging Using Transformation - Based Learning , \" Foundations of Data Mining and Knowledge Discovery , T.Y. Lin , S. Ohsuga , C.-J. Liau , X. Hu , and S. Tsumoto , eds . , pp .","label":"Extends","metadata":{},"score":"50.28385"}{"text":"The tempo and the confpertime and salpertime features are used only for predicting auto - SLU - success .301 Walker , Langkilde - Geary , Wright Hastie , Wright & Gorin The motivation for these slu features is to make use of information that the slu module has as a result of processing the output of asr and the current discourse context .","label":"Extends","metadata":{},"score":"50.565628"}{"text":"In 2010 , version 1.0.1 of openSMILE was published and presented at the ACM - MM open - source software challenge - winning an honorable mention .Since 2011 , openSMILE was further developed by Florian Eyben and Felix Weninger , during their PhD thesis work at Technische Universität München , Germany .","label":"Extends","metadata":{},"score":"50.802673"}{"text":"[ 12 ] T. Polzehl , S. Sundaram , H. Ketabdar , M. Wagner , and F. Metze , \" Emotion Classification in Children 's Speech Using Fusion of Acoustic and Linguistic Features , \" Proc . 10th Ann .Conf .","label":"Extends","metadata":{},"score":"50.8599"}{"text":"86 - 89 , Nov.-Dec .2012 , doi:10.1109/MIS.2012.110 .M.S. Hussain et al . , \" Affect Detection from Multichannel Physiology during Learning Sessions with AutoTutor , \" Artificial Intelligence in Education , LNAI 6738 , G. Biswas et al . , eds . , Springer , 2011 , pp .","label":"Extends","metadata":{},"score":"50.932182"}{"text":"For Exchange 1 , only the slu features , out of the automatic feature sets , yields an improvement over the baseline .Interestingly , training the system on the asr yields the best result out of the automatic feature sets for Exchange 1&2 and the whole dialogue .","label":"Extends","metadata":{},"score":"51.023582"}{"text":"This results in a complete list of predicted auto - SLU - success for the training set .The features for the test set exchanges are derived by training ripper on the whole training set .This process is illustrated in Figure 6 .","label":"Extends","metadata":{},"score":"51.027958"}{"text":"Conf .Int'l Speech Comm .Assoc . , pp .2794 - 2797 , 2010 .[40 ] J. Jeon , R. Xia , and Y. Liu , \" Level of Interest Sensing in Spoken Dialog Using Multi - Level Fusion of Acoustic and Lexical Evidence , \" Proc . 11th","label":"Extends","metadata":{},"score":"51.32923"}{"text":"Knowledge collection for natural language spoken dialog systems .In Proceedings of the European Conference on Speech Communication and Technology .317 Walker , Langkilde - Geary , Wright Hastie , Wright & Gorin Furnkranz , J. , & Widmer , G. ( 1994 ) .","label":"Extends","metadata":{},"score":"51.35686"}{"text":"Levow obtains an accuracy rate of 75 % with a baseline of 50 % .( Swerts et al . , 2000 ) and ( Hirschberg et al ., 2001b ) perform similar studies for automatically identifying corrections using prosody , asr features and dialogue context .","label":"Extends","metadata":{},"score":"51.456688"}{"text":"2007 , n. 37507 , May 2007 .[ 2]Cai , R. et al .\" A flexible framework for key audio events detection and auditory context inference \" , IEEE Trans . on Speech and Audio Processing , 2005 .[ 3]Chang , C. and Lin , C. , \" LIBSVM : a library for support vector machines \" , Manual , 2001 .","label":"Extends","metadata":{},"score":"51.46254"}{"text":"Classification and Regression Trees .Wadsworth and Brooks , Monterey California .Catlett , J. ( 1991 ) .Megainduction : A test flight .In Proceedings of the Eighth International Conference on Machine Learning .Chu - Carroll , J. , & Carpenter , B. ( 1999 ) .","label":"Extends","metadata":{},"score":"51.619118"}{"text":"For lower sampling rates the filterbank will have a lower frequency range , chaning the frequency assignments of the bands , which is not desired .If you use openSMILE in your research , please cite the following paper for version 2.x and above : .","label":"Extends","metadata":{},"score":"51.657074"}{"text":"The final row of the table gives the results using the hand - labelled feature SLU - success in both the training and testing and is taken as the topline result .ripper was trained separately on sets of features based on the groups given in Figure 7 , namely Acoustic / asr , slu , Dialogue and Handlabelled ( including SLU - success ) .","label":"Extends","metadata":{},"score":"51.66345"}{"text":"Previous work suggests that the if - then rules that ripper uses to express the learned classification model are easy for people to understand ( Catlett , 1991 ; Cohen , 1995 ) , making it easier to integrate the learned rules into the hmihy system .","label":"Extends","metadata":{},"score":"51.852676"}{"text":"The challenge is that building the model requires having mechanisms to assess user goals and how the environment fits them , a form of plan recognition .In this paper , we illustrate how we built the predictive part of the affective model by combining general theories with empirical studies to adapt the theories to our target application domain .","label":"Extends","metadata":{},"score":"51.871834"}{"text":"Theprincipalcomponents are calculated in the training set and their respective variance coverage rate is verified in the development set .The results show significant improvements relatively to the results using pitch , and are better than the initial SVMs results for the test set .","label":"Extends","metadata":{},"score":"51.914837"}{"text":"[ 7 ] Moncrieff , S. et al . \"Detecting indexical signs in film audio for scene interpretation \" , Proc .IEEE Int .Conf . on Multimedia and Expo , 2001 .[ 8]Torres - Carrasquillo , P. A. et al .","label":"Extends","metadata":{},"score":"51.95491"}{"text":"If one compares the second rule in both figures , one can see that ripper uses recog - numwords as a substitute for the task - specific feature sys - label .6.4 Cross - validation Method vs. Hand - labelled - training Method As mentioned above , an alternative to training the PDP on the automatically derived autoSLU - success feature is to train it on the hand - labelled SLU - success while still testing it on the automatic feature .","label":"Extends","metadata":{},"score":"52.009506"}{"text":"6.1.2 Hand - labelled Features Row 7 in table 5 gives the results using hand - labelled and automatic features including both SLU - success and auto - SLU - success .By comparing rows 6 and 7 , one can see that there is not very much to be gained by adding the other hand - labelled features given in Figure 7 to the hand - labelled and SLU - success feature set .","label":"Extends","metadata":{},"score":"52.045273"}{"text":"[ 69 ] A.K. Seewald and F. Kleedorfer , \" Lambda Pruning : An Approximation of the String Subsequence Kernel for Practical SVM Classification and Redundancy Clustering , \" Advances in Data Analysis and Classification , vol .1 , no . 3 , pp .","label":"Extends","metadata":{},"score":"52.19204"}{"text":"Int'l Speech Comm .Assoc . , pp .805 - 808 , 2005 .First Int'l Language Technologies Conf . , pp .240 - 245 , 2006 .[ 37 ] B. Schuller , A. Batliner , S. Steidl , and D. Seppi , \" Emotion Recognition from Speech : Putting ASR in the Loop , \" Proc .","label":"Extends","metadata":{},"score":"52.20002"}{"text":"The research aims to develop an agile learning environment that is sensitive to a learner 's affective state , presuming that this will promote learning .We integrate state - of - the - art , nonintrusive , affect - sensing technology with AutoTutor in an endeavor to classify emotions on the bases of facial expressions , gross body movements , and conversational cues .","label":"Extends","metadata":{},"score":"52.261883"}{"text":"In addition , in contrast to the current study , the previous work automatically approximated the notion of a good or bad dialogue using a threshold on the percentage of recognition errors .There is a danger of this approach being circular when recognition performance at the utterance level is a primary predictor of a good or bad dialogue .","label":"Extends","metadata":{},"score":"52.28186"}{"text":"In addition , in contrast to the current study , the previous work automatically approximated the notion of a good or bad dialogue using a threshold on the percentage of recognition errors .There is a danger of this approach being circular when recognition performance at the utterance level is a primary predictor of a good or bad dialogue .","label":"Extends","metadata":{},"score":"52.28186"}{"text":"In previous work , ( Walker et al . , 2000b ) reported results from training a problematic dialogue predictor in which they noted the extent to which the hand - labelled SLU - success feature improves classifier performance .As a result of this prior analysis , in this work we report results from training an auto - SLU - success classifier for each exchange and using its predictions as an input feature to the Problematic Dialogue Predictor .","label":"Extends","metadata":{},"score":"52.43721"}{"text":"We compare two different student uncertainty adaptations which were designed , implemented and evaluated in a controlled experiment using four versions ... \" .Abstract .This study shows that affect - adaptive computer tutoring can significantly improve performance on learning efficiency and user satisfaction .","label":"Extends","metadata":{},"score":"52.662674"}{"text":"[82 ] G. Rigoll , \" The ALERT - System : Advanced Broadcast Speech Recognition Technology for Selective Dissemination of Multimedia Information , \" Proc .IEEE Workshop Automatic Speech Recognition and Understanding , pp .301 - 306 , 2001 .","label":"Extends","metadata":{},"score":"52.6896"}{"text":"[ 92 ] J. Yi , T. Nasukawa , R. Bunescu , and W. Niblack , \" Sentiment Analyzer : Extracting Sentiments about a Given Topic Using Natural Language Processing Techniques , \" Proc .IEEE Int'l Conf .Data Mining , pp .","label":"Extends","metadata":{},"score":"52.709316"}{"text":"The results for the test set are shown in Table 4 .These were obtained using the number of states and mixtures that yielded the best results on the development set .Even using a more limited feature set , the results for the 20ms window length show a small improvement over the previous SVM re- sults ( 0.43 mean positive detection , compared with 0.29 for the SVMs ) .","label":"Extends","metadata":{},"score":"52.8287"}{"text":"Walker , M. A. , Litman , D. , Kamm , C. A. , & Abella , A. ( 1997 ) .PARADISE : A general framework for evaluating spoken dialogue agents .In Proceedings of the 35th Annual Meeting of the Association of Computational Linguistics , ACL / EACL 97 , pp .","label":"Extends","metadata":{},"score":"52.92768"}{"text":"192 - 205 , October - December 2011 , doi:10.1109/T - AFFC.2011.17 .[ 2 ] R. Cowie , E. Douglas - Cowie , N. Tsapatsoulis , G. Votsis , S. Kollias , W. Fellenz , and J. Taylor , \" Emotion Recognition in Human - Computer Interaction , \" IEEE Signal Processing Magazine , vol .","label":"Extends","metadata":{},"score":"52.94362"}{"text":"Computational Linguistics , 25 - 3 , 361 - 387 .Cohen , W. ( 1995 ) .Fast effective rule induction .In Proceedings of the Twelfth International Conference on Machine Learning .Cohen , W. ( 1996 ) .Learning trees and rules with set - valued features .","label":"Extends","metadata":{},"score":"52.96798"}{"text":"The challenge results are not the most important thing , but this kind of competition can definitely put our field forward .In terms of the suggestions , we might consider the following two questions in the future challenges : ( 1 ) what are the most appropriate evaluation metrics ?","label":"Extends","metadata":{},"score":"52.96899"}{"text":"She finds that the most discriminatory features are dialogue context ( the type of previous system utterance ) followed by lexical features , with prosodic features being the least discriminatory .The system recognizes error corrections with an accuracy of 90 % compared to a baseline of 81.9 % .","label":"Extends","metadata":{},"score":"52.980595"}{"text":"She finds that the most discriminatory features are dialogue context ( the type of previous system utterance ) followed by lexical features , with prosodic features being the least discriminatory .The system recognizes error corrections with an accuracy of 90 % compared to a baseline of 81.9 % .","label":"Extends","metadata":{},"score":"52.980595"}{"text":"This is the first release which contains the configuration files for the first release of the Geneva Minimalistic Acoustic Parameter Set ( GeMAPS ) .Binaries for Linux ( statically linked , no Portaudio support ) are included with the package .","label":"Extends","metadata":{},"score":"53.108547"}{"text":"Previous studies on error correction recognition are also related to our method of misunderstanding recognition .( Levow , 1998 ) applied similar techniques to learn to distinguish between utterances in which the user originally provided some information to the system , and corrections , which provided the same information a second time , following a misunderstanding .","label":"Extends","metadata":{},"score":"53.120346"}{"text":"941 - 944 , 2007 .[89 ] A.-M. Popescu and O. Etzioni , \" Extracting Product Features and Opinions from Reviews , \" Proc .Human Language Technology Conf .and the Conf .Empirical Methods in Natural Language Processing , pp .","label":"Extends","metadata":{},"score":"53.168667"}{"text":"We also believe that it is necessary to investigate more prosodic cues to the speaker state and emotion detection tasks .Can you tell us a bit about the Intoxication Sub - Challenge at Interspeech this year ?What were the goals of the challenge ?","label":"Extends","metadata":{},"score":"53.347824"}{"text":"In Proceedings of Interspeech 2011 , Florence , Italy , 2011 .( PDF ) .[ Biran and Rambow , 2011a ] .Or Biran and Owen Rambow .Identifying justifications in written dialog .In Proceedings of the Fifth IEEE International Conference on Semantic Computing , 2011 .","label":"Extends","metadata":{},"score":"53.519787"}{"text":"In the field of language and accent identification , NIST organizes language recognition evaluation workshops every two years , and some of the best systems from the workshop have already reached 3 - 4 % equal error rate in a 30-second close - set dialect / accent identification task .","label":"Extends","metadata":{},"score":"53.771664"}{"text":"[ 25 ] S. Steidl , C. Ruff , A. Batliner , E. Nöth , and J. Haas , \" Looking at the Last Two Turns , I 'd Say This Dialogue Is Doomed - Measuring Dialogue Success , \" Proc .","label":"Extends","metadata":{},"score":"53.79173"}{"text":"We can train systems to improve their ability to detect problems by exploiting dialogues collected in interactions with human users where the initial segments of these dialogues are used to train a Problematic Dialogue Predictor ( PDP ) to predict that a problem is likely to occur .","label":"Extends","metadata":{},"score":"53.89137"}{"text":"In 2013 audEERING acquired the rights to the code - base from TUM , and version 2.0 ( release candidate ) was released under an open - source research license .In 2014 , audEERING started hosting the openSMILE website with the release of the 2.1 version .","label":"Extends","metadata":{},"score":"53.89396"}{"text":"Tools . by Diane J. Litman , Carolyn P. Rosé , Kate Forbes - Riley , et al . -IN PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT TUTORING SYSTEMS(ITS ) .MACEIO , 2004 . \" ...While human tutors typically interact with students using spoken dialogue , most computer dialogue tutors are text - based .","label":"Extends","metadata":{},"score":"53.923767"}{"text":"9/10 , pp .1115 - 1136 , 2011 , doi:10.1016/j.specom.2011.02.006 .[ 25 ] C.G. Shields et al . , \" Emotion Language in Primary care Encounters : Reliability and Validity of an Emotion Word Count Coding System , \" Patient Education and Counseling , vol .","label":"Extends","metadata":{},"score":"53.967842"}{"text":".. 2 Promising results have been reported on correlating uncertainty and learning [ 1,5 ] and on manually annotating ( e.g. [ 5,8 ] ) and automatically detecting ( e.g. [ 8,9,3 ] ) uncertainty in computer tutor ... . \" ...","label":"Extends","metadata":{},"score":"54.00301"}{"text":"This paper investigates the reliability of detecting a learner 's affective states in an attempt to augment an Intelligent Tutoring System ( AutoTutor ) with the ability to incorporate such states into its pedagogical strategies to improve learning .We describe two studies that used observational and emote - aloud protocols in order to identify the affective states that learners experience while interacting with AutoTutor .","label":"Extends","metadata":{},"score":"54.018024"}{"text":"3 , pp .2315 - 2318 , 1999 .[ 78 ] S. Matos , S. Birring , I. Pavord , and D. Evans , \" Detection of Cough Signals in Continuous Audio Recordings Using Hidden Markov Models , \" IEEE Trans .","label":"Extends","metadata":{},"score":"54.395473"}{"text":"Our performance metrics include correctness , uncertainty , and learning impasse severities , which are measured in a \" test \" dialogue after the tutoring treatment .Although these metrics did not significantly differ across conditions when considering all student answers in our test dialogue , we found significant differences in specific types of student answers , and these differences suggest that our uncertainty adaptation does have a positive benefit on student performance . by Ma . ... he Incredible Machine .","label":"Extends","metadata":{},"score":"54.413403"}{"text":"232 - 238 , 2005 , doi:10.1016/j.pec.2004.06.005 .[ 35 ] M. Shaikh et al . , \" Sentiment Assessment of Text by Analyzing Linguistic Features and Contextual Valence Assignment , \" Applied Artificial Intelligence , vol .22 , no .","label":"Extends","metadata":{},"score":"54.43509"}{"text":"304 - 317 , Fourth Quarter 2012 , doi:10.1109/TLT.2012.10 .[ 1 ] R.A. Calvo and S.K. D'Mello , \" Affect Detection : An Interdisciplinary Review of Models , Methods , and Their Applications , \" IEEE Trans .Affective Computing , vol .","label":"Extends","metadata":{},"score":"54.55156"}{"text":"Affective computing , speech emotion recognition , sentiment analysis , support vector regression , string kernels .CITATION .Björn Schuller , \" Recognizing Affect from Linguistic Information in 3D Continuous Space \" , IEEE Transactions on Affective Computing , vol.2 , no .","label":"Extends","metadata":{},"score":"54.614002"}{"text":"31 , no . 1 , pp .39 - 58 , Jan. 2009 , doi:10.1109/TPAMI.2008.52 .[ 16 ] A. Ward et al . , \" Predicting Change in Student Motivation by Measuring Cohesion between Tutor and Student , \" Proc .","label":"Extends","metadata":{},"score":"54.68029"}{"text":"Since we were primarily interested in the performance of the PDP using the full automatic feature set , after having seen Exchanges 1&2 , we conducted our analysis on this version of the PDP .Table 10 shows the distribution of the 4 types of dialogue in the test set and whether the Exchanges 1&2 PDP was able to predict correctly that the dialogue would be tasksuccess or problematic .","label":"Extends","metadata":{},"score":"54.718094"}{"text":"The system trained on the whole dialogue with automatic features plus auto - SLU - success also does not yield an improvement over the system trained without auto - SLU - success .6.1.1 Task - independent Features Rows 4 and 5 give the results using the auto , task - indept feature set described in Figure 9 without and with the auto - SLU - success feature , respectively .","label":"Extends","metadata":{},"score":"54.819656"}{"text":"[Thadani and McKeown , 2011b ] .Kapil Thadani and Kathleen McKeown .Towards strict sentence intersection : Decoding and evaluation strategies .In the Workshop on Monolingual Text - to - Text Generation at ACL - HLT , Portland , Oregon , June 2011 .","label":"Extends","metadata":{},"score":"54.85855"}{"text":"After a learning session with AutoTutor , the affective states of the learner were classified by the learner , a peer , and judges trained on Ekman 's Facial Action Coding system .The classification of the trained judges was more reliable and matched the learners much better than the low scores of untrained peers .","label":"Extends","metadata":{},"score":"54.889774"}{"text":"As in Baker et al , each observation lasted twenty seconds , and was conducted using p ..Affect - aware technologies are moving the frontiers of how we understand , support , and optimize student learning .The authors explore five areas that exemplify cutting - edge research in the burgeoning field .","label":"Extends","metadata":{},"score":"54.917057"}{"text":"This may provide a more accurate model but it may not capture the characteristics of the automatic feature in the test set .Table 8 gives results for the two methods .One can see from this table that there is a slight , insignificant increase in accuracy for Exchange 1 and the whole dialogue using the hand - labelled - training method .","label":"Extends","metadata":{},"score":"55.013237"}{"text":"[ Wang and Hirschberg , 2011 ] .William Yang Wang and Julia Hirschberg .Detecting levels of interest from spoken dialog with multistream prediction feedback and similarity based hierarchical fusion learning .In Proceedings of SIGDIAL 2011 , Portland OR , 2011 .","label":"Extends","metadata":{},"score":"55.03236"}{"text":"6.2 Precision and Recall The performance of the system that uses automatic features ( including auto - SLU - success ) for the first utterance is given in Table 6 .This system has an overall accuracy of 69.6 % .These results show that , given the first exchange , the ruleset predicts that 18.3 % of the dialogues will be problematic , while 33 % of them actually will be .","label":"Extends","metadata":{},"score":"55.087948"}{"text":"To ensure good applicability to the real world , spontaneous speech and nonacted nonprototypical emotions are examined in the recently popular dimensional model in 3D continuous space .As there is a lack of linguistic analysis approaches and experiments for this model , various methods are proposed .","label":"Extends","metadata":{},"score":"55.269867"}{"text":"\" A number of scene classification studies have explored the relevance of low - level features in capturing scene characteristics .These reports suggest that low - level acoustic features are powerful in distinguishing simple scenes . \"\" SIFT or SURF features [ 5 ] , distributed acoustic SLAM ( DASLAM ) would be based on matching acoustic events .","label":"Extends","metadata":{},"score":"55.29117"}{"text":"( PDF ) .Kristen Parton , Joel Tetreault , Nitin Madnani , and artin Chodorow .E - rating machine translation .In Proceedings of WMT , 2011 .( PDF ) .[ Petinot et al . , 2011 ] .","label":"Extends","metadata":{},"score":"55.491013"}{"text":"The system 's Dialogue Manager decides among several different hypotheses produced by the slu module , and logs its hypothesis about what task the user was asking hmihy to perform ; the Dialogue Manager 's hypothesis is known as the sys - label . ffl Acoustic / ASR Features - recog , recog - numwords , asr - duration , dtmf - flag , rg - modality actual modality of the user utterance .","label":"Extends","metadata":{},"score":"55.5865"}{"text":"All of this is to improve our services .We use Google Analytics to collect anonymous statistical information such as the number of visitors to our site .Cookies added by Google Analytics are governed by the privacy policies of Google Analytics .","label":"Extends","metadata":{},"score":"55.595367"}{"text":"Section 5 describes the training and results of the auto - SLU - success predictor and Section 6 reports the accuracy results for the PDP . ffl Hand - Labelled Features - tscript , human - label , age , gender , user - modality , clean - tscript , cltscriptnumwords , SLU - success Figure 7 : Features for spoken dialogues .","label":"Extends","metadata":{},"score":"55.77951"}{"text":"event data .One of the advantages of PCA is to allow for a faster execution of the training process by reducing the num- ber of features .Moreover , by combining the most discrimi- nating features into a small set , the PCA removes unimportant data that can decrease the performance of machine learning algorithms such as SVMs .","label":"Extends","metadata":{},"score":"55.813065"}{"text":"Papers - Search Results .Ani Nenkova Advaith Siddharthan and Kathleen McKeown .Information status distinctions and referring expressions : An empirical study of references to people in news summaries .Computational Linguistics , 37(4):811 - 842 , 2011 .( PDF ) .","label":"Extends","metadata":{},"score":"55.813454"}{"text":"openSMILE 2.2 release candidate 1 is now available ( Oct. 2nd 2015 ) .This is the first release which contains the configuration files for the first release of the Geneva Minimalistic Acoustic Parameter Set ( GeMAPS ) .Get your copy today in the download section .","label":"Extends","metadata":{},"score":"55.83457"}{"text":"Features Used Accuracy baseline ( majority class ) 43.1 % automatic 90.1 % Table 1 : Results for detecting slu Errors using ripper Figure 10 shows some top performing rules that ripper learns when given all the features .These rules directly reflect the usefulness of the slu features .","label":"Extends","metadata":{},"score":"55.854794"}{"text":"[ Wang et al . , 2011 ] .William Yang Wang , Kapil Thadani , and Kathleen McKeown .Identifying event descriptions using co - training with online news summaries .In proceedings of IJCNLP , Chiang - Mai , Thailand , Nov 2011 .","label":"Extends","metadata":{},"score":"55.857323"}{"text":"The motivation for the asr features is that any one of them may reflect recognition performance with a concomitant effect on spoken language understanding .For example , other work has found asr - duration to be correlated with incorrect recognition ( Hirschberg , Litman , & Swerts , 1999 ) .","label":"Extends","metadata":{},"score":"55.885345"}{"text":"We conducted an experiment using a subset of tasksuccess dialogues in the same proportion as taskfailure for the training and the test set and trained a second PDP using the fully automatic Exchange 1&2 features .This resulted in a training set of 690 dialogues and a test set of 216 .","label":"Extends","metadata":{},"score":"55.983677"}{"text":".. ing interaction with an intelligent tutoring system .The limitation with this approach is that one affective state is not sufficient to encompass the whole gamut of learning [ 5].Another problem with the single state detection appro ... . by Kate Forbes - riley , Diane Litman - Proceedings of the 14th International Conference on Artificial Intelligence and Education , 2009 . \" ... Abstract .","label":"Extends","metadata":{},"score":"56.085064"}{"text":"Table 1 summarizes the overall accuracy results of the system trained on the whole training set and tested on the test set described in Section 3 .The first line of Table 1 represents the accuracy from always guessing the majority class ( no - recog ) ; this is the baseline against which the other results should be compared .","label":"Extends","metadata":{},"score":"56.12892"}{"text":"Section 5 presents the method of predicting the feature auto - SLU - success and gives accuracy results .Section 6 presents methods used for utilizing ripper to train the automatic Problematic Dialogue Predictor and gives the results .We delay our discussion of related work to Section 7 when we can compare it to our approach .","label":"Extends","metadata":{},"score":"56.309395"}{"text":"highly dependent on the set of features .audio event has distinct frequency characteristics , we have explored an extended set of features that includes pitch .Because the pitch was extracted using 20ms windows and all the other features were extracted using 500ms windows , for every feature vector we included several pitch values .","label":"Extends","metadata":{},"score":"56.316345"}{"text":"The integration of cues derived from the audio signal is es- sential for many types of search concepts .Our role in the project is to contribute towards this integration with three dif- ferent modules : audio segmentation , speech recognition , and detection of audio events .","label":"Extends","metadata":{},"score":"56.392967"}{"text":"The system they built could detect differences in the phonetic structure of sober and intoxicated speech .William Yang Wang , currently a PhD student at Carnegie Mellon that worked on this team while a Master 's student , discussed the project and its goals with us .","label":"Extends","metadata":{},"score":"56.421944"}{"text":"The first was the number of words in the cleaned transcript ( cltscript - numwords ) , again on the assumption that utterance length is strongly correlated with asr and slu errors .The second derived feature was based on calculating whether the human - label matches the sys - label from the Dialogue Manager ( SLU - success ) .","label":"Extends","metadata":{},"score":"56.42601"}{"text":"Krahmer , E. , Swerts , M. , Theune , M. , & Weegels , M. ( 1999a ) .Problem spotting in humanmachine interaction .In Proc .Eurospeech 99 .Krahmer , E. , Swerts , M. , Theune , M. , & Weegels , M. ( 1999b ) .","label":"Extends","metadata":{},"score":"56.541306"}{"text":"[ 16 ] F. de Rosis , A. Batliner , N. Novielli , and S. Steidl , \" ' You Are Sooo Cool , Valentina ! 'Recognizing Social Attitude in Speech - Based Dialogues with an ECA , \" Affective Computing and Intelligent Interaction , A. Paiva , R. Prada , and R.W. Picard , eds . , pp .","label":"Extends","metadata":{},"score":"56.54789"}{"text":"This project augments an existing intelligent tutoring system ( AutoTutor ) that helps learners construct explanations by interacting with them in natural language and helping them use simulation environments .The research aims to develop an agile learning environment that is sensitive to a learner 's ... \" .","label":"Extends","metadata":{},"score":"56.72335"}{"text":"[ Guo and Diab , 2011 ] .Weiwei Guo and Mona Diab .Semantic topic models : Combining word distributional statistics and dictionary definitions .In Proceedings of EMNLP , Edinburgh , UK , 2011 .( PDF ) .[ Levitan and Hirschberg , 2011 ] .","label":"Extends","metadata":{},"score":"56.745163"}{"text":"Unfortunately , due to data sparsity and other problems , the final results using the prosodic approach were not as good as what we had in previous emotional speech classification tasks .The second property we looked at was the changes of phone durations in intoxication state .","label":"Extends","metadata":{},"score":"56.784855"}{"text":"Finally , we give results for the system trained only on auto - SLU - success and hlt - SLUsuccess .One can see that there is not much difference in the two sets of results .On examining the ruleset , one finds that the hlt - SLU - success uses rpartialmismatch where the auto - SLU - success ruleset does not .","label":"Extends","metadata":{},"score":"56.788155"}{"text":"Related Work The research reported here is the first that we know of to automatically analyze a corpus of logs from a spoken dialogue system for the purpose of learning to predict problematic situations .This work builds on two strands of earlier research .","label":"Extends","metadata":{},"score":"56.86554"}{"text":"This paper focuses on the detection of non - speech events , and as such only searches for events in audio segments that have been previously classified as non-speech .Preliminaryexperimentswithasmallcorpusofsound effects have shown the potential of this type of corpus for training purposes .","label":"Extends","metadata":{},"score":"56.95292"}{"text":"We developed a metric to measure the relative likelihood of transitioning from an affective state at time ti to a subsequent affective state at time ti+1 .Several significant trajectories between affective states were identified .Instructional implications are discussed in the context of an expanded version of a cognitive disequilibrium model . .","label":"Extends","metadata":{},"score":"57.131104"}{"text":"Age prediction in blogs : A study of style , content , and online behavior in pre- and post - social media generations .In proceedings of ACL - HLT , 2011 .( PDF ) .Masoud Rouhizadeh , Daniel Bauer , Bob Coyne , Owen Rambow , and Richard Sproat .","label":"Extends","metadata":{},"score":"57.13151"}{"text":"The context - shift feature incorporates this knowledge of the discourse history , with the motivation that if it appears that the caller has changed her mind , then the slu module may have misunderstood an utterance .The Dialogue Manager decides whether it believes there is a single unambiguous task that the user is trying to accomplish , and how to resolve any ambiguity .","label":"Extends","metadata":{},"score":"57.153442"}{"text":"Most of the files have a sampling rate of 44.1kHz .This real life corpus covers 13 of the 15 audio events .The development experiments described in this paper will be assessed in terms of the well - known F - measure .","label":"Extends","metadata":{},"score":"57.270325"}{"text":"Levow 's experiments train a decision tree using features such as duration , tempo , pitch , amplitude , and within - utterance pauses .Examination of the trained tree in this study also reveals that the durational features are the most discriminatory .","label":"Extends","metadata":{},"score":"57.404465"}{"text":"Levow 's experiments train a decision tree using features such as duration , tempo , pitch , amplitude , and within - utterance pauses .Examination of the trained tree in this study also reveals that the durational features are the most discriminatory .","label":"Extends","metadata":{},"score":"57.404465"}{"text":"The salience - coverage feature measures the proportion of the utterance which is covered by the salient grammar fragments .This may include the whole of a phone or card number if it occurs within a fragment .The context - shift feature is an inter - utterance measure of the extent of a shift of context away from the current task focus , caused by the appearance of salient phrases that are incompatible with it , according to a task model of the domain .","label":"Extends","metadata":{},"score":"57.498558"}{"text":"Left - to - right models with several number of states and Gaussian mixtures were trained to tune these parameters according to the development set re- sults .MFCC features ( 12 coefficients + energy + deltas ) of three different window lengths were used .","label":"Extends","metadata":{},"score":"57.76677"}{"text":"Learning systems , Research and development , Artificial intelligence , Education , human - computer interaction , advanced learning technologies , affective computing , affect and learning .CITATION .Rafael A. Calvo , Sidney D'Mello , \" Frontiers of Affect - Aware Learning Technologies \" , IEEE Intelligent Systems , vol.27 , no .","label":"Extends","metadata":{},"score":"57.836357"}{"text":"If a problem can be detected , the system can either transfer the call to a human customer care agent or modify its dialogue strategy in an attempt to cfl2002 AI Access Foundation and Morgan Kaufmann Publishers .All rights reserved .","label":"Extends","metadata":{},"score":"57.85563"}{"text":"We are currently working towards reducing the differences between the training / development and test data by using normalization techniques , and we are also testing agglomerative clustering approaches .We observed that HMMs are a promising method for our AED task that justifies further tests .","label":"Extends","metadata":{},"score":"57.867485"}{"text":"We show that a Problematic Dialogue Predictor using automaticallyobtainable features from the first two exchanges in the dialogue can predict problematic dialogues 13.2 % more accurately than the baseline .Introduction Spoken dialogue systems promise efficient and natural access to a large variety of information sources and services from any phone .","label":"Extends","metadata":{},"score":"57.975018"}{"text":"The goal of SEMAINE was to design an automated virtual agent with affective and social skills .openSMILE served the purpose of a real - time speech and emotion analyser component in this system .In the final SEMAINE release , version 1.0.1 of openSMILE is used .","label":"Extends","metadata":{},"score":"57.99231"}{"text":"Furthermore , string kernels are considered .By early fusion and combined space optimization of the proposed linguistic features with acoustic ones , the regression of continuous emotion primitives outperforms reported benchmark results on the VAM corpus of highly emotional face - to - face communication .","label":"Extends","metadata":{},"score":"58.066254"}{"text":"In fact , Fadi Biadsy has just finished his PhD thesis on automatic dialect and accent identification at Columbia , so we thought it would be an interesting idea to run his system on this dataset .Which properties of speech did you study in your work ?","label":"Extends","metadata":{},"score":"58.157684"}{"text":"Or Biran , Samuel Brody , and Noemie Elhadad .Putting it simply : a context - aware approach to lexical simplification .In Proceedings of the 49thAnnual Meeting of the Association for Computational Linguistics : Human Language Technologies ( ACL - HLT 2011 ) , 2011 .","label":"Extends","metadata":{},"score":"58.360016"}{"text":"[ Biran and Rambow , 2011b ] .Or Biran and Owen Rambow .Identifying justifications in written dialog by classifying text as argumentative .International Journal of Semantic Computing , 5(4):363 - 381 , December 2011 .( PDF ) .","label":"Extends","metadata":{},"score":"58.579506"}{"text":"They observe that disconfirmations are longer , have a marked word order , and contain specific lexicon such as ' ' no ' ' .In addition , there are specific prosodic cues such as boundary tones and pauses .Some of these features such as length , choice of words are captured in our RIPPER ruleset as discussed above .","label":"Extends","metadata":{},"score":"58.59083"}{"text":"Visual SLAM depends on matching local features between images , whereas distributed acoustic SLAM is based on matching acoustic events .Proposed DASLAM is based on distributed microphone arrays , where each microphone is connected to a separate , moving , controllable recording device , which requires compensation for their different clock shifts .","label":"Extends","metadata":{},"score":"58.600323"}{"text":"Since the initial results were quite promising , we moved on to a larger corpus of approximately 18700 files with an estimated total duration of 289.6h , also provided by B&G.The corpus includes enough training mate- rial for over 40 different audio events , but so far we have only considered15 .","label":"Extends","metadata":{},"score":"58.619095"}{"text":"In CoSLI-2 ( Computational Models for Spatial Languages ) at CogSci 2011 , 2011 .( PDF ) .[ Rush and Collins , 2011 ] .Alexander M. Rush and Michael Collins .Exact decoding of syntactic translation models through lagrangian relaxation .","label":"Extends","metadata":{},"score":"58.877758"}{"text":"New release announcement ( for Dec 2014 ) : A next full release ( version 2.1 ) is on its way .Compared to the previous 2.0-rc1 there have been many fixes and improvements and some new features .The release is delayed , but scheduled to be released before christmas .","label":"Extends","metadata":{},"score":"58.887337"}{"text":"In Proceedings of Workshop on Speech and Language Technology in Education ( SlaTE ) at Interspeech 2011 , 2011 .( PDF ) .[Gravan and Hirschberg , 2011 ] .Agustín Gravan and Julia Hirschberg .Turn - taking cues in task - oriented dialogue .","label":"Extends","metadata":{},"score":"59.11653"}{"text":"In order to test the auto - SLU - success predictor as input to the PDP , we first defined a training and test set for the combined problem .The test set for the auto - SLU - success predictor contains the exchanges that occur in the dialogues of the PDP test set .","label":"Extends","metadata":{},"score":"59.20749"}{"text":"Conf .Int'l Speech Comm .Assoc . , pp .797 - 800 , 2006 .[29 ] J. Ang , R. Dhillon , E. Shriberg , and A. Stolcke , \" Prosody - Based Automatic Detection of Annoyance and Frustration in Human - Computer Dialog , \" Proc .","label":"Extends","metadata":{},"score":"59.298798"}{"text":"One would expect longer utterances to be more difficult , but the learned rulesets indicate that duration is a better measure of utterance length than the number of words .These features seem to provide good general indicators of the system 's success in recognition and understanding .","label":"Extends","metadata":{},"score":"59.305206"}{"text":"Classification results in the test set are smoothed over time [ 9].TWO - STAGE AED Our initial experiments with the pilot sound effect corpus led us into adopting a two - stage approach for audio event de- tection .","label":"Extends","metadata":{},"score":"59.31821"}{"text":"However , in case of acoustic SLAM the event detection and classification accuracy is irrelevant .\" [ Show abstract ] [ Hide abstract ] ABSTRACT : Vision - based methods are very popular for simultaneous localization and environment mapping ( SLAM ) .","label":"Extends","metadata":{},"score":"59.349228"}{"text":"32 - 80 , Jan. 2001 .[5 ] B. Schuller , C. Hage , D. Schuller , and G. Rigoll , \" ' Mister D.J. , Cheer Me Up ! ' : Musical and Textual Features for Automatic Mood Classification , \" J. New Music Research , vol .","label":"Extends","metadata":{},"score":"59.597916"}{"text":"These automatically derived features provide a better training model than the hand - labelled ones .This is true also in the current study as discussed in Section 6.1 .We explored the possibility of predicting student emotions ( boredom , flow / engagement , confusion , and frustration ) by analyzing the text of student and tutor dialogues during interactions with an Intelligent Tutoring System ( ITS ) with conversational dialogues .","label":"Extends","metadata":{},"score":"59.641376"}{"text":"Yet there are still many research challenges : current systems are limited in the interaction they support and brittle in many respects .This paper investigates methods by which spoken dialogue systems can learn to support more natural interaction on the basis of their previous experience .","label":"Extends","metadata":{},"score":"60.10717"}{"text":"147 - 187 , 2010 .In order to provide you with the best online experience this website uses cookies .Information cookies .Cookies are short reports that are sent and stored on the hard drive of the user 's computer through your browser when it connects to a web .","label":"Extends","metadata":{},"score":"60.20893"}{"text":"It contains a detailed and most up - to - date description of all the components that are currently included in the toolkit .Another good resource is the on - line help of the commandline feature extractor .Type SMILExtract -H to get help on using it .","label":"Extends","metadata":{},"score":"60.230186"}{"text":"Given the unavailability of a corpus labeled in terms of audio events , we used a sound effect corpus for training .The potential of this type of corpus was proved in early experi- ments with a small pilot corpus [ 9].","label":"Extends","metadata":{},"score":"60.398132"}{"text":"Thus , we trained ripper using only features that are both automatically acquirable during runtime and independent of the hmihy task .The subset of features from Figure 7 that fit this qualification are in Figure 9 .We refer to them as the auto , task - indept feature set .","label":"Extends","metadata":{},"score":"60.471527"}{"text":"On the other hand , touchtone input in combination with speech , as encoded by the feature dtmf - flag , might increase the likelihood of understanding the speech : since the touchtone input is unambiguous it can constrain spoken language understanding .","label":"Extends","metadata":{},"score":"60.5665"}{"text":"We have investigated high level prosodic , phone duration , phonotactic , and phonetic cues to intoxicated speech .The first thing we looked at was the n - gram frequencies of prosodic events in an utterance , where we hypothesize energetic and depressed intoxicated speakers might use higher and lower rates of emphasis ( pitch accents ) than sober speakers .","label":"Extends","metadata":{},"score":"60.667908"}{"text":"Previous studies on error correction recognition are also related to our method of misunderstanding recognition .[LevowLevow1998 ] applied similar techniques to learn to distinguish between utterances in which the user originally provided some information to the system , and corrections , which provided the same information a second time , following a misunderstanding .","label":"Extends","metadata":{},"score":"60.711758"}{"text":"They observe that disconfirmations are longer , have a marked word order , and contain specific lexicon such as \" no \" .In addition , there are specific prosodic cues such as boundary tones and pauses .Some of these features such as length , choice of words are captured in our ripper ruleset as discussed above .","label":"Extends","metadata":{},"score":"60.773666"}{"text":"Features logged by the system are utilized because they are produced automatically , and thus can be used during runtime to alter the course of the dialogue .Each module and the features obtained from it are described below .Automatic Speech Recognition : The automatic speech recognizer ( asr ) takes as input the caller 's speech and produces a potentially errorful transcription of what it believes the caller said .","label":"Extends","metadata":{},"score":"60.834427"}{"text":"Computer Systems That Learn : Classification and Prediction Methods from Statistics , Neural Nets , Machine Learning , and Expert Systems .San Mateo , CA : Morgan Kaufmann .Wright , H. ( 2000 ) .Modelling Prosodic and Dialogue Information for Automatic Speech Recognition .","label":"Extends","metadata":{},"score":"60.892387"}{"text":"This second method is referred to as \" hand - labelled - training \" or hlt - SLU - success .This may provide a more accurate model but it may not capture the characteristics of the automatic feature in the test set .","label":"Extends","metadata":{},"score":"60.89521"}{"text":"The sys - label feature is intended to capture the fact that some tasks may be harder than others .The utt - id feature is motivated by the idea that the length of the dialogue may be important , possibly in combination with other features like sys - label .","label":"Extends","metadata":{},"score":"60.90445"}{"text":"Abstract : Spoken dialogue systems promise efficient and natural access to a large variety of information sources and services from any phone .However , current spoken dialogue systems are deficient in their strategies for preventing , identifying and repairing problems that arise in the conversation .","label":"Extends","metadata":{},"score":"60.99363"}{"text":"The log files also included labels indicating whether the wizard had taken over the call or the user had hung up .Our experiments use the log files to extract automatically obtainable features used as predictors , and to define the classes of dialogues that we want to learn to predict .","label":"Extends","metadata":{},"score":"61.062737"}{"text":"Our model is based on a probabilistic framework that deals with the high level of uncertainty involved in recognizing a ... \" .We present a probabilistic model of user affect designed to allow an intelligent agent to recognise multiple user emotions during the interaction with an educational computer game .","label":"Extends","metadata":{},"score":"61.140533"}{"text":"Comparing rows 2 and 4 , neither of which use auto - SLU - success , one sees a slight degradation in results for the whole dialogue using task - indept features .This shows that using auto - SLU - success in combination with the set of task - indept features produces a statistically significant increase in accuracy over a set of automatic features that does not include this feature .","label":"Extends","metadata":{},"score":"61.29496"}{"text":"The results show that fewer taskfailures are predicted as successful , suggesting that taskfailures are not inherently more difficult to predict than other classes of problematic dialogues .Below we discuss the potential of using ripper 's loss ratio to weight different types of classification errors in future work .","label":"Extends","metadata":{},"score":"61.348198"}{"text":"[70 ] B. Schuller , R. Müller , F. Eyben , J. Gast , B. Hörnler , M. Wöllmer , G. Rigoll , A. Höthker , and H. Konosu , \" Being Bored ?Recognising Natural Interest by Extensive Audiovisual Integration for Real - Life Application , \" J. Image and Vision Computing , vol .","label":"Extends","metadata":{},"score":"61.47641"}{"text":"Figure 8 gives an example of the encoding of some of the automatic features for the second exchange of the wizard dialogue in Figure 3 .The prefix \" e2- \" designates the second exchange .We discuss several of the features values here to ensure that the reader understands the way in which the features are used .","label":"Extends","metadata":{},"score":"61.547707"}{"text":"Classification accuracy was poor at constant intervals of polling ( every 20 seconds ) but much higher when individuals declared that an affect state had been experienced . ...e minimal relevance to learning per se ( Kort et al . , 2001 ) .","label":"Extends","metadata":{},"score":"61.721806"}{"text":"In other words , the system frequently misinterprets long utterances as DIAL - FOR - ME resulting in task failure .Figure 12 gives a subset of the ruleset for the task - indept feature set for Exchanges 1&2 .One can see a similarity between this ruleset and the one given in Figure 11 .","label":"Extends","metadata":{},"score":"61.840073"}{"text":"Table 5 shows the results for the SVMs using PLPs ( with deltas or SDC ) , the 3 additional features and pitch .The results were slightly worse compared to Table 3 .Since the Siren 4.4 .Data dimensionality reduction The results obtained by adding the pitch feature have shown that increasing the number of features may decrease the per- formance of the SVMs .","label":"Extends","metadata":{},"score":"61.893394"}{"text":"One can see that the top two rules use auto - SLU - success .The first rule basically states that if there is no recognition for the second exchange ( as predicted by the auto - SLUsuccess ) then the dialogue will fail .","label":"Extends","metadata":{},"score":"61.965714"}{"text":"The third study assessed the reliability of automatic detection of boredom , confusion , delight , flow , and frustration ( versus the neutral baseline ) from sensors that monitored the manner in which learners communicate affect through conversational cues , gross body language , and facial expressions .","label":"Extends","metadata":{},"score":"62.061626"}{"text":"We have released the next final release of openSMILE with support for Windows , Linux , MacOS , and Android and new features such as LSTM - RNN decoder components that support CURRENNT and RNNLIB network formats as well as updated reference feature sets .","label":"Extends","metadata":{},"score":"62.112957"}{"text":"In some situations , one might not need to distinguish between the different misunderstanding categories : no - recog , rmismatch and rpartial - match .This resulted in a recognition accuracy of 92.4 % , a 29.4 % improvement over the baseline of 63 % , which is the percentage of rincorrect exchanges .","label":"Extends","metadata":{},"score":"62.12194"}{"text":"558 - 601 , 2008 , doi:10.1080/08839510802226801 .[ 44 ] S. D'Mello and A. Graesser , \" Multimodal Semi - Automated Affect Detection from Conversational Cues , Gross Body Language , and Facial Features , \" User Modeling and User - Adapted Interaction , vol .","label":"Extends","metadata":{},"score":"62.227013"}{"text":"Each dialogue and exchange is encoded using the set of 53 features in Figure 7 .Each feature was either automatically logged by one of the system modules , hand - labelled by humans , or derived from raw features .The hand - labelled features are used to produce a topline , an estimation of how well a classifier could do that had access to perfect information .","label":"Extends","metadata":{},"score":"62.351643"}{"text":"by Roger S. Taylor , Art Graesser - in : Proceedings of the 29th Annual Meeting of the Cognitive Science Society , 2007 . \" ...This study investigated the transitions between affective states ( i.e. , boredom , flow , confusion , frustration , delight , and surprise ) during learning while college students were tutored in computer literacy by AutoTutor , an automated tutoring system with natural language dialogue .","label":"Extends","metadata":{},"score":"62.374744"}{"text":"In the experiments , the features in Figure 7 , excluding the hand - labelled features , are referred to as the automatic feature set .The experiments test how well misunderstandings can be identified and whether problematic dialogues can be predicted using the automatic features .","label":"Extends","metadata":{},"score":"62.379158"}{"text":"The training of the auto - SLU - success feature is discussed in Section 5 .Evidence from previous trials of hmihy suggest that it is important to identify problems within a couple of exchanges and 97 % of the dialogues in the corpus are five exchanges or less .","label":"Extends","metadata":{},"score":"62.442696"}{"text":"We look forward to hearing more about intoxication detection in speech in future challenges !References .[ 1 ] Bjorn Schuller , Stefan Steidl , Anton Batliner , Florian Schiel , Jarek Krajewski . \"The INTERSPEECH 2011Speaker State Challenge \" , in Proceedings of the 12th Annual Conference of the International Speech Communication Association ( INTERSPEECH 2011 ) , Florence , Italy 28 - 31 Aug. , 2011 .","label":"Extends","metadata":{},"score":"62.47354"}{"text":"Therefore , we used a cross - validation technique ( also known as jack - knifing ) ( Weiss & Kulikowski , 1991 ) , whereby the training set is partitioned into 4 sets .Three of these sets are used for training and the fourth for testing .","label":"Extends","metadata":{},"score":"62.555214"}{"text":"In ESCA Workshop on Interactive Dialogue in Multi - Modal Systems .Langkilde , I. , Walker , M. A. , Wright , J. , Gorin , A. , & Litman , D. ( 1999 ) .Automatic prediction of problematic human - computer dialogues in How May I Help You ?","label":"Extends","metadata":{},"score":"62.587284"}{"text":"In this trial , the hmihy system was installed at an AT&T customer care center .hmihy answered calls from live customer traffic and successfully automated a large number of customer requests .An example dialogue that hmihy completed successfully is shown in Figure 1 .","label":"Extends","metadata":{},"score":"62.63389"}{"text":"Researchers at Columbia are investigating a crucial problem in this space - ways to automatically detect intoxication in speech .In a recent presentation at the Intoxication Sub - Challenge at Interspeech , the Columbia group discussed their approach [ 1 , 2].","label":"Extends","metadata":{},"score":"62.83941"}{"text":"The experimental architecture of the PDP is illustrated in Figure 5 .This shows how ripper is used first to predict auto - SLU - success for the first and second exchanges .This feature is fed into the PDP along with the other automatic features .","label":"Extends","metadata":{},"score":"63.034866"}{"text":"In Natural Language Engineering : Special Issue on Best Practice in Spoken Dialogue Systems .Walker , M. A. , Langkilde , I. , Wright , J. , Gorin , A. , & Litman , D. ( 2000b ) .Learning to Predict Problematic Situations in a Spoken Dialogue System : Experiments with How May I Help You ?","label":"Extends","metadata":{},"score":"63.782814"}{"text":"Some of the potentially interesting Dialogue Manager events arise due to low slu confidence levels which lead the Dialogue Manager to reprompt the user or confirm its understanding .A reprompt might be a variant of the same question that was asked before , or it could include asking the user to choose between two tasks that have been assigned similar confidences by the slu module .","label":"Extends","metadata":{},"score":"63.801704"}{"text":"Estimation is done using particle filtering .Results show that both tasks can be accomplished with good precision , even for the theoretically underdetermined cases .For example , we were able to achieve mapping error as low as 17.53 cm for sound sources with localization error of 18.61 cm and clock synchronization error of 42 μs for 2 robots and 2 sources .","label":"Extends","metadata":{},"score":"63.808052"}{"text":"Baggia , P. , Castagneri , G. , & Danieli , M. ( 1998 ) .Field Trials of the Italian ARISE Train Timetable System .In Interactive Voice Technology for Telecommunications Applications , IVTTA , pp .97 - 102 .","label":"Extends","metadata":{},"score":"64.01437"}{"text":"affective states were defined for the learners before the experiment started .This result confirms the hypothesis that Ekman 's basic emotions play nonsignificant roles in learning , Although eureka was relatively well reported , we ... . by Sidney K. D'mello , Scotty D. Craig , Barry Gholson , Stan Franklin - In Affective Interactions : The Computer in the Affective Loop Workshop at 2005 Intl .","label":"Extends","metadata":{},"score":"64.11209"}{"text":"Since 23 % of the dialogues consisted of only two exchanges , we exclude the second exchange features for those dialogues where the second exchange consists only of the system playing a closing prompt .We also excluded any features that indicated to the classifier that the second exchange was the last exchange in the dialogue .","label":"Extends","metadata":{},"score":"64.12911"}{"text":"We then study a phonotactic based language / accent identification technique for this task , where we believe intoxicated speakers might use certain phones or words more frequently than others .The experiment results showed that our hypothesis was correct .Finally , we have investigated a state - of - the - art accent identification technique where we hypothesize intoxicated speakers realize certain phones differently than sober speakers .","label":"Extends","metadata":{},"score":"64.135666"}{"text":"The other use would be as input to the Dialogue Manager 's dialogue strategy selection mechanism .Demonstrating the utility of the PDP for dialogue strategy selection requires experiments that test out several different ways that this information could be used by the Dialogue Manager .","label":"Extends","metadata":{},"score":"64.235535"}{"text":"ripper is based on the incremental reduced error pruning ( IREP ) algorithm described in ( Furnkranz & Widmer , 1994 ) .ripper improves on IREP with an information gain metric to guide rule pruning and a Minimum Description Length or MDL - based heuristic for determining how many rules should be learned ( see Cohen 1995 , 1996 for more details ) .","label":"Extends","metadata":{},"score":"64.71757"}{"text":"When tested in the sound effect corpus , the SNS some- times detects speech in non - speech events , as shown in the fourth column of Table 1 , which contains the duration of the detected speech segments .This observation motivated the retraining of the detector including non - speech examples randomly selected from the large sound effects corpus ( excluding the files that were used for training each audio event classifier ) .","label":"Extends","metadata":{},"score":"64.77233"}{"text":"Vignet : Grounding language in graphics using frame semantics .In Proceedings of ACL Workshop on Relational Models of Semantics ( RELMS 2011 ) , 2011 .( PDF ) .Bob Coyne , Cecilia Schudel , Michael Bitz , and Julia Hirschberg .","label":"Extends","metadata":{},"score":"65.0659"}{"text":"Evaluation of the dutchtrain timetable information system developed in the ARISE project .In Interactive Voice Technology for Telecommunications Applications , IVTTA , pp .91- 96 .Seneff , S. , Zue , V. , Polifroni , J. , Pao , C. , Hetherington , L. , Goddeau , D. , & Glass , J. ( 1995 ) .","label":"Extends","metadata":{},"score":"65.122665"}{"text":"We show that the basic adaptive system outperforms the normal ( non - adaptive ) and empirical ( adaptive ) systems in terms of learning efficiency .We also show that the empirical ( adaptive ) and random ( non - adaptive ) systems outperform the basic adaptive system in terms of user perception of tutor response quality .","label":"Extends","metadata":{},"score":"65.22573"}{"text":"In ARPA Spoken Language Technology Workshop .Shriberg , E. , Wade , E. , & Price , P. ( 1992 ) .Human - machine problem solving using spoken language systems ( SLS ) : Factors affecting performance and user satisfaction .","label":"Extends","metadata":{},"score":"65.73846"}{"text":"Audio Events Detection ( AED ) is a relatively new re- search area with ambitious goals .Typical AED frameworks are composed of at least two parts : feature extraction and au- dio event inference .Brightness and band- width are , respectively , the first and second order statistics of the spectrogram , and they roughly measure the timbre qual- ity of the sound .","label":"Extends","metadata":{},"score":"65.96591"}{"text":"Although , the task - indept feature sets are a subset of those features used in row 3 , it is possible for them to perform better because the task - indept features are more general , and because ripper uses a greedy algorithm to discover its rule sets .","label":"Extends","metadata":{},"score":"66.18087"}{"text":"As discussed above , initial experiments showed that the hand - labelled SLU - success feature , which encodes whether an utterance has been misunderstood or not , is highly discriminatory in identifying problematic dialogues .However , all the features used to train the PDP must be totally automatic if we are to use the PDP in a working spoken dialogue system .","label":"Extends","metadata":{},"score":"66.74379"}{"text":"A feature available for identifying problematic dialogues is dial - duration that is not available for initial segments of the dialogue .Hand Labelling : As mentioned above , the features obtained via hand - labelling are used to provide a topline against which to compare the performance of the fully automatic features .","label":"Extends","metadata":{},"score":"67.12674"}{"text":"An emotionally responsive tutor would presumably facilitate learning , but ... \" .The relationship between emotions and learning was investigated by tracking the affective states that college students experienced while interacting with AutoTutor , an intelligent tutoring system with conversational dialogue .","label":"Extends","metadata":{},"score":"67.27042"}{"text":"Assoc . , pp .340 - 343 , 2009 .[ 13 ] B. Schuller , J. Schenk , G. Rigoll , and T. Knaup , \" The ' Godfather ' vs. ' Chaos ' : Comparing Linguistic Analysis Based on Online Knowledge Sources and Bags - of - N - Grams for Movie Review Valence Estimation , \" Proc . 10th Int'l Conf .","label":"Extends","metadata":{},"score":"67.74878"}{"text":"Detecting Intoxication in Speech .Matthew Marge .SLTC Newsletter , October 2011 .Researchers at Columbia are investigating ways to automatically detect intoxication in speech .William Yang Wang , currently a PhD student at Carnegie Mellon that worked on this team while a Master 's student , discussed the project and its goals with us .","label":"Extends","metadata":{},"score":"67.78483"}{"text":"Auto - SLU - success Predictor The goal of the auto - SLU - success predictor is to identify , for each exchange , whether or not the system correctly understood the user 's utterance .As mentioned above , when the dialogues were transcribed by humans after the data collection was completed , the human labelers not only transcribed the users ' utterances , but also labelled each utterance with a semantic category representing the task that the user was asking hmihy to perform .","label":"Extends","metadata":{},"score":"67.90715"}{"text":"ACM Multimedia ( MM ) , ACM , Florence , Italy , ACM , ISBN 978 - 1 - 60558 - 933 - 6 , pp .1459 - 1462 , October 2010 .doi : 10.1145/1873951.1874246 .We are always happy to hear what people are using openSMILE for .","label":"Extends","metadata":{},"score":"68.027756"}{"text":"SMILE is an acronym for Speech & Music Interpretation by Large - space Extraction .It is written in C++ and is available as both a standalone commandline executable as well as a dynamic library .The main features of openSMILE are its capability of on - line incremental processing and its modularity .","label":"Extends","metadata":{},"score":"68.35772"}{"text":"Camille Guinaudeau and Julia Hirschberg .Accounting for prosodic information to improve asr - based topic tracking for tv broadcast news .In Proceedings of 12th Annual Conference of the International Speech Communication Association , Interspeech ' 11 , Florence , Italy , August 2011 .","label":"Extends","metadata":{},"score":"68.58703"}{"text":"Similarly for training , the PDP training set contains 3825 dialogues which corresponds to a total of 16901 exchanges for training the auto - SLU - success predictor .The feature auto - SLU - success is predicted for each utterance in the test set , thus enabling the system to be used on new data without the need for hand - labelling .","label":"Extends","metadata":{},"score":"68.73035"}{"text":"Ad- ditionally , in a speech database , equivalent ( speech ) detection performance to the original SNS1detector was observed .List of audio events : number of files , total duration , and amount of data misclassified as speech ( seconds ) .","label":"Extends","metadata":{},"score":"69.06545"}{"text":"ffl Dialogue Manager Features - utterance by utterance : utt - id , reprompt , confirmation , subdial - running tallies : num - utts , num - reprompts , percent - reprompts , num - confirms , percent - confirms , num - subdials , percent - subdials , dial - duration Figure 9 : Automatic task - independent features available at runtime .","label":"Extends","metadata":{},"score":"69.206215"}{"text":"The challenge is documented in more detail here .For the intoxication challenge , it is interesting to note the wide variety of approaches of taken .-- Jason Williams , 2010 - 10 - 28 .","label":"Extends","metadata":{},"score":"69.43534"}{"text":"ACM Multimedia ( MM ) , Barcelona , Spain , ACM , ISBN 978 - 1 - 4503 - 2404 - 5 , pp .835 - 838 , October 2013 . doi : 10.1145/2502081.2502224 .For older work based on openSMILE version 1.0.1 and below , you may cite this paper : .","label":"Extends","metadata":{},"score":"69.477005"}{"text":"However , please note that you can enable or disable cookies by following the instructions of your browser .openSMILE .Florian Eyben , Felix Weninger , Martin Woellmer , Bjoern Schuller .The openSMILE feature extration tool enables you to extract large audio feature spaces in realtime .","label":"Extends","metadata":{},"score":"69.48079"}{"text":"This is because every call that the hmihy system can handle successfully saves a company the cost of using a human customer care agent to handle the call .Thus , we can associate this cost with the decision that hmihy makes to transfer the call .","label":"Extends","metadata":{},"score":"69.54077"}{"text":"This study investigated the transitions between affective states ( i.e. , boredom , flow , confusion , frustration , delight , and surprise ) during learning while college students were tutored in computer literacy by AutoTutor , an automated tutoring system with natural language dialogue .","label":"Extends","metadata":{},"score":"69.57309"}{"text":"The part of the framework that reasons from causes to emotions ( diagnostic model ) implements a theoretical model of affect , the OCC model , which accounts for how emotions are caused by one 's appraisal of the current context in terms of one 's goals and preferences .","label":"Extends","metadata":{},"score":"70.12979"}{"text":"Its output is a classification model for predicting the class of future examples , expressed as an ordered set of if - then rules .Although any one of a number of learners could be applied to this problem , we had a number of reasons for choosing ripper .","label":"Extends","metadata":{},"score":"70.42381"}{"text":"As mentioned above , dialogues in which hmihy successfully automates the customer 's call , as illustrated in Figure 1 , are referred to as tasksuccess .Other calls , which are problematic , are divided into three categories .The first category , referred to as hangup , results from a customer 's decision to hang up on the system .","label":"Extends","metadata":{},"score":"70.60654"}{"text":"Does this mean that these configuration files implicitly assume 16 kHz sample rate ?No , the frequency range of the Mel - filterbank is configured independet of the sample rate .For a 44.1 kHz input , the filterbank will still only span the frequency range from 20 - 8000 Hz , just zeroing or ignoring all bins above 8 kHz .","label":"Extends","metadata":{},"score":"70.61684"}{"text":"Matthew Marge is a doctoral student in the Language Technologies Institute at Carnegie Mellon University .His interests are spoken dialog systems , human - robot interaction , and crowdsourcing for natural language research .Editor 's note : For more information , readers are referred to the papers presented at the 2011","label":"Extends","metadata":{},"score":"70.65014"}{"text":"In both experiments , we ... \" .While human tutors typically interact with students using spoken dialogue , most computer dialogue tutors are text - based .We have conducted two experiments comparing typed and spoken tutoring dialogues , one in a human - human scenario , and another in a human - computer scenario .","label":"Extends","metadata":{},"score":"70.69779"}{"text":"Wang : At Columbia , we have studied speaker states that do not map directly to the classic or even derived emotions : charismatic speech , deceptive speech , depression , and levels of interest .In this work , we are interested in building a system that can automatically classify intoxicated speech from sober speech , given only a very short sample from the speaker .","label":"Extends","metadata":{},"score":"70.74403"}{"text":"Publisher conditions are provided by RoMEO .Differing provisions from the publisher 's actual policy or licence agreement may be applicable . \"Acoustic event detection and classification ( AED / C ) [ 1 ] recently draws great attention of audio research community [ 2].","label":"Extends","metadata":{},"score":"70.77879"}{"text":"These automatically derived features provide a better training model than the hand - labelled ones .This is true also in the current study as discussed in Section 6.1 .Discussion and Future Work This paper reports results on automatically training a Problematic Dialogue Predictor to predict problematic human - computer dialogues using a corpus of 4692 dialogues collected with the How May I Help You spoken dialogue system .","label":"Extends","metadata":{},"score":"70.88912"}{"text":"In Figure 8 , this is encoded by several features .The feature e2-prompt gives the name of that prompt , top - reject - rep .The feature e2-reprompt specifies that S2 is a reprompt , a second attempt by the system to elicit a description of the caller 's problem .","label":"Extends","metadata":{},"score":"71.256645"}{"text":"There were a number of agents who participated as wizards during the trial of hmihy and each wizard was simply told to take over the call if s / he perceived problems with the system 's performance .The wizard 's decision was logged by the experimental setup , resulting in labelling the call as one that the wizard took over .","label":"Extends","metadata":{},"score":"71.3924"}{"text":"Cookies can be themselves or others .There are several types of cookies : .Customization cookies that allow users to access services according to their preferences ( language , browser , configuration , etc . ) .Analytical cookies which allow anonymous analysis of the behavior of web users and allow to measure user activity and develop navigation profiles in order to improve the websites .","label":"Extends","metadata":{},"score":"71.80678"}{"text":"Problematic Dialogue Predictor The goal of the PDP is to predict , on the basis of information that it has early in the dialogue , whether or not the system will be able to complete the user 's task .The output classes are based on the four dialogue categories described above .","label":"Extends","metadata":{},"score":"72.44217"}{"text":"Download : openSMILE-2.2rc1 ( as tar.gz file ) and here as zip file .The current stable version of openSMILE is 2.1 ( released Dec. 23rd 2014 ) .You can download the full package , including source , binaries for Windows , Linux , and Android here as tar.gz for Unix / Linux / Mac and here as .","label":"Extends","metadata":{},"score":"72.827065"}{"text":": It is a wrong number .( impatient humming ) S4 : What was the number that you dialed ?USER HANGS UP Figure 2 : Sample hangup Dialogue The second problematic category ( wizard ) , results from a human customer care agent 's decision to take over the call from the system .","label":"Extends","metadata":{},"score":"72.85954"}{"text":"Definitely .Interspeech has organized three shared tasks on emotion , paralinguistic , and speaker state detection in the past three years respectively .All of them were very interesting tasks .This year , the organizers thought they would like to focus on a rarely studied speaker state : intoxication , and the goal was to identify interesting features that could characterize intoxication and approaches that can separate intoxicated speech efficiently .","label":"Extends","metadata":{},"score":"73.32483"}{"text":"Imagine a world where DUI 's ( driving under the influence violations ) never occurred .How can this happen ?Traditionally devices like breathalyzers can detect intoxication , but these tools are expensive and impractical for \" passive operation \" in vehicles .","label":"Extends","metadata":{},"score":"73.78319"}{"text":"Please enter or say your card number again .WIZARD STEPS IN Figure 3 : Sample wizard Dialogue The third problematic category , the taskfailure dialogues , are cases where the system completed the call , but carried out a task that was not the one that the customer 296 Predicting Problematic Dialogues was actually requesting .","label":"Extends","metadata":{},"score":"74.22034"}{"text":"In Proceedings of the Eleventh National Conference on Machine Learning .Gorin , A. , Riccardi , G. , & Wright , J. ( 1997 ) .How May I Help You ?Speech Communication , 23 , 113 - 127 .","label":"Extends","metadata":{},"score":"74.517624"}{"text":"It is possible to identify problematic dialogues with an accuracy up to 87 % .Section 2 describes hmihy and the dialogue corpus that the experiments are based on .Section 3 discusses the type of machine learning algorithm adopted , namely ripper and gives a description of the experimental design .","label":"Extends","metadata":{},"score":"74.89207"}{"text":"Page 4 .Test file PLPdeltas+3+pitch prp 0.24 0.28 0.41 0.34 PLPSDC+3+pitch prp 0.32 0.18 0.38 0.33 prn 0.97 0.96 0.97 0.97 prn 0.97 0.98 0.99 0.98 007 DieHard4 BN1 Total Table 5 .SVM results with extended features ( Sirens ) .","label":"Extends","metadata":{},"score":"75.03126"}{"text":"S5 : What number would you like to call ?U5 : 800 225 5288 ( touchtone input ) S6 : Thank you .Figure 4 : Sample taskfailure Dialogue 3 .Experimental Design Our experiments apply the machine learning program ripper ( Cohen , 1995 , 1996 ) to automatically classify the dialogues as problematic or successful .","label":"Extends","metadata":{},"score":"75.16901"}{"text":"How does it work ?The traditional approaches to speaker state detection include two steps : the extraction of low - level acoustic features ( e.g. MFCC ) , and n - way direct classification or regression using maximum margin classifiers .","label":"Extends","metadata":{},"score":"75.33618"}{"text":"318 Predicting Problematic Dialogues Riccardi , G. , & Gorin , A. ( 2000 ) .Spoken language adaptation over time and state in a natural spoken dialog system .IEEE Transactions on Speech and Audio Processing , 8 ( 1 ) , 3 - 10 .","label":"Extends","metadata":{},"score":"75.595146"}{"text":"The feature e2-subdial specifies that S2 initiates a subdialogue and e2-num - subdials encodes that this is the first subdialogue so far , while e2-percent - subdials encodes that out of all the system utterances so far , 50 % of them initiate subdialogues .","label":"Extends","metadata":{},"score":"75.624565"}{"text":"However , in any particular installation of the hmihy system , there may be differences between these costs that would need to be accounted for in the training of the PDP .It would be possible to use ripper to do this , if these costs were known , by using its ability to vary the loss ratio .","label":"Extends","metadata":{},"score":"75.78587"}{"text":"Three different kernels were considered for the SVM ( linear , polynomial and radial basis function ( RBF ) ) , but only the results for the RBF kernel are shown , as they 1974 .Page 3 .SVM results for the development set ( F - measure ) .","label":"Extends","metadata":{},"score":"75.94917"}{"text":": 8 1 4 7 7 7 6 6 6 6 ( misunderstood ) S4 : May I have that number again ?U4 : 8 1 4 7 7 7 6 6 6 6 S5 : Thank you .Figure 1 : Sample tasksuccess Dialogue Note that the system 's utterance in S4 consists of a repair initiation , motivated by the system 's ability to detect that the user 's utterance U3 was likely to have been misunderstood .","label":"Extends","metadata":{},"score":"76.51463"}{"text":"Fadi Biadsy , Julia Hirschberg , and Daniel Ellis .Dialect and accent recognition using phonetic - segmentation supervectors .In Proceedings of Interspeech 2011 , Florence , Italy , 2011 .( PDF ) .Fadi Biadsy , William Yang Wang , Andrew Rosenberg , and Julia Hirschberg .","label":"Extends","metadata":{},"score":"76.67944"}{"text":"This stage attempts to separate the events that are typi- cally produced by the human speech production system ( not only speech , but also laughing , crying , screaming , etc . ) , from the ones that are not related to human voice .","label":"Extends","metadata":{},"score":"77.68329"}{"text":"S2 : Okay .What is the reason for the credit ?U2 : Miss , uh , Miss , different area code than I needed .S3 : Sorry .I need to know whether you need credit for a wrong number , bad connection or a call that was cut off .","label":"Extends","metadata":{},"score":"78.11635"}{"text":"( Note that both packages have the same content , only the compressed format is different ) .Full Installation and usage instructions are provided in the book .Here are q u ick - Install instructions for the impatient : . exe ( Windows ) in the bin/ subdirectory of the release package and run it from the command line with the -h option to see an on - line help .","label":"Extends","metadata":{},"score":"79.079285"}{"text":"The HMIHY Data hmihy is a spoken dialogue system based on the notion of call routing ( Gorin et al . , 1997 ; Chu - Carroll & Carpenter , 1999 ) .In the hmihy call routing system , services that the user can access are classified into 14 categories , plus a category called other for tasks that are not covered by the automated system and must be transferred to a human operator ( Gorin et al . , 1997 ) .","label":"Extends","metadata":{},"score":"79.36917"}{"text":"The dialogues that have the desired outcome , in which hmihy successfully automates the customer 's call , are referred to as the tasksuccess dia294 Predicting Problematic Dialogues logues .Dialogues in which the hmihy system did not successfully complete the caller 's task are referred to as problematic .","label":"Extends","metadata":{},"score":"80.470184"}{"text":"HMM classifiers : Modeling time structure After the initial experiments with SVMs , we tried to take ad- vantageoftheperiodicnatureofsomeaudioevents .Although SVMs are a powerful machine learning tool , some other tools , likeHMMs , aremoresuitableformodelingthetimestructure .Some of the 15 chosen audio events present a strong periodic nature , such as Airplanes , Helicopters and Sirens .","label":"Extends","metadata":{},"score":"80.6236"}{"text":"The rcorrect class accounts for 7481 ( 36.1 % ) of the exchanges in the corpus .The rpartial - match accounts for 109 ( 0.5 % ) of the exchanges .The rmismatch class accounts for 4197 ( 20.2 % ) of the exchanges and the no - recog class accounts for 8943 ( 43.1 % ) of the exchanges .","label":"Extends","metadata":{},"score":"81.32675"}{"text":"Be sure to check the FAQ and Known - issues section if you have problems with running or installing openSMILE .Be sure to read and understand the documentation in the openSMILE book before you contact us for support .If you can not find an answer to your problem in any of these resources or you have found a bug , please contact Florian Eyben via e - mail ( fe at audeering . com ) .","label":"Extends","metadata":{},"score":"81.4906"}{"text":"The first row gives the baseline result which represents the prediction accuracy from always guessing the majority class .Since 67.1 % of the dialogues are tasksuccess dialogues , we can achieve 67.1 % accuracy from simply guessing tasksuccess for each dialogue .","label":"Extends","metadata":{},"score":"81.57654"}{"text":"On the other hand , every call that hmihy attempts to handle and fails , would potentially accrue a different cost , namely the lost revenue from customers who become irritated with faulty customer service and take their business elsewhere .We call this cost the system failure cost .","label":"Extends","metadata":{},"score":"83.84506"}{"text":"The system determines which task the caller is requesting on the basis of its understanding of the caller 's response to the open - ended system greeting AT&T , How May I Help You ?Once the task has been determined , the information needed for completing the caller 's request is obtained using dialogue submodules that are specific for each task ( Abella & Gorin , 1999 ) .","label":"Extends","metadata":{},"score":"83.94905"}{"text":"One reason that this might occur is that this sub - category of dialogues are much more difficult to predict since in this case the hmihy system has no indication that it is not succeeding in the task .However , another possibility is that the PDP performs poorly on this category because there are fewer examples in the training set , although it does better on the hangup subset , which is about the same proportion .","label":"Extends","metadata":{},"score":"86.671776"}{"text":"U2 : I wanta find out how much my bill 's worth .S3 : What phone number would you like the call billed to ?U3: Um the access number .S4 : Sorry .Could I have that phone number again ?","label":"Extends","metadata":{},"score":"86.77756"}{"text":"A dialogue where the wizard decided that the dialogue was problematic and took over the call is shown in Figure 3 .S1 : AT&T How may I help you ?U1 : ( silence )S2 : Sorry .Please briefly tell me how I may help you ?","label":"Extends","metadata":{},"score":"87.6967"}{"text":"A caller may hang up because s / he is frustrated with the system ; our goal is to learn from the corpus which system behaviors led to the caller 's frustration .S1 : AT&T How may I help you ?","label":"Extends","metadata":{},"score":"89.81392"}{"text":"Note that this categorization is inherently noisy because it is impossible to know the real reasons why a caller hangs up or a wizard takes over the call .The caller may hang up because she is frustrated with the system , or she may simply dislike automation , or her child may have started crying .","label":"Extends","metadata":{},"score":"90.22135"}{"text":"Nevertheless , we take these human actions as a human labelling of these calls as problematic .Given this binary classification , approximately 33 % of the calls in the corpus of 4692 dialogues are problematic and 67 % are tasksuccess .","label":"Extends","metadata":{},"score":"90.59082"}{"text":"hmihy then asked the caller for the information it needed to carry out this task , the caller complied , and the system completed the call .S1 : AT&T How may I help you ?U1 : ( silence )S2 : Sorry .","label":"Extends","metadata":{},"score":"90.62246"}{"text":"I get an error message that openSMILE can not read a WAVE file ( Bogus RIFF header ) , what is wrong with my files ?There is a possibility that your wave files are corrupted .In most cases , however , the wave files just contain some extended header information ( WAVExt ) , which openSMILE can not ( yet ) read .","label":"Extends","metadata":{},"score":"90.74716"}{"text":"U3: Through my calling card .S4 : May I have your card number , please ?U4 : It 's 8 7 6 5 4 3 2 1 0 and then my pin number is 8 7 6 5 .","label":"Extends","metadata":{},"score":"90.824554"}{"text":"sThese studies have revealed that the basic emotions identifiedsby Ekman and Friesen ( 1978 ) , namely anger , fear , sadness , sjoy , disgust , and surprise , typ ... .by Art Graesser , Patrick Chipman - Proceedings of the 28 th Annual Meetings of the Cognitive Science Society , 2006 . \" ...","label":"Extends","metadata":{},"score":"90.954124"}{"text":"In the United States , there were 164,755 alcohol related fatalities in a past window of ten years ( 1999 - 2008 ) .A system to detect a person 's level of intoxication via minimally invasive means would not only be able to significantly aid in the enforcement of drunk driving laws , but also ultimately save lives .","label":"Extends","metadata":{},"score":"93.74579"}{"text":"S1 : AT&T How may I help you ?U1 : I need to [ uh ] put a call on my calling card please S2 : May I have your card number , please ?U2 : 7 6 5 4 3 2 1 0 9 8 7 6 5 4 S3 : What number would you like to call ?","label":"Extends","metadata":{},"score":"95.06928"}{"text":"SVM results for the test set ( prpand prn ) .Test file20ms60ms100ms prp 0.18 0.06 0.42 0.29 prp 0.47 0.18 0.48 0.43 prn 0.94 0.98 0.97 0.97 prp 0.30 0.17 0.36 0.32 prn 0.99 0.99 0.99 0.99 prn 0.99 0.99 0.99 0.99 007 DieHard4 BN1 Total Table 4 .","label":"Extends","metadata":{},"score":"97.43796"}