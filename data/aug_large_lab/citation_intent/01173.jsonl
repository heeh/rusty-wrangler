{"text":"They will use the data for developing a named - entity recognition system that includes a machine learning component .For each language , additional information ( lists of names and non - annotated data ) will be supplied as well .","label":"Background","metadata":{},"score":"25.865215"}
{"text":"They will use the data for developing a named - entity recognition system that includes a machine learning component .For each language , additional information ( lists of names and non - annotated data ) will be supplied as well .","label":"Background","metadata":{},"score":"25.865215"}
{"text":"It presents a statistical model for estimating accuracy for bootstrap learning of named entity and relation extractors , under the assumption that correct entities and relations will be repeatedly extracted from a large corpus , and that correct extractions will be repeatedly more frequently than incorrect extractions .","label":"Background","metadata":{},"score":"31.167877"}
{"text":"In 1975 Kelly and Stone published a book explicitly listing their rules for disambiguation of word senses .These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system A. Luk .","label":"Background","metadata":{},"score":"32.149513"}
{"text":"In 1975 Kelly and Stone published a book explicitly listing their rules for disambiguation of word senses .These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system A. Luk .","label":"Background","metadata":{},"score":"32.149513"}
{"text":"This paper presents a statistical decision procedure for lexical ambiguity resolution .The algorithm exploits both local syntactic patterns and more distant collocational evidence , generating an efficient , effective , and highly perspicuous recipe for resolving a given ambiguity .By identifying and utilizing only the single best disambiguating evidence in a target context , the algorithm avoids the problematic complex modeling of statistical dependencies .","label":"Background","metadata":{},"score":"32.53175"}
{"text":"Yarowsky reports that the system correctly classifies senses 96 % of the time .Revision as of 04:20 , 25 June 2012 .Word Sense Disambiguation ( WSD ) is the process of identifying the sense of a polysemic word .In modern WSD systems , the senses of a word are typically taken from some specified dictionary .","label":"Background","metadata":{},"score":"33.686954"}
{"text":"These operations capture linguistic differences such as word order and case marking .Model parameters are es ... \" .We present a syntax - based statistical translation model .Our model transforms a source - language parse tree into a target - language string by applying stochastic operations at each node .","label":"Background","metadata":{},"score":"34.4693"}
{"text":"A paper that is related to the topic of this shared task is the EMNLP-99 paper by Cucerzan and Yarowsky [ CY99 ] .Interesting papers about using unsupervised data , though not for named entity recognition , are those of Mitchell [ Mit99 ] and Banko and Brill [ BB01 ] .","label":"Background","metadata":{},"score":"34.70246"}
{"text":"A paper that is related to the topic of this shared task is the EMNLP-99 paper by Cucerzan and Yarowsky [ CY99 ] .Interesting papers about using unsupervised data , though not for named entity recognition , are those of Mitchell [ Mit99 ] and Banko and Brill [ BB01 ] .","label":"Background","metadata":{},"score":"34.70246"}
{"text":"We test this empirical hypothesis for several definitions of sense and collocation , and discover that it holds with 90 - 99 % accuracy for binary ambiguities .We utilize this property in a disambiguation algorithm that achieves precision of 92 % using combined models of very local context .","label":"Background","metadata":{},"score":"34.727688"}
{"text":"Yarowsky reports that the system correctly classifies senses 96 % of the time .Revision as of 07:00 , 4 January 2011 .Word Sense Disambiguation ( WSD ) is the process of identifying the sense of a polysemic word .In modern WSD systems , the senses of a word are typically taken from some specified dictionary .","label":"Background","metadata":{},"score":"34.737793"}
{"text":"This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .","label":"Background","metadata":{},"score":"34.93126"}
{"text":"This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .","label":"Background","metadata":{},"score":"34.93126"}
{"text":"This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .","label":"Background","metadata":{},"score":"34.93126"}
{"text":"This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .","label":"Background","metadata":{},"score":"34.93126"}
{"text":"This set of techniques requires a training corpus which has already been disambiguated .In general a machine learning algorithm of some kind is applied to certain features extracted from the corpus and used to form a representation of each of the senses .","label":"Background","metadata":{},"score":"34.93126"}
{"text":"The selection of categories is accomplished by identifying and weighting words that are indicative of each category when seen in context , using a Bayesian theoretical framework .Other . \" ...We present a syntax - based statistical translation model .","label":"Background","metadata":{},"score":"35.86188"}
{"text":"What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .An example of this is the dynamic matching technique [ 9 ] which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .","label":"Background","metadata":{},"score":"36.035164"}
{"text":"What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .An example of this is the dynamic matching technique [ 9 ] which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .","label":"Background","metadata":{},"score":"36.035164"}
{"text":"What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .An example of this is the dynamic matching technique [ 9 ] which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .","label":"Background","metadata":{},"score":"36.035164"}
{"text":"What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .An example of this is the dynamic matching technique [ 10 ] which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .","label":"Background","metadata":{},"score":"36.049656"}
{"text":"What unsupervised disambiguation can achieve is word sense discrimination , it clusters the instances of a word into distinct categories without giving those categories labels from a lexicon ( such as WordNet synsets ) .An example of this is the dynamic matching technique [ 10 ] which examines all instances of a given term in a corpus and compares the contexts in which they occur for common words and syntactic patterns .","label":"Background","metadata":{},"score":"36.049656"}
{"text":"Yarowsky , David .Unsupervised word sense disambiguation rivaling supervised methods .In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics , pages 189 - 196 .This has been used to train web page classifiers , named entity recognizers , image classifiers , and more .","label":"Background","metadata":{},"score":"36.517277"}
{"text":"Thus , we draw on work done at AT&T Bell Laboratories by Gale and Church ( 1991a ; 1991b ... . \" ...This paper presents a statistical decision procedure for lexical ambiguity resolution .The algorithm exploits both local syntactic patterns and more distant collocational evidence , generating an efficient , effective , and highly perspicuous recipe for resolving a given ambiguity .","label":"Background","metadata":{},"score":"37.37735"}
{"text":"In Proceedings of 1999 Joint SIGDAT Conference on EMNLP and VLC , University of Maryland , MD , 1999 .Language - Independent Named Entity Recognition ( II ) .Named entities are phrases that contain the names of persons , organizations , locations , times and quantities .","label":"Background","metadata":{},"score":"37.61551"}
{"text":"In Proceedings of 1999 Joint SIGDAT Conference on EMNLP and VLC , University of Maryland , MD , 1999 .Language - Independent Named Entity Recognition ( II ) .Named entities are phrases that contain the names of persons , organizations , locations , times and quantities .","label":"Background","metadata":{},"score":"37.61551"}
{"text":"Yarowsky reports that the system correctly classifies senses 96 % of the time .Another example of this approach is the unsupervised algorithm of Yarowsky D. Yarowsky .Unsupervised word - sense disambiguation rivaling supervised methods .In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .","label":"Background","metadata":{},"score":"38.60428"}
{"text":"Yarowsky reports that the system correctly classifies senses 96 % of the time .Another example of this approach is the unsupervised algorithm of Yarowsky D. Yarowsky .Unsupervised word - sense disambiguation rivaling supervised methods .In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .","label":"Background","metadata":{},"score":"38.60428"}
{"text":"Yarowsky reports that the system correctly classifies senses 96 % of the time .Another example of this approach is the unsupervised algorithm of Yarowsky D. Yarowsky .Unsupervised word - sense disambiguation rivaling supervised methods .In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .","label":"Background","metadata":{},"score":"38.60428"}
{"text":"Yarowsky reports that the system correctly classifies senses 96 % of the time .Another example of this approach is the unsupervised algorithm of Yarowsky D. Yarowsky .Unsupervised word - sense disambiguation rivaling supervised methods .In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .","label":"Background","metadata":{},"score":"38.60428"}
{"text":"Yarowsky reports that the system correctly classifies senses 96 % of the time .Another example of this approach is the unsupervised algorithm of Yarowsky D. Yarowsky .Unsupervised word - sense disambiguation rivaling supervised methods .In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .","label":"Background","metadata":{},"score":"38.60428"}
{"text":"We present a detailed case study of this learning method applied to part of speech tagging . by David Yarowsky - IN PROCEEDINGS OF THE 33RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS , 1995 . \" ...This paper presents an unsupervised learning algorithm for sense disambiguation that , when trained on unannotated English text , rivals the performance of supervised techniques that require time - consuming hand annotations .","label":"Background","metadata":{},"score":"39.076126"}
{"text":"Distinguishing word senses in untagged text .In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 .","label":"Background","metadata":{},"score":"39.154938"}
{"text":"Distinguishing word senses in untagged text .In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 .","label":"Background","metadata":{},"score":"39.154938"}
{"text":"Distinguishing word senses in untagged text .In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 .","label":"Background","metadata":{},"score":"39.154938"}
{"text":"We will concentrate on four types of named entities : persons , locations , organizations and names of miscellaneous entities that do not belong to the previous three groups .The participants of the shared task will be offered training and test data for at least two languages .","label":"Background","metadata":{},"score":"39.287476"}
{"text":"The above papers contain a number of theoretiical models , especially the Blum & Mitchell 1998 paper , and the Abney paper .Following are more recent theoretical models for how and when unlabeled data can improve learning .These papers provide PAC - style bounds on co - training and related learning settings that go beyond those provided in the original co - training paper .","label":"Background","metadata":{},"score":"39.443214"}
{"text":"Discussions .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .","label":"Background","metadata":{},"score":"39.90763"}
{"text":"Discussions .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .","label":"Background","metadata":{},"score":"39.90763"}
{"text":"Discussions .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .","label":"Background","metadata":{},"score":"39.90763"}
{"text":"There have been at least two studies that have applied one NER system to different languages .Palmer and Day [ PD97 ] have used statistical methods for finding named entities in newswire articles in Chinese , English , French , Japanese , Portuguese and Spanish .","label":"Background","metadata":{},"score":"40.0579"}
{"text":"Yarowsky reports that the system correctly classifies senses 96 % of the time .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .","label":"Background","metadata":{},"score":"40.519753"}
{"text":"Yarowsky reports that the system correctly classifies senses 96 % of the time .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .","label":"Background","metadata":{},"score":"40.519753"}
{"text":"Yarowsky reports that the system correctly classifies senses 96 % of the time .Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .","label":"Background","metadata":{},"score":"40.519753"}
{"text":"Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .","label":"Background","metadata":{},"score":"40.657642"}
{"text":"Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .","label":"Background","metadata":{},"score":"40.657642"}
{"text":"Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .","label":"Background","metadata":{},"score":"40.657642"}
{"text":"Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .","label":"Background","metadata":{},"score":"40.657642"}
{"text":"Different researchers have made use of different sets of features , for example local collocates such as first noun to the left and right , second word to the left / right and so on .However , a more common feature set is to take all the words in a window of words around the ambiguous words , treating the context as an unordered bag of words .","label":"Background","metadata":{},"score":"40.657642"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky [ 13 ] .","label":"Background","metadata":{},"score":"40.737793"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky [ 13 ] .","label":"Background","metadata":{},"score":"40.737793"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky [ 12 ] .","label":"Background","metadata":{},"score":"40.878555"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky [ 12 ] .","label":"Background","metadata":{},"score":"40.878555"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky [ 12 ] .","label":"Background","metadata":{},"score":"40.878555"}
{"text":"These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system [ 11 ] which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"40.96814"}
{"text":"These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system [ 11 ] which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"40.96814"}
{"text":"These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system [ 11 ] which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"40.96814"}
{"text":"This paper presents an unsupervised learning algorithm for sense disambiguation that , when trained on unannotated English text , rivals the performance of supervised techniques that require time - consuming hand annotations .The algorithm is based on two powerful constraints -- that words tend to have one sense per discourse and one sense per collocation -- exploited in an iterative bootstrapping procedure .","label":"Background","metadata":{},"score":"41.057808"}
{"text":"The meaning of a word in a particular usage can only be determined by examining its context .This is , in general , a trivial task for the human language processing system , for example consider the following two sentences , each with a different sense of the word bank : .","label":"Background","metadata":{},"score":"41.119087"}
{"text":"The meaning of a word in a particular usage can only be determined by examining its context .This is , in general , a trivial task for the human language processing system , for example consider the following two sentences , each with a different sense of the word bank : .","label":"Background","metadata":{},"score":"41.119087"}
{"text":"The meaning of a word in a particular usage can only be determined by examining its context .This is , in general , a trivial task for the human language processing system , for example consider the following two sentences , each with a different sense of the word bank : .","label":"Background","metadata":{},"score":"41.119087"}
{"text":"Word Sense Disambiguation ( WSD ) is the process of identifying the sense of a polysemic word .In modern WSD systems , the senses of a word are typically taken from some specified dictionary .These days WordNet is the usual dictionary in question .","label":"Background","metadata":{},"score":"41.234623"}
{"text":"Word Sense Disambiguation ( WSD ) is the process of identifying the sense of a polysemic word .In modern WSD systems , the senses of a word are typically taken from some specified dictionary .These days WordNet is the usual dictionary in question .","label":"Background","metadata":{},"score":"41.234623"}
{"text":"Word Sense Disambiguation ( WSD ) is the process of identifying the sense of a polysemic word .In modern WSD systems , the senses of a word are typically taken from some specified dictionary .These days WordNet is the usual dictionary in question .","label":"Background","metadata":{},"score":"41.234623"}
{"text":"The problem of WSD was first introduced by Warren Weaver in 1949 [ 3 ] .In 1975 Kelly and Stone [ 4 ] published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .","label":"Background","metadata":{},"score":"41.25626"}
{"text":"The problem of WSD was first introduced by Warren Weaver in 1949 [ 3 ] .In 1975 Kelly and Stone [ 4 ] published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .","label":"Background","metadata":{},"score":"41.25626"}
{"text":"This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .","label":"Background","metadata":{},"score":"41.44785"}
{"text":"This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .","label":"Background","metadata":{},"score":"41.44785"}
{"text":"This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .","label":"Background","metadata":{},"score":"41.44785"}
{"text":"This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .","label":"Background","metadata":{},"score":"41.44785"}
{"text":"This approach attempts to disambiguate words using information which is gained by training on some corpus , rather that taking it directly from an explicit knowledge source .This training can be carried out on either a disambiguated or raw corpus , where a disambiguated corpus is one where the semantics of each polysemous lexical item is marked and a raw corpus one without such marking .","label":"Background","metadata":{},"score":"41.44785"}
{"text":"These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system [ 12 ] which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"41.452583"}
{"text":"These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .A good example of this is Luk 's system [ 12 ] which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"41.452583"}
{"text":"CMP03a ] Xavier Carreras , Lluís Màrquez , and Lluís Padró , Learning a Perceptron - Based Named Entity Chunker via Online Recognition Feedback .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .156 - 159 .","label":"Background","metadata":{},"score":"41.45459"}
{"text":"CMP03a ] Xavier Carreras , Lluís Màrquez , and Lluís Padró , Learning a Perceptron - Based Named Entity Chunker via Online Recognition Feedback .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .156 - 159 .","label":"Background","metadata":{},"score":"41.45459"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky D. Yarowsky .","label":"Background","metadata":{},"score":"41.61293"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky D. Yarowsky .","label":"Background","metadata":{},"score":"41.61293"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .Another example of this approach is the unsupervised algorithm of Yarowsky D. Yarowsky .","label":"Background","metadata":{},"score":"41.61293"}
{"text":"155 - 158 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] sheets : [ ps ] [ ps.gz ] [ pdf ] .[ BV02 ] William J. Black and Argyrios Vasilakopoulos , Language - Independent Named Entity Classification by Modified Transformation - Based Learning and by Decision Tree Induction .","label":"Background","metadata":{},"score":"41.6934"}
{"text":"The example deals with text chunking , a task which uses the same output format as this named entity task .The output of the NER system for each word should be appended behind each line , with a single space between the line and the output tag .","label":"Background","metadata":{},"score":"41.699654"}
{"text":"Approaches .Knowledge based .Under this approach disambiguation is carried out using information from an explicit lexicon or knowledge base .The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet [ 5 ] and LDOCE [ 6 ] .","label":"Background","metadata":{},"score":"41.825455"}
{"text":"Approaches .Knowledge based .Under this approach disambiguation is carried out using information from an explicit lexicon or knowledge base .The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet [ 5 ] and LDOCE [ 6 ] .","label":"Background","metadata":{},"score":"41.825455"}
{"text":"Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .In Proceedings of the 14th International Conference on Computational Linguistics ( COLING-92 ) , pages 454 - 460 , Nantes , France , 1992 .An experiment in semantic tagging using hidden markov model tagging .","label":"Background","metadata":{},"score":"41.88162"}
{"text":"Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .In Proceedings of the 14th International Conference on Computational Linguistics ( COLING-92 ) , pages 454 - 460 , Nantes , France , 1992 .An experiment in semantic tagging using hidden markov model tagging .","label":"Background","metadata":{},"score":"41.88162"}
{"text":"Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .In Proceedings of the 14th International Conference on Computational Linguistics ( COLING-92 ) , pages 454 - 460 , Nantes , France , 1992 .An experiment in semantic tagging using hidden markov model tagging .","label":"Background","metadata":{},"score":"41.88162"}
{"text":"Approaches .Knowledge based .Under this approach disambiguation is carried out using information from an explicit lexicon or knowledge base .The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet [ 4 ] and LDOCE [ 5 ] .","label":"Background","metadata":{},"score":"42.032166"}
{"text":"Approaches .Knowledge based .Under this approach disambiguation is carried out using information from an explicit lexicon or knowledge base .The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet [ 4 ] and LDOCE [ 5 ] .","label":"Background","metadata":{},"score":"42.032166"}
{"text":"Approaches .Knowledge based .Under this approach disambiguation is carried out using information from an explicit lexicon or knowledge base .The lexicon may be a machine readable dictionary , thesaurus or it may be hand - crafted .This is one of most popular approaches to word sense disambiguation and amongst others , work has been done using existing lexical knowledge sources such as WordNet [ 4 ] and LDOCE [ 5 ] .","label":"Background","metadata":{},"score":"42.032166"}
{"text":"The problem of WSD was first introduced by Warren weaver in 1949 [ 3 ] In 1975 Kelly and Stone published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .","label":"Background","metadata":{},"score":"42.476837"}
{"text":"The problem of WSD was first introduced by Warren weaver in 1949 [ 3 ] In 1975 Kelly and Stone published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .","label":"Background","metadata":{},"score":"42.476837"}
{"text":"The problem of WSD was first introduced by Warren weaver in 1949 [ 3 ] In 1975 Kelly and Stone published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .","label":"Background","metadata":{},"score":"42.476837"}
{"text":"WSD has been investigated in computational linguistics as a specific task for well over 40 years , though the acronym is newer .One of the first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .","label":"Background","metadata":{},"score":"43.353127"}
{"text":"The example deals with text chunking , a task which uses the same output format as this named entity task .The program requires the output of the NER system for each word to be appended to the corresponding line in the test file , with a single space between the line and the output tag .","label":"Background","metadata":{},"score":"43.5651"}
{"text":"The example deals with text chunking , a task which uses the same output format as this named entity task .The program requires the output of the NER system for each word to be appended to the corresponding line in the test file , with a single space between the line and the output tag .","label":"Background","metadata":{},"score":"43.5651"}
{"text":"[ 2 ] However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .","label":"Background","metadata":{},"score":"43.60406"}
{"text":"[ 2 ] However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .","label":"Background","metadata":{},"score":"43.60406"}
{"text":"[ 2 ] However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .","label":"Background","metadata":{},"score":"43.60406"}
{"text":"[ 2 ] However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .","label":"Background","metadata":{},"score":"43.60406"}
{"text":"[ 2 ] However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .","label":"Background","metadata":{},"score":"43.60406"}
{"text":"[CMP03b ] Xavier Carreras , Lluís Màrquez , and Lluís Padró , A Simple Named Entity Extractor using AdaBoost .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .152 - 155 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"44.5084"}
{"text":"[CMP03b ] Xavier Carreras , Lluís Màrquez , and Lluís Padró , A Simple Named Entity Extractor using AdaBoost .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .152 - 155 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"44.5084"}
{"text":"An experiment in semantic tagging using hidden markov model tagging .In Vossen , P. , Adriaens , G. , Calzolari , N. , Sanfilippo , A. , and Wilks , Y. , editors , Proceedings of the ACL / EACL'97 Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources .","label":"Background","metadata":{},"score":"44.804993"}
{"text":"An experiment in semantic tagging using hidden markov model tagging .In Vossen , P. , Adriaens , G. , Calzolari , N. , Sanfilippo , A. , and Wilks , Y. , editors , Proceedings of the ACL / EACL'97 Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources .","label":"Background","metadata":{},"score":"44.804993"}
{"text":"WSD has been investigated in computational linguistics as a specific task for well over 40 years , though the acronym is newer .Contents .One of the first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .","label":"Background","metadata":{},"score":"45.25061"}
{"text":"The general problem with these methods is their reliance on disambiguated corpora which are expensive and difficult to obtain .This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .","label":"Background","metadata":{},"score":"45.339462"}
{"text":"The general problem with these methods is their reliance on disambiguated corpora which are expensive and difficult to obtain .This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .","label":"Background","metadata":{},"score":"45.339462"}
{"text":"The general problem with these methods is their reliance on disambiguated corpora which are expensive and difficult to obtain .This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .","label":"Background","metadata":{},"score":"45.339462"}
{"text":"The general problem with these methods is their reliance on disambiguated corpora which are expensive and difficult to obtain .This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .","label":"Background","metadata":{},"score":"45.339462"}
{"text":"The general problem with these methods is their reliance on disambiguated corpora which are expensive and difficult to obtain .This has meant that many of these algorithms have been tested on very small numbers of different words , often as few as 10 .","label":"Background","metadata":{},"score":"45.339462"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .This takes a small number of seed definitions of the senses of some word ( the seeds could be WordNet synsets or definitions from some lexicon ) and uses these to classify the ' ' obvious ' ' cases in a corpus .","label":"Background","metadata":{},"score":"45.341866"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .This takes a small number of seed definitions of the senses of some word ( the seeds could be WordNet synsets or definitions from some lexicon ) and uses these to classify the ' ' obvious ' ' cases in a corpus .","label":"Background","metadata":{},"score":"45.341866"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .This takes a small number of seed definitions of the senses of some word ( the seeds could be WordNet synsets or definitions from some lexicon ) and uses these to classify the ' ' obvious ' ' cases in a corpus .","label":"Background","metadata":{},"score":"45.341866"}
{"text":"Model parameters are estimated in polynomial time using an EM algorithm .The model produces word alignments that are better than those produced by IBM Model 5 .Developing a better TM is a fundamental issue for those applications .Researchers at IBM first described such a statistical TM in ( Brown et al . , 1988 ) .","label":"Background","metadata":{},"score":"45.39228"}
{"text":"Each word has been put on a separate line and there is an empty line after each sentence .The first item on each line is a word , the second a part - of - speech ( POS ) tag , the third a syntactic chunk tag and the fourth the named entity tag .","label":"Background","metadata":{},"score":"45.64118"}
{"text":"Each word has been put on a separate line and there is an empty line after each sentence .The first item on each line is a word , the second a part - of - speech ( POS ) tag , the third a syntactic chunk tag and the fourth the named entity tag .","label":"Background","metadata":{},"score":"45.64118"}
{"text":"This approach has been shown for a number of tasks to capture information in a clearer and more direct fashion without a compromise in performance .We present a detailed case study of this learni ... \" .this paper , we will describe a simple rule - based approach to automated learning of linguistic knowledge .","label":"Background","metadata":{},"score":"45.87205"}
{"text":"Palmer and Day [ PD97 ] have used statistical methods for finding named entities in newswire articles in Chinese , English , French , Japanese , Portuguese and Spanish .They found that the difficulty of the NER task was different for the six languages but that a large part of the task could be performed with simple methods .","label":"Background","metadata":{},"score":"45.965622"}
{"text":"Palmer and Day [ PD97 ] have used statistical methods for finding named entities in newswire articles in Chinese , English , French , Japanese , Portuguese and Spanish .They found that the difficulty of the NER task was different for the six languages but that a large part of the task could be performed with simple methods .","label":"Background","metadata":{},"score":"45.965622"}
{"text":"[ 1 ] The problem is that words often have more than one meaning , sometimes fairly similar and sometimes completely different .The meaning of a word in a particular usage can only be determined by examining its context .This is , in general , a trivial task for the human language processing system , for example consider the following two sentences , each with a different sense of the word bank : .","label":"Background","metadata":{},"score":"46.137608"}
{"text":"[ 1 ] The problem is that words often have more than one meaning , sometimes fairly similar and sometimes completely different .The meaning of a word in a particular usage can only be determined by examining its context .This is , in general , a trivial task for the human language processing system , for example consider the following two sentences , each with a different sense of the word bank : .","label":"Background","metadata":{},"score":"46.137608"}
{"text":"The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .To appear in Journal of Natural Language Engineering , 4(3 ) .Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .","label":"Background","metadata":{},"score":"46.181377"}
{"text":"The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .To appear in Journal of Natural Language Engineering , 4(3 ) .Word - sense disambiguation using statistical models of Roget 's categories trained on large corpora .","label":"Background","metadata":{},"score":"46.181377"}
{"text":"159 - 162 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .[BHM02 ] John D. Burger , John C. Henderson and William T. Morgan , Statistical Named Entity Recognizer Adaptation .","label":"Background","metadata":{},"score":"46.23726"}
{"text":"Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .For example , does it make sense to describe an overall percentage accuracy for a WSD system or does evaluation require specific comparison of system performance on a word by word basis .","label":"Background","metadata":{},"score":"46.326073"}
{"text":"Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .For example , does it make sense to describe an overall percentage accuracy for a WSD system or does evaluation require specific comparison of system performance on a word by word basis .","label":"Background","metadata":{},"score":"46.326073"}
{"text":"Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .For example , does it make sense to describe an overall percentage accuracy for a WSD system or does evaluation require specific comparison of system performance on a word by word basis .","label":"Background","metadata":{},"score":"46.326073"}
{"text":"Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .For example , does it make sense to describe an overall percentage accuracy for a WSD system or does evaluation require specific comparison of system performance on a word by word basis .","label":"Background","metadata":{},"score":"46.326073"}
{"text":"Word Sense Disambiguation has several debates within the field as to whether the senses offered in existing dictionaries are adequate to distinguish the subtle meanings used in text contexts and how to evaluate the overall performance of a WSD system .For example , does it make sense to describe an overall percentage accuracy for a WSD system or does evaluation require specific comparison of system performance on a word by word basis .","label":"Background","metadata":{},"score":"46.326073"}
{"text":"One of the first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .The resolution of a word 's syntactic ambiguity has largely been solved in language processing by part - of - speech taggers which predict the syntactic category of words in text with high levels of accuracy .","label":"Background","metadata":{},"score":"46.405293"}
{"text":"In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 .","label":"Background","metadata":{},"score":"46.496605"}
{"text":"In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing , Providence , RI , August 1997 .Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 .","label":"Background","metadata":{},"score":"46.496605"}
{"text":"[ WP03 ] Casey Whitelaw and Jon Patrick , Named Entity Recognition Using a Character - based Probabilistic Approach .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .196 - 199 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"46.583344"}
{"text":"[ WP03 ] Casey Whitelaw and Jon Patrick , Named Entity Recognition Using a Character - based Probabilistic Approach .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .196 - 199 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"46.583344"}
{"text":"Chapter 4 Transformation - Based Error - Driven Learning Applied to Natural Language 4.1 Introduction In this section , we describe a framew ... . by David Yarowsky - In Proceedings of the ARPA Human Language Technology Workshop , 1993 . \" ...","label":"Background","metadata":{},"score":"46.988262"}
{"text":"These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .","label":"Background","metadata":{},"score":"47.114613"}
{"text":"These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .","label":"Background","metadata":{},"score":"47.114613"}
{"text":"These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .","label":"Background","metadata":{},"score":"47.114613"}
{"text":"These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .","label":"Background","metadata":{},"score":"47.114613"}
{"text":"These clusters were then mapped onto the closest sense from the appropriate lexicon .Unfortunately the results are not very encouraging , Pedersen reports 65 - 66 % correct disambiguation depending on the learning algorithm used .This result should be compared against that fact that , in the corpus he used , 73 % of the instances could be correctly classified by simply choosing the most frequent sense .","label":"Background","metadata":{},"score":"47.114613"}
{"text":"In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .Word sense disambiguation using conceptual density .In Proceedings of COLING'96 .The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .","label":"Background","metadata":{},"score":"47.493862"}
{"text":"In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .Word sense disambiguation using conceptual density .In Proceedings of COLING'96 .The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .","label":"Background","metadata":{},"score":"47.493862"}
{"text":"Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , [ 8 ] decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .","label":"Background","metadata":{},"score":"47.688534"}
{"text":"Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , [ 8 ] decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .","label":"Background","metadata":{},"score":"47.688534"}
{"text":"Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , [ 8 ] decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .","label":"Background","metadata":{},"score":"47.688534"}
{"text":"199 - 202 . paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .[ Tjo02 ] Erik F. Tjong Kim Sang , Memory - Based Named Entity Recognition .","label":"Background","metadata":{},"score":"47.71666"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .This takes a small number of seed definitions of the senses of some word ( the seeds could be WordNet synsets or definitions from some lexicon ) and uses these to classify the . ''","label":"Background","metadata":{},"score":"47.88809"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .This takes a small number of seed definitions of the senses of some word ( the seeds could be WordNet synsets or definitions from some lexicon ) and uses these to classify the . ''","label":"Background","metadata":{},"score":"47.88809"}
{"text":"The categories listed for a word in Roget 's index tend to ... \" .This paper describes a program that disambiguates English word senses in unrestricted text using statistical models of the major Roget 's Thesaurus categories .Roget 's categories serve as approximations of conceptual classes .","label":"Background","metadata":{},"score":"47.963543"}
{"text":"Translation .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .Word sense disambiguation using conceptual density .In Proceedings of COLING'96 .The Grammar of Sense : using part - of - speech tags as a first step in semantic disambiguation .","label":"Background","metadata":{},"score":"47.993584"}
{"text":"Language and Information .Addison - Wesley , 1964 .However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .","label":"Background","metadata":{},"score":"48.00154"}
{"text":"163 - 166 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .[ CMP02 ] Xavier Carreras , Lluís Márques and Lluís Padró , Named Entity Extraction using AdaBoost In : Proceedings of CoNLL-2002 , Taipei , Taiwan , 2002 , pp .","label":"Background","metadata":{},"score":"48.00273"}
{"text":"Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , [ 9 ] decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .","label":"Background","metadata":{},"score":"48.04895"}
{"text":"Realizing of course that semantic tagging is a much more difficult problem than part - of - speech tagging , [ 9 ] decided nonetheless to perform an experiment to see how well words can be semantically disambiguated using techniques that have proven to be effective in part - of - speech tagging .","label":"Background","metadata":{},"score":"48.04895"}
{"text":"MLP03 ] Robert Munro , Daren Ler , and Jon Patrick , Meta - Learning Orthographic and Contextual Models for Language Independent Named Entity Recognition .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .192 - 195 .","label":"Background","metadata":{},"score":"48.12319"}
{"text":"MLP03 ] Robert Munro , Daren Ler , and Jon Patrick , Meta - Learning Orthographic and Contextual Models for Language Independent Named Entity Recognition .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .192 - 195 .","label":"Background","metadata":{},"score":"48.12319"}
{"text":"175 - 178 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .[Jan02 ] Martin Jansche , Named Entity Extraction with Conditional Markov Models and Classifiers .","label":"Background","metadata":{},"score":"48.12839"}
{"text":"In Proceedings of 1999 Joint SIGDAT Conference on EMNLP and VLC , University of Maryland , MD , 1999 .Models for Natural Language Learning using Unlabeled Data .Here is a lightly - annotated bibliography of papers on learning from labeled and unlabeled data .","label":"Background","metadata":{},"score":"48.22358"}
{"text":"It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .This lack of resources has led several researchers to explore the use of unannotated , raw , corpora to perform unsupervised disambiguation .","label":"Background","metadata":{},"score":"48.650917"}
{"text":"It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .This lack of resources has led several researchers to explore the use of unannotated , raw , corpora to perform unsupervised disambiguation .","label":"Background","metadata":{},"score":"48.650917"}
{"text":"It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .This lack of resources has led several researchers to explore the use of unannotated , raw , corpora to perform unsupervised disambiguation .","label":"Background","metadata":{},"score":"48.650917"}
{"text":"It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .This lack of resources has led several researchers to explore the use of unannotated , raw , corpora to perform unsupervised disambiguation .","label":"Background","metadata":{},"score":"48.650917"}
{"text":"It is often difficult to obtain appropriate lexical resources ( especially for texts in a specialized sublanguage ) .This lack of resources has led several researchers to explore the use of unannotated , raw , corpora to perform unsupervised disambiguation .","label":"Background","metadata":{},"score":"48.650917"}
{"text":"The data consists of two columns separated by a single space .Each word has been put on a separate line and there is an empty line after each sentence .The first item on each line is a word and the second the named entity tag .","label":"Background","metadata":{},"score":"48.802887"}
{"text":"Without this additional information their system ( 79.28 ) does not perform significantly better than that of [ Flo02 ] ( 79.05 ) .The [ CMP02 ] system uses AdaBoost applied to decision trees .The papers associated with the participating systems can be found in the reference section below .","label":"Background","metadata":{},"score":"48.97364"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .","label":"Background","metadata":{},"score":"49.021233"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .","label":"Background","metadata":{},"score":"49.021233"}
{"text":"This allowed Luk to produce a system which used the information in lexical resources as a way of reducing the amount of text needed in the training corpus .These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .","label":"Background","metadata":{},"score":"49.021233"}
{"text":"However , many of them used language - specific resources for performing the task and it is unknown how they would have performed on another language than English [ PD97 ] .After 1995 , NER systems have been developed for some European languages and a few Asian languages .","label":"Background","metadata":{},"score":"49.30584"}
{"text":"However , many of them used language - specific resources for performing the task and it is unknown how they would have performed on another language than English [ PD97 ] .After 1995 , NER systems have been developed for some European languages and a few Asian languages .","label":"Background","metadata":{},"score":"49.30584"}
{"text":"WNC03 ] Dekai Wu , Grace Ngai and Marine Carpuat , A Stacked , Voted , Stacked Model for Named Entity Recognition .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .200 - 203 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] ( with corrections ) system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"49.447693"}
{"text":"WNC03 ] Dekai Wu , Grace Ngai and Marine Carpuat , A Stacked , Voted , Stacked Model for Named Entity Recognition .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .200 - 203 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] ( with corrections ) system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"49.447693"}
{"text":"Words having no semantic tags ( determiners , prepositions , auxiliary verbs , etc . ) are ignored . constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .","label":"Background","metadata":{},"score":"49.551796"}
{"text":"Words having no semantic tags ( determiners , prepositions , auxiliary verbs , etc . ) are ignored . constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .","label":"Background","metadata":{},"score":"49.551796"}
{"text":"Words having no semantic tags ( determiners , prepositions , auxiliary verbs , etc . ) are ignored . constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .","label":"Background","metadata":{},"score":"49.551796"}
{"text":"Words having no semantic tags ( determiners , prepositions , auxiliary verbs , etc . ) are ignored . constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .","label":"Background","metadata":{},"score":"49.551796"}
{"text":"Words having no semantic tags ( determiners , prepositions , auxiliary verbs , etc . ) are ignored . constructing a training corpus and a test corpus from the semantically tagged Brown corpus ( manually tagged by the WordNet team ) by extracting tokens for the HMM bigrams .","label":"Background","metadata":{},"score":"49.551796"}
{"text":"Ham03 ] James Hammerton , Named Entity Recognition with Long Short - Term Memory .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .172 - 175 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"49.697876"}
{"text":"Ham03 ] James Hammerton , Named Entity Recognition with Long Short - Term Memory .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .172 - 175 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"49.697876"}
{"text":"Another example is the work of Pedersen [ 11 ] who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .","label":"Background","metadata":{},"score":"49.799194"}
{"text":"Another example is the work of Pedersen [ 11 ] who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .","label":"Background","metadata":{},"score":"49.799194"}
{"text":"Another example is the work of Pedersen [ 10 ] who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .","label":"Background","metadata":{},"score":"50.057407"}
{"text":"Another example is the work of Pedersen [ 10 ] who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .","label":"Background","metadata":{},"score":"50.057407"}
{"text":"Another example is the work of Pedersen [ 10 ] who compared three different unsupervised learning algorithms on 13 different words .Each algorithm was trained on text with was tagged with either the WordNet or LDOCE sense for the word but the algorithm had no access to the truce senses .","label":"Background","metadata":{},"score":"50.057407"}
{"text":"In this paper we show that for certain definitions of collocation , a polysemous word exhibits essentially only one sense per collocation .We test this empirical hypothesis ... \" .Previous work [ Gale , Church and Yarowsky , 1992 ] showed that with high probability a polysemous word has one sense per discourse .","label":"Background","metadata":{},"score":"50.187958"}
{"text":"In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 . which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"50.948303"}
{"text":"In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 . which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"50.948303"}
{"text":"[ TD03 ] Erik F. Tjong Kim Sang and Fien De Meulder , Introduction to the CoNLL-2003 Shared Task : Language - Independent Named Entity Recognition .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .142 - 147 .","label":"Background","metadata":{},"score":"50.95688"}
{"text":"[ TD03 ] Erik F. Tjong Kim Sang and Fien De Meulder , Introduction to the CoNLL-2003 Shared Task : Language - Independent Named Entity Recognition .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .142 - 147 .","label":"Background","metadata":{},"score":"50.95688"}
{"text":"paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .[ CY02 ] Silviu Cucerzan and David Yarowsky , Language Independent NER using a Unified Model of Internal and Contextual Evidence .","label":"Background","metadata":{},"score":"51.73509"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 Another example of this approach is the unsupervised algorithm of Yarowsky D. Yarowsky .","label":"Background","metadata":{},"score":"51.748215"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 Another example of this approach is the unsupervised algorithm of Yarowsky D. Yarowsky .","label":"Background","metadata":{},"score":"51.748215"}
{"text":"CoNLL-2002 Shared Task Papers .Note : in some cases the output files provided here contain results which are slightly different from those mentioned in the papers .[ TKS02 ] Erik F. Tjong Kim Sang , Introduction to the CoNLL-2002 Shared Task : Language - Independent Named Entity Recognition .","label":"Background","metadata":{},"score":"51.785255"}
{"text":"[ORG U.N. ] official [ PER Ekeus ] heads for [ LOC Baghdad ] .The shared task of CoNLL-2003 concerns language - independent named entity recognition .We will concentrate on four types of named entities : persons , locations , organizations and names of miscellaneous entities that do not belong to the previous three groups .","label":"Background","metadata":{},"score":"52.164497"}
{"text":"[ORG U.N. ] official [ PER Ekeus ] heads for [ LOC Baghdad ] .The shared task of CoNLL-2003 concerns language - independent named entity recognition .We will concentrate on four types of named entities : persons , locations , organizations and names of miscellaneous entities that do not belong to the previous three groups .","label":"Background","metadata":{},"score":"52.164497"}
{"text":"Cucerzan and Yarowsky [ CY99 ] used both morphological and contextual clues for identifying named entities in English , Greek , Hindi , Rumanian and Turkish .With minimal supervision , they obtained overall F measures between 40 and 70 , depending on the languages used .","label":"Background","metadata":{},"score":"52.381927"}
{"text":"Background information .Named Entity Recognition ( NER ) is a subtask of Information Extraction .Different NER systems were evaluated as a part of the Sixth Message Understanding Conference in 1995 ( MUC6 ) .The target language was English .","label":"Background","metadata":{},"score":"53.080345"}
{"text":"Background information .Named Entity Recognition ( NER ) is a subtask of Information Extraction .Different NER systems were evaluated as a part of the Sixth Message Understanding Conference in 1995 ( MUC6 ) .The target language was English .","label":"Background","metadata":{},"score":"53.080345"}
{"text":"Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 . which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"53.577583"}
{"text":"Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 . which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"53.577583"}
{"text":"Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 . which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"53.577583"}
{"text":"Statistical sense disambiguation with relatively small corpora using dictionary definitions .In Proceedings of the 33rd Meetings of the Association for Computational Linguistics ( ACL-95 ) , pages 181 - 188 , Cambridge , M.A. , 1995 . which uses the textual definitions of senses from a machine readable dictionary ( LDOCE ) to identify relations between senses .","label":"Background","metadata":{},"score":"53.577583"}
{"text":"Only if two phrases of the same type immediately follow each other , the first word of the second phrase will have tag B - TYPE to show that it starts a new phrase .A word with tag O is not part of a phrase .","label":"Background","metadata":{},"score":"53.842182"}
{"text":"Only if two phrases of the same type immediately follow each other , the first word of the second phrase will have tag B - TYPE to show that it starts a new phrase .A word with tag O is not part of a phrase .","label":"Background","metadata":{},"score":"53.842182"}
{"text":"The column to the right of the F rates shows estimations of the significance intervals for the F rates .They have been obtained with bootstrap resampling [ Nor89 ] .The results of [ BV02 ] mentioned here are different from those listed in the related paper because the latter were produced by incorrect software .","label":"Background","metadata":{},"score":"54.82772"}
{"text":".. training sets .It thrives on raw , unannotated monolingual corpora - the more the merrier .The use of dictionary ... . \" ...This paper describes a program that disambiguates English word senses in unrestricted text using statistical models of the major Roget 's Thesaurus categories .","label":"Background","metadata":{},"score":"55.168373"}
{"text":"In 1975 Kelly and Stone .E.F. Kelly and P.J. Stone .Computer Recognition of English Word Senses , Amsterdam : North - Holland . published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .","label":"Background","metadata":{},"score":"55.38784"}
{"text":"In 1975 Kelly and Stone .E.F. Kelly and P.J. Stone .Computer Recognition of English Word Senses , Amsterdam : North - Holland . published a book explicitly listing their rules for disambiguation of word senses .As large - scale lexical resources became available in the 1980s , the automatic extraction of lexical knowledge became possible , disambiguation was still knowledge- or dictionary - based though .","label":"Background","metadata":{},"score":"55.38784"}
{"text":"The significance intervals for the F rates have been obtained with bootstrap resampling [ Nor89 ] .A discussion of the shared task results can be found in the introduction paper [ TD03 ] .References .This is a list of papers that are relevant for this task .","label":"Background","metadata":{},"score":"55.39438"}
{"text":"The significance intervals for the F rates have been obtained with bootstrap resampling [ Nor89 ] .A discussion of the shared task results can be found in the introduction paper [ TD03 ] .References .This is a list of papers that are relevant for this task .","label":"Background","metadata":{},"score":"55.39438"}
{"text":"Please edit this file ( /afs / cs / project / theo-21/www / semisupervised .html ) to add more citations .Yarowsky wrote an early paper describing how to learn to disambiguate word senses .It makes the assumption that each occurance of a word ( e.g. , \" bank \" ) in a document has the same meaning ( e.g. , river bank or financial bank ) .","label":"Background","metadata":{},"score":"55.810287"}
{"text":"[ BON03 ] Oliver Bender , Franz Josef Och and Hermann Ney , Maximum Entropy Models for Named Entity Recognition In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .148 - 151 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"55.965656"}
{"text":"[ BON03 ] Oliver Bender , Franz Josef Och and Hermann Ney , Maximum Entropy Models for Named Entity Recognition In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .148 - 151 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"55.965656"}
{"text":"obvious .cases in a corpus .Decision lists R. Rivest .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .","label":"Background","metadata":{},"score":"56.01468"}
{"text":"obvious .cases in a corpus .Decision lists R. Rivest .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .","label":"Background","metadata":{},"score":"56.01468"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 These approaches can be neither properly classified as knowledge or corpus based but use part of both approaches .","label":"Background","metadata":{},"score":"56.185326"}
{"text":"203 - 206 . paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .[ Tsu02 ] Koji Tsukamoto , Yutaka Mitsuishi and Manabu Sassano , Learning with Multiple Stacking for Named Entity Recognition .","label":"Background","metadata":{},"score":"56.25215"}
{"text":"Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .","label":"Background","metadata":{},"score":"57.063236"}
{"text":"Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .","label":"Background","metadata":{},"score":"57.063236"}
{"text":"Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .","label":"Background","metadata":{},"score":"57.063236"}
{"text":"Tong Zhang and David Johnson , A Robust Risk Minimization based Named Entity Recognition System .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .204 - 207 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"57.331585"}
{"text":"Tong Zhang and David Johnson , A Robust Risk Minimization based Named Entity Recognition System .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .204 - 207 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"57.331585"}
{"text":"cases in a corpus .Decision lists R. Rivest .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .","label":"Background","metadata":{},"score":"57.848015"}
{"text":"cases in a corpus .Decision lists R. Rivest .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .","label":"Background","metadata":{},"score":"57.848015"}
{"text":"CC03 ] James R. Curran and Stephen Clark , Language Independent NER using a Maximum Entropy Tagger .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .164 - 167 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"58.33982"}
{"text":"CC03 ] James R. Curran and Stephen Clark , Language Independent NER using a Maximum Entropy Tagger .In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .164 - 167 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"58.33982"}
{"text":"Decision lists [ 13 ] are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .The learning proceeds in this way until all corpus instances are classified .","label":"Background","metadata":{},"score":"58.417713"}
{"text":"Decision lists [ 13 ] are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .The learning proceeds in this way until all corpus instances are classified .","label":"Background","metadata":{},"score":"58.417713"}
{"text":"Decision lists [ 13 ] are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .The learning proceeds in this way until all corpus instances are classified .","label":"Background","metadata":{},"score":"58.417713"}
{"text":"An early sceptic was Bar - Hillel who famously proclaimed that \" sense ambiguity could not be resolved by electronic computer either current or imaginable . ''Y. Bar - Hillel .Language and Information .Addison - Wesley , 1964 .","label":"Background","metadata":{},"score":"58.993877"}
{"text":"Decision lists [ 14 ] are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .The learning proceeds in this way until all corpus instances are classified .","label":"Background","metadata":{},"score":"59.57448"}
{"text":"Decision lists [ 14 ] are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .The learning proceeds in this way until all corpus instances are classified .","label":"Background","metadata":{},"score":"59.57448"}
{"text":"179 - 182 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .[Mal02 ] Robert Malouf , Markov models for language - independent named entity recognition .","label":"Background","metadata":{},"score":"60.198334"}
{"text":"[ CS99 ] Michael Collins and Yoram Singer , Unsupervised models for named entity classification .In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora , University of Maryland , MD , 1999 .","label":"Background","metadata":{},"score":"60.89971"}
{"text":"Language - Independent Named Entity Recognition ( I ) .Named entities are phrases that contain the names of persons , organizations , locations , times and quantities .Example : .[ PER Wolff ] , currently a journalist in [ LOC Argentina ] , played with [ PER Del Bosque ] in the final years of the seventies in [ ORG Real Madrid ] .","label":"Background","metadata":{},"score":"61.011078"}
{"text":"195 - 198 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .Other related publications .A paper that is related to the topic of this shared task is the EMNLP-99 paper by Cucerzan and Yarowsky [ CY99 ] .","label":"Background","metadata":{},"score":"61.072655"}
{"text":"In \" Proceedings of the International Conference on Recent Advances in Natural Language Processing , RANLP-2003 \" , Borovets , Bulgaria , 2003 .[ CS99 ] Michael Collins and Yoram Singer , Unsupervised models for named entity classification .In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora , University of Maryland , MD , 1999 .","label":"Background","metadata":{},"score":"61.15715"}
{"text":"In \" Proceedings of the International Conference on Recent Advances in Natural Language Processing , RANLP-2003 \" , Borovets , Bulgaria , 2003 .[ CS99 ] Michael Collins and Yoram Singer , Unsupervised models for named entity classification .In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora , University of Maryland , MD , 1999 .","label":"Background","metadata":{},"score":"61.15715"}
{"text":"Decision lists R. Rivest .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .","label":"Background","metadata":{},"score":"61.270454"}
{"text":"Decision lists R. Rivest .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .","label":"Background","metadata":{},"score":"61.270454"}
{"text":"Decision lists R. Rivest .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 are then used to make generalisations based on the corpus instances classified so far and these lists are then re - applied to the corpus to classify more instances .","label":"Background","metadata":{},"score":"61.270454"}
{"text":"Information sources other than the training data may be used in this shared task .We are especially interested in methods that can use additional unannotated data for improving their performance ( for example co - training ) .Background information .","label":"Background","metadata":{},"score":"61.4635"}
{"text":"We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .","label":"Background","metadata":{},"score":"62.210926"}
{"text":"Translation .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .Computer Recognition of English Word Senses , Amsterdam : North - Holland .Word sense disambiguation using conceptual density .","label":"Background","metadata":{},"score":"62.288086"}
{"text":"Translation .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .Computer Recognition of English Word Senses , Amsterdam : North - Holland .Word sense disambiguation using conceptual density .","label":"Background","metadata":{},"score":"62.288086"}
{"text":"191 - 194 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .[ WNC02 ] Dekai Wu , Grace Ngai , Marine Carpuat , Jeppe Larsen and Yongsheng Yang , Boosting for Named Entity Recognition .","label":"Background","metadata":{},"score":"62.902153"}
{"text":"Current accuracy exceeds 99 % on the full task , and typically is over 90 % for even the most difficult ambiguities .","label":"Background","metadata":{},"score":"63.38302"}
{"text":"Addison - Wesley , 1964 .However , the situation is not as bad as Bar - Hillel feared , there have been several advances in word sense disambiguation and it is now at a stage where lexical ambiguity in text can be resolved with a reasonable degree of accuracy .","label":"Background","metadata":{},"score":"63.41767"}
{"text":"183 - 186 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .[ PWM02 ] Jon Patrick , Casey Whitelaw and Robert Munro , SLINERC : The Sydney Language - Independent Named Entity Recogniser and Classifier .","label":"Background","metadata":{},"score":"63.61243"}
{"text":"Y. Bar - Hillel .Language and Information .Addison - Wesley , 1964 .We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .","label":"Background","metadata":{},"score":"63.769295"}
{"text":"Results .Sixteen systems have participated in the CoNLL-2003 shared task .They used a wide variety of machine learning techniques and different feature sets .Here is the result table for the English test set : .Here are some remarks on these results : .","label":"Background","metadata":{},"score":"64.14214"}
{"text":"Results .Sixteen systems have participated in the CoNLL-2003 shared task .They used a wide variety of machine learning techniques and different feature sets .Here is the result table for the English test set : .Here are some remarks on these results : .","label":"Background","metadata":{},"score":"64.14214"}
{"text":"171 - 174 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .[ Flo02 ] Radu Florian , Named Entity Recognition as a House of Cards : Classifier Stacking .","label":"Background","metadata":{},"score":"64.54466"}
{"text":"Contents .One of the first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .The resolution of a word 's syntactic ambiguity has largely been solved in language processing by part - of - speech taggers which predict the syntactic category of words in text with high levels of accuracy .","label":"Background","metadata":{},"score":"65.64145"}
{"text":"Contents .One of the first problems that is encountered by any natural language processing system is that of lexical ambiguity , be it syntactic or semantic .The resolution of a word 's syntactic ambiguity has largely been solved in language processing by part - of - speech taggers which predict the syntactic category of words in text with high levels of accuracy .","label":"Background","metadata":{},"score":"65.64145"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .","label":"Background","metadata":{},"score":"65.8277"}
{"text":"Results .Twelve systems have participated in the CoNLL-2002 shared task .They used a wide variety of machine learning techniques .Here is an overview of their performance on the two test data sets : .Here are some remarks on these results : .","label":"Background","metadata":{},"score":"65.88809"}
{"text":"However , the task has proved to be difficult for computer and some have believed that it would never be solved .An early sceptic was Bar - Hillel who famously proclaimed that \" sense ambiguity could not be resolved by electronic computer either current or imaginable . Y. Bar - Hillel .","label":"Background","metadata":{},"score":"67.48119"}
{"text":"Different NER systems were evaluated as a part of the Sixth Message Understanding Conference in 1995 ( MUC6 ) .The target language was English .The participating systems performed well .However , many of them used language - specific resources for performing the task and it is unknown how they would have performed on another language than English [ PD97 ] .","label":"Background","metadata":{},"score":"67.654015"}
{"text":"The data consists of three files per language : one training file and two test files testa and testb .The first test file will be used in the development phase for finding good parameters for the learning system .The second test file will be used for the final evaluation .","label":"Background","metadata":{},"score":"68.653786"}
{"text":"The data consists of three files per language : one training file and two test files testa and testb .The first test file will be used in the development phase for finding good parameters for the learning system .The second test file will be used for the final evaluation .","label":"Background","metadata":{},"score":"68.653786"}
{"text":"The data consists of three files per language : one training file and two test files testa and testb .The first test file will be used in the development phase for finding good parameters for the learning system .The second test file will be used for the final evaluation .","label":"Background","metadata":{},"score":"68.653786"}
{"text":"With minimal supervision , they obtained overall F measures between 40 and 70 , depending on the languages used .In the shared task at CoNLL-2002 , twelve different learning systems were applied to data in Spanish and Dutch .Software and Data .","label":"Background","metadata":{},"score":"68.815155"}
{"text":"With minimal supervision , they obtained overall F measures between 40 and 70 , depending on the languages used .In the shared task at CoNLL-2002 , twelve different learning systems were applied to data in Spanish and Dutch .Software and Data .","label":"Background","metadata":{},"score":"68.815155"}
{"text":"187 - 190 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .[ MM02 ] Paul McNamee and James Mayfield , Entity Extraction Without Language - Specific Resources .","label":"Background","metadata":{},"score":"69.07243"}
{"text":"in 1949 W. Weaver .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .The problem of WSD was first introduced by Warren .Weaver . in 1949 W. Weaver .","label":"Background","metadata":{},"score":"72.09592"}
{"text":"in 1949 W. Weaver .In Machine Translation of Languages : Fourteen Essays , ed . by Locke , W.N. and Booth , A.D. Cambridge , MA : MIT Press .The problem of WSD was first introduced by Warren .Weaver . in 1949 W. Weaver .","label":"Background","metadata":{},"score":"72.09592"}
{"text":"The van pulled up outside the bank and three masked men got out .We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .","label":"Background","metadata":{},"score":"74.3331"}
{"text":"The van pulled up outside the bank and three masked men got out .We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .","label":"Background","metadata":{},"score":"74.3331"}
{"text":"The van pulled up outside the bank and three masked men got out .We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .","label":"Background","metadata":{},"score":"74.3331"}
{"text":"The van pulled up outside the bank and three masked men got out .We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .","label":"Background","metadata":{},"score":"74.3331"}
{"text":"The van pulled up outside the bank and three masked men got out .We immediately recognise that in the first sentence bank refers to the edge of a river and in the second to a building .However , the task has proved to be difficult for computer and some have believed that it would never be solved .","label":"Background","metadata":{},"score":"74.3331"}
{"text":"The German files contain an extra column ( the second ) which holds the lemma of each word .Fetch this file , extract the data files with the command tar zxf ner.tgz and follow the instructions in the file ner/000README .","label":"Background","metadata":{},"score":"75.55863"}
{"text":"The German files contain an extra column ( the second ) which holds the lemma of each word .Fetch this file , extract the data files with the command tar zxf ner.tgz and follow the instructions in the file ner/000README .","label":"Background","metadata":{},"score":"75.55863"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .168 - 171 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"75.606"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .168 - 171 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"75.606"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .184 - 187 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"76.25202"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .184 - 187 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"76.25202"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .176 - 179 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"76.4541"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .176 - 179 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"76.4541"}
{"text":"The system of [ BV02 ] performs worse than the baseline system when processing the Dutch data because the authors used a poor representation of the data .They had removed all sentence breaks .The system of Xavier Carreras , Luís Màrquez and Luís Padró [ CMP02 ] outperformed all other systems by a significant margin , both on the Spanish test data ( 81.39 ) and the Dutch test data ( 77.05 ) .","label":"Background","metadata":{},"score":"76.493065"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .208 - 211 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"76.494675"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .208 - 211 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"76.494675"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .160 - 163 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"76.94844"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .160 - 163 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"76.94844"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Lainguistics ( ACL ' 95 ) , pages 189 - 196 , Cambridge , MA , 1995 .Learning decision lists .Machine Learning , 2(3):229 - 246 , 1987 aining algorithm still converges .","label":"Background","metadata":{},"score":"77.03294"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .188 - 191 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"77.30875"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .188 - 191 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"77.30875"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .180 - 183 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"77.447205"}
{"text":"In : Proceedings of CoNLL-2003 , Edmonton , Canada , 2003 , pp .180 - 183 .paper : [ ps ] [ ps.gz ] [ pdf ] [ bibtex ] system output : [ tgz ] [ files ] .","label":"Background","metadata":{},"score":"77.447205"}
{"text":"There are four types of phrases : person names ( PER ) , organizations ( ORG ) , locations ( LOC ) and miscellaneous names ( MISC ) .Here is an example : .Wolff B - PER , O currently O a O journalist O in O Argentina B - LOC , O played O with O Del B - PER Bosque I - PER in O the O final O years O of O the O seventies O in O Real B - ORG Madrid I - ORG .","label":"Background","metadata":{},"score":"79.85879"}
{"text":"The German data is a collection of articles from the Frankfurter Rundschau .The named entities have been annotated by people of the University of Antwerp .Only the annotations are available here .In order to build these data sets you need access to the ECI Multilingual Text Corpus .","label":"Background","metadata":{},"score":"84.43007"}
{"text":"The German data is a collection of articles from the Frankfurter Rundschau .The named entities have been annotated by people of the University of Antwerp .Only the annotations are available here .In order to build these data sets you need access to the ECI Multilingual Text Corpus .","label":"Background","metadata":{},"score":"84.43007"}
{"text":"The articles are from May 2000 .The Dutch data consist of four editions of the Belgian newspaper \" De Morgen \" of 2000 ( June 2 , July 1 , August 1 and September 1 ) .The data was annotated as a part of the Atranos project at the University of Antwerp .","label":"Background","metadata":{},"score":"87.30135"}
{"text":"U.N. NNP I - NP I - ORG official NN I - NP O Ekeus NNP I - NP I - PER heads VBZ I - VP O for IN I - PP O Baghdad NNP I - NP I - LOC .","label":"Background","metadata":{},"score":"104.96329"}
{"text":"U.N. NNP I - NP I - ORG official NN I - NP O Ekeus NNP I - NP I - PER heads VBZ I - VP O for IN I - PP O Baghdad NNP I - NP I - LOC .","label":"Background","metadata":{},"score":"104.96329"}
{"text":"The English data is a collection of news wire articles from the Reuters Corpus .The annotation has been done by people of the University of Antwerp .Because of copyright reasons we only make available the annotations .In order to build the complete data sets you will need access to the Reuters Corpus .","label":"Background","metadata":{},"score":"108.209175"}
{"text":"The English data is a collection of news wire articles from the Reuters Corpus .The annotation has been done by people of the University of Antwerp .Because of copyright reasons we only make available the annotations .In order to build the complete data sets you will need access to the Reuters Corpus .","label":"Background","metadata":{},"score":"108.209175"}
