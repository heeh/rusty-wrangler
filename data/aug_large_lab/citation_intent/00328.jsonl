{"text":"Our approach learns from natural language sentences paired with world states consisting of multiple potential logical meaning representations .It disambiguates the meaning of each sentence while simultaneously learning a semantic parser that maps sentences into logical form .Compared to a previous generative model for semantic alignment , it also supports full semantic parsing .","label":"Background","metadata":{},"score":"24.963087"}{"text":"Our approach learns from natural language sentences paired with world states consisting of multiple potential logical meaning representations .It disambiguates the meaning of each sentence while simultaneously learning a semantic parser that maps sentences into logical form .Compared to a previous generative model for semantic alignment , it also supports full semantic parsing .","label":"Background","metadata":{},"score":"24.963087"}{"text":"Most recent work on semantic analysis of natural language has focused on ' ' shallow ' ' semantics such as word - sense disambiguation and semantic role labeling .Our work addresses a more ambitious task we call semantic parsing where natural language sentences are mapped to complete formal meaning representations .","label":"Background","metadata":{},"score":"25.901115"}{"text":"Most recent work on semantic analysis of natural language has focused on ' ' shallow ' ' semantics such as word - sense disambiguation and semantic role labeling .Our work addresses a more ambitious task we call semantic parsing where natural language sentences are mapped to complete formal meaning representations .","label":"Background","metadata":{},"score":"25.901115"}{"text":"We present a new approach to learning a semantic parser ( a system that maps natural language sentences into logical form ) .Unlike previous methods , it exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .","label":"Background","metadata":{},"score":"25.98249"}{"text":"We present a new approach to learning a semantic parser ( a system that maps natural language sentences into logical form ) .Unlike previous methods , it exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .","label":"Background","metadata":{},"score":"25.98249"}{"text":"In recent years there has been considerable interest in corpus - based methods for constructing natural language parsers .These empirical approaches replace hand - crafted grammars with linguistic models acquired through automated training over language corpora .A common thread among such methods to date is the use of propositional or probablistic representations for the learned knowledge .","label":"Background","metadata":{},"score":"26.561117"}{"text":"In recent years there has been considerable interest in corpus - based methods for constructing natural language parsers .These empirical approaches replace hand - crafted grammars with linguistic models acquired through automated training over language corpora .A common thread among such methods to date is the use of propositional or probablistic representations for the learned knowledge .","label":"Background","metadata":{},"score":"26.561117"}{"text":"In this thesis , we focus on the task of semantic parsing , which maps a natural language sentence into a complete , formal meaning representation in a meaning representation language .We present two novel state - of - the - art learned syntax - based semantic parsers using statistical syntactic parsing techniques , motivated by the following two reasons .","label":"Background","metadata":{},"score":"26.65575"}{"text":"We also introduce a modified closed - world assumption that significantly reduces the size of the ground network , thereby making inference feasible .Our approach is evaluated on the recognizing textual entailment task , and experiments demonstrate its dramatic impact on the efficiency of inference .","label":"Background","metadata":{},"score":"27.029707"}{"text":"However , I believe that logical approaches may have the most relevance and impact at the level of semantic interpretation , where a logical representation of sentence meaning is important and useful .We have explored the use of inductive logic programming for learning parsers that map natural - language database queries into executable logical form .","label":"Background","metadata":{},"score":"27.91969"}{"text":"I first present a historical view of the shifting emphasis of research on various tasks in natural language processing and then briefly review our own work on learning for semantic interpretation .I will then attempt to encourage others to study such problems and explain why I believe logical approaches have the most to offer at the level of producing semantic interpretations of complete sentences .","label":"Background","metadata":{},"score":"27.919945"}{"text":"In future work , we intend to pursue several directions in developing accurate semantic parsers for a variety of application domains .This will involve exploiting prior knowledge about the natural - language syntax and the application domain .We also plan to construct a syntax - aware word - based alignment model for lexical acquisition .","label":"Background","metadata":{},"score":"28.977518"}{"text":"In future work , we intend to pursue several directions in developing accurate semantic parsers for a variety of application domains .This will involve exploiting prior knowledge about the natural - language syntax and the application domain .We also plan to construct a syntax - aware word - based alignment model for lexical acquisition .","label":"Background","metadata":{},"score":"28.977518"}{"text":"In future work , we intend to pursue several directions in developing accurate semantic parsers for a variety of application domains .This will involve exploiting prior knowledge about the natural - language syntax and the application domain .We also plan to construct a syntax - aware word - based alignment model for lexical acquisition .","label":"Background","metadata":{},"score":"28.977518"}{"text":"A current research topic involves using machine learning methods to automate the development of NLI 's .This proposal presents a method for learning semantic parsers ( systems for mapping natural language to logical form ) that integrates logic - based and probabilistic methods in order to exploit the complementary strengths of these competing approaches .","label":"Background","metadata":{},"score":"29.696545"}{"text":"Initial experimental results from three different domains suggest that an integration of statistical and logical approaches to semantic parsing can outperform a purely logical approach .Future research will further develop this integrated approach and demonstrate its ability to improve the automated development of NLI 's .","label":"Background","metadata":{},"score":"29.720064"}{"text":"This is quite different from representing them in standard first - order logic . 2 ) knowledge base construction in the form of weighted inference rules from different sources like WordNet , paraphrase collections , and lexical and phrasal distributional rules generated on the fly .","label":"Background","metadata":{},"score":"30.278912"}{"text":"It is especially important in language grounding where the training data usually consist of language paired with an ambiguous perceptual context .Recent work by Chen and Mooney ( 2011 ) introduced a lexicon learning method that deals with ambiguous relational data by taking intersections of graphs .","label":"Background","metadata":{},"score":"30.54126"}{"text":"Empirical methods for building natural language systems has become an important area of research in recent years .Most current approaches are based on propositional learning algorithms and have been applied to the problem of acquiring broad - coverage parsers for relatively shallow ( syntactic ) representations .","label":"Background","metadata":{},"score":"30.663137"}{"text":"In recent years , startling progress has been made at different levels of natural language processing tasks , which provides great opportunity for deeper natural language understanding .In this thesis , we focus on the task of semantic parsing , which maps a natural language sentence into a complete , formal meaning representation in a meaning representation language .","label":"Background","metadata":{},"score":"30.89133"}{"text":"In recent years , startling progress has been made at different levels of natural language processing tasks , which provides great opportunity for deeper natural language understanding .In this thesis , we focus on the task of semantic parsing , which maps a natural language sentence into a complete , formal meaning representation in a meaning representation language .","label":"Background","metadata":{},"score":"30.89133"}{"text":"Our work is also the first attempt to use the same automatically - learned grammar for both parsing and generation .Unlike previous systems that require manually - constructed grammars and lexicons , our systems require much less knowledge engineering and can be easily ported to other languages and domains .","label":"Background","metadata":{},"score":"30.973402"}{"text":"Our work is also the first attempt to use the same automatically - learned grammar for both parsing and generation .Unlike previous systems that require manually - constructed grammars and lexicons , our systems require much less knowledge engineering and can be easily ported to other languages and domains .","label":"Background","metadata":{},"score":"30.973402"}{"text":"Our work is also the first attempt to use the same automatically - learned grammar for both parsing and generation .Unlike previous systems that require manually - constructed grammars and lexicons , our systems require much less knowledge engineering and can be easily ported to other languages and domains .","label":"Background","metadata":{},"score":"30.973402"}{"text":"Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing user - friendly natural language interfaces to computing systems .Most of the research in natural language understanding , however , has mainly focused on shallow semantic analysis like case - role analysis or word sense disambiguation .","label":"Background","metadata":{},"score":"31.088413"}{"text":"This paper presents an effort to enable robots to utilize open - source knowledge resources autonomously for human - robot interaction .The main challenges include how to extract knowledge in semi - structured and unstructured natural languages , how to make use of multiple types of knowledge in decision making , and how to identify the knowledge that is missing .","label":"Background","metadata":{},"score":"31.389423"}{"text":"Our results demonstrate that even a small amount of semantic annotations greatly improves the accu - racy of learned dependencies when tested on both in - domain and out - of - domain texts.1 . \" ...This paper presents an effort to enable robots to utilize open - source knowledge resources autonomously for human - robot interaction .","label":"Background","metadata":{},"score":"31.601303"}{"text":"To acquire such grammar rules automatically in an unsupervised manner , we also propose a novel approach with a generative model , which maps from sub - expressions of logical forms to word sequences in natural language sentences .Experiments on benchmark datasets for both English and Chinese generation tasks yield significant improvements over results obtained by two state - of - the - art machine translation models , in terms of both automatic metrics and human evaluation . \" ...","label":"Background","metadata":{},"score":"31.804693"}{"text":"However , novel natural language text or discourse often presents both unknown concepts and words which refer to these concepts .Also , developmental data suggests that the learning of words and their concepts frequently occurs concurrently instead of concept learning proceeding word learning .","label":"Background","metadata":{},"score":"31.850147"}{"text":"We combine logical and distributional representations of natural language meaning by transforming distributional similarity judgments into weighted inference rules using Markov Logic Networks ( MLNs ) .We show that this framework supports both judging sentence similarity and recognizing textual entailment by appropriately adapting the MLN implementation of logical connectives .","label":"Background","metadata":{},"score":"31.91462"}{"text":"However , it is an open question of how best to integrate it with uncertain , probabilistic knowledge , for example regarding word meaning .This paper describes the first steps of an approach to recasting first - order semantics into the probabilistic models that are part of Statistical Relational AI .","label":"Background","metadata":{},"score":"31.94501"}{"text":"We have explored the use of inductive logic programming for learning parsers that map natural - language database queries into executable logical form .This work goes against the growing trend in computational linguistics of focusing on shallow but broad - coverage natural language tasks ( ' ' scaling up by dumbing down ' ' ) and instead concerns using logic - based learning to develop narrower , domain - specific systems that perform relatively deep processing .","label":"Background","metadata":{},"score":"32.166004"}{"text":"These classifiers are further refined using EM - type iterations based on their performance on the training data .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .Our experiments on two real - world data sets that have deep meaning representations show that this approach compares favorably to other existing systems in terms of accuracy and coverage .","label":"Background","metadata":{},"score":"32.258423"}{"text":"These classifiers are further refined using EM - type iterations based on their performance on the training data .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .Our experiments on two real - world data sets that have deep meaning representations show that this approach compares favorably to other existing systems in terms of accuracy and coverage .","label":"Background","metadata":{},"score":"32.258423"}{"text":"These classifiers are further refined using EM - type iterations based on their performance on the training data .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .Our experiments on two real - world data sets that have deep meaning representations show that this approach compares favorably to other existing systems in terms of accuracy and coverage .","label":"Background","metadata":{},"score":"32.258423"}{"text":"Our approach involves building a probabilistic context - free grammar for each author and using this grammar as a language model for classification .We evaluate the performance of our method on a wide range of datasets to demonstrate its efficacy .","label":"Background","metadata":{},"score":"32.312187"}{"text":"Our approach involves building a probabilistic context - free grammar for each author and using this grammar as a language model for classification .We evaluate the performance of our method on a wide range of datasets to demonstrate its efficacy .","label":"Background","metadata":{},"score":"32.312187"}{"text":"However , it does not scale to problems with a large set of potential meanings for each sentence , such as the navigation instruction following task studied by Chen and Mooney ( 2011 ) .This paper presents an enhancement of the PCFG approach that scales to such problems with highly - ambiguous supervision .","label":"Background","metadata":{},"score":"32.384575"}{"text":"However , it does not scale to problems with a large set of potential meanings for each sentence , such as the navigation instruction following task studied by Chen and Mooney ( 2011 ) .This paper presents an enhancement of the PCFG approach that scales to such problems with highly - ambiguous supervision .","label":"Background","metadata":{},"score":"32.384575"}{"text":"Distributional models use contextual similarity to predict the ' ' graded ' ' semantic similarity of words and phrases but they do not adequately capture logical structure .In addition , there are a few recent attempts to combine both representations either on the logic side ( still , not a graded representation ) , or in the distribution side(not full logic ) .","label":"Background","metadata":{},"score":"32.576534"}{"text":"Initial experiments show that this approach is able to construct accurate parsers which generalize well to novel sentences and significantly outperform previous approaches to learning case - role mapping based on connectionist techniques .Planned extensions of the general framework and the specific applications as well as plans for further evaluation are also discussed .","label":"Background","metadata":{},"score":"32.596817"}{"text":"Logic - based representations characterize sentence structure , but do not capture the graded aspect of meaning .Distributional models give graded similarity ratings for words and phrases , but do not adequately capture overall sentence structure .So it has been argued that the two are complementary .","label":"Background","metadata":{},"score":"32.77485"}{"text":"Because we do not have gold - standard references for training a secondary conditional reranker , we incorporate weak supervision of evaluations against the perceptual world during the process of improving model performance .All these approaches are evaluated on the two publicly available domains that have been actively used in many other grounded language learning studies .","label":"Background","metadata":{},"score":"32.778168"}{"text":"I will then attempt to encourage others to study such problems and explain why I believe logical approaches have the most to offer at the level of producing semantic interpretations of complete sentences .ML ID : 93 .Automatic Construction of Semantic Lexicons for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixteenth National Conference on Artificial Intelligence ( AAAI-99 ) , 487 - 493 , Orlando , FL , July 1999 .","label":"Background","metadata":{},"score":"32.96315"}{"text":"They can also provide insight into important issues in human language acquisition .However , within AI , computational linguistics , and machine learning , there has been relatively little research on developing systems that learn such semantic parsers .This paper briefly reviews our own work in this area and presents semantic - parser acquistion as an important challenge problem for AI .","label":"Background","metadata":{},"score":"33.065327"}{"text":"They can also provide insight into important issues in human language acquisition .However , within AI , computational linguistics , and machine learning , there has been relatively little research on developing systems that learn such semantic parsers .This paper briefly reviews our own work in this area and presents semantic - parser acquistion as an important challenge problem for AI .","label":"Background","metadata":{},"score":"33.065327"}{"text":"Most of the research in natural language understanding , however , has mainly focused on shallow semantic analysis like case - role analysis or word sense disambiguation .The existing work in semantic parsing either lack the robustness of statistical methods or are applicable only to simple domains where semantic analysis is equivalent to filling a single semantic frame .","label":"Background","metadata":{},"score":"33.227074"}{"text":"Most of the research in natural language understanding , however , has mainly focused on shallow semantic analysis like case - role analysis or word sense disambiguation .The existing work in semantic parsing either lack the robustness of statistical methods or are applicable only to simple domains where semantic analysis is equivalent to filling a single semantic frame .","label":"Background","metadata":{},"score":"33.227074"}{"text":"It describes the representation of knowledge assumed by each of these approaches and reviews basic algorithms for inducing such representations from annotated training examples and using the acquired knowledge to classify future instances .These techniques can be applied to learn knowledge required for a variety of problems in computational linguistics ranging from part - of - speech tagging and syntactic parsing to word - sense disambiguation and anaphora resolution .","label":"Background","metadata":{},"score":"33.23495"}{"text":"Our system uses a syntactic combinatorial categorial parser to parse natural language sentences and also to construct the semantic meaning of the sentences as directed by their parsing .The same parser is used for both .In addition to the inverse Î» - calculus operators , our system uses a notion of generalization to learn semantic representation of words from the semantic representation of other words that are of the same category .","label":"Background","metadata":{},"score":"33.34078"}{"text":"Typically the task involves identifying a subset of records from a list of candidates as the correct meaning of a sentence .While most current work assume complete or partial independence be- tween the records , we examine a scenario in which they are strongly related .","label":"Background","metadata":{},"score":"33.353676"}{"text":"This paper presents a general framework , learning search - control heuristics for logic programs , which can be used to improve both the efficiency and accuracy of knowledge - based systems expressed as definite - clause logic programs .The approach combines techniques of explanation - based learning and recent advances in inductive logic programming to learn clause - selection heuristics that guide program execution .","label":"Background","metadata":{},"score":"33.392307"}{"text":"In particular , our learning approach takes semantic annotations encoding underlying embedded struc - tural relations and automatically induces derivation rules that map sentences to their semantic meaning representa - tions .ports rightbranching semantic structures .However these systems either require a hand - built , ambiguous combinatory categorial grammar template to learn a probabilistic semantic parser [ 6 ] , or assume the existence of an unambiguous , context- ...","label":"Background","metadata":{},"score":"33.77564"}{"text":"Semantic parsing , on the other hand , involves deep semantic analysis in which word senses , semantic roles and other components are combined to produce useful meaning representations for a particular application domain ( e.g. database query ) .Prior research in machine learning for semantic parsing is mainly based on inductive logic programming or deterministic parsing , which lack some of the robustness that characterizes statistical learning .","label":"Background","metadata":{},"score":"33.795914"}{"text":"Semantic parsing , on the other hand , involves deep semantic analysis in which word senses , semantic roles and other components are combined to produce useful meaning representations for a particular application domain ( e.g. database query ) .Prior research in machine learning for semantic parsing is mainly based on inductive logic programming or deterministic parsing , which lack some of the robustness that characterizes statistical learning .","label":"Background","metadata":{},"score":"33.795914"}{"text":"Semantic parsing , on the other hand , involves deep semantic analysis in which word senses , semantic roles and other components are combined to produce useful meaning representations for a particular application domain ( e.g. database query ) .Prior research in machine learning for semantic parsing is mainly based on inductive logic programming or deterministic parsing , which lack some of the robustness that characterizes statistical learning .","label":"Background","metadata":{},"score":"33.795914"}{"text":"Unfortunately , large scale systems can not be easily machine - learned due to lack of directly supervised data .We propose here a method that ... \" .Open - text ( or open - domain ) semantic parsers are designed to interpret any statement in natural language by inferring a corresponding meaning representation ( MR ) .","label":"Background","metadata":{},"score":"34.01703"}{"text":"To truly understand language , an intelligent system must be able to connect words , phrases , and sentences to its perception of objects and events in the world .Current natural language processing and computer vision systems make extensive use of machine learning to acquire the probabilistic knowledge needed to comprehend linguistic and visual input .","label":"Background","metadata":{},"score":"34.083763"}{"text":"To truly understand language , an intelligent system must be able to connect words , phrases , and sentences to its perception of objects and events in the world .Current natural language processing and computer vision systems make extensive use of machine learning to acquire the probabilistic knowledge needed to comprehend linguistic and visual input .","label":"Background","metadata":{},"score":"34.083763"}{"text":"We introduce a refinement algorithm that first learns a lexicon which is then used to remove parts of the graphs that are irrelevant .Experiments in a navigation domain shows that the algorithm successfully recovered over three quarters of the correct semantic content .","label":"Background","metadata":{},"score":"34.115307"}{"text":"We focus on two important sub - tasks , semantic parsing and tactical generation .The key idea is that both tasks can be treated as the translation between natural languages and formal meaning representation languages , and therefore , can be performed using state - of - the - art statistical machine translation techniques .","label":"Background","metadata":{},"score":"34.21843"}{"text":"We focus on two important sub - tasks , semantic parsing and tactical generation .The key idea is that both tasks can be treated as the translation between natural languages and formal meaning representation languages , and therefore , can be performed using state - of - the - art statistical machine translation techniques .","label":"Background","metadata":{},"score":"34.21843"}{"text":"We focus on two important sub - tasks , semantic parsing and tactical generation .The key idea is that both tasks can be treated as the translation between natural languages and formal meaning representation languages , and therefore , can be performed using state - of - the - art statistical machine translation techniques .","label":"Background","metadata":{},"score":"34.21843"}{"text":"Invited paper .Semantic parsing is the task of mapping a natural language sentence into a complete , formal meaning representation .Over the past decade , we have developed a number of machine learning methods for inducing semantic parsers by training on a corpus of sentences paired with their meaning representations in a specified formal language .","label":"Background","metadata":{},"score":"34.2229"}{"text":"Invited paper .Semantic parsing is the task of mapping a natural language sentence into a complete , formal meaning representation .Over the past decade , we have developed a number of machine learning methods for inducing semantic parsers by training on a corpus of sentences paired with their meaning representations in a specified formal language .","label":"Background","metadata":{},"score":"34.2229"}{"text":"Invited paper .Semantic parsing is the task of mapping a natural language sentence into a complete , formal meaning representation .Over the past decade , we have developed a number of machine learning methods for inducing semantic parsers by training on a corpus of sentences paired with their meaning representations in a specified formal language .","label":"Background","metadata":{},"score":"34.2229"}{"text":"Our system handles overall sentence structure and phenomena like negation in the logic , then uses our Robinson resolution variant to query distributional systems about words and short phrases .Therefor , we use our system to evaluate distributional lexical entailment approaches .","label":"Background","metadata":{},"score":"34.371033"}{"text":"Models of learning word meanings have generally assumed prior knowledge of the concepts to which the words refer .However , novel natural language text or discourse often presents both unknown concepts and words which refer to these concepts .Also , developmental data suggests that the learning of words and their concepts frequently occurs concurrently instead of concept learning proceeding word learning .","label":"Background","metadata":{},"score":"34.457855"}{"text":"Next , I present an end - to - end deep network that can jointly model a sequence of video frames and a sequence of words .The second part of the proposal outlines a set of models to significantly extend work in this area .","label":"Background","metadata":{},"score":"34.458557"}{"text":"In the second approach , the implicit extraction features are focused on the shortest path between the two entities in the word - word dependency graph of the sentence .Finally , in a significant departure from previous learning approaches to relation extraction , we propose reducing the amount of required supervision to only a handful of pairs of entities known to exhibit or not exhibit the desired relationship .","label":"Background","metadata":{},"score":"34.677605"}{"text":"Furthermore , we propose a novel approach to weighting rules using a curated lexical ontology like WordNet .The learned rules along with their parameters are then used to infer implicit information using a Bayesian Logic Program .Experimental evaluation on a machine reading testbed demonstrates the efficacy of the proposed methods .","label":"Background","metadata":{},"score":"34.838707"}{"text":"In this paper , we present an approach that learns the parameters of a Bayesian network composed of noisy - or and noisy - and nodes by using a gradient descent back - propagation approach similar to that used to train neural networks .","label":"Background","metadata":{},"score":"34.853516"}{"text":"Semantic parsing is the process of mapping a natural - language sentence into a formal representation of its meaning .A shallow form of semantic representation is a case - role analysis ( a.k.a . a semantic role labeling ) , which identifies roles such as agent , patient , source , and destination .","label":"Background","metadata":{},"score":"34.87774"}{"text":"Learning Semantic Parsers Using Statistical Syntactic Parsing Techniques [ Details ] [ PDF ] Ruifang Ge 2006 .Most recent work on semantic analysis of natural language has focused on ' ' shallow ' ' semantics such as word - sense disambiguation and semantic role labeling .","label":"Background","metadata":{},"score":"34.920242"}{"text":"However , most results to date for active learning have only considered standard classification tasks .To reduce annotation effort while maintaining accuracy , we apply active learning to semantic lexicons .We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance .","label":"Background","metadata":{},"score":"34.927765"}{"text":"This paper shows how the semantic - grammar acquisition problem can be viewed as the learning of search - control heuristics in a logic program .Appropriate control rules are learned using a new first - order induction algorithm that automatically invents useful syntactic and semantic categories .","label":"Background","metadata":{},"score":"34.946144"}{"text":"This paper presents an approach for inducing transformation rules that map natural - language sentences into a formal semantic representation language .The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .","label":"Background","metadata":{},"score":"34.97823"}{"text":"This paper presents an approach for inducing transformation rules that map natural - language sentences into a formal semantic representation language .The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .","label":"Background","metadata":{},"score":"34.97823"}{"text":"For most natural language processing tasks , a parser that maps sentences into a semantic representation is significantly more useful than a grammar or automata that simply recognizes syntactically well - formed strings .This paper reviews our work on using inductive logic programming methods to learn deterministic shift - reduce parsers that translate natural language into a semantic representation .","label":"Background","metadata":{},"score":"35.025917"}{"text":"For most natural language processing tasks , a parser that maps sentences into a semantic representation is significantly more useful than a grammar or automata that simply recognizes syntactically well - formed strings .This paper reviews our work on using inductive logic programming methods to learn deterministic shift - reduce parsers that translate natural language into a semantic representation .","label":"Background","metadata":{},"score":"35.025917"}{"text":"For most natural language processing tasks , a parser that maps sentences into a semantic representation is significantly more useful than a grammar or automata that simply recognizes syntactically well - formed strings .This paper reviews our work on using inductive logic programming methods to learn deterministic shift - reduce parsers that translate natural language into a semantic representation .","label":"Background","metadata":{},"score":"35.025917"}{"text":"However , due to lexical ambiguity , encoding word meaning with a single vector is problematic .This paper presents a method that uses clustering to produce multiple \" sense - specific&rdquo vectors for each word .This approach provides a context - dependent vector representation of word meaning that naturally accommodates homonymy and polysemy .","label":"Background","metadata":{},"score":"35.27149"}{"text":"However , due to lexical ambiguity , encoding word meaning with a single vector is problematic .This paper presents a method that uses clustering to produce multiple \" sense - specific&rdquo vectors for each word .This approach provides a context - dependent vector representation of word meaning that naturally accommodates homonymy and polysemy .","label":"Background","metadata":{},"score":"35.27149"}{"text":"However , due to lexical ambiguity , encoding word meaning with a single vector is problematic .This paper presents a method that uses clustering to produce multiple \" sense - specific&rdquo vectors for each word .This approach provides a context - dependent vector representation of word meaning that naturally accommodates homonymy and polysemy .","label":"Background","metadata":{},"score":"35.27149"}{"text":"Previous work in computational linguistics on extracting lexical semantic information from unannotated corpora does not provide adequate representational flexibility and hence fails to capture the full extent of human conceptual knowledge .In this thesis I outline a family of probabilistic models capable of capturing important aspects of the rich organizational structure found in human language that can predict contextual variation , selectional preference and feature - saliency norms to a much higher degree of accuracy than previous approaches .","label":"Background","metadata":{},"score":"35.42533"}{"text":"Previous work in computational linguistics on extracting lexical semantic information from unannotated corpora does not provide adequate representational flexibility and hence fails to capture the full extent of human conceptual knowledge .In this thesis I outline a family of probabilistic models capable of capturing important aspects of the rich organizational structure found in human language that can predict contextual variation , selectional preference and feature - saliency norms to a much higher degree of accuracy than previous approaches .","label":"Background","metadata":{},"score":"35.42533"}{"text":"In the future , we intend to pursue several directions in developing more accurate semantic parsing algorithms and automating the annotation process .This work will involve exploring alternative tree representations for better generalization in parsing .We also plan to apply discriminative reranking methods to semantic parsing , which allows exploring arbitrary , potentially correlated features not usable by the baseline learner .","label":"Background","metadata":{},"score":"35.512497"}{"text":"In the future , we intend to pursue several directions in developing more accurate semantic parsing algorithms and automating the annotation process .This work will involve exploring alternative tree representations for better generalization in parsing .We also plan to apply discriminative reranking methods to semantic parsing , which allows exploring arbitrary , potentially correlated features not usable by the baseline learner .","label":"Background","metadata":{},"score":"35.512497"}{"text":"In this proposal I will outline a family of probabilistic models capable of accounting for the rich organizational structure found in human language that can predict contextual variation , selectional preference and feature - saliency norms to a much higher degree of accuracy than previous approaches .","label":"Background","metadata":{},"score":"35.64025"}{"text":"In this proposal I will outline a family of probabilistic models capable of accounting for the rich organizational structure found in human language that can predict contextual variation , selectional preference and feature - saliency norms to a much higher degree of accuracy than previous approaches .","label":"Background","metadata":{},"score":"35.64025"}{"text":"In this proposal I will outline a family of probabilistic models capable of accounting for the rich organizational structure found in human language that can predict contextual variation , selectional preference and feature - saliency norms to a much higher degree of accuracy than previous approaches .","label":"Background","metadata":{},"score":"35.64025"}{"text":"In particular , we are developing methods in which advice is given in ordinary natural language ( which is translated into formal advice using a learned semantic parser ) .By taking advantage of general advice on actions to perform in certain situations , the agent 's learning rate can be greatly accelerated .","label":"Background","metadata":{},"score":"35.643867"}{"text":"Finally , we test the system on an alternate sentence representation , and on a set of large , artificial corpora with varying levels of ambiguity and synonymy .One difficulty in using machine learning methods for building natural language interfaces is building the required annotated corpus .","label":"Background","metadata":{},"score":"35.733505"}{"text":"Finally , we test the system on an alternate sentence representation , and on a set of large , artificial corpora with varying levels of ambiguity and synonymy .One difficulty in using machine learning methods for building natural language interfaces is building the required annotated corpus .","label":"Background","metadata":{},"score":"35.733505"}{"text":"Finally , we test the system on an alternate sentence representation , and on a set of large , artificial corpora with varying levels of ambiguity and synonymy .One difficulty in using machine learning methods for building natural language interfaces is building the required annotated corpus .","label":"Background","metadata":{},"score":"35.733505"}{"text":"The parsing and generation algorithms learn all of their linguistic knowledge from annotated corpora , and can handle natural - language sentences that are conceptually complex .A nice feature of our algorithms is that the semantic parsers and tactical generators share the same learned synchronous grammars .","label":"Background","metadata":{},"score":"35.857384"}{"text":"The parsing and generation algorithms learn all of their linguistic knowledge from annotated corpora , and can handle natural - language sentences that are conceptually complex .A nice feature of our algorithms is that the semantic parsers and tactical generators share the same learned synchronous grammars .","label":"Background","metadata":{},"score":"35.857384"}{"text":"The parsing and generation algorithms learn all of their linguistic knowledge from annotated corpora , and can handle natural - language sentences that are conceptually complex .A nice feature of our algorithms is that the semantic parsers and tactical generators share the same learned synchronous grammars .","label":"Background","metadata":{},"score":"35.857384"}{"text":"the notion that humans make use of different categorization systems for different kinds of generalization tasks - and can be applied to Web - scale corpora .Using these models , natural language systems will be able to infer a more comprehensive semantic relations , in turn improving question answering , text classification , machine translation , and information retrieval .","label":"Background","metadata":{},"score":"36.089294"}{"text":"the notion that humans make use of different categorization systems for different kinds of generalization tasks - and can be applied to Web - scale corpora .Using these models , natural language systems will be able to infer a more comprehensive semantic relations , in turn improving question answering , text classification , machine translation , and information retrieval .","label":"Background","metadata":{},"score":"36.089294"}{"text":"the notion that humans make use of different categorization systems for different kinds of generalization tasks - and can be applied to Web - scale corpora .Using these models , natural language systems will be able to infer a more comprehensive semantic relations , in turn improving question answering , text classification , machine translation , and information retrieval .","label":"Background","metadata":{},"score":"36.089294"}{"text":"Numerous examples are presented illustrating its application to a wide variety of domains , including \" blocks world \" planning , logic circuit design , artifact recognition , and various forms of mathematical problem solving .The system is shown to improve its performance in each of these domains .","label":"Background","metadata":{},"score":"36.114014"}{"text":"We approach this task as a phrase classification problem , in which candidate phrases from the same document are collectively classified .Global correlations between candidate entities are captured in a model built using the expressive framework of Relational Markov Networks .","label":"Background","metadata":{},"score":"36.166092"}{"text":"The motivation for a combined system is to generate richer linguistic descriptions of images .Standalone vision systems are typically unable to generate linguistically rich descriptions .This approach combines abundant available language data to clean up noisy results from standalone vision systems .","label":"Background","metadata":{},"score":"36.23462"}{"text":"The approach combines techniques of explanation - based learning and recent advances in inductive logic programming to learn clause - selection heuristics that guide program execution .Two specific applications of this framework are detailed : dynamic optimization of Prolog programs ( improving efficiency ) and natural language acquisition ( improving accuracy ) .","label":"Background","metadata":{},"score":"36.266125"}{"text":"Learning from natural - language advice and reinforcements is the topic of the PILLAR research project .We present a new approach to learning a semantic parser ( a system that maps natural language sentences into logical form ) .Unlike previous methods , it exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .","label":"Background","metadata":{},"score":"36.28603"}{"text":"Semantic parsing is the construction of a complete , formal , symbolic meaning representation of a sentence .While it is crucial to natural language understanding , the problem of semantic parsing has received relatively little attention from the machine learning community .","label":"Background","metadata":{},"score":"36.354557"}{"text":"Semantic parsing is the construction of a complete , formal , symbolic meaning representation of a sentence .While it is crucial to natural language understanding , the problem of semantic parsing has received relatively little attention from the machine learning community .","label":"Background","metadata":{},"score":"36.354557"}{"text":"Semantic parsing is the construction of a complete , formal , symbolic meaning representation of a sentence .While it is crucial to natural language understanding , the problem of semantic parsing has received relatively little attention from the machine learning community .","label":"Background","metadata":{},"score":"36.354557"}{"text":"With better natural language semantic representations , computers can do more applications more efficiently as a result of better understanding of natural text .However , no single semantic representation at this time fulfills all requirements needed for a satisfactory representation .","label":"Background","metadata":{},"score":"36.36155"}{"text":"Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations .Finally , we show that hybridizing these two approaches results in still more accurate generation systems .Automatic and human evaluation of generated sentences are presented across two domains and four languages .","label":"Background","metadata":{},"score":"36.588753"}{"text":"Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations .Finally , we show that hybridizing these two approaches results in still more accurate generation systems .Automatic and human evaluation of generated sentences are presented across two domains and four languages .","label":"Background","metadata":{},"score":"36.588753"}{"text":"Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations .Finally , we show that hybridizing these two approaches results in still more accurate generation systems .Automatic and human evaluation of generated sentences are presented across two domains and four languages .","label":"Background","metadata":{},"score":"36.588753"}{"text":"Learning for Semantic Interpretation : Scaling Up Without Dumbing Down [ Details ] [ PDF ] Raymond J. Mooney In Workshop Notes for the Workshop on Learning Language in Logic , 7 - 15 , Bled , Slovenia , 2000 .Most recent research in learning approaches to natural language have studied fairly ' ' low - level ' ' tasks such as morphology , part - of - speech tagging , and syntactic parsing .","label":"Background","metadata":{},"score":"36.657383"}{"text":"In natural language acquisition , it is difficult to gather the annotated data needed for supervised learning ; however , unannotated data is fairly plentiful .Active learning methods ( Cohn , Atlas , & Ladner , 1994 ) attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .","label":"Background","metadata":{},"score":"36.748398"}{"text":"In natural language acquisition , it is difficult to gather the annotated data needed for supervised learning ; however , unannotated data is fairly plentiful .Active learning methods ( Cohn , Atlas , & Ladner , 1994 ) attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .","label":"Background","metadata":{},"score":"36.748398"}{"text":"For this we exploit recurrent neural networks , specifically LSTMs , which have demonstrated state - of - the - art performance in image caption generation .Our LSTM model is trained on video - sentence pairs and learns to associate a sequence of video frames to a sequence of words in order to generate a description of the event in the video clip .","label":"Background","metadata":{},"score":"36.83045"}{"text":"This schema can then be used to process narratives which were previously beyond the system 's capabilities .The thesis also discusses GENESIS ' ability to learn meanings for words related to its learned schemata and reviews several recent psychological experiments which demonstrate that GENESIS can be productively interpreted as a cognitive model of certain types of human learning .","label":"Background","metadata":{},"score":"36.84943"}{"text":"We present a method for integrating statistical and relational learning techniques for this task which exploits the strength of both approaches .Experimental results from three different domains suggest that such an approach is more robust than a previous purely logic - based approach .","label":"Background","metadata":{},"score":"36.943546"}{"text":"We present a method for integrating statistical and relational learning techniques for this task which exploits the strength of both approaches .Experimental results from three different domains suggest that such an approach is more robust than a previous purely logic - based approach .","label":"Background","metadata":{},"score":"36.943546"}{"text":"In this article , we review our recent work on using Relational Markov Networks ( RMNs ) for information extraction , the problem of identifying phrases in natural language text that refer to specific types of entities .We use the expressive power of RMNs to represent and reason about several specific relationships between candidate entities and thereby collectively identify the appropriate set of phrases to extract .","label":"Background","metadata":{},"score":"36.989777"}{"text":"We propose an approach that uses Bayesian Logic Programs ( BLPs ) , a statistical relational model combining first - order logic and Bayesian networks , to infer additional implicit information from extracted facts .It involves learning uncertain commonsense knowledge ( in the form of probabilistic first - order rules ) from natural language text by mining a large corpus of automatically extracted facts .","label":"Background","metadata":{},"score":"36.994186"}{"text":"Empirically , we show that it yields substantial improvements over previous work that used similar biases to initialize an EM - based learner .Additional gains are obtained by further shaping the prior with corpus - specific information that is extracted automatically from raw text and a tag dictionary .","label":"Background","metadata":{},"score":"37.00966"}{"text":"Here , we first develop an approach using BLPs to infer implicitly stated facts from natural language text .It involves learning uncertain common sense knowledge in the form of probabilistic first - order rules by mining a large corpus of automatically extracted facts using an existing rule learner .","label":"Background","metadata":{},"score":"37.063725"}{"text":"The same parser is used for both .In addition to the inverse Î» - calculus operators , our system uses a notion of generalization to learn semantic representation of words from the semantic representation of other words that are of the same category .","label":"Background","metadata":{},"score":"37.082397"}{"text":"For future work , I propose to extend our PCFG induction model in several ways : improving the lexicon learning algorithm , discriminative re - ranking of top - k parses , and integrating the meaning representation language ( MRL ) grammar for extra structural information .","label":"Background","metadata":{},"score":"37.106876"}{"text":"For future work , I propose to extend our PCFG induction model in several ways : improving the lexicon learning algorithm , discriminative re - ranking of top - k parses , and integrating the meaning representation language ( MRL ) grammar for extra structural information .","label":"Background","metadata":{},"score":"37.106876"}{"text":"We then describe first steps of an approach that uses this mapping to recast first - order semantics into the probabilistic models that are part of Statistical Relational AI .Specifically , we show how Discourse Representation Structures can be combined with distributional models for word meaning inside a Markov Logic Network and used to successfully perform inferences that take advantage of logical concepts such as negation and factivity as well as weighted information on word meaning in context .","label":"Background","metadata":{},"score":"37.137"}{"text":"This builds on the intuitions of Klein and Manning 's ( 2002 ) \" constituent - context \" model , which demonstrated the value of modeling context , but has the advantage of being able to exploit the properties of CCG .","label":"Background","metadata":{},"score":"37.430027"}{"text":"Hence , research in semantic parsing can be roughly divided into two tracks .Since this requires highly annotated training data and/or MRs built specifically for one domain , such approaches typically have a restricted vocab ... . \" ...This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus .","label":"Background","metadata":{},"score":"37.47743"}{"text":"Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers .Our experiments on two real - world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise .","label":"Background","metadata":{},"score":"37.497047"}{"text":"Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers .Our experiments on two real - world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise .","label":"Background","metadata":{},"score":"37.497047"}{"text":"Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers .Our experiments on two real - world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise .","label":"Background","metadata":{},"score":"37.497047"}{"text":"Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers .Our experiments on two real - world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise .","label":"Background","metadata":{},"score":"37.497047"}{"text":"Experimental results are presented that demonstrate WOLFIE 's ability to learn useful lexicons for a realistic domain .The lexicons learned by WOLFIE are also compared to those learned by another lexical acquisition system , that of Siskind ( 1996 ) .","label":"Background","metadata":{},"score":"37.647343"}{"text":"Experimental results are presented that demonstrate WOLFIE 's ability to learn useful lexicons for a realistic domain .The lexicons learned by WOLFIE are also compared to those learned by another lexical acquisition system , that of Siskind ( 1996 ) .","label":"Background","metadata":{},"score":"37.647343"}{"text":"The main innovation of the algorithm is its use of state - of - the - art statistical machine translation techniques .A statistical word alignment model is used for lexical acquisition , and the parsing model itself can be seen as an instance of a syntax - based translation model .","label":"Background","metadata":{},"score":"37.665215"}{"text":"The main innovation of the algorithm is its use of state - of - the - art statistical machine translation techniques .A statistical word alignment model is used for lexical acquisition , and the parsing model itself can be seen as an instance of a syntax - based translation model .","label":"Background","metadata":{},"score":"37.665215"}{"text":"The main innovation of the algorithm is its use of state - of - the - art statistical machine translation techniques .A statistical word alignment model is used for lexical acquisition , and the parsing model itself can be seen as an instance of a syntax - based translation model .","label":"Background","metadata":{},"score":"37.665215"}{"text":"Our approaches to this information extraction task differ in the type and the amount of supervision required .We first propose two relation extraction methods that are trained on documents in which sentences are manually annotated for the required relationships .In the first method , the extraction patterns correspond to sequences of words and word classes anchored at two entity names occurring in the same sentence .","label":"Background","metadata":{},"score":"37.808304"}{"text":"Using statistical machine translation techniques , a semantic parser based on a synchronous context - free grammar augmented with lambda - operators is learned given a set of training sentences and their correct logical forms .The resulting parser is shown to be the best - performing system so far in a database query domain .","label":"Background","metadata":{},"score":"37.81806"}{"text":"Using statistical machine translation techniques , a semantic parser based on a synchronous context - free grammar augmented with lambda - operators is learned given a set of training sentences and their correct logical forms .The resulting parser is shown to be the best - performing system so far in a database query domain .","label":"Background","metadata":{},"score":"37.81806"}{"text":"Using statistical machine translation techniques , a semantic parser based on a synchronous context - free grammar augmented with lambda - operators is learned given a set of training sentences and their correct logical forms .The resulting parser is shown to be the best - performing system so far in a database query domain .","label":"Background","metadata":{},"score":"37.81806"}{"text":"Generalizing Explanations of Narratives into Schemata [ Details ] [ PDF ] Raymond J. Mooney In Proceedings of the Third International Machine Learning Workshop , 126 - -128 , New Brunswick , New Jersey , 1985 .This paper describes a natural language system which improves its performance through learning .","label":"Background","metadata":{},"score":"37.884586"}{"text":"In particular , we draw our inspirations from the fact that humans are able to learn language through exposure to linguistic inputs in the context of a rich , relevant , perceptual environment .We first present a system that learned to sportscast for RoboCup simulation games by observing how humans commentate a game .","label":"Background","metadata":{},"score":"37.908516"}{"text":"However , it is not always possible to restrict the set of possible alignments to such limited numbers .Thus , we present another system that allows each sentence to be aligned to one of exponentially many connected subgraphs without explicitly enumerating them .","label":"Background","metadata":{},"score":"38.061584"}{"text":"In order to respond to increasing demand for natural language interfaces - and provide meaningful insight into user query intent - fast , scalable lexical semantic models with flexible representations are needed .Human concept organization is a rich epiphenomenon that has yet to be accounted for by a single coherent psychological framework : Concept generalization is captured by a mixture of prototype and exemplar models , and local taxonomic information is available through multiple overlapping organizational systems .","label":"Background","metadata":{},"score":"38.096306"}{"text":"In order to respond to increasing demand for natural language interfaces - and provide meaningful insight into user query intent - fast , scalable lexical semantic models with flexible representations are needed .Human concept organization is a rich epiphenomenon that has yet to be accounted for by a single coherent psychological framework : Concept generalization is captured by a mixture of prototype and exemplar models , and local taxonomic information is available through multiple overlapping organizational systems .","label":"Background","metadata":{},"score":"38.096306"}{"text":"We present a holistic data - driven technique that generates natural - language descriptions for videos .We combine the output of state - of - the - art object and activity detectors with ' ' real - world ' ' knowledge to select the most probable subject - verb - object triplet for describing a video .","label":"Background","metadata":{},"score":"38.097557"}{"text":"Integrating Visual and Linguistic Information to Describe Properties of Objects [ Details ] [ PDF ] Calvin MacKenzie 2014 .Undergraduate Honors Thesis , Computer Science Department , University of Texas at Austin .Generating sentences from images has historically been performed with standalone Computer Vision systems .","label":"Background","metadata":{},"score":"38.310696"}{"text":"An Inductive Logic Programming Method for Corpus - based Parser Construction [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney January 1997 .Unpublished Technical Note .Empirical methods for building natural language systems has become an important area of research in recent years .","label":"Background","metadata":{},"score":"38.40429"}{"text":"An Inductive Logic Programming Method for Corpus - based Parser Construction [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney January 1997 .Unpublished Technical Note .Empirical methods for building natural language systems has become an important area of research in recent years .","label":"Background","metadata":{},"score":"38.40429"}{"text":"A previously collected realistic corpus of complex English navigation instructions for these environments is used for training and testing data .By using a learned lexicon to refine inferred plans and a supervised learner to induce a semantic parser , the system is able to automatically learn to correctly interpret a reasonable fraction of the complex instructions in this corpus .","label":"Background","metadata":{},"score":"38.40575"}{"text":"A simple extension using transductive SVMs enables the system to do semi - supervised learning and improve its performance utilizing unannotated sentences which are usually easily available .Another extension involving EM - like retraining makes the system capable of learning under ambiguous supervision in which the correct meaning representation for each sentence is not explicitly given , but instead a set of possible meaning representations is given .","label":"Background","metadata":{},"score":"38.42697"}{"text":"A simple extension using transductive SVMs enables the system to do semi - supervised learning and improve its performance utilizing unannotated sentences which are usually easily available .Another extension involving EM - like retraining makes the system capable of learning under ambiguous supervision in which the correct meaning representation for each sentence is not explicitly given , but instead a set of possible meaning representations is given .","label":"Background","metadata":{},"score":"38.42697"}{"text":"A simple extension using transductive SVMs enables the system to do semi - supervised learning and improve its performance utilizing unannotated sentences which are usually easily available .Another extension involving EM - like retraining makes the system capable of learning under ambiguous supervision in which the correct meaning representation for each sentence is not explicitly given , but instead a set of possible meaning representations is given .","label":"Background","metadata":{},"score":"38.42697"}{"text":"The task of mining relations from collections of documents is usually approached in two different ways .One type of systems do relation extraction from individual sentences , followed by an aggregation of the results over the entire collection .Other systems follow an entirely different approach , in which co - occurrence counts are used to determine whether the mentioning together of two entities is due to more than simple chance .","label":"Background","metadata":{},"score":"38.4357"}{"text":"For a semantic parser to work well , conformity between natural language and meaning representation grammar is necessary .However meaning representation grammars are typically designed to best suit the application which will use the meaning representations with little consideration for how well they correspond to natural language semantics .","label":"Background","metadata":{},"score":"38.514954"}{"text":"For a semantic parser to work well , conformity between natural language and meaning representation grammar is necessary .However meaning representation grammars are typically designed to best suit the application which will use the meaning representations with little consideration for how well they correspond to natural language semantics .","label":"Background","metadata":{},"score":"38.514954"}{"text":"For a semantic parser to work well , conformity between natural language and meaning representation grammar is necessary .However meaning representation grammars are typically designed to best suit the application which will use the meaning representations with little consideration for how well they correspond to natural language semantics .","label":"Background","metadata":{},"score":"38.514954"}{"text":"An overview of the system is presented followed by recent experimental results on corpora of Spanish geography queries and English job - search queries .ML ID : 75 .Relational Learning of Pattern - Match Rules for Information Extraction [ Details ] [ PDF ] Mary Elaine Califf and Raymond J. Mooney In Proceedings of the ACL Workshop on Natural Language Learning , 9 - 15 , Madrid , Spain , July 1997 .","label":"Background","metadata":{},"score":"38.61475"}{"text":"An overview of the system is presented followed by recent experimental results on corpora of Spanish geography queries and English job - search queries .ML ID : 75 .Relational Learning of Pattern - Match Rules for Information Extraction [ Details ] [ PDF ] Mary Elaine Califf and Raymond J. Mooney In Proceedings of the ACL Workshop on Natural Language Learning , 9 - 15 , Madrid , Spain , July 1997 .","label":"Background","metadata":{},"score":"38.61475"}{"text":"Next , I present a PCFG induction model for grounded language learning that extends the model of Borschinger , Jones , and Johnson ( 2011 ) by utilizing a semantic lexicon .Our model overcomes such limitations by employing a semantic lexicon as the basic building block for PCFG rule generation .","label":"Background","metadata":{},"score":"38.726624"}{"text":"Next , I present a PCFG induction model for grounded language learning that extends the model of Borschinger , Jones , and Johnson ( 2011 ) by utilizing a semantic lexicon .Our model overcomes such limitations by employing a semantic lexicon as the basic building block for PCFG rule generation .","label":"Background","metadata":{},"score":"38.726624"}{"text":"We also intend to broaden the scope of application domains , for example , domains where the sentences are noisy as typical in speech , or domains where corpora available for training do not have natural language sentences aligned with their unique meaning representations .","label":"Background","metadata":{},"score":"38.779037"}{"text":"We also intend to broaden the scope of application domains , for example , domains where the sentences are noisy as typical in speech , or domains where corpora available for training do not have natural language sentences aligned with their unique meaning representations .","label":"Background","metadata":{},"score":"38.779037"}{"text":"We also intend to broaden the scope of application domains , for example , domains where the sentences are noisy as typical in speech , or domains where corpora available for training do not have natural language sentences aligned with their unique meaning representations .","label":"Background","metadata":{},"score":"38.779037"}{"text":"Unlike previous work , we model the interactions between multiple entities in a script .Experiments on a large corpus using the task of inferring held - out events ( the \" narrative cloze evaluation \" ) demonstrate that modeling multi - argument events improves predictive accuracy .","label":"Background","metadata":{},"score":"38.79407"}{"text":"The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .The learned transformation rules incrementally map a natural - language sentence or its syntactic parse tree into a parse - tree for the target formal language .","label":"Background","metadata":{},"score":"38.82019"}{"text":"The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .The learned transformation rules incrementally map a natural - language sentence or its syntactic parse tree into a parse - tree for the target formal language .","label":"Background","metadata":{},"score":"38.82019"}{"text":"The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .The learned transformation rules incrementally map a natural - language sentence or its syntactic parse tree into a parse - tree for the target formal language .","label":"Background","metadata":{},"score":"38.82019"}{"text":"ML ID : 273 . \"Grounded \" language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts .Borschinger et al .( 2011 ) introduced an approach to grounded language learning based on unsupervised PCFG induction .","label":"Background","metadata":{},"score":"38.877052"}{"text":"ML ID : 273 . \"Grounded \" language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts .Borschinger et al .( 2011 ) introduced an approach to grounded language learning based on unsupervised PCFG induction .","label":"Background","metadata":{},"score":"38.877052"}{"text":"As our parsing model we choose a deterministic shift - reduce type parser that integrates part - of - speech tagging and syntactic and semantic processing , which not only makes parsing very efficient , but also assures transparency during the supervised example acquisition .","label":"Background","metadata":{},"score":"39.150764"}{"text":"As our parsing model we choose a deterministic shift - reduce type parser that integrates part - of - speech tagging and syntactic and semantic processing , which not only makes parsing very efficient , but also assures transparency during the supervised example acquisition .","label":"Background","metadata":{},"score":"39.150764"}{"text":"Since designing an extraction system through introspection by a domain expert is a laborious and time consuming process , the focus of this thesis will be on methods that automatically induce an extraction model by training on a dataset of manually labeled examples .","label":"Background","metadata":{},"score":"39.22231"}{"text":"Context - dependent word similarity can be measured over multiple cross - cutting dimensions .Both of these notions of similarity play a role in determining word meaning , and hence lexical semantic models must take them both into account .Towards this end , we develop a novel model , Multi - View Mixture ( MVM ) , that represents words as multiple overlapping clusterings .","label":"Background","metadata":{},"score":"39.277718"}{"text":"Such approaches may raise privacy concerns and may be difficult to implement for pragmatic reasons .In this work , we present an approach to Web query disambiguation that bases its predictions only on a short glimpse of user search activity , captured in a brief session of about 5 - -6 previous searches on average .","label":"Background","metadata":{},"score":"39.431465"}{"text":"One core issue toward this goal is \" grounded \" language learning , a process of learning the semantics of natural language with respect to relevant perceptual inputs .In order to ground the meanings of language in a real world situation , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .","label":"Background","metadata":{},"score":"39.481956"}{"text":"We then develop an online rule learner that handles the concise , incomplete nature of natural - language text and learns first - order rules from noisy IE extractions .Finally , we develop a novel approach to calculate the weights of the rules using a curated lexical ontology like WordNet .","label":"Background","metadata":{},"score":"39.485073"}{"text":"The system first learns a lexicon and uses it to prune the nodes in the graph that are unrelated to the words in the sentence .By only observing how humans follow navigation instructions , the system was able to infer the corresponding hidden navigation plans and parse previously unseen instructions in new environments for both English and Chinese data .","label":"Background","metadata":{},"score":"39.611324"}{"text":"We evaluate in two ways : first , we evaluate systems ' ability to infer held - out events from documents ( the \" Narrative Cloze \" evaluation ) ; second , we evaluate novel event inferences by collecting human judgments .","label":"Background","metadata":{},"score":"39.724895"}{"text":"Although a number of exploratory EBL systems which operate in particular domains have previously been constructed , recent research in this area has lead to the development of general mechanisms which can perform explanation - based learning in a wide variety of domains .","label":"Background","metadata":{},"score":"39.764725"}{"text":"This induc - tion set - up is attractive because such annotations provide use - ful clues about the underlying syntactic structure , and they are readily available in many domains ( e.g. , info - boxes ... \" .We present a method for dependency grammar induction that utilizes sparse annotations of semantic relations .","label":"Background","metadata":{},"score":"39.83604"}{"text":"Applying machine learning techniques , the system uses parse action examples acquired under supervision to generate a deterministic shift - reduce parser in the form of a decision structure .It relies heavily on context , as encoded in features which describe the morpholgical , syntactical , semantical and other aspects of a given parse state .","label":"Background","metadata":{},"score":"40.013542"}{"text":"Applying machine learning techniques , the system uses parse action examples acquired under supervision to generate a deterministic shift - reduce parser in the form of a decision structure .It relies heavily on context , as encoded in features which describe the morpholgical , syntactical , semantical and other aspects of a given parse state .","label":"Background","metadata":{},"score":"40.013542"}{"text":"Preliminary experimental results show that this system can learn correct and useful mappings .The correctness is evaluated by comparing a known lexicon to one learned from the training input .The usefulness is evaluated by examining the effect of using the lexicon learned by WOLFIE to assist a parser acquisition system , where previously this lexicon had to be hand - built .","label":"Background","metadata":{},"score":"40.084805"}{"text":"Empirical results show that the learned parsers generalize well to novel sentences and out - perform previous approaches based on connectionist techniques .ML ID : 25 .Learning Search - Control Heuristics for Logic Programs : Applications to Speedup Learning and Language Acquisition [ Details ] [ PDF ] John M. Zelle March 1993 .","label":"Background","metadata":{},"score":"40.10523"}{"text":"Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing computing systems that understand natural language input .This thesis presents a new machine learning approach for semantic parsing based on string - kernel - based classification .","label":"Background","metadata":{},"score":"40.121597"}{"text":"Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing computing systems that understand natural language input .This thesis presents a new machine learning approach for semantic parsing based on string - kernel - based classification .","label":"Background","metadata":{},"score":"40.121597"}{"text":"Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing computing systems that understand natural language input .This thesis presents a new machine learning approach for semantic parsing based on string - kernel - based classification .","label":"Background","metadata":{},"score":"40.121597"}{"text":"In this thesis , we present several approaches for addressing this problem by employing learnable similarity functions .Given supervision in the form of similar or dissimilar pairs of instances , learnable similarity functions can be trained to provide accurate estimates for the domain and task at hand .","label":"Background","metadata":{},"score":"40.1517"}{"text":"Our system produces improved results on standard corpora on natural language interfaces for robot command and control and database queries . \" ...We present a system to translate natural language sentences to formulas in a formal or a knowledge representation language .","label":"Background","metadata":{},"score":"40.451424"}{"text":"I build on recent \" deep \" machine learning approaches to develop video description models using a unified deep neural network with both convolutional and recurrent structure .This technique treats the video domain as another \" language \" and takes a machine translation approach using the deep network to translate videos to text .","label":"Background","metadata":{},"score":"40.466606"}{"text":"Our system requires no manual labeling of video clips and needs minimal human supervision .We also present a novel caption classifier that uses additional linguistic information to determine whether a specific comment refers to an ongoing activity .We demonstrate that combining linguistic analysis and automatically trained activity recognizers can significantly improve the precision of video retrieval .","label":"Background","metadata":{},"score":"40.489174"}{"text":"We introduce tiered clustering , a mixture model capable of accounting for varying degrees of shared ( context - independent ) feature structure , and demonstrate its applicability to inferring distributed representations of word meaning .Tiered clustering can also be viewed as a form of soft feature selection , where features that do not contribute meaningfully to the clustering can be excluded .","label":"Background","metadata":{},"score":"40.51059"}{"text":"This paper presents approaches for automatically transforming a meaning representation grammar ( MRG ) to conform it better with the natural language semantics .It introduces grammar transformation operators and meaning representation macros which are applied in an error - driven manner to transform an MRG while training a semantic parser learning system .","label":"Background","metadata":{},"score":"40.601524"}{"text":"This paper presents approaches for automatically transforming a meaning representation grammar ( MRG ) to conform it better with the natural language semantics .It introduces grammar transformation operators and meaning representation macros which are applied in an error - driven manner to transform an MRG while training a semantic parser learning system .","label":"Background","metadata":{},"score":"40.601524"}{"text":"This paper presents approaches for automatically transforming a meaning representation grammar ( MRG ) to conform it better with the natural language semantics .It introduces grammar transformation operators and meaning representation macros which are applied in an error - driven manner to transform an MRG while training a semantic parser learning system .","label":"Background","metadata":{},"score":"40.601524"}{"text":"The usefulness is evaluated by examining the effect of using the lexicon learned by WOLFIE to assist a parser acquisition system , where previously this lexicon had to be hand - built .Future work in the form of extensions to the algorithm , further evaluation , and possible applications is discussed .","label":"Background","metadata":{},"score":"40.603485"}{"text":"The usefulness is evaluated by examining the effect of using the lexicon learned by WOLFIE to assist a parser acquisition system , where previously this lexicon had to be hand - built .Future work in the form of extensions to the algorithm , further evaluation , and possible applications is discussed .","label":"Background","metadata":{},"score":"40.603485"}{"text":"During the understanding process , the system constructs explanations for characters ' actions in terms of the goals they were meant to achieve .If a character achieves a common goal in a novel way , it generalizes the set of actions used to achieve this goal into a new schema .","label":"Background","metadata":{},"score":"40.625347"}{"text":"In this paper , we explored a learning approach which combines different learning methods in inductive logic programming ( ILP ) to allow a learner to produce more expressive hypothese than that of each individual learner .Such a learning approach may be useful when the performance of the task depends on solving a large amount of classification problems and each has its own characteristics which may or may not fit a particular learning method .","label":"Background","metadata":{},"score":"40.699158"}{"text":"\" We present a number of results improving the state of the art of learning statistical scripts for inferring implicit events .First , we demonstrate that incorporating multiple arguments into events , yielding a more complex event representation than is used in previous work , helps to improve a co - occurrence - based script system 's predictive power .","label":"Background","metadata":{},"score":"40.71792"}{"text":"Also as Technical Report AI07 - 345 , Artificial Intelligence Lab , University of Texas at Austin , August 2007 .Information Extraction , the task of locating textual mentions of specific types of entities and their relationships , aims at representing the information contained in text documents in a structured format that is more amenable to applications in data mining , question answering , or the semantic web .","label":"Background","metadata":{},"score":"40.75194"}{"text":"The lexicon , or the mapping from words to meanings , is one component that is typically difficult to update and that changes from one domain to the next .Therefore , automating the acquisition of the lexicon is an important task in automating the acquisition of NLP systems .","label":"Background","metadata":{},"score":"40.753506"}{"text":"By using a top - down approach to heuristically guide the construction of generalizations of a bottom clause , Beth combines the strength of both approaches .Learning patterns for detecting potential terrorist activity is a current challenge problem for relational data mining .","label":"Background","metadata":{},"score":"40.753796"}{"text":"By using a top - down approach to heuristically guide the construction of generalizations of a bottom clause , Beth combines the strength of both approaches .Learning patterns for detecting potential terrorist activity is a current challenge problem for relational data mining .","label":"Background","metadata":{},"score":"40.753796"}{"text":"Lexical semantics concerns the representation and use of word meanings in natural language processing .Our work in the area has focused on learning word meanings for use in semantic parsing and , more recently , improved distributional ( vector space ) models of word meaning .","label":"Background","metadata":{},"score":"40.830105"}{"text":"The model jointly learns representations of words , entities and MRs via a multi - task training process operating on these diverse sources of data .Hence , the system ends up providing methods for knowledge acquisition and word - sense disambiguation within the context of semantic parsing in a single elegant framework .","label":"Background","metadata":{},"score":"40.925247"}{"text":"During the understanding process , the system attempts to construct explanations for characters ' actions in terms of the goals their actions were meant to achieve .When the system observes that a character in a narrative has achieved an interesting goal in a novel way , it generalizes the set of actions they used to achieve this goal into a new schema .","label":"Background","metadata":{},"score":"40.97963"}{"text":"Experimental results are presented demonstrating WOLFIE 's ability to learn useful lexicons for a database interface in four different natural languages .The lexicons learned by WOLFIE are compared to those acquired by a competing system developed by Siskind ( 1996 ) .","label":"Background","metadata":{},"score":"41.016876"}{"text":"Experimental results are presented demonstrating WOLFIE 's ability to learn useful lexicons for a database interface in four different natural languages .The lexicons learned by WOLFIE are compared to those acquired by a competing system developed by Siskind ( 1996 ) .","label":"Background","metadata":{},"score":"41.016876"}{"text":"Experimental results are presented demonstrating WOLFIE 's ability to learn useful lexicons for a database interface in four different natural languages .The lexicons learned by WOLFIE are compared to those acquired by a competing system developed by Siskind ( 1996 ) .","label":"Background","metadata":{},"score":"41.016876"}{"text":"A second set of experiments demonstrates Wolfie 's ability to scale to larger and more difficult , albeit artificially generated , corpora .In natural language acquisition , it is difficult to gather the annotated data needed for supervised learning ; however , unannotated data is fairly plentiful .","label":"Background","metadata":{},"score":"41.03504"}{"text":"Learning Semantic Grammars With Constructive Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In Proceedings of the 11th National Conference on Artificial Intelligence , 817 - 822 , 1993 .Menlo Park , CA : AAAI Press .","label":"Background","metadata":{},"score":"41.14009"}{"text":"Cross - Cutting Models of Lexical Semantics [ Details ] [ PDF ] [ Slides ] Joseph Reisinger and Raymond Mooney In Proceedings of The Conference on Empirical Methods in Natural Language Processing ( EMNLP 2011 ) , 1405 - 1415 , July 2011 .","label":"Background","metadata":{},"score":"41.162025"}{"text":"Experimental evidence shows that CHILL performs comparably to propositional learning systems on similar tasks , and is able to go beyond the broad - but - shallow paradigm and learn mappings directly from sentences into useful semantic representations .In a complete database - query application , parsers learned by CHILL outperform an existing hand - crafted system , demonstrating the promise of empricial techniques for automating the construction certain NLP systems .","label":"Background","metadata":{},"score":"41.183784"}{"text":"Experimental evidence shows that CHILL performs comparably to propositional learning systems on similar tasks , and is able to go beyond the broad - but - shallow paradigm and learn mappings directly from sentences into useful semantic representations .In a complete database - query application , parsers learned by CHILL outperform an existing hand - crafted system , demonstrating the promise of empricial techniques for automating the construction certain NLP systems .","label":"Background","metadata":{},"score":"41.183784"}{"text":"Besides being robust , this approach is also flexible and able to learn under a wide range of supervision , from extra to weaker forms of supervision .It can easily utilize extra supervision given in the form of syntactic parse trees for natural language sentences by using a syntactic tree kernel instead of a string kernel .","label":"Background","metadata":{},"score":"41.258724"}{"text":"Besides being robust , this approach is also flexible and able to learn under a wide range of supervision , from extra to weaker forms of supervision .It can easily utilize extra supervision given in the form of syntactic parse trees for natural language sentences by using a syntactic tree kernel instead of a string kernel .","label":"Background","metadata":{},"score":"41.258724"}{"text":"Besides being robust , this approach is also flexible and able to learn under a wide range of supervision , from extra to weaker forms of supervision .It can easily utilize extra supervision given in the form of syntactic parse trees for natural language sentences by using a syntactic tree kernel instead of a string kernel .","label":"Background","metadata":{},"score":"41.258724"}{"text":"We address both problems by presenting a novel data collection framework that produces highly parallel text data relatively inexpensively and on a large scale .The highly parallel nature of this data allows us to use simple n - gram comparisons to measure both the semantic adequacy and lexical dissimilarity of paraphrase candidates .","label":"Background","metadata":{},"score":"41.28887"}{"text":"The resulting generalized combination of actions is then stored as a new schema in the system 's knowledge base .This new schema can then be used by the system to correctly process narratives which were previously beyond its capabilities .Publications : 2010 .","label":"Background","metadata":{},"score":"41.290096"}{"text":"Building natural language parsing systems by hand is a tedious , error - prone undertaking .We build on previous research in automating the construction of such systems using machine learning techniques .The result is a combined system that learns semantic lexicons and semantic parsers from one common set of training examples .","label":"Background","metadata":{},"score":"41.320175"}{"text":"Building natural language parsing systems by hand is a tedious , error - prone undertaking .We build on previous research in automating the construction of such systems using machine learning techniques .The result is a combined system that learns semantic lexicons and semantic parsers from one common set of training examples .","label":"Background","metadata":{},"score":"41.320175"}{"text":"Building natural language parsing systems by hand is a tedious , error - prone undertaking .We build on previous research in automating the construction of such systems using machine learning techniques .The result is a combined system that learns semantic lexicons and semantic parsers from one common set of training examples .","label":"Background","metadata":{},"score":"41.320175"}{"text":"Multi - Prototype Vector - Space Models of Word Meaning [ Details ] [ PDF ] [ Slides ] Joseph Reisinger , Raymond J. Mooney In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics ( NAACL-2010 ) , 109 - 117 , 2010 .","label":"Background","metadata":{},"score":"41.35611"}{"text":"Multi - Prototype Vector - Space Models of Word Meaning [ Details ] [ PDF ] [ Slides ] Joseph Reisinger , Raymond J. Mooney In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics ( NAACL-2010 ) , 109 - 117 , 2010 .","label":"Background","metadata":{},"score":"41.35611"}{"text":"Multi - Prototype Vector - Space Models of Word Meaning [ Details ] [ PDF ] [ Slides ] Joseph Reisinger , Raymond J. Mooney In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics ( NAACL-2010 ) , 109 - 117 , 2010 .","label":"Background","metadata":{},"score":"41.35611"}{"text":"Toward this goal , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .With such ambiguous supervision , it is required to resolve the ambiguity between a natural language ( NL ) sentence and a corresponding set of possible logical meaning representations ( MR ) .","label":"Background","metadata":{},"score":"41.381657"}{"text":"Toward this goal , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .With such ambiguous supervision , it is required to resolve the ambiguity between a natural language ( NL ) sentence and a corresponding set of possible logical meaning representations ( MR ) .","label":"Background","metadata":{},"score":"41.381657"}{"text":"These parsing and translation results already compare well with other systems and , given the relatively small training set and amount of overall knowledge used so far , the results suggest that our system Contex can break previous accuracy ceilings when scaled up further .","label":"Background","metadata":{},"score":"41.4492"}{"text":"These parsing and translation results already compare well with other systems and , given the relatively small training set and amount of overall knowledge used so far , the results suggest that our system Contex can break previous accuracy ceilings when scaled up further .","label":"Background","metadata":{},"score":"41.4492"}{"text":"We present a system that learns to transform natural - language navigation instructions into executable formal plans .Given no prior linguistic knowledge , the system learns by simply observing how humans follow navigation instructions .The system is evaluated in three complex virtual indoor environments with numerous objects and landmarks .","label":"Background","metadata":{},"score":"41.497707"}{"text":"However , NLP also requires integrating uncertain evidence from a variety of sources in order to resolve numerous syntactic and semantic ambiguities .Effectively integrating multiple sources of uncertain evidence has generally been considered a strength of Bayesian probabilistic methods and graphical models .","label":"Background","metadata":{},"score":"41.515472"}{"text":"This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that learns a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with representations of their meaning , and allows for both synonymy and polysemy .","label":"Background","metadata":{},"score":"41.51548"}{"text":"We have explored learning semantic parsers for mapping natural - language sentences to case - role analyses , formal database queries , and formal command languages ( i.e. the Robocup coaching language for use in advice - taking learners ) .We have also explored methods for learning semantic lexicons , i.e. databases of words or phrases paired with one or more alternative formal meaning representations .","label":"Background","metadata":{},"score":"41.53504"}{"text":"More sources can easily be added by mapping them to logical rules ; our system learns a resource - specific weight that counteract scaling differences between resources .3 ) inference , where we show how to solve the inference problems efficiently .","label":"Background","metadata":{},"score":"41.850857"}{"text":"The two models we present overcome such limitations by employing a learned semantic lexicon as a basic correspondence unit between NL and MR for PCFG rule generation .Finally , we present a method of adapting discriminative reranking to grounded language learning in order to improve the performance of our proposed generative models .","label":"Background","metadata":{},"score":"41.880917"}{"text":"Our results show that annotation of word types is the most important , provided a sufficiently capable semi - supervised learning infrastructure is in place to project type information onto a raw corpus .We also show that finite - state morphological analyzers are effective sources of type information when few labeled examples are available .","label":"Background","metadata":{},"score":"42.043327"}{"text":"We present a system to translate natural language sentences to formulas in a formal or a knowledge representation language .Our system uses two inverse Î» - calculus operators and using them can take as input the semantic representation of some words , phrases and sentences and from that derive the semantic representation of other words and phrases .","label":"Background","metadata":{},"score":"42.059326"}{"text":"One type of processing appropriate for many tasks is information extraction , a type of text skimming that retrieves specific types of information from text .Although information extraction systems have existed for two decades , these systems have generally been built by hand and contain domain specific information , making them difficult to port to other domains .","label":"Background","metadata":{},"score":"42.080956"}{"text":"Learning Language Semantics from Ambiguous Supervision [ Details ] [ PDF ] Rohit J. Kate and Raymond J. Mooney In Proceedings of the 22nd Conference on Artificial Intelligence ( AAAI-07 ) , 895 - 900 , Vancouver , Canada , July 2007 .","label":"Background","metadata":{},"score":"42.127983"}{"text":"Learning Language Semantics from Ambiguous Supervision [ Details ] [ PDF ] Rohit J. Kate and Raymond J. Mooney In Proceedings of the 22nd Conference on Artificial Intelligence ( AAAI-07 ) , 895 - 900 , Vancouver , Canada , July 2007 .","label":"Background","metadata":{},"score":"42.127983"}{"text":"Learning Language Semantics from Ambiguous Supervision [ Details ] [ PDF ] Rohit J. Kate and Raymond J. Mooney In Proceedings of the 22nd Conference on Artificial Intelligence ( AAAI-07 ) , 895 - 900 , Vancouver , Canada , July 2007 .","label":"Background","metadata":{},"score":"42.127983"}{"text":"The framework requires a minimal amount of human involvement or expertise and assumes a cost for each relocation .Several methods for taking advantage of the ability to relocate are proposed , and their effectiveness is tested in two commonly - used domains .","label":"Background","metadata":{},"score":"42.130775"}{"text":"The framework requires a minimal amount of human involvement or expertise and assumes a cost for each relocation .Several methods for taking advantage of the ability to relocate are proposed , and their effectiveness is tested in two commonly - used domains .","label":"Background","metadata":{},"score":"42.130775"}{"text":"We extend the subsequence kernel to handle this weaker form of supervision , and describe a method for weighting features in order to focus on those correlated with the target relation rather than with the individual entities .The resulting Multiple Instance Learning approach offers a competitive alternative to previous relation extraction methods , at a significantly reduced cost in human supervision .","label":"Background","metadata":{},"score":"42.174965"}{"text":"The algorithms tested include statistical , neural - network , decision - tree , rule - based , and case - based classification techniques .The specific problem tested involves disambiguating six senses of the word ' ' line ' ' using the words in the current and proceeding sentence as context .","label":"Background","metadata":{},"score":"42.392136"}{"text":"The algorithms tested include statistical , neural - network , decision - tree , rule - based , and case - based classification techniques .The specific problem tested involves disambiguating six senses of the word ' ' line ' ' using the words in the current and proceeding sentence as context .","label":"Background","metadata":{},"score":"42.392136"}{"text":"In a complete database - query application , parsers learned by CHILL outperform an existing hand - crafted system , demonstrating the promise of empricial techniques for automating the construction certain NLP systems .ML ID : 71 .Semantic Lexicon Acquisition for Learning Parsers [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney 1997 .","label":"Background","metadata":{},"score":"42.414528"}{"text":"( 3 )We provide two novel ways to extend the bimodal models to support three or more modalities .We find that the three- , four- , and five - dimensional models significantly outperform models using only one or two modalities , and that nontextual modalities each provide separate , disjoint knowledge that can not be forced into a shared , latent structure .","label":"Background","metadata":{},"score":"42.419792"}{"text":"( 3 )We provide two novel ways to extend the bimodal models to support three or more modalities .We find that the three- , four- , and five - dimensional models significantly outperform models using only one or two modalities , and that nontextual modalities each provide separate , disjoint knowledge that can not be forced into a shared , latent structure .","label":"Background","metadata":{},"score":"42.419792"}{"text":"Semantic Lexicon Acquisition for Learning Parsers [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney 1997 .Submitted for review .This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that learns a semantic lexicon from a corpus of sentences paired with representations of their meaning .","label":"Background","metadata":{},"score":"42.446514"}{"text":"I will first present a system we completed that can describe events in RoboCup 2D simulation games by learning only from sample language commentaries paired with traces of simulated activities without any language - specific prior knowledge .By applying an EM - like algorithm , the system was able to simultaneously learn a grounded language model as well as align the ambiguous training data .","label":"Background","metadata":{},"score":"42.479492"}{"text":"I will first present a system we completed that can describe events in RoboCup 2D simulation games by learning only from sample language commentaries paired with traces of simulated activities without any language - specific prior knowledge .By applying an EM - like algorithm , the system was able to simultaneously learn a grounded language model as well as align the ambiguous training data .","label":"Background","metadata":{},"score":"42.479492"}{"text":"Automatic Construction of Semantic Lexicons for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixteenth National Conference on Artificial Intelligence ( AAAI-99 ) , 487 - 493 , Orlando , FL , July 1999 .","label":"Background","metadata":{},"score":"42.50209"}{"text":"However , constructing such corpora can be expensive and time - consuming due to the expertise it requires to annotate such data .In this thesis , we explore alternative ways of learning which do not rely on direct human supervision .","label":"Background","metadata":{},"score":"42.50274"}{"text":"Submitted for review .This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that learns a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with representations of their meaning , and allows for both synonymy and polysemy .","label":"Background","metadata":{},"score":"42.58907"}{"text":"In this document , we describe our methods for learning these rules , estimating their associated weights , and performing probabilistic and logical inference to infer unseen relations .In the KBP SF task , our system was able to infer several unextracted relations , but its performance was limited by the base level extractor .","label":"Background","metadata":{},"score":"42.714836"}{"text":"Patterns for the transformation rules are learned using an induction algorithm based on longest - common - subsequences previously developed for an information extraction system .Experimental results are presented on learning to map English coaching instructions for Robocup soccer into an existing formal language for coaching simulated robotic agents .","label":"Background","metadata":{},"score":"42.768784"}{"text":"Demos of learned natural - language database interfaces : .Tutorial on semantic parsing presented at ACL 2010 : .Using natural language to write programs is a touchstone problem for computational linguistics .We present an approach that learns to map natural - language descriptions of simple \" if - then \" rules to executable code .","label":"Background","metadata":{},"score":"42.79857"}{"text":"Unlike conventional reranking used in syntactic and semantic parsing , gold - standard reference trees are not naturally available in a grounded setting .Instead , we show how the weak supervision of response feedback ( e.g. successful task completion ) can be used as an alternative , experimentally demonstrating that its performance is comparable to training on gold - standard parse trees .","label":"Background","metadata":{},"score":"42.817665"}{"text":"Unlike conventional reranking used in syntactic and semantic parsing , gold - standard reference trees are not naturally available in a grounded setting .Instead , we show how the weak supervision of response feedback ( e.g. successful task completion ) can be used as an alternative , experimentally demonstrating that its performance is comparable to training on gold - standard parse trees .","label":"Background","metadata":{},"score":"42.817665"}{"text":"Past work on learning part - of - speech taggers from tag dictionaries and raw data has reported good results , but the assumptions made about those dictionaries are often unrealistic : due to historical precedents , they assume access to information about labels in the raw and test sets .","label":"Background","metadata":{},"score":"42.823948"}{"text":"This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus .The approach is built on top of a novel reduction - based weighted synchronous context free grammar formalism , which facilitates the transformation process from typed lambda calculus into natural language sentences .","label":"Background","metadata":{},"score":"42.8292"}{"text":"Learning Transformation Rules for Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate , Yuk Wah Wong , Ruifang Ge , and Raymond J. Mooney April 2004 .Unpublished Technical Report .This paper presents an approach for inducing transformation rules that map natural - language sentences into a formal semantic representation language .","label":"Background","metadata":{},"score":"42.941265"}{"text":"The system processes short English narratives and is able to acquire , from a single narrative , a new schema for a stereotypical set of actions .During the understanding process , the system attempts to construct explanations for characters ' actions in terms of the goals their actions were meant to achieve .","label":"Background","metadata":{},"score":"42.984386"}{"text":"Comparative Experiments on Disambiguating Word Senses : An Illustration of the Role of Bias in Machine Learning [ Details ] [ PDF ] Raymond J. Mooney In Proceedings of the Conference on Empirical Methods in Natural Language Processing ( EMNLP-96 ) , 82 - 91 , Philadelphia , PA , 1996 .","label":"Background","metadata":{},"score":"42.98873"}{"text":"Publications : Advice - taking Learners .Adaptive systems learn in dynamic environments by repeatedly sensing the world , performing an action , and receiving feedback from the environment .The area of reinforcement learning concerns agents that learn sequential behaviors from experience ; however , learning in complex domains is excruciatingly slow .","label":"Background","metadata":{},"score":"43.11468"}{"text":"Next , text mining is employed to learn the correlations between these verbs and related objects .This knowledge is then used together with the outputs of an off - the - shelf object recognizer and the trained activity classifier to produce an improved activity recognizer .","label":"Background","metadata":{},"score":"43.158676"}{"text":"Experimental results with a complete database - query application for U.S. geography show that CHILL is able to learn parsers that outperform a pre - existing , hand - crafted counterpart .These results demonstrate the ability of a corpus - based system to produce more than purely syntactic representations .","label":"Background","metadata":{},"score":"43.222416"}{"text":"Experimental results with a complete database - query application for U.S. geography show that CHILL is able to learn parsers that outperform a pre - existing , hand - crafted counterpart .These results demonstrate the ability of a corpus - based system to produce more than purely syntactic representations .","label":"Background","metadata":{},"score":"43.222416"}{"text":"However , much of the information conveyed in text must be inferred from what is explicitly stated since easily inferable facts are rarely mentioned .Human readers naturally use common sense knowledge and \" read between the lines \" to infer such implicit information from the explicitly stated facts .","label":"Background","metadata":{},"score":"43.27436"}{"text":"To move beyond short video clips , I also outline models to process multi - activity movie videos , learning to jointly segment and describe coherent event sequences .I propose further extensions to take advantage of movie scripts and subtitle information to generate richer descriptions .","label":"Background","metadata":{},"score":"43.319984"}{"text":"Human evaluations of the generated commentaries indicate they are of reasonable quality compared to human commentaries .ML ID : 219 .Learning to Connect Language and Perception [ Details ] [ PDF ] Raymond J. Mooney In Proceedings of the 23rd AAAI Conference on Artificial Intelligence ( AAAI ) , 1598 - -1601 , Chicago , IL , July 2008 .","label":"Background","metadata":{},"score":"43.413044"}{"text":"Much of the information conveyed in text must be inferred from what is explicitly stated since easily inferable facts are rarely mentioned .The proposed rule learner accounts for this phenomenon by learning rules in which the body of the rule contains relations that are usually explicitly stated , while the head employs a less - frequently mentioned relation that is easily inferred .","label":"Background","metadata":{},"score":"43.56264"}{"text":"Sources of information include tag dictionaries , morphological analyzers , constituent bracketings , and partial tree annotations , as well as unannotated corpora .For example , we present algorithms that are able to combine faster - to - obtain type - level annotation with unannotated text to remove the need for slower - to - obtain token - level annotation .","label":"Background","metadata":{},"score":"43.616074"}{"text":"Although information extraction systems have existed for two decades , these systems have generally been built by hand and contain domain specific information , making them difficult to port to other domains .A few researchers have begun to apply machine learning to information extraction tasks , but most of this work has involved applying learning to pieces of a much larger system .","label":"Background","metadata":{},"score":"43.646854"}{"text":"Although information extraction systems have existed for two decades , these systems have generally been built by hand and contain domain specific information , making them difficult to port to other domains .A few researchers have begun to apply machine learning to information extraction tasks , but most of this work has involved applying learning to pieces of a much larger system .","label":"Background","metadata":{},"score":"43.646854"}{"text":"Our system takes natural language sentences paired with their formal meaning representations as training data .For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .","label":"Background","metadata":{},"score":"43.69879"}{"text":"Our system takes natural language sentences paired with their formal meaning representations as training data .For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .","label":"Background","metadata":{},"score":"43.69879"}{"text":"First - order logic provides a powerful and flexible mechanism for representing natural language semantics .However , it is an open question of how best to integrate it with uncertain , weighted knowledge , for example regarding word meaning .This paper describes a mapping between predicates of logical form and points in a vector space .","label":"Background","metadata":{},"score":"43.769455"}{"text":"Unlike previous work , our approach works on out - of - domain actions : it does not require training videos of the exact activity .If it can not find an accurate prediction for a pre - trained model , it finds a less specific answer that is also plausible from a pragmatic standpoint .","label":"Background","metadata":{},"score":"43.7797"}{"text":"Representing Meaning with a Combination of Logical Form and Vectors [ Details ] [ PDF ] Islam Beltagy and Stephen Roller and Pengxiang Cheng and Katrin Erk and Raymond J. Mooney arXiv preprint arXiv:1505.06816 [ cs .CL ] , 2015 .","label":"Background","metadata":{},"score":"43.87516"}{"text":"We have developed methods for automatically learning semantic parsers from annotated corpora using inductive logic programming and other learning methods .We have explored learning semantic parsers for mapping natural - language sentences to case - role analyses , formal database queries , and formal command languages ( i.e. the Robocup coaching language for use in advice - taking learners ) .","label":"Background","metadata":{},"score":"43.903206"}{"text":"We present a new kernel method for extracting semantic relations between entities in natural language text , based on a generalization of subsequence kernels .This kernel uses three types of subsequence patterns that are typically employed in natural language to assert relationships between two entities .","label":"Background","metadata":{},"score":"43.911293"}{"text":"This paper describes a system , Wolfie ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with semantic representations .The lexicon learned consists of words paired with meaning representations .Wolfie is part of an integrated system that learns to parse novel sentences into semantic representations , such as logical database queries .","label":"Background","metadata":{},"score":"43.999702"}{"text":"The ambiguous and synonymous nature of words causes the difficulty of using standard induction techniques to learn a lexicon .Additionally , negative examples are typically unavailable or difficult to construct in this domain .One approach to solve the lexical acquisition problem is presented , along with preliminary experimental results on an artificial corpus .","label":"Background","metadata":{},"score":"44.018265"}{"text":"The ambiguous and synonymous nature of words causes the difficulty of using standard induction techniques to learn a lexicon .Additionally , negative examples are typically unavailable or difficult to construct in this domain .One approach to solve the lexical acquisition problem is presented , along with preliminary experimental results on an artificial corpus .","label":"Background","metadata":{},"score":"44.018265"}{"text":"Human evaluations of the generated commentaries indicate they are of reasonable quality compared to human commentaries .ML ID : 219 .Transfer Learning by Mapping with Minimal Target Data [ Details ] [ PDF ] Lilyana Mihalkova and Raymond J. Mooney In Proceedings of the AAAI-08 Workshop on Transfer Learning For Complex Tasks , Chicago , IL , July 2008 .","label":"Background","metadata":{},"score":"44.054195"}{"text":"Existing hand - crafted systems can provide in - depth analysis of domain sub - languages , but are often notoriously fragile and costly to build .Existing machine - learned systems are considerably more robust , but are limited to relatively shallow NLP tasks .","label":"Background","metadata":{},"score":"44.055794"}{"text":"Existing hand - crafted systems can provide in - depth analysis of domain sub - languages , but are often notoriously fragile and costly to build .Existing machine - learned systems are considerably more robust , but are limited to relatively shallow NLP tasks .","label":"Background","metadata":{},"score":"44.055794"}{"text":"Existing hand - crafted systems can provide in - depth analysis of domain sub - languages , but are often notoriously fragile and costly to build .Existing machine - learned systems are considerably more robust , but are limited to relatively shallow NLP tasks .","label":"Background","metadata":{},"score":"44.055794"}{"text":"We show that just a small amount of annotation input - even that which can be collected in just a few hours - can provide enormous advantages if we have learning algorithms that can appropriately exploit it .This work presents new algorithms , models , and approaches designed to learn grammatical information from weak supervision .","label":"Background","metadata":{},"score":"44.113586"}{"text":"This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural - language interface for database queries .CHILL treats parser acquisition as the learning of search - control rules within a logic program representing a shift - reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge .","label":"Background","metadata":{},"score":"44.12428"}{"text":"This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural - language interface for database queries .CHILL treats parser acquisition as the learning of search - control rules within a logic program representing a shift - reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge .","label":"Background","metadata":{},"score":"44.12428"}{"text":"Using natural language to write programs is a touchstone problem for computational linguistics .We present an approach that learns to map natural - language descriptions of simple \" if - then \" rules to executable code .By training and testing on a large corpus of naturally - occurring programs ( called \" recipes \" ) and their natural language descriptions , we demonstrate the ability to effectively map language to code .","label":"Background","metadata":{},"score":"44.149002"}{"text":"We present a new method for joint entity and relation extraction using a graph we call a \" card - pyramid \" .This graph compactly encodes all possible entities and relations in a sentence , reducing the task of their joint extraction to jointly labeling its nodes .","label":"Background","metadata":{},"score":"44.174473"}{"text":"We present a new method for joint entity and relation extraction using a graph we call a \" card - pyramid \" .This graph compactly encodes all possible entities and relations in a sentence , reducing the task of their joint extraction to jointly labeling its nodes .","label":"Background","metadata":{},"score":"44.174473"}{"text":"Both of these notions of similarity play a role in determining word meaning , and hence lexical semantic models must take them both into account .Towards this end , we develop a novel model , Multi - View Mixture ( MVM ) , that represents words as multiple overlapping clusterings .","label":"Background","metadata":{},"score":"44.19153"}{"text":"A Kernel - based Approach to Learning Semantic Parsers [ Details ] [ PDF ] [ Slides ] Rohit J. Kate 2005 .Doctoral Dissertation Proposal , University of Texas at Austin .Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .","label":"Background","metadata":{},"score":"44.200226"}{"text":"However , textual variation due to typos , abbreviations , and other sources can prevent the productive discovery and utilization of hard - matching rules .Recent methods for inducing soft - matching rules from extracted data can more effectively find and exploit predictive relationships in textual data .","label":"Background","metadata":{},"score":"44.205833"}{"text":"This paper reviews our prior work on this topic and discusses directions for future research .ML ID : 196 .Extracting Relations from Text : From Word Sequences to Dependency Paths [ Details ] [ PDF ] Razvan C. Bunescu and Raymond J. Mooney In A. Kao and S. Poteet , editors , Natural Language Processing and Text Mining , 29 - 44 , Berlin , 2007 .","label":"Background","metadata":{},"score":"44.23604"}{"text":"This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with meaning representations .","label":"Background","metadata":{},"score":"44.24383"}{"text":"This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with meaning representations .","label":"Background","metadata":{},"score":"44.24383"}{"text":"This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with meaning representations .","label":"Background","metadata":{},"score":"44.24383"}{"text":"Natural language understanding ( NLU ) aims to map sen - tences to their semantic mean representations .Statistical approaches to NLU normally require fully - annotated train - ing data where each sentence is paired with its word - level semantic annotations .","label":"Background","metadata":{},"score":"44.34768"}{"text":"Other systems follow an entirely different approach , in which co - occurrence counts are used to determine whether the mentioning together of two entities is due to more than simple chance .We show that increased extraction performance can be obtained by combining the two approaches into an integrated relation extraction model .","label":"Background","metadata":{},"score":"44.398582"}{"text":"We present a system to translate natural language sentences to formulas in a formal or a knowledge representation language .Our system uses two inverse Î» - calculus operators and using them can take as input the semantic representation of some words , phrases and sentences and from that derive the sema ... \" .","label":"Background","metadata":{},"score":"44.480103"}{"text":"A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .Training the system requires sentences annotated with augmented parse trees .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .","label":"Background","metadata":{},"score":"44.49318"}{"text":"A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .Training the system requires sentences annotated with augmented parse trees .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .","label":"Background","metadata":{},"score":"44.49318"}{"text":"More precisely , an inductive logic programming ( ILP ) method , TABULATE , is developed for learning multiple models that are integrated via linear weighted combination to produce probabilistic models for statistical semantic parsing .Initial experimental results from three different domains suggest that an integration of statistical and logical approaches to semantic parsing can outperform a purely logical approach .","label":"Background","metadata":{},"score":"44.50807"}{"text":"For future work , I am proposing to solve the more complex task of learning how to give and receive navigation instructions in a virtual environment .In this setting , each instruction corresponds to a navigation plan that is not directly observable .","label":"Background","metadata":{},"score":"44.52093"}{"text":"For future work , I am proposing to solve the more complex task of learning how to give and receive navigation instructions in a virtual environment .In this setting , each instruction corresponds to a navigation plan that is not directly observable .","label":"Background","metadata":{},"score":"44.52093"}{"text":"A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .","label":"Background","metadata":{},"score":"44.572006"}{"text":"A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .","label":"Background","metadata":{},"score":"44.572006"}{"text":"A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .","label":"Background","metadata":{},"score":"44.572006"}{"text":"Lexical Acquisition : A Novel Machine Learning Problem [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Technical Report , Artificial Intelligence Lab , University of Texas at Austin , January 1996 .This paper defines a new machine learning problem to which standard machine learning algorithms can not easily be applied .","label":"Background","metadata":{},"score":"44.609226"}{"text":"Lexical Acquisition : A Novel Machine Learning Problem [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Technical Report , Artificial Intelligence Lab , University of Texas at Austin , January 1996 .This paper defines a new machine learning problem to which standard machine learning algorithms can not easily be applied .","label":"Background","metadata":{},"score":"44.609226"}{"text":"An overview of the system is presented followed by recent experimental results on corpora of Spanish geography queries and English job - search queries .ML ID : 75 .An Inductive Logic Programming Method for Corpus - based Parser Construction [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney January 1997 .","label":"Background","metadata":{},"score":"44.756897"}{"text":"Learning Language from Perceptual Context : A Challenge Problem for AI [ Details ] [ PDF ] Raymond J. Mooney In Proceedings of the 2006 AAAI Fellows Symposium , Boston , MA , July 2006 .We present the problem of learning to understand natural language from examples of utterances paired only with their relevant real - world context as an important challenge problem for AI .","label":"Background","metadata":{},"score":"44.79886"}{"text":"Encouraging results are presented on learning to extract information from computer job postings from the newsgroup misc.jobs.offered .ML ID : 74 .Learning Parse and Translation Decisions From Examples With Rich Context [ Details ] [ PDF ] Ulf Hermjakob and Raymond J. Mooney In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics ( ACL'97/EACL'97 ) , 482 - 489 , July 1997 .","label":"Background","metadata":{},"score":"44.81489"}{"text":"Encouraging results are presented on learning to extract information from computer job postings from the newsgroup misc.jobs.offered .ML ID : 74 .Learning Parse and Translation Decisions From Examples With Rich Context [ Details ] [ PDF ] Ulf Hermjakob and Raymond J. Mooney In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics ( ACL'97/EACL'97 ) , 482 - 489 , July 1997 .","label":"Background","metadata":{},"score":"44.81489"}{"text":"The lexicon learned consists of words paired with meaning representations .Wolfie is part of an integrated system that learns to parse novel sentences into semantic representations , such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .","label":"Background","metadata":{},"score":"44.837257"}{"text":"The lexicon learned consists of words paired with meaning representations .Wolfie is part of an integrated system that learns to parse novel sentences into semantic representations , such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .","label":"Background","metadata":{},"score":"44.837257"}{"text":"Our system produces improved results on standard corpora on natural language interfaces for robot command and control and database queries . \" ...Natural language understanding ( NLU ) aims to map sen - tences to their semantic mean representations .Statistical approaches to NLU normally require fully - annotated train - ing data where each sentence is paired with its word - level semantic annotations .","label":"Background","metadata":{},"score":"44.910675"}{"text":"A shallow form of semantic representation is a case - role analysis ( a.k.a . a semantic role labeling ) , which identifies roles such as agent , patient , source , and destination .A deeper semantic analysis provides a representation of the sentence in predicate logic or other formal language which supports automated reasoning .","label":"Background","metadata":{},"score":"45.093937"}{"text":"Next , we describe two PCFG induction models for grounded language learning that extend the previous grounded language learning model of Borschinger , Jones , and Johnson ( 2011 ) .Borschinger et al .'s approach works well in situations of limited ambiguity , such as in the sportscasting task .","label":"Background","metadata":{},"score":"45.107826"}{"text":"Our approach uses recent machine learning methods for inducing Prolog rules from examples ( inductive logic programming ) .We discuss several advantages of this method compared to recent statistical methods and present results on learning complete parsers from portions of the ATIS corpus .","label":"Background","metadata":{},"score":"45.27503"}{"text":"ML ID : 88 .Relational Learning of Pattern - Match Rules for Information Extraction [ Details ] [ PDF ] Mary Elaine Califf and Raymond J. Mooney In Proceedings of AAAI Spring Symposium on Applying Machine Learning to Discourse Processing , 6 - 11 , Standford , CA , March 1998 .","label":"Background","metadata":{},"score":"45.465237"}{"text":"First , we propose a number of new probabilistic script models leveraging recent advances in Neural Network training .These include recurrent sequence models with different hidden unit structure and Convolutional Neural Network models .Second , we propose integrating more lexical and linguistic information into events .","label":"Background","metadata":{},"score":"45.467453"}{"text":"Previously proposed blocking methods require manually constructing an indexbased similarity function or selecting a set of predicates , followed by hand - tuning of parameters .In this paper , we introduce an adaptive framework for automatically learning blocking functions that are efficient and accurate .","label":"Background","metadata":{},"score":"45.512672"}{"text":"While a variety of semi - supervised methods exist for training from incomplete data , there are open questions regarding what types of training data should be used and how much is necessary .We discuss a series of experiments designed to shed light on such questions in the context of part - of - speech tagging .","label":"Background","metadata":{},"score":"45.590393"}{"text":"We outperform text - only models in two different evaluations , and demonstrate that low - level visual features are directly compatible with the existing model .( 2 ) We present a novel way to integrate visual features into the LDA model using unsupervised clusters of images .","label":"Background","metadata":{},"score":"45.595673"}{"text":"We outperform text - only models in two different evaluations , and demonstrate that low - level visual features are directly compatible with the existing model .( 2 ) We present a novel way to integrate visual features into the LDA model using unsupervised clusters of images .","label":"Background","metadata":{},"score":"45.595673"}{"text":"We present a novel combination of standard activity classification , object recognition , and text mining to learn effective activity recognizers without ever explicitly labeling training videos .We cluster verbs used to describe videos to automatically discover classes of activities and produce a labeled training set .","label":"Background","metadata":{},"score":"45.600662"}{"text":"Tools . by David L. Chen , Joohyun Kim , Raymond J. Mooney - Journal of Artificial Intelligence Research , 2010 . \" ...We present a novel framework for learning to interpret and generate language using only perceptual context as supervision .","label":"Background","metadata":{},"score":"45.657234"}{"text":"Learned schemata allow GENESIS to use schema - based understanding techniques when interpreting events and thereby avoid the expensive search associated with plan - based understanding .Learned schemata also function as new concepts that can be used to cluster examples and index events in memory .","label":"Background","metadata":{},"score":"45.67884"}{"text":"Our method is based on the intuition that syntactic realizations of the same semantic predicate exhibit some degree of consistency .We incorporate this intuition in a directed graphical model that tightly links the syntactic and semantic structures .This design enables us to exploit syn - tactic regularities while still allowing for variations .","label":"Background","metadata":{},"score":"45.718803"}{"text":"To learn good parsing and translation decisions , our system relies heavily on context , as encoded in currently 205 features describing the morphological , syntactical and semantical aspects of a given parse state .Compared with recent probabilistic systems that were trained on 40,000 sentences , our system relies on more background knowledge and a deeper analysis , but radically fewer examples , currently 256 sentences .","label":"Background","metadata":{},"score":"45.854965"}{"text":"To learn good parsing and translation decisions , our system relies heavily on context , as encoded in currently 205 features describing the morphological , syntactical and semantical aspects of a given parse state .Compared with recent probabilistic systems that were trained on 40,000 sentences , our system relies on more background knowledge and a deeper analysis , but radically fewer examples , currently 256 sentences .","label":"Background","metadata":{},"score":"45.854965"}{"text":"NLP tasks differ in the semantic information they require , and at this time no single semantic representation fulfills all requirements .Logic - based representations characterize sentence structure , but do not capture the graded aspect of meaning .Distributional models give graded similarity ratings for words and phrases , but do not adequately capture overall sentence structure .","label":"Background","metadata":{},"score":"45.860092"}{"text":"We find that this hypothesis only holds when it is applied to relevant dimensions .We propose a robust supervised approach that achieves accuracies of .84 and .85 on two existing datasets and that can be interpreted as selecting the dimensions that are relevant for distributional inclusion .","label":"Background","metadata":{},"score":"45.889954"}{"text":"We find that this hypothesis only holds when it is applied to relevant dimensions .We propose a robust supervised approach that achieves accuracies of .84 and .85 on two existing datasets and that can be interpreted as selecting the dimensions that are relevant for distributional inclusion .","label":"Background","metadata":{},"score":"45.889954"}{"text":"Our research involves two complementary components : ( a ) mapping advice expressed in English to a formal advice language and ( b ) using advice expressed in a formal notation in a reinforcement learner .We use a subtask of the challenging RoboCup simulated soccer task as our testbed .","label":"Background","metadata":{},"score":"45.91243"}{"text":"ML ID : 45 .Learning Semantic Grammars With Constructive Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In Proceedings of the 11th National Conference on Artificial Intelligence , 817 - 822 , 1993 .","label":"Background","metadata":{},"score":"45.91344"}{"text":"In this proposal , we present a new approach to semantic parsing based on string - kernel - based classification .Our system takes natural language sentences paired with their formal meaning representations as training data .For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .","label":"Background","metadata":{},"score":"45.920578"}{"text":"Building accurate and efficient natural language processing ( NLP ) systems is an important and difficult problem .There has been increasing interest in automating this process .The lexicon , or the mapping from words to meanings , is one component that is typically difficult to update and that changes from one domain to the next .","label":"Background","metadata":{},"score":"45.95957"}{"text":"Building accurate and efficient natural language processing ( NLP ) systems is an important and difficult problem .There has been increasing interest in automating this process .The lexicon , or the mapping from words to meanings , is one component that is typically difficult to update and that changes from one domain to the next .","label":"Background","metadata":{},"score":"45.95957"}{"text":"We have developed a technique for learning a special type of Prolog program called a first - order decision list , defined as an ordered list of clauses each ending in a cut .FOIDL is based on FOIL ( Quinlan , 1990 ) but employs intensional background knowledge and avoids the need for explicit negative examples .","label":"Background","metadata":{},"score":"45.977448"}{"text":"The ability to understand natural - language instructions is critical to building intelligent agents that interact with humans .We present a system that learns to transform natural - language navigation instructions into executable formal plans .Given no prior linguistic knowledge , the system learns by simply observing how humans follow navigation instructions .","label":"Background","metadata":{},"score":"46.021347"}{"text":"We propose learning blocking functions automatically from linkage and semi - supervised clustering supervision , which allows automatic construction of blocking methods that are efficient and accurate .This approach yields computationally cheap learnable similarity functions that can be used for scaling up in a variety of tasks that rely on pairwise distance computations , including record linkage and clustering .","label":"Background","metadata":{},"score":"46.106834"}{"text":"We present a novel statistical approach to semantic parsing , WASP , for constructing a complete , formal meaning representation of a sentence .A semantic parser is learned given a set of sentences annotated with their correct meaning representations .The main innovation of WASP is its use of state - of - the - art statistical machine translation techniques .","label":"Background","metadata":{},"score":"46.166664"}{"text":"We present a novel statistical approach to semantic parsing , WASP , for constructing a complete , formal meaning representation of a sentence .A semantic parser is learned given a set of sentences annotated with their correct meaning representations .The main innovation of WASP is its use of state - of - the - art statistical machine translation techniques .","label":"Background","metadata":{},"score":"46.166664"}{"text":"We present a novel statistical approach to semantic parsing , WASP , for constructing a complete , formal meaning representation of a sentence .A semantic parser is learned given a set of sentences annotated with their correct meaning representations .The main innovation of WASP is its use of state - of - the - art statistical machine translation techniques .","label":"Background","metadata":{},"score":"46.166664"}{"text":"Transfer learning is a convenient framework to overcome such problems where the learning of a model specific to a domain can benefit the learning of other models in other domains through either simultaneous training of domains or sequential transfer of knowledge from one domain to the others .","label":"Background","metadata":{},"score":"46.193207"}{"text":"Currently , most state - of - the - art natural language processing ( NLP ) systems use statistical machine learning methods to extract linguistic knowledge from large , annotated corpora .However , constructing such corpora can be expensive and time - consuming due to the expertise it requires to annotate such data .","label":"Background","metadata":{},"score":"46.205227"}{"text":"Therefore , we extend BLPs to use logical abduction to construct Bayesian networks and call the resulting model Bayesian Abductive Logic Programs ( BALPs ) .In the second part of the dissertation , we apply BLPs to the task of machine reading , which involves automatic extraction of knowledge from natural language text .","label":"Background","metadata":{},"score":"46.279984"}{"text":"Such systems can be useful , but require domain - specific knowledge and rules , and are time - consuming and difficult to build by hand , making infomation extraction a good testbed for the application of machine learning techniques to natural language processing .","label":"Background","metadata":{},"score":"46.29016"}{"text":"However , in many cases , considering influences between different potential extractions could improve overall accuracy .Statistical methods based on undirected graphical models , such as conditional random fields ( CRFs ) , have been shown to be an effective approach to learning accurate IE systems .","label":"Background","metadata":{},"score":"46.39552"}{"text":"However , in many cases , considering influences between different potential extractions could improve overall accuracy .Statistical methods based on undirected graphical models , such as conditional random fields ( CRFs ) , have been shown to be an effective approach to learning accurate IE systems .","label":"Background","metadata":{},"score":"46.39552"}{"text":"Wolfie is part of an integrated system that learns to parse representations such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .The usefulness of the lexicons learned by Wolfie are compared to those acquired by a similar system developed by Siskind ( 1996 ) , with results favorable to Wolfie .","label":"Background","metadata":{},"score":"46.417133"}{"text":"Wolfie is part of an integrated system that learns to parse representations such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .The usefulness of the lexicons learned by Wolfie are compared to those acquired by a similar system developed by Siskind ( 1996 ) , with results favorable to Wolfie .","label":"Background","metadata":{},"score":"46.417133"}{"text":"The lexicon learned consists of phrases paired with meaning representations .Wolfie is part of an integrated system that learns to parse representations such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .","label":"Background","metadata":{},"score":"46.457645"}{"text":"Previous work has shown that learning sequence models for CCG tagging can be improved by using priors that are sensitive to the formal properties of CCG as well as cross - linguistic universals .We extend this approach to the task of learning a full CCG parser from weak supervision .","label":"Background","metadata":{},"score":"46.465706"}{"text":"In this paper , we show how to formulate Textual Entailment ( RTE ) inference problems in probabilistic logic in a way that takes the domain closure and closed - world assumptions into account .We evaluate our proposed technique on three RTE datasets , on a synthetic dataset with a focus on complex forms of quantification , on FraCas and on one more natural dataset .","label":"Background","metadata":{},"score":"46.506645"}{"text":"We show that our method performs overall better and faster than previous approaches in both domains .ML ID : 160 .Learning Transformation Rules for Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate , Yuk Wah Wong , Ruifang Ge , and Raymond J. Mooney April 2004 .","label":"Background","metadata":{},"score":"46.53492"}{"text":"For each of these tasks , we present learnable similarity functions and training algorithms that lead to improved performance .In record linkage , also known as duplicate detection and entity matching , the goal is to identify database records referring to the same underlying entity .","label":"Background","metadata":{},"score":"46.53746"}{"text":"Sentences and the on - the - fly ontology are represented in probabilistic logic .For inference , we use probabilistic logic frameworks like Markov Logic Networks ( MLN ) and Probabilistic Soft Logic ( PSL ) .This semantic parsing approach is evaluated on two tasks , Textual Entitlement ( RTE ) and Textual Similarity ( STS ) , both accomplished using inference in probabilistic logic .","label":"Background","metadata":{},"score":"46.54401"}{"text":"Integrating Top - down and Bottom - up Approaches in Inductive Logic Programming : Applications in Natural Language Processing and Relational Data Mining [ Details ] [ PDF ] Lappoon R. Tang PhD Thesis , Department of Computer Sciences , University of Texas , Austin , TX , August 2003 .","label":"Background","metadata":{},"score":"46.67654"}{"text":"Integrating Top - down and Bottom - up Approaches in Inductive Logic Programming : Applications in Natural Language Processing and Relational Data Mining [ Details ] [ PDF ] Lappoon R. Tang PhD Thesis , Department of Computer Sciences , University of Texas , Austin , TX , August 2003 .","label":"Background","metadata":{},"score":"46.67654"}{"text":"This proposal describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that learns a lexicon from input consisting of sentences paired with representations of their meanings .Preliminary experimental results show that this system can learn correct and useful mappings .","label":"Background","metadata":{},"score":"46.720734"}{"text":"This proposal describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that learns a lexicon from input consisting of sentences paired with representations of their meanings .Preliminary experimental results show that this system can learn correct and useful mappings .","label":"Background","metadata":{},"score":"46.720734"}{"text":"For most people , watching a brief video and describing what happened ( in words ) is an easy task .For machines , extracting the meaning from video pixels and generating a sentence description is a very complex problem .The goal of my research is to develop models that can automatically generate natural language ( NL ) descriptions for events in videos .","label":"Background","metadata":{},"score":"46.728367"}{"text":"The resulting generalized set of actions is then stored as a new schema and used by the system to process narratives which were previously beyond its capabilities .ML ID : 276 .Learning Schemata for Natural Language Processing [ Details ] [ PDF ] Raymond J. Mooney and Gerald F. DeJong In Proceedings of the Ninth International Joint Conference on Artificial Intelligence ( IJCAI-85 ) , 681 - 687 , Los Angeles , CA , August 1985 .","label":"Background","metadata":{},"score":"46.8077"}{"text":"ML ID : 126 .Bottom - Up Relational Learning of Pattern Matching Rules for Information Extraction [ Details ] [ PDF ] Mary Elaine Califf and Raymond J. Mooney Journal of Machine Learning Research : 177 - 210 , 2003 .","label":"Background","metadata":{},"score":"46.94552"}{"text":"Automating the construction of semantic grammars is a difficult and interesting problem for machine learning .This paper shows how the semantic - grammar acquisition problem can be viewed as the learning of search - control heuristics in a logic program .","label":"Background","metadata":{},"score":"46.99154"}{"text":"Unlike previous methods , our approach can annotate arbitrary videos without requiring the expensive collection and annotation of a similar training video corpus .We evaluate our technique against a baseline that does not use text - mined knowledge and show that humans prefer our descriptions 61 % of the time .","label":"Background","metadata":{},"score":"47.04407"}{"text":"Our factor graph model combines these detection confidences with probabilistic knowledge mined from text corpora to estimate the most likely subject , verb , object , and place .Results on YouTube videos show that our approach improves both the joint detection of these latent , diverse sentence components and the detection of some individual components when compared to using the vision system alone , as well as over a previous n - gram language - modeling approach .","label":"Background","metadata":{},"score":"47.09752"}{"text":"Furthermore , MVM uses soft feature assignment , hence the contribution of each data point to each clustering view is variable , isolating the impact of data only to views where they assign the most features .Through a series of experiments , we demonstrate the utility of MVM as an inductive bias for capturing relations between words that are intuitive to humans , outperforming related models such as Latent Dirichlet Allocation .","label":"Background","metadata":{},"score":"47.106155"}{"text":"Furthermore , MVM uses soft feature assignment , hence the contribution of each data point to each clustering view is variable , isolating the impact of data only to views where they assign the most features .Through a series of experiments , we demonstrate the utility of MVM as an inductive bias for capturing relations between words that are intuitive to humans , outperforming related models such as Latent Dirichlet Allocation .","label":"Background","metadata":{},"score":"47.106155"}{"text":"WOLFIE is part of an integrated system that learns to parse novel sentences into their meaning representations .Experimental results are presented that demonstrate WOLFIE 's ability to learn useful lexicons for a realistic domain .The lexicons learned by WOLFIE are also compared to those learned by another lexical acquisition system , that of Siskind ( 1996 ) .","label":"Background","metadata":{},"score":"47.13736"}{"text":"Active learning methods attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .However , existing results for active learning have only considered standard classification tasks .To reduce annotation effort while maintaining accuracy , we apply active learning to two non - classification tasks in natural language processing : semantic parsing and information extraction .","label":"Background","metadata":{},"score":"47.15829"}{"text":"Active learning methods attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .However , existing results for active learning have only considered standard classification tasks .To reduce annotation effort while maintaining accuracy , we apply active learning to two non - classification tasks in natural language processing : semantic parsing and information extraction .","label":"Background","metadata":{},"score":"47.15829"}{"text":"Large corpora of labeled videos can be used to train automated activity recognition systems , but this requires expensive human labor and time .This paper explores how closed captions that naturally accompany many videos can act as weak supervision that allows automatically collecting ' labeled ' data for activity recognition .","label":"Background","metadata":{},"score":"47.277878"}{"text":"The Inverse Entailment approach to ILP , implemented in the Progol and Aleph systems , starts with the construction of a bottom clause , the most specific hypothesis covering a seed example .When mining relational data with a large number of background facts , the bottom clause becomes intractably large , making learning very inefficient .","label":"Background","metadata":{},"score":"47.294918"}{"text":"The Inverse Entailment approach to ILP , implemented in the Progol and Aleph systems , starts with the construction of a bottom clause , the most specific hypothesis covering a seed example .When mining relational data with a large number of background facts , the bottom clause becomes intractably large , making learning very inefficient .","label":"Background","metadata":{},"score":"47.294918"}{"text":"This kernel uses three types of subsequence patterns that are typically employed in natural language to assert relationships between two entities .Experiments on extracting protein interactions from biomedical corpora and top - level relations from newspaper corpora demonstrate the advantages of this approach .","label":"Background","metadata":{},"score":"47.321075"}{"text":"We first present a system that learned to sportscast for RoboCup simulation games by observing how humans commentate a game .Using the simple assumption that people generally talk about events that have just occurred , we pair each textual comment with a set of events that it could be referring to .","label":"Background","metadata":{},"score":"47.350647"}{"text":"Such a learning approach may be useful when the performance of the task depends on solving a large amount of classification problems and each has its own characteristics which may or may not fit a particular learning method .The task of sematnic parser acquisition in two different domains was attempted and preliminary results demonstrated that such an approach is promising .","label":"Background","metadata":{},"score":"47.3812"}{"text":"CHILL is a very flexible system and has been used to learn parsers that produce syntactic parse trees , case - role analyses , and executable database queries .The reported experiments compare CHILL 's performance to that of a more naive application of ILP to parser acquisition .","label":"Background","metadata":{},"score":"47.388374"}{"text":"We also present a novel algorithm for learning which events are worth describing .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans for our limited domain .","label":"Background","metadata":{},"score":"47.448776"}{"text":"We also present a novel algorithm for learning which events are worth describing .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans for our limited domain .","label":"Background","metadata":{},"score":"47.448776"}{"text":"We also present a novel algorithm for learning which events are worth describing .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans for our limited domain .","label":"Background","metadata":{},"score":"47.448776"}{"text":"The learning algorithm incorporates techniques from several inductive logic programming systems and learns unbounded patterns that include constraints on the words and part - of - speech tags surrounding the filler .Encouraging results are presented on learning to extract information from computer job postings from the newsgroup misc.jobs.offered .","label":"Background","metadata":{},"score":"47.47329"}{"text":"The learning algorithm incorporates techniques from several inductive logic programming systems and learns unbounded patterns that include constraints on the words and part - of - speech tags surrounding the filler .Encouraging results are presented on learning to extract information from computer job postings from the newsgroup misc.jobs.offered .","label":"Background","metadata":{},"score":"47.47329"}{"text":"The learning algorithm incorporates techniques from several inductive logic programming systems and learns unbounded patterns that include constraints on the words and part - of - speech tags surrounding the filler .Encouraging results are presented on learning to extract information from computer job postings from the newsgroup misc.jobs.offered .","label":"Background","metadata":{},"score":"47.47329"}{"text":"Scripts represent knowledge of stereotypical event sequences that can aid text understanding .Initial statistical methods have been developed to learn probabilistic scripts from raw text corpora ; however , they utilize a very impoverished representation of events , consisting of a verb and one dependent argument .","label":"Background","metadata":{},"score":"47.49333"}{"text":"The paper gives a very efficient algorithm to compute it .This kernel is also an improvement over the word subsequence kernel because it only counts linguistically meaningful word subsequences which are based on word dependencies .It overcomes some of the difficulties encountered by syntactic tree kernels as well .","label":"Background","metadata":{},"score":"47.504555"}{"text":"The paper gives a very efficient algorithm to compute it .This kernel is also an improvement over the word subsequence kernel because it only counts linguistically meaningful word subsequences which are based on word dependencies .It overcomes some of the difficulties encountered by syntactic tree kernels as well .","label":"Background","metadata":{},"score":"47.504555"}{"text":"The paper gives a very efficient algorithm to compute it .This kernel is also an improvement over the word subsequence kernel because it only counts linguistically meaningful word subsequences which are based on word dependencies .It overcomes some of the difficulties encountered by syntactic tree kernels as well .","label":"Background","metadata":{},"score":"47.504555"}{"text":"Any other outputs generated by an incomplete program implicitly represent negative examples ; however , large numbers of ground negative examples never need to be generated .This method has been incorporated into two ILP systems , CHILLIN and IFOIL , both of which use intensional background knowledge .","label":"Background","metadata":{},"score":"47.54427"}{"text":"Given a few pairs of named entities known to exhibit or not exhibit a particular relation , bags of sentences containing the pairs are extracted from the web .We extend an existing relation extraction method to handle this weaker form of supervision , and present experimental results demonstrating that our approach can reliably extract relations from web documents .","label":"Background","metadata":{},"score":"47.59207"}{"text":"Generative Alignment and Semantic Parsing for Learning from Ambiguous Supervision [ Details ] [ PDF ] Joohyun Kim and Raymond J. Mooney In Proceedings of the 23rdInternational Conference on Computational Linguistics ( COLING 2010 ) , 543 - -551 , Beijing , China , August 2010 .","label":"Background","metadata":{},"score":"47.698364"}{"text":"ML ID : 285 .A Formal Approach to Linking Logical Form and Vector - Space Lexical Semantics [ Details ] [ PDF ] Dan Garrette , Katrin Erk , Raymond J. Mooney In Harry Bunt , Johan Bos , and Stephen Pulman , editors , Computing Meaning , 27 - -48 , Berlin , 2013 .","label":"Background","metadata":{},"score":"47.70631"}{"text":"International Conference on Computational Linguistics ( COLING 2010 ) , 543 - -551 , Beijing , China , August 2010 .We present a probabilistic generative model for learning semantic parsers from ambiguous supervision .Our approach learns from natural language sentences paired with world states consisting of multiple potential logical meaning representations .","label":"Background","metadata":{},"score":"47.753716"}{"text":"Human concept organization is a rich epiphenomenon that has yet to be accounted for by a single coherent psychological framework : Concept generalization is captured by a mixture of prototype and exemplar models , and local taxonomic information is available through multiple overlapping organizational systems .","label":"Background","metadata":{},"score":"47.85494"}{"text":"Unlike many current corpus - based approaches that use propositional or probabilistic learning algorithms , CHILL uses techniques from inductive logic programming ( ILP ) to learn relational representations .The reported experiments compare CHILL 's performance to that of a more naive application of ILP to parser acquisition .","label":"Background","metadata":{},"score":"47.866516"}{"text":"Unlike many current corpus - based approaches that use propositional or probabilistic learning algorithms , CHILL uses techniques from inductive logic programming ( ILP ) to learn relational representations .The reported experiments compare CHILL 's performance to that of a more naive application of ILP to parser acquisition .","label":"Background","metadata":{},"score":"47.866516"}{"text":"There are two major ILP approaches : top - down and bottom - up .The former searches the hypothesis space from general to specific while the latter the other way round .Integrating both approaches has been demonstrated to be more effective .","label":"Background","metadata":{},"score":"47.896347"}{"text":"There are two major ILP approaches : top - down and bottom - up .The former searches the hypothesis space from general to specific while the latter the other way round .Integrating both approaches has been demonstrated to be more effective .","label":"Background","metadata":{},"score":"47.896347"}{"text":"We use a variant of Robinson resolution to determine the necessary inference rules .More sources can easily be added by mapping them to logical rules ; our system learns a resource - specific weight that counteract scaling differences between resources .","label":"Background","metadata":{},"score":"47.94097"}{"text":"Generative Models of Grounded Language Learning with Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joohyun Kim Technical Report , PhD proposal , Department of Computer Science , The University of Texas at Austin , June 2012 . \"","label":"Background","metadata":{},"score":"48.001053"}{"text":"ML ID : 295 .Recent investigations into grounded models of language have shown that holistic views of language and perception can provide higher performance than independent views .In this work , we improve a two - dimensional multimodal version of Latent Dirichlet Allocation ( Andrews et al . , 2009 ) in various ways .","label":"Background","metadata":{},"score":"48.032227"}{"text":"ML ID : 165 .Learning Language from Perceptual Context : A Challenge Problem for AI [ Details ] [ PDF ] Raymond J. Mooney In Proceedings of the 2006 AAAI Fellows Symposium , Boston , MA , July 2006 .We present the problem of learning to understand natural language from examples of utterances paired only with their relevant real - world context as an important challenge problem for AI .","label":"Background","metadata":{},"score":"48.122864"}{"text":"Furthermore search queries lack explicit syntax often used to determine intent in question answering .In this paper we propose a hybrid model of semantic analysis combining explicit class - label extraction with a latent class PCFG .This class - label correlation ( CLC ) model admits a robust parallel approximation , allowing it to scale to large amounts of query data .","label":"Background","metadata":{},"score":"48.13736"}{"text":"Fine - Grained Class Label Markup of Search Queries [ Details ] [ PDF ] Joseph Reisinger and Marius Pasca In Proceedings of The 49th Annual Meeting of the Association for Computational Linguistics : Human Language Technologies ( ACL - HLT 2011 ) , 1200 - 1209 , June 2011 .","label":"Background","metadata":{},"score":"48.16531"}{"text":"Also appears as Technical Report AI 99 - 278 , Artificial Intelligence Lab , University of Texas at Austin .A long - standing goal for the field of artificial intelligence is to enable computer understanding of human languages .A core requirement in reaching this goal is the ability to transform individual sentences into a form better suited for computer manipulation .","label":"Background","metadata":{},"score":"48.211773"}{"text":"Also appears as Technical Report AI 99 - 278 , Artificial Intelligence Lab , University of Texas at Austin .A long - standing goal for the field of artificial intelligence is to enable computer understanding of human languages .A core requirement in reaching this goal is the ability to transform individual sentences into a form better suited for computer manipulation .","label":"Background","metadata":{},"score":"48.211773"}{"text":"Also appears as Technical Report AI 99 - 278 , Artificial Intelligence Lab , University of Texas at Austin .A long - standing goal for the field of artificial intelligence is to enable computer understanding of human languages .A core requirement in reaching this goal is the ability to transform individual sentences into a form better suited for computer manipulation .","label":"Background","metadata":{},"score":"48.211773"}{"text":"ML ID : 45 .Induction of First - Order Decision Lists : Results on Learning the Past Tense of English Verbs [ Details ] [ PDF ] Raymond J. Mooney and Mary Elaine Califf Journal of Artificial Intelligence Research , 3:1 - 24 , 1995 .","label":"Background","metadata":{},"score":"48.297985"}{"text":"ML ID : 95 .Relational Learning of Pattern - Match Rules for Information Extraction [ Details ] [ PDF ] Mary Elaine Califf and Raymond J. Mooney In Proceedings of the Sixteenth National Conference on Artificial Intelligence ( AAAI-99 ) , 328 - 334 , Orlando , FL , July 1999 .","label":"Background","metadata":{},"score":"48.31034"}{"text":"Information extraction ( IE ) distills structured data or knowledge from unstructured text by identifying references to named entities as well as stated relationships between such entities .IE systems can be used to directly extricate abstract knowledge from a text corpus , or to extract concrete data from a set of documents which can then be further analyzed with traditional data - mining techniques to discover more general patterns .","label":"Background","metadata":{},"score":"48.32335"}{"text":"Our approach outperforms a baseline model trained with uniform priors by exploiting universal , intrinsic properties of the CCG formalism to bias the model toward simpler , more cross - linguistically common categories .ML ID : 310 .Natural Language Semantics using Probabilistic Logic [ Details ] [ PDF ] [ Slides ] Islam Beltagy October 2014 .","label":"Background","metadata":{},"score":"48.33797"}{"text":"By learning language from perceptual context , the need for laborious annotation is removed and the system 's resulting understanding is grounded in its perceptual experience .ML ID : 192 .Association for Computational Linguistics .We present a new approach for mapping natural language sentences to their formal meaning representations using string - kernel - based classifiers .","label":"Background","metadata":{},"score":"48.37114"}{"text":"By learning language from perceptual context , the need for laborious annotation is removed and the system 's resulting understanding is grounded in its perceptual experience .ML ID : 192 .Association for Computational Linguistics .We present a new approach for mapping natural language sentences to their formal meaning representations using string - kernel - based classifiers .","label":"Background","metadata":{},"score":"48.37114"}{"text":"Existing methods for learning the logical structure of an MLN are not discriminative ; however , many relational learning problems involve specific target predicates that must be inferred from given background information .We found that existing MLN methods perform very poorly on several such ILP benchmark problems , and we present improved discriminative methods for learning MLN clauses and weights that outperform existing MLN and traditional ILP methods .","label":"Background","metadata":{},"score":"48.39778"}{"text":"In this proposal , we present a novel statistical approach to semantic parsing , WASP , which can handle meaning representations with a nested structure .The WASP algorithm learns a semantic parser given a set of sentences annotated with their correct meaning representations .","label":"Background","metadata":{},"score":"48.466255"}{"text":"In this proposal , we present a novel statistical approach to semantic parsing , WASP , which can handle meaning representations with a nested structure .The WASP algorithm learns a semantic parser given a set of sentences annotated with their correct meaning representations .","label":"Background","metadata":{},"score":"48.466255"}{"text":"In this proposal , we present a novel statistical approach to semantic parsing , WASP , which can handle meaning representations with a nested structure .The WASP algorithm learns a semantic parser given a set of sentences annotated with their correct meaning representations .","label":"Background","metadata":{},"score":"48.466255"}{"text":"Our work addresses a more ambitious task we call semantic parsing where natural language sentences are mapped to complete formal meaning representations .We present our system Scissor based on a statistical parser that generates a semantically - augmented parse tree ( SAPT ) , in which each internal node has both a syntactic and semantic label .","label":"Background","metadata":{},"score":"48.630066"}{"text":"In these experiments , SAM consistently outperforms existing models .ML ID : 248 .Joint Entity and Relation Extraction using Card - Pyramid Parsing [ Details ] [ PDF ] [ Slides ] Rohit J. Kate and Raymond J. Mooney In Proceedings of the Fourteenth Conference on Computational Natural Language Learning ( CoNLL-2010 ) , 203 - -212 , Uppsala , Sweden , July 2010 .","label":"Background","metadata":{},"score":"48.69288"}{"text":"A Mutually Beneficial Integration of Data Mining and Information Extraction [ Details ] [ PDF ] Un Yong Nahm and Raymond J. Mooney In Proceedings of the Seventeenth National Conference on Artificial Intelligence ( AAAI-00 ) , 627 - 632 , Austin , TX , July 2000 .","label":"Background","metadata":{},"score":"48.696907"}{"text":"The experimental results show that the new algorithms achieve better accuracy than existing methods .ML ID : 245 .Bayesian Abductive Logic Programs [ Details ] [ PDF ] [ Slides ] Sindhu Raghavan and Raymond Mooney In Proceedings of the AAAI-10 Workshop on Statistical Relational AI ( Star - AI 10 ) , 82 - -87 , Atlanta , GA , July 2010 .","label":"Background","metadata":{},"score":"48.719593"}{"text":"Identifying Phrasal Verbs Using Many Bilingual Corpora [ Details ] [ PDF ][Poster ] Karl Pichotta and John DeNero In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing ( EMNLP 2013 ) , 636 - -646 , Seattle , WA , October 2013 .","label":"Background","metadata":{},"score":"48.760784"}{"text":"Identifying Phrasal Verbs Using Many Bilingual Corpora [ Details ] [ PDF ][Poster ] Karl Pichotta and John DeNero In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing ( EMNLP 2013 ) , 636 - -646 , Seattle , WA , October 2013 .","label":"Background","metadata":{},"score":"48.760784"}{"text":"The generalization process is a knowledge - based analysis of the causal structure of the narrative which removes unnecessary details while maintaining the validity of the causal explanation .The resulting generalized set of actions is then stored as a new schema and used by the system to correctly process narratives which were previously beyond its capabilities .","label":"Background","metadata":{},"score":"48.770317"}{"text":"As a result , they are widely used in domains like social network analysis , biological data analysis , and natural language processing .Bayesian Logic Programs ( BLPs ) , which integrate both first - order logic and Bayesian networks are a powerful SRL formalism developed in the recent past .","label":"Background","metadata":{},"score":"48.83722"}{"text":"Therefore , the generators are said to be the inverse of the parsers , an elegant property that has been widely advocated .Furthermore , we show that our parsers and generators can handle formal meaning representation languages containing logical variables , including predicate logic .","label":"Background","metadata":{},"score":"48.9259"}{"text":"Therefore , the generators are said to be the inverse of the parsers , an elegant property that has been widely advocated .Furthermore , we show that our parsers and generators can handle formal meaning representation languages containing logical variables , including predicate logic .","label":"Background","metadata":{},"score":"48.9259"}{"text":"Therefore , the generators are said to be the inverse of the parsers , an elegant property that has been widely advocated .Furthermore , we show that our parsers and generators can handle formal meaning representation languages containing logical variables , including predicate logic .","label":"Background","metadata":{},"score":"48.9259"}{"text":"We present a new method for detecting and disambiguating named entities in open domain text .A disambiguation SVM kernel is trained to exploit the high coverage and rich structure of the knowledge encoded in an online encyclopedia .The resulting model significantly outperforms a less informed baseline .","label":"Background","metadata":{},"score":"48.964024"}{"text":"The problem occurs in the domain of lexical acquisition .The ambiguous and synonymous nature of words causes the difficulty of using standard induction techniques to learn a lexicon .Additionally , negative examples are typically unavailable or difficult to construct in this domain .","label":"Background","metadata":{},"score":"48.992405"}{"text":"In this paper we focus on the SICK dataset , and we achieve a state - of - the - art result .Our system handles overall sentence structure and phenomena like negation in the logic , then uses our Robinson resolution variant to query distributional systems about words and short phrases .","label":"Background","metadata":{},"score":"49.023365"}{"text":"Experimental results show that the number of examples needed to reach a given level of performance can be significantly reduced with this method .ML ID : 90 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixth Workshop on Very Large Corpora , Montreal , Quebec , Canada , August 1998 .","label":"Background","metadata":{},"score":"49.034435"}{"text":"Experimental results show that the number of examples needed to reach a given level of performance can be significantly reduced with this method .ML ID : 90 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixth Workshop on Very Large Corpora , Montreal , Quebec , Canada , August 1998 .","label":"Background","metadata":{},"score":"49.034435"}{"text":"Experimental results show that the number of examples needed to reach a given level of performance can be significantly reduced with this method .ML ID : 90 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixth Workshop on Very Large Corpora , Montreal , Quebec , Canada , August 1998 .","label":"Background","metadata":{},"score":"49.034435"}{"text":"We present encouraging experimental results on two domains .ML ID : 124 .Acquiring Word - Meaning Mappings for Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Journal of Artificial Intelligence Research , 18:1 - 44 , 2003 .","label":"Background","metadata":{},"score":"49.057278"}{"text":"By applying an EM - like algorithm , the system simultaneously learns a grounded language model and aligns each description to the corresponding event .The system does not use any prior language knowledge and was able to learn to sportscast in both English and Korean .","label":"Background","metadata":{},"score":"49.134995"}{"text":"A prototype language acquisition system , CHILL , is also described .It is capable of automatically acquiring semantic grammars , which uniformly incorprate syntactic and semantic constraints to parse sentences into case - role representations .Initial experiments show that this approach is able to construct accurate parsers which generalize well to novel sentences and significantly outperform previous approaches to learning case - role mapping based on connectionist techniques .","label":"Background","metadata":{},"score":"49.174564"}{"text":"For computing field - level similarity between strings , we describe two learnable variants of edit distance that lead to improvements in linkage accuracy .For learning record - level similarity functions , we employ Support Vector Machines to combine similarities of individual record fields in proportion to their relative importance , yielding a high - accuracy linkage system .","label":"Background","metadata":{},"score":"49.18568"}{"text":"Despite a recent push towards large - scale object recognition , activity recognition remains limited to narrow domains and small vocabularies of actions .In this paper , we tackle the challenge of recognizing and describing activities \" in - the - wild \" .","label":"Background","metadata":{},"score":"49.243877"}{"text":"SYNSEM also significantly improves results with limited training data , and is shown to be robust to syntactic errors .ML ID : 246 .Authorship Attribution Using Probabilistic Context - Free Grammars [ Details ] [ PDF ] [ Slides ] Sindhu Raghavan , Adriana Kovashka and Raymond Mooney In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics ( ACL-2010 ) , 38 - -42 , 2010 .","label":"Background","metadata":{},"score":"49.275608"}{"text":"Another important goal is improving the quality of final plans .Learning to improve plan quality has been examined by a few researchers , however , little research has been done learning to improve both efficiency and quality .This paper explores this problem by using the SCOPE learning system to acquire control knowledge that improves on both of these metrics .","label":"Background","metadata":{},"score":"49.453182"}{"text":"In this thesis , we focus on devising effective models for simultaneously disambiguating such supervision and learning the underlying semantics of language to map NL sentences into proper logical MRs .We present probabilistic generative models for learning such correspondences along with a reranking model to improve the performance further .","label":"Background","metadata":{},"score":"49.52091"}{"text":"( 2013 ) to handle word - level code - switching between multiple languages .Further , we enable our system to handle spelling variability , including now - obsolete shorthand systems used by printers .Our results show average relative character error reductions of 14 % across a variety of historical texts .","label":"Background","metadata":{},"score":"49.568787"}{"text":"Both simultaneous and sequential knowledge transfer are achieved through the latent variables , either by sharing these across multiple related domains ( for simultaneous learning ) or by adapting their distributions to fit data from a new domain ( for sequential learning ) .","label":"Background","metadata":{},"score":"49.59169"}{"text":"Learning to Extract Relations from the Web using Minimal Supervision [ Details ] [ PDF ] Razvan C. Bunescu and Raymond J. Mooney In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics ( ACL'07 ) , Prague , Czech Republic , June 2007 .","label":"Background","metadata":{},"score":"49.700256"}{"text":"Initially , the system will passively observe a human giving instruction to another human , and try to learn the correspondences between the instructions and the intended plan .After the system has a decent understanding of the language , it can then participate in the interactions to learn more directly by playing either the role of the instructor or the follower .","label":"Background","metadata":{},"score":"49.74491"}{"text":"Initially , the system will passively observe a human giving instruction to another human , and try to learn the correspondences between the instructions and the intended plan .After the system has a decent understanding of the language , it can then participate in the interactions to learn more directly by playing either the role of the instructor or the follower .","label":"Background","metadata":{},"score":"49.74491"}{"text":"The performance of SCISSOR is further improved by using discriminative reranking for incorporating non - local features .The second semantic parser , SYNSEM , exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .","label":"Background","metadata":{},"score":"49.89723"}{"text":"The performance of SCISSOR is further improved by using discriminative reranking for incorporating non - local features .The second semantic parser , SYNSEM , exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .","label":"Background","metadata":{},"score":"49.89723"}{"text":"The performance of SCISSOR is further improved by using discriminative reranking for incorporating non - local features .The second semantic parser , SYNSEM , exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .","label":"Background","metadata":{},"score":"49.89723"}{"text":"Arguably the most advanced approach to abduction , especially for natural language processing , is weighted abduction , which uses logical formulas with costs to guide inference .But it has no clear probabilistic semantics .In this paper we propose an approach that implements weighted abduction in Markov logic , which uses weighted first - order formulas to represent probabilistic knowledge , pointing toward a sound probabilistic semantics for weighted abduction .","label":"Background","metadata":{},"score":"49.934944"}{"text":"The method , called FOIDL , is based on FOIL but employs intensional background knowledge and avoids the need for explicit negative examples .It is particularly useful for problems that involve rules with specific exceptions , such as learning the past - tense of English verbs , a task widely studied in the context of the symbolic / connectionist debate .","label":"Background","metadata":{},"score":"49.950485"}{"text":"SYNSEM also significantly improves results with limited training data , and is shown to be robust to syntactic errors .ML ID : 246 .Training a Multilingual Sportscaster : Using Perceptual Context to Learn Language [ Details ] [ PDF ] David L. Chen , Joohyun Kim , Raymond J. Mooney Journal of Artificial Intelligence Research , 37:397 - -435 , 2010 .","label":"Background","metadata":{},"score":"49.952305"}{"text":"ML ID : 119 .Using Multiple Clause Constructors in Inductive Logic Programming for Semantic Parsing [ Details ] [ PDF ] Lappoon R. Tang and Raymond J. Mooney In Proceedings of the 12th European Conference on Machine Learning , 466 - 477 , Freiburg , Germany , 2001 .","label":"Background","metadata":{},"score":"49.966293"}{"text":"The system simultaneously establishes correspondences between individual comments and the events that they describe while building a translation model that supports both parsing and generation .We also present a novel algorithm for learning which events are worth describing .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans for our limited domain .","label":"Background","metadata":{},"score":"50.076607"}{"text":"A word alignment model is used for lexical acquisition , and the parsing model itself can be seen as a syntax - based translation model .We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision , and shows better robustness to variations in task complexity and word order .","label":"Background","metadata":{},"score":"50.133537"}{"text":"We present a Bayesian formulation for weakly - supervised learning of a Combinatory Categorial Grammar ( CCG ) supertagger with an HMM .We assume supervision in the form of a tag dictionary , and our prior encourages the use of cross - linguistically common category structures as well as transitions between tags that can combine locally according to CCG 's combinators .","label":"Background","metadata":{},"score":"50.17491"}{"text":"Transfer Learning with Markov Logic Networks [ Details ] [ PDF ] Lilyana Mihalkova and Raymond Mooney In Proceedings of the ICML-06 Workshop on Structural Knowledge Transfer for Machine Learning , Pittsburgh , PA , June 2006 .We propose a new algorithm for transfer learning of Markov Logic Network ( MLN ) structure .","label":"Background","metadata":{},"score":"50.207134"}{"text":"Understanding natural language presents many challenging problems that lend themselves to statistical relational learning ( SRL ) .Historically , both logical and probabilistic methods have found wide application in natural language processing ( NLP ) .NLP inevitably involves reasoning about an arbitrary number of entities ( people , places , and things ) that have an unbounded set of complex relationships between them .","label":"Background","metadata":{},"score":"50.214554"}{"text":"Specifically , I will present two probabilistic generative models for learning such correspondences .The models are applied to two publicly available datasets in two different domains , sportscasting and navigation , and compared with previous work on the same data .","label":"Background","metadata":{},"score":"50.21699"}{"text":"Specifically , I will present two probabilistic generative models for learning such correspondences .The models are applied to two publicly available datasets in two different domains , sportscasting and navigation , and compared with previous work on the same data .","label":"Background","metadata":{},"score":"50.21699"}{"text":"Compared to a previous generative model for semantic alignment , it also supports full semantic parsing .Experimental results on the Robocup sportscasting corpora in both English and Korean indicate that our approach produces more accurate semantic alignments than existing methods and also produces competitive semantic parsers and improved language generators .","label":"Background","metadata":{},"score":"50.430706"}{"text":"ML ID : 259 .Implementing Weighted Abduction in Markov Logic [ Details ] [ PDF ] James Blythe , Jerry R. Hobbs , Pedro Domingos , Rohit J. Kate , Raymond J. Mooney In Proceedings of the International Conference on Computational Semantics , 55 - -64 , Oxford , England , January 2011 .","label":"Background","metadata":{},"score":"50.58029"}{"text":"A new system , Wolfie , learns semantic lexicons to be used as background knowledge by a previously developed parser acquisition system , Chill .The combined system is tested on a real world domain of answering database queries .We also compare this combination to a combination of Chill with a previously developed lexicon learner , demonstrating superior performance with our system .","label":"Background","metadata":{},"score":"50.63179"}{"text":"A new system , Wolfie , learns semantic lexicons to be used as background knowledge by a previously developed parser acquisition system , Chill .The combined system is tested on a real world domain of answering database queries .We also compare this combination to a combination of Chill with a previously developed lexicon learner , demonstrating superior performance with our system .","label":"Background","metadata":{},"score":"50.63179"}{"text":"A new system , Wolfie , learns semantic lexicons to be used as background knowledge by a previously developed parser acquisition system , Chill .The combined system is tested on a real world domain of answering database queries .We also compare this combination to a combination of Chill with a previously developed lexicon learner , demonstrating superior performance with our system .","label":"Background","metadata":{},"score":"50.63179"}{"text":"In this dissertation , we demonstrate the efficacy of BLPs for inference and learning from incomplete data .Experimental comparison on various benchmark data sets on both tasks demonstrate the superior performance of BLPs over state - of - the - art methods .","label":"Background","metadata":{},"score":"50.945713"}{"text":"However , such resources are extremely costly to produce , making them an unlikely option for building NLP tools in under - resourced languages or domains .This dissertation is concerned with reducing the annotation required to learn NLP models , with the goal of opening up the range of domains and languages to which NLP technologies may be applied .","label":"Background","metadata":{},"score":"50.973457"}{"text":"The lexicons learned by Wolfie are compared to those acquired by a competing system developed by Siskind .ML ID : 95 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia Ann Thompson PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , December 1998 .","label":"Background","metadata":{},"score":"50.978462"}{"text":"The need for NLIs has become more pronounced given the widespread access to complex databases now available through the Internet .However , such systems are difficult to build and must be tailored to each application .A current research topic involves using machine learning methods to automate the development of NLI 's .","label":"Background","metadata":{},"score":"51.016815"}{"text":"Encouraging results are presented on applying these techniques to a corpus of computer job postings from an Internet newsgroup .ML ID : 100 .Integrating Statistical and Relational Learning for Semantic Parsing : Applications to Learning Natural Language Interfaces for Databases [ Details ] [ PDF ] Lappoon R. Tang May 2000 .","label":"Background","metadata":{},"score":"51.097725"}{"text":"ILP algorithms , which learn relational ( first - order ) rules , are used in a parser acquisition system called CHILL that learns rules to control the behavior of a traditional shift - reduce parser .Using this approach , CHILL is able to learn parsers for a variety of different types of analyses , from traditional syntax trees to more meaning - oriented case - role and database query forms .","label":"Background","metadata":{},"score":"51.185772"}{"text":"This paper outlines an alternative empirical approach based on techniques from a subfield of machine learning known as Inductive Logic Programming ( ILP ) .ILP algorithms , which learn relational ( first - order ) rules , are used in a parser acquisition system called CHILL that learns rules to control the behavior of a traditional shift - reduce parser .","label":"Background","metadata":{},"score":"51.209385"}{"text":"This paper outlines an alternative empirical approach based on techniques from a subfield of machine learning known as Inductive Logic Programming ( ILP ) .ILP algorithms , which learn relational ( first - order ) rules , are used in a parser acquisition system called CHILL that learns rules to control the behavior of a traditional shift - reduce parser .","label":"Background","metadata":{},"score":"51.209385"}{"text":"All of these tasks are accomplished within the same framework , using a single , general learning method that can acquire new syntactic and semantic categories for resolving ambiguities .Experimental evidence from both aritificial and real - world corpora demonstrate that CHILL learns parsers as well or better than previous artificial neural network or probablistic approaches on comparable tasks .","label":"Background","metadata":{},"score":"51.23514"}{"text":"All of these tasks are accomplished within the same framework , using a single , general learning method that can acquire new syntactic and semantic categories for resolving ambiguities .Experimental evidence from both aritificial and real - world corpora demonstrate that CHILL learns parsers as well or better than previous artificial neural network or probablistic approaches on comparable tasks .","label":"Background","metadata":{},"score":"51.23514"}{"text":"We present encouraging experimental results on two domains .ML ID : 94 .Active Learning for Natural Language Parsing and Information Extraction [ Details ] [ PDF ] Cynthia A. Thompson , Mary Elaine Califf and Raymond J. Mooney In Proceedings of the Sixteenth International Conference on Machine Learning ( ICML-99 ) , 406 - 414 , Bled , Slovenia , June 1999 .","label":"Background","metadata":{},"score":"51.502205"}{"text":"Search Query Disambiguation from Short Sessions [ Details ] [ PDF ] Lilyana Mihalkova and Raymond Mooney In Beyond Search : Computational Intelligence for the Web Workshop at NIPS , 2008 .Web searches tend to be short and ambiguous .It is therefore not surprising that Web query disambiguation is an actively researched topic .","label":"Background","metadata":{},"score":"51.514584"}{"text":"The parsing of unrestricted text , with its enormous lexical and structural ambiguity , still poses a great challenge in natural language processing .The difficulties with traditional approaches , which try to master the complexity of parse grammars with hand - crafted rules , have led to a trend towards more empirical techniques .","label":"Background","metadata":{},"score":"51.590584"}{"text":"The parsing of unrestricted text , with its enormous lexical and structural ambiguity , still poses a great challenge in natural language processing .The difficulties with traditional approaches , which try to master the complexity of parse grammars with hand - crafted rules , have led to a trend towards more empirical techniques .","label":"Background","metadata":{},"score":"51.590584"}{"text":"Integrating Statistical and Relational Learning for Semantic Parsing : Applications to Learning Natural Language Interfaces for Databases [ Details ] [ PDF ] Lappoon R. Tang May 2000 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .","label":"Background","metadata":{},"score":"51.73075"}{"text":"ML ID : 56 .Acquisition of a Lexicon from Semantic Representations of Sentences [ Details ] [ PDF ] Cynthia A. Thompson In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics ( ACL-95 ) , 335 - 337 , Cambridge , MA , 1995 .","label":"Background","metadata":{},"score":"51.735283"}{"text":"Text Analysis Conference conducts English Slot Filling ( ESF ) and Slot Filler Validation ( SFV ) tasks as part of its KBP track to promote research in this area .Slot Filling systems are developed to do relation extraction for specific relation and entity types .","label":"Background","metadata":{},"score":"51.837025"}{"text":"ML ID : 269 .Learning to Interpret Natural Language Navigation Instructions from Observations [ Details ] [ PDF ] [ Slides ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th AAAI Conference on Artificial Intelligence ( AAAI-2011 ) , 859 - 865 , August 2011 .","label":"Background","metadata":{},"score":"51.8607"}{"text":"ML ID : 254 .Integrating Logical Representations with Probabilistic Information using Markov Logic [ Details ] [ PDF ] [ Slides ] Dan Garrette , Katrin Erk , Raymond Mooney In Proceedings of the International Conference on Computational Semantics , 105 - -114 , Oxford , England , January 2011 .","label":"Background","metadata":{},"score":"51.90798"}{"text":"We demonstrate that our stacking approach outperforms the best system from the 2014 KBP - ESF competition as well as alternative ensembling methods employed in the 2014 KBP Slot Filler Validation task and several other ensembling baselines .Additionally , we demonstrate that including provenance information further increases the performance of stacking .","label":"Background","metadata":{},"score":"51.96824"}{"text":"To classify images , our method learns from captioned images of natural scenes ; and to recognize human actions , it learns from videos of athletic events with commentary .We show that by exploiting both multi - modal representations and unlabeled data our approach learns more accurate image and video classifiers than standard baseline algorithms .","label":"Background","metadata":{},"score":"52.065197"}{"text":"Semantic lexicons can also be learned from semantically annotated sentences and are an important source of knowledge for semantic parsing .Learning for semantic parsing is part of our research on natural language learning .\" The fish trap exists because of the fish .","label":"Background","metadata":{},"score":"52.240654"}{"text":"Experimental results show that the resulting system is able to cope up with ambiguities and learn accurate semantic parsers .ML ID : 200 .Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus [ Details ] [ PDF ] Yuk Wah Wong and Raymond J. Mooney In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics ( ACL-2007 ) , Prague , Czech Republic , June 2007 .","label":"Background","metadata":{},"score":"52.26374"}{"text":"Experimental results show that the resulting system is able to cope up with ambiguities and learn accurate semantic parsers .ML ID : 200 .Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus [ Details ] [ PDF ] Yuk Wah Wong and Raymond J. Mooney In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics ( ACL-2007 ) , Prague , Czech Republic , June 2007 .","label":"Background","metadata":{},"score":"52.26374"}{"text":"Experimental results show that the resulting system is able to cope up with ambiguities and learn accurate semantic parsers .ML ID : 200 .Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus [ Details ] [ PDF ] Yuk Wah Wong and Raymond J. Mooney In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics ( ACL-2007 ) , Prague , Czech Republic , June 2007 .","label":"Background","metadata":{},"score":"52.26374"}{"text":"For the sportscasting task , while each comment could be aligned to one of several events , the level of ambiguity was low enough that we could enumerate all the possible alignments .However , it is not always possible to restrict the set of possible alignments to such limited numbers .","label":"Background","metadata":{},"score":"52.30019"}{"text":"Inducing Grammars from Linguistic Universals and Realistic Amounts of Supervision [ Details ] [ PDF ] Dan Garrette PhD Thesis , Department of Computer Science , The University of Texas at Austin , 2015 .The best performing NLP models to date are learned from large volumes of manually - annotated data .","label":"Background","metadata":{},"score":"52.3689"}{"text":"While crowdsourcing offers a cheap alternative , quality control and scalability can become problematic .We discuss a novel annotation task that uses videos as the stimulus which discourages cheating .In addi- tion , our approach requires only monolingual speakers , thus making it easier to scale since more workers are qualified to contribute .","label":"Background","metadata":{},"score":"52.446075"}{"text":"Experimental results are presented on learning to map English coaching instructions for Robocup soccer into an existing formal language for coaching simulated robotic agents .ML ID : 140 .Learning Semantic Parsers : An Important But Under - Studied Problem [ Details ] [ PDF ] Raymond J. Mooney In Papers from the AAAI 2004 Spring Symposium on Language Learning : An Interdisciplinary Perspective , 39 - -44 , Stanford , CA , March 2004 .","label":"Background","metadata":{},"score":"52.649986"}{"text":"Experimental results are presented on learning to map English coaching instructions for Robocup soccer into an existing formal language for coaching simulated robotic agents .ML ID : 140 .Learning Semantic Parsers : An Important But Under - Studied Problem [ Details ] [ PDF ] Raymond J. Mooney In Papers from the AAAI 2004 Spring Symposium on Language Learning : An Interdisciplinary Perspective , 39 - -44 , Stanford , CA , March 2004 .","label":"Background","metadata":{},"score":"52.649986"}{"text":"ML ID : 164 .Learning to Transform Natural to Formal Languages [ Details ] [ PDF ] [ Slides ] Rohit J. Kate , Yuk Wah Wong and Raymond J. Mooney In Proceedings of the Twentieth National Conference on Artificial Intelligence ( AAAI-05 ) , 1062 - 1068 , Pittsburgh , PA , July 2005 .","label":"Background","metadata":{},"score":"52.680603"}{"text":"ML ID : 130 .Acquiring Word - Meaning Mappings for Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Journal of Artificial Intelligence Research , 18:1 - 44 , 2003 .This paper focuses on a system , Wolfie ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with semantic representations .","label":"Background","metadata":{},"score":"52.681076"}{"text":"Several real world tasks involve data that is uncertain and relational in nature .Traditional approaches like first - order logic and probabilistic models either deal with structured data or uncertainty , but not both .To address these limitations , statistical relational learning ( SRL ) , a new area in machine learning integrating both first - order logic and probabilistic graphical models , has emerged in the recent past .","label":"Background","metadata":{},"score":"52.758656"}{"text":"Instead , we use distributional semantics to generate only the relevant part of an on - the - fly ontology .Sentences and the on - the - fly ontology are represented in probabilistic logic .For inference , we use probabilistic logic frameworks like Markov Logic Networks ( MLN ) and Probabilistic Soft Logic ( PSL ) .","label":"Background","metadata":{},"score":"52.847565"}{"text":"This allows for ' ' collective information extraction ' ' that exploits the mutual influence between possible extractions .Experiments on learning to extract protein names from biomedical text demonstrate the advantages of this approach .ML ID : 145 .Learning Transformation Rules for Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate , Yuk Wah Wong , Ruifang Ge , and Raymond J. Mooney April 2004 .","label":"Background","metadata":{},"score":"52.855225"}{"text":"Explanation - based learning ( EBL ) is a learning method which uses existing knowledge of the domain to construct an explanation for why a specific example is a member of a concept or why a specific combination of actions achieves a goal .","label":"Background","metadata":{},"score":"52.865738"}{"text":"ML ID : 47 .Acquisition of a Lexicon from Semantic Representations of Sentences [ Details ] [ PDF ] Cynthia A. Thompson In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics ( ACL-95 ) , 335 - 337 , Cambridge , MA , 1995 .","label":"Background","metadata":{},"score":"52.869232"}{"text":"ML ID : 47 .Acquisition of a Lexicon from Semantic Representations of Sentences [ Details ] [ PDF ] Cynthia A. Thompson In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics ( ACL-95 ) , 335 - 337 , Cambridge , MA , 1995 .","label":"Background","metadata":{},"score":"52.869232"}{"text":"Learning Language from Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen December 2009 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .Most current natural language processing ( NLP ) systems are built using statistical learning algorithms trained on large annotated corpora which can be expensive and time - consuming to collect .","label":"Background","metadata":{},"score":"52.89942"}{"text":"Learning Language from Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen December 2009 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .Most current natural language processing ( NLP ) systems are built using statistical learning algorithms trained on large annotated corpora which can be expensive and time - consuming to collect .","label":"Background","metadata":{},"score":"52.89942"}{"text":"For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .","label":"Background","metadata":{},"score":"52.939903"}{"text":"For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .","label":"Background","metadata":{},"score":"52.939903"}{"text":"For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .","label":"Background","metadata":{},"score":"52.939903"}{"text":"ML ID : 66 .Comparative Experiments on Disambiguating Word Senses : An Illustration of the Role of Bias in Machine Learning [ Details ] [ PDF ] Raymond J. Mooney In Proceedings of the Conference on Empirical Methods in Natural Language Processing ( EMNLP-96 ) , 82 - 91 , Philadelphia , PA , 1996 .","label":"Background","metadata":{},"score":"53.29458"}{"text":"GENESIS processes short English narratives and constructs explanations for characters ' intentional behavior .When the system detects that a character has achieved an important goal by combining actions in an unfamiliar way , EGGS is used to generalize the specific explanation for how the goal was achieved into a general plan schema .","label":"Background","metadata":{},"score":"53.30797"}{"text":"Scripts encode knowledge of prototypical sequences of events .We describe a Recurrent Neural Network model for statistical script learning using Long Short - Term Memory , an architecture which has been demonstrated to work well on a range of Artificial Intelligence tasks .","label":"Background","metadata":{},"score":"53.354828"}{"text":"The ATIS corpus of airline information queries was used to test the acquisition of syntactic parsers , and CHILL performed competitively with recent statistical methods .English queries to a small database on U.S. geography were used to test the acquisition of a complete natural language interface , and the parser that CHILL acquired was more accurate than an existing hand - coded system .","label":"Background","metadata":{},"score":"53.37673"}{"text":"The ATIS corpus of airline information queries was used to test the acquisition of syntactic parsers , and CHILL performed competitively with recent statistical methods .English queries to a small database on U.S. geography were used to test the acquisition of a complete natural language interface , and the parser that CHILL acquired was more accurate than an existing hand - coded system .","label":"Background","metadata":{},"score":"53.37673"}{"text":"Discriminative Reranking for Semantic Parsing [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ( COLING / ACL-06 ) , Sydney , Australia , July 2006 .","label":"Background","metadata":{},"score":"53.434814"}{"text":"Discriminative Reranking for Semantic Parsing [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ( COLING / ACL-06 ) , Sydney , Australia , July 2006 .","label":"Background","metadata":{},"score":"53.434814"}{"text":"Discriminative Reranking for Semantic Parsing [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ( COLING / ACL-06 ) , Sydney , Australia , July 2006 .","label":"Background","metadata":{},"score":"53.434814"}{"text":"Discriminative Reranking for Semantic Parsing [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ( COLING / ACL-06 ) , Sydney , Australia , July 2006 .","label":"Background","metadata":{},"score":"53.434814"}{"text":"Experiments show the potential of the approach .ML ID : 301 .Grounded Language Learning Models for Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joo Hyun Kim PhD Thesis , Department of Computer Science , University of Texas at Austin , December 2013 .","label":"Background","metadata":{},"score":"53.445427"}{"text":"We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .We present experimental results demonstrating that Scissor produces more accurate semantic representations than several previous approaches on long sentences .","label":"Background","metadata":{},"score":"53.527718"}{"text":"Learning for Semantic Parsing [ Details ] [ PDF ] Raymond J. Mooney In A. Gelbukh , editors , Computational Linguistics and Intelligent Text Processing : Proceedings of the 8th International Conference ( CICLing 2007 ) , 311 - -324 , Mexico City , Mexico , February 2007 .","label":"Background","metadata":{},"score":"53.556503"}{"text":"Learning for Semantic Parsing [ Details ] [ PDF ] Raymond J. Mooney In A. Gelbukh , editors , Computational Linguistics and Intelligent Text Processing : Proceedings of the 8th International Conference ( CICLing 2007 ) , 311 - -324 , Mexico City , Mexico , February 2007 .","label":"Background","metadata":{},"score":"53.556503"}{"text":"Learning for Semantic Parsing [ Details ] [ PDF ] Raymond J. Mooney In A. Gelbukh , editors , Computational Linguistics and Intelligent Text Processing : Proceedings of the 8th International Conference ( CICLing 2007 ) , 311 - -324 , Mexico City , Mexico , February 2007 .","label":"Background","metadata":{},"score":"53.556503"}{"text":"RAPIER takes pairs of documents and filled templates indicating the information to be extracted and learns patterns to extract fillers for the slots in the template .This proposal presents initial results on a small corpus of computer - related job postings with a preliminary version of RAPIER .","label":"Background","metadata":{},"score":"53.605556"}{"text":"RAPIER takes pairs of documents and filled templates indicating the information to be extracted and learns patterns to extract fillers for the slots in the template .This proposal presents initial results on a small corpus of computer - related job postings with a preliminary version of RAPIER .","label":"Background","metadata":{},"score":"53.605556"}{"text":"By only observing how humans follow navigation instructions , the system was able to infer the corresponding hidden navigation plans and parse previously unseen instructions in new environments for both English and Chinese data .With the rise in popularity of crowdsourcing , we also present results on collecting additional training data using Amazon 's Mechanical Turk .","label":"Background","metadata":{},"score":"53.612892"}{"text":"Future work includes extending the algorithm and performing tests on a more realistic corpus .ML ID : 56 .Using Inductive Logic Programming to Automate the Construction of Natural Language Parsers [ Details ] [ PDF ] John M. Zelle PhD Thesis , Department of Computer Sciences , The University of Texas at Austin , Austin , TX , 1995 .","label":"Background","metadata":{},"score":"53.640587"}{"text":"We also discuss the role of bias in machine learning and its importance in explaining performance differences observed on specific problems .ML ID : 62 .Corpus - Based Lexical Acquisition For Semantic Parsing [ Details ] [ PDF ] Cynthia Thompson February 1996 .","label":"Background","metadata":{},"score":"53.688644"}{"text":"We also discuss the role of bias in machine learning and its importance in explaining performance differences observed on specific problems .ML ID : 62 .Corpus - Based Lexical Acquisition For Semantic Parsing [ Details ] [ PDF ] Cynthia Thompson February 1996 .","label":"Background","metadata":{},"score":"53.688644"}{"text":"Using real Internet traces and synthetic polymorphic worms , we evaluated the performance of several advanced machine learning algorithms , including naive Bayes , decision - tree induction , rule learning ( RIPPER ) , and support vector machines .The results are very promising .","label":"Background","metadata":{},"score":"53.7237"}{"text":"We focus on textual entailment ( RTE ) , a task that can utilize the strengths of both representations .Our system is three components , 1 ) parsing and task representation , where input RTE problems are represented in probabilistic logic .","label":"Background","metadata":{},"score":"53.748524"}{"text":"ML ID : 218 .Learning to Connect Language and Perception [ Details ] [ PDF ] Raymond J. Mooney In Proceedings of the 23rd AAAI Conference on Artificial Intelligence ( AAAI ) , 1598 - -1601 , Chicago , IL , July 2008 .","label":"Background","metadata":{},"score":"53.807068"}{"text":"SYNSEM also significantly improves results with limited training data , and is shown to be robust to syntactic errors .ML ID : 246 .Online Max - Margin Weight Learning with Markov Logic Networks [ Details ] [ PDF ] [ Slides ] Tuyen N. Huynh and Raymond J. Mooney In Proceedings of the AAAI-10 Workshop on Statistical Relational AI ( Star - AI 10 ) , 32 - -37 , Atlanta , GA , July 2010 .","label":"Background","metadata":{},"score":"53.83779"}{"text":"ML ID : 180 .We present a novel approach to relation extraction , based on the observation that the information required to assert a relationship between two named entities in the same sentence is typically captured by the shortest path between the two entities in the dependency graph .","label":"Background","metadata":{},"score":"53.839867"}{"text":"Using Closed Captions as Supervision for Video Activity Recognition [ Details ] [ PDF ] Sonal Gupta , Raymond J. Mooney In Proceedings of the Twenty - Fourth AAAI Conference on Artificial Intelligence ( AAAI-2010 ) , 1083 - -1088 , Atlanta , GA , July 2010 .","label":"Background","metadata":{},"score":"53.845245"}{"text":"Our system uses two inverse Î» - calculus operators and using them can take as input the semantic representation of some words , phrases and sentences and from that derive the semantic representation of other words and phrases .Our inverse Î» operator works on many formal languages including first order logic , database query languages and answer set programming .","label":"Background","metadata":{},"score":"53.91517"}{"text":"ML ID : 68 .Learning to Parse Database Queries using Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In AAAI / IAAI , 1050 - 1055 , Portland , OR , August 1996 .","label":"Background","metadata":{},"score":"54.119637"}{"text":"ML ID : 68 .Learning to Parse Database Queries using Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In AAAI / IAAI , 1050 - 1055 , Portland , OR , August 1996 .","label":"Background","metadata":{},"score":"54.119637"}{"text":"University of Texas at Austin KBP 2013 Slot Filling System : Bayesian Logic Programs for Textual Inference [ Details ] [ PDF ] Yinon Bentor and Amelia Harrison and Shruti Bhosale and Raymond Mooney In Proceedings of the Sixth Text Analysis Conference ( TAC 2013 ) , 2013 .","label":"Background","metadata":{},"score":"54.131557"}{"text":"ML ID : 252 .Generative Alignment and Semantic Parsing for Learning from Ambiguous Supervision [ Details ] [ PDF ] Joohyun Kim and Raymond J. Mooney In Proceedings of the 23rdInternational Conference on Computational Linguistics ( COLING 2010 ) , 543 - -551 , Beijing , China , August 2010 .","label":"Background","metadata":{},"score":"54.21228"}{"text":"In this thesis , we investigate the use of ensemble learning to combine the output of existing individual Slot Filling systems .We are the first to employ Stacking , a type of ensemble learning algorithm for the task of ensembling Slot Filling systems for the KBP ESF and SFV tasks .","label":"Background","metadata":{},"score":"54.336487"}{"text":"We report experimental results on two real applications , an interpreter for coaching instructions in robotic soccer and a natural - language database interface .The results show that reranking can improve the performance on the coaching interpreter , but not on the database interface .","label":"Background","metadata":{},"score":"54.457596"}{"text":"We report experimental results on two real applications , an interpreter for coaching instructions in robotic soccer and a natural - language database interface .The results show that reranking can improve the performance on the coaching interpreter , but not on the database interface .","label":"Background","metadata":{},"score":"54.457596"}{"text":"We report experimental results on two real applications , an interpreter for coaching instructions in robotic soccer and a natural - language database interface .The results show that reranking can improve the performance on the coaching interpreter , but not on the database interface .","label":"Background","metadata":{},"score":"54.457596"}{"text":"We report experimental results on two real applications , an interpreter for coaching instructions in robotic soccer and a natural - language database interface .The results show that reranking can improve the performance on the coaching interpreter , but not on the database interface .","label":"Background","metadata":{},"score":"54.457596"}{"text":"Control rules are induced using a novel ILP algorithm which handles difficult issues arising in the induction of search - control heuristics .Both the control - rule framework and the induction algorithm are crucial to CHILL 's success .The main advantage of CHILL over propositional counterparts is its flexibility in handling varied representations .","label":"Background","metadata":{},"score":"54.511734"}{"text":"Control rules are induced using a novel ILP algorithm which handles difficult issues arising in the induction of search - control heuristics .Both the control - rule framework and the induction algorithm are crucial to CHILL 's success .The main advantage of CHILL over propositional counterparts is its flexibility in handling varied representations .","label":"Background","metadata":{},"score":"54.511734"}{"text":"Training the system requires sentences annotated with augmented parse trees .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .We present experimental results demonstrating that Scissor produces more accurate semantic representations than several previous approaches on long sentences .","label":"Background","metadata":{},"score":"54.567463"}{"text":"Real - World Semi - Supervised Learning of POS - Taggers for Low - Resource Languages [ Details ] [ PDF ] Dan Garrette and Jason Mielens and Jason Baldridge In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL-2013 ) , 583 - -592 , Sofia , Bulgaria , August 2013 .","label":"Background","metadata":{},"score":"54.616726"}{"text":"ML ID : 241 .Acquiring Word - Meaning Mappings for Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Journal of Artificial Intelligence Research , 18:1 - 44 , 2003 .This paper focuses on a system , Wolfie ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with semantic representations .","label":"Background","metadata":{},"score":"54.69982"}{"text":"ML ID : 78 .Learning to Improve both Efficiency and Quality of Planning [ Details ] [ PDF ] Tara A. Estlin and Raymond J. Mooney In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence ( IJCAI-97 ) , 1227 - 1232 , Nagoya , Japan , 1997 .","label":"Background","metadata":{},"score":"54.985046"}{"text":"Pairwise similarity computations are particularly important in record linkage systems , as well as in clustering and schema mapping algorithms .Because the number of object pairs grows quadratically with the size of the dataset , computing similarity between all pairs is impractical and becomes prohibitive for large datasets and complex similarity functions .","label":"Background","metadata":{},"score":"54.99383"}{"text":"Subsequence Kernels for Relation Extraction [ Details ] [ PDF ] Razvan Bunescu and Raymond J. Mooney In Y. Weiss , B. Schoelkopf , J. Platt , editors , Advances in Neural Information Processing Systems , Vol .18 : Proceedings of the 2005 Conference ( NIPS ) , 2006 .","label":"Background","metadata":{},"score":"55.039917"}{"text":"ML ID : 66 .Corpus - Based Lexical Acquisition For Semantic Parsing [ Details ] [ PDF ] Cynthia Thompson February 1996 .Ph.D. proposal .Building accurate and efficient natural language processing ( NLP ) systems is an important and difficult problem .","label":"Background","metadata":{},"score":"55.095924"}{"text":"Training data consists of natural language sentences annotated with multiple potential meaning representations , only one of which is correct .Such ambiguous supervision models the type of supervision that can be more naturally available to language - learning systems .Given such weak supervision , our approach produces a semantic parser that maps sentences into meaning representations .","label":"Background","metadata":{},"score":"55.142365"}{"text":"Training data consists of natural language sentences annotated with multiple potential meaning representations , only one of which is correct .Such ambiguous supervision models the type of supervision that can be more naturally available to language - learning systems .Given such weak supervision , our approach produces a semantic parser that maps sentences into meaning representations .","label":"Background","metadata":{},"score":"55.142365"}{"text":"Training data consists of natural language sentences annotated with multiple potential meaning representations , only one of which is correct .Such ambiguous supervision models the type of supervision that can be more naturally available to language - learning systems .Given such weak supervision , our approach produces a semantic parser that maps sentences into meaning representations .","label":"Background","metadata":{},"score":"55.142365"}{"text":"We introduce a dialog agent for mobile robots that understands human instructions through semantic parsing , actively resolves ambiguities using a dialog manager , and incrementally learns from human - robot conversations by inducing training data from user paraphrases .Our dialog agent is implemented and tested both on a web interface with hundreds of users via Mechanical Turk and on a mobile robot over several days , tasked with understanding navigation and delivery requests through natural language in an office environment .","label":"Background","metadata":{},"score":"55.282284"}{"text":"In this setting , target domain data contains information about only a single entity .We present the SR2LR algorithm that finds an effective mapping of the source model to the target domain in this setting and demonstsrate its effectiveness in three relational domains .","label":"Background","metadata":{},"score":"55.323402"}{"text":"188 pages .Also appears as Technical Report AI07 - 343 , Artificial Intelligence Lab , University of Texas at Austin , August 200 ... .Rohit J. Kate and Raymond J. Mooney , In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics , Short Papers ( NAACL / HLT-2007 ) , pp .","label":"Background","metadata":{},"score":"55.323715"}{"text":"ML ID : 171 .Learning to Transform Natural to Formal Languages [ Details ] [ PDF ] [ Slides ] Rohit J. Kate , Yuk Wah Wong and Raymond J. Mooney In Proceedings of the Twentieth National Conference on Artificial Intelligence ( AAAI-05 ) , 1062 - 1068 , Pittsburgh , PA , July 2005 .","label":"Background","metadata":{},"score":"55.331566"}{"text":"ML ID : 171 .Learning to Transform Natural to Formal Languages [ Details ] [ PDF ] [ Slides ] Rohit J. Kate , Yuk Wah Wong and Raymond J. Mooney In Proceedings of the Twentieth National Conference on Artificial Intelligence ( AAAI-05 ) , 1062 - 1068 , Pittsburgh , PA , July 2005 .","label":"Background","metadata":{},"score":"55.331566"}{"text":"The text mining system first identifies protein names in the text using a trained Conditional Random Field ( CRF ) and then identifies interactions through a filtered co - citation analysis .We also report two new strategies for mining interactions , either by finding explicit statements of interactions in the text using learned pattern - based rules or a Support - Vector Machine using a string kernel .","label":"Background","metadata":{},"score":"55.37822"}{"text":"We show that our method performs overall better and faster than previous approaches in both domains .ML ID : 160 .Guiding a Reinforcement Learner with Natural Language Advice : Initial Results in RoboCup Soccer [ Details ] [ PDF ] Gregory Kuhlmann , Peter Stone , Raymond J. Mooney , and Jude W. Shavlik In The AAAI-2004 Workshop on Supervisory Control of Learning and Adaptive Systems , July 2004 .","label":"Background","metadata":{},"score":"55.44331"}{"text":"These algorithms typically utilize the pairwise constraints to either modify the clustering objective function or to learn the clustering distortion measure .This chapter describes an approach that employs Hidden Markov Random Fields ( HMRFs ) as a probabilistic generative model for semi - supervised clustering , thereby providing a principled framework for incorporating constraint - based supervision into prototype - based clustering .","label":"Background","metadata":{},"score":"55.474495"}{"text":"This paper reviews our recent work on applying inductive logic programming to the construction of natural language processing systems .We have developed a system , CHILL , that learns a parser from a training corpus of parsed sentences by inducing heuristics that control an initial overly - general shift - reduce parser .","label":"Background","metadata":{},"score":"55.518936"}{"text":"This paper reviews our recent work on applying inductive logic programming to the construction of natural language processing systems .We have developed a system , CHILL , that learns a parser from a training corpus of parsed sentences by inducing heuristics that control an initial overly - general shift - reduce parser .","label":"Background","metadata":{},"score":"55.518936"}{"text":"[Poster ] Islam Beltagy and Katrin Erk and Raymond Mooney In Proceedings of ACL 2014 Workshop on Semantic Parsing ( SP-2014 ) , 7 - -11 , Baltimore , MD , June 2014 .We propose a new approach to semantic parsing that is not constrained by a fixed formal ontology and purely logical inference .","label":"Background","metadata":{},"score":"55.541"}{"text":"Relational Learning Techniques for Natural Language Information Extraction [ Details ] [ PDF ] Mary Elaine Califf 1997 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .The recent growth of online information available in the form of natural language documents creates a greater need for computing systems with the ability to process those documents to simplify access to the information .","label":"Background","metadata":{},"score":"55.659798"}{"text":"Relational Learning Techniques for Natural Language Information Extraction [ Details ] [ PDF ] Mary Elaine Califf 1997 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .The recent growth of online information available in the form of natural language documents creates a greater need for computing systems with the ability to process those documents to simplify access to the information .","label":"Background","metadata":{},"score":"55.659798"}{"text":"Online Inference - Rule Learning from Natural - Language Extractions [ Details ] [ PDF ][Poster ] Sindhu Raghavan and Raymond J. Mooney In Proceedings of the 3rd Statistical Relational AI ( StaRAI-13 ) workshop at AAAI ' 13 , July 2013 .","label":"Background","metadata":{},"score":"55.79705"}{"text":"Learning Parse and Translation Decisions From Examples With Rich Context [ Details ] [ PDF ] Ulf Hermjakob PhD Thesis , Department of Computer Sciences , The University of Texas at Austin , Austin , TX , May 1997 .175 pages .","label":"Background","metadata":{},"score":"55.80417"}{"text":"Learning Parse and Translation Decisions From Examples With Rich Context [ Details ] [ PDF ] Ulf Hermjakob PhD Thesis , Department of Computer Sciences , The University of Texas at Austin , Austin , TX , May 1997 .175 pages .","label":"Background","metadata":{},"score":"55.80417"}{"text":"Joint Entity and Relation Extraction using Card - Pyramid Parsing [ Details ] [ PDF ] [ Slides ] Rohit J. Kate and Raymond J. Mooney In Proceedings of the Fourteenth Conference on Computational Natural Language Learning ( CoNLL-2010 ) , 203 - -212 , Uppsala , Sweden , July 2010 .","label":"Background","metadata":{},"score":"55.859215"}{"text":"Natural language understanding is a sub - field of natural language processing , which builds automated systems to understand natural language .It is such an ambitious task that it sometimes is referred to as an AI - complete problem , implying that its difficulty is equivalent to solving the central artificial intelligence problem -- making computers as intelligent as people .","label":"Background","metadata":{},"score":"55.903778"}{"text":"Natural language understanding is a sub - field of natural language processing , which builds automated systems to understand natural language .It is such an ambitious task that it sometimes is referred to as an AI - complete problem , implying that its difficulty is equivalent to solving the central artificial intelligence problem -- making computers as intelligent as people .","label":"Background","metadata":{},"score":"55.903778"}{"text":"On the Proper Treatment of Quantifiers in Probabilistic Logic Semantics [ Details ] [ PDF ] [ Slides ] Islam Beltagy and Katrin Erk In Proceedings of the 11th International Conference on Computational Semantics ( IWCS-2015 ) , London , UK , April 2015 .","label":"Background","metadata":{},"score":"55.925377"}{"text":"This dissertation presents a novel rule representation specific to natural language and a relational learning system , Rapier , which learns information extraction rules .Rapier takes pairs of documents and filled templates indicating the information to be extracted and learns pattern - matching rules to extract fillers for the slots in the template .","label":"Background","metadata":{},"score":"56.025284"}{"text":"In this paper , we adopt a hybrid approach that combines logic - based and distributional semantics through probabilistic logic inference in Markov Logic Networks ( MLNs ) .We focus on textual entailment ( RTE ) , a task that can utilize the strengths of both representations .","label":"Background","metadata":{},"score":"56.047176"}{"text":"Relational Learning Techniques for Natural Language Information Extraction [ Details ] [ PDF ] Mary Elaine Califf PhD Thesis , Department of Computer Sciences , University of Texas , Austin , TX , August 1998 .142 pages .Also appears as Artificial Intelligence Laboratory Technical Report AI 98 - 276 .","label":"Background","metadata":{},"score":"56.064568"}{"text":"Learning for Information Extraction : From Named Entity Recognition and Disambiguation To Relation Extraction [ Details ] [ PDF ] Razvan Constantin Bunescu PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .","label":"Background","metadata":{},"score":"56.126648"}{"text":"We present a method for utilizing unannotated sentences to improve a semantic parser which maps natural language ( NL ) sentences into their formal meaning representations ( MRs ) .Given NL sentences annotated with their MRs , the initial supervised semantic parser learns the mapping by training Support Vector Machine ( SVM ) classifiers for every production in the MR grammar .","label":"Background","metadata":{},"score":"56.18805"}{"text":"We present a method for utilizing unannotated sentences to improve a semantic parser which maps natural language ( NL ) sentences into their formal meaning representations ( MRs ) .Given NL sentences annotated with their MRs , the initial supervised semantic parser learns the mapping by training Support Vector Machine ( SVM ) classifiers for every production in the MR grammar .","label":"Background","metadata":{},"score":"56.18805"}{"text":"We present a method for utilizing unannotated sentences to improve a semantic parser which maps natural language ( NL ) sentences into their formal meaning representations ( MRs ) .Given NL sentences annotated with their MRs , the initial supervised semantic parser learns the mapping by training Support Vector Machine ( SVM ) classifiers for every production in the MR grammar .","label":"Background","metadata":{},"score":"56.18805"}{"text":"The results are very promising .Compared with Polygraph , the state of the art in polymorphic worm fingerprinting , several machine learning algorithms are able to generate more accurate signatures , tolerate more noise in the training data , and require much shorter training time .","label":"Background","metadata":{},"score":"56.18856"}{"text":"ML ID : 21 .Learning Plan Schemata From Observation : Explanation - Based Learning for Plan Recognition [ Details ] [ PDF ] Raymond J. Mooney Cognitive Science , 14(4):483 - 509 , 1990 .This article discusses how explanation - based learning of plan schemata from observation can improve performance of plan recognition .","label":"Background","metadata":{},"score":"56.275284"}{"text":"ML ID : 44 .Inducing Deterministic Prolog Parsers From Treebanks : A Machine Learning Approach [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In Proceedings of the Twelfth National Conference on Artificial Intelligence ( AAAI-94 ) , 748 - -753 , Seattle , WA , July 1994 .","label":"Background","metadata":{},"score":"56.427277"}{"text":"Knowledge Transfer Using Latent Variable Models [ Details ] [ PDF ] [ Slides ] Ayan Acharya PhD Thesis , Department of Electrical and Computer Engineering , The University of Texas at Austin , August 2015 .In several applications , scarcity of labeled data is a challenging problem that hinders the predictive capabilities of machine learning algorithms .","label":"Background","metadata":{},"score":"56.479843"}{"text":"Experimental results on a corpus of computer - science job postings demonstrate that soft - matching rules improve information extraction more effectively than hard - matching rules .ML ID : 150 .Relational Markov Networks for Collective Information Extraction [ Details ] [ PDF ] Razvan Bunescu and Raymond J. Mooney In Proceedings of the ICML-04 Workshop on Statistical Relational Learning and its Connections to Other Fields , Banff , Alberta , July 2004 .","label":"Background","metadata":{},"score":"56.683266"}{"text":"ML ID : 305 .Recent investigations into grounded models of language have shown that holistic views of language and perception can provide higher performance than independent views .In this work , we improve a two - dimensional multimodal version of Latent Dirichlet Allocation ( Andrews et al . , 2009 ) in various ways .","label":"Background","metadata":{},"score":"56.71148"}{"text":"We also demonstrate that various rule induction methods are able to identify protein interactions more accurately than manually - developed rules .ML ID : 137 .Collective Information Extraction with Relational Markov Networks [ Details ] [ PDF ] Razvan Bunescu and Raymond J. Mooney In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ( ACL-04 ) , 439 - 446 , Barcelona , Spain , July 2004 .","label":"Background","metadata":{},"score":"56.829353"}{"text":"Described video datasets are scarce , and most existing methods have been applied to toy domains with a small vocabulary of possible words .By transferring knowledge from 1.2M+ images with category labels and 100,000 + images with captions , our method is able to create sentence descriptions of open - domain videos with large vocabularies .","label":"Background","metadata":{},"score":"56.84149"}{"text":"We evaluate this semantic representation on two tasks , Recognizing Textual Entailment ( RTE ) and Semantic Textual Similarity ( STS ) .Doing RTE and STS better is an indication of a better semantic understanding .Our system has three main components , 1 .","label":"Background","metadata":{},"score":"56.90829"}{"text":"We present results showing that FOIDL learns a more accurate past - tense generator from significantly fewer examples than all other previous methods .ML ID : 53 .This paper presents a method for learning logic programs without explicit negative examples by exploiting an assumption of output completeness .","label":"Background","metadata":{},"score":"56.948074"}{"text":"The system learns to parse and generate commentaries without any engineered knowledge about the English language .Training is done using only ambiguous supervision in the form of textual human commentaries and simulation states of the soccer games .The system simultaneously tries to establish correspondences between the commentaries and the simulation states as well as build a translation model .","label":"Background","metadata":{},"score":"57.0122"}{"text":"The system learns to parse and generate commentaries without any engineered knowledge about the English language .Training is done using only ambiguous supervision in the form of textual human commentaries and simulation states of the soccer games .The system simultaneously tries to establish correspondences between the commentaries and the simulation states as well as build a translation model .","label":"Background","metadata":{},"score":"57.0122"}{"text":"The system learns to parse and generate commentaries without any engineered knowledge about the English language .Training is done using only ambiguous supervision in the form of textual human commentaries and simulation states of the soccer games .The system simultaneously tries to establish correspondences between the commentaries and the simulation states as well as build a translation model .","label":"Background","metadata":{},"score":"57.0122"}{"text":"Parameter Revision Techniques for Bayesian Networks with Hidden Variables : An Experimental Comparison [ Details ] [ PDF ] Sowmya Ramachandran and Raymond J. Mooney January 1997 .Unpublished Technical Note .Learning Bayesian networks inductively in the presence of hidden variables is still an open problem .","label":"Background","metadata":{},"score":"57.21514"}{"text":"This paper presents an approach for detecting promotional content in Wikipedia .By incorporating stylometric features , including features based on n - gram and PCFG language models , we demonstrate improved accuracy at identifying promotional articles , compared to using only lexical information and meta - features .","label":"Background","metadata":{},"score":"57.326828"}{"text":"SAM maintains the same hierarchical structure as Latent Dirichlet Allocation ( LDA ) , but models documents as points on a high - dimensional spherical manifold , allowing a natural likelihood parameterization in terms of cosine distance .Furthermore , SAM can model word absence / presence at the document level , and unlike previous models can assign explicit negative weight to topic terms .","label":"Background","metadata":{},"score":"57.364048"}{"text":"Learning for Semantic Parsing Using Statistical Syntactic Parsing Techniques [ Details ] [ PDF ] [ Slides ] Ruifang Ge PhD Thesis , Department of Computer Science , University of Texas at Austin , Austin , TX , May 2010 .165 pages .","label":"Background","metadata":{},"score":"57.5875"}{"text":"Next , we apply BALPs to the task of plan recognition and demonstrate its efficacy on two data sets .We also compare the performance of BALPs with several existing approaches for abduction .ML ID : 244 .Authorship Attribution Using Probabilistic Context - Free Grammars [ Details ] [ PDF ] [ Slides ] Sindhu Raghavan , Adriana Kovashka and Raymond Mooney In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics ( ACL-2010 ) , 38 - -42 , 2010 .","label":"Background","metadata":{},"score":"57.70641"}{"text":"Further possible applications of the presented approaches include summarized machine translation tasks and learning from real perception data assisted by computer vision and robotics .ML ID : 291 .Adapting Discriminative Reranking to Grounded Language Learning [ Details ] [ PDF ] [ Slides ] Joohyun Kim and Raymond J. Mooney In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL-2013 ) , 218 - -227 , Sofia , Bulgaria , August 2013 .","label":"Background","metadata":{},"score":"57.78793"}{"text":"English Slot Filling ( SF ) task .The UT Austin system builds upon the output of an existing relation extractor by augmenting relations that are explicitly stated in the text with ones that are inferred from the stated relations using probabilistic rules that encode commonsense world knowledge .","label":"Background","metadata":{},"score":"57.7911"}{"text":"But practical probabilistic logic frameworks usually assume a finite domain in which each entity corresponds to a constant in the logic ( domain closure assumption ) .They also assume a closed world where everything has a very low prior probability .","label":"Background","metadata":{},"score":"57.87123"}{"text":"Tiered clustering can also be viewed as a form of soft feature selection , where features that do not contribute meaningfully to the clustering can be excluded .We demonstrate the applicability of tiered clustering , highlighting particular cases where modeling shared structure is beneficial and where it can be detrimental .","label":"Background","metadata":{},"score":"57.967472"}{"text":"Information extraction ( IE ) is a form of shallow text understanding that locates specific pieces of data in natural language documents , transforming unstructured text into a structured database .This paper describes a system called DiscoTEX , that combines IE and data mining methodologies to perform text mining as well as improve the performance of the underlying extraction system .","label":"Background","metadata":{},"score":"57.990547"}{"text":"This allows for ' ' collective information extraction ' ' that exploits the mutual influence between possible extractions .Experiments on learning to extract protein names from biomedical text demonstrate the advantages of this approach .ML ID : 152 .Using Soft - Matching Mined Rules to Improve Information Extraction [ Details ] [ PDF ] Un Yong Nahm and Raymond J. Mooney In Proceedings of the AAAI-2004 Workshop on Adaptive Text Extraction and Mining ( ATEM-2004 ) , 27 - 32 , San Jose , CA , July 2004 .","label":"Background","metadata":{},"score":"58.036015"}{"text":"Discriminative Structure and Parameter Learning for Markov Logic Networks [ Details ] [ PDF ] [ Slides ] Tuyen N. Huynh and Raymond J. Mooney In Proceedings of the 25th International Conference on Machine Learning ( ICML ) , Helsinki , Finland , July 2008 .","label":"Background","metadata":{},"score":"58.06015"}{"text":"ML ID : 314 .Semantic Parsing using Distributional Semantics and Probabilistic Logic [ Details ] [ PDF ][Poster ] Islam Beltagy and Katrin Erk and Raymond Mooney In Proceedings of ACL 2014 Workshop on Semantic Parsing ( SP-2014 ) , 7 - -11 , Baltimore , MD , June 2014 .","label":"Background","metadata":{},"score":"58.0997"}{"text":"Generalizing Explanations of Narratives into Schemata [ Details ] [ PDF ] Raymond J. Mooney Masters Thesis , Department of Computer Science , University of Illinois at Urbana - Champaign , 1985 .This thesis describes a natural language system called GENESIS which improves its own performance through learning .","label":"Background","metadata":{},"score":"58.24238"}{"text":"Many machine learning and data mining tasks depend on functions that estimate similarity between instances .Similarity computations are particularly important in clustering and information integration applications , where pairwise distances play a central role in many algorithms .Typically , algorithms for these tasks rely on pre - defined similarity measures , such as edit distance or cosine similarity for strings , or Euclidean distance for vector - space data .","label":"Background","metadata":{},"score":"58.253975"}{"text":"We represent natural language semantics by combining logical and distributional information in probabilistic logic .We use Markov Logic Networks ( MLN ) for the RTE task , and Probabilistic Soft Logic ( PSL ) for the STS task .The system is evaluated on the SICK dataset .","label":"Background","metadata":{},"score":"58.277782"}{"text":"We represent natural language semantics by combining logical and distributional information in probabilistic logic .We use Markov Logic Networks ( MLN ) for the RTE task , and Probabilistic Soft Logic ( PSL ) for the STS task .The system is evaluated on the SICK dataset .","label":"Background","metadata":{},"score":"58.277782"}{"text":"The model leads to the HMRF - KMeans algorithm which minimizes an objective function derived from the joint probability of the model , and allows unification of constraint - based and distance - based semi - supervised clustering methods .Additionally , a two - phase active learning algorithm for selecting informative pairwise constraints in a query - driven framework is derived from the HMRF model , facilitating improved clustering performance with relatively small amounts of supervision from the user .","label":"Background","metadata":{},"score":"58.328655"}{"text":"Classifying entity mentions into a predefined set of categories achieves only a partial disambiguation of the names .This is further refined in the task of Named Entity Disambiguation , where names need to be linked to their actual denotations .In our research , we use Wikipedia as a repository of named entities and propose a ranking approach to disambiguation that exploits learned correlations between words from the name context and categories from the Wikipedia taxonomy .","label":"Background","metadata":{},"score":"58.329987"}{"text":"ML ID : 45 .Integrated Learning of Words and their Underlying Concepts [ Details ] [ PDF ] Raymond J. Mooney In Proceedings of the Ninth Annual Conference of the Cognitive Science Society , 947 - 978 , Seattle , WA , July 1987 .","label":"Background","metadata":{},"score":"58.33638"}{"text":"Rapier 's performance is compared to a propositional learning system for information extraction , demonstrating the superiority of relational learning for some information extraction tasks .Because one difficulty in using machine learning to develop natural language processing systems is the necessity of providing annotated examples to supervised learning systems , this dissertation also describes an attempt to reduce the number of examples Rapier requires by employing a form of active learning .","label":"Background","metadata":{},"score":"58.353523"}{"text":"experiments are reviewed which demonstrate that human subjects , like GENESIS , can learn a schema by observing , explaining , and generalizing a single specific instance presented in a narrative .ML ID : 1 .A General Explanation - Based Learning Mechanism and its Application to Narrative Understanding [","label":"Background","metadata":{},"score":"58.423313"}{"text":"It is such an ambitious task that it sometimes is referred to as an AI - complete problem , implying that its difficulty is equivalent to solving the central artificial intelligence problem -- making computers as intelligent as people .Despite its complexity , natural language understanding continues to be a fundamental problem in natural language processing in terms of its theoretical and empirical importance .","label":"Background","metadata":{},"score":"58.600212"}{"text":"Raymond J. Mooney , In Computational Linguistics and Intelligent Text Processing : Proceedings of the 8th International Conference ( CICLing 2007 ) , A. Gelbukh ( Eds . ) , pp . 311 - -324 , Mexico City , Mexico , February 2007 ... .","label":"Background","metadata":{},"score":"58.601955"}{"text":"Two new integrated ILP systems for these tasks that overcome limitations of existing methods will be presented .Cocktail is a new ILP algorithm for inducing semantic parsers .For this task , two features of a parse state , functional structure and context , provide important information for disambiguation .","label":"Background","metadata":{},"score":"58.711952"}{"text":"Two new integrated ILP systems for these tasks that overcome limitations of existing methods will be presented .Cocktail is a new ILP algorithm for inducing semantic parsers .For this task , two features of a parse state , functional structure and context , provide important information for disambiguation .","label":"Background","metadata":{},"score":"58.711952"}{"text":"Taking the MIN - GREEDY algorithm ( Ravi et al . , 2010 ) as a starting point , we improve it with several intuitive heuristics .We also define a simple HMM emission initialization that takes advantage of the tag dictionary and raw data to capture both the openness of a given tag and its estimated prevalence in the raw data .","label":"Background","metadata":{},"score":"58.961426"}{"text":"ML ID : 57 .Lexical Acquisition : A Novel Machine Learning Problem [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Technical Report , Artificial Intelligence Lab , University of Texas at Austin , January 1996 .","label":"Background","metadata":{},"score":"58.981796"}{"text":"Publications : 2006 .Adaptive Blocking : Learning to Scale Up Record Linkage [ Details ] [ PDF ] Mikhail Bilenko , Beena Kamath , Raymond J. Mooney In Proceedings of the Sixth IEEE International Conference on Data Mining ( ICDM-06 ) , 87 - -96 , Hong Kong , December 2006 .","label":"Background","metadata":{},"score":"58.99074"}{"text":"Lappoon R. Tang and Raymond J. Mooney , In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora(EMNLP / VLC-2000 ) , pp .133 - 141 , Hong Kong , October 2000 .","label":"Background","metadata":{},"score":"59.01957"}{"text":"Plan recognition is the task of predicting an agent 's top - level plans based on its observed actions .It is an abductive reasoning task that involves inferring cause from effect .In the first part of the dissertation , we develop an approach to abductive plan recognition using BLPs .","label":"Background","metadata":{},"score":"59.07596"}{"text":"We present our system Scissor based on a statistical parser that generates a semantically - augmented parse tree ( SAPT ) , in which each internal node has both a syntactic and semantic label .A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .","label":"Background","metadata":{},"score":"59.163338"}{"text":"ML ID : 95 .Active Learning for Natural Language Parsing and Information Extraction [ Details ] [ PDF ] Cynthia A. Thompson , Mary Elaine Califf and Raymond J. Mooney In Proceedings of the Sixteenth International Conference on Machine Learning ( ICML-99 ) , 406 - 414 , Bled , Slovenia , June 1999 .","label":"Background","metadata":{},"score":"59.239548"}{"text":"Associative Anaphora Resolution : A Web - Based Approach [ Details ] [ PDF ] Razvan Bunescu In Proceedings of the EACL-2003 Workshop on the Computational Treatment of Anaphora , 47 - 52 , Budapest , Hungary , 2003 .We present a novel approach to solving definite descriptions in unrestricted text based on searching the web for a particular type of lexicosyntactic patterns .","label":"Background","metadata":{},"score":"59.27837"}{"text":"To overcome this problem , previous work has used online learning algorithms to learn weights for MLNs .However , this prior work has only applied existing online algorithms , and there is no comprehensive study of online weight learning for MLNs .","label":"Background","metadata":{},"score":"59.341812"}{"text":"In plan recognition , the underlying cause or the top - level plan that resulted in the observed actions is not known or observed .Further , only a subset of the executed actions can be observed by the plan recognition system resulting in partially observed data .","label":"Background","metadata":{},"score":"59.343773"}{"text":"ML ID : 272 .Fast Online Lexicon Learning for Grounded Language Acquisition [ Details ] [ PDF ] [ Slides ] David L. Chen In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics ( ACL-2012 ) , 430 - -439 , July 2012 .","label":"Background","metadata":{},"score":"59.362545"}{"text":"ML ID : 274 .Generative Models of Grounded Language Learning with Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joohyun Kim Technical Report , PhD proposal , Department of Computer Science , The University of Texas at Austin , June 2012 . \"","label":"Background","metadata":{},"score":"59.416637"}{"text":"ML ID : 169 .A Kernel - based Approach to Learning Semantic Parsers [ Details ] [ PDF ] [ Slides ] Rohit J. Kate 2005 .Doctoral Dissertation Proposal , University of Texas at Austin .Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .","label":"Background","metadata":{},"score":"59.4663"}{"text":"Experiments show that our semantic representation can handle RTE and STS reasonably well .For the future work , our short - term goals are 1 . better RTE task representation and finite domain handling , 2 . adding more inference rules , precompiled and on - the - fly , 3 . generalizing the modified closed - world assumption , 4 . enhancing our inference algorithm for MLNs , and 5 . adding a weight learning step to better adapt the weights .","label":"Background","metadata":{},"score":"59.48012"}{"text":"ML ID : 99 .Learning for Semantic Interpretation : Scaling Up Without Dumbing Down [ Details ] [ PDF ] Raymond J. Mooney In Workshop Notes for the Workshop on Learning Language in Logic , 7 - 15 , Bled , Slovenia , 2000 .","label":"Background","metadata":{},"score":"59.590797"}{"text":"We demonstrate its capabilities by developing a system that learns to sportscast simulated robot soccer games in both English and Korean without any language - specific prior knowledge .Training employs only ambiguous supervision consisting of a stream of descriptive textual comments and a sequence of events extracted from the simulation trace .","label":"Background","metadata":{},"score":"59.62901"}{"text":"We demonstrate its capabilities by developing a system that learns to sportscast simulated robot soccer games in both English and Korean without any language - specific prior knowledge .Training employs only ambiguous supervision consisting of a stream of descriptive textual comments and a sequence of events extracted from the simulation trace .","label":"Background","metadata":{},"score":"59.62901"}{"text":"We demonstrate its capabilities by developing a system that learns to sportscast simulated robot soccer games in both English and Korean without any language - specific prior knowledge .Training employs only ambiguous supervision consisting of a stream of descriptive textual comments and a sequence of events extracted from the simulation trace .","label":"Background","metadata":{},"score":"59.62901"}{"text":"Experimental evaluation on a benchmark data set for machine reading demonstrates the efficacy of our approach .ML ID : 270 .Learning Language from Ambiguous Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen PhD Thesis , Department of Computer Science , University of Texas at Austin , May 2012 .","label":"Background","metadata":{},"score":"59.68032"}{"text":"This work will involve exploring alternative tree representations for better generalization in parsing .We also plan to apply discriminative reranking methods to semantic parsing , which allows exploring arbitrary , potentially correlated features not usable by the baseline learner .We also propose to design a method for automating the SAPT - generation process to alleviate the extra annotation work currently required for training Scissor .","label":"Background","metadata":{},"score":"59.738503"}{"text":"This work will involve exploring alternative tree representations for better generalization in parsing .We also plan to apply discriminative reranking methods to semantic parsing , which allows exploring arbitrary , potentially correlated features not usable by the baseline learner .We also propose to design a method for automating the SAPT - generation process to alleviate the extra annotation work currently required for training Scissor .","label":"Background","metadata":{},"score":"59.738503"}{"text":"An advantage of using probabilistic logic is that more rules can be added from more resources easily by mapping them to logical rules and weighting them appropriately .The last component is the inference , where we solve the probabilistic logic inference problem using an appropriate probabilistic logic tool like Markov Logic Network ( MLN ) , or Probabilistic Soft Logic ( PSL ) .","label":"Background","metadata":{},"score":"59.863342"}{"text":"Like BLPs , BALPs also combine first - order logic and Bayesian networks .However , unlike BLPs that use logical deduction to construct Bayes nets , BALPs employ logical abduction .As a result , BALPs are more suited for solving problems like plan / activity recognition and diagnosis that require abductive reasoning .","label":"Background","metadata":{},"score":"59.898415"}{"text":"Human evaluations of the generated commentaries indicate they are of reasonable quality compared to human commentaries .ML ID : 219 .Learning for Semantic Parsing with Kernels under Various Forms of Supervision [ Details ] [ PDF ] [ Slides ] Rohit J. Kate PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .","label":"Background","metadata":{},"score":"60.125942"}{"text":"Our polyglot ranking approach integrates frequency statistics from translated corpora in 50 different languages .Our experimental evaluation demonstrates that combining statistical evidence from many parallel corpora using a novel ranking - oriented boosting algorithm produces a comprehensive set of English phrasal verbs , achieving performance comparable to a human - curated set .","label":"Background","metadata":{},"score":"60.177593"}{"text":"Our polyglot ranking approach integrates frequency statistics from translated corpora in 50 different languages .Our experimental evaluation demonstrates that combining statistical evidence from many parallel corpora using a novel ranking - oriented boosting algorithm produces a comprehensive set of English phrasal verbs , achieving performance comparable to a human - curated set .","label":"Background","metadata":{},"score":"60.177593"}{"text":"ML ID : 56 .Springer .This paper presents results from recent experiments with CHILL , a corpus - based parser acquisition system .CHILL treats language acquisition as the learning of search - control rules within a logic program .","label":"Background","metadata":{},"score":"60.237564"}{"text":"ML ID : 171 .Mining Knowledge from Text Using Information Extraction [ Details ] [ PDF ] Raymond J. Mooney and R. Bunescu SIGKDD Explorations ( special issue on Text Mining and Natural Language Processing ) , 7(1):3 - 10 , 2005 .","label":"Background","metadata":{},"score":"60.250763"}{"text":"This model is implemented as a word learning component added to the GENESIS explanation - based learning schema acquisition system for narrative understanding .A detailed example is described in which GENESIS learns provisional definitions for the words \" kidnap \" , \" kidnapper \" , and \" ransom \" as well as a kidnapping schema from a single narrative .","label":"Background","metadata":{},"score":"60.34468"}{"text":"This model is implemented as a word learning component added to the GENESIS explanation - based learning schema acquisition system for narrative understanding .A detailed example is described in which GENESIS learns provisional definitions for the words \" kidnap \" , \" kidnapper \" , and \" ransom \" as well as a kidnapping schema from a single narrative .","label":"Background","metadata":{},"score":"60.34468"}{"text":"Finally , we will investigate the impact of different statistical syntactic parsers on semantic parsing using the automated SAPT - generation process .ML ID : 184 .Using Active Relocation to Aid Reinforcement Learning [ Details ] [ PDF ] Lilyana Mihalkova and Raymond Mooney In Prodeedings of the 19th International FLAIRS Conference ( FLAIRS-2006 ) , 580 - 585 , Melbourne Beach , FL , May 2006 .","label":"Background","metadata":{},"score":"60.378334"}{"text":"Preliminary results obtained with this method are promising and compare well with other methods .ML ID : 120 .Machine Learning [ Details ] [ PDF ] Raymond J. Mooney New York , NY , 2003 .McGraw - Hill .","label":"Background","metadata":{},"score":"60.383522"}{"text":"Adapting Discriminative Reranking to Grounded Language Learning [ Details ] [ PDF ] [ Slides ] Joohyun Kim and Raymond J. Mooney In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL-2013 ) , 218 - -227 , Sofia , Bulgaria , August 2013 .","label":"Background","metadata":{},"score":"60.619102"}{"text":"The OK - KeJia robot prototype is implemented and evaluated , with special attention to two tests on 11,615 user tasks and 467 user desires .The experiments show that the overall performance . ...e semantics .For this purpose , a lexicon with semantically annotated lexemes and a collection of augmented syntax rules ( as - rules , for short ) are hand crafted in our current implementation .","label":"Background","metadata":{},"score":"60.694077"}{"text":"We present empirical results that demonstrate the effectiveness of our proposed approach on data collected form a commercial general - purpose search engine .ML ID : 225 .A Dependency - based Word Subsequence Kernel [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the conference on Empirical Methods in Natural Language Processing ( EMNLP-2008 ) , 400 - -409 , Waikiki , Honolulu , Hawaii , October 2008 .","label":"Background","metadata":{},"score":"60.77442"}{"text":"Using Encyclopedic Knowledge for Named Entity Disambiguation [ Details ] [ PDF ] Razvan Bunescu and Marius Pasca In Proceesings of the 11th Conference of the European Chapter of the Association for Computational Linguistics ( EACL-06 ) , 9 - 16 , Trento , Italy , 2006 .","label":"Background","metadata":{},"score":"60.948948"}{"text":"Inductive Logic Programming for Natural Language Processing [ Details ] [ PDF ] Raymond J. Mooney In Stephen Muggleton , editors , Inductive Logic Programming : Selected papers from the 6th International Workshop , 3 - 22 , Berlin , 1996 .","label":"Background","metadata":{},"score":"61.083103"}{"text":"Inductive Logic Programming for Natural Language Processing [ Details ] [ PDF ] Raymond J. Mooney In Stephen Muggleton , editors , Inductive Logic Programming : Selected papers from the 6th International Workshop , 3 - 22 , Berlin , 1996 .","label":"Background","metadata":{},"score":"61.083103"}{"text":"Latent Variable Models of Distributional Lexical Semantics [ Details ] [ PDF ] Joseph Reisinger PhD Thesis , Department of Computer Science , University of Texas at Austin , May 2012 .In order to respond to increasing demand for natural language interfaces - and provide meaningful insight into user query intent - fast , scalable lexical semantic models with flexible representations are needed .","label":"Background","metadata":{},"score":"61.238033"}{"text":"Latent Variable Models of Distributional Lexical Semantics [ Details ] [ PDF ] Joseph Reisinger PhD Thesis , Department of Computer Science , University of Texas at Austin , May 2012 .In order to respond to increasing demand for natural language interfaces - and provide meaningful insight into user query intent - fast , scalable lexical semantic models with flexible representations are needed .","label":"Background","metadata":{},"score":"61.238033"}{"text":"ML ID : 279 .Improving Video Activity Recognition using Object Recognition and Text Mining [ Details ] [ PDF ] [ Slides ] Tanvi S. Motwani and Raymond J. Mooney In Proceedings of the 20th European Conference on Artificial Intelligence ( ECAI-2012 ) , 600 - -605 , August 2012 .","label":"Background","metadata":{},"score":"61.25836"}{"text":"Also appears as Technical Report AI 99 - 278 , Artificial Intelligence Lab , University of Texas at Austin .Cynthia A. Thompson and Raymond J. Mooney , In Proceedings of the Sixth Workshop on Very Large Corpora , Montreal , Quebec , Canada , August 1998 .","label":"Background","metadata":{},"score":"61.27777"}{"text":"In this paper we introduce a new online algorithm that is an order of magnitude faster and surpasses the state - of - the - art results .We show that by changing the grammar of the formal meaning representation language and training on additional data collected from Amazon 's Mechanical Turk we can further improve the results .","label":"Background","metadata":{},"score":"61.27873"}{"text":"We show that our method performs overall better and faster than previous approaches in both domains .ML ID : 160 .Automatically extracting information from biomedical text holds the promise of easily consolidating large amounts of biological knowledge in computer - accessible form .","label":"Background","metadata":{},"score":"61.38668"}{"text":"ML ID : 172 .A Statistical Semantic Parser that Integrates Syntax and Semantics [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of CoNLL-2005 , Ann Arbor , Michigan , June 2005 .We introduce a learning semantic parser , Scissor , that maps natural - language sentences to a detailed , formal , meaning - representation language .","label":"Background","metadata":{},"score":"61.476173"}{"text":"Machine translations of 32 Wall Street Journal sentences to German have been evaluated by 10 bilingual volunteers and been graded as 2.4 on a 1.0 ( best ) to 6.0 ( worst ) scale for both grammatical correctness and meaning preservation .","label":"Background","metadata":{},"score":"61.637535"}{"text":"Machine translations of 32 Wall Street Journal sentences to German have been evaluated by 10 bilingual volunteers and been graded as 2.4 on a 1.0 ( best ) to 6.0 ( worst ) scale for both grammatical correctness and meaning preservation .","label":"Background","metadata":{},"score":"61.637535"}{"text":"1923 - -1929 , Buenos Aires , Argentina , July 2015 .Joohyun Kim and Raymond J. Mooney , In Proceedings of the Conference on Empirical Methods in Natural Language Processing and Natural Language Learning ( EMNLP - CoNLL ' 12 ) , pp .","label":"Background","metadata":{},"score":"61.666435"}{"text":"Tree least general generalizations ( TLGGs ) of the representations of input sentences are performed to assist in determining the representations of individual words in the sentences .The best guess for a meaning of a word is the TLGG which overlaps with the highest percentage of sentence representations in which that word appears .","label":"Background","metadata":{},"score":"61.692932"}{"text":"Tree least general generalizations ( TLGGs ) of the representations of input sentences are performed to assist in determining the representations of individual words in the sentences .The best guess for a meaning of a word is the TLGG which overlaps with the highest percentage of sentence representations in which that word appears .","label":"Background","metadata":{},"score":"61.692932"}{"text":"Tree least general generalizations ( TLGGs ) of the representations of input sentences are performed to assist in determining the representations of individual words in the sentences .The best guess for a meaning of a word is the TLGG which overlaps with the highest percentage of sentence representations in which that word appears .","label":"Background","metadata":{},"score":"61.692932"}{"text":"A disambiguation SVM kernel is trained to exploit the high coverage and rich structure of the knowledge encoded in an online encyclopedia .The resulting model significantly outperforms a less informed baseline .ML ID : 185 .Learning Semantic Parsers Using Statistical Syntactic Parsing Techniques [ Details ] [ PDF ] Ruifang Ge 2006 .","label":"Background","metadata":{},"score":"61.704544"}{"text":"We present a novel framework for learning to interpret and generate language using only perceptual context as supervision .We demonstrate its capabilities by developing a system that learns to sportscast simulated robot soccer games in both English and Korean without any language - specific prior knowledge .","label":"Background","metadata":{},"score":"61.799515"}{"text":"The experiments also compare the performances of different learning algorithms and different types of feature sets when used for predicting readability .ML ID : 250 .Cross - cutting Models of Distributional Lexical Semantics [ Details ] [ PDF ] [ Slides ] Joseph S. Reisinger June 2010 .","label":"Background","metadata":{},"score":"62.005085"}{"text":"The experiments also compare the performances of different learning algorithms and different types of feature sets when used for predicting readability .ML ID : 250 .Cross - cutting Models of Distributional Lexical Semantics [ Details ] [ PDF ] [ Slides ] Joseph S. Reisinger June 2010 .","label":"Background","metadata":{},"score":"62.005085"}{"text":"This work shows how linguistic universals intrinsic to the CCG formalism itself can be encoded as Bayesian priors to improve learning .ML ID : 321 .Combinatory Categorial Grammar ( CCG ) is a lexicalized grammar formalism in which words are associated with categories that specify the syntactic configurations in which they may occur .","label":"Background","metadata":{},"score":"62.01742"}{"text":"The development of natural language interfaces ( NLIs ) for databases has been an interesting problem in natural language processing since the 70 's .The need for NLIs has become more pronounced given the widespread access to complex databases now available through the Internet .","label":"Background","metadata":{},"score":"62.20146"}{"text":"Most of the other parsing and generation algorithms presented in this thesis are extensions of WASP or its inverse .We demonstrate the effectiveness of our parsing and generation algorithms by performing experiments in two real - world , restricted domains .","label":"Background","metadata":{},"score":"62.284187"}{"text":"Most of the other parsing and generation algorithms presented in this thesis are extensions of WASP or its inverse .We demonstrate the effectiveness of our parsing and generation algorithms by performing experiments in two real - world , restricted domains .","label":"Background","metadata":{},"score":"62.284187"}{"text":"Most of the other parsing and generation algorithms presented in this thesis are extensions of WASP or its inverse .We demonstrate the effectiveness of our parsing and generation algorithms by performing experiments in two real - world , restricted domains .","label":"Background","metadata":{},"score":"62.284187"}{"text":"ML ID : 25 .Learning Search - Control Heuristics for Logic Programs : Applications to Speedup Learning and Language Acquisition [ Details ] [ PDF ] John M. Zelle March 1993 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .","label":"Background","metadata":{},"score":"62.299828"}{"text":"Knowledge Base Construction , and 3 .Inference The input natural sentences of the RTE / STS task are mapped to logical form using Boxer which is a rule based system built on top of a CCG parser , then they are used to formulate the RTE / STS problem in probabilistic logic .","label":"Background","metadata":{},"score":"62.68374"}{"text":"We intend to extend the rule representation and algorithm to allow for more types of constraints than are currently supported .We also plan to incorporate active learning , or sample selection , methods , specifically query by committee , into RAPIER .","label":"Background","metadata":{},"score":"62.70781"}{"text":"We intend to extend the rule representation and algorithm to allow for more types of constraints than are currently supported .We also plan to incorporate active learning , or sample selection , methods , specifically query by committee , into RAPIER .","label":"Background","metadata":{},"score":"62.70781"}{"text":"The system does not use any prior language knowledge and was able to learn to sportscast in both English and Korean .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans .","label":"Background","metadata":{},"score":"63.102615"}{"text":"ML ID : 223 .Transforming Meaning Representation Grammars to Improve Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the Twelfth Conference on Computational Natural Language Learning ( CoNLL-2008 ) , 33 - -40 , Manchester , UK , August 2008 .","label":"Background","metadata":{},"score":"63.118576"}{"text":"ML ID : 223 .Transforming Meaning Representation Grammars to Improve Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the Twelfth Conference on Computational Natural Language Learning ( CoNLL-2008 ) , 33 - -40 , Manchester , UK , August 2008 .","label":"Background","metadata":{},"score":"63.118576"}{"text":"ML ID : 223 .Transforming Meaning Representation Grammars to Improve Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the Twelfth Conference on Computational Natural Language Learning ( CoNLL-2008 ) , 33 - -40 , Manchester , UK , August 2008 .","label":"Background","metadata":{},"score":"63.118576"}{"text":"Finally , we also show that ensembles of different semantic parser learning systems can obtain the best overall performance .ML ID : 215 .Learning for Semantic Parsing and Natural Language Generation Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .","label":"Background","metadata":{},"score":"63.301876"}{"text":"Finally , we also show that ensembles of different semantic parser learning systems can obtain the best overall performance .ML ID : 215 .Learning for Semantic Parsing and Natural Language Generation Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .","label":"Background","metadata":{},"score":"63.301876"}{"text":"Finally , we also show that ensembles of different semantic parser learning systems can obtain the best overall performance .ML ID : 215 .Learning for Semantic Parsing and Natural Language Generation Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .","label":"Background","metadata":{},"score":"63.301876"}{"text":"ML ID : 241 .Training a Multilingual Sportscaster : Using Perceptual Context to Learn Language [ Details ] [ PDF ] David L. Chen , Joohyun Kim , Raymond J. Mooney Journal of Artificial Intelligence Research , 37:397 - -435 , 2010 .","label":"Background","metadata":{},"score":"63.30282"}{"text":"ML ID : 241 .Training a Multilingual Sportscaster : Using Perceptual Context to Learn Language [ Details ] [ PDF ] David L. Chen , Joohyun Kim , Raymond J. Mooney Journal of Artificial Intelligence Research , 37:397 - -435 , 2010 .","label":"Background","metadata":{},"score":"63.30282"}{"text":"ML ID : 180 .A Statistical Semantic Parser that Integrates Syntax and Semantics [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of CoNLL-2005 , Ann Arbor , Michigan , June 2005 .We introduce a learning semantic parser , Scissor , that maps natural - language sentences to a detailed , formal , meaning - representation language .","label":"Background","metadata":{},"score":"63.36716"}{"text":"ML ID : 180 .A Statistical Semantic Parser that Integrates Syntax and Semantics [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of CoNLL-2005 , Ann Arbor , Michigan , June 2005 .We introduce a learning semantic parser , Scissor , that maps natural - language sentences to a detailed , formal , meaning - representation language .","label":"Background","metadata":{},"score":"63.36716"}{"text":"Second , adopting a syntax - based approach allows us to directly leverage the enormous progress made in statistical syntactic parsing .The first semantic parser , SCISSOR , adopts an integrated syntactic - semantic parsing approach , in which a statistical syntactic parser is augmented with semantic parameters to produce a semantically - augmented parse tree ( SAPT ) .","label":"Background","metadata":{},"score":"63.495605"}{"text":"ML ID : 229 .Learning for Semantic Parsing with Kernels under Various Forms of Supervision [ Details ] [ PDF ] [ Slides ] Rohit J. Kate PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .","label":"Background","metadata":{},"score":"63.49904"}{"text":"Ruifang Ge and Raymond J. Mooney , In Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of ... .Yuk Wah Wong and Raymond J. Mooney , In Proceedings of Human Language Technologies : The Conference of the North American Chapter of the Association for Computational Linguistics ( NAACL - HLT-07 ) , pp .","label":"Background","metadata":{},"score":"63.628044"}{"text":"ML ID : 272 .Learning Language from Ambiguous Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen PhD Thesis , Department of Computer Science , University of Texas at Austin , May 2012 .Building a computer system that can understand human languages has been one of the long - standing goals of artificial intelligence .","label":"Background","metadata":{},"score":"63.872215"}{"text":"ML ID : 54 .Springer .This paper presents results on using a new inductive logic programming method called FOIDL to learn the past tense of English verbs .The past tense task has been widely studied in the context of the symbolic / connectionist debate .","label":"Background","metadata":{},"score":"63.948105"}{"text":"Inclusive yet Selective : Supervised Distributional Hypernymy Detection [ Details ] [ PDF ] Stephen Roller and Katrin Erk and Gemma Boleda In Proceedings of the 25th International Conference on Computational Linguistics ( COLING 2014 ) , 1025 - -1036 , Dublin , Ireland , August 2014 .","label":"Background","metadata":{},"score":"64.09806"}{"text":"We compare a number of semantic parsing approaches on the highly noisy training data collected from ordinary users , and find that loosely synchronous systems perform best .ML ID : 317 .Intelligent robots frequently need to understand requests from naive users through natural language .","label":"Background","metadata":{},"score":"64.184235"}{"text":"As Internet worms become ever faster and more sophisticated , it is important to be able to extract worm signatures in an accurate and timely manner .In this paper , we apply machine learning to automatically fingerprint polymorphic worms , which are able to change their appearance across every instance .","label":"Background","metadata":{},"score":"64.2055"}{"text":"The performance of semantic parsing can be potentially improved by using discriminative reranking , which explores arbitrary global features .In this paper , we investigate discriminative reranking upon a baseline semantic parser , SCISSOR , where the composition of meaning representations is guided by syntax .","label":"Background","metadata":{},"score":"64.23241"}{"text":"The performance of semantic parsing can be potentially improved by using discriminative reranking , which explores arbitrary global features .In this paper , we investigate discriminative reranking upon a baseline semantic parser , SCISSOR , where the composition of meaning representations is guided by syntax .","label":"Background","metadata":{},"score":"64.23241"}{"text":"The performance of semantic parsing can be potentially improved by using discriminative reranking , which explores arbitrary global features .In this paper , we investigate discriminative reranking upon a baseline semantic parser , SCISSOR , where the composition of meaning representations is guided by syntax .","label":"Background","metadata":{},"score":"64.23241"}{"text":"The performance of semantic parsing can be potentially improved by using discriminative reranking , which explores arbitrary global features .In this paper , we investigate discriminative reranking upon a baseline semantic parser , SCISSOR , where the composition of meaning representations is guided by syntax .","label":"Background","metadata":{},"score":"64.23241"}{"text":"Thus , it is applicable to a wide range of domains and data representations .Similarity functions are learned within the HMRF - KMeans algorithm derived from the framework , leading to significant improvements in clustering accuracy .The third application we consider , blocking , is critical in making record linkage and clustering algorithms scalable to large datasets , as it facilitates efficient selection of approximately similar instance pairs without explicitly considering all possible pairs .","label":"Background","metadata":{},"score":"64.42293"}{"text":"Rohit J. Kate and Raymond J. Mooney , In ACL 2006 : Proceedings of the 21stInternational Conference on Computational Linguistics and the 44th annual meeting of the ACL , pp .913 - 920 , Morristown , NJ , USA 2006 .","label":"Background","metadata":{},"score":"64.428154"}{"text":"Words exist because of meaning .Once you 've gotten the meaning , you can forget the words .Where can I find a man who has forgotten words so I can talk with him ? \" -- The Writings of Chuang Tzu , 4th century B.C. ( Original text in Chinese ) .","label":"Background","metadata":{},"score":"64.53269"}{"text":"We evaluate several variants of our model that exploit different visual features on a standard set of YouTube videos and two movie description datasets ( M - VAD and MPII - MD ) .ML ID : 319 .We present results on using stacking to ensemble multiple systems for the Knowledge Base Population English Slot Filling ( KBP - ESF ) task .","label":"Background","metadata":{},"score":"64.72667"}{"text":"ML ID : 317 .Representing Meaning with a Combination of Logical Form and Vectors [ Details ] [ PDF ] Islam Beltagy and Stephen Roller and Pengxiang Cheng and Katrin Erk and Raymond J. Mooney arXiv preprint arXiv:1505.06816 [ cs .","label":"Background","metadata":{},"score":"64.94328"}{"text":"ML ID : 311 .Weakly - Supervised Grammar - Informed Bayesian CCG Parser Learning [ Details ] [ PDF ] [ Slides ] Dan Garrette , Chris Dyer , Jason Baldridge , Noah A. Smith In Proceedings of the Twenty - Ninth AAAI Conference on Artificial Intelligence ( AAAI-15 ) , Austin , TX , January 2015 .","label":"Background","metadata":{},"score":"65.147736"}{"text":"Most work on weakly - supervised learning for part - of - speech taggers has been based on unrealistic assumptions about the amount and quality of training data .For this paper , we attempt to create true low - resource scenarios by allowing a linguist just two hours to annotate data and evaluating on the languages Kinyarwanda and Malagasy .","label":"Background","metadata":{},"score":"65.1734"}{"text":"In clustering , similarity functions are essential as they determine the grouping of instances that is the goal of clustering .We describe a framework for integrating learnable similarity functions within a probabilistic model for semi - supervised clustering based on Hidden Markov Random Fields ( HMRFs ) .","label":"Background","metadata":{},"score":"65.637924"}{"text":"Finally , we also plan to investigate ways to combine our semantic parser with some recently developed semantic parsers to form committees in order to get the best overall performance .ML ID : 181 .Learning for Semantic Parsing Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong 2005 .","label":"Background","metadata":{},"score":"65.821526"}{"text":"Finally , we also plan to investigate ways to combine our semantic parser with some recently developed semantic parsers to form committees in order to get the best overall performance .ML ID : 181 .Learning for Semantic Parsing Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong 2005 .","label":"Background","metadata":{},"score":"65.821526"}{"text":"Finally , we also plan to investigate ways to combine our semantic parser with some recently developed semantic parsers to form committees in order to get the best overall performance .ML ID : 181 .Learning for Semantic Parsing Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong 2005 .","label":"Background","metadata":{},"score":"65.821526"}{"text":"First , the syntax - based semantic parsing is theoretically well - founded in computational semantics .Second , adopting a syntax - based approach allows us to directly leverage the enormous progress made in statistical syntactic parsing .The first semantic parser , SCISSOR , adopts an integrated syntactic - semantic parsing approach , in which a statistical syntactic parser is augmented with semantic parameters to produce a semantically - augmented parse tree ( SAPT ) .","label":"Background","metadata":{},"score":"66.067345"}{"text":"First , the syntax - based semantic parsing is theoretically well - founded in computational semantics .Second , adopting a syntax - based approach allows us to directly leverage the enormous progress made in statistical syntactic parsing .The first semantic parser , SCISSOR , adopts an integrated syntactic - semantic parsing approach , in which a statistical syntactic parser is augmented with semantic parameters to produce a semantically - augmented parse tree ( SAPT ) .","label":"Background","metadata":{},"score":"66.067345"}{"text":"ML ID : 92 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia Ann Thompson PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , December 1998 .","label":"Background","metadata":{},"score":"66.162025"}{"text":"ML ID : 92 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia Ann Thompson PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , December 1998 .","label":"Background","metadata":{},"score":"66.162025"}{"text":"ML ID : 229 .A Dependency - based Word Subsequence Kernel [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the conference on Empirical Methods in Natural Language Processing ( EMNLP-2008 ) , 400 - -409 , Waikiki , Honolulu , Hawaii , October 2008 .","label":"Background","metadata":{},"score":"66.47056"}{"text":"ML ID : 229 .A Dependency - based Word Subsequence Kernel [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the conference on Empirical Methods in Natural Language Processing ( EMNLP-2008 ) , 400 - -409 , Waikiki , Honolulu , Hawaii , October 2008 .","label":"Background","metadata":{},"score":"66.47056"}{"text":"Conclusion .These interactions and the accuracy benchmarks will aid interpretation of current functional genomics data and provide a basis for determining the quality of future large - scale human protein interaction assays .Projecting from the approximately 15 interactions per protein in the best - sampled interaction set to the estimated 25,000 human genes implies more than 375,000 interactions in the complete human protein interaction network .","label":"Background","metadata":{},"score":"66.486725"}{"text":"ML ID : 216 .Learning for Semantic Parsing with Kernels under Various Forms of Supervision [ Details ] [ PDF ] [ Slides ] Rohit J. Kate PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .","label":"Background","metadata":{},"score":"66.80885"}{"text":"Extensive protein interaction maps are being constructed for yeast , worm , and fly to ask how the proteins organize into pathways and systems , but no such genome - wide interaction map yet exists for the set of human proteins .","label":"Background","metadata":{},"score":"66.96455"}{"text":"Experimental results show improved results for our joint extraction method compared to a pipelined approach .ML ID : 247 .Learning for Semantic Parsing Using Statistical Syntactic Parsing Techniques [ Details ] [ PDF ] [ Slides ] Ruifang Ge PhD Thesis , Department of Computer Science , University of Texas at Austin , Austin , TX , May 2010 .","label":"Background","metadata":{},"score":"67.01058"}{"text":"Experimental results show improved results for our joint extraction method compared to a pipelined approach .ML ID : 247 .Learning for Semantic Parsing Using Statistical Syntactic Parsing Techniques [ Details ] [ PDF ] [ Slides ] Ruifang Ge PhD Thesis , Department of Computer Science , University of Texas at Austin , Austin , TX , May 2010 .","label":"Background","metadata":{},"score":"67.01058"}{"text":"ML ID : 320 .Real - world videos often have complex dynamics ; and methods for generating open - domain video descriptions should be sensitive to temporal structure and allow both input ( sequence of frames ) and output ( sequence of words ) of variable length .","label":"Background","metadata":{},"score":"67.04077"}{"text":"The development of natural language interfaces ( NLI 's ) for databases has been a challenging problem in natural language processing ( NLP ) since the 1970 's .The need for NLI 's has become more pronounced due to the widespread access to complex databases now available through the Internet .","label":"Background","metadata":{},"score":"67.21965"}{"text":"We present the results of one of the largest linguistic data collection efforts to date using Mechanical Turk , yielding 85 K English sentences and more than 1k sentences for each of a dozen more languages .ML ID : 265 .","label":"Background","metadata":{},"score":"67.303665"}{"text":"ML ID : 184 .Subsequence Kernels for Relation Extraction [ Details ] [ PDF ] Razvan Bunescu and Raymond J. Mooney In Y. Weiss , B. Schoelkopf , J. Platt , editors , Advances in Neural Information Processing Systems , Vol .","label":"Background","metadata":{},"score":"67.34068"}{"text":"ML ID : 252 .Cross - cutting Models of Distributional Lexical Semantics [ Details ] [ PDF ] [ Slides ] Joseph S. Reisinger June 2010 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .","label":"Background","metadata":{},"score":"67.421814"}{"text":"However , extraction efforts have been frustrated by the lack of conventions for describing human genes and proteins .We have developed and evaluated a variety of learned information extraction systems for identifying human protein names in Medline abstracts and subsequently extracting information on interactions between the proteins .","label":"Background","metadata":{},"score":"67.46497"}{"text":"ML ID : 271 .Most information extraction ( IE ) systems identify facts that are explicitly stated in text .However , in natural language , some facts are implicit , and identifying them requires \" reading between the lines \" .","label":"Background","metadata":{},"score":"67.68693"}{"text":"Ruifang Ge and Raymond J. Mooney , In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ( COLING / ACL-06 ) , Sydney , Australia , Jul ..Yuk Wah Wong and Raymond J. Mooney , In Proceedings of Human Language Technology Conference / North American Chapter of the Association for Computational Linguistics Annual Meeting ( HLT - NAACL-06 ) , pp .","label":"Background","metadata":{},"score":"67.71855"}{"text":"ML ID : 260 .Collecting Highly Parallel Data for Paraphrase Evaluation [ Details ] [ PDF ] [ Slides ] David L. Chen and William B. Dolan In Proceedings of the 49thAnnual Meeting of the Association for Computational Linguistics , 190 - 200 , Portland , Oregon , USA , June 2011 .","label":"Background","metadata":{},"score":"68.09763"}{"text":"Learning to Sportscast : A Test of Grounded Language Acquisition [ Details ] [ PDF ] [ Slides ] [ Video ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th International Conference on Machine Learning ( ICML ) , Helsinki , Finland , July 2008 .","label":"Background","metadata":{},"score":"68.17551"}{"text":"Experimental results show that SCOPE can significantly improve both the quality of final plans and overall planning efficiency .ML ID : 77 .Information extraction systems process natural language documents and locate a specific set of relevant items .Given the recent success of empirical or corpus - based approaches in other areas of natural language processing , machine learning has the potential to significantly aid the development of these knowledge - intensive systems .","label":"Background","metadata":{},"score":"68.20173"}{"text":"In the area of program optimization , a prototype system , DOLPHIN , is able to transform some intractable specifications into polynomial - time algorithms , and outperforms competing approaches in several benchmark speedup domains .A prototype language acquisition system , CHILL , is also described .","label":"Background","metadata":{},"score":"68.59791"}{"text":"ML ID : 253 .We introduce tiered clustering , a mixture model capable of accounting for varying degrees of shared ( context - independent ) feature structure , and demonstrate its applicability to inferring distributed representations of word meaning .Tiered clustering can also be viewed as a form of soft feature selection , where features that do not contribute meaningfully to the clustering can be excluded .","label":"Background","metadata":{},"score":"68.635704"}{"text":"Since the world never provides any direct feedback on syntactic structure , language - learning methods that 424TRAININGA MULTILINGUAL SPORTSCASTER require syntact ... . by Antoine Bordes , Xavier Glorot , Jason Weston , Yoshua Bengio - In Proceedings of 15th International Conference on Artificial Intelligence and Statistics , 2012 . \" ...","label":"Background","metadata":{},"score":"68.73252"}{"text":"ML ID : 316 .Knowledge Base Population using Stacked Ensembles of Information Extractors [ Details ] [ PDF ] Vidhoon Viswanathan Masters Thesis , Department of Computer Science , The University of Texas at Austin , May 2015 .The performance of relation extractors plays a significant role in automatic creation of knowledge bases from web corpus .","label":"Background","metadata":{},"score":"69.31215"}{"text":"Given the recent success of empirical or corpus - based approaches in other areas of natural language processing , machine learning has the potential to significantly aid the development of these knowledge - intensive systems .This paper presents a system , RAPIER , that takes pairs of documents and filled templates and induces pattern - match rules that directly extract fillers for the slots in the template .","label":"Background","metadata":{},"score":"69.36866"}{"text":"Given the recent success of empirical or corpus - based approaches in other areas of natural language processing , machine learning has the potential to significantly aid the development of these knowledge - intensive systems .This paper presents a system , RAPIER , that takes pairs of documents and filled templates and induces pattern - match rules that directly extract fillers for the slots in the template .","label":"Background","metadata":{},"score":"69.36866"}{"text":"Spherical Topic Models [ Details ] [ PDF ] [ Slides ] Joseph Reisinger , Austin Waters , Bryan Silverthorn , and Raymond J. Mooney In Proceedings of the 27th International Conference on Machine Learning ( ICML 2010 ) , 2010 .","label":"Background","metadata":{},"score":"69.590034"}{"text":"Experiments in a pair of synthetic domains demonstrate that this strategy significantly decreases the search space and speeds up learning while maintaining a level of accuracy comparable to that of the current best algorithm .ML ID : 189 .The task of mining relations from collections of documents is usually approached in two different ways .","label":"Background","metadata":{},"score":"69.61104"}{"text":"Systems for this task require significant domain - specific knowledge and are time - consuming and difficult to build by hand , making them a good application for machine learning .We present a aystem , RAPIER , that uses pairs of sample documents and filled templates to induce pattern - match rules that directly extract fillers for the slots in the template .","label":"Background","metadata":{},"score":"69.876625"}{"text":"We also publish the set of rules queried from the SICK dataset , which can be a good resource to evaluate them .ML ID : 316 .Inclusive yet Selective : Supervised Distributional Hypernymy Detection [ Details ] [ PDF ] Stephen Roller and Katrin Erk and Gemma Boleda In Proceedings of the 25th International Conference on Computational Linguistics ( COLING 2014 ) , 1025 - -1036 , Dublin , Ireland , August 2014 .","label":"Background","metadata":{},"score":"70.00925"}{"text":"Using Active Relocation to Aid Reinforcement Learning [ Details ] [ PDF ] Lilyana Mihalkova and Raymond Mooney In Prodeedings of the 19th International FLAIRS Conference ( FLAIRS-2006 ) , 580 - 585 , Melbourne Beach , FL , May 2006 .","label":"Background","metadata":{},"score":"70.012215"}{"text":"Systems for this task require significant domain - specific knowledge and are time - consuming and difficult to build by hand , making them a good application for machine learning .This paper presents a system , Rapier , that takes pairs of sample documents and filled templates and induces pattern - match rules that directly extract fillers for the slots in the template .","label":"Background","metadata":{},"score":"70.03819"}{"text":"ML ID : 175 .Consolidating the Set of Known Human Protein - Protein Interactions in Preparation for Large - Scale Mapping of the Human Interactome [ Details ] [ PDF ] A.K. Ramani , R.C. Bunescu , Raymond J. Mooney and E.M. Marcotte Genome Biology , 6(5):r40 , 2005 .","label":"Background","metadata":{},"score":"70.095505"}{"text":"Results .We established two tests of the accuracy of human protein interaction datasets and measured the relative accuracy of the available data .We then developed and applied natural language processing and literature - mining algorithms to recover from Medline abstracts 6,580 interactions among 3,737 human proteins .","label":"Background","metadata":{},"score":"70.158615"}{"text":"ML ID : 50 .Using Inductive Logic Programming to Automate the Construction of Natural Language Parsers [ Details ] [ PDF ] John M. Zelle PhD Thesis , Department of Computer Sciences , The University of Texas at Austin , Austin , TX , 1995 .","label":"Background","metadata":{},"score":"70.36258"}{"text":"ML ID : 325 .Statistical Script Learning with Recurrent Neural Nets [ Details ] [ PDF ] [ Slides ] Karl Pichotta December 2015 .PhD proposal , Department of Computer Science , The University of Texas at Austin .Statistical Scripts are probabilistic models of sequences of events .","label":"Background","metadata":{},"score":"70.75438"}{"text":"Finally , we will investigate the impact of different statistical syntactic parsers on semantic parsing using the automated SAPT - generation process .ML ID : 184 .A Kernel - based Approach to Learning Semantic Parsers [ Details ] [ PDF ] [ Slides ] Rohit J. Kate 2005 .","label":"Background","metadata":{},"score":"70.87323"}{"text":"ML ID : 183 .MIT Press .In certain clustering tasks it is possible to obtain limited supervision in the form of pairwise constraints , i.e. , pairs of instances labeled as belonging to same or different clusters .The resulting problem is known as semi - supervised clustering , an instance of semi - supervised learning stemming from a traditional unsupervised learning setting .","label":"Background","metadata":{},"score":"70.9417"}{"text":"These results support the claim that ILP techniques as implemented in CHILL represent a viable alternative with significant potential advantages over neural - network , propositional , and probablistic approaches to empirical parser construction .ML ID : 48 .This paper presents results from recent experiments with CHILL , a corpus - based parser acquisition system .","label":"Background","metadata":{},"score":"71.04202"}{"text":"These results support the claim that ILP techniques as implemented in CHILL represent a viable alternative with significant potential advantages over neural - network , propositional , and probablistic approaches to empirical parser construction .ML ID : 48 .This paper presents results from recent experiments with CHILL , a corpus - based parser acquisition system .","label":"Background","metadata":{},"score":"71.04202"}{"text":"ML ID : 186 .Statistical Relational Learning for Natural Language Information Extraction [ Details ] [ PDF ] Razvan Bunescu and Raymond J. Mooney In L. Getoor and B. Taskar , editors , Introduction to Statistical Relational Learning , 535 - 552 , Cambridge , MA , 2007 .","label":"Background","metadata":{},"score":"71.290184"}{"text":"Since our system only needs supervision in the form of language being used in relevant contexts , it is easy for virtually anyone to contribute to the training data .ML ID : 269 .Building a Persistent Workforce on Mechanical Turk for Multilingual Data Collection [ Details ] [ PDF ] [ Slides ] David L. Chen and William B. Dolan In Proceedings of The 3rd Human Computation Workshop ( HCOMP 2011 ) , August 2011 .","label":"Background","metadata":{},"score":"71.36858"}{"text":"ML ID : 78 .Information extraction systems process natural language documents and locate a specific set of relevant items .Given the recent success of empirical or corpus - based approaches in other areas of natural language processing , machine learning has the potential to significantly aid the development of these knowledge - intensive systems .","label":"Background","metadata":{},"score":"71.439095"}{"text":"Integrating Abduction and Induction in Machine Learning [ Details ] [ PDF ] Raymond J. Mooney In Working Notes of the IJCAI-97 Workshop on Abduction and Induction in AI , 37 - -42 , Nagoya , Japan , August 1997 .This paper discusses the integration of traditional abductive and inductive reasoning methods in the development of machine learning systems .","label":"Background","metadata":{},"score":"71.78691"}{"text":"ML ID : 313 .Transcribing documents from the printing press era , a challenge in its own right , is more complicated when documents interleave multiple languages - a common feature of 16th century texts .Additionally , many of these documents precede consistent orthographic conventions , making the task even harder .","label":"Background","metadata":{},"score":"71.92204"}{"text":"ML ID : 222 .Learning to Sportscast : A Test of Grounded Language Acquisition [ Details ] [ PDF ] [ Slides ] [ Video ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th International Conference on Machine Learning ( ICML ) , Helsinki , Finland , July 2008 .","label":"Background","metadata":{},"score":"72.15723"}{"text":"ML ID : 222 .Learning to Sportscast : A Test of Grounded Language Acquisition [ Details ] [ PDF ] [ Slides ] [ Video ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th International Conference on Machine Learning ( ICML ) , Helsinki , Finland , July 2008 .","label":"Background","metadata":{},"score":"72.15723"}{"text":"ILP , which investigates the learning of relational ( first - order ) rules , provides an empirical method for acquiring knowledge within traditional , symbolic parsing frameworks .This dissertation details the architecture , implementation and evaluation of CHILL a computer system for acquiring natural language parsers by training over corpora of parsed text .","label":"Background","metadata":{},"score":"72.22748"}{"text":"ILP , which investigates the learning of relational ( first - order ) rules , provides an empirical method for acquiring knowledge within traditional , symbolic parsing frameworks .This dissertation details the architecture , implementation and evaluation of CHILL a computer system for acquiring natural language parsers by training over corpora of parsed text .","label":"Background","metadata":{},"score":"72.22748"}{"text":"This paper reviews our prior work on this topic and discusses directions for future research .ML ID : 196 .Association for Computational Linguistics .We present a new approach for mapping natural language sentences to their formal meaning representations using string - kernel - based classifiers .","label":"Background","metadata":{},"score":"72.262634"}{"text":"This paper reviews our prior work on this topic and discusses directions for future research .ML ID : 196 .Association for Computational Linguistics .We present a new approach for mapping natural language sentences to their formal meaning representations using string - kernel - based classifiers .","label":"Background","metadata":{},"score":"72.262634"}{"text":"ML ID : 315 .Solving the visual symbol grounding problem has long been a goal of artificial intelligence .The field appears to be advancing closer to this goal with recent breakthroughs in deep learning for natural language grounding in static images .","label":"Background","metadata":{},"score":"72.44348"}{"text":"We compare the performance of this approach with the adaptive probabilistic networks technique on a real - world classification problem in molecular biology , and show that our approach trains faster and learns networks with higher classification accuracy .ML ID : 70 .","label":"Background","metadata":{},"score":"73.38924"}{"text":"By allowing both approaches to induce program clauses and choosing the best combination of their results , Cocktail learns more effective parsers .Experimental results on learning natural - language interfaces for two databases demonstrate that it learns more accurate parsers than Chillin , the previous best method for this task .","label":"Background","metadata":{},"score":"73.44212"}{"text":"By allowing both approaches to induce program clauses and choosing the best combination of their results , Cocktail learns more effective parsers .Experimental results on learning natural - language interfaces for two databases demonstrate that it learns more accurate parsers than Chillin , the previous best method for this task .","label":"Background","metadata":{},"score":"73.44212"}{"text":"The effectiveness of the proposed techniques is demonstrated on real and simulated datasets , on which they prove to be more accurate than non - adaptive blocking methods .ML ID : 195 .Poster Session .As Internet worms become ever faster and more sophisticated , it is important to be able to extract worm signatures in an accurate and timely manner .","label":"Background","metadata":{},"score":"73.728714"}{"text":"Also appears as Technical Report AI07 - 343 , Artificial Intelligence Lab , University of Texas at Austin , August 2007 .One of the main goals of natural language processing ( NLP ) is to build automated systems that can understand and generate human languages .","label":"Background","metadata":{},"score":"73.759895"}{"text":"Also appears as Technical Report AI07 - 343 , Artificial Intelligence Lab , University of Texas at Austin , August 2007 .One of the main goals of natural language processing ( NLP ) is to build automated systems that can understand and generate human languages .","label":"Background","metadata":{},"score":"73.759895"}{"text":"Also appears as Technical Report AI07 - 343 , Artificial Intelligence Lab , University of Texas at Austin , August 2007 .One of the main goals of natural language processing ( NLP ) is to build automated systems that can understand and generate human languages .","label":"Background","metadata":{},"score":"73.759895"}{"text":"These results open the possibility of applying machine learning to build a fast and accurate online worm fingerprinting system .ML ID : 194 .Learnable Similarity Functions and Their Application to Record Linkage and Clustering [ Details ] [ PDF ] Mikhail Bilenko PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2006 .","label":"Background","metadata":{},"score":"74.5004"}{"text":"ML ID : 301 .Probabilistic Soft Logic ( PSL ) is a recently developed framework for probabilistic logic .We use PSL to combine logical and distributional representations of natural - language meaning , where distributional information is represented in the form of weighted inference rules .","label":"Background","metadata":{},"score":"75.26892"}{"text":"Panning for Gold : Finding Relevant Semantic Content for Grounded Language Learning [ Details ] [ PDF ] [ Slides ] David L. Chen and Raymond J. Mooney In Proceedings of Symposium on Machine Learning in Speech and Language Processing ( MLSLP 2011 ) , June 2011 .","label":"Background","metadata":{},"score":"75.5428"}{"text":"Learning for semantic parsing is part of our research on natural language learning .\" The fish trap exists because of the fish .Once you 've gotten the fish you can forget the trap .The rabbit snare exists because of the rabbit .","label":"Background","metadata":{},"score":"75.729935"}{"text":"We will explore the issue of distinguishing relevant and irrelevant messages , since currently RAPIER only extracts from the any messages given to it , assuming that all are relevant .We also intend to run much larger tests with RAPIER on multiple domains including the terrorism domain from the third and fourth Message Uncderstanding Conferences , which will allow comparison against other systems .","label":"Background","metadata":{},"score":"75.94779"}{"text":"We will explore the issue of distinguishing relevant and irrelevant messages , since currently RAPIER only extracts from the any messages given to it , assuming that all are relevant .We also intend to run much larger tests with RAPIER on multiple domains including the terrorism domain from the third and fourth Message Uncderstanding Conferences , which will allow comparison against other systems .","label":"Background","metadata":{},"score":"75.94779"}{"text":"By using a learned lexicon to refine inferred plans and a supervised learner to induce a semantic parser , the system is able to automatically learn to correctly interpret a reasonable fraction of the complex instructions in this corpus .ML ID : 264 .","label":"Background","metadata":{},"score":"76.82368"}{"text":"ML ID : 304 .Using Markov logic to integrate logical and distributional information in natural - language semantics results in complex inference problems involving long , complicated formulae .Current inference methods for Markov logic are ineffective on such problems .","label":"Background","metadata":{},"score":"77.2398"}{"text":"ML ID : 222 .Recognizing visual scenes and activities is challenging : often visual cues alone are ambiguous , and it is expensive to obtain manually labeled examples from which to learn .To cope with these constraints , we propose to leverage the text that often accompanies visual data to learn robust models of scenes and actions from partially labeled collections .","label":"Background","metadata":{},"score":"77.70253"}{"text":"We also discuss challenges that arise when employing current information extraction technology to discover knowledge in text .ML ID : 170 .This paper presents the results of a large - scale effort to construct a comprehensive database of known human protein interactions by combining and linking known interactions from existing databases and then adding to them by automatically mining additional interactions from 750,000 Medline abstracts .","label":"Background","metadata":{},"score":"78.12671"}{"text":"ML ID : 107 .The development of natural language interfaces ( NLI 's ) for databases has been a challenging problem in natural language processing ( NLP ) since the 1970 's .The need for NLI 's has become more pronounced due to the widespread access to complex databases now available through the Internet .","label":"Background","metadata":{},"score":"78.63811"}{"text":"ML ID : 184 .Fast and Effective Worm Fingerprinting via Machine Learning [ Details ] [ PDF ] Stewart Yang , Jianping Song , Harish Rajamani , Taewon Cho , Yin Zhang and Raymond Mooney Technical Report AI-06 - 335 , Artificial Intelligence Lab , The University of Texas at Austin , August 2006 .","label":"Background","metadata":{},"score":"78.85322"}{"text":"ML ID : 188 .We present a novel statistical approach to semantic parsing , WASP , for constructing a complete , formal meaning representation of a sentence .A semantic parser is learned given a set of sentences annotated with their correct meaning representations .","label":"Background","metadata":{},"score":"79.59212"}{"text":"Experimental results show the improvements obtained over the purely supervised parser , particularly when the annotated training set is small .ML ID : 198 .This paper explores the use of statistical machine translation ( SMT ) methods for tactical natural language generation .","label":"Background","metadata":{},"score":"81.25868"}{"text":"Experimental results show the improvements obtained over the purely supervised parser , particularly when the annotated training set is small .ML ID : 198 .This paper explores the use of statistical machine translation ( SMT ) methods for tactical natural language generation .","label":"Background","metadata":{},"score":"81.25868"}{"text":"Experimental results show the improvements obtained over the purely supervised parser , particularly when the annotated training set is small .ML ID : 198 .This paper explores the use of statistical machine translation ( SMT ) methods for tactical natural language generation .","label":"Background","metadata":{},"score":"81.25868"}{"text":"ML ID : 251 .In this paper we consider the problem of building a system to predict readability of natural - language documents .Our system is trained using diverse features based on syntax and language models which are generally indicative of readability .","label":"Background","metadata":{},"score":"82.69217"}{"text":"ML ID : 251 .In this paper we consider the problem of building a system to predict readability of natural - language documents .Our system is trained using diverse features based on syntax and language models which are generally indicative of readability .","label":"Background","metadata":{},"score":"82.69217"}{"text":"Finally , we propose investigating the interface between models of event co - occurrence and coreference resolution , in particular by integrating script information into general coreference systems .ML ID : 326 .Natural Language Video Description using Deep Recurrent Neural Networks [ Details ] [ PDF ] [ Slides ] Subhashini Venugopalan November 2015 .","label":"Background","metadata":{},"score":"82.813065"}{"text":"Our experimental evaluation proves that Stacking is useful for ensembling SF systems .We demonstrate new state - of - the - art results for KBP ESF task .Our proposed system achieves an F1 score of 47 .Given the complexity of developing Slot Filling systems from scratch , our promising results indicate that performance on Slot Filling tasks can be increased by ensembling existing systems in shorter timeframe .","label":"Background","metadata":{},"score":"83.23874"}{"text":"ML ID : 305 .This paper integrates techniques in natural language processing and computer vision to improve recognition and description of entities and activities in real - world videos .We propose a strategy for generating textual descriptions of videos by using a factor graph to combine visual detections with language statistics .","label":"Background","metadata":{},"score":"84.871506"}{"text":"ML ID : 130 .We present results from a variety of learned information extraction systems for identifying human protein names in Medline abstracts and subsequently extracting interactions between the proteins .We demonstrate that machine learning approaches using support vector machines and hidden Markov models are able to identify human proteins with higher accuracy than several previous approaches .","label":"Background","metadata":{},"score":"85.59018"}{"text":"The rabbit snare exists because of the rabbit .Once you 've gotten the rabbit , you can forget the snare .Words exist because of meaning .Once you 've gotten the meaning , you can forget the words .","label":"Background","metadata":{},"score":"87.03148"}{"text":"The attributes used were split into two categories : color attributes and other attributes .Our proposed model was found to be statistically significantly more accurate than the vision system alone for both sets of attributes .ML ID : 302 .","label":"Background","metadata":{},"score":"89.71575"}{"text":"To reduce annotation effort while maintaining accuracy , we apply active learning to semantic lexicons .We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance .ML ID : 121 .","label":"Background","metadata":{},"score":"90.39762"}{"text":"To reduce annotation effort while maintaining accuracy , we apply active learning to semantic lexicons .We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance .ML ID : 121 .","label":"Background","metadata":{},"score":"90.39762"}{"text":"We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision , and shows better robustness to variations in task complexity and word order .ML ID : 187 .","label":"Background","metadata":{},"score":"93.94365"}{"text":"We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision , and shows better robustness to variations in task complexity and word order .ML ID : 187 .","label":"Background","metadata":{},"score":"93.94365"}{"text":"We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision , and shows better robustness to variations in task complexity and word order .ML ID : 187 .","label":"Background","metadata":{},"score":"93.94365"}{"text":"Using these models , natural language systems will be able to infer a more comprehensive semantic relations , which in turn may yield improved systems for question answering , text classification , machine translation , and information retrieval .ML ID : 309 .","label":"Background","metadata":{},"score":"94.10014"}{"text":"Using these models , natural language systems will be able to infer a more comprehensive semantic relations , which in turn may yield improved systems for question answering , text classification , machine translation , and information retrieval .ML ID : 309 .","label":"Background","metadata":{},"score":"94.10014"}