{"text":"It differentiates from most of the previous approaches mainly in three respects .First of all , while theoretical linguists have defined Chinese words with various linguistic criteria , Chinese words in this study are defined pragmatically as segmentation units whose definition depends on how they are used and processed in realistic computer applications .","label":"CompareOrContrast","metadata":{},"score":"27.40871"}
{"text":"doi : 10.1145/772755.772758 .Nie , J. , Gao , J. , Zhang , J. , & Zhou , M. ( 2000 ) .On the use of words and n - grams for Chinese information retrieval .In Proceedings of the fifth international workshop on on Information retrieval with Asian languages ( pp .","label":"CompareOrContrast","metadata":{},"score":"27.616343"}
{"text":"doi : 10.1145/772755.772758 .Nie , J. , Gao , J. , Zhang , J. , & Zhou , M. ( 2000 ) .On the use of words and n - grams for Chinese information retrieval .In Proceedings of the fifth international workshop on on Information retrieval with Asian languages ( pp .","label":"CompareOrContrast","metadata":{},"score":"27.616343"}
{"text":"It differs from most previous approaches mainly in three respects .First , while theoretical linguists have defined Chinese words using various linguistic criteria , Chinese words in this study are defined pragmatically as segmentation units whose definition depends on how they are used and processed in realistic computer applications .","label":"CompareOrContrast","metadata":{},"score":"27.896502"}
{"text":"For further discussion of Chinese word segmentation , see Tseng et al .( 2005 ) , Sproat and Emerson ( 2003 ) , Sproat et al .( 1996 ) , and Gao et al .( 2005 ) .Language identification was perhaps first explored in cryptography ; for example , Konheim ( 1981 ) presents a character - level -gram language identification algorithm .","label":"CompareOrContrast","metadata":{},"score":"29.10725"}
{"text":"First , while theoretical linguists have defined Chinese words using various linguistic criteria , Chinese words in this study are defined pragmatically as segmentation units whose definition depends on how they are used and processed in realistic computer applications .Second , we propose a pragmatic mathematical framework in which segmenting known words and detecting unknown words of different types ( i.e. , morphologically derived words , factoids , named entities , and other unlisted words ) can be performed simultaneously in a unified way .","label":"CompareOrContrast","metadata":{},"score":"29.782936"}
{"text":"This article presents a pragmatic approach to Chinese word segmentation .It differs from most previous approaches mainly in three respects .First , while theoretical linguists have defined Chinese words using various linguistic criteria , Chinese words in this study are defined pragmatically as segmentation units whose definition depends on how they are used and processed in realistic computer applications .","label":"CompareOrContrast","metadata":{},"score":"32.569374"}
{"text":"These tasks are usually conducted separately in other systems .Finally , we do not assume the existence of a universal word segmentation standard which is application independent .Instead , we argue for the necessity of multiple segmentation standards due to the pragmatic fact that different NLP applications might require different granularities of Chinese words .","label":"CompareOrContrast","metadata":{},"score":"32.755344"}
{"text":"Finally , we do not assume the existence of a universal word segmentation standard that is application - independent .Instead , we argue for the necessity of multiple segmentation standards due to the pragmatic fact that different natural language processing applications might require different granularities of Chinese words .","label":"CompareOrContrast","metadata":{},"score":"33.11252"}
{"text":"Therefore , identification of a new word is very simple and effective , so that the OOV problem can be avoided , which is inevitable in the previous methods .[ 0018 ] As analyzed by Wu , A. in Customizable Segmentation of Morphologically Derived Words in Chinese .","label":"CompareOrContrast","metadata":{},"score":"33.47699"}
{"text":"[0004 ] Word segmentation approaches for Chinese words primarily need to solve two issues in Chinese Natural Language Processing ( NLP ) , that is , what a word is in Chinese , and how a computer identifies automatically a Chinese word .","label":"CompareOrContrast","metadata":{},"score":"33.52264"}
{"text":"In n - gram based matching ( Angell et al . , 1983 ; Hall and Dowling , 1980 ; Pfeifer et al ., 1996 ; Robertson and Willett , 1998 ; Salton , 1989 ; Zobel and Dart , 1995 ) , text strings are decomposed into n - grams , i.e. , substrings of length n , which usually consist of the adjacent characters of the text strings .","label":"CompareOrContrast","metadata":{},"score":"33.875206"}
{"text":"These tasks are usually conducted separately in other systems .Finally , we do not assume the existence of a universal word segmentation standard that is application - independent .Instead , we argue for the necessity of multiple segmentation standards due to the pragmatic fact that different natural language processing applications might require different granularities of Chinese words .","label":"CompareOrContrast","metadata":{},"score":"35.162945"}
{"text":"These tasks are usually conducted separately in other systems .Finally , we do not assume the existence of a universal word segmentation standard that is application - independent .Instead , we argue for the necessity of multiple segmentation standards due to the pragmatic fact that different natural language processing applications might require different granularities of Chinese words .","label":"CompareOrContrast","metadata":{},"score":"35.162945"}
{"text":"As the Web prospers , it brings new opportunities to solve many previously \" unsolvable \" problems .In this paper , we propose to leverage the Web and search technology to segment Chinese words .Its typical advantages include : . 1 ) Free from the Out - of - Vocabulary ( OOV ) problem , and this is a typical feature of leveraging the Web documents . 2 ) Adaptive to different segmentation standards since ideally we can obtain all valid character sequences by searching the Web . 3 ) Can be entirely unsupervised that need no training corpora .","label":"CompareOrContrast","metadata":{},"score":"35.387775"}
{"text":"3 and FIG .4 . FIG .3 depicts a flow chart of an example of the search - based word segmentation method according to the embodiment of the invention .As illustrated in FIG .3 , firstly in step S1101 , a document S is input , e.g. a Chinese document .","label":"CompareOrContrast","metadata":{},"score":"35.493385"}
{"text":"This paper presents a pragmatic approach to Chinese word segmentation .It differentiates from most of the previous approaches mainly in three respects .First of all , while theoretical linguists have defined Chinese words with various linguistic criteria , Chinese words in this study are defined pragm ... \" .","label":"CompareOrContrast","metadata":{},"score":"35.706947"}
{"text":"[ 1 ] Chinese word segmentation is an open problem in the research literature .Native speakers do not necessarily agree on how to segment groups of characters into words ( Sproat , Shih , Gale , & Chang , 1994 ; Wu & Fung , 1994 .","label":"CompareOrContrast","metadata":{},"score":"36.252377"}
{"text":"[ 1 ] Chinese word segmentation is an open problem in the research literature .Native speakers do not necessarily agree on how to segment groups of characters into words ( Sproat , Shih , Gale , & Chang , 1994 ; Wu & Fung , 1994 .","label":"CompareOrContrast","metadata":{},"score":"36.252377"}
{"text":"Vol . 8 , No . 1 , Feb. 2003 , pp . 1 - 28 , for instance , different applications expect different word segmentation units , and even native speakers of Chinese would disagree on whether a given character string is a word .","label":"CompareOrContrast","metadata":{},"score":"37.967125"}
{"text":"Firstly , the system segments character strings in ideographic language ( e.g. , Chinese ) into word sequences and identifies accurately unregistered entities , such as the name of a person , organization , place , and so on .Further examples of named entities are given hereinafter .","label":"CompareOrContrast","metadata":{},"score":"38.1449"}
{"text":"Consider an extreme case that the local segmentor segments each sentences into unigrams , intuitively , segments collected will still be n - grams since the unigrams neighbor each other in the retrieved documents as they are written in natural language .","label":"CompareOrContrast","metadata":{},"score":"38.16144"}
{"text":"Instead of using a non - iterative segmentation - mergingfiltering -and - disambiguation approach , the proposed method iteratively integrates the contextual constraints ... \" .An unsupervised iterative approach for extracting a new lexicon ( or unknown words ) from a Chinese text corpus is proposed in this paper .","label":"CompareOrContrast","metadata":{},"score":"38.203102"}
{"text":"Instead of using a non - iterative segmentation - mergingfiltering -and - disambiguation approach , the proposed method iteratively integrates the contextual constraints ... \" .An unsupervised iterative approach for extracting a new lexicon ( or unknown words ) from a Chinese text corpus is proposed in this paper .","label":"CompareOrContrast","metadata":{},"score":"38.203102"}
{"text":"There are many possible future works , such as finding more effective scoring methods , combining current approach to other types of segmentation methods to give a better performance , etc . .REFERENCES .[ 1 ] Gao , J.F. , Li , M. , Wu A. , Huang , C.N. Chinese Word Segmentation and Named Entity Recognition : A Pragmatic Approach .","label":"CompareOrContrast","metadata":{},"score":"38.29978"}
{"text":"As can be seen from the above aspects , the invention may be advantageous in the following .[ 0015 ] Unlike previous dictionary - based method or statistical learning method , the invention uses a search technology for word segmentation of a language without a word boundary , such as Chinese .","label":"CompareOrContrast","metadata":{},"score":"38.844345"}
{"text":"In the technique , s - grams are classified into categories on the basis of the number of skipped characters , and only the s - grams belonging to the same category are compared with one another .We will demonstrate that the technique is effective for many types of word form variants .","label":"CompareOrContrast","metadata":{},"score":"39.391994"}
{"text":"For instance , one might identify a string as a unit but fail to identify that it is a person name .Second , ... . by Andi Wu - in Proceedings of the 2 nd Chinese Language Processing Workshop , 2000 . \" ...","label":"CompareOrContrast","metadata":{},"score":"39.402584"}
{"text":"In this study , we classified s - grams on the basis of character contiguity .It may be possible to improve the technique by utilizing information on s - gram locations in words .The method could be further improved by taking into account s - gram frequencies .","label":"CompareOrContrast","metadata":{},"score":"39.55597"}
{"text":"We present a novel n - gram based string matching technique , which we call the targeted s - gram matching technique .In the technique , n - grams are classified into categories on the basis of character contiguity in words .","label":"CompareOrContrast","metadata":{},"score":"39.59557"}
{"text":"Chinese word segmentation is a widely requested Chinese information processing step .In this paper , we propose a novel solution which leverages the Web data and search technology .It contains three steps : 1 ) collecting segments from search results , 2 ) scoring segments , and 3 ) ranking segmentations .","label":"CompareOrContrast","metadata":{},"score":"40.089157"}
{"text":"Most existing Chinese word segmentation approaches are either statistics - based or dictionary - based .The pure statistical method has lower precision , while the pure dictionary - based method can not deal with new words beyond the dictionary .In this paper , we propose a hybrid method that is able to avoid the limitations of both types of approaches .","label":"CompareOrContrast","metadata":{},"score":"40.50743"}
{"text":"Huang et.al .( 2003 ) , Peng et.al .( 2002 ) , and Kwok ( 1999 ) also explain that breaking a larger word into bigrams acts similarly to decompounding in European languages as constituents of larger words often have related meanings .","label":"CompareOrContrast","metadata":{},"score":"40.601707"}
{"text":"Huang et.al .( 2003 ) , Peng et.al .( 2002 ) , and Kwok ( 1999 ) also explain that breaking a larger word into bigrams acts similarly to decompounding in European languages as constituents of larger words often have related meanings .","label":"CompareOrContrast","metadata":{},"score":"40.601707"}
{"text":"Recent heavy activity in this area has shown the biggest stumbling block to be words that are absent from the lexicon , since successful tokenizers to date have been bas ... \" .The first step in Chinese NLP is to tokenize or segment character sequences into words , since the text contains no word delimiters .","label":"CompareOrContrast","metadata":{},"score":"40.930557"}
{"text":"The system also acts as a name recognizer to determine boundaries and categories of names in text .A name can consist of one or more words .Because there are no capitalized features of names in ideographic languages , e.g. Chinese , the process of determining boundaries of names is difficult .","label":"CompareOrContrast","metadata":{},"score":"41.217148"}
{"text":"Given an ideographic language ( e.g. , Chinese ) text corpus , categorised name corpus and a word list that contains all ideographic characters and some proper names as seeds , the system is used to perform tokenization and name recognition .","label":"CompareOrContrast","metadata":{},"score":"41.250587"}
{"text":"This article presents a pragmatic approach to Chinese word segmentation .It differs from most previous approaches mainly in three respects .First , while theoretical linguists have defined Chinese words using various linguistic criteria , Chinese words in this study are defined pragmatically as segmen ... \" .","label":"CompareOrContrast","metadata":{},"score":"41.371292"}
{"text":"It differs from most previous approaches mainly in three respects .First , while theoretical linguists have defined Chinese words using various linguistic criteria , Chinese words in this study are defined pragmatically as segmen ... \" .This article presents a pragmatic approach to Chinese word segmentation .","label":"CompareOrContrast","metadata":{},"score":"41.661243"}
{"text":"This paper describes a hybrid model that combines machine learning with linguistic heuristics for integrating unknown word identification with Chinese word segmentation .The model consists of two components : a position - of - character ( POC ) tagging component that annotates each character in a sentence with a POC tag that indicates its position in a word , and a merging component that transforms a POCtagged character sequence into a word - segmented sentence .","label":"CompareOrContrast","metadata":{},"score":"41.949596"}
{"text":"However , it can be seen by viewing a source file of an HTML file that this search engine indexes only each part of this n - gram .As can be seen from this example , the candidate word segmentation units will not be affected by the local segmentation model of a search engine .","label":"CompareOrContrast","metadata":{},"score":"42.010567"}
{"text":"The X - axis of the lattice represents time intervals , and the Y - axis represents individual samples .For the case of Chinese segmentation and entity recognition , the time intervals correspond to character orders in the sentence .Samples correspond to words starting with the characters .","label":"CompareOrContrast","metadata":{},"score":"42.366913"}
{"text":"A typical operation process of a search engine is as following .The search engine preliminarily segmented a submitted query into a set of terms based upon the query .These terms are either n - grams or are based upon a local segmentation model as adopted by this search engine .","label":"CompareOrContrast","metadata":{},"score":"42.378006"}
{"text":"[ 4 ] Xue , N.W. Chinese Word Segmentation as Character Tagging .Computational Linguistics and Chinese Language Processing .Vol . 8 , No . 1 , Feb. 2003 , pp.29 - 48 .Tools . by Jing - shin Chang , Keh - yih Su - International Journal of Computational Linguistics & amp ; Chinese Language Processing , 1997 . \" ...","label":"CompareOrContrast","metadata":{},"score":"42.4318"}
{"text":"Fu , G. , Kit , C. , & Webster , J. J. ( 2008 ) .Chinese word segmentation as morpheme - based lexical chunking .Information Sciences , 178(9 ) , 2282 - 2296 .doi : 10.1016/j.ins.2008.01.001 .","label":"CompareOrContrast","metadata":{},"score":"42.447514"}
{"text":"ACM 978 - 1 - 59593 - 654 - 7/07/0005 .ABSTRACT .In this paper , we propose a novel Chinese word segmentation method which leverages the huge deposit of Web documents and search technology .It simultaneously solves ambiguous phrase boundary resolution and unknown word identification problems .","label":"CompareOrContrast","metadata":{},"score":"42.5867"}
{"text":"The technique was highly effective also for monolingual word form variants .The effects of query key length and the length of the longest common subsequence ( LCS ) of the variants on the performance of s - grams were analyzed .","label":"CompareOrContrast","metadata":{},"score":"42.979355"}
{"text":"It can also identify new words through MI - based token merging and dictionary updating .In addition , with the proposed Improved Bigram method IASeg can process N - grams .To evaluate the Multilingual Issues Part 1 : Word Segmentation .","label":"CompareOrContrast","metadata":{},"score":"43.622425"}
{"text":"However , the classification of s - grams on the basis of character contiguity , and matching based on the s - gram categories is a novel idea .Also the perspectives adopted in this study on the issue , and the research problems we will explore are novel .","label":"CompareOrContrast","metadata":{},"score":"43.939148"}
{"text":"The most common n - grams are uni - grams and bi - grams , but other n - grams may also be practised .Thus , the language - model training branch generates word N - gram statistics , word classes , and a class n - gram language model from the segmented text / name corpus 110 .","label":"CompareOrContrast","metadata":{},"score":"44.06978"}
{"text":"0007 ] Statistical machine learning methods are word segmentation methods for text using probabilities or a cost - based scoring mechanism instead of dictionaries .Consequently , this type of approaches generally requires large annotated Chinese corpora for model training , and more importantly , it lacks the flexibility to be adapted to different segmentation standards .","label":"CompareOrContrast","metadata":{},"score":"44.090263"}
{"text":"doi:10.1016/S0306 - 4573(02)00079 - 1 .Fu , G. , Kit , C. , & Webster , J. J. ( 2008 ) .Chinese word segmentation as morpheme - based lexical chunking .Information Sciences , 178(9 ) , 2282 - 2296 .","label":"CompareOrContrast","metadata":{},"score":"44.312187"}
{"text":"In fact , for Eng2 words , the precision of baseline n - grams is slightly better than that of s - grams .For the medium length words performance improvements are substantial for both lists .In a few cases , however , the use of s - grams yields substantial performance improvements .","label":"CompareOrContrast","metadata":{},"score":"44.427456"}
{"text":"Firstly , unlike English , there are no boundaries between words in Chinese text .For example , a sentence is often a contiguous string of ideograms , where one or more ideograms may form a word , without spaces between \" words \" .","label":"CompareOrContrast","metadata":{},"score":"44.451508"}
{"text":"This mechanism avoids the sparse data problem of pure statistical approaches and the over - g ... \" .This paper presents a mechanism of new word identification in Chinese text where probabilities are used to filter candidate character strings and to assign POS to the selected strings in a ruled - based system .","label":"CompareOrContrast","metadata":{},"score":"44.532074"}
{"text":"Experiments o ... \" .We propose a self - supervised word segmentation technique for text segmentation in Chinese information retrieval .This method combines the advantages of traditional dictionary based , character based and mutual information based approaches , while overcoming many of their shortcomings .","label":"CompareOrContrast","metadata":{},"score":"44.63595"}
{"text":"To create word classes that correspond to the categories of name entities , different categories of named entities can be selected as representative seeds and added into the lexicon for automatic word classification to create word classes of these proper names .","label":"CompareOrContrast","metadata":{},"score":"44.64266"}
{"text":"Naomi Exhaustive discussion of the character - level processing of can be found in Lunde ( 1998 ) .Character bigram indexes are perhaps the most standard approach to indexing Chinese , although some systems use word segmentation .Due to differences in the language and writing system , word segmentation is most usual for Japanese ( Luk and Kwok , 2002 , Kishida et al . , 2005 ) .","label":"CompareOrContrast","metadata":{},"score":"44.70196"}
{"text":"The effectiveness of the targeted s - gram matching : The targeted s - gram matching technique was compared with the conventional n - gram technique using adjacent characters as n - grams ( digrams and trigrams ) .Also unclassified s - grams were tested .","label":"CompareOrContrast","metadata":{},"score":"45.010197"}
{"text":"Chinese text into dictionary entries and productively derived words , and providing pronunciations for these words ; the method incorporates a class - based model in its treatment of personal names .We also evaluate the system 's performance , taking into account the fact that people often do not agree on a single seg- mentation . \" ...","label":"CompareOrContrast","metadata":{},"score":"45.04369"}
{"text":"Comput .Linguist . , 30(1 ) , 75 - 93 .Foo , S. , & Li , H. ( 2004 ) .Chinese word segmentation and its effect on information retrieval .Information Processing & Management , 40(1 ) , 161 - 190 .","label":"CompareOrContrast","metadata":{},"score":"45.045715"}
{"text":"We will investigate the effectiveness of digrams combined both of adjacent and non - adjacent characters of words .These kinds of n - grams we call s - grams ( where s refers to the term skip ) .We assumed that for cross - lingual spelling variants s - grams may be more effective than n - grams combined of adjacent characters only , because variant forms may share just a few ( 1 - 2 ) digrams formed of adjacent characters , or no digrams at all if the words are very short .","label":"CompareOrContrast","metadata":{},"score":"45.0774"}
{"text":"We seek a knowledge - free method for inducing multiword units from text corpora for use as machine - readable dictionary headwords .We provide two major evaluations of nine existing collocation - finders and illustrate the continuing need for improvement .","label":"CompareOrContrast","metadata":{},"score":"45.258667"}
{"text":"We seek a knowledge - free method for inducing multiword units from text corpora for use as machine - readable dictionary headwords .We provide two major evaluations of nine existing collocation - finders and illustrate the continuing need for improvement .","label":"CompareOrContrast","metadata":{},"score":"45.258667"}
{"text":"Chinese word segmentation , search .INTRODUCTION .Automatic Chinese word segmentation is an important technique for many areas including speech synthesis , text categorization , etc [ 3].It is challenging because 1 ) there is no standard definition of words in Chinese , 2 ) word boundaries are not marked by spaces .","label":"CompareOrContrast","metadata":{},"score":"45.345192"}
{"text":"The statistical decoder module 230 produces and outputs the segmented text / name corpus 250 .The decoding module 200 processes text sentence - by - sentence in two stages .Given a ideographic language ( e.g. , Chinese ) sentence , the module 200 finds all possible segmentations of the sentence and makes -hypotheses on possible named entity boundaries and named entity classes .","label":"CompareOrContrast","metadata":{},"score":"45.89506"}
{"text":"Using SIGHAN 2005 Competition ( SIGHAN Workshop 2005 .Moreover , these results have to be compared separately under four segmentation standards ( namely MSR , PKU , CityU and MSRA ) .This brings a problem to the development in corpuses that can be used in training of different types of NLP systems , and also poses a challenge to the Chinese word segmentation system that can support multi - user application .","label":"CompareOrContrast","metadata":{},"score":"46.00173"}
{"text":"Using the produced lattices , the module 200 then combines entity models 152B with a contextual model 152A in the statistical decoder module 230 to decide word boundaries and entity categories .Using the contextual model 152A and the entity models 152B , the statistical decoder module 230 goes through all these word arrangements of the lattice and finds the most probable word arrangement and entity category , if any .","label":"CompareOrContrast","metadata":{},"score":"46.05443"}
{"text":"Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics , 66 - 73 .Teahan , W. J. , McNab , R. , Wen , Y. , & Witten , I. H. ( 2000 ) .A compression - based algorithm for chinese word segmentation .","label":"CompareOrContrast","metadata":{},"score":"46.056305"}
{"text":"Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics , 66 - 73 .Teahan , W. J. , McNab , R. , Wen , Y. , & Witten , I. H. ( 2000 ) .A compression - based algorithm for chinese word segmentation .","label":"CompareOrContrast","metadata":{},"score":"46.056305"}
{"text":"[ 0006 ] In dictionary - based methods , a predefined dictionary is used along with artificial grammar rules .In such dictionary - based methods , sentences are segmented in accordance with the dictionaries , and the grammar rules are used to improve the performance .","label":"CompareOrContrast","metadata":{},"score":"46.38788"}
{"text":"( 1 ) Run the decoder module ( 200 of FIG .2 ) as a segmentor and segment the characterstring text and name corpus into word - string format .A single text corpus can be used , which preferably is a collection of materials from newspapers , magazines , books , etc .","label":"CompareOrContrast","metadata":{},"score":"46.699608"}
{"text":"In this paper , we present a similarity - based framework to model the task of backward transliteration , and provide a learning algorithm to automatically acquire phonetic similarities from a corpus .The learning algorithm is based on Widrow - Hoff rule with some modifications .","label":"CompareOrContrast","metadata":{},"score":"46.80867"}
{"text":"In this paper we show that , for Chinese , the relationship between segmentation and retrieval performance is in fact nonmonotonic ; that is , at around 70 % word se ... \" .It is commonly believed that word segmentation accuracy is monotonically related to retrieval performance in Chinese information retrieval .","label":"CompareOrContrast","metadata":{},"score":"46.861153"}
{"text":"More importantly , the class - based language model creates word classes that associate proper names or named entities .These entity classes play an important role in the decoding module 200 for disambiguation of named - entity categories .The training branch including modules 130 and 140 is applicable to both a contextual model and entity models .","label":"CompareOrContrast","metadata":{},"score":"47.03215"}
{"text":"However , for Chinese , we nd that the relationship between segmentation and retrieval performance is in fact nonmonotonic ; that is , at around 70 % word segmentation accuracy an over - segmentation phenomenon begins to occur which leads to a reduction in information retrieval performance .","label":"CompareOrContrast","metadata":{},"score":"47.03255"}
{"text":"Accessor variety criteria for Chinese word extraction .Comput .Linguist . , 30(1 ) , 75 - 93 .Foo , S. , & Li , H. ( 2004 ) .Chinese word segmentation and its effect on information retrieval .","label":"CompareOrContrast","metadata":{},"score":"47.32528"}
{"text":"The tokenization and named - entity recognition system segments character strings of ideographic language ( e.g. , Chinese , Korean , Japanese , and the like ) sentences into word form sentences .Tokenization is the process of determining the boundaries of meaningful units of a sentence(s ) in a given context for an ideographic language .","label":"CompareOrContrast","metadata":{},"score":"47.43663"}
{"text":"Jianfeng Gao , Andi Wu , Grapecity Inc , Mu Li , Chang - ning Huang - Computational Linguistics , 2005 . \" ...This article presents a pragmatic approach to Chinese word segmentation .It differs from most previous approaches mainly in three respects .","label":"CompareOrContrast","metadata":{},"score":"47.461098"}
{"text":"Unfortunately , in most of current systems , these two issues are considered to be two separate tasks , and hence are dealt with using different components in a cascaded or consecutive manner .However , some specific language natures of Chinese words result in that a major difficulty in Chinese word segmentation presents an output which can vary dependent upon different linguistic definitions of words and different engineering requirements .","label":"CompareOrContrast","metadata":{},"score":"47.7604"}
{"text":"After the automatic word clustering process , mappings between the entity categories can be built with some of the automatically created classes in which the representative seeds fall .Using the framework of n - gram models , entity models can be built by training the models with the segmented name entity corpus 110 .","label":"CompareOrContrast","metadata":{},"score":"47.786556"}
{"text":"0052 ] Finally in step S1107 , the optimal subset of word segmentation units is output as the way by which the query sentence is segmented .[0053 ] The features and advantages of the invention have been demonstrated fully as above , and hereinafter , two apparent advantages of the inventing will be further described by way of the following examples .","label":"CompareOrContrast","metadata":{},"score":"47.916058"}
{"text":"Therefore , the IBM Full - Parser segments into four independent word units , and .However , the new word can be identified correctly by the inventive method since the latter uses a set of documents , e.g. the Internet , and thus can be dynamic and updated in a real - time way .","label":"CompareOrContrast","metadata":{},"score":"48.012207"}
{"text":"Still further , the seeds can be manually selected .Other techniques of selecting the seeds can be utilized without departing from the scope and spirit of the invention .In step 414 , a word is selected from the word list from outside the classes ( for the case of 80,000 words , the word is selected from the remaining 80,000-N words ) , and the n - gram statistical data of the word is obtained .","label":"CompareOrContrast","metadata":{},"score":"48.036148"}
{"text":"In fact Huang et.al .( 2003 ) found that as segmentation accuracy increased above 70 % , information retrieval performance declined .They attribute this to the fact that poor segmentation will tend to break compound words into smaller constituents .","label":"CompareOrContrast","metadata":{},"score":"48.128067"}
{"text":"In fact Huang et.al .( 2003 ) found that as segmentation accuracy increased above 70 % , information retrieval performance declined .They attribute this to the fact that poor segmentation will tend to break compound words into smaller constituents .","label":"CompareOrContrast","metadata":{},"score":"48.128067"}
{"text":"MIT Press .[ 2 ] Platt , J. , Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods .Large Margin Classifiers , MIT Press , 1999 .[ 3 ] Sproat , R. , and Shih C. Corpus - based Methods in Chinese Morphology and Phonology .","label":"CompareOrContrast","metadata":{},"score":"48.13128"}
{"text":"Vietnamese separates syllables with spaces , so the default of splitting on whitespace produces something somewhat analogous to unigrams .Korean separates words with spaces but has issues similar to decompounding in European languages .[ 2 ] Linguists who study Chinese also disagree on word segmentation partly because of different theories on the concept of \" wordhood \" and partly because the appropriate segmentation may depend on the context of use .","label":"CompareOrContrast","metadata":{},"score":"48.161045"}
{"text":"Vietnamese separates syllables with spaces , so the default of splitting on whitespace produces something somewhat analogous to unigrams .Korean separates words with spaces but has issues similar to decompounding in European languages .[ 2 ] Linguists who study Chinese also disagree on word segmentation partly because of different theories on the concept of \" wordhood \" and partly because the appropriate segmentation may depend on the context of use .","label":"CompareOrContrast","metadata":{},"score":"48.161045"}
{"text":"Therefore , the down - weighting of high frequency s - grams seems a method worth testing .In some cases the extent of cross - lingual spelling variation is so high that no n - gram technique is able to fing right target language correspondents .","label":"CompareOrContrast","metadata":{},"score":"48.35502"}
{"text":"Abstract As the amount of online Chinese contents grows , there is a critical need for effective Chinese word segmentation approaches to facilitate Web computing applications in a range of domains including terrorism informatics .Most existing Chinese word segmentation approaches are either statistic ... \" .","label":"CompareOrContrast","metadata":{},"score":"48.43949"}
{"text":"S - digram types .Classified and unclassified s - digrams , and the following types of character combinations were tested in the study : .In the case of unclassified digrams no restrictions were set , but each digram of a query key was compared with each digram of TWL 's words .","label":"CompareOrContrast","metadata":{},"score":"48.44422"}
{"text":"In this paper we present Chinese word segmentation algorithms based on the socalled LMR tagging .Our LMR taggers are implemented with the Maximum Entropy Markov Model and we then use Transformation - Based Learning to combine the results of the two LMR taggers that scan the input in opposite directions .","label":"CompareOrContrast","metadata":{},"score":"48.5895"}
{"text":"p 65 . )[ 3 ]According to ( Wong et .al 2010 , p 61 )Sixty percent of word segementation errors result from unknown words .Emerson ( Emerson , 2000 ) gives a nice overview of word - based approaches and the various problems with out of vocabulary words including transliterations of foreign words and personal names .","label":"CompareOrContrast","metadata":{},"score":"48.59736"}
{"text":"p 65 . )[ 3 ]According to ( Wong et .al 2010 , p 61 )Sixty percent of word segementation errors result from unknown words .Emerson ( Emerson , 2000 ) gives a nice overview of word - based approaches and the various problems with out of vocabulary words including transliterations of foreign words and personal names .","label":"CompareOrContrast","metadata":{},"score":"48.59736"}
{"text":"\" Nymble : a High - Performance Learning Name - Finder \" cmp - lg/9803003 .Nam et al . \"A Local Grammar - based Approach to Recognising of Proper Names in Korean Text \" , Proceedings of Fifth Workshop on Very Large Corpora , pp273 - 288 , 1997 .","label":"CompareOrContrast","metadata":{},"score":"48.683586"}
{"text":"2010 ) provide a much more in - depth discussion , including an overview of the algorithms used in the word - based approaches as well as examples of ambiguity and unknown words .[ 4 ] Huang et.al .( 2003 , p 358 ) found that as segmentation accuracy increases over 70 % accuracy , that retrieval scores decline .","label":"CompareOrContrast","metadata":{},"score":"48.753654"}
{"text":"2010 ) provide a much more in - depth discussion , including an overview of the algorithms used in the word - based approaches as well as examples of ambiguity and unknown words .[ 4 ] Huang et.al .( 2003 , p 358 ) found that as segmentation accuracy increases over 70 % accuracy , that retrieval scores decline .","label":"CompareOrContrast","metadata":{},"score":"48.753654"}
{"text":"0008 ] Transformation - based methods are initially used in POS ( Part - of - Speech ) tagging and parsing .The main idea of these methods is to try to learn a set of n - gram rules from a training corpus and to apply them to segmentation of a new text .","label":"CompareOrContrast","metadata":{},"score":"48.77268"}
{"text":"We demonstrate this e ect by presenting an empirical investigation of information retrieval on Chinese TREC data , using a wide variety of word segmentation algorithms with word segmentation accuracies ranging from 44 % to 95 % .It appears that the main reason for the drop in retrieval performance is that correct compounds and collocations are preserved by accurate segmenters , while they are broken up by less accurate ( but reasonable ) segmenters , to a surprising advantage .","label":"CompareOrContrast","metadata":{},"score":"48.853024"}
{"text":"This paper describes a general scheme for segmenting text by inferring the position of word boundaries , thus supplying a necessary preprocessing step for applications like those mentioned above .Unlike other approaches , which involve a dictionary of legal words and are therefore language - specific , i ... \" .","label":"CompareOrContrast","metadata":{},"score":"48.866035"}
{"text":"However , little activity has been reported for ideographic languages such as Chinese .In an ideographic language , a word is made of one or more ideograms , where each ideogram is a symbol representing something such as an object or idea without expressing its sound(s ) .","label":"CompareOrContrast","metadata":{},"score":"48.900726"}
{"text":"In summary , our main findings are as follows : .The effects of different character combinations types ( i.e. , CCIs were varied ) were evaluated using English - Finnish spelling variants .We found that s - grams perform well if a relatively low CCI is chosen for matching .","label":"CompareOrContrast","metadata":{},"score":"48.97458"}
{"text":"Class - based language models are employed in both the contextual model and the entity models .Some word classes can be automatically generated from text corpus for contextual models and are not only used as HMM states in a statistical decoding process , but are also entity class identifications , preferably after minor handcrafting .","label":"CompareOrContrast","metadata":{},"score":"49.08631"}
{"text":"Preferably , the contextual language model and the one or more entity language models incorporate local and contextual linguistic information , respectively , for producing prioritized word and corresponding category sequences .The contextual language model and the one or more entity language models may be dependent upon an n - gram paradigm .","label":"CompareOrContrast","metadata":{},"score":"49.13091"}
{"text":"How to delimit words is dependent upon whether a word in question is a phoneme word , a vocabulary word , a morphology word , a sentence making - based word , a semantics word or a psychology word .Consequently , for any word - based language process , for example , Text - to - Speech ( i.e. speech synthesis , or TTS ) , extracting a document feature , automatic document abstraction , automatic document sorting , and Chinese text searching , the first step is to segment each sentence into words .","label":"CompareOrContrast","metadata":{},"score":"49.256626"}
{"text":"In addition to statistical information , we try to use as much information as possible , such as morphology , syntax , semantics , and world knowledge .The identification system fully utilizes the context and content information of unknown words in the steps of detection process , extraction process , and verification process .","label":"CompareOrContrast","metadata":{},"score":"49.302517"}
{"text":"For instance , one or a combination of the following three types of features can be extracted for each word segmentation unit : .[ 0043 ] 1 .LEN : The \" LEN \" feature is defined as the number of characters in a word segmentation unit .","label":"CompareOrContrast","metadata":{},"score":"49.308105"}
{"text":"The most effective single technique was n - gram matching .Digrams were more effective than trigrams .Digrams with a space as their constituent character performed better than digrams in which only alphabetic characters were used .N - gram matching also could be utilized in resolving spelling errors which may be common in some databases ( Zobel and Dart , 1995 ) , in searching for historical word variants ( O'Rourke et al . , 1997 ) , as well as an alternative method for stemming algorithms ( Kosinov , 2001 ; Xu and Croft , 1998 ) .","label":"CompareOrContrast","metadata":{},"score":"49.505165"}
{"text":"N - gram refers to up to N words .A single ideogram word is a uni - gram , a two ideogram word is a bi - gram , and so on .The word n - gram generation module 130 generates word n - gram statistical data from the segmented text / name corpus .","label":"CompareOrContrast","metadata":{},"score":"49.52224"}
{"text":"One transformation - based method trains taggers based on manually annotated data so as to automatically assign Chinese characters with tags that indicate the position of a character within a word .The tagged output is then converted into segmented text for evaluation .","label":"CompareOrContrast","metadata":{},"score":"49.523285"}
{"text":"A class bi - gram method is described hereinafter with reference to Equation ( 2 ) .( 3 ) Integrate the contextual language and entity models and entity FSGs in the segmentor .( 4 ) Segment the text corpus with the ( new ) segmentor obtained in ( 3 ) .","label":"CompareOrContrast","metadata":{},"score":"49.81147"}
{"text":"The degree of similarity between the strings is computed on the basis of the number of similar n - grams and the total number of unique n - grams in the strings .In this paper , we will investigate n - gram based word matching .","label":"CompareOrContrast","metadata":{},"score":"49.862915"}
{"text":"The s - digrams belonging to the same category in the case of classified s - grams are marked using the parentheses ' [ ' and ' ] ' .farmakologian .We assumed that the effectiveness of s - gram matching depends on CCI .","label":"CompareOrContrast","metadata":{},"score":"49.88085"}
{"text":"The lexicon ( 240 ) includes single ideographic characters , words , and predetermined features of the characters and words .Cucchiarelli et al . \"Automatic Semantic Tagging of Unknown Proper Names \" , Proceedings of Coling - ACL'98 , pp286 - 292 , 1998 .","label":"CompareOrContrast","metadata":{},"score":"50.014656"}
{"text":"According to the invention , if a \" term frequency \" is used as a scoring criterion for word segmentation units , then no data needs to be trained , thus making the entire solution unsupervised .BRIEF DESCRIPTION ON THE DRAWINGS .","label":"CompareOrContrast","metadata":{},"score":"50.164562"}
{"text":"5 ] Foo and Li ( 2004 ) did systematic experimentation combining different segmentation methods for query and indexing and found that the best results are when the same segmentation is used for both query and indexing .At least when using Chinese search engines , users do not use spaces in their Chinese language queries , see examples in from the Sogou query logs in Xu et.al .","label":"CompareOrContrast","metadata":{},"score":"50.246857"}
{"text":"5 ] Foo and Li ( 2004 ) did systematic experimentation combining different segmentation methods for query and indexing and found that the best results are when the same segmentation is used for both query and indexing .At least when using Chinese search engines , users do not use spaces in their Chinese language queries , see examples in from the Sogou query logs in Xu et.al .","label":"CompareOrContrast","metadata":{},"score":"50.246857"}
{"text":"Lattice Construction .This is one of the steps of building up the word lattice where all the word arrangements of a sentence are enumerated .However , processing words outside the system vocabulary or bigger units in the sentences ( such as named entities ) is not as simple .","label":"CompareOrContrast","metadata":{},"score":"50.478874"}
{"text":"A system lexicon 240 and the entity FSGs 150 are also input to the lattice constructor module 220 .For the Chinese language , for example , each ideogram or character is stored in the lexicon as a two - byte word or entry .","label":"CompareOrContrast","metadata":{},"score":"50.575905"}
{"text":"The technique was compared with the conventional n - gram technique using adjacent characters as n - grams .Several types of words and word pairs were studied .English , German , and Swedish query keys were matched against their Finnish spelling variants and Finnish morphological variants using a target word list of 119 000 Finnish words .","label":"CompareOrContrast","metadata":{},"score":"50.679947"}
{"text":"Among all these word classes , only those associated with named entities are of concern .Given a word lattice obtained from the lattice constructor module 220 , the statistical decoder module 230 estimates probabilities of all word strings and all named entities and finds the most probable word string and its associated word class sequence .","label":"CompareOrContrast","metadata":{},"score":"50.72303"}
{"text":"..y this involves segmenting the text into individual words . by Xiangji Huang , Fuchun Peng , Dale Schuurmans , Nick Cercone , Stephen Robertson , 2002 . \" ...We propose a self - supervised word segmentation technique for text segmentation in Chinese information retrieval .","label":"CompareOrContrast","metadata":{},"score":"51.043056"}
{"text":"4 , a flowchart depicts the processing of the automatic word - clustering module 140 .The word - clustering processing commences in step 410 using word n - gram statistical data from module 130 as input .Preferably , the n - gram statistical data is that of bi - grams .","label":"CompareOrContrast","metadata":{},"score":"51.1055"}
{"text":"The analysis of the factors affecting the performance of classified s - grams showed that the effectiveness of the technique depends on query key and LCS lengths .Word length is a language and domain dependent property .LCS length is dependent on the specific language pair considered .","label":"CompareOrContrast","metadata":{},"score":"51.240837"}
{"text":"However , the fact that proper names ( technical terms ) often are form variants of each other allows the use of approximate string matching techniques to find the target language correspondents of source language keys .In morphologically complex languages , retrieval effectiveness can be improved , and users can be freed from taking into account word morphology , by using dictionary - based morphological analyzers , which normalize inflected word forms into their base forms .","label":"CompareOrContrast","metadata":{},"score":"51.38198"}
{"text":"Dealing with ambiguities and out of vocabulary words is a problem with word based approaches ( Fu , Kit , & Webster , 2008 , Wong et.al 2010 . )[ [ 3 ] .Information retrieval research indicates that completely accurate segmentation is not necessary for decent retrieval ( Foo , S. , & Li , H. 2004 , Huang et.al .","label":"CompareOrContrast","metadata":{},"score":"51.484047"}
{"text":"Dealing with ambiguities and out of vocabulary words is a problem with word based approaches ( Fu , Kit , & Webster , 2008 , Wong et.al 2010 . )[ [ 3 ] .Information retrieval research indicates that completely accurate segmentation is not necessary for decent retrieval ( Foo , S. , & Li , H. 2004 , Huang et.al .","label":"CompareOrContrast","metadata":{},"score":"51.484047"}
{"text":"[0009 ] Combining Methods are methods which combine several current methods or various information .As disclosed in Unsupervised Training for Overlapping Ambiguity Resolution in Chinese Word Segmentation \" ( Li , M. , Gao , J. F. , Huang , C. N. , and Li , J. F. , Proceedings of the Second SIGHAN Workshop on Chinese Language Processing .","label":"CompareOrContrast","metadata":{},"score":"51.60137"}
{"text":"Thus , the use of these two samples allows studying the effects of target word length on the effectiveness of n - gram matching .The base and genitive forms of these words were used as query keys , while the words that were gathered from the TWL formed the recall bases of the keys .","label":"CompareOrContrast","metadata":{},"score":"51.63321"}
{"text":"3 ) Transformation - based methods [ 4].They are initially used in POS tagging and parsing , which learn a set of n - gram rules from a training corpus and then apply them to the new text .","label":"CompareOrContrast","metadata":{},"score":"51.761665"}
{"text":"Multilingual Issues Part 1 : Word Segmentation .At the core of the Solr / Lucene search engine is an inverted index .The inverted index has a list of tokens and a list of the documents that contain those tokens .","label":"CompareOrContrast","metadata":{},"score":"51.86836"}
{"text":"A class - based language model overcomes ' these problems .This model uses classes fewer in number to estimate the probabilities of word sequences , rather than the words themselves , by mapping groups of words into classes according to predetermined criteria .","label":"CompareOrContrast","metadata":{},"score":"51.876926"}
{"text":"The system then identifies and categorizes named entities in a given body of text .The segmentor decomposes a string of ideographic characters into a word lattice according to system dictionary entries .The entity recognition portion of the system finds possible entities within the lattice by applying finite state grammars ( FSGs ) to the lattice structure .","label":"CompareOrContrast","metadata":{},"score":"51.938736"}
{"text":"Linguist ., 26(3 ) , 375 - 393 .Wu , D. , & Fung , P. ( 1994 ) .Improving Chinese tokenization with linguistic filters on statistical lexical acquisition .In Proceedings of the fourth conference on Applied natural language processing ( pp .","label":"CompareOrContrast","metadata":{},"score":"52.178078"}
{"text":"Linguist ., 26(3 ) , 375 - 393 .Wu , D. , & Fung , P. ( 1994 ) .Improving Chinese tokenization with linguistic filters on statistical lexical acquisition .In Proceedings of the fourth conference on Applied natural language processing ( pp .","label":"CompareOrContrast","metadata":{},"score":"52.178078"}
{"text":"The database has been used in many IR studies ( e.g. , Jrvelin and Keklinen , 2000 ; Sormunen , 2000 ) .The words were normalized using the Twol morphological analyzer of Lingsoft Corp.Those words that the Twol did not recognize were indexed in a separate index .","label":"CompareOrContrast","metadata":{},"score":"52.18473"}
{"text":"The figure below , Figure 3 from ( Teahan et al . , 2000 ) p 376 . , shows how the 3 character word for physics / physicist interpreted as single characters on the left could result in documents about evidence , barbers , and credit .","label":"CompareOrContrast","metadata":{},"score":"52.2353"}
{"text":"The figure below , Figure 3 from ( Teahan et al . , 2000 ) p 376 . , shows how the 3 character word for physics / physicist interpreted as single characters on the left could result in documents about evidence , barbers , and credit .","label":"CompareOrContrast","metadata":{},"score":"52.2353"}
{"text":"The approach contains three steps : 1 ) segments collecting , 2 ) segments scoring , and 3 ) segmentation scheme ranking .2.1 Segments Collecting .The segments are collected in two steps : . 1 )Firstly , the query sentence is semantically segmented by punctuation which gives several sub - sentences . 2 )","label":"CompareOrContrast","metadata":{},"score":"52.301304"}
{"text":"Also in the case of monolingual word form variants the technique was very effective .The rest of this paper is organized as follows .The next section introduces to the research problems investigated in this study and presents the problems .","label":"CompareOrContrast","metadata":{},"score":"52.35107"}
{"text":"The system identifies and categorizes members of certain categories of named entities from word sequences of a given text corpus .Referring first to FIG .1 , the training module 100 has two sub - modules or branches : a language - model training branch and a module for deriving an entity finite state grammar ( FSG ) .","label":"CompareOrContrast","metadata":{},"score":"52.371685"}
{"text":"2.4 Evaluation Performance of Chinese word segmenters is generally reported in terms of precision and recall .However , a comparison across systems cou ... . \" ...This paper describes a hybrid model that combines machine learning with linguistic heuristics for integrating unknown word identification with Chinese word segmentation .","label":"CompareOrContrast","metadata":{},"score":"52.385933"}
{"text":"The term P(c.sub.i.vertline.c.sub.i-1 ) indicates the contextual parameters , and p(w.sub.i.vertline.c.sub.i ) is the lexicon parameters .In the statistical decoder module 230 of FIG .2 , the classes are regarded as prescribed , and the vocabulary is regarded as dynamic .","label":"CompareOrContrast","metadata":{},"score":"52.41346"}
{"text":"Languages employing such writing systems comprise , e.g. , Chinese and Japanese .However , there are also a number of data - driven algorithms that work more or less without supervision and induce , from nothing ... .by Keh - jiann Chen , Chu - ren Huang , Li - ping Chang , Hui - li Hsu - Proceedings of PACLIC 11th Conference , 1996 . \" ...","label":"CompareOrContrast","metadata":{},"score":"52.69953"}
{"text":"Different outputs of segmentation can be obtained from different cuts of the word tree , which cuts are specified by the user through the different value combinations of those resolution parameters .Obviously , the combing methods merely combine the several types of methods as described previously , and therefore , may still be limited alike .","label":"CompareOrContrast","metadata":{},"score":"52.777817"}
{"text":"Among the combing methods , a system can be conveniently customized to meet various user - defined standards in the segmentation of MDWs ( Morphologically Derived Words ) .In this system , all MDWs contain word trees where root nodes correspond to maximal words and leaf nodes correspond to minimal words .","label":"CompareOrContrast","metadata":{},"score":"52.831398"}
{"text":"The role of lexical resources in CJK natural language processing .Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing , 64 - 71 .Hatcher , E. , Gospodneti , O. , & McCandless , M. ( 2010 ) .","label":"CompareOrContrast","metadata":{},"score":"52.92686"}
{"text":"Categories & Subject Descriptors .I.2.7 .[Artificial Intelligence ] : Natural Language Processing - Language parsing and understanding . H.3.1 .[ Information Storage and Retrieval ] : Content Analysis and Indexing -Linguistic processing .General Terms .Performance , Algorithms .","label":"CompareOrContrast","metadata":{},"score":"52.928726"}
{"text":"As can be seen in Table 2 , on the average one key in the Eng2 list had 3.9 relevant target words .For the other lists , the number of relevant words varied between 1.6 - 2.0 .Compound words containing relevant words as their components were judged as relevant target words .","label":"CompareOrContrast","metadata":{},"score":"52.98385"}
{"text":"You 've certainly got the basic idea of things for dealing with Chinese , but there are some other things you 're gon na want to consider as well .Chinese users will expect to have the ability to find text regardless of whether they enter the query in Simplified or Traditional Chinese .","label":"CompareOrContrast","metadata":{},"score":"53.031517"}
{"text":"In step S1105 , all collected candidate word segmentation units are scored , and various available scoring methods can be used for this step .Hereinafter , two scoring method will be described illustratively , namely a frequency - based method and an SVM ( Support Vector Machine)-based method .","label":"CompareOrContrast","metadata":{},"score":"53.133553"}
{"text":"In the Chinese language , there are two kinds of word in Chinese text : static and dynamic .Static words are commonly used words collected in dictionaries according to predetermined standards .On the other hand , dynamic words ( e.g. , named entities ) can only be formed at run time by the combination of static words in the dictionary according to predetermined rules and word features .","label":"CompareOrContrast","metadata":{},"score":"53.14188"}
{"text":"Since the IBM Full - Parser uses a maximum matching method based upon dictionaries , and exists in the dictionaries , and therefore gives the former word segmentation approach which is incorrect .[ 0056 ] Of course , it shall be appreciated by those skilled in the art , the inventive method may be encoded as a program , which may be stored on a computer readable storage medium and executed by a computer to implement the inventive method .","label":"CompareOrContrast","metadata":{},"score":"53.26736"}
{"text":"Training Process for Models .The training module ( upper branch ) of FIG .1 is applicable to both contextual model and entity model training .The training module itself can be divided into two parts .word n - gram generation and word clustering modules .","label":"CompareOrContrast","metadata":{},"score":"53.274445"}
{"text":"Presumably if you continue down the n - gram route for ideographs you 'll do that for kanji and hanja as well ?To answer your last question first : I believe the ICUTokenizer labels kanji and hanja as Han and therefore treats them the same as the regular Hanzi .","label":"CompareOrContrast","metadata":{},"score":"53.547462"}
{"text":"This also helps to explain why bigram indexing is competitive with more sophisticated segmentation methods and why combining unigrams and bigrams produce better retrieval results .However , what is not exlained in the literature is why this effect is not offset by a decrease in precision which would be expected when the smaller constituents do not have a meaning related to the larger word .","label":"CompareOrContrast","metadata":{},"score":"53.716072"}
{"text":"This also helps to explain why bigram indexing is competitive with more sophisticated segmentation methods and why combining unigrams and bigrams produce better retrieval results .However , what is not exlained in the literature is why this effect is not offset by a decrease in precision which would be expected when the smaller constituents do not have a meaning related to the larger word .","label":"CompareOrContrast","metadata":{},"score":"53.716072"}
{"text":"The grammars are used to make hypotheses to find possible proper names in a body of text .To do so , proper name or named entity statistical models are built to derive scores for names .Also , contextual language models are built to evaluate the problem of what type of proper name is found .","label":"CompareOrContrast","metadata":{},"score":"53.730347"}
{"text":"Using a static lexicon , a productive engine is built that generates names according to grammatical rules both statistically and deterministically .Further aspects of the embodiments are described hereinafter .System Architecture .FIGS . 1 and 2 are block diagrams illustrating a system for tokenization and named - entity recognition of ideographic language in accordance with a first embodiment of the invention .","label":"CompareOrContrast","metadata":{},"score":"53.77188"}
{"text":"Ullmann concluded that parallel processing of sets of n - grams probably is faster than scanning through the dictionary in the case of large dictionaries .The research problems investigated in this paper are as follows : .The effects of CCI on the effectiveness of s - gram matching : Several character combination types were tested , i.e. , CCIs were varied .","label":"CompareOrContrast","metadata":{},"score":"53.812843"}
{"text":"The results are statistically significant at the levels of 0.01 - 0.001 .In the Fin tests performance improvements are smaller ( Tables 8a-8d ) .In one case ( Finnish a - words / genitive forms , with start + end spaces ) the baseline n - grams perform better than the classified s - grams ( Table 8b ) .","label":"CompareOrContrast","metadata":{},"score":"53.84784"}
{"text":"Therefore a given query key may be retained , say , in a genitive form in the morphological normalizing of a query , while the corresponding index term may be in several different forms .This problem concerns both mono- and cross - lingual retrieval systems in which morphological analyzers are employed , and could be addressed using approximate string matching techniques .","label":"CompareOrContrast","metadata":{},"score":"53.987823"}
{"text":"Evaluation on five test sets with different standards shows that the adaptive system achieves state - of - the - art performance on all the test sets .n widely applied because they use a probabilistic or cost - based scoring mechanism rather than a dictionary to segment the text .","label":"CompareOrContrast","metadata":{},"score":"54.037483"}
{"text":"Approximate string matching techniques , however , are capable of finding word form variants .In this paper , we will explore one such technique - n - gram based string matching .We will explore cross - lingual spelling variants , i.e. , equivalent words in different languages which differ slightly in spelling , as well as monolingual morphological variants .","label":"CompareOrContrast","metadata":{},"score":"54.15396"}
{"text":"The module 130 calculates the frequencies in the training corpus of the adjacent n words .For a fixed number of classes in a word list , the automatic word clustering module 140 performs a many - to - one mapping of words to classes , dependent upon the similarities of the words ' contextual statistical information .","label":"CompareOrContrast","metadata":{},"score":"54.359562"}
{"text":"1 represents entity feature extraction processing .A segmented text / name corpus 110 is input to a module 130 for generating word n - grams and a module 120 for extracting entity features .The training data has the ideograms of the corpus 110 segmented into words .","label":"CompareOrContrast","metadata":{},"score":"54.49468"}
{"text":"For all the 52 matching cases in the a - word / base form test the frequency of such inflectional stem words that contributed to precision was much lower , that is , 19,2 % ( 10/52 ) .In the Eng1 , Eng2 , Swe , and Ger tests , the use of the start space yields lower relative improvements than the other two cases .","label":"CompareOrContrast","metadata":{},"score":"54.66165"}
{"text":"In the Eng2 test classified s - grams with start and end spaces perform slightly better .For Finnish a - words / genitive forms ( Table 8b ) the case of classified s - grams with the start space yields substantial improvements with respect to the case of classified s - grams with no space .","label":"CompareOrContrast","metadata":{},"score":"54.72892"}
{"text":"Still referring to FIG .4 , as can be seen , appears three times , and appears four times .On the other hand , an n - gram or a local segmentation model as adopted by the search engine may not be effective per se .","label":"CompareOrContrast","metadata":{},"score":"54.792244"}
{"text":"Therefore , identification of a new word is very simple and effective , so that the OOV problem can be avoided , which is inevitable in the previous methods .FIG .5 illustrates word segmentation results of the inventive method for vs. the IBM Full - Parser ( a current dictionary - based word segmentation tool used by IBM ) .","label":"CompareOrContrast","metadata":{},"score":"54.81678"}
{"text":"The module 120 works on lists of proper names to build the FSGs 150 for each category or kind of entity .The entity FSGs 150 is a lexicon including the extracted features of entities .Referring to FIG .2 , the decoding module 200 includes a lattice constructor module 220 coupled to a statistical decoding module 230 .","label":"CompareOrContrast","metadata":{},"score":"55.00474"}
{"text":"This feature , plus the word segmentation unit scoring step in the invention , enables the adaptability of the inventive method and device to various standards .[ 0020 ] As mentioned above , the manual labeling of a training corpus is a time - consuming and tedious task , while the inventive method and device may be entirely unsupervised .","label":"CompareOrContrast","metadata":{},"score":"55.04126"}
{"text":"Focusing on transduction grammars for bracketing , we formu- late a normal form , and a stochastic version amenable to a maximum - likelihood bracketing algorithm .Several extensions and experiments are discussed . by Jing - shin Chang , Keh - yih Su - International Journal of Computational Linguistics & amp ; Chinese Language Processing , 1997 . \" ...","label":"CompareOrContrast","metadata":{},"score":"55.169044"}
{"text":"[14 ] .What we would really like to do is to use the ICUTokenizer and have C and J tokenized into both unigrams and overlapping bigrams .We need unigrams for single character queries .We need overlapping bigrams in order to overcome the false drops caused by unigrams .","label":"CompareOrContrast","metadata":{},"score":"55.271664"}
{"text":"[14 ] .What we would really like to do is to use the ICUTokenizer and have C and J tokenized into both unigrams and overlapping bigrams .We need unigrams for single character queries .We need overlapping bigrams in order to overcome the false drops caused by unigrams .","label":"CompareOrContrast","metadata":{},"score":"55.271664"}
{"text":"Halpern , J. ( 2006 ) .The role of lexical resources in CJK natural language processing .Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing , 64 - 71 .Hatcher , E. , Gospodneti , O. , & McCandless , M. ( 2010 ) .","label":"CompareOrContrast","metadata":{},"score":"55.588894"}
{"text":"There is no blank to mark word boundaries in Chinese text .As a result , identifying words is difficult , because of segmentation ambiguities and occurrences of unknown words .Conventionally unknown words were extracted by statistical methods because statistical methods are simple and efficient .","label":"CompareOrContrast","metadata":{},"score":"55.698135"}
{"text":"There is no blank to mark word boundaries in Chinese text .As a result , identifying words is difficult , because of segmentation ambiguities and occurrences of unknown words .Conventionally unknown words were extracted by statistical methods because statistical methods are simple and efficient .","label":"CompareOrContrast","metadata":{},"score":"55.698135"}
{"text":"In Information Retrieval Technology ( pp .362 - 373 ) .Lecture Notes in Computer Science .Emerson , T. ( 2000 ) .Segmenting chinese in unicode . 16thInternational Unicode Conference , Amsterdam , The Netherlands .Feng , H. , Chen , K. , Deng , X. , & Zheng , W. ( 2004 ) .","label":"CompareOrContrast","metadata":{},"score":"55.74787"}
{"text":"In step 416 , the similarity of the word with all the classes is computed using the n - gram statistical data to find the most similar class .After N steps of comparison , the most similar class can be determined .","label":"CompareOrContrast","metadata":{},"score":"56.112732"}
{"text":"The effectiveness of s - gram matching with respect to that of the conventional n - gram matching depends on query key length and the number of characters in the longest common subsequence ( LCS ) of the variants .The s - gram technique is more effective than the n - gram technique particularly for short words and short LCSs .","label":"CompareOrContrast","metadata":{},"score":"56.12792"}
{"text":"One is a word segmentation unit that does not appear in a query sentence , i.e. the query sentence does not contain a part of a character sequence that exactly matches this word segmentation unit .Another is the so - called unigram , strictly speaking , such segmentation can not be deemed as a word segmentation method and most of such one - character terms are stopwords .","label":"CompareOrContrast","metadata":{},"score":"56.33943"}
{"text":"For example , the word list preferably contains 80,000 words and the predetermined number N of classes is preferably 1000 .Any of a number of techniques may be practiced to select the seeds for each class .Preferably , the word list is sorted by uni - gram statistics and the most frequent N words are selected as the seeds .","label":"CompareOrContrast","metadata":{},"score":"56.362305"}
{"text":"In Information Retrieval Technology ( pp .362 - 373 ) .Lecture Notes in Computer Science .Emerson , T. ( 2000 ) .Segmenting chinese in unicode .[ 7 ] 16th International Unicode Conference , Amsterdam , The Netherlands .","label":"CompareOrContrast","metadata":{},"score":"56.380234"}
{"text":"A probabilistic maximum a posteriori model is utilized , which builds hierarchical representations for a set of morphs , which are morpheme - like units discovered from unannotated ... \" .This work presents an algorithm for the unsupervised learning , or induction , of a simple morphology of a natural language .","label":"CompareOrContrast","metadata":{},"score":"56.432487"}
{"text":"Using bigrams and unigrams has the advantage of not needing any language specific information such as dictionaries , word formation rules or other language specific heuristics .[ 6 ] ( Abdou & Savoy , 2006 ; Luk & Kwok , 2002 ) .","label":"CompareOrContrast","metadata":{},"score":"56.47722"}
{"text":"Using bigrams and unigrams has the advantage of not needing any language specific information such as dictionaries , word formation rules or other language specific heuristics .[ 6 ] ( Abdou & Savoy , 2006 ; Luk & Kwok , 2002 ) .","label":"CompareOrContrast","metadata":{},"score":"56.47722"}
{"text":"In other words , the length of LCS was determined .This holds for all the four lists .However , for baseline n - grams the performance drop is more striking .This is shown in the last column of Table 10 , which presents the performance of baseline n - grams with respect to classified s - grams ; for all lists , the relative performance of baseline n - grams is markedly worse for short than long LCSs .","label":"CompareOrContrast","metadata":{},"score":"56.71671"}
{"text":"Therefore , the constituents of each kind of named entity can have three features .Because entity constituents are lexicon words , words in a lexicon can have multiple features .In some cases , one word can appear in different types of entity ( e.g. , person , place , organization , etc . ) , and even in the same type of entity at a different position .","label":"CompareOrContrast","metadata":{},"score":"56.75953"}
{"text":"by Richard Sproat , Chilin Shih , William Gale , Nancy Chang - Computational Linguistics , 1996 . \" ...Chinese text into dictionary entries and productively derived words , and providing pronunciations for these words ; the method incorporates a class - based model in its treatment of personal names .","label":"CompareOrContrast","metadata":{},"score":"56.94532"}
{"text":"Word form variation , which involves cross - lingual spelling variation and monolingual morphological variation , is an important and challenging issue in mono- and cross - language information retrieval .Different forms of the same word represent the same concept , thus being equal from the standpoint of users ' requests .","label":"CompareOrContrast","metadata":{},"score":"57.03282"}
{"text":"To deal with this problem , Fung and Wu ( 1994 ) suggest a procedure called nk - blind that uses n blind judges \" standards . ...In this paper we present Chinese word segmentation algorithms based on the socalled LMR tagging .","label":"CompareOrContrast","metadata":{},"score":"57.069595"}
{"text":"An augmented dictionary , which includes potential unknown words ( in addition to known words ) , is used to segment the input corpus , unlike traditional approaches which use only known words for segmentation . by Dekai Wu - In Proceedings of the Fourth Conference on Applied Natural Language Processing , 1994 . \" ...","label":"CompareOrContrast","metadata":{},"score":"57.096756"}
{"text":"Thirdly , the operation of the system is automatic and self - organized .Handcrafted data is not required for training .Given an appropriate amount of training data , robust statistical language models can be created to model the contextual constraints of words and the individual structures of named entities .","label":"CompareOrContrast","metadata":{},"score":"57.114174"}
{"text":"Because Web documents are human - written , thus they follow the natural language .Even if the local segmentation of a search engine is not correct , the local segmentation will be corrected by those documents , or by the way people speak .","label":"CompareOrContrast","metadata":{},"score":"57.1765"}
{"text":"The entity - feature extraction module 120 produces and outputs entity finite state grammars ( FSGs ) 150 .The module 120 only takes a segmented name corpus as input to extract the features of the entity constituents .These features can be used to define the entity FSGs 150 for suggesting names later .","label":"CompareOrContrast","metadata":{},"score":"57.284325"}
{"text":"Stuttgart , Germany : Association for Computational Linguistics .Xu , Ying , Randy Goebel , Christoph Ringlstetter and Grzegorz Kondrak .Application of the Tightness Continuum Measure to Chinese Information Retrieval .Proceedings of the Workshop on Multiword Expressions MWE2010 , China , Beijing , COLING 2010 , pp .","label":"CompareOrContrast","metadata":{},"score":"57.31021"}
{"text":"Stuttgart , Germany : Association for Computational Linguistics .Xu , Ying , Randy Goebel , Christoph Ringlstetter and Grzegorz Kondrak .Application of the Tightness Continuum Measure to Chinese Information Retrieval .Proceedings of the Workshop on Multiword Expressions MWE2010 , China , Beijing , COLING 2010 , pp .","label":"CompareOrContrast","metadata":{},"score":"57.31021"}
{"text":"9 is a block diagram illustrating a list of proper names from which named entity features can be extracted ; .FIG .10 is a block diagram of a system lexicon including named entity features ; .FIG .11 is a diagram depicting a word lattice derived from a sentence containing ideographic characters ; and .","label":"CompareOrContrast","metadata":{},"score":"57.36872"}
{"text":"For person names , it can derive family name and given names .An FSG is a machine that produces or recognizes certain kinds of syllable sequences .For example , an FSG for generating person 's name is : Pn.fwdarw .","label":"CompareOrContrast","metadata":{},"score":"57.470497"}
{"text":"Both compound and derivative correspondents were more common in the Eng2 list than in the other lists .Below is an example of a result list for the query key calcitonin ( the top ranked words ordered by decreasing SIM value )","label":"CompareOrContrast","metadata":{},"score":"57.62781"}
{"text":"The n - grams of a key are then matched against the n - grams of TWL words .The effectiveness of an n - gram matching technique can be calculated using the measure of precision , i.e. , the proportion of relevant words among all the words retrieved .","label":"CompareOrContrast","metadata":{},"score":"57.701057"}
{"text":"For this reason , we use a sophisticated SVM - based initial tagger .A second initial tagger based on the hidden Markov model ( HMM ) is used for comparison .The second component is the space of transfo ... . by","label":"CompareOrContrast","metadata":{},"score":"57.71447"}
{"text":"Evaluation on five test sets with different standards shows that the adaptive system achieves state - of - the - art performance on all the test sets .ue to the following two reasons .First of all , the \" correct \" segmentation is not clearly defined .","label":"CompareOrContrast","metadata":{},"score":"57.76525"}
{"text":"0017 ]Since the previous methods require a support from dictionaries , the dictionaries are limited regardless of whether they are used for a real - time query ( e.g. a dictionary - based method ) or for training a word segmentation model ( e.g. a statistical method , etc . ) .","label":"CompareOrContrast","metadata":{},"score":"57.812626"}
{"text":"Variants are really important , actually : even across locales that use Traditional Chinese the \" standard \" character may differ .Japanese will bring an interesting wrinkle to this as well : kanji usage has changed over time , and there is an expectation that variants are interchangeable as in Chinese .","label":"CompareOrContrast","metadata":{},"score":"57.901745"}
{"text":"In step 622 , a new word(s ) is ( are ) created and added at the beginning of the current frame .There could be more than one type of entity .For each entity , create a word at the beginning of the frame .","label":"CompareOrContrast","metadata":{},"score":"58.275158"}
{"text":"Our method is completely language independent and unsupervised , which provides a promising avenue for constructing accurate multi - lingual or cross - lingual information retrieval systems that are exible and adaptive .We nd that although the segmentation accuracy of self - supervised segmentation is not as high as some other segmentation methods , it is enough to give comparable ( in some cases even better ) retrieval performance .","label":"CompareOrContrast","metadata":{},"score":"58.396587"}
{"text":"In our situation this would lead to many false drops where the word \" l \" appears somewhere in a document ( perhaps as someone 's initial ) and the word \" art \" appears somewhere else in the document .The current large scale search implementation .","label":"CompareOrContrast","metadata":{},"score":"58.44499"}
{"text":"In our situation this would lead to many false drops where the word \" l \" appears somewhere in a document ( perhaps as someone 's initial ) and the word \" art \" appears somewhere else in the document .The current large scale search implementation .","label":"CompareOrContrast","metadata":{},"score":"58.44499"}
{"text":"Proceedings of the 23th Annual International ACM SIGIR on Research and Development in Information Retrieval , Athens , July 24 - 28 , 2000 , pp .41 - 48 .New York , NY : ACM Press .Kosinov , S. ( 2001 ) Evaluation of n - grams conflation approach in text - based information retrieval .","label":"CompareOrContrast","metadata":{},"score":"58.459133"}
{"text":"Previous approaches fall roughly into four categories : 1 ) Dictionary - based methods , which segment sentences by matching entries in a dictionary [ 3].Its accuracy is determined by the coverage of the dictionary , and drops sharply as new words appear . 2 ) Statistical machine learning methods [ 1 ] , which are typically based on co - occurrences of character sequences .","label":"CompareOrContrast","metadata":{},"score":"58.463673"}
{"text":"An apparatus for tokenization and named entity recognition of ideographic language , said apparatus including : . means for generating segmented text by determining word boundaries in said string of ideographic characters using said word lattice dependent upon a contextual language model and one or more entity language models ; and .","label":"CompareOrContrast","metadata":{},"score":"58.466805"}
{"text":"Unlike other approaches , which involve a dictionary of legal words and are therefore language - specific , it works by using a corpus of already segmented text for training and thus can easily be retargeted for any language for which a suitable corpus of segmented material is available .","label":"CompareOrContrast","metadata":{},"score":"58.506004"}
{"text":"The i- vowel at the end of kalsitoniini represents the case of single vowel addition .We will test several types of character combinations regarding the number of skipped characters , as well as a novel technique to compare the s - grams of query keys with those of target words .","label":"CompareOrContrast","metadata":{},"score":"58.56028"}
{"text":"Segmented text is generated by determining word boundaries in the string of ideographic characters using the word lattice dependent upon a contextual language model ( 152A ) and one or more entity language models ( 152B ) .One or more named entities is recognized in the string of ideographic characters using the word lattice dependent upon the contextual language model ( 152A ) and the one or more entity language models ( 152B ) .","label":"CompareOrContrast","metadata":{},"score":"58.608032"}
{"text":"11 , two words are indicated in the first frame having the characters \" C1\"and \" C1C2 \" , respectively .In step 516 candidate words are put into the word lattice at the indexed position .Along with the candidate words , their word features ( i.e. , entity features ) and statistical information are put into the word lattice .","label":"CompareOrContrast","metadata":{},"score":"58.63309"}
{"text":"[ 0023 ] FIG .1 is a schematic diagram of elementary elements in a search - based word segmentation system for a language without a word boundary tag according to an embodiment of the invention ; .[ 0024 ] FIG .","label":"CompareOrContrast","metadata":{},"score":"58.72074"}
{"text":"I am not suprised by the character variant issue .Are there available resources for mapping character variants ?I do n't sufficiently understand the issues of Japanese orthographic variation .There was some interesting work on phonetic similarity done by Kummer , Womser - Hacker and Kando , but I have n't seen any follow - up .","label":"CompareOrContrast","metadata":{},"score":"58.76533"}
{"text":"Illustratively , in the present embodiment , the highest - ranked path can be found through terms of a reconstructed query sentence .[0048 ] An illustrative path - finding method is dynamical programming .Obviously , the beginning character of w i j +1 should be the one which immediately follows the ending character of w i j in a character string S i .","label":"CompareOrContrast","metadata":{},"score":"58.780624"}
{"text":"A computer program product having a computer readable medium having a computer program recorded therein for tokenization and named entity recognition of ideographic language , said computer program product including : . computer program means for generating segmented text by determining word boundaries in said string of ideographic characters using said word lattice dependent upon a contextual language model and one or more entity language models ; and . computer program means for recognizing one or more named entities in said string of ideographic characters using said word lattice dependent upon said contextual language model and said one or more entity language models .","label":"CompareOrContrast","metadata":{},"score":"58.962788"}
{"text":"In all the cross - lingual experiments we did , the technique outperformed the conventional n - gram matching technique .Several types of words and word pairs were studied .The types were English - Finnish medical ( pharmacological ) and geographical spelling variants , German - Finnish and Swedish - Finnish medical spelling variants , and Finnish morphological variants .","label":"CompareOrContrast","metadata":{},"score":"59.152397"}
{"text":"9 , a single entry 900A with the name \" Bai Shuan Hu \" is depicted .In step 314 , the current word and its position information pointed to by the scanning pointer are determined ( e.g. , \" Bai \" and \" 1\"in FIG .","label":"CompareOrContrast","metadata":{},"score":"59.19937"}
{"text":"For an overview of the approaches to cross - language retrieval , see ( Oard and Diekema , 1998 ) .For an overview of the methods used in dictionary - based CLIR , see ( Pirkola et al .Our experience on CLIR system development and evaluation at the University of Tampere , Information Retrieval Laboratory ( Hedlund et al . , 2001 ; Pirkola , 1998 ) , and the analysis of request key properties ( Pirkola and Jrvelin , 2001 ) have shown that proper names and technical terms often are prime keys in requests , and if not translated by dictionaries , query performance may deteriorate .","label":"CompareOrContrast","metadata":{},"score":"59.246925"}
{"text":"TF is defined as in Section 2.2.1 .DF is the number of documents indexed by a segment , and LEN indicates the number of characters in a segment .Figure 2 shows the performance of our approach which is output by SIGHAN'05 benchmark evaluation .","label":"CompareOrContrast","metadata":{},"score":"59.37734"}
{"text":"Description : .FIELD OF THE INVENTION .[ 0001 ] The present invention relates to the field of word segmentation technologies for a language without a word boundary tag , and in particular to a search - based word segmentation method and device for a language without a word boundary tag .","label":"CompareOrContrast","metadata":{},"score":"59.377342"}
{"text":"In English and Western European languages spaces are used to separate words , so Solr uses whitespace to determine what is a token for indexing .In a number of languages the words are not separated by spaces .Chinese , Japanese , ( the C and J in CJK ) , Thai , and Vietnamese are common languages that do not use white space to separate words For languages that do not use spaces , a segmentation algorithm has to be used .","label":"CompareOrContrast","metadata":{},"score":"59.545334"}
{"text":"Moreover , manual labeling of a training corpus is a time - consuming and tedious task , which is the reason that few training corpuses are available .SUMMARY OF THE INVENTION .The invention uses search results returned from a search engine to segment words , and thus combat the limitations of the current word segmentation approaches in terms of flexibility , dependence upon coverage of dictionaries , available training data corpuses , processing of a new word , etc . .","label":"CompareOrContrast","metadata":{},"score":"59.563026"}
{"text":"The \" type \" of segmented name corpus means entity type , such as people , place , organization , etc .In step 312 , a named entity is read or obtained from the training corpus 110 , and the scanning pointer is set at the first word of the named entity .","label":"CompareOrContrast","metadata":{},"score":"59.634712"}
{"text":"\" Exploiting Diverse Knowledge Source via Maximum Entropy in Named Entity Recognition \" , pp152 - 160 , Proceedings of Sixth Workshop on Very Large Corpora , 1998 .Shuanghu et al .\" Building class - based language models with contexual statistics \" , Proceedings of ICASSP'98 , pp173 - 176 , Seattle Washington , USA , 1998 .","label":"CompareOrContrast","metadata":{},"score":"59.744846"}
{"text":"However , other categories can be utilized without departing from the scope and spirit of the invention .Each type of named entity has its own model .The models are similar for different kinds of named entities ; only the training data to make the models are different .","label":"CompareOrContrast","metadata":{},"score":"59.82052"}
{"text":", where each of the foregoing is a person 's family name preferably .Examples of Pnc are : Pnc.fwdarw .Shuan.vertline.nil.vertline . . . .Thus , a person 's name continuous can be Shuan , empty syllable string , or something else .","label":"CompareOrContrast","metadata":{},"score":"59.87432"}
{"text":"2.4 Evaluation Performance of Chinese word segmenters is generally reported in terms of precision and recall .However , a comparison across systems cou ... . by Radu Florian , Grace Ngai - Conference on Natural Language Learning , 2001 . \" ...","label":"CompareOrContrast","metadata":{},"score":"59.940342"}
{"text":"Comparative study of monolingual and multilingual search models for use with asian languages .ACM Transactions on Asian Language Information Processing ( TALIP ) , 4(2 ) , 163 - 189 .doi : 10.1145/1105696.1105701 .Shi , L. , Nie , J. , & Bai , J. ( 2007 ) .","label":"CompareOrContrast","metadata":{},"score":"60.011"}
{"text":"Comparative study of monolingual and multilingual search models for use with asian languages .ACM Transactions on Asian Language Information Processing ( TALIP ) , 4(2 ) , 163 - 189 .doi : 10.1145/1105696.1105701 .Shi , L. , Nie , J. , & Bai , J. ( 2007 ) .","label":"CompareOrContrast","metadata":{},"score":"60.011"}
{"text":"In step S110 , searches for the query content ( segment ) through the search engine 1 are made in a search network 2 , such as the Internet , and the search results are returned .In the step S120 , a word segmentation generating means 3 selects an optimal word segmentation approach for the submitted segment in accordance with the returned search results .","label":"CompareOrContrast","metadata":{},"score":"60.020874"}
{"text":"All the candidate word segmentation units form a plurality of subsets .The candidate word segmentation units in each subset are cascaded to form the submitted query , that is , a \" path \" ( i.e. sequence ) , and an optimal \" path \" is taken as a word segmentation result of the submitted sentence units .","label":"CompareOrContrast","metadata":{},"score":"60.19024"}
{"text":"( 2 ) Apply word - clustering to create word classes for the contextual and name models , respectively , and build class - based language models for the contextual and entity models .Apply feature extraction to extract features of the words used in the names .","label":"CompareOrContrast","metadata":{},"score":"60.22946"}
{"text":"Nonetheless .the system is able to perform well in terms of named entity recognition accuracy and efficiency .Still further , the entity models and the contextual models are well organized .The system is able to perform tokenization and named entity recognition at the same time .","label":"CompareOrContrast","metadata":{},"score":"60.312004"}
{"text":"The method according to claim 4 , wherein said contextual language model and said one or more entity language models are dependent upon an n - gram paradigm .The method according to claim 1 , wherein said lattice generating step includes the step of generating one or more elements of said lattice using said lexicon .","label":"CompareOrContrast","metadata":{},"score":"60.320297"}
{"text":"It improves parser coverage and provides a tool for the lexical acquisition of new words . by Dekai Wu - in Parallel Text Processing : Alignment and Use of Translation Corpora , 2000 . \" ... parsing Abstract : We introduce ( 1 ) a novel stochastic inversion transduction grammar formalism for bilingual language modeling of sentence - pairs , and ( 2 ) the concept of bilingual parsing with a variety of parallel corpus analysis applications .","label":"CompareOrContrast","metadata":{},"score":"60.45647"}
{"text":"0038 ]In the present embodiment , the frequency - based method is used as a scoring method .A simplest way is to use , based upon the search results , occurrence frequencies of all terms in each w i j as scores .","label":"CompareOrContrast","metadata":{},"score":"60.501755"}
{"text":"The contextual and entity models are probability data derived from the training corpus and the mechanism of estimating the probabilities of word sequences .Again , the contextual model is derived preferably from a text corpus containing text from newspapers , magazines , books , etc .","label":"CompareOrContrast","metadata":{},"score":"60.556488"}
{"text":"[ 4 ] .As long as the same segmentation algorithm is used for both segmenting the query and segmenting the text for indexing , good retrieval is possible with character - based approaches .[5 ] .Information retrieval research has generally found that simple approaches such as indexing overlapping character bigrams have comparable performance with more sophisticated word based approaches .","label":"CompareOrContrast","metadata":{},"score":"60.61622"}
{"text":"[ 4 ] .As long as the same segmentation algorithm is used for both segmenting the query and segmenting the text for indexing , good retrieval is possible with character - based approaches .[5 ] .Information retrieval research has generally found that simple approaches such as indexing overlapping character bigrams have comparable performance with more sophisticated word based approaches .","label":"CompareOrContrast","metadata":{},"score":"60.61622"}
{"text":"This reflects the complex suffix - based inflectional system of Finnish ; many of the target words were in inflected forms .The use of the end space in n - gram matching is not suited for inflectionally complex suffix languages .","label":"CompareOrContrast","metadata":{},"score":"60.655357"}
{"text":"This is a remarkable in the sense that the comparison precision of 74.2 % is high .Analyzing the factors affecting the performance of classified s - grams .To explain the superior performance of classified s - grams , we analyzed the results as follows .","label":"CompareOrContrast","metadata":{},"score":"60.676376"}
{"text":"[ 0046 ]In the SVM - based method , one or more features also can be used as the feature(s ) of a word segmentation unit .[ 0047 ] Next in step S1106 , an optimal subset of candidate word segmentation units is determined from the candidate word segmentation units in accordance with the scoring results obtained in the step S1105 .","label":"CompareOrContrast","metadata":{},"score":"60.705143"}
{"text":"A set of Finnish words in different morphological forms beginning with the letters a and k was gathered from the TWL .In both cases this was done systematically by selecting from the list the first 50 original Finnish words .A native Finnish speaker can readily recognize the original Finnish words .","label":"CompareOrContrast","metadata":{},"score":"60.761852"}
{"text":"Thanks for this ; I really enjoyed it !If someone on the team has a little extra time to scratch another language - related curiosity itch of mine sometime ...How does one tokenize and/or stem words in agglutinative languages such as Finnish , Hungarian , and Quechua ?","label":"CompareOrContrast","metadata":{},"score":"60.767693"}
{"text":"Hu.vertline . . . .The foregoing are rules of the FSG .The upper branch represents language model training processing where both contextual model and entity models are trained .The class - based model is preferably a Hidden Markov Model ( HMM ) .","label":"CompareOrContrast","metadata":{},"score":"60.804306"}
{"text":"Large Margin Classifiers , Smola , A. , Bartlett , P. , Scholkopf , B. , Schuurmans , D. ( eds . ) , MIT Press , 1999 .In the embodiment of the present invention , SVM classifiers are used to score each word segmentation unit .","label":"CompareOrContrast","metadata":{},"score":"60.80548"}
{"text":"Intuitively , the accuracy of this type of methods is seriously affected by the limited coverage of the dictionary and the lack of robust statistical inference in the rules .Since it is virtually impossible to list all the words in a predefined dictionary and impossible to timely update the dictionary , the accuracy of such methods degrades sharply as new words appear .","label":"CompareOrContrast","metadata":{},"score":"60.814194"}
{"text":"Employing multiple representations for Chinese information retrieval .J. Am .Soc .Inf .Sci . , 50(8 ) , 709 - 723 .Luk , R. W. P. , & Kwok , K. L. ( 2002 ) .A comparison of Chinese document indexing strategies and retrieval models .","label":"CompareOrContrast","metadata":{},"score":"60.83456"}
{"text":"Employing multiple representations for Chinese information retrieval .J. Am .Soc .Inf .Sci . , 50(8 ) , 709 - 723 .Luk , R. W. P. , & Kwok , K. L. ( 2002 ) .A comparison of Chinese document indexing strategies and retrieval models .","label":"CompareOrContrast","metadata":{},"score":"60.83456"}
{"text":"( See : https://issues.apache.org/jira/browse/LUCENE-2458 [ 1 ] ) .While this may not seem like a problem for very short queries ( 1 - 3 characters , ) for longer queries it can be a problem .However if it is searched as overlapping bigrams there are about 600 hits .","label":"CompareOrContrast","metadata":{},"score":"61.041534"}
{"text":"The ICUTokenizer also provides segmentation for Lao , Myanmar , and Khmer , and segments Chinese and Japanese ( Han and Kanji ) characters into unigrams .Unfortunately unigrams produce many false drops ( Halpern , 2006 .pp 65 - 66 ; Kwok , 1999 , p 170 ) .","label":"CompareOrContrast","metadata":{},"score":"61.09295"}
{"text":"The ICUTokenizer also provides segmentation for Lao , Myanmar , and Khmer , and segments Chinese and Japanese ( Han and Kanji ) characters into unigrams .Unfortunately unigrams produce many false drops ( Halpern , 2006 .pp 65 - 66 ; Kwok , 1999 , p 170 ) .","label":"CompareOrContrast","metadata":{},"score":"61.09295"}
{"text":"The effectiveness of s - gram matching for various types of words and word pairs : English , German , and Swedish query keys against the Finnish words in the TWL were matched .Query key lists contained medical and pharmacological terms ( the first key list ) and geographical names ( the second list ) .","label":"CompareOrContrast","metadata":{},"score":"61.177544"}
{"text":"However , the illustrative sentence gives the context information ( have titles of a technical post ) \" , and a ( titles of a technical post ) \" is meaningless to .Therefore , the context information actually defines that a correct word segmentation approach should be the latter one , and .","label":"CompareOrContrast","metadata":{},"score":"61.290596"}
{"text":"Whether the finding of the effectiveness of classified s - gram matching can be generalized for other ( target ) languages is a research problem of future research .However , it is likely that the technique is also suited for other languages , because spelling variation is the same type of phenomenon in most languages ( deletion , addition , and substitution of letters in words ) .","label":"CompareOrContrast","metadata":{},"score":"61.487762"}
{"text":"Statistical Decoding .The statistical parameters of the words in the vocabulary are obtained from the training corpus .This is applicable to the process of estimating both the probabilities of sentences and the probabilities of named entities .When a sentence is processed , w.sub.i indicates words in the sentence .","label":"CompareOrContrast","metadata":{},"score":"61.56343"}
{"text":"The contextual and entity models employ preferably the same mechanism for estimating the probabilities of word sequences .The contextual and entity models can be either word or class - based , but are preferably class - based .A word - based language model is a direct and simple mechanism that calculates probabilities of word sequences by multiplying the probability of each word ( word unigram model ) or by multiplying of each n-1 preceding words in the word sequences .","label":"CompareOrContrast","metadata":{},"score":"61.583557"}
{"text":"This bug in the QueryParser is also what caused problems for us with words like \" l'art \" triggering a phrase search with a common word \" l \" .Prior to the Solr bug fix , we tried to get around the problem with a custom punctuation filter that did not split \" l'art \" into two tokens .","label":"CompareOrContrast","metadata":{},"score":"61.7426"}
{"text":"This bug in the QueryParser is also what caused problems for us with words like \" l'art \" triggering a phrase search with a common word \" l \" .Prior to the Solr bug fix , we tried to get around the problem with a custom punctuation filter that did not split \" l'art \" into two tokens .","label":"CompareOrContrast","metadata":{},"score":"61.7426"}
{"text":"Figure 1 .Red words are the segments . 2.2Segments Scoring .Each segment is scored so that we can select a subset of segments as the final segmentation which , when reconstructing the query , scores the highest .Obviously various methods can be used .","label":"CompareOrContrast","metadata":{},"score":"61.855965"}
{"text":"( 2004 ) provide detailed results for the effectiveness of language - specific methods on 8 European languages .In terms of percent change in mean average precision ( see page 8.4 ) over a baseline system , diacritic removal gains up to 23 % ( being especially helpful for Finnish , French , and Swedish ) .","label":"CompareOrContrast","metadata":{},"score":"61.902687"}
{"text":"Proper Name ( PN ) Feature Extraction .Named - entity model - training processing ( lower branch of training module 100 ) of FIG .1 extracts features of the constituents of named entities .This involves the module 120 for extracting entity features .","label":"CompareOrContrast","metadata":{},"score":"62.042183"}
{"text":"The lattice - generating step may include the step of generating one or more elements of the lattice using the lexicon .Optionally , the finite state grammars are a dynamic and complementary extension of the lexicon for creating named entity hypotheses .","label":"CompareOrContrast","metadata":{},"score":"62.148552"}
{"text":"The most common word forms in Finnish are the base ( nominative ) and genitive forms ( Karlsson , 1983 ) .Gathering query keys .Altogether 8 query key lists were used in the experiments of this study .For different lists we used different query key gathering methods , as described in this section .","label":"CompareOrContrast","metadata":{},"score":"62.42723"}
{"text":"In CLIR , proper names often are untranslatable due to limited coverages of translation dictionaries .Similarly , some words can not be normalized , because the dictonaries of morphological analyzers are incomplete .In such cases , approximate matching techniques can be applied in searching for cross - lingual spelling variants and morphological variants .","label":"CompareOrContrast","metadata":{},"score":"62.447495"}
{"text":"The computer program product according to claim 15 , wherein said computer program means for lattice - generating includes computer program code means for generating one or more elements of said lattice using said lexicon .The computer program product according to claim 15 , wherein said finite state grammars run on said predetermined features contained in said lexicon to suggest possible entities , entity boundaries and entity categories .","label":"CompareOrContrast","metadata":{},"score":"62.460274"}
{"text":"The system uses two knowledge bases : a contextual model 152A and name entity models 152B. A name entity is a proper name ( PN ) .Preferably , there are seven categories of named entities : person , place , organization , date , time , percentage , and monetary amount .","label":"CompareOrContrast","metadata":{},"score":"62.494488"}
{"text":"0031 ]For instance , firstly a sentence is segmented by punctuation into a group of sentence units .Then each sentence unit is submitted as a query to a search engine .All candidate phrases ( i.e. the hits ) , called candidate word segmentation units , are extracted from snippets of the documents , which are returned from the search engine .","label":"CompareOrContrast","metadata":{},"score":"62.524883"}
{"text":"( See : https://issues.apache.org/jira/browse/LUCENE-2458 ) .While this may not seem like a problem for very short queries ( 1 - 3 characters , ) for longer queries it can be a problem .However if it is searched as overlapping bigrams there are about 600 hits .","label":"CompareOrContrast","metadata":{},"score":"62.60238"}
{"text":"6 is still a lattice , but it now contains more named entities ( e.g. , person , organization , place , etc . ) .The suggested names in the lattice may be indicated by a flag , indicating whether or not a name is suggested .","label":"CompareOrContrast","metadata":{},"score":"62.651466"}
{"text":"Hong Kong , China : ACM .doi : 10.1145/355214.355235 .Nie , Jian - Yun , Ren , Fuji .Chinese information retrieval : using characters or words ?Information Processing & Management 35 ( 1999 ) p 443 - 462 .","label":"CompareOrContrast","metadata":{},"score":"62.74861"}
{"text":"Hong Kong , China : ACM .doi : 10.1145/355214.355235 .Nie , Jian - Yun , Ren , Fuji .Chinese information retrieval : using characters or words ?Information Processing & Management 35 ( 1999 ) p 443 - 462 .","label":"CompareOrContrast","metadata":{},"score":"62.74861"}
{"text":"It shall be appreciated that the invention will not be limited to this , but it is also possible to collect all highlighted phrases given in search results from a public or self - maintained search engine , and to combine the search results .","label":"CompareOrContrast","metadata":{},"score":"62.825706"}
{"text":"The lattice constructor module 220 reads a sentence from the text / name corpus 210 .Using the system lexicon 240 and the entity finite state grammars 150 , the lattice constructor module 220 generates all possible word arrangements of the sentence and puts them into a data structure called a lattice according to the starting character of the words .","label":"CompareOrContrast","metadata":{},"score":"62.843864"}
{"text":"Greenwich , CT : Manning Publications .Huang , Xiangji , Peng , Fuchun , Schuurmans , Dale , Cercone , Nick and Stephen E. Robertson ( 2003 )Applying Machine Learning to Text Segmentation for Information Retrieval .Information Retrieval Volume 6 , Numbers 3 - 4 , 333 - 362 , DOI : 10.1023/A:1026028229881 .","label":"CompareOrContrast","metadata":{},"score":"62.952156"}
{"text":"Greenwich , CT : Manning Publications .Huang , Xiangji , Peng , Fuchun , Schuurmans , Dale , Cercone , Nick and Stephen E. Robertson ( 2003 )Applying Machine Learning to Text Segmentation for Information Retrieval .Information Retrieval Volume 6 , Numbers 3 - 4 , 333 - 362 , DOI : 10.1023/A:1026028229881 .","label":"CompareOrContrast","metadata":{},"score":"62.952156"}
{"text":"The TWL contained 119 000 words .By using this test data we investigated empirically several research problems described below .For digrams , we use a character combination index ( CCI ) to indicate the number of skipped characters as s - digrams are formed .","label":"CompareOrContrast","metadata":{},"score":"63.02494"}
{"text":"[ 0025 ] FIG .3 depicts a flow chart of an example of the search - based word segmentation method according to an embodiment of the invention ; .[ 0026 ] FIG .4 depicts search results of the search using the public Yahoo ! search engine ; .","label":"CompareOrContrast","metadata":{},"score":"63.09906"}
{"text":"Research problems .For example , for a spelling variant pair which shares many high frequency n - grams , matching can be expected to be less effective than for a spelling variant pair only sharing low frequency n - grams .","label":"CompareOrContrast","metadata":{},"score":"63.180214"}
{"text":"12 , this is indicated by two thick arrows between nodes having probabilities 0.6 , 0.7 and 0.5 in the first three frames , respectively .Processing then terminates in step 732 .The embodiments of the invention are preferably implemented using a computer , such as the general - purpose computer shown in FIG . 8 .","label":"CompareOrContrast","metadata":{},"score":"63.18708"}
{"text":"In accordance with a first aspect of the invention , there is disclosed a method of tokenization and named entity recognition of ideographic language .Preferably , the method further includes the step of combining the contextual language model and the one or more entity language models .","label":"CompareOrContrast","metadata":{},"score":"63.2703"}
{"text":"EVALUATIONS .Evaluation on SIGHAN'05 Benchmark Data .The training data used is 3,000 randomly selected sentences ( Note that in the case of using frequency - based scoring function , our method needs no training and is unsupervised segmentation ) .","label":"CompareOrContrast","metadata":{},"score":"63.282673"}
{"text":"0036 ] Next , the rest of candidate word segmentation units , which remain after the filtering out , are scored for reconstruction of the query sentence , and a word segmentation unit that most probably gives the query sentence corresponds to an optimal word segmentation .","label":"CompareOrContrast","metadata":{},"score":"63.405785"}
{"text":"The LMR taggers in such a method are implemented with the Maximum Entropy Markov Model , and transformation - based learning is adopted to combine results of two LMR taggers that scan an input in opposite directions .A further transformation - based method presents a statistical framework , and identifies domain - specific or strongly time - dependent words based upon linear models , and then performs adaptation to standards by a post - processor performing a series of conversion on an output from the generic segmenter to implement a single word - segmentation system .","label":"CompareOrContrast","metadata":{},"score":"63.426407"}
{"text":"The processing of the lattice constructor module 220 is depicted in FIG .5 .In step 510 , processing commences to build a word lattice for a sentence .In step 512 , a character pointer is set to the first character of the sentence and the frame index of the lattice is set at a value of 1 .","label":"CompareOrContrast","metadata":{},"score":"63.612103"}
{"text":"The target word list was browsed from the start to end .A list of pharmacological and medical terms was gathered .Each term was looked up in a medical dictionary to find its English equivalent .If the dictionary translated the term into English , the English word was selected as a query key .","label":"CompareOrContrast","metadata":{},"score":"63.699245"}
{"text":"[ 0016 ] One advantage of the invention lies in detection of a new word .The invention provides a very easy way to identify an OOV word , e.g. ( SARS ) , while new words emerge everyday , since information available in the Internet is dynamic and updated rapidly .","label":"CompareOrContrast","metadata":{},"score":"63.75922"}
{"text":"Finnish is a highly complex suffix language ( Pirkola , 2001 ) .It has been estimated that theoretically a Finnish noun may have over 2000 inflectional forms .In practice , most words occur in several inflectional forms in databases .","label":"CompareOrContrast","metadata":{},"score":"63.79696"}
{"text":"3 is a flow diagram depicting the entity - feature extraction processing of the module 120 of FIG .1 , .FIG .4 is a flow diagram depicting the word - clustering processing of the module 140 of FIG .","label":"CompareOrContrast","metadata":{},"score":"63.97187"}
{"text":"FIG .7 is a flow diagram depicting the statistical decoding processing of module 230 of FIG .2 ; .FIG .8 is a block diagram illustrating a general - purpose computer , with which the embodiments of the invention can be practiced ; .","label":"CompareOrContrast","metadata":{},"score":"64.01325"}
{"text":"The device according to claim 15 , wherein the word segmentation result generating means is further adapted to select a subset of candidate word segmentation units with the highest average score of candidate word segmentation units as the word segmentation approach for the segment .","label":"CompareOrContrast","metadata":{},"score":"64.181625"}
{"text":"The effectiveness of test digrams was compared with that of the better baseline ( digrams / trigrams ) .All the s - gram types were first tested on the Eng1 list .In the first experiment the effects of CCI were tested .","label":"CompareOrContrast","metadata":{},"score":"64.185684"}
{"text":"Each entity model corresponds to an entity corpus consisting of lists of names ( entities ) .For example , a person 's name model can be built from a person 's name corpus .Likewise , an organization name model can be built from an organization name corpus , and so on .","label":"CompareOrContrast","metadata":{},"score":"64.22269"}
{"text":"parsing Abstract : We introduce ( 1 ) a novel stochastic inversion transduction grammar formalism for bilingual language modeling of sentence - pairs , and ( 2 ) the concept of bilingual parsing with a variety of parallel corpus analysis applications .","label":"CompareOrContrast","metadata":{},"score":"64.401"}
{"text":"The term refers to words whose word stems are changed in inflection , e.g. , Asonen ( personal name in a base form ) and Asosen ( the genitive form of the name Asonen ) .For example , in Fin a - word / base form tests , the application of the classified s - gram technique gave performance improvements for 10 matching cases ( on the average precision was improved from 79,3 % to 82,7 % for the 52 matching cases ; Table 8a ) .","label":"CompareOrContrast","metadata":{},"score":"64.43146"}
{"text":"In a number of languages the words are not separated by spaces .Chinese , Japanese , ( the C and J in CJK ) , Thai , and Vietnamese are common languages that do not use white space to separate words For languages that do not use spaces , a segmentation algorithm has to be used .","label":"CompareOrContrast","metadata":{},"score":"64.53072"}
{"text":"The results were analyzed manually .The result lists were cut at the SIM - value of 0.2 .This means that for each query key the result list contained several hundreds words .In some cases the last relevant word did not occur in the list , in which case the default precision value of 0 % was used .","label":"CompareOrContrast","metadata":{},"score":"64.594696"}
{"text":"Spaces are inserted into positions where their presence enables the text to be compressed more effectively .This approach means that we can capitalize on existing research in text compression to create good models for word segmentation .To build a segmenter for a new language , the only resource required is a corpus of segmented text to train the compression model ... . by","label":"CompareOrContrast","metadata":{},"score":"64.667465"}
{"text":"The method or process steps for tokenization and named entity recognition of an ideographic language are effected by instructions in the software that are carried out by the computer .The software may be implemented as one or more modules for implementing the process steps .","label":"CompareOrContrast","metadata":{},"score":"64.73949"}
{"text":"The motivation for constructing such a system stems from the ... \" .This paper presents a novel method that allows a machine learning algorithm following the transformation - based learning paradigm ( Brill , 1995 ) to be applied to multiple classication tasks by training jointly and simultaneously on all elds . by Fuchun Peng , Xiangji Huang , Dale Schuurmans , Nick Cercone - Retrieval Performance in Chinese IR , Coling2002 , 2002 . \" ...","label":"CompareOrContrast","metadata":{},"score":"64.82443"}
{"text":"In the foregoing manner , a method , an apparatus , a computer program product and a system for tokenization and named entity recognition of ideographic language are described .While only a small number of embodiments are described , it will be apparent to those skilled in the art in view of this disclosure that numerous changes and/or modifications can be made without departing from the scope and spirit of the invention .","label":"CompareOrContrast","metadata":{},"score":"64.83165"}
{"text":"In addition to the POC tags assigned to the characters , the merging component incorporates a number of linguistic and statistical heuristics to detect words with regular internal structures , recognize long words , and filter non - words .Experiments show that , without resorting to a separate unknown word identification mechanism , the model achieves an F - score of 95.0 % for word segmentation and a competitive recall of 74.8 % for unknown word recognition . .","label":"CompareOrContrast","metadata":{},"score":"64.88814"}
{"text":"Digrams were run for all 8 lists .Trigrams were run for the following lists : Eng1 , Eng2 , Finnish a - words / base forms and Finnish a - words / genitive forms .For cross - lingual spelling variants , the digram baseline always performed better than the trigram baseline ( Tables 4 - 5 ) .","label":"CompareOrContrast","metadata":{},"score":"64.90544"}
{"text":"Transliteration may be used in combination with s - gram matching for better matching performance .Conclusions .In this study we discovered an effective n - gram technique which we call the targeted s - gram matching technique .We demonstrated that the technique is effective for many types of word form variants when a proper character combination operation is used .","label":"CompareOrContrast","metadata":{},"score":"65.04492"}
{"text":"At the core of the Solr / Lucene search engine is an inverted index .The inverted index has a list of tokens and a list of the documents that contain those tokens .In order to index text , Solr needs to break strings of text into \" tokens . \"","label":"CompareOrContrast","metadata":{},"score":"65.099304"}
{"text":"[ 0019 ]According to the invention , various word segmentation units can be provided through a search engine .For instance , a query ( \" had a try \" ) returns ( \" tried \" ) , ( \" a try \" ) , ( \" had a try \" ) by the Yahoo !","label":"CompareOrContrast","metadata":{},"score":"65.10707"}
{"text":"In step 310 , the feature - extraction process commences for a , given lexicon and a particular type of segmented name corpus 110 .The segmented name corpus can be organized as a list of named entities .In this connection , a list of named entities 910 is depicted in FIG .","label":"CompareOrContrast","metadata":{},"score":"65.18039"}
{"text":"We introduce inversion - invariant transduction grammars which serve as generafive models for parallel bilingual se ... \" .We describe a granmmrless method for simultaneously bracketing both halves of a parallel text and giving word alignments , assuming only a translation lexicon for the language pair .","label":"CompareOrContrast","metadata":{},"score":"65.18846"}
{"text":"In accordance with a third aspect of the invention , there is disclosed a computer program product having a computer readable medium having a computer program recorded therein for tokenization and named entity recognition of ideographic language .BRIEF DESCRIPTION OF THE DRAWINGS .","label":"CompareOrContrast","metadata":{},"score":"65.31973"}
{"text":"New York , NY : ACM Press , .Pirkola , A , Keskustalo , Heikki , Leppnen , Erkka , Knsl , Antti - Pekka and Jrvelin , Kalervo ( 2002 ) \" Targeted s - gram matching : a novel n - gram matching technique for cross- and monolingual word form variants . \"","label":"CompareOrContrast","metadata":{},"score":"65.32959"}
{"text":"The target word list .In the Information Retrieval Laboratory at the University of Tampere there are many full text research databases .Laboratory 's Finnish database contains 55 000 documents ( Finnish newspaper articles ) .A set of 35 test topics has been created on the basis of the articles .","label":"CompareOrContrast","metadata":{},"score":"65.406944"}
{"text":"A possible reason is that the feature space is too simple to fully describe the data , so that the power of SVM models was not fully taken advantages of .We argue that a better performance can be achieved with more search results provided .","label":"CompareOrContrast","metadata":{},"score":"65.463646"}
{"text":"This study was the first in our n - gram research project at the University of Tampere Information Retrieval Laboratory .In the project we are studying n - gram based translation of proper names and other spelling variants .In the next phrase , we will set up a new research environment ( fully automated analysis methods and English language as a target language ) .","label":"CompareOrContrast","metadata":{},"score":"65.62409"}
{"text":"Under the formalism of Equation ( 2 ) , the probabilities of the sub - string ending at the preceding adjacent words and the probabilities between the current word and its preceding adjacent words are combined .A pointer is created to point to the most probable preceding word .","label":"CompareOrContrast","metadata":{},"score":"65.62836"}
{"text":"The learning algorithm does not assume any underlying phonological structures or rules , and can be extended to other language pairs once a training corpus and a pronouncing dictionary are available .Easy To Use Patents Search & Patent Lawyer Directory .","label":"CompareOrContrast","metadata":{},"score":"65.941216"}
{"text":"N - gram matching is a language independent matching technique .It thus seems to be an ideal approximate matching technique for CLIR systems processing different languages .Moreover , n - gram matching has been reported to be an effective technique among various approximate matching techniques ( Pfeifer et al .","label":"CompareOrContrast","metadata":{},"score":"66.21555"}
{"text":"Analysis of the formalism 's expressiveness suggests that it is particularly well - suited to model ordering shifts between languages , balancing needed flexibility against complexity constraints .We discuss a number of examples of how stochastic inversion transduction grammars bring bilingual constraints to bear upon problematic corpus analysis tasks such as segmentation , bracketing , phrasal alignment , and parsing .","label":"CompareOrContrast","metadata":{},"score":"66.24031"}
{"text":"Based on this formulation , with seven types of entity and three types of constituent features , the total number of features is 7 .The processing of the module 120 for extracting entity features is described hereinafter with reference to FIG .","label":"CompareOrContrast","metadata":{},"score":"66.24987"}
{"text":"New York , NY : ACM Press .Pirkola , A. , Hedlund , T. , Keskustalo , H. , and Jrvelin , K. ( 2001 ) \" Dictionary - based cross - language information retrieval : problems , methods , and research findings \" .","label":"CompareOrContrast","metadata":{},"score":"66.32451"}
{"text":"\" Investigating the Relationship of Word Segmentation Performance and Retrieval Performance in Chinese IR \" , Proceedings of the 19th Biennial International Conference on Computational Linguistics ( COLING'02 ) , Taipei , Taiwan , August 24-September 1 , 2002 .","label":"CompareOrContrast","metadata":{},"score":"66.421906"}
{"text":"\" Investigating the Relationship of Word Segmentation Performance and Retrieval Performance in Chinese IR \" , Proceedings of the 19th Biennial International Conference on Computational Linguistics ( COLING'02 ) , Taipei , Taiwan , August 24-September 1 , 2002 .","label":"CompareOrContrast","metadata":{},"score":"66.421906"}
{"text":"Pirkola , A. ( 1998 ) \" The effects of query structure and dictionary setups in dictionary - based cross - language information retrieval \" .Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , Melbourne , Australia , Aug. 24 - 28 , 1998 , pp .","label":"CompareOrContrast","metadata":{},"score":"66.49667"}
{"text":"Technically , if the search engine 's inverted indices are inaccessible as commercial search engines do , e.g. Google and Yahoo ! , we collect the highlights ( the red words in Figure 1 ) from the returned snippets as the segments .","label":"CompareOrContrast","metadata":{},"score":"66.5148"}
{"text":"[0002 ] Numerous Asian languages , such as Chinese , Japanese , Korean , Thai , and the like , do not delimit words by word boundary tag , such as white space , which is unlike English and other western languages .","label":"CompareOrContrast","metadata":{},"score":"66.7744"}
{"text":"Sign up to receive free email alerts when patent applications with chosen keywords are published SIGN UP .Abstract : .The present invention discloses a search - based segmentation method and device for a language without a word boundary tag .","label":"CompareOrContrast","metadata":{},"score":"66.82379"}
{"text":"For example , a module may be implemented using discrete electronic components , or it can form a portion of an entire electronic circuit such as an Application Specific Integrated Circuit ( ASIC ) .Numerous other possibilities exist .Those skilled in the art will appreciate that the system can also be implemented as a combination of hardware and software modules .","label":"CompareOrContrast","metadata":{},"score":"66.892"}
{"text":"Also , as described hereinbefore , a module can also be a packaged functional hardware unit for use with other components or modules .In particular , the software may be stored in a computer readable medium , including the storage devices described below .","label":"CompareOrContrast","metadata":{},"score":"67.02001"}
{"text":"The method according to claim 3 , wherein the extracting of candidate word segmentation units from the returned search results is implemented via extracting highlighted phrases in the returned snippets .The method according to claim 3 , wherein when the search engine is a self - maintained search engine , a word segmentation unit is obtained by viewing adjacencies of positions of terms in a document using information provided from an indexing table .","label":"CompareOrContrast","metadata":{},"score":"67.07085"}
{"text":"The first frame is selected as the current frame in which words are to be put .With reference to the example of FIG .11 , a character pointer is directed to the first character \" C1 \" in a character string .","label":"CompareOrContrast","metadata":{},"score":"67.27327"}
{"text":"w.sub.n .When a named entity is processed , w.sub.i indicates constituents of a named entity .The problem is then to estimate the joint probability of the constituent sequence , and this probability is used as the lexicon parameter of the entity .","label":"CompareOrContrast","metadata":{},"score":"67.40798"}
{"text":"Findings .The performance of s - grams .The results were evaluated as average precision at 100 % recall .In other words , we computed the proportion of relevant words to all words at the last relevant word in the result list .","label":"CompareOrContrast","metadata":{},"score":"67.46358"}
{"text":"The main paper in the algorithms literature is Pugh ( 1990 ) , which uses multilevel skip pointers to give expected list access ( the same expected efficiency as using a tree data structure ) with less implementational complexity .In practice , the effectiveness of using skip pointers depends on various system parameters .","label":"CompareOrContrast","metadata":{},"score":"67.49759"}
{"text":"The word bi - gram statistics are preferably used to find the conditional probability .In step 724 , the current word pointer is moved forward to the next word to begin preparing for possible processing of the next word .In decision block 726 , a check is made to determine if the current word pointer is pointing the end of current frame .","label":"CompareOrContrast","metadata":{},"score":"67.53708"}
{"text":"The apparatus according to claim 11 wherein said contextual language model and said one or more entity language models are dependent upon an n - gram paradigm .The apparatus according to claim 8 , wherein said lattice - generating means includes means for generating one or more elements of said lattice using said lexicon .","label":"CompareOrContrast","metadata":{},"score":"67.54466"}
{"text":"We present a model of text analysis for text - to - speech ( TTS ) synthesis based on ( weighted ) finite - state transducers , which serves as the text - analysis module of the multilingual Bell Labs TTS system .","label":"CompareOrContrast","metadata":{},"score":"67.609505"}
{"text":"We present a model of text analysis for text - to - speech ( TTS ) synthesis based on ( weighted ) finite - state transducers , which serves as the text - analysis module of the multilingual Bell Labs TTS system .","label":"CompareOrContrast","metadata":{},"score":"67.609505"}
{"text":"Cross - lingual spelling variation involves substitution and addition / deletion of letters in words .For instance , in the Finnish word kalsitoniini ( calcitonin ) there are many transformations typical of Finnish spelling variants : c  k and c  s substitutions , the lengthening of a vowel ( one type of addition ) and addition of a single vowel .","label":"CompareOrContrast","metadata":{},"score":"67.76959"}
{"text":"Claims : . selecting a word segmentation approach for the segment in accordance with at least part of the returned search results .The method according to claim 1 , wherein the at least part of the returned search results are top - ranked search results .","label":"CompareOrContrast","metadata":{},"score":"68.006775"}
{"text":"In the TWL , Finnish words were in many different forms owing to word inflection .For two words , their LCS is the longest character sequence of the sequences that occur in both words .For example , for the words r e t r i e v a l and r e v i v a l the LCS is r e i v a l .","label":"CompareOrContrast","metadata":{},"score":"68.08289"}
{"text":"In these cases , the orthographically closest equivalent was chosen for the test ( this also holds for the Eng2 list below ) .The selected English keys were translated into German and Swedish by means of medical dictionaries .In some cases translations were searched in the Web .","label":"CompareOrContrast","metadata":{},"score":"68.14054"}
{"text":"FIG .1 is a block diagram of a training module 100 , forming part of a system for tokenization and named - entity recognition of ideographic language in accordance with a first embodiment of the invention ; .FIG .2 is a block diagram of a decoding module 200 , forming part of the system for tokenization and named - entity recognition of ideographic language in accordance with a first embodiment of the invention ; .","label":"CompareOrContrast","metadata":{},"score":"68.5264"}
{"text":"A list of English place names and their Finnish equivalents was collected from a place name dictionary , which contains world 's place names in both languages .Each Finnish name was searched in the target word list .If the Finnish name was found in the list , the English name was selected as a query key .","label":"CompareOrContrast","metadata":{},"score":"68.60776"}
{"text":"An augmented dictionary , which includes potential unknown words ( in addition to known words ) , is used to segment the input corpus , unlike traditional approaches which use only known words for segmentation . by Mathias Creutz , Krista Lagus - In Proceedings of the International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning ( AKRR'05 . \" ...","label":"CompareOrContrast","metadata":{},"score":"68.68855"}
{"text":"0010 ] As can be seen from the descriptions above , although many different approaches have been proposed in the art , they are mainly methods based upon either dictionaries or statistics , and thus confront many problems in theory linguistics and computer linguistics .","label":"CompareOrContrast","metadata":{},"score":"68.72281"}
{"text":"In Proceedings of the 2nd international conference on Scalable information systems ( pp . 1 - 9 ) .Suzhou , China : ICST ( Institute for Computer Sciences , Social - Informatics and Telecommunications Engineering ) .Sproat , R. , Shih , C. , Gale , W. , & Chang , N. ( 1994 ) .","label":"CompareOrContrast","metadata":{},"score":"68.84355"}
{"text":"In Proceedings of the 2nd international conference on Scalable information systems ( pp . 1 - 9 ) .Suzhou , China : ICST ( Institute for Computer Sciences , Social - Informatics and Telecommunications Engineering ) .Sproat , R. , Shih , C. , Gale , W. , & Chang , N. ( 1994 ) .","label":"CompareOrContrast","metadata":{},"score":"68.84355"}
{"text":"[ 1 ] The Japanese writing system uses four different character sets , Kanji ( characters borrowed from Chinese ) , Hirigana , Katakana , and borrowed Latin alphabet : romanji .For our purposes , Japanese words written in Kanji have similar issues to Chinese .","label":"CompareOrContrast","metadata":{},"score":"68.85717"}
{"text":"[ 1 ] The Japanese writing system uses four different character sets , Kanji ( characters borrowed from Chinese ) , Hirigana , Katakana , and borrowed Latin alphabet : romanji .For our purposes , Japanese words written in Kanji have similar issues to Chinese .","label":"CompareOrContrast","metadata":{},"score":"68.85717"}
{"text":"Information Processing & Management , 19 ( 4 ) , 255 - 261 .Hedlund , T. , Keskustalo , H. , Pirkola , A. , Sepponen , M. , Jrvelin , K. ( 2001 ) \" Bilingual tests with Swedish , Finnish and German queries : dealing with morphology , compound words and query structure .","label":"CompareOrContrast","metadata":{},"score":"68.97383"}
{"text":"It has been reported to be an effective technique among different approximate matching techniques in indexed systems , such as text retrieval systems ( Pfeifer et al ., 1996 ; Zobel and Dart , 1995 ) .Pfeifer et al .","label":"CompareOrContrast","metadata":{},"score":"69.35794"}
{"text":"However , it may also be true that especially the end parts of English ( German , Swedish ) - Finnish spelling variants are different .For some language pairs , spelling variation concerns particularly the initial parts of words .For example , Spanish words often begin with the letter e , while the corresponding English words do start with other letters .","label":"CompareOrContrast","metadata":{},"score":"69.45647"}
{"text":"In the English language , capitalization indicates proper names .The capitalized feature of proper names in English provides important information on the location and boundary of proper names in a text corpus .Therefore , a need clearly exists for a system for tokenization and named - entity recognition of ideographic language .","label":"CompareOrContrast","metadata":{},"score":"69.60541"}
{"text":"General translation dictionaries may include some proper names , such as the names of countries and capital cities , as well as common technical terms , but generally these kinds of words are untranslatable .In dictionary - based cross - language retrieval untranslatable query keys are typically used in target language queries in their original source language forms .","label":"CompareOrContrast","metadata":{},"score":"69.61006"}
{"text":"The TWL contains some 119 000 words .It includes Finnish proper names ( e.g. , personal names , company names , and geographical names ) and Finnish common nouns , Finnish words borrowed from other languages , i.e. , spelling variants , English and other foreign language words , and Finnish spelling error forms .","label":"CompareOrContrast","metadata":{},"score":"69.92977"}
{"text":"SmartChineseAnalyzer [ 9 ] - indexes words based on dictionary and heuristics .It only deals with Simplified Chinese .Simplified Chinese characters are used in the Peoples Republic of China , Singapore , and Malaysia .Traditional Chinese characters are used in Taiwan , Hong Kong , and Macau , and for works published in Mainland China published prior to 1949 .","label":"CompareOrContrast","metadata":{},"score":"70.01839"}
{"text":"SmartChineseAnalyzer [ 9 ] - indexes words based on dictionary and heuristics .It only deals with Simplified Chinese .Simplified Chinese characters are used in the Peoples Republic of China , Singapore , and Malaysia .Traditional Chinese characters are used in Taiwan , Hong Kong , and Macau , and for works published in Mainland China published prior to 1949 .","label":"CompareOrContrast","metadata":{},"score":"70.01839"}
{"text":"This may depress the effectiveness .On the other hand , restricted skipping provides less similar digrams for related words than an extensive skipping .This also may depress the effectiveness .Therefore determining a balanced CCI seems crucial for s - gram matching to be effective .","label":"CompareOrContrast","metadata":{},"score":"70.119"}
{"text":"The induced morph lexicon stores parameters related to both the \" meaning \" and \" form \" of the morphs it contains .These parameters affect the role of the morphs in words .The model is implemented in a task of unsupervised morpheme segmentation of Finnish and English words .","label":"CompareOrContrast","metadata":{},"score":"70.46185"}
{"text":"FIG .12 illustrates the probabilities for a number of words in three frames .To simplify the drawing , each word is represented by a black circle with an associated probability .In step 722 , the contextual model is applied to find the optimal preceding adjacent word , and a backward pointer to that word is created .","label":"CompareOrContrast","metadata":{},"score":"70.47808"}
{"text":"We are n't doing stemming or lemmatization partially because it can increase recall at the expense of precision , which may not be desirable when searching the full text of 10 million books .Also stemming / lemmatization is language - specific and we try to avoid language specific processing because the OCR for all 400 + languages is in the one field .","label":"CompareOrContrast","metadata":{},"score":"70.5164"}
{"text":"[ 0034 ] Thus , the hits contained in the top - ranked documents intuitively suggest some candidate word segmentation units , which units indicate how characters associate with each other in a natural language .As shown in FIG .4 , for instance , ( \" he happily ) , ( \" happy \" ) , ( \" he said \" ) , etc . are obtained for a sentence such as ( \" he said happily \" ) .","label":"CompareOrContrast","metadata":{},"score":"70.565735"}
{"text":"12 is a diagram illustrating the probabilities of words and corresponding back pointers .DETAILED DESCRIPTION .A method , an apparatus , a computer program product and a system for tokenization and named entity recognition of ideographic language are described .","label":"CompareOrContrast","metadata":{},"score":"70.71709"}
{"text":"( 1 ) below : . [ 0040 ]The Eq .Fundamentally , this method corresponds to the maximum likelihood criterion .As to statistical learning theories , this criterion minimizes an empirical risk on a dataset when the dataset is large enough ( in compliance with the large - number theory ) .","label":"CompareOrContrast","metadata":{},"score":"71.00507"}
{"text":"[ 15 ] Although the Information Retrieval literature is pretty consistent in recommending a combination of unigrams and bigrams , exactly how they can be combined with Solr remains to be determined .If we were indexing small fields we would copy the field containing CJK and index one field as bigrams and one as unigrams and then combine them with dismax to give much more weight to matches in the bigrams .","label":"CompareOrContrast","metadata":{},"score":"71.04932"}
{"text":"[ 15 ] Although the Information Retrieval literature is pretty consistent in recommending a combination of unigrams and bigrams , exactly how they can be combined with Solr remains to be determined .If we were indexing small fields we would copy the field containing CJK and index one field as bigrams and one as unigrams and then combine them with dismax to give much more weight to matches in the bigrams .","label":"CompareOrContrast","metadata":{},"score":"71.04932"}
{"text":"In step 318 , the feature \" entity - begin \" or E - Begin is added to this word in the lexicon .The entity category is easily determined by the type(s ) of training corpus .In the example of FIG .","label":"CompareOrContrast","metadata":{},"score":"71.22983"}
{"text":"[ 0050 ]Here , S ( ) is a score given via either the frequency - based method or the SVM - based method , and n is the number of word segmentation units contained in the optimal subset .[ 0051 ] There will be other possible path - finding criteria which are effective , such as greedy search , etc . .","label":"CompareOrContrast","metadata":{},"score":"71.262436"}
{"text":"The problem is that a group of characters might be segmented in different ways resulting in different meanings .There are Chinese jokes based on these ambiguities .In the example below from ( Teahan , McNab , Wen , & Witten , 2000)the first segmentation means \" I like New Zealand Flowers .","label":"CompareOrContrast","metadata":{},"score":"71.30843"}
{"text":"The problem is that a group of characters might be segmented in different ways resulting in different meanings .There are Chinese jokes based on these ambiguities .In the example below from ( Teahan , McNab , Wen , & Witten , 2000)the first segmentation means \" I like New Zealand Flowers .","label":"CompareOrContrast","metadata":{},"score":"71.30843"}
{"text":"6 gives an example for this , and illustrates word segmentation results of the inventive method for an illustrative sentence ( those have titles of a technical post and these have n't titles of a technical post ) \" vs. the IBM Full - Parser .","label":"CompareOrContrast","metadata":{},"score":"71.64906"}
{"text":"The computer program product according to claim 15 , wherein said contextual language model and said one more entity language models are each class - based language models .The compute program product according to claim 15 , wherein said cotextual language model and said one or more entity language models incorporate local and contextual linguistic information , respectively , for producing prioritized word and corresponding category sequences .","label":"CompareOrContrast","metadata":{},"score":"71.768234"}
{"text":"Sormunen , E. ( 2000 ) \" A novel method for the evaluation of Boolean query effectiveness across a wide operational range \" .Proceedings of the 23 rd Annual ACM SIGIR Conference on Research and Development in Information Retrieval , Athens , July 24 - 28 , 2000 , pp .","label":"CompareOrContrast","metadata":{},"score":"71.78176"}
{"text":"In the system according to the first embodiment , named entities are described in the following manner : .Named entities can have three kinds of constituents : entity - begin , entity - continuance , and entity - end .In a named entity , entity - begin and entity - end can be the same .","label":"CompareOrContrast","metadata":{},"score":"71.94919"}
{"text":"2.2.1 Frequency - based .This method uses term frequency as the scoring function , which is defined as the ratio of the number of occurrences of the segment to the total number of occurrences of all the segments .2.2.2SVM - based .","label":"CompareOrContrast","metadata":{},"score":"72.10721"}
{"text":"Segments Selecting .We call a subset \" valid \" if its member segments can reconstruct exactly the query , and the score of a valid subset is the average score of its member segments .We select the valid subset which scores the highest as the final segmentation .","label":"CompareOrContrast","metadata":{},"score":"72.115906"}
{"text":"In step 614 , a word pointer is set at the first word of the current frame , indicating that this is the current word under consideration .In FIG .11 , the word pointer is depicted as initially pointing at the word \" C1 \" .","label":"CompareOrContrast","metadata":{},"score":"72.12982"}
{"text":"In step 522 , name suggestion processing is carried out on the word lattice .In step 524 , lattice construction processing for the sentence terminates .The name suggestion process of step 522 is depicted in FIG .6 .Processing commences in step 610 .","label":"CompareOrContrast","metadata":{},"score":"72.28865"}
{"text":"The Solr QueryParser and CJK processing .The Solr QueryParser had a bug which caused any string that is separated into separate tokens by the filter chain to be searched as a phrase query .[ 10 ] So until this bug was fixed , it did n't matter which of the Analyzer / Tokenizers you used .","label":"CompareOrContrast","metadata":{},"score":"72.49404"}
{"text":"The Solr QueryParser and CJK processing .The Solr QueryParser had a bug which caused any string that is separated into separate tokens by the filter chain to be searched as a phrase query .[ 10 ] So until this bug was fixed , it did n't matter which of the Analyzer / Tokenizers you used .","label":"CompareOrContrast","metadata":{},"score":"72.49404"}
{"text":"Evaluation on five test sets with different standards shows that the adaptive system achieves state - of - the - art performance on all the test sets . rules ( or transformations ) are acquired automatically from application data via the TBL method ( Gao et al .","label":"CompareOrContrast","metadata":{},"score":"72.60521"}
{"text":"Evaluation on five test sets with different standards shows that the adaptive system achieves state - of - the - art performance on all the test sets . rules ( or transformations ) are acquired automatically from application data via the TBL method ( Gao et al .","label":"CompareOrContrast","metadata":{},"score":"72.60521"}
{"text":"The temporary solution for the issues with unigrams is a list of suggestions to users to put Chinese \" words \" in quotes separated by spaces .[ 3 ] .Update : January 1 , 2012 : Robert Muir , Solr / Lucene committer , completed the patch and committed the code for LUCENE-2906 in late December .","label":"CompareOrContrast","metadata":{},"score":"73.01729"}
{"text":"The query key lists are described in Table 2 .For each query key , the corresponding Finnish word in different forms in the TWL formed the recall base of the key ( i.e. , the set of relevant words ( word forms ) ) .","label":"CompareOrContrast","metadata":{},"score":"73.2103"}
{"text":"5 depicts one illustrative word segmentation result according to the invention ; and .[ 0028 ] FIG .6 depicts another illustrative word segmentation result according to the invention .DESCRIPTION OF THE PREFERRED EMBODIMENTS .[ 0029 ] Preferred embodiments of the invention will be described in details hereinafter .","label":"CompareOrContrast","metadata":{},"score":"73.2459"}
{"text":"Preferably , a Viterbi search engine is used , as depicted in FIG . 7 .In step 710 , processing commences .In step 712 , the frame index is set at a value of 1 for the first frame , indicating that this is the current frame under consideration .","label":"CompareOrContrast","metadata":{},"score":"73.594604"}
{"text":"Although they are worse than those reported by SIGHAN'05 , the approach is effective because we used only 3,000 training sentences ( in the case of SVM - based method ) while SIGHAN'05 groups used about 86,000 .Moreover , out method avoids OOV problem .","label":"CompareOrContrast","metadata":{},"score":"73.60466"}
{"text":"Otherwise , if decision block 320 returns true ( Yes ) indicating the word is the last one in the entity , processing continues at step 324 .In step 324 , the feature \" entity - end \" or E - End is added to the word in the system lexicon .","label":"CompareOrContrast","metadata":{},"score":"73.654655"}
{"text":"FIELD OF THE INVENTION .The present invention relates to the field of natural language processing , and in particular to systems for tokenizing and recognizing named entities in a text corpus of an ideographic language .BACKGROUND .Natural language processing is an area of technology experiencing active research interest .","label":"CompareOrContrast","metadata":{},"score":"74.00355"}
{"text":"Thus , we used as test words such words that actually are problematic in IR .This method of isolating the difficult cases in a separate file is reasonable from the n - gram matching perspective , otherwise the effectiveness of n - gram matching would be lower due to the higher number of TWL words .","label":"CompareOrContrast","metadata":{},"score":"74.12427"}
{"text":"Patents are available using simple keyword or date criteria .If you are looking to hire a patent attorney , you 've come to the right place .Protect your idea and hire a patent lawyer .A system ( 100 , 200 ) for tokenization and named entity recognition of ideographic language is disclosed .","label":"CompareOrContrast","metadata":{},"score":"74.49448"}
{"text":"Approximate matching techniques involve Soundex and Phonix , which compare words on the basis of their phonetic similarity ( Gadd , 1988 ; Gadd , 1990 ) .In the techniques , phonetic codes are computed for the strings that are compared , and the strings with similar codes are counted similar .","label":"CompareOrContrast","metadata":{},"score":"74.51048"}
{"text":"The temporary solution for the issues with unigrams is a list of suggestions to users to put Chinese \" words \" in quotes separated by spaces .Update : January 1 , 2012 : Robert Muir , Solr / Lucene committer , completed the patch and committed the code for LUCENE-2906 in late December .","label":"CompareOrContrast","metadata":{},"score":"74.53349"}
{"text":"A computer program product includes a computer readable medium having such software or a computer program recorded on it that can be carried out by a computer .The use of the computer program product in the computer preferably effects an advantageous apparatus for tokenization and named entity recognition of an ideographic language in accordance with the embodiments of the invention .","label":"CompareOrContrast","metadata":{},"score":"74.5411"}
{"text":"If decision block 616 returns false ( No ) , processing continues at step 624 .Otherwise , if decision block 616 returns true ( Yes ) , processing continues at step 618 .In step 618 , the current word is expanded by applying finite state grammars ( FSGs ) indicated by Equation ( 1 ) to adjacent words in following frames .","label":"CompareOrContrast","metadata":{},"score":"74.60823"}
{"text":"The unrestricted s - gram technique , in which all the possible digrams are formed is the worst method , giving much lower precision ( 38.2 % ) than the baseline ( 55.2 % ) .The results are presented in Tables 5 - 8 .","label":"CompareOrContrast","metadata":{},"score":"74.609764"}
{"text":"Processing then continues at step 714 .Otherwise , if decision block 728 returns true ( Yes ) , processing continues at step 732 .In step 732 , the backward pointer of the most probable word is traced back in the last frame , and the word sequence and entity information , if any , are then output .","label":"CompareOrContrast","metadata":{},"score":"74.70154"}
{"text":"[0044 ] 2 .A higher AVGOCCU value indicates a better word segmentation unit .[ 0045 ] 3 .DF : The \" DF \" feature is defined as a document frequency , that is , as for a word segmentation unit , how many search results contain the word segmentation unit .","label":"CompareOrContrast","metadata":{},"score":"74.77897"}
{"text":"In fact , based on a rough evaluation , much better performance can be achieved if we combine search results of Yahoo ! and Google .However , since Yahoo ! prohibits frequent query ( to prevent DDOS attack ) , we were not able to collect enough training data from Yahoo ! , but it inspires us that with a local search engine and a large document set , we can expect a much better performance .","label":"CompareOrContrast","metadata":{},"score":"74.88472"}
{"text":"Preferably , this is done three times , although other numbers of times may be practiced without departing from the scope and spirit of the invention .The embodiments of the invention implement a statistically based system .The system can be trained using off - the - shelf data that can be readily obtained .","label":"CompareOrContrast","metadata":{},"score":"74.95091"}
{"text":"11 pointing at the first frame .Dashed vertical lines indicate the frame boundaries .In step 514 , the character string starting from the pointer is matched with the system lexicon to find all possible sub - strings / candidate words .","label":"CompareOrContrast","metadata":{},"score":"75.056526"}
{"text":"Computing similarity values .Similarity values were computed using the following string similarity scheme ( Pfeifer et al .where N 1 and N 2 are digram sets of two words .For example , the degree of similarity for the words rwanda .","label":"CompareOrContrast","metadata":{},"score":"75.139046"}
{"text":"Otherwise , if decision block 716 returns true ( Yes ) , processing continues at step 718 .In step 718 , the lexicon probability of the entity is estimated from its corresponding entity models under the formalism of Equation ( 2 ) .","label":"CompareOrContrast","metadata":{},"score":"75.82492"}
{"text":"[ 0057 ] It shall be noted that descriptions of some technical details , which are well known to those skilled in the art , and may be necessary to practice the invention , have been omitted to make the invention more apparent .","label":"CompareOrContrast","metadata":{},"score":"76.10217"}
{"text":"In decision block 716 , a check is made to determine if the current word in the lattice is a newly suggested entity .If decision block returns false ( No ) , processing continues at step 720 .In step 720 , the lexicon probability data of the word is obtained from the contextual language model data .","label":"CompareOrContrast","metadata":{},"score":"76.113434"}
{"text":"Among other things it was interacting with dirty OCR to create long strings of nonsense which added millions of nonsense \" words \" to our index .After some discussion with some of the Solr / Lucene committers we decided to use the ICUTokenizer .","label":"CompareOrContrast","metadata":{},"score":"76.34503"}
{"text":"Among other things it was interacting with dirty OCR to create long strings of nonsense which added millions of nonsense \" words \" to our index .After some discussion with some of the Solr / Lucene committers we decided to use the ICUTokenizer .","label":"CompareOrContrast","metadata":{},"score":"76.34503"}
{"text":"Table 3 presents examples of unclassified and classified s - grams with different CCIs . abcde .( [ 0 ] , [ 1 ] ) .abcde .( [ 0 ] , [ 1 , 2 ] ) .axxc .","label":"CompareOrContrast","metadata":{},"score":"76.47038"}
{"text":"In decision block 520 , a check is made to determine if the character pointer has reached the end of the current sentence .If decision block 520 returns false ( No ) , processing continues at step 514 for the next character in the sentence .","label":"CompareOrContrast","metadata":{},"score":"76.58052"}
{"text":"To date , the model has been applied to eight languages : Spanish , Italian , Romanian , . ... onal mechanism for accomplishing this is the finite - state transducer ( FST ) .We present such a model below .","label":"CompareOrContrast","metadata":{},"score":"76.881195"}
{"text":"Evaluation on SIGHAN'05 data with the two different segment scoring methods .Comparison to IBM Full - parser ( FP ) .Figure 3 gives examples of the comparison results between our method and IBM Full - Parser , which show four cases that our method is superior to the dictionary - based methods .","label":"CompareOrContrast","metadata":{},"score":"77.094345"}
{"text":"FIG .5 is a flow diagram depicting the lattice - construction processing of the module 220 of FIG .2 ; .FIG .6 is a flow diagram depicting the named - entity suggestion processing of step 522 of FIG .","label":"CompareOrContrast","metadata":{},"score":"77.20949"}
{"text":"Different kernels may be tried , such as RBF kernel , sigmoid kernel , linear and polynomial kernels .It is possible to choose either an SVM classifier or an SVM regression model to score a word segmentation unit .However , since the training of an SVM regression model requires providing a numerical score to each training data point , it is generally difficult to specify a score strategy .","label":"CompareOrContrast","metadata":{},"score":"77.418106"}
{"text":"9 simply had the name \" Bai \" , a P - End feature would also be added to the \" Bai \" entry 1010 of FIG .10 .If decision block 320 returns false ( No ) , processing continues at step 322 .","label":"CompareOrContrast","metadata":{},"score":"77.46016"}
{"text":"The foregoing is merely exemplary of the types of computers with which the embodiments of the invention may be practiced .Typically , the processes of the embodiments , described hereinafter , are resident as software or a program recorded on a hard disk drive ( generally depicted as block 812 in FIG .","label":"CompareOrContrast","metadata":{},"score":"77.48598"}
{"text":"Intermediate storage of the program and intermediate data and any data fetched from the network man be accomplished using the semiconductor memory 806 , possibly in concert with the hard disk drive 812 .The foregoing is merely exemplary of relevant computer readable mediums .","label":"CompareOrContrast","metadata":{},"score":"77.59591"}
{"text":"What is claimed is : .A method of tokenization and named entity recognition of ideographic language , said method including the steps of : . generating segmented text by determining word boundaries in said string of ideographic characters using said word lattice dependent upon a contextual language model and one or more entity language models ; and .","label":"CompareOrContrast","metadata":{},"score":"77.72466"}
{"text":"It will be apparent to one skilled in the art , however , that the present invention may be practised without these specific details .In other instances , well - known features are not described in detail so as not to obscure the present invention .","label":"CompareOrContrast","metadata":{},"score":"77.77556"}
{"text":"In step 624 , the word pointer is moved forward to the next word in the same frame .In decision block 626 , a check is made to determine whether the word pointer has reached the end of current frame .","label":"CompareOrContrast","metadata":{},"score":"77.98152"}
{"text":"The test uses both the direction and the relative magnitude of the difference of comparable samples .The statistical program that was used is based on Conover ( 1980 ) .The statistical significance levels of 0.01 , and 0.001 are indicated in the tables .","label":"CompareOrContrast","metadata":{},"score":"78.75453"}
{"text":"SIXTH CONFERENCE ON NATURAL LANGUAGE LEARNING , 2002 . \" ...In many cross - lingual applications we need to convert a transliterated word into its original word .In this paper , we present a similarity - based framework to model the task of backward transliteration , and provide a learning algorithm to automatically acquire phonetic similarities from a corpu ... \" .","label":"CompareOrContrast","metadata":{},"score":"78.899185"}
{"text":"Acknowledgements .This research is part of the research project Query structures and dictionaries as tools in concept - based and cross - lingual information retrieval funded by the Academy of Finland ( Research Projects 44703 ; 49157 ) .References .","label":"CompareOrContrast","metadata":{},"score":"79.147354"}
{"text":"However , because we could not write a Lucene tokenizer that would segment words the same way that Google was segmenting the OCR , we were unable to take advantage of this segmentation .Additionally , HathiTrust receives OCR from works digitized from the Internet Archive and other sources that do not use the Google segmenter .","label":"CompareOrContrast","metadata":{},"score":"79.28493"}
{"text":"However , because we could not write a Lucene tokenizer that would segment words the same way that Google was segmenting the OCR , we were unable to take advantage of this segmentation .Additionally , HathiTrust receives OCR from works digitized from the Internet Archive and other sources that do not use the Google segmenter .","label":"CompareOrContrast","metadata":{},"score":"79.28493"}
{"text":"The person 's name ( Pn ) can comprise a person 's name begin ( Pnb ) , a person 's name continue ( Pnc ) , and a person 's name end ( Pne ) .Examples of Pnb are : Pnb.fwdarw . Bai.vertline .","label":"CompareOrContrast","metadata":{},"score":"79.2924"}
{"text":"[ 10 ] The bug in the Solr query parser only affects filter chains that break a token into multiple tokens with different positions .For example the synonym filter which produces multiple tokens with the same position is unaffected by this bug .","label":"CompareOrContrast","metadata":{},"score":"79.49927"}
{"text":"[ 10 ] The bug in the Solr query parser only affects filter chains that break a token into multiple tokens with different positions .For example the synonym filter which produces multiple tokens with the same position is unaffected by this bug .","label":"CompareOrContrast","metadata":{},"score":"79.49927"}
{"text":"The QueryParser bug was fixed with a configuration parameter in Solr 3.1 .Since this parameter is set on a per - field basis and we have multiple languages in the OCR field , this affects both CJK and other languages .","label":"CompareOrContrast","metadata":{},"score":"79.564156"}
{"text":"The QueryParser bug was fixed with a configuration parameter in Solr 3.1 .Since this parameter is set on a per - field basis and we have multiple languages in the OCR field , this affects both CJK and other languages .","label":"CompareOrContrast","metadata":{},"score":"79.564156"}
{"text":"The method according to claim 1 . further including the step of combining said contextual language model and said one or more entity language models .The method according to claim 1 , wherein said contextual language model and said one or more entity language models are each class - based language models .","label":"CompareOrContrast","metadata":{},"score":"79.63066"}
{"text":"The corpus ( Sinica 2.0 ) is open to the research community through the WWW ... \" . byJianfeng Gao , Andi Wu , Grapecity Inc , Mu Li , Chang - ning Huang - Computational Linguistics , 2005 . \" ...","label":"CompareOrContrast","metadata":{},"score":"79.99812"}
{"text":"On the other hand , the words Beijing and China each are a place name and have two features : place - begin and place - end .As an illustration , a typical expression is : .Hongkong Asia Pacific Satellite Communication Corporation .","label":"CompareOrContrast","metadata":{},"score":"80.771194"}
{"text":"FIG .4 illustrates an example of Yahoo ! search results for ( he said happily ) .Red highlights indicate word segmentation units , e.g. ( he happily ) , ( say ) , ( happy ) , etc . ) .","label":"CompareOrContrast","metadata":{},"score":"81.35122"}
{"text":"The current frame under consideration is changed to the next one in the lattice .Processing then continues at step 614 .Otherwise , if decision block 628 returns true ( Yes ) , processing continues at step 632 .In step 632 , the name suggestion processing terminates .","label":"CompareOrContrast","metadata":{},"score":"81.451126"}
{"text":"A module , and in particular its functionality , can be implemented in either hardware or software .In the software sense , a module is a process , program , or portion thereof , that usually performs a particular function or related functions .","label":"CompareOrContrast","metadata":{},"score":"82.070946"}
{"text":"Tom , Thank you so much for this write up and all the references !I can bring this to our CJK librarians and have an intelligent discussion on which problems to tackle first and what to try .I 'm hoping I can focus some coding effort on a solr index testing gem for the community that will make it easier to write tests for search result relevancy .","label":"CompareOrContrast","metadata":{},"score":"82.20868"}
{"text":"In decision block 420 , a check is made to determine if the last word in the list has been finished , i.e. if all of the words have been put into the classes .If decision block 420 returns false ( No ) , processing continues at step 414 and the next word is selected .","label":"CompareOrContrast","metadata":{},"score":"82.949905"}
{"text":"It seems that the only means to find right correspondents in cases like this is to use transliteration rules .For transliteration in CLIR ( Japanese - English word transliteration ) , see ( Fujii and Ishikawa , 2001 ) .At the University of Tampere our objective is to develop language independent methods for CLIR .","label":"CompareOrContrast","metadata":{},"score":"84.79808"}
{"text":"If decision block 626 returns true ( Yes ) , processing continues at decision block 628 .In decision block 628 , a check is made to determine if the current frame is the last frame of the word lattice .If decision block 628 returns false ( No ) , processing continues at step 630 .","label":"CompareOrContrast","metadata":{},"score":"85.00195"}
{"text":"10 is given the feature P - Begin for a person 's name .Processing then continues at the decision block 320 .In decision block 320 , a check is made to determine if the current word is the last word of the named entity , based on the position information of the word in the entity being processed .","label":"CompareOrContrast","metadata":{},"score":"85.8846"}
{"text":"( 2006 ) for a recent survey .Experiments on and discussion of the positive and negative impact of stemming in English can be found in the following works : Salton ( 1989 ) , Krovetz ( 1995 ) , Hull ( 1996 ) , Harman ( 1991 ) .","label":"CompareOrContrast","metadata":{},"score":"85.915634"}
{"text":"Compound splitting gained 25 % for Swedish and 15 % for German , but only 4 % for Dutch .Tomlinson ( 2003 ) presents broadly similar results .The classic presentation of for IR can be found in Moffat and Zobel ( 1996 ) .","label":"CompareOrContrast","metadata":{},"score":"86.06495"}
{"text":"The expansion produces one or more entity candidates , meaning that the expansion succeeded , or none , meaning that the expansion failed .In decision block 620 , a check is made to determine if the expansion is successful .If decision block 620 returns false ( No ) , processing continues at step 624 .","label":"CompareOrContrast","metadata":{},"score":"87.165794"}
{"text":"Otherwise , if decision block 726 returns true ( Yes ) , processing continues at decision block 728 .In decision block 728 , a check is made to determine if the last frame of the lattice has been reached .If decision block 728 returns false ( No ) , processing continues at step 730 .","label":"CompareOrContrast","metadata":{},"score":"87.50743"}
{"text":"0.361111 calcitonin calvinin .An example of a compound word containing a relevant word is the compound sambesijoki ( zambezi river ) for the key zambezi ( sambesi ) .An example of an adjective derivative is the word katatoninen ( catatonic ) , which is derived from the noun katatonia ( catatonia ) .","label":"CompareOrContrast","metadata":{},"score":"87.891235"}
{"text":"For example , an operator can use the keyboard 818 and/or a pointing device such as the mouse 820 to provide input to the computer 802 .The system 800 is simply provided for illustrative purposes and other configurations can be employed without departing from the scope and spirit of the invention .","label":"CompareOrContrast","metadata":{},"score":"87.99539"}
{"text":"In addition , the computer system 800 can have any of a number of other output devices including line printers , laser printers , plotters , and other reproduction devices connected to the computer 802 .The computer system 800 can be connected to one or more other computers via a communication interface 808b using an appropriate communication channel 830 such as a modem communications path , a computer network , or the like .","label":"CompareOrContrast","metadata":{},"score":"88.26253"}
{"text":"In decision block 316 , a check is made to determine if the current word . based on the position information of the word in the entity being processed , is the first word of the named entity .If decision block 316 returns false ( No ) , processing continues at decision block 320 .","label":"CompareOrContrast","metadata":{},"score":"88.36001"}
{"text":"In decision block 326 , a check is made to determine if the end of the training corpus 110 has been reached .If decision block .326 returns false ( No ) , processing continues at step 312 and another named entity is read from the training corpus 110 .","label":"CompareOrContrast","metadata":{},"score":"89.16642"}
{"text":"The apparatus according to claim 8 , further including means for combining said contextual language model and said one or more entity language models .The apparatus according to claim 8 , wherein said contextual language model and said one or more entity language models are each class - based language models .","label":"CompareOrContrast","metadata":{},"score":"91.16533"}
{"text":"In : Cross - language information retrieval and evaluation .Cross - language evaluation forum workshop , CLEF 2000 , Lisbon , Portugal , September 22 - 23 , 2000 , Revised Papers .pp .211 - 225 .Heidelberg : Springer , ( Lecture Notes in Computer Science , Vol .","label":"CompareOrContrast","metadata":{},"score":"91.30293"}
{"text":"Each of the components 804 to 812 is typically connected to one or more of the other devices via a bus 814 that in turn can consist of data , address , and control buses .The video interface 810 is connected to the video display 816 and provides video signals from the computer 802 for display on the video display 816 .","label":"CompareOrContrast","metadata":{},"score":"92.81308"}
{"text":"Huazhong University of Science and Technology Wunhan , China .Yong Qin .IBM China Research Lab Beijing , China .Copyright is held by the World Wide Web Conference Committee ( IW3C2 ) .Distribution of these papers is limited to classroom use , and personal use by others .","label":"CompareOrContrast","metadata":{},"score":"93.482254"}
{"text":"Hooray for open source and the Solr / Lucene communitiy !We will be testing the new code and plan to put it into production some time in February .Abdou , S. , & Savoy , J. ( 2006 ) .","label":"CompareOrContrast","metadata":{},"score":"95.21167"}
{"text":"Hooray for open source and the Solr / Lucene communitiy !We will be testing the new code and plan to put it into production some time in February .Abdou , S. , & Savoy , J. ( 2006 ) .","label":"CompareOrContrast","metadata":{},"score":"95.21167"}
{"text":"0058 ]The specification is provided for the purpose of illustration and description but not to exhaust or limit the invention to the disclosure .Various modifications and variations shall be apparent to those skilled in the art .IBM China Research Lab Beijing , China .","label":"CompareOrContrast","metadata":{},"score":"98.934875"}
