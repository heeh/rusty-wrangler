{"text":"In an interesting spin - off of this work , we have applied the idea of using a pair of weight vectors to define similarity measures for case - based classification systems that can report their classification confidence [ Bridge & Ferguson 2001 ] .","label":"Background","metadata":{},"score":"31.539192"}
{"text":"Research results in the recent years show that combining the two modalities ( text based and content based ) even with simple fusion strategies alleviates the image retrieval results and also reduces the semantic gap .In this paper , we propose a new approach called weighted semantic similarity , which assesses the semantics between the query image and textual query provided by the user as an input to the system .","label":"Background","metadata":{},"score":"32.543907"}
{"text":"Research results in the recent years show that combining the two modalities ( text based and content based ) even with simple fusion strategies alleviates the image retrieval results and also reduces the semantic gap .In this paper , we propose a new approach called weighted semantic similarity , which assesses the semantics between the query image and textual query provided by the user as an input to the system .","label":"Background","metadata":{},"score":"32.543907"}
{"text":"However , it does not scale to problems with a large set of potential meanings for each sentence , such as the navigation instruction following task studied by Chen and Mooney ( 2011 ) .This paper presents an enhancement of the PCFG approach that scales to such problems with highly - ambiguous supervision .","label":"Background","metadata":{},"score":"33.168068"}
{"text":"Experimental results show that a closer correspondence to human data can be obtained by uncovering latent information shared among the textual and perceptual modalities rather than arriving at semantic knowledge by concatenating the two . ...An important question in the formulation of such models concerns the provenance of perceptual information .","label":"Background","metadata":{},"score":"33.717007"}
{"text":"Borschinger et al .'s approach works well in situations of limited ambiguity , such as in the sportscasting task .However , it does not scale well to highly ambiguous situations when there are large sets of potential meaning possibilities for each sentence , such as in the navigation instruction following task first studied by Chen and Mooney ( 2011 ) .","label":"Background","metadata":{},"score":"34.634026"}
{"text":"Borschinger et al .'s approach works well in situations of limited ambiguity , such as in the sportscasting task .However , it does not scale well to highly ambiguous situations when there are large sets of potential meaning possibilities for each sentence , such as in the navigation instruction following task first studied by Chen and Mooney ( 2011 ) .","label":"Background","metadata":{},"score":"34.634026"}
{"text":"We find that this hypothesis only holds when it is applied to relevant dimensions .We propose a robust supervised approach that achieves accuracies of .84 and .85 on two existing datasets and that can be interpreted as selecting the dimensions that are relevant for distributional inclusion .","label":"Background","metadata":{},"score":"34.889793"}
{"text":"We find that this hypothesis only holds when it is applied to relevant dimensions .We propose a robust supervised approach that achieves accuracies of .84 and .85 on two existing datasets and that can be interpreted as selecting the dimensions that are relevant for distributional inclusion .","label":"Background","metadata":{},"score":"34.889793"}
{"text":"We also introduce a modified closed - world assumption that significantly reduces the size of the ground network , thereby making inference feasible .Our approach is evaluated on the recognizing textual entailment task , and experiments demonstrate its dramatic impact on the efficiency of inference .","label":"Background","metadata":{},"score":"35.15583"}
{"text":"We also introduce a modified closed - world assumption that significantly reduces the size of the ground network , thereby making inference feasible .Our approach is evaluated on the recognizing textual entailment task , and experiments demonstrate its dramatic impact on the efficiency of inference .","label":"Background","metadata":{},"score":"35.15583"}
{"text":"We also introduce a modified closed - world assumption that significantly reduces the size of the ground network , thereby making inference feasible .Our approach is evaluated on the recognizing textual entailment task , and experiments demonstrate its dramatic impact on the efficiency of inference .","label":"Background","metadata":{},"score":"35.15583"}
{"text":"We extend the subsequence kernel to handle this weaker form of supervision , and describe a method for weighting features in order to focus on those correlated with the target relation rather than with the individual entities .The resulting Multiple Instance Learning approach offers a competitive alternative to previous relation extraction methods , at a significantly reduced cost in human supervision .","label":"Background","metadata":{},"score":"35.737526"}
{"text":"But , if we make less personalised predictions from summary information about the clusters , we obtain surprisingly good accuracy at tremendous speed [ Kelleher & Bridge 2003 , Kelleher & Bridge 2004 ] .Supporting Reuse in the Software Development Cycle .","label":"Background","metadata":{},"score":"36.47921"}
{"text":"Empirically , we show that it yields substantial improvements over previous work that used similar biases to initialize an EM - based learner .Additional gains are obtained by further shaping the prior with corpus - specific information that is extracted automatically from raw text and a tag dictionary .","label":"Background","metadata":{},"score":"36.603363"}
{"text":"Empirically , we show that it yields substantial improvements over previous work that used similar biases to initialize an EM - based learner .Additional gains are obtained by further shaping the prior with corpus - specific information that is extracted automatically from raw text and a tag dictionary .","label":"Background","metadata":{},"score":"36.603363"}
{"text":"In particular , we investigate the usefulness of three types of knowledge in guiding the extraction process : encyclopedic , syntactic and semantic .We present first a semantic analysis of existing , human - generated feature production norms , which reveals information about co - occurring concept and feature classes .","label":"Background","metadata":{},"score":"36.912212"}
{"text":"The proposed approach is assessed on standard annotated database .Higher values of precision and recall show better performance of the proposed approach .Moreover , the use of correlation helps in reducing the semantic gap and providing good results through better ranking of the similar images .","label":"Background","metadata":{},"score":"37.059895"}
{"text":"The proposed approach is assessed on standard annotated database .Higher values of precision and recall show better performance of the proposed approach .Moreover , the use of correlation helps in reducing the semantic gap and providing good results through better ranking of the similar images .","label":"Background","metadata":{},"score":"37.059895"}
{"text":"We test the model on a variety of different datasets from grounded cognition experiments and demonstrate that this diverse set of results can be explained as perceptual simulation ( cf .Barsalou , Simmons , Barbey , & Wilson , 2003 ) within a global memory model . .","label":"Background","metadata":{},"score":"37.57812"}
{"text":"It is especially important in language grounding where the training data usually consist of language paired with an ambiguous perceptual context .Recent work by Chen and Mooney ( 2011 ) introduced a lexicon learning method that deals with ambiguous relational data by taking intersections of graphs .","label":"Background","metadata":{},"score":"37.62665"}
{"text":"This builds on the intuitions of Klein and Manning 's ( 2002 ) \" constituent - context \" model , which demonstrated the value of modeling context , but has the advantage of being able to exploit the properties of CCG .","label":"Background","metadata":{},"score":"37.734665"}
{"text":"[ 30 ] J.A. Rodríguez - Serrano , F. Perronnin , J. Lladós , and G. Sánchez , \" A Similarity Measure between Vector Sequences with Application to Handwritten Word Image Retrieval , \" Proc .IEEE Conf .Computer Vision and Pattern Recognition , 2009 .","label":"Background","metadata":{},"score":"37.770332"}
{"text":"2005 ] .Using Clustering to Build Scalable Collaborative Filtering Systems .Jerome Kelleher and I applied clustering techniques to the ratings matrices used by collaborative recommenders .We then predicted the active user 's rating for a product that s / he has not yet rated from the clusters .","label":"Background","metadata":{},"score":"38.1013"}
{"text":"We have argued that , for on - line shopping , our framework , deploying this notion of indifference between degrees of similarity , avoids a level of spurious precision which plagues systems that are based on conventional numeric - valued similarity measures [ Ferguson & Bridge 2000a ] .","label":"Background","metadata":{},"score":"38.16187"}
{"text":"153 - 168 , 2000 .[26 ] J. Goldberger , S. Gordon , and H. Greenspan , \" An Efficient Image Similarity Measure Based on Approximations of KL - Divergence between Two Gaussian Mixtures , \" Proc .IEEE Int'l Conf .","label":"Background","metadata":{},"score":"39.155495"}
{"text":"This crucial constraint provides two major benefits .First , the a priori information contained in the common set of Gaussians leads to a more accurate estimate of the HMM parameters .Second , the computation of a similarity between two SC - HMMs can be simplified to a Dynamic Time Warping ( DTW ) between their mixture weight vectors , which significantly reduces the computational cost .","label":"Background","metadata":{},"score":"39.269367"}
{"text":"We describe a Recurrent Neural Network model for statistical script learning using Long Short - Term Memory , an architecture which has been demonstrated to work well on a range of Artificial Intelligence tasks .We evaluate our system on two tasks , inferring held - out events from text and inferring novel events from text , substantially outperforming prior approaches on both tasks .","label":"Background","metadata":{},"score":"39.328476"}
{"text":"In attempts to overcome this , fuzzy aggregation can be used to combine single , simple index queries into larger , more complex ones .This paper outlines the use of a fuzzy aggregation technique for hybrid querying which has the ability to adjust its behavior according operator - controlled parameters .","label":"Background","metadata":{},"score":"39.343933"}
{"text":"In attempts to overcome this , fuzzy aggregation can be used to combine single , simple index queries into larger , more complex ones .This paper outlines the use of a fuzzy aggregation technique for hybrid querying which has the ability to adjust its behavior according operator - controlled parameters .","label":"Background","metadata":{},"score":"39.343933"}
{"text":"In this document , we describe our methods for learning these rules , estimating their associated weights , and performing probabilistic and logical inference to infer unseen relations .In the KBP SF task , our system was able to infer several unextracted relations , but its performance was limited by the base level extractor .","label":"Background","metadata":{},"score":"39.627686"}
{"text":"In this document , we describe our methods for learning these rules , estimating their associated weights , and performing probabilistic and logical inference to infer unseen relations .In the KBP SF task , our system was able to infer several unextracted relations , but its performance was limited by the base level extractor .","label":"Background","metadata":{},"score":"39.627686"}
{"text":"We show that these bimodal models give a better fit to human word association data compared to amodal models and word representations based on handcrafted norming data .In this paper we are concerned with the latter task , namely constructing perceptually grounded distributional models .","label":"Background","metadata":{},"score":"39.634377"}
{"text":"To compensate for the scarcity of user - specific information , our approach exploits the relations between users , search terms , and URLs .We demonstrate the effectiveness of our approach in the presence of noise and show that it outperforms several natural baselines on a large data set collected from the MSN search engine .","label":"Background","metadata":{},"score":"39.754395"}
{"text":"In this document , we describe our methods for learning these rules , estimating their associated weights , and performing probabilistic and logical inference to infer unseen relations .Although our system was able to infer additional correct relations that were not extracted by our baseline relation extraction system , we were unable to significantly outperform a pure extraction baseline .","label":"Background","metadata":{},"score":"39.90609"}
{"text":"In this document , we describe our methods for learning these rules , estimating their associated weights , and performing probabilistic and logical inference to infer unseen relations .Although our system was able to infer additional correct relations that were not extracted by our baseline relation extraction system , we were unable to significantly outperform a pure extraction baseline .","label":"Background","metadata":{},"score":"39.90609"}
{"text":"S12 - 1056 [ bib ] : Kirk Roberts ; Sanda Harabagiu UTD - SpRL : A Joint Approach to Spatial Role Labeling .S12 - 1057 [ bib ] : Yingjie Zhang ; Bin Li ; Xinyu Dai ; Jiajun Chen MIXCD : System Description for Evaluating Chinese Word Similarity at SemEval-2012 .","label":"Background","metadata":{},"score":"39.934566"}
{"text":"We evaluate in two ways : first , we evaluate systems ' ability to infer held - out events from documents ( the \" Narrative Cloze \" evaluation ) ; second , we evaluate novel event inferences by collecting human judgments .","label":"Background","metadata":{},"score":"40.324726"}
{"text":"ML ID : 295 .Recent investigations into grounded models of language have shown that holistic views of language and perception can provide higher performance than independent views .In this work , we improve a two - dimensional multimodal version of Latent Dirichlet Allocation ( Andrews et al . , 2009 ) in various ways .","label":"Background","metadata":{},"score":"40.469803"}
{"text":"ML ID : 295 .Recent investigations into grounded models of language have shown that holistic views of language and perception can provide higher performance than independent views .In this work , we improve a two - dimensional multimodal version of Latent Dirichlet Allocation ( Andrews et al . , 2009 ) in various ways .","label":"Background","metadata":{},"score":"40.469803"}
{"text":"In this work , we propose approaches to adapt both these formalisms for abductive plan recognition .We present an extensive evaluation of our approaches on three benchmark datasets on plan recognition , comparing them with existing state - of - the - art methods .","label":"Background","metadata":{},"score":"40.516113"}
{"text":"In this work , we propose approaches to adapt both these formalisms for abductive plan recognition .We present an extensive evaluation of our approaches on three benchmark datasets on plan recognition , comparing them with existing state - of - the - art methods .","label":"Background","metadata":{},"score":"40.516113"}
{"text":"( 2013 ) to handle word - level code - switching between multiple languages .Further , we enable our system to handle spelling variability , including now - obsolete shorthand systems used by printers .Our results show average relative character error reductions of 14 % across a variety of historical texts .","label":"Background","metadata":{},"score":"40.737423"}
{"text":"However , it is an open question of how best to integrate it with uncertain , probabilistic knowledge , for example regarding word meaning .This paper describes the first steps of an approach to recasting first - order semantics into the probabilistic models that are part of Statistical Relational AI .","label":"Background","metadata":{},"score":"40.85016"}
{"text":"However , it is an open question of how best to integrate it with uncertain , probabilistic knowledge , for example regarding word meaning .This paper describes the first steps of an approach to recasting first - order semantics into the probabilistic models that are part of Statistical Relational AI .","label":"Background","metadata":{},"score":"40.85016"}
{"text":"The conventional wisdom in case - based classification is that the system can explain its conclusion by showing the user the case or cases that are closest to the new problem ( i.e. the nearest neighbours ) .Lisa Cummins and I later generalised this work and made it more knowledge lite , i.e. so that it requires less effort on the part of the knowledge engineer and domain expert [ Bridge & Cummins 2005 , Cummins and Bridge 2006 ] .","label":"Background","metadata":{},"score":"40.959923"}
{"text":"2012a , Blanoc et al .2012b ] .We investigated algorithms for maintenance of case bases .These algorithms propose the deletion of noisy or redundant cases , with a view to increasing retrieval efficiency while doing as little damage as possible or even increasing reasoning accuracy .","label":"Background","metadata":{},"score":"41.08529"}
{"text":"We demonstrate that our stacking approach outperforms the best system from the 2014 KBP - ESF competition as well as alternative ensembling methods employed in the 2014 KBP Slot Filler Validation task and several other ensembling baselines .Additionally , we demonstrate that including provenance information further increases the performance of stacking .","label":"Background","metadata":{},"score":"41.151794"}
{"text":"We showed that , not only is OBR expresssive , but it gives a natural way of obtaining a diverse set of retrieved items .We applied the ideas to case - based recommender systems [ Bridge 2001 , Bridge & Ferguson 2002a , Bridge & Ferguson 2002b ] .","label":"Background","metadata":{},"score":"41.271797"}
{"text":"These models make use of both latent and supervised shared topics to accomplish multitask learning .Experimental results on both document and image classification show that integrating MTL and active learning along with shared latent and supervised topics is superior to other methods which do not employ all of these components .","label":"Background","metadata":{},"score":"41.533314"}
{"text":"We combine logical and distributional representations of natural language meaning by transforming distributional similarity judgments into weighted inference rules using Markov Logic Networks ( MLNs ) .We show that this framework supports both judging sentence similarity and recognizing textual entailment by appropriately adapting the MLN implementation of logical connectives .","label":"Background","metadata":{},"score":"41.55961"}
{"text":"We combine logical and distributional representations of natural language meaning by transforming distributional similarity judgments into weighted inference rules using Markov Logic Networks ( MLNs ) .We show that this framework supports both judging sentence similarity and recognizing textual entailment by appropriately adapting the MLN implementation of logical connectives .","label":"Background","metadata":{},"score":"41.55961"}
{"text":"We combine logical and distributional representations of natural language meaning by transforming distributional similarity judgments into weighted inference rules using Markov Logic Networks ( MLNs ) .We show that this framework supports both judging sentence similarity and recognizing textual entailment by appropriately adapting the MLN implementation of logical connectives .","label":"Background","metadata":{},"score":"41.55961"}
{"text":"These experiments show that the proposed similarity outperforms the traditional DTW between the original sequences , and the model - based approach which uses ordinary continuous HMMs .We also show that this increase in accuracy can be traded against a significant reduction of the computational cost .","label":"Background","metadata":{},"score":"41.620926"}
{"text":"In the second approach , the implicit extraction features are focused on the shortest path between the two entities in the word - word dependency graph of the sentence .Finally , in a significant departure from previous learning approaches to relation extraction , we propose reducing the amount of required supervision to only a handful of pairs of entities known to exhibit or not exhibit the desired relationship .","label":"Background","metadata":{},"score":"41.682922"}
{"text":"We also address this challenging case and develop a general transfer learning approach that makes effective use of such limited target data in several social network domains .Finally , we develop an application of MLNs to the problem of Web query disambiguation in a more privacy - aware setting where the only information available about a user is that captured in a short search session of 5 - -6 previous queries on average .","label":"Background","metadata":{},"score":"41.86571"}
{"text":"We introduce a refinement algorithm that first learns a lexicon which is then used to remove parts of the graphs that are irrelevant .Experiments in a navigation domain shows that the algorithm successfully recovered over three quarters of the correct semantic content .","label":"Background","metadata":{},"score":"41.877438"}
{"text":"For future work , I propose to extend our PCFG induction model in several ways : improving the lexicon learning algorithm , discriminative re - ranking of top - k parses , and integrating the meaning representation language ( MRL ) grammar for extra structural information .","label":"Background","metadata":{},"score":"41.937386"}
{"text":"Previous work in computational linguistics on extracting lexical semantic information from unannotated corpora does not provide adequate representational flexibility and hence fails to capture the full extent of human conceptual knowledge .In this thesis I outline a family of probabilistic models capable of capturing important aspects of the rich organizational structure found in human language that can predict contextual variation , selectional preference and feature - saliency norms to a much higher degree of accuracy than previous approaches .","label":"Background","metadata":{},"score":"42.07113"}
{"text":"However , this prior work has only applied existing online algorithms , and there is no comprehensive study of online weight learning for MLNs .In this paper , we derive a new online algorithm for structured prediction using the primaldual framework , apply it to learn weights for MLNs , and compare against existing online algorithms on three large , real - world datasets .","label":"Background","metadata":{},"score":"42.29625"}
{"text":"\" We present a number of results improving the state of the art of learning statistical scripts for inferring implicit events .First , we demonstrate that incorporating multiple arguments into events , yielding a more complex event representation than is used in previous work , helps to improve a co - occurrence - based script system 's predictive power .","label":"Background","metadata":{},"score":"42.33231"}
{"text":"( 3 )We provide two novel ways to extend the bimodal models to support three or more modalities .We find that the three- , four- , and five - dimensional models significantly outperform models using only one or two modalities , and that nontextual modalities each provide separate , disjoint knowledge that can not be forced into a shared , latent structure .","label":"Background","metadata":{},"score":"42.441917"}
{"text":"( 3 )We provide two novel ways to extend the bimodal models to support three or more modalities .We find that the three- , four- , and five - dimensional models significantly outperform models using only one or two modalities , and that nontextual modalities each provide separate , disjoint knowledge that can not be forced into a shared , latent structure .","label":"Background","metadata":{},"score":"42.441917"}
{"text":"We contemplate using generic sources such as external dictionaries , or web statistics on discriminative textual patterns .We also intend to alleviate the modeling problems due to the intrinsic local nature of entity features by exploiting syntactic information .All these generic features will be input to a feature selection algorithm , so that in the end we obtain a model which is both compact and accurate .","label":"Background","metadata":{},"score":"42.46448"}
{"text":"For this we exploit recurrent neural networks , specifically LSTMs , which have demonstrated state - of - the - art performance in image caption generation .Our LSTM model is trained on video - sentence pairs and learns to associate a sequence of video frames to a sequence of words in order to generate a description of the event in the video clip .","label":"Background","metadata":{},"score":"42.605965"}
{"text":"In addition , the results obtained are at a minimum compara- ble to multiple - feature queries generated using a weighted mean approach but exhibiting scalability and greater fiexir bility in parameter adjustment .Full - text .Data provided are for informational purposes only .","label":"Background","metadata":{},"score":"43.027985"}
{"text":"In addition , the results obtained are at a minimum compara- ble to multiple - feature queries generated using a weighted mean approach but exhibiting scalability and greater fiexir bility in parameter adjustment .Full - text .Data provided are for informational purposes only .","label":"Background","metadata":{},"score":"43.027985"}
{"text":"In addition , these problems usually involve data that have thousands of examples .Thus , it is important to develop new discriminative learning methods for MLNs that are more accurate and more scalable , which are the topics addressed in this thesis .","label":"Background","metadata":{},"score":"43.229385"}
{"text":"Our system handles overall sentence structure and phenomena like negation in the logic , then uses our Robinson resolution variant to query distributional systems about words and short phrases .Therefor , we use our system to evaluate distributional lexical entailment approaches .","label":"Background","metadata":{},"score":"43.312405"}
{"text":"Our system handles overall sentence structure and phenomena like negation in the logic , then uses our Robinson resolution variant to query distributional systems about words and short phrases .Therefor , we use our system to evaluate distributional lexical entailment approaches .","label":"Background","metadata":{},"score":"43.312405"}
{"text":"This paper presents an approach for detecting promotional content in Wikipedia .By incorporating stylometric features , including features based on n - gram and PCFG language models , we demonstrate improved accuracy at identifying promotional articles , compared to using only lexical information and meta - features .","label":"Background","metadata":{},"score":"43.63192"}
{"text":"This paper presents an approach for detecting promotional content in Wikipedia .By incorporating stylometric features , including features based on n - gram and PCFG language models , we demonstrate improved accuracy at identifying promotional articles , compared to using only lexical information and meta - features .","label":"Background","metadata":{},"score":"43.63192"}
{"text":"30 , no .11 , pp .1945 - 1957 , Nov. 2008 .[ 23 ] A. Kolcz , J. Alspector , M. Augusteijn , R. Carlson , and G.V. Popescu , \" A Line - Oriented Approach to Word Spotting in Handwritten Documents , \" Pattern Analysis and Applications , vol .","label":"Background","metadata":{},"score":"43.824608"}
{"text":"We present an approach to Web query disambiguation that bases its predictions only on a short glimpse of user search activity , captured in a brief session of 4 - -6 previous searches on average .We present empirical results that demonstrate the effectiveness of our proposed approach on data collected from a commercial general - purpose search engine .","label":"Background","metadata":{},"score":"44.008698"}
{"text":"However , most of the learning problems in relational data are discriminative .So to utilize the power of MLNs , we need discriminative learning methods that well match these discriminative tasks .In this proposal , we present two new discriminative learning algorithms for MLNs .","label":"Background","metadata":{},"score":"44.051178"}
{"text":"Previous work has shown that learning sequence models for CCG tagging can be improved by using priors that are sensitive to the formal properties of CCG as well as cross - linguistic universals .We extend this approach to the task of learning a full CCG parser from weak supervision .","label":"Background","metadata":{},"score":"44.15226"}
{"text":"Furthermore , we propose a novel approach to weighting rules using a curated lexical ontology like WordNet .The learned rules along with their parameters are then used to infer implicit information using a Bayesian Logic Program .Experimental evaluation on a machine reading testbed demonstrates the efficacy of the proposed methods .","label":"Background","metadata":{},"score":"44.31282"}
{"text":"Furthermore , we propose a novel approach to weighting rules using a curated lexical ontology like WordNet .The learned rules along with their parameters are then used to infer implicit information using a Bayesian Logic Program .Experimental evaluation on a machine reading testbed demonstrates the efficacy of the proposed methods .","label":"Background","metadata":{},"score":"44.31282"}
{"text":"Furthermore , we propose a novel approach to weighting rules using a curated lexical ontology like WordNet .The learned rules along with their parameters are then used to infer implicit information using a Bayesian Logic Program .Experimental evaluation on a machine reading testbed demonstrates the efficacy of the proposed methods .","label":"Background","metadata":{},"score":"44.31282"}
{"text":"An important aspect of our approach is that it first diagnoses the provided source MLN and then focuses on re - learning only the incorrect portions .Experiments in a pair of synthetic domains demonstrate that this strategy significantly decreases the search space and speeds up learning while maintaining a level of accuracy comparable to that of the current best algorithm .","label":"Background","metadata":{},"score":"44.33211"}
{"text":"Next , I present an end - to - end deep network that can jointly model a sequence of video frames and a sequence of words .The second part of the proposal outlines a set of models to significantly extend work in this area .","label":"Background","metadata":{},"score":"44.403748"}
{"text":"S12 - 1100 [ bib ] : Miguel Rios ; Wilker Aziz ; Lucia Specia UOW : Semantically Informed Text Similarity .S12 - 1101 [ bib ] : Sneha Jha ; Hansen A. Schwartz ; Lyle Ungar Penn : Using Word Similarities to better Estimate Sentence Similarity .","label":"Background","metadata":{},"score":"44.583855"}
{"text":"In this paper , we describe a model that learns semantic representations from the distributional statistics of language .This model , however , goes beyond the common bag - of - words paradigm , and infers semantic representations by taking into account the inherent sequential nature of linguistic data .","label":"Background","metadata":{},"score":"44.696213"}
{"text":"Unlike previous methods , our approach can annotate arbitrary videos without requiring the expensive collection and annotation of a similar training video corpus .We evaluate our technique against a baseline that does not use text - mined knowledge and show that humans prefer our descriptions 61 % of the time .","label":"Background","metadata":{},"score":"44.72989"}
{"text":"We then describe first steps of an approach that uses this mapping to recast first - order semantics into the probabilistic models that are part of Statistical Relational AI .Specifically , we show how Discourse Representation Structures can be combined with distributional models for word meaning inside a Markov Logic Network and used to successfully perform inferences that take advantage of logical concepts such as negation and factivity as well as weighted information on word meaning in context .","label":"Background","metadata":{},"score":"44.836887"}
{"text":"We then describe first steps of an approach that uses this mapping to recast first - order semantics into the probabilistic models that are part of Statistical Relational AI .Specifically , we show how Discourse Representation Structures can be combined with distributional models for word meaning inside a Markov Logic Network and used to successfully perform inferences that take advantage of logical concepts such as negation and factivity as well as weighted information on word meaning in context .","label":"Background","metadata":{},"score":"44.836887"}
{"text":"We then describe first steps of an approach that uses this mapping to recast first - order semantics into the probabilistic models that are part of Statistical Relational AI .Specifically , we show how Discourse Representation Structures can be combined with distributional models for word meaning inside a Markov Logic Network and used to successfully perform inferences that take advantage of logical concepts such as negation and factivity as well as weighted information on word meaning in context .","label":"Background","metadata":{},"score":"44.836887"}
{"text":"Patrick du Boucher - Ryan and I applied Formal Concept Analysis to the ratings matrix used by a collaborative recommender .We showed how the concept lattice that this produces can be used as an index to rapidly find candidate neighbours for making predictions and recommendations .","label":"Background","metadata":{},"score":"44.885433"}
{"text":"S12 - 1050 [ bib ] : Wanxiang Che ; Meishan Zhang ; Yanqiu Shao ; Ting Liu SemEval-2012 Task 5 : Chinese Semantic Dependency Parsing .S12 - 1051 [ bib ] : Eneko Agirre ; Daniel Cer ; Mona Diab ; Aitor Gonzalez - Agirre SemEval-2012 Task 6 : A Pilot on Semantic Textual Similarity .","label":"Background","metadata":{},"score":"44.927464"}
{"text":"S12 - 1082 [ bib ] : NIkos Malandrakis ; Elias Iosif ; Alexandros Potamianos DeepPurple : Estimating Sentence Semantic Similarity using N - gram Regression Models and Web Snippets .S12 - 1083 [ bib ] : Snehasis Neogi ; Partha Pakray ; Sivaji Bandyopadhyay ; Alexander Gelbukh JU_CSE_NLP : Multi - grade Classification of Semantic Similarity between Text Pairs .","label":"Background","metadata":{},"score":"44.95077"}
{"text":"In this paper we present a comparative study of models that represent word meaning based on linguistic and perceptual data .Linguistic information is approximated by naturally occurring corpora and sensorimotor experience by feature norms ( i.e. , attributes native speakers consider important in describing the meaning of a word ) .","label":"Background","metadata":{},"score":"45.017265"}
{"text":"We approach this task as a phrase classification problem , in which candidate phrases from the same document are collectively classified .Global correlations between candidate entities are captured in a model built using the expressive framework of Relational Markov Networks .","label":"Background","metadata":{},"score":"45.052338"}
{"text":"Unlike previous work , we model the interactions between multiple entities in a script .Experiments on a large corpus using the task of inferring held - out events ( the \" narrative cloze evaluation \" ) demonstrate that modeling multi - argument events improves predictive accuracy .","label":"Background","metadata":{},"score":"45.119606"}
{"text":"Unlike previous work , we model the interactions between multiple entities in a script .Experiments on a large corpus using the task of inferring held - out events ( the \" narrative cloze evaluation \" ) demonstrate that modeling multi - argument events improves predictive accuracy .","label":"Background","metadata":{},"score":"45.119606"}
{"text":"Unlike previous methods , our approach can annotate arbitrary videos without requiring the expensive collection and annotation of a similar training video corpus .We evaluate our technique against a baseline that does not use text - mined knowledge and show that humans prefer our descriptions 61 percent of the time .","label":"Background","metadata":{},"score":"45.164062"}
{"text":"Unlike previous methods , our approach can annotate arbitrary videos without requiring the expensive collection and annotation of a similar training video corpus .We evaluate our technique against a baseline that does not use text - mined knowledge and show that humans prefer our descriptions 61 percent of the time .","label":"Background","metadata":{},"score":"45.164062"}
{"text":"Finally , we present a method of adapting discriminative reranking to grounded language learning in order to improve the performance of our proposed generative models .Although such generative models are easy to implement and are intuitive , it is not always the case that generative models perform best , since they are maximizing the joint probability of data and model , rather than directly maximizing conditional probability .","label":"Background","metadata":{},"score":"45.28573"}
{"text":"Finally , we present a method of adapting discriminative reranking to grounded language learning in order to improve the performance of our proposed generative models .Although such generative models are easy to implement and are intuitive , it is not always the case that generative models perform best , since they are maximizing the joint probability of data and model , rather than directly maximizing conditional probability .","label":"Background","metadata":{},"score":"45.28573"}
{"text":"We outperform text - only models in two different evaluations , and demonstrate that low - level visual features are directly compatible with the existing model .( 2 ) We present a novel way to integrate visual features into the LDA model using unsupervised clusters of images .","label":"Background","metadata":{},"score":"45.348392"}
{"text":"We outperform text - only models in two different evaluations , and demonstrate that low - level visual features are directly compatible with the existing model .( 2 ) We present a novel way to integrate visual features into the LDA model using unsupervised clusters of images .","label":"Background","metadata":{},"score":"45.348392"}
{"text":"The experimental results show that our proposed algorithm outperforms existing learning methods for MLNs and traditional ILP systems in term of predictive accuracy , and its performance is comparable to state - of - the - art results on some ILP benchmarks .","label":"Background","metadata":{},"score":"45.46276"}
{"text":"Work with Francesco Ricci and Henry Blanco Lores continued , with an investigation of the case where the system has only a finite set of possible user profiles and must infer whcih subset of these is consistent with the user 's actions .","label":"Background","metadata":{},"score":"45.473408"}
{"text":"Our approaches to this information extraction task differ in the type and the amount of supervision required .We first propose two relation extraction methods that are trained on documents in which sentences are manually annotated for the required relationships .In the first method , the extraction patterns correspond to sequences of words and word classes anchored at two entity names occurring in the same sentence .","label":"Background","metadata":{},"score":"45.47515"}
{"text":"CL ] , 2015 .NLP tasks differ in the semantic information they require , and at this time no single semantic representation fulfills all requirements .Logic - based representations characterize sentence structure , but do not capture the graded aspect of meaning .","label":"Background","metadata":{},"score":"45.61941"}
{"text":"For future work , our short - term goal is to develop a more efficient inference algorithm and test our max - margin weight learner on more complex problems where there are complicated relationships between the input and output variables and among the outputs .","label":"Background","metadata":{},"score":"45.715336"}
{"text":"The standard solution , which is also the one that we used in our initial work , is to resort to approximate inference .In this proposal we show that by considering only a selected subset of mutual influences between candidate extractions , exact inference can be done in linear time .","label":"Background","metadata":{},"score":"45.7243"}
{"text":"Unlike conventional reranking used in syntactic and semantic parsing , gold - standard reference trees are not naturally available in a grounded setting .Instead , we show how the weak supervision of response feedback ( e.g. successful task completion ) can be used as an alternative , experimentally demonstrating that its performance is comparable to training on gold - standard parse trees .","label":"Background","metadata":{},"score":"45.805153"}
{"text":"Unlike conventional reranking used in syntactic and semantic parsing , gold - standard reference trees are not naturally available in a grounded setting .Instead , we show how the weak supervision of response feedback ( e.g. successful task completion ) can be used as an alternative , experimentally demonstrating that its performance is comparable to training on gold - standard parse trees .","label":"Background","metadata":{},"score":"45.805153"}
{"text":"With better natural language semantic representations , computers can do more applications more efficiently as a result of better understanding of natural text .However , no single semantic representation at this time fulfills all requirements needed for a satisfactory representation .","label":"Background","metadata":{},"score":"45.872086"}
{"text":"Transfer Learning by Mapping with Minimal Target Data [ Details ] [ PDF ] Lilyana Mihalkova and Raymond J. Mooney In Proceedings of the AAAI-08 Workshop on Transfer Learning For Complex Tasks , Chicago , IL , July 2008 .This paper introduces the single - entity - centered setting for transfer across two relational domains .","label":"Background","metadata":{},"score":"46.006653"}
{"text":"Because inference plays an important role in this process , programming with an MLN would be significantly facilitated by speeding up inference .We present a new meta - inference algorithm that exploits the repeated structure frequently present in relational domains to speed up existing inference techniques .","label":"Background","metadata":{},"score":"46.140762"}
{"text":"Next , I present a PCFG induction model for grounded language learning that extends the model of Borschinger , Jones , and Johnson ( 2011 ) by utilizing a semantic lexicon .Our model overcomes such limitations by employing a semantic lexicon as the basic building block for PCFG rule generation .","label":"Background","metadata":{},"score":"46.14183"}
{"text":"Most of the existing learning algorithms for MLNs are in the generative setting : they try to learn a model that is equally capable of predicting the values of all variables given an arbitrary set of evidence ; and they do not scale to problems with thousands of examples .","label":"Background","metadata":{},"score":"46.26012"}
{"text":"Our method exploits the relations of the current search session in which the ambiguous query is issued to previous sessions in order to predict the user 's intentions and is based on Markov logic .We present empirical results that demonstrate the effectiveness of our proposed approach on data collected form a commercial general - purpose search engine .","label":"Background","metadata":{},"score":"46.26701"}
{"text":"Since designing an extraction system through introspection by a domain expert is a laborious and time consuming process , the focus of this thesis will be on methods that automatically induce an extraction model by training on a dataset of manually labeled examples .","label":"Background","metadata":{},"score":"46.498436"}
{"text":"A popular tradition of studying semantic representation has been driven by the assumption that word meaning can be learned from the linguistic environment , despite ample evidence suggesting that language is grounded in perception and action .In this paper we present a comparative study of models tha ... \" .","label":"Background","metadata":{},"score":"46.630493"}
{"text":"Existing discriminative weight learning methods for MLNs all try to learn weights that optimize the Conditional Log Likelihood ( CLL ) of the training examples .In this work , we present a new discriminative weight learning method for MLNs based on a max - margin framework .","label":"Background","metadata":{},"score":"46.642883"}
{"text":"Our second algorithm , BUSL improves structure learning from scratch by approaching the problem in a more bottom - up fashion and first constructing a variablized Markov network template that significantly constrains the space of viable clause candidates .We demonstrate the effectiveness of our methods in three social domains .","label":"Background","metadata":{},"score":"46.7078"}
{"text":"In this article , we review our recent work on using Relational Markov Networks ( RMNs ) for information extraction , the problem of identifying phrases in natural language text that refer to specific types of entities .We use the expressive power of RMNs to represent and reason about several specific relationships between candidate entities and thereby collectively identify the appropriate set of phrases to extract .","label":"Background","metadata":{},"score":"46.712593"}
{"text":"This allows the representation of each word by a distribution of numerical values over the feature set .Admittedly , norming studies have the potential of revealing ... . \" ...This position paper proposes that the study of embodied cognitive agents , such as humanoid robots , can advance our understanding of the cognitive development of complex sensorimotor , linguistic and social learning skills .","label":"Background","metadata":{},"score":"46.822144"}
{"text":"Within our new framework , we defined operators for combining similarity metrics .These operators make use of ways of combining partial orders .Strikingly , this means that in our framework different similarity metrics ( e.g. set - valued and numeric - valued ) can be combined , without inter - conversion [ Osborne & Bridge 1997a , Osborne & Bridge 1997b , Osborne & Bridge 1997c ] .","label":"Background","metadata":{},"score":"46.941772"}
{"text":"We showed that combining both types of retrieval gave the best results [ Grabert & Bridge 2003c ] .Order - Based Retrieval .With Alex Ferguson , I devised a query language that builds on the best aspects of similarity - based retrieval , while offering a number of new operators that give greater expressiveness .","label":"Background","metadata":{},"score":"47.073006"}
{"text":"All these approaches are evaluated on the two publicly available domains that have been actively used in many other grounded language learning studies .Our methods demonstrate consistently improved performance over those of previous studies in the domains with different languages ; this proves that our methods are language - independent and can be generally applied to other grounded learning problems as well .","label":"Background","metadata":{},"score":"47.08544"}
{"text":"All these approaches are evaluated on the two publicly available domains that have been actively used in many other grounded language learning studies .Our methods demonstrate consistently improved performance over those of previous studies in the domains with different languages ; this proves that our methods are language - independent and can be generally applied to other grounded learning problems as well .","label":"Background","metadata":{},"score":"47.08544"}
{"text":"The most important outcome from this project was a generalised framework for measuring similarity in CBR systems .In our new framework , similarity is measured by functions whose result types are partial orders .This both subsumes and extends many existing numeric - valued and non - numeric - valued ways of measuring similarity .","label":"Background","metadata":{},"score":"47.165844"}
{"text":"Semantic Parsing using Distributional Semantics and Probabilistic Logic [ Details ] [ PDF ][Poster ] Islam Beltagy and Katrin Erk and Raymond Mooney In Proceedings of ACL 2014 Workshop on Semantic Parsing ( SP-2014 ) , 7 - -11 , Baltimore , MD , June 2014 .","label":"Background","metadata":{},"score":"47.17954"}
{"text":"However , NLP also requires integrating uncertain evidence from a variety of sources in order to resolve numerous syntactic and semantic ambiguities .Effectively integrating multiple sources of uncertain evidence has generally been considered a strength of Bayesian probabilistic methods and graphical models .","label":"Background","metadata":{},"score":"47.203983"}
{"text":"ML ID : 273 . \"Grounded \" language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts .Borschinger et al .( 2011 ) introduced an approach to grounded language learning based on unsupervised PCFG induction .","label":"Background","metadata":{},"score":"47.227146"}
{"text":"Distributional models use contextual similarity to predict the ' ' graded ' ' semantic similarity of words and phrases but they do not adequately capture logical structure .In addition , there are a few recent attempts to combine both representations either on the logic side ( still , not a graded representation ) , or in the distribution side(not full logic ) .","label":"Background","metadata":{},"score":"47.43708"}
{"text":"A challenging problem for empirical NLP is the automated acquisition of NLI 's from training examples .We present a method for integrating statistical and relational learning techniques for this task which exploits the strength of both approaches .Experimental results from three different domains suggest that such an approach is more robust than a previous purely logic - based approach .","label":"Background","metadata":{},"score":"47.51032"}
{"text":"The literature contains a disconnect between accounts of how humans learn lexical semantic representations for words .Theories generally propose that lexical semantics are learned either through perceptual experience or through exposure to regularities in language .We propose here a model to integrate these two information sources .","label":"Background","metadata":{},"score":"47.520615"}
{"text":"S12 - 1047 [ bib ] : David Jurgens ; Saif Mohammad ; Peter Turney ; Keith Holyoak SemEval-2012 Task 2 : Measuring Degrees of Relational Similarity .S12 - 1048 [ bib ] : parisa kordjamshidi ; steven bethard ; Marie - Francine Moens SemEval-2012 Task 3 : Spatial Role Labeling .","label":"Background","metadata":{},"score":"47.61831"}
{"text":"Existing semantic representation models are primarily amodal based on information provided by the linguistic input despite ample evidence indicating that the cognitive system is also sensitive to perceptual information .In this work we exploit the vast resource of images and associated documents available on the web and develop a model of multimodal meaning representation which is based on the linguistic and visual context .","label":"Background","metadata":{},"score":"47.645473"}
{"text":"This is quite different from representing them in standard first - order logic . 2 ) knowledge base construction in the form of weighted inference rules from different sources like WordNet , paraphrase collections , and lexical and phrasal distributional rules generated on the fly .","label":"Background","metadata":{},"score":"47.86254"}
{"text":"This is quite different from representing them in standard first - order logic . 2 ) knowledge base construction in the form of weighted inference rules from different sources like WordNet , paraphrase collections , and lexical and phrasal distributional rules generated on the fly .","label":"Background","metadata":{},"score":"47.86254"}
{"text":"Speeding up Inference In Statistical Relational Learning by Clustering Similar Query Literals [ Details ] [ PDF ] Lilyana Mihalkova and Matthew Richardson In Proceedings of the 19th International Conference on Inductive Logic Programming ( ILP-09 ) , Leuven , Belgium , July 2009 .","label":"Background","metadata":{},"score":"47.863888"}
{"text":"To overcome this problem , previous work has used online learning algorithms to learn weights for MLNs .However , this prior work has only applied existing online algorithms , and there is no comprehensive study of online weight learning for MLNs .","label":"Background","metadata":{},"score":"47.871513"}
{"text":"We assess our system output in three ways : lexical comparison with norms derived from human - generated property norm data , direct evaluation by four human judges , and a semantic distance comparison with both WordNet similarity data and human - judged concept similarity ratings .","label":"Background","metadata":{},"score":"47.888535"}
{"text":"2108 - 2120 , Nov. 2012 , doi:10.1109/TPAMI.2012.25 .[ 2 ] Q. Huo and W. Li , \" A DTW - Based Dissimilarity Measure for Left - to - Right Hidden Markov Models and Its Application to Word Confusability Analysis , \" Proc .","label":"Background","metadata":{},"score":"47.943737"}
{"text":"Our results show that annotation of word types is the most important , provided a sufficiently capable semi - supervised learning infrastructure is in place to project type information onto a raw corpus .We also show that finite - state morphological analyzers are effective sources of type information when few labeled examples are available .","label":"Background","metadata":{},"score":"48.07321"}
{"text":"Our results show that annotation of word types is the most important , provided a sufficiently capable semi - supervised learning infrastructure is in place to project type information onto a raw corpus .We also show that finite - state morphological analyzers are effective sources of type information when few labeled examples are available .","label":"Background","metadata":{},"score":"48.07321"}
{"text":"The set of issues that we intend to investigate in future work is two fold .One direction refers to applying the already developed framework to other natural language tasks that may benefit from the same types of influences , such as word sense disambiguation and part - of - speech tagging .","label":"Background","metadata":{},"score":"48.289055"}
{"text":"We then use these rules to infer additional facts using BLPs , thereby improving the recall of the underlying IE system .Here again , the standard inference used in BLPs can not be used to construct the networks .So , we extend BLPs to perform forward inference on all facts extracted by the IE system and then construct the ground Bayesian networks .","label":"Background","metadata":{},"score":"48.323563"}
{"text":"Our most ambitious long - term goal is to develop a system that transfers knowledge from multiple potential sources .An important prerequisite to such a system is a method for measuring the similarity between domains .We would also like to extend BUSL to learn other SRL models and to handle functions .","label":"Background","metadata":{},"score":"48.35282"}
{"text":"For content matching , color feature is extracted and is represented using Fuzzy Color Histogram ( FCH ) .The two modalities are fused together using reordering technique to improve the retrieval results .The proposed approach shows that the semantics learned at an early stage not only reduces the semantic gap but also decreases the computation time largely .","label":"Background","metadata":{},"score":"48.511124"}
{"text":"For content matching , color feature is extracted and is represented using Fuzzy Color Histogram ( FCH ) .The two modalities are fused together using reordering technique to improve the retrieval results .The proposed approach shows that the semantics learned at an early stage not only reduces the semantic gap but also decreases the computation time largely .","label":"Background","metadata":{},"score":"48.511124"}
{"text":"However , most existing work relies on the existence of search engine log data in which each user 's search activities are recorded over long periods of time .Such approaches may raise privacy concerns and may be difficult to implement for pragmatic reasons .","label":"Background","metadata":{},"score":"48.51699"}
{"text":"Taking the MIN - GREEDY algorithm ( Ravi et al . , 2010 ) as a starting point , we improve it with several intuitive heuristics .We also define a simple HMM emission initialization that takes advantage of the tag dictionary and raw data to capture both the openness of a given tag and its estimated prevalence in the raw data .","label":"Background","metadata":{},"score":"48.56227"}
{"text":"Spoken Language Processing , 2006 .[ 6 ] C. Bahlmann and H. Burkhardt , \" Measuring HMM Similarity with the Bayes Probability of Error and Its Application to Online Handwriting Recognition , \" Proc .Sixth Int'l Conf .Document Analysis and Recognition , 2001 .","label":"Background","metadata":{},"score":"48.63875"}
{"text":"15 , pp .69 - 90 , 2001 .[ 8 ] A. Vinciarelli , S. Bengio , and H. Bunke , \" Offline Recognition of Unconstrained Handwritten Texts Using HMMs and Statistical Language Models , \" IEEE Trans .Pattern Analysis and Machine Intelligence , vol .","label":"Background","metadata":{},"score":"48.72335"}
{"text":"Likewise , the users of a search engine are related by searches for similar items and clicks to shared sites .The ability to model and reason about such relations is essential not only because better predictive accuracy is achieved by exploiting this additional information , but also because frequently the goal is to predict whether a set of entities are related in a particular way .","label":"Background","metadata":{},"score":"48.766476"}
{"text":"However , there is little connection in these models to existing theories of modal perce ... . \" ...We present an introduction to Bayesian inference as it is used in probabilistic models of cognitive development .Our goal is to provide an intuitive and accessible guide to the what , the how , and the why of the Bayesian approach : what sorts of problems and data the framework is most relevant for , an ... \" .","label":"Background","metadata":{},"score":"48.910946"}
{"text":"The attributes represent pe ... . by Brendan T. Johns , Michael N. Jones - Topics in Cognitive Science , 2012 . \" ...The literature contains a disconnect between accounts of how humans learn lexical semantic representations for words .Theories generally propose that lexical semantics are learned either through perceptual experience or through exposure to regularities in language .","label":"Background","metadata":{},"score":"48.9308"}
{"text":"More sources can easily be added by mapping them to logical rules ; our system learns a resource - specific weight that counteract scaling differences between resources .3 ) inference , where we show how to solve the inference problems efficiently .","label":"Background","metadata":{},"score":"49.036987"}
{"text":"More sources can easily be added by mapping them to logical rules ; our system learns a resource - specific weight that counteract scaling differences between resources .3 ) inference , where we show how to solve the inference problems efficiently .","label":"Background","metadata":{},"score":"49.036987"}
{"text":"For the purposes of this extended summary , the scope of the aggregator is limited to queries involving color content , color coverage , and horizontal /vertical trends , and applied to a media database comprised of COREL images of fixed size .","label":"Background","metadata":{},"score":"49.14376"}
{"text":"For the purposes of this extended summary , the scope of the aggregator is limited to queries involving color content , color coverage , and horizontal /vertical trends , and applied to a media database comprised of COREL images of fixed size .","label":"Background","metadata":{},"score":"49.14376"}
{"text":"Our goal is to provide an intuitive and accessible guide to the what , the how , and the why of the Bayesian approach : what sorts of problems and data the framework is most relevant for , and how and why it may be useful for developmentalists .","label":"Background","metadata":{},"score":"49.199562"}
{"text":"Also as Technical Report AI07 - 345 , Artificial Intelligence Lab , University of Texas at Austin , August 2007 .Information Extraction , the task of locating textual mentions of specific types of entities and their relationships , aims at representing the information contained in text documents in a structured format that is more amenable to applications in data mining , question answering , or the semantic web .","label":"Background","metadata":{},"score":"49.23979"}
{"text":"Our factor graph model combines these detection confidences with probabilistic knowledge mined from text corpora to estimate the most likely subject , verb , object , and place .Results on YouTube videos show that our approach improves both the joint detection of these latent , diverse sentence components and the detection of some individual components when compared to using the vision system alone , as well as over a previous n - gram language - modeling approach .","label":"Background","metadata":{},"score":"49.34281"}
{"text":"Our factor graph model combines these detection confidences with probabilistic knowledge mined from text corpora to estimate the most likely subject , verb , object , and place .Results on YouTube videos show that our approach improves both the joint detection of these latent , diverse sentence components and the detection of some individual components when compared to using the vision system alone , as well as over a previous n - gram language - modeling approach .","label":"Background","metadata":{},"score":"49.34281"}
{"text":"However , it is not always possible to restrict the set of possible alignments to such limited numbers .Thus , we present another system that allows each sentence to be aligned to one of exponentially many connected subgraphs without explicitly enumerating them .","label":"Background","metadata":{},"score":"49.384094"}
{"text":"The main contribution of this proposal are two algorithms for learning the structure of MLNs that proceed in a more data - driven fashion , in contrast to most existing SRL algorithms .The first algorithm we present , R - TAMAR , improves learning by transferring the structure of an MLN learned in a domain related to the current one .","label":"Background","metadata":{},"score":"49.388336"}
{"text":"The Ph.D. gives a partial solution to the presupposition projection problem .The solution distinguishes two types of presuppositions failure : where a presupposition is not satisfied by the discourse model , and where a presupposition is false .An incremental natural language processing system was shown to be especially well - suited to computing presuppositions of compound sentences .","label":"Background","metadata":{},"score":"49.44107"}
{"text":"We show that just a small amount of annotation input - even that which can be collected in just a few hours - can provide enormous advantages if we have learning algorithms that can appropriately exploit it .This work presents new algorithms , models , and approaches designed to learn grammatical information from weak supervision .","label":"Background","metadata":{},"score":"49.480873"}
{"text":"Here , we first develop an approach using BLPs to infer implicitly stated facts from natural language text .It involves learning uncertain common sense knowledge in the form of probabilistic first - order rules by mining a large corpus of automatically extracted facts using an existing rule learner .","label":"Background","metadata":{},"score":"49.488224"}
{"text":"One challenge posed by such data is that individual instances are frequently very large and include complex relationships among the entities .Moreover , because separate instances do not follow the same structure and contain varying numbers of entities , they can not be effectively represented as a feature - vector .","label":"Background","metadata":{},"score":"49.495884"}
{"text":"In this paper , we show how to formulate Textual Entailment ( RTE ) inference problems in probabilistic logic in a way that takes the domain closure and closed - world assumptions into account .We evaluate our proposed technique on three RTE datasets , on a synthetic dataset with a focus on complex forms of quantification , on FraCas and on one more natural dataset .","label":"Background","metadata":{},"score":"49.583763"}
{"text":"In this paper , we show how to formulate Textual Entailment ( RTE ) inference problems in probabilistic logic in a way that takes the domain closure and closed - world assumptions into account .We evaluate our proposed technique on three RTE datasets , on a synthetic dataset with a focus on complex forms of quantification , on FraCas and on one more natural dataset .","label":"Background","metadata":{},"score":"49.583763"}
{"text":"In this dissertation , we demonstrate the efficacy of BLPs for inference and learning from incomplete data .Experimental comparison on various benchmark data sets on both tasks demonstrate the superior performance of BLPs over state - of - the - art methods .","label":"Background","metadata":{},"score":"49.646637"}
{"text":"In addition , we discuss some important interpretation issues that often arise when evaluating Bayesian models in cognitive science . \" ...In this paper , we describe a model that learns semantic representations from the distributional statistics of language .This model , however , goes beyond the common bag - of - words paradigm , and infers semantic representations by taking into account the inherent sequential nature of linguistic data .","label":"Background","metadata":{},"score":"49.767437"}
{"text":"We first present a system that learned to sportscast for RoboCup simulation games by observing how humans commentate a game .Using the simple assumption that people generally talk about events that have just occurred , we pair each textual comment with a set of events that it could be referring to .","label":"Background","metadata":{},"score":"50.100224"}
{"text":"To move beyond short video clips , I also outline models to process multi - activity movie videos , learning to jointly segment and describe coherent event sequences .I propose further extensions to take advantage of movie scripts and subtitle information to generate richer descriptions .","label":"Background","metadata":{},"score":"50.156487"}
{"text":"The current state - of - the - art algorithm for learning MLN structure follows a top - down paradigm where many potential candidate structures are systematically generated without considering the data and then evaluated using a statistical measure of their fit to the data .","label":"Background","metadata":{},"score":"50.15948"}
{"text":"6 , pp .709 - 720 , June 2004 .[ 12 ] E. Saykol , A. Sinop , U. Gudukbay , O. Ulusoy , and A. Cetin , \" Content - Based Retrieval of Historical Ottoman Documents Stored as Textual Images , \" IEEE Trans .","label":"Background","metadata":{},"score":"50.169277"}
{"text":"I build on recent \" deep \" machine learning approaches to develop video description models using a unified deep neural network with both convolutional and recurrent structure .This technique treats the video domain as another \" language \" and takes a machine translation approach using the deep network to translate videos to text .","label":"Background","metadata":{},"score":"50.170403"}
{"text":"[Poster ] Islam Beltagy and Katrin Erk and Raymond Mooney In Proceedings of ACL 2014 Workshop on Semantic Parsing ( SP-2014 ) , 7 - -11 , Baltimore , MD , June 2014 .We propose a new approach to semantic parsing that is not constrained by a fixed formal ontology and purely logical inference .","label":"Background","metadata":{},"score":"50.256054"}
{"text":"[Poster ] Islam Beltagy and Katrin Erk and Raymond Mooney In Proceedings of ACL 2014 Workshop on Semantic Parsing ( SP-2014 ) , 7 - -11 , Baltimore , MD , June 2014 .We propose a new approach to semantic parsing that is not constrained by a fixed formal ontology and purely logical inference .","label":"Background","metadata":{},"score":"50.256054"}
{"text":"S12 - 1079 [ bib ] : Demetrios Glinos ATA - Sem : Chunk - based Determination of Semantic Text Similarity .S12 - 1080 [ bib ] : Davide Buscaldi ; Ronan Tournier ; Nathalie Aussenac - Gilles ; Josiane Mothe IRIT : Textual Similarity Combining Conceptual Similarity with an N - Gram Comparison Method .","label":"Background","metadata":{},"score":"50.27707"}
{"text":"Our approach outperforms a baseline model trained with uniform priors by exploiting universal , intrinsic properties of the CCG formalism to bias the model toward simpler , more cross - linguistically common categories .ML ID : 310 .Natural Language Semantics using Probabilistic Logic [ Details ] [ PDF ] [ Slides ] Islam Beltagy October 2014 .","label":"Background","metadata":{},"score":"50.30109"}
{"text":"The motivation for a combined system is to generate richer linguistic descriptions of images .Standalone vision systems are typically unable to generate linguistically rich descriptions .This approach combines abundant available language data to clean up noisy results from standalone vision systems .","label":"Background","metadata":{},"score":"50.46241"}
{"text":"The motivation for a combined system is to generate richer linguistic descriptions of images .Standalone vision systems are typically unable to generate linguistically rich descriptions .This approach combines abundant available language data to clean up noisy results from standalone vision systems .","label":"Background","metadata":{},"score":"50.46241"}
{"text":"In the longer term , we would like to develop a rule / structure learner that is capable of learning an even better set of first - order rules for BLPs .ML ID : 258 .Improving the Accuracy and Scalability of Discriminative Learning Methods for Markov Logic Networks [ Details ] [ PDF ] [ Slides ] Tuyen N. Huynh PhD Thesis , Department of Computer Science , University of Texas at Austin , May 2011 .","label":"Background","metadata":{},"score":"50.501194"}
{"text":"We present a holistic data - driven technique that generates natural - language descriptions for videos .We combine the output of state - of - the - art object and activity detectors with \" real - world \" knowledge to select the most probable subject - verb - object triplet for describing a video .","label":"Background","metadata":{},"score":"50.517094"}
{"text":"We present a holistic data - driven technique that generates natural - language descriptions for videos .We combine the output of state - of - the - art object and activity detectors with \" real - world \" knowledge to select the most probable subject - verb - object triplet for describing a video .","label":"Background","metadata":{},"score":"50.517094"}
{"text":"Inference and learning using this graphical model allows for collective information extraction in a way that exploits the mutual influence between possible extractions .Preliminary experiments on learning to extract named entities from biomedical and newspaper text demonstrate the advantages of our approach .","label":"Background","metadata":{},"score":"50.5354"}
{"text":"Toward this goal , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .With such ambiguous supervision , it is required to resolve the ambiguity between a natural language ( NL ) sentence and a corresponding set of possible logical meaning representations ( MR ) .","label":"Background","metadata":{},"score":"50.55123"}
{"text":"Conor Nugent and I developed Case - Based Reasoning methods for predicting the product yield of the trees in a managed forest [ Nugent et al 2009 ] .In the project , we developed a compact graphical data structure into which case bases or product catalogs can be compiled .","label":"Background","metadata":{},"score":"50.624866"}
{"text":"ML ID : 279 .Improving Video Activity Recognition using Object Recognition and Text Mining [ Details ] [ PDF ] [ Slides ] Tanvi S. Motwani and Raymond J. Mooney In Proceedings of the 20th European Conference on Artificial Intelligence ( ECAI-2012 ) , 600 - -605 , August 2012 .","label":"Background","metadata":{},"score":"50.685806"}
{"text":"We present a novel algorithm for learning MLN structure that follows a more bottom - up approach to address this problem .Our algorithm uses a ' ' propositional ' ' Markov network learning method to construct ' ' template ' ' networks that guide the construction of candidate clauses .","label":"Background","metadata":{},"score":"50.736412"}
{"text":"Abstract In recent years a number of methods have been proposed for the automatic acquisition of feature - based conceptual representations from text corpora .Such methods could offer valuable support for theoretical research on conceptual representation .However , existing methods do not target the fu ... \" .","label":"Background","metadata":{},"score":"50.92997"}
{"text":"However , in many cases , considering influences between different potential extractions could improve overall accuracy .Statistical methods based on undirected graphical models , such as conditional random fields ( CRFs ) , have been shown to be an effective approach to learning accurate IE systems .","label":"Background","metadata":{},"score":"51.22235"}
{"text":"However , in many cases , considering influences between different potential extractions could improve overall accuracy .Statistical methods based on undirected graphical models , such as conditional random fields ( CRFs ) , have been shown to be an effective approach to learning accurate IE systems .","label":"Background","metadata":{},"score":"51.22235"}
{"text":"The advantage of these formalisms is that they can handle both uncertainty and structured / relational data .As a result , they are widely used in domains like social network analysis , biological data analysis , and natural language processing .","label":"Background","metadata":{},"score":"51.339348"}
{"text":"For content matching , color feature is extracted and is represented using fuzzy color histogram ( FCH ) .For text matching , fuzzy string matching with edit distance is used .Furthermore , we find the correlation between the query image and the textual query provided by the user to reduce the semantic gap .","label":"Background","metadata":{},"score":"51.41937"}
{"text":"For content matching , color feature is extracted and is represented using fuzzy color histogram ( FCH ) .For text matching , fuzzy string matching with edit distance is used .Furthermore , we find the correlation between the query image and the textual query provided by the user to reduce the semantic gap .","label":"Background","metadata":{},"score":"51.41937"}
{"text":"Identifying Phrasal Verbs Using Many Bilingual Corpora [ Details ] [ PDF ][Poster ] Karl Pichotta and John DeNero In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing ( EMNLP 2013 ) , 636 - -646 , Seattle , WA , October 2013 .","label":"Background","metadata":{},"score":"51.42279"}
{"text":"Identifying Phrasal Verbs Using Many Bilingual Corpora [ Details ] [ PDF ][Poster ] Karl Pichotta and John DeNero In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing ( EMNLP 2013 ) , 636 - -646 , Seattle , WA , October 2013 .","label":"Background","metadata":{},"score":"51.42279"}
{"text":"ML ID : 253 .Online Max - Margin Weight Learning with Markov Logic Networks [ Details ] [ PDF ] [ Slides ] Tuyen N. Huynh and Raymond J. Mooney In Proceedings of the AAAI-10 Workshop on Statistical Relational AI ( Star - AI 10 ) , 32 - -37 , Atlanta , GA , July 2010 .","label":"Background","metadata":{},"score":"51.42821"}
{"text":"This paper considers transfer learning with Markov logic networks ( MLNs ) , a powerful formalism for learning in relational domains .We present a complete MLN transfer system that first autonomously maps the predicates in the source MLN to the target domain and then revises the mapped structure to further improve its accuracy .","label":"Background","metadata":{},"score":"51.472275"}
{"text":"We present probabilistic generative models for learning such correspondences along with a reranking model to improve the performance further .We perform evaluations on the RoboCup sportscasting corpus , proving that our model is more effective than those proposed by previous researchers .","label":"Background","metadata":{},"score":"51.621597"}
{"text":"We present probabilistic generative models for learning such correspondences along with a reranking model to improve the performance further .We perform evaluations on the RoboCup sportscasting corpus , proving that our model is more effective than those proposed by previous researchers .","label":"Background","metadata":{},"score":"51.621597"}
{"text":"Discriminative Structure and Parameter Learning for Markov Logic Networks [ Details ] [ PDF ] [ Slides ] Tuyen N. Huynh and Raymond J. Mooney In Proceedings of the 25th International Conference on Machine Learning ( ICML ) , Helsinki , Finland , July 2008 .","label":"Background","metadata":{},"score":"51.68454"}
{"text":"The project employed Markus Grabert .We built a Case - Based Reasoning system for improving software reuse .In particular , the case base contains what we called Java ' examplets ' , i.e. snippets that demonstrate Java usage of the kind you might find in a how - to FAQ list .","label":"Background","metadata":{},"score":"51.712303"}
{"text":"Finally , we develop a novel approach to calculate the weights of the rules using a curated lexical ontology like WordNet .Both tasks described above involve inference and learning from partially observed or incomplete data .In plan recognition , the underlying cause or the top - level plan that resulted in the observed actions is not known or observed .","label":"Background","metadata":{},"score":"51.802727"}
{"text":"S12 - 1088 [ bib ] : Danilo Croce ; Paolo Annesi ; Valerio Storch ; Roberto Basili UNITOR : Combining Semantic Text Similarity functions through SV Regression .S12 - 1089 [ bib ] : Georgiana Dinu ; Stefan Thater Saarland : Vector - based models of semantic textual similarity .","label":"Background","metadata":{},"score":"51.823143"}
{"text":"The experimental results show that the new algorithms achieve better accuracy than existing methods .ML ID : 245 .Bayesian Abductive Logic Programs [ Details ] [ PDF ] [ Slides ] Sindhu Raghavan and Raymond Mooney In Proceedings of the AAAI-10 Workshop on Statistical Relational AI ( Star - AI 10 ) , 82 - -87 , Atlanta , GA , July 2010 .","label":"Background","metadata":{},"score":"52.03848"}
{"text":"It is important for plan or intent recognition systems .Traditional approaches to abductive reasoning have either used first - order logic , which is unable to reason under uncertainty , or Bayesian networks , which can handle uncertainty using probabilities but can not directly handle an unbounded number of related entities .","label":"Background","metadata":{},"score":"52.06692"}
{"text":"Our approach first constructs a novel data structure called a Markov network template that is used to restrict the search space for clauses .Our experiments in three relational domains demonstrate that BUSL dramatically reduces the search space for clauses and attains a significantly higher accuracy than a structure learner that follows a top - down approach .","label":"Background","metadata":{},"score":"52.375706"}
{"text":"Existing methods for learning the logical structure of an MLN are not discriminative ; however , many relational learning problems involve specific target predicates that must be inferred from given background information .We found that existing MLN methods perform very poorly on several such ILP benchmark problems , and we present improved discriminative methods for learning MLN clauses and weights that outperform existing MLN and traditional ILP methods .","label":"Background","metadata":{},"score":"52.38775"}
{"text":"We then develop an online rule learner that handles the concise , incomplete nature of natural - language text and learns first - order rules from noisy IE extractions .Finally , we develop a novel approach to calculate the weights of the rules using a curated lexical ontology like WordNet .","label":"Background","metadata":{},"score":"52.419884"}
{"text":"Hidden Markov models , Vectors , Computational modeling , Visualization , Training , Feature extraction , Handwriting recognition , hidden Markov model , Handwriting recognition , word spotting , image retrieval .CITATION .José A. Rodríguez - Serrano , F. Perronnin , \" A Model - Based Sequence Similarity with Application to Handwritten Word Spotting \" , IEEE Transactions on Pattern Analysis & Machine Intelligence , vol.34 , no .","label":"Background","metadata":{},"score":"52.461945"}
{"text":"We work in the framework of model - based approaches , where each sequence is first mapped to a Hidden Markov Model ( HMM ) and then a measure of similarity is computed between the HMMs .We propose to model sequences with semicontinuous HMMs ( SC - HMMs ) .","label":"Background","metadata":{},"score":"52.513218"}
{"text":"Unlike previous work , our approach works on out - of - domain actions : it does not require training videos of the exact activity .If it can not find an accurate prediction for a pre - trained model , it finds a less specific answer that is also plausible from a pragmatic standpoint .","label":"Background","metadata":{},"score":"52.548553"}
{"text":"Unlike previous work , our approach works on out - of - domain actions : it does not require training videos of the exact activity .If it can not find an accurate prediction for a pre - trained model , it finds a less specific answer that is also plausible from a pragmatic standpoint .","label":"Background","metadata":{},"score":"52.548553"}
{"text":"Logic - based representations like first - order logic capture many of the linguistic phenomena using logical constructs , and they come with standardized inference mechanisms , but standard first - order logic fails to capture the ' ' graded ' ' aspect of meaning in languages .","label":"Background","metadata":{},"score":"52.567383"}
{"text":"Logic - based representations like first - order logic capture many of the linguistic phenomena using logical constructs , and they come with standardized inference mechanisms , but standard first - order logic fails to capture the ' ' graded ' ' aspect of meaning in languages .","label":"Background","metadata":{},"score":"52.567383"}
{"text":"Experimental results on two real- world datasets for natural - language field segmentation show that OSL outperforms systems that can not revise structure .ML ID : 267 .Abductive Plan Recognition by Extending Bayesian Logic Programs [ Details ] [ PDF ] [ Slides ] Sindhu Raghavan , Raymond J. Mooney In Proceedings of the European Conference on Machine Learning / Principles and Practice of Knowledge Discovery in Databases ( ECML - PKDD 2011 ) , 629 - 644 , September 2011 .","label":"Background","metadata":{},"score":"52.5968"}
{"text":"The ideas we present are unified by two main themes : the need to deal with limited training data and the use of bottom - up learning techniques .Structure learning , the task of automatically acquiring a set of dependencies among the relations in the domain , is a central problem in SRL .","label":"Background","metadata":{},"score":"52.61543"}
{"text":"We consider the problem of grounding the meaning of words in the physical world and focus on the visual modality which we represent by visual attributes .We create a new large - scale taxonomy of visual attributes covering more than 500 concepts and their corresponding 688 K images .","label":"Background","metadata":{},"score":"52.765633"}
{"text":"We consider the problem of grounding the meaning of words in the physical world and focus on the visual modality which we represent by visual attributes .We create a new large - scale taxonomy of visual attributes covering more than 500 concepts and their corresponding 688 K images .","label":"Background","metadata":{},"score":"52.765633"}
{"text":"To train the proposed model , we design a new approximation algorithm for loss - augmented inference in MLNs based on Linear Programming ( LP ) .The experimental result shows that the proposed approach generally achieves higher F1 scores than the current best discriminative weight learner for MLNs .","label":"Background","metadata":{},"score":"52.81601"}
{"text":"Integrating Visual and Linguistic Information to Describe Properties of Objects [ Details ] [ PDF ] Calvin MacKenzie 2014 .Undergraduate Honors Thesis , Computer Science Department , University of Texas at Austin .Generating sentences from images has historically been performed with standalone Computer Vision systems .","label":"Background","metadata":{},"score":"52.890697"}
{"text":"Integrating Visual and Linguistic Information to Describe Properties of Objects [ Details ] [ PDF ] Calvin MacKenzie 2014 .Undergraduate Honors Thesis , Computer Science Department , University of Texas at Austin .Generating sentences from images has historically been performed with standalone Computer Vision systems .","label":"Background","metadata":{},"score":"52.890697"}
{"text":"NLP tasks differ in the semantic information they require , and at this time no single semantic representation fulfills all requirements .Logic - based representations characterize sentence structure , but do not capture the graded aspect of meaning .Distributional models give graded similarity ratings for words and phrases , but do not adequately capture overall sentence structure .","label":"Background","metadata":{},"score":"52.966587"}
{"text":"S12 - 1059 [ bib ] : Daniel Bär ; Chris Biemann ; Iryna Gurevych ; Torsten Zesch UKP :Computing Semantic Textual Similarity by Combining Multiple Content Similarity Measures .S12 - 1060 [ bib ] : Frane Šarić ; Goran Glavaš ; Mladen Karan ; Jan Šnajder ; Bojana Dalbelo Bašić TakeLab : Systems for Measuring Semantic Text Similarity .","label":"Background","metadata":{},"score":"53.11708"}
{"text":"In order to ground the meanings of language in a real world situation , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .With such ambiguous supervision , it is required to resolve the ambiguity between a natural language ( NL ) sentence and a corresponding set of possible logical meaning representations ( MR ) .","label":"Background","metadata":{},"score":"53.14814"}
{"text":"In order to ground the meanings of language in a real world situation , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .With such ambiguous supervision , it is required to resolve the ambiguity between a natural language ( NL ) sentence and a corresponding set of possible logical meaning representations ( MR ) .","label":"Background","metadata":{},"score":"53.14814"}
{"text":"[45 ] Z. Kim , G. Gomes , R. Hranac , and A. Skabardonis , \" A Machine Vision System for Generating Vehicle Trajectories over Extended Freeway Segments , \" Proc .12th World Congress Intelligent Transportation Systems , 2005 .","label":"Background","metadata":{},"score":"53.16076"}
{"text":"Cormac Gebruers and I ( with Eugene Freuder , Brahim Hnich and James Little ) experimented with case - based classification techniques for two of the phases of constraint programming .The first phase is how best to model a problem using constraints ; the second is choosing the best solution strategy ( search algorithm , heuristics , etc . ) for finding solutions [ Little et al .","label":"Background","metadata":{},"score":"53.16754"}
{"text":"Using Recommendation Technology to Enhance Waste Exchange Services .A waste exchange service connects people who produce waste with people who can reuse or recycle the waste .We are applying recommender systems ideas to Macroom - E 's web - based waste exchange service , with the goal or making more and better matches .","label":"Background","metadata":{},"score":"53.198956"}
{"text":"Finally , we present an experimental evaluation of BALPs on three benchmark data sets and compare its performance with the state - of - the - art for plan recognition .ML ID : 266 .Abductive Markov Logic for Plan Recognition [ Details ] [ PDF ] [ Slides ] Parag Singla and Raymond J. Mooney In Proceedings of the 25th AAAI Conference on Artificial Intelligence ( AAAI-2011 ) , 1069 - 1075 , August 2011 .","label":"Background","metadata":{},"score":"53.235554"}
{"text":"However , constructing such corpora can be expensive and time - consuming due to the expertise it requires to annotate such data .In this thesis , we explore alternative ways of learning which do not rely on direct human supervision .","label":"Background","metadata":{},"score":"53.382072"}
{"text":"Collective Information Extraction with Relational Markov Networks [ Details ] [ PDF ] Razvan Bunescu and Raymond J. Mooney In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ( ACL-04 ) , 439 - 446 , Barcelona , Spain , July 2004 .","label":"Background","metadata":{},"score":"53.466026"}
{"text":"In this thesis , we investigate the use of ensemble learning to combine the output of existing individual Slot Filling systems .We are the first to employ Stacking , a type of ensemble learning algorithm for the task of ensembling Slot Filling systems for the KBP ESF and SFV tasks .","label":"Background","metadata":{},"score":"53.497833"}
{"text":"Non - recursive clauses arise in many learning problems in Inductive Logic Programming .To further improve the predictive accuracy , we propose a max - margin approach to learning weights for MLNs .Then , to address the issue of scalability , we present CDA , an online max - margin weight learning algorithm for MLNs .","label":"Background","metadata":{},"score":"53.66124"}
{"text":"In the extreme case , only a single entity is known .We present the SR2LR algorithm that finds an effective mapping of predicates from a source model to the target domain in this setting and thus renders pre - existing knowledge useful to the target task .","label":"Background","metadata":{},"score":"53.696148"}
{"text":"Experiments show that our semantic representation can handle RTE and STS reasonably well .For the future work , our short - term goals are 1 . better RTE task representation and finite domain handling , 2 . adding more inference rules , precompiled and on - the - fly , 3 . generalizing the modified closed - world assumption , 4 . enhancing our inference algorithm for MLNs , and 5 . adding a weight learning step to better adapt the weights .","label":"Background","metadata":{},"score":"53.725082"}
{"text":"Experiments show that our semantic representation can handle RTE and STS reasonably well .For the future work , our short - term goals are 1 . better RTE task representation and finite domain handling , 2 . adding more inference rules , precompiled and on - the - fly , 3 . generalizing the modified closed - world assumption , 4 . enhancing our inference algorithm for MLNs , and 5 . adding a weight learning step to better adapt the weights .","label":"Background","metadata":{},"score":"53.725082"}
{"text":"Experiments show that our semantic representation can handle RTE and STS reasonably well .For the future work , our short - term goals are 1 . better RTE task representation and finite domain handling , 2 . adding more inference rules , precompiled and on - the - fly , 3 . generalizing the modified closed - world assumption , 4 . enhancing our inference algorithm for MLNs , and 5 . adding a weight learning step to better adapt the weights .","label":"Background","metadata":{},"score":"53.725082"}
{"text":"Similarly , in machine reading , since some information is implicitly stated , they are rarely observed in the data .In this dissertation , we demonstrate the efficacy of BLPs for inference and learning from incomplete data .Experimental comparison on various benchmark data sets on both tasks demonstrate the superior performance of BLPs over state - of - the - art methods .","label":"Background","metadata":{},"score":"53.81658"}
{"text":"Sources of information include tag dictionaries , morphological analyzers , constituent bracketings , and partial tree annotations , as well as unannotated corpora .For example , we present algorithms that are able to combine faster - to - obtain type - level annotation with unannotated text to remove the need for slower - to - obtain token - level annotation .","label":"Background","metadata":{},"score":"53.86721"}
{"text":"At the same time , MLNs can flexibly deal with noisy or uncertain data to produce probabilistic predictions for a set of propositions .MLNs have also been shown to subsume several other popular SRL models .The expressive power of MLNs comes at a cost : structure learning , or learning the first - order clauses of the model , is a very computationally intensive process that needs to sift through a large hypothesis space with many local maxima and plateaus .","label":"Background","metadata":{},"score":"53.906673"}
{"text":"A First Approximation to Relational Similarity Measuring .S12 - 1072 [ bib ] : zhou qiaoli ; zhang ling ; liu fei ; cai dongfeng ; zhang guiping Zhou qiaoli : A divide - and - conquer strategy for semantic dependency parsing .","label":"Background","metadata":{},"score":"53.915813"}
{"text":"S12 - 1040 [ bib ] : Valerio Basile ; Johan Bos ; Kilian Evang ; Noortje Venhuizen UGroningen : Negation detection with Discourse Representation Structures .S12 - 1041 [ bib ] : Jonathon Read ; Erik Velldal ; Lilja Øvrelid ; Stephan Oepen UiO1 : Constituent - Based Discriminative","label":"Background","metadata":{},"score":"53.971527"}
{"text":"Specifically , I will present two probabilistic generative models for learning such correspondences .The models are applied to two publicly available datasets in two different domains , sportscasting and navigation , and compared with previous work on the same data .","label":"Background","metadata":{},"score":"53.99739"}
{"text":"We view transfer as a revision task and present an algorithm that diagnoses a source MLN to determine which of its parts transfer directly to the target domain and which need to be updated .This analysis focuses the search for revisions on the incorrect portions of the source structure , thus speeding up learning .","label":"Background","metadata":{},"score":"54.016853"}
{"text":"ML ID : 285 .A Formal Approach to Linking Logical Form and Vector - Space Lexical Semantics [ Details ] [ PDF ] Dan Garrette , Katrin Erk , Raymond J. Mooney In Harry Bunt , Johan Bos , and Stephen Pulman , editors , Computing Meaning , 27 - -48 , Berlin , 2013 .","label":"Background","metadata":{},"score":"54.13098"}
{"text":"ML ID : 285 .A Formal Approach to Linking Logical Form and Vector - Space Lexical Semantics [ Details ] [ PDF ] Dan Garrette , Katrin Erk , Raymond J. Mooney In Harry Bunt , Johan Bos , and Stephen Pulman , editors , Computing Meaning , 27 - -48 , Berlin , 2013 .","label":"Background","metadata":{},"score":"54.13098"}
{"text":"ML ID : 285 .A Formal Approach to Linking Logical Form and Vector - Space Lexical Semantics [ Details ] [ PDF ] Dan Garrette , Katrin Erk , Raymond J. Mooney In Harry Bunt , Johan Bos , and Stephen Pulman , editors , Computing Meaning , 27 - -48 , Berlin , 2013 .","label":"Background","metadata":{},"score":"54.13098"}
{"text":"We evaluate several variants of our model that exploit different visual features on a standard set of YouTube videos and two movie description datasets ( M - VAD and MPII - MD ) .ML ID : 319 .We present results on using stacking to ensemble multiple systems for the Knowledge Base Population English Slot Filling ( KBP - ESF ) task .","label":"Background","metadata":{},"score":"54.15798"}
{"text":"In this work , we propose a generalized arc consistency algorithm that prunes the domains of predicates by propagating hard constraints .Our algorithm effectively performs unit propagation at a lifted level , avoiding the need to explicitly ground the hard constraints during the pre - processing phase , yielding a potentially exponential savings in space and time .","label":"Background","metadata":{},"score":"54.27717"}
{"text":"University of Texas at Austin KBP 2013 Slot Filling System : Bayesian Logic Programs for Textual Inference [ Details ] [ PDF ] Yinon Bentor and Amelia Harrison and Shruti Bhosale and Raymond Mooney In Proceedings of the Sixth Text Analysis Conference ( TAC 2013 ) , 2013 .","label":"Background","metadata":{},"score":"54.29071"}
{"text":"Finally , we address an issue arising in applying MLNs to many real - world problems : learning in the presence of many hard constraints .Including hard constraints during training greatly increases the computational complexity of the learning problem .Thus , we propose a simple heuristic for selecting which hard constraints to include during training .","label":"Background","metadata":{},"score":"54.69924"}
{"text":"We present a Bayesian formulation for weakly - supervised learning of a Combinatory Categorial Grammar ( CCG ) supertagger with an HMM .We assume supervision in the form of a tag dictionary , and our prior encourages the use of cross - linguistically common category structures as well as transitions between tags that can combine locally according to CCG 's combinators .","label":"Background","metadata":{},"score":"54.88243"}
{"text":"We present a Bayesian formulation for weakly - supervised learning of a Combinatory Categorial Grammar ( CCG ) supertagger with an HMM .We assume supervision in the form of a tag dictionary , and our prior encourages the use of cross - linguistically common category structures as well as transitions between tags that can combine locally according to CCG 's combinators .","label":"Background","metadata":{},"score":"54.88243"}
{"text":"Much of the information conveyed in text must be inferred from what is explicitly stated since easily inferable facts are rarely mentioned .The proposed rule learner accounts for this phenomenon by learning rules in which the body of the rule contains relations that are usually explicitly stated , while the head employs a less - frequently mentioned relation that is easily inferred .","label":"Background","metadata":{},"score":"54.919456"}
{"text":"Much of the information conveyed in text must be inferred from what is explicitly stated since easily inferable facts are rarely mentioned .The proposed rule learner accounts for this phenomenon by learning rules in which the body of the rule contains relations that are usually explicitly stated , while the head employs a less - frequently mentioned relation that is easily inferred .","label":"Background","metadata":{},"score":"54.919456"}
{"text":"Much of the information conveyed in text must be inferred from what is explicitly stated since easily inferable facts are rarely mentioned .The proposed rule learner accounts for this phenomenon by learning rules in which the body of the rule contains relations that are usually explicitly stated , while the head employs a less - frequently mentioned relation that is easily inferred .","label":"Background","metadata":{},"score":"54.919456"}
{"text":"However , in many cases , considering influences between different candidate extractions could improve overall accuracy .For example , phrase repetitions inside a document are usually associated with the same entity type , the same being true for acronyms and their corresponding long form .","label":"Background","metadata":{},"score":"55.02249"}
{"text":"Next , text mining is employed to learn the correlations between these verbs and related objects .This knowledge is then used together with the outputs of an off - the - shelf object recognizer and the trained activity classifier to produce an improved activity recognizer .","label":"Background","metadata":{},"score":"55.041103"}
{"text":"We proposed the ideas of smart search and smart suggestions as ways of heping users to find items and helping users to author descriptions of items respectively .Aidan wrote up this work for his Research Masters , with the smart suggestions work published in [ Bridge & Waugh 2009 , Waugh & Bridge 2010 ] .","label":"Background","metadata":{},"score":"55.06151"}
{"text":"S12 - 1067 [ bib ] : Marilisa Amoia ; Massimo Romanelli SB : mmSystem - Using Decompositional Semantics for Lexical Simplification .S12 - 1068 [ bib ] : Anne - Laure Ligozat ; Cyril Grouin ; Anne Garcia - Fernandez ; Delphine Bernhard ANNLOR :","label":"Background","metadata":{},"score":"55.124786"}
{"text":"This paper proposes a framework for representing the meaning of phrases and sentences in vector space .Central to our approach is vector composition which we operationalize in terms of additive and multiplicative functions .Under this framework , we introduce a wide range of composition models which ... \" .","label":"Background","metadata":{},"score":"55.183792"}
{"text":"Diversity - Enhanced Conversational Collaborative Recommendations .John Paul Kelly and I investigated ways of building conversational collaborative recommenders , in which user feedback over the course of a multi - step interaction guides the recommender so that it makes recommendations that satisfy the user 's short - term , ephemeral interests .","label":"Background","metadata":{},"score":"55.18393"}
{"text":"However , such resources are extremely costly to produce , making them an unlikely option for building NLP tools in under - resourced languages or domains .This dissertation is concerned with reducing the annotation required to learn NLP models , with the goal of opening up the range of domains and languages to which NLP technologies may be applied .","label":"Background","metadata":{},"score":"55.371822"}
{"text":"S12 - 1091 [ bib ] : Eric Yeh ; Eneko Agirre SRIUBC : Simple Similarity Features for Semantic Textual Similarity .S12 - 1092 [ bib ] : Josè Guilherme Camargo de Souza ; Matteo Negri ; Yashar Mehdad FBK : Machine Translation Evaluation and Word Similarity metrics for Semantic Textual Similarity .","label":"Background","metadata":{},"score":"55.401726"}
{"text":"Publications : 2013 .University of Texas at Austin KBP 2013 Slot Filling System : Bayesian Logic Programs for Textual Inference [ Details ] [ PDF ] Yinon Bentor and Amelia Harrison and Shruti Bhosale and Raymond Mooney In Proceedings of the Sixth Text Analysis Conference ( TAC 2013 ) , 2013 .","label":"Background","metadata":{},"score":"55.47678"}
{"text":"S12 - 1094 [ bib ] : Carmen Banea ; Samer Hassan ; Michael Mohler ; Rada Mihalcea UNT : A Supervised Synergistic Approach to Semantic Text Similarity .S12 - 1095 [ bib ] : Nitish Aggarwal ; Kartik Asooja ; Paul Buitelaar DERI&UPM : Pushing Corpus Based Relatedness to Similarity : Shared Task System Description .","label":"Background","metadata":{},"score":"55.518272"}
{"text":"We went on to test the robustness of both approaches , in particular in dealing with the fact that spam is a moving target , i .. e we are faced with what machine learning researchers would call ' concept drift ' .","label":"Background","metadata":{},"score":"55.52639"}
{"text":"13 , no . 3 , pp .314 - 325 , Mar. 2004 .[14 ] T. Van der Zant , L. Schomaker , and K. Haak , \" Handwritten - Word Spotting Using Biologically Inspired Features , \" IEEE Trans .","label":"Background","metadata":{},"score":"55.552616"}
{"text":"Morgan Kaufmann .Plan recognition is the task of predicting an agent 's top - level plans based on its observed actions .It is an abductive reasoning task that involves inferring plans that best explain observed actions .Most existing approaches to plan recognition and other abductive reasoning tasks either use first - order logic ( or subsets of it ) or probabilistic graphical models .","label":"Background","metadata":{},"score":"55.64826"}
{"text":"Morgan Kaufmann .Plan recognition is the task of predicting an agent 's top - level plans based on its observed actions .It is an abductive reasoning task that involves inferring plans that best explain observed actions .Most existing approaches to plan recognition and other abductive reasoning tasks either use first - order logic ( or subsets of it ) or probabilistic graphical models .","label":"Background","metadata":{},"score":"55.64826"}
{"text":"ML ID : 165 .Transfer Learning with Markov Logic Networks [ Details ] [ PDF ] Lilyana Mihalkova and Raymond Mooney In Proceedings of the ICML-06 Workshop on Structural Knowledge Transfer for Machine Learning , Pittsburgh , PA , June 2006 .","label":"Background","metadata":{},"score":"55.708015"}
{"text":"Mapping and Revising Markov Logic Networks for Transfer Learning [ Details ] [ PDF ] Lilyana Mihalkova , Tuyen N. Huynh , Raymond J. Mooney In Proceedings of the Twenty - Second Conference on Artificial Intelligence ( AAAI-07 ) , 608 - 614 , Vancouver , BC , July 2007 .","label":"Background","metadata":{},"score":"55.731163"}
{"text":"S12 - 1076 [ bib ] : Michael Heilman ; Nitin Madnani ETS : Discriminative Edit Models for Paraphrase Scoring .S12 - 1077 [ bib ] : Samir AbdelRahman ; Catherine Blake Sbdlrhmn : A Rule - based Human Interpretation System for Semantic Textual Similarity Task .","label":"Background","metadata":{},"score":"55.78732"}
{"text":"S12 - 1074 [ bib ] : Guangchao Tang ; Bin Li ; Shuaishuai Xu ; Xinyu Dai ; Jiajun Chen NJU - Parser : Achievements on Semantic Dependency Parsing .S12 - 1075 [ bib ] : Jian Xu ; Qin Lu ; Zhengzhong Liu","label":"Background","metadata":{},"score":"55.793785"}
{"text":"However , much of the information conveyed in text must be inferred from what is explicitly stated since easily inferable facts are rarely mentioned .Human readers naturally use common sense knowledge and \" read between the lines \" to infer such implicit information from the explicitly stated facts .","label":"Background","metadata":{},"score":"55.88327"}
{"text":"S12 - 1107 [ bib ] : Alpar Perini DirRelCond3 : Detecting Textual Entailment Across Languages With Conditions On Directional Text Relatedness Scores .S12 - 1108 [ bib ] : Fandong Meng ; Hao Xiong ; Qun Liu ICT : A Translation based Method for Cross - lingual Textual Entailment .","label":"Background","metadata":{},"score":"56.040924"}
{"text":"Most existing approaches to plan recognition and other abductive tasks employ either purely logical methods that do not handle uncertainty , or purely probabilistic methods that do not handle structured representations .To overcome these limitations , this paper introduces an approach to abductive reasoning using a first - order probabilistic logic , specifically Markov Logic Networks ( MLNs ) .","label":"Background","metadata":{},"score":"56.07076"}
{"text":"Human readers naturally use common sense knowledge and \" read between the lines \" to infer such implicit information from the explicitly stated facts .Since IE systems do not have access to common sense knowledge , they can not perform deeper reasoning to infer implicitly stated facts .","label":"Background","metadata":{},"score":"56.07109"}
{"text":"S12 - 1053 [ bib ] : Matteo Negri ; Alessandro Marchetti ; Yashar Mehdad ; Luisa Bentivogli ; Danilo Giampiccolo Semeval-2012 Task 8 : Cross - lingual Textual Entailment for Content Synchronization .S12 - 1054 [ bib ] : Anders Johannsen ; Hèctor Martìnez ; Sigrid Klerke ; Anders Søgaard EMNLP@CPH : Is frequency all there is to simplicity ?","label":"Background","metadata":{},"score":"56.115494"}
{"text":"University of Texas at Austin KBP 2014 Slot Filling System : Bayesian Logic Programs for Textual Inference [ Details ] [ PDF ] Yinon Bentor and Vidhoon Viswanathan and Raymond Mooney In Proceedings of the Seventh Text Analysis Conference : Knowledge Base Population ( TAC 2014 ) , 2014 .","label":"Background","metadata":{},"score":"56.20639"}
{"text":"This paper introduces two new frameworks , Doubly Supervised Latent Dirichlet Allocation ( DSLDA ) and its non - parametric variation ( NP - DSLDA ) , that integrate two different types of supervision : topic labels and category labels .This approach is particularly useful for multitask learning , in which both latent and supervised topics are shared between multiple categories .","label":"Background","metadata":{},"score":"56.28534"}
{"text":"The question of how meaning might be acquired by young children and represented by adult speakers of a language is one of the most debated topics in cognitive science .Existing semantic representation models are primarily amodal based on information provided by the linguistic input despite ample evi ... \" .","label":"Background","metadata":{},"score":"56.294815"}
{"text":"This position paper proposes that the study of embodied cognitive agents , such as humanoid robots , can advance our understanding of the cognitive development of complex sensorimotor , linguistic and social learning skills .This in turn will benefit the design of cognitive robots capable of learning to handle and manipulate objects and tools autonomously , to cooperate and communicate with other robots and humans , and to adapt their abilities to changing internal , environmental , and social conditions .","label":"Background","metadata":{},"score":"56.443855"}
{"text":"On the Proper Treatment of Quantifiers in Probabilistic Logic Semantics [ Details ] [ PDF ] [ Slides ] Islam Beltagy and Katrin Erk In Proceedings of the 11th International Conference on Computational Semantics ( IWCS-2015 ) , London , UK , April 2015 .","label":"Background","metadata":{},"score":"56.53826"}
{"text":"To overcome these limitations , we explore the application of statistical relational models that combine the strengths of both first - order logic and probabilistic graphical models to plan recognition .Specifically , we introduce two new approaches to abductive plan recognition using Bayesian Logic Programs ( BLPs ) and Markov Logic Networks ( MLNs ) .","label":"Background","metadata":{},"score":"56.699688"}
{"text":"To overcome these limitations , we explore the application of statistical relational models that combine the strengths of both first - order logic and probabilistic graphical models to plan recognition .Specifically , we introduce two new approaches to abductive plan recognition using Bayesian Logic Programs ( BLPs ) and Markov Logic Networks ( MLNs ) .","label":"Background","metadata":{},"score":"56.699688"}
{"text":"ML ID : 272 .Fast Online Lexicon Learning for Grounded Language Acquisition [ Details ] [ PDF ] [ Slides ] David L. Chen In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics ( ACL-2012 ) , 430 - -439 , July 2012 .","label":"Background","metadata":{},"score":"56.851444"}
{"text":"ML ID : 227 .Search Query Disambiguation from Short Sessions [ Details ] [ PDF ] Lilyana Mihalkova and Raymond Mooney In Beyond Search : Computational Intelligence for the Web Workshop at NIPS , 2008 .Web searches tend to be short and ambiguous .","label":"Background","metadata":{},"score":"56.886185"}
{"text":"Classifying entity mentions into a predefined set of categories achieves only a partial disambiguation of the names .This is further refined in the task of Named Entity Disambiguation , where names need to be linked to their actual denotations .In our research , we use Wikipedia as a repository of named entities and propose a ranking approach to disambiguation that exploits learned correlations between words from the name context and categories from the Wikipedia taxonomy .","label":"Background","metadata":{},"score":"56.902363"}
{"text":"This allows for ' ' collective information extraction ' ' that exploits the mutual influence between possible extractions .Experiments on learning to extract protein names from biomedical text demonstrate the advantages of this approach .ML ID : 152 .Relational Markov Networks for Collective Information Extraction [ Details ] [ PDF ] Razvan Bunescu and Raymond J. Mooney In Proceedings of the ICML-04 Workshop on Statistical Relational Learning and its Connections to Other Fields , Banff , Alberta , July 2004 .","label":"Background","metadata":{},"score":"56.966827"}
{"text":"Text Analysis Conference conducts English Slot Filling ( ESF ) and Slot Filler Validation ( SFV ) tasks as part of its KBP track to promote research in this area .Slot Filling systems are developed to do relation extraction for specific relation and entity types .","label":"Background","metadata":{},"score":"57.142418"}
{"text":"Miles Osborne successfully completed his D.Phil .under my supervision .Miles developed one of the first systems capable of learning unification - based grammars .The inductive search space was constrained by a set of linguistic universals ( and , in the implemented system , some language - specific linguistic constraints ) [ Osborne & Bridge 1993a , Osborne & Bridge 1993b , Osborne & Bridge 1994b , Osborne & Bridge 1997e ] .","label":"Background","metadata":{},"score":"57.201897"}
{"text":"In this proposal , we focus on applying BLPs to two real worlds tasks -- plan recognition and machine reading .Plan recognition is the task of predicting an agent 's top - level plans based on its observed actions .It is an abductive reasoning task that involves inferring cause from effect .","label":"Background","metadata":{},"score":"57.212635"}
{"text":"ML ID : 311 .Weakly - Supervised Grammar - Informed Bayesian CCG Parser Learning [ Details ] [ PDF ] [ Slides ] Dan Garrette , Chris Dyer , Jason Baldridge , Noah A. Smith In Proceedings of the Twenty - Ninth AAAI Conference on Artificial Intelligence ( AAAI-15 ) , Austin , TX , January 2015 .","label":"Background","metadata":{},"score":"57.27533"}
{"text":"ML ID : 254 .Integrating Logical Representations with Probabilistic Information using Markov Logic [ Details ] [ PDF ] [ Slides ] Dan Garrette , Katrin Erk , Raymond Mooney In Proceedings of the International Conference on Computational Semantics , 105 - -114 , Oxford , England , January 2011 .","label":"Background","metadata":{},"score":"57.484337"}
{"text":"Past work on learning part - of - speech taggers from tag dictionaries and raw data has reported good results , but the assumptions made about those dictionaries are often unrealistic : due to historical precedents , they assume access to information about labels in the raw and test sets .","label":"Background","metadata":{},"score":"57.523773"}
{"text":"S12 - 1036 [ bib ] : Binod Gyawali ; Thamar Solorio UABCoRAL : A Preliminary study for Resolving the Scope of Negation .S12 - 1037 [ bib ] : Jorge Carrillo de Albornoz ; Laura Plaza ; Alberto Dìaz ; Miguel Ballesteros UCM - I : A Rule - based Syntactic Approach for Resolving the Scope of Negation .","label":"Background","metadata":{},"score":"57.611404"}
{"text":"ML ID : 311 .University of Texas at Austin KBP 2014 Slot Filling System : Bayesian Logic Programs for Textual Inference [ Details ] [ PDF ] Yinon Bentor and Vidhoon Viswanathan and Raymond Mooney In Proceedings of the Seventh Text Analysis Conference : Knowledge Base Population ( TAC 2014 ) , 2014 .","label":"Background","metadata":{},"score":"57.64549"}
{"text":"First , we propose a number of new probabilistic script models leveraging recent advances in Neural Network training .These include recurrent sequence models with different hidden unit structure and Convolutional Neural Network models .Second , we propose integrating more lexical and linguistic information into events .","label":"Background","metadata":{},"score":"57.651287"}
{"text":"The generalization process is a knowledge - based analysis of the narrative 's causal structure which removes unnecessary details while maintaining the validity of the explanation .The resulting generalized set of actions is then stored as a new schema and used by the system to process narratives which were previously beyond its capabilities .","label":"Background","metadata":{},"score":"57.66935"}
{"text":"Next , we apply BALPs to the task of plan recognition and demonstrate its efficacy on two data sets .We also compare the performance of BALPs with several existing approaches for abduction .ML ID : 244 .Discriminative Learning with Markov Logic Networks [ Details ] [ PDF ] [ Slides ] Tuyen N. Huynh October 2009 .","label":"Background","metadata":{},"score":"57.720867"}
{"text":"We evaluate this semantic representation on two tasks , Recognizing Textual Entailment ( RTE ) and Semantic Textual Similarity ( STS ) .Doing RTE and STS better is an indication of a better semantic understanding .Our system has three main components , 1 .","label":"Background","metadata":{},"score":"57.7502"}
{"text":"The clustering step incurs only a one - time up - front cost when weights are learned over a fixed structure .ML ID : 231 .Probabilistic Abduction using Markov Logic Networks [ Details ] [ PDF ] [ Slides ] Rohit J. Kate and Raymond J. Mooney In Proceedings of the IJCAI-09 Workshop on Plan , Activity , and Intent Recognition ( PAIR-09 ) , Pasadena , CA , July 2009 .","label":"Background","metadata":{},"score":"57.77751"}
{"text":"While crowdsourcing offers a cheap alternative , quality control and scalability can become problematic .We discuss a novel annotation task that uses videos as the stimulus which discourages cheating .In addi- tion , our approach requires only monolingual speakers , thus making it easier to scale since more workers are qualified to contribute .","label":"Background","metadata":{},"score":"57.939133"}
{"text":"S12 - 1069 [ bib ] : Ravi Sinha UNT - SimpRank : Systems for Lexical Simplification Ranking .S12 - 1070 [ bib ] : Ted Pedersen Duluth : Measuring Degrees of Relational Similarity with the Gloss Vector Measure of Semantic Relatedness .","label":"Background","metadata":{},"score":"57.949745"}
{"text":"The model leads to an EM - style clustering algorithm , the E - step of which requires collective assignment of instances to cluster centroids under the constraints .We evaluate three known techniques for such collective assignment : belief propagation , linear programming relaxation , and iterated conditional modes ( ICM ) .","label":"Background","metadata":{},"score":"58.08348"}
{"text":"Adapting Discriminative Reranking to Grounded Language Learning [ Details ] [ PDF ] [ Slides ] Joohyun Kim and Raymond J. Mooney In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL-2013 ) , 218 - -227 , Sofia , Bulgaria , August 2013 .","label":"Background","metadata":{},"score":"58.09302"}
{"text":"Adapting Discriminative Reranking to Grounded Language Learning [ Details ] [ PDF ] [ Slides ] Joohyun Kim and Raymond J. Mooney In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL-2013 ) , 218 - -227 , Sofia , Bulgaria , August 2013 .","label":"Background","metadata":{},"score":"58.09302"}
{"text":"A central goal of transfer learning is to enable learning when training data from the domain of interest is limited .Yet , work on transfer across relational domains has so far focused on the case where there is a significant amount of target data .","label":"Background","metadata":{},"score":"58.09472"}
{"text":"S12 - 1097 [ bib ] : Sam Biggins ; Shaabi Mohammed ; Sam Oakley ; Luke Stringer ; Mark Stevenson ; Judita Preiss University_Of_Sheffield : Two Approaches to Semantic Text Similarity .S12 - 1098 [ bib ] : Janardhan Singh ; Arindam Bhattacharya ; Pushpak Bhattacharyya janardhan : Semantic Textual Similarity using Universal Networking Language graph matching .","label":"Background","metadata":{},"score":"58.123257"}
{"text":"S12 - 1062 [ bib ] : Enrique Amigó ; Jesus Gimenez ; Julio Gonzalo ; Felisa Verdejo UNED : Improving Text Similarity Measures without Human Assessments .S12 - 1063 [ bib ] : Travis Goodwin ; Bryan Rink ; Kirk Roberts ; Sanda Harabagiu UTDHLT :","label":"Background","metadata":{},"score":"58.244972"}
{"text":"This allows for ' ' collective information extraction ' ' that exploits the mutual influence between possible extractions .Experiments on learning to extract protein names from biomedical text demonstrate the advantages of this approach .ML ID : 145 .Recently , a number of methods have been proposed for semi - supervised clustering that employ supervision in the form of pairwise constraints .","label":"Background","metadata":{},"score":"58.25075"}
{"text":"We present a novel combination of standard activity classification , object recognition , and text mining to learn effective activity recognizers without ever explicitly labeling training videos .We cluster verbs used to describe videos to automatically discover classes of activities and produce a labeled training set .","label":"Background","metadata":{},"score":"58.990158"}
{"text":"As these kinds of histograms results with large variations between neighbouring bins , they seem so sensitive to any kind of changes such as noise , illumination .The experimental results on 100 images within two categories of Cat and Sky reveals better performance of the proposed method in comparison with the other mentioned methods .","label":"Background","metadata":{},"score":"59.076874"}
{"text":"As these kinds of histograms results with large variations between neighbouring bins , they seem so sensitive to any kind of changes such as noise , illumination .The experimental results on 100 images within two categories of Cat and Sky reveals better performance of the proposed method in comparison with the other mentioned methods .","label":"Background","metadata":{},"score":"59.076874"}
{"text":"In the second part of the dissertation , we apply BLPs to the task of machine reading , which involves automatic extraction of knowledge from natural language text .Most information extraction ( IE ) systems identify facts that are explicitly stated in text .","label":"Background","metadata":{},"score":"59.171898"}
{"text":"ML ID : 255 .Implementing Weighted Abduction in Markov Logic [ Details ] [ PDF ] James Blythe , Jerry R. Hobbs , Pedro Domingos , Rohit J. Kate , Raymond J. Mooney In Proceedings of the International Conference on Computational Semantics , 55 - -64 , Oxford , England , January 2011 .","label":"Background","metadata":{},"score":"59.342873"}
{"text":"Active learning , on the other hand , reduces the cost of labeling examples by making informative queries over an unlabeled pool of data .Therefore , a unification of both of these approaches can potentially be useful in settings where labeled information is expensive to obtain but the learning tasks or domains have some common characteristics .","label":"Background","metadata":{},"score":"59.408245"}
{"text":"While a variety of semi - supervised methods exist for training from incomplete data , there are open questions regarding what types of training data should be used and how much is necessary .We discuss a series of experiments designed to shed light on such questions in the context of part - of - speech tagging .","label":"Background","metadata":{},"score":"59.470657"}
{"text":"While a variety of semi - supervised methods exist for training from incomplete data , there are open questions regarding what types of training data should be used and how much is necessary .We discuss a series of experiments designed to shed light on such questions in the context of part - of - speech tagging .","label":"Background","metadata":{},"score":"59.470657"}
{"text":"S12 - 1103 [ bib ] : Snehasis Neogi ; Partha Pakray ; Sivaji Bandyopadhyay ; Alexander Gelbukh JU_CSE_NLP : Language Independent Cross - lingual Textual Entailment System .S12 - 1104 [ bib ] : Milen Kouylekov ; Luca Dini ; Alessio Bosca ; Marco Trevisan CELI :","label":"Background","metadata":{},"score":"59.5358"}
{"text":"Described video datasets are scarce , and most existing methods have been applied to toy domains with a small vocabulary of possible words .By transferring knowledge from 1.2M+ images with category labels and 100,000 + images with captions , our method is able to create sentence descriptions of open - domain videos with large vocabularies .","label":"Background","metadata":{},"score":"59.770123"}
{"text":"We present the SR2LR algorithm that finds an effective mapping of the source model to the target domain in this setting and demonstsrate its effectiveness in three relational domains .Our experiments additionally show that the most accurate model for the source domain is not always the best model to use for transfer .","label":"Background","metadata":{},"score":"59.889446"}
{"text":"This work shows how linguistic universals intrinsic to the CCG formalism itself can be encoded as Bayesian priors to improve learning .ML ID : 321 .Combinatory Categorial Grammar ( CCG ) is a lexicalized grammar formalism in which words are associated with categories that specify the syntactic configurations in which they may occur .","label":"Background","metadata":{},"score":"60.044827"}
{"text":"S12 - 1085 [ bib ] : Sumit Bhagwani ; Shrutiranjan Satapathy ; Harish Karnick sranjans : Semantic Textual Similarity using Maximal Weighted Bipartite Graph Matching .S12 - 1086 [ bib ] : Weiwei Guo ; Mona Diab Weiwei : A Simple Unsupervised Latent Semantics based Approach for Sentence Similarity .","label":"Background","metadata":{},"score":"60.063744"}
{"text":"ML ID : 253 .Generalizing Explanations of Narratives into Schemata [ Details ] [ PDF ] Raymond J. Mooney In Proceedings of the Third International Machine Learning Workshop , 126 - -128 , New Brunswick , New Jersey , 1985 .","label":"Background","metadata":{},"score":"60.133736"}
{"text":"Traditionally , machine learning algorithms assume that training data is provided as a set of independent instances , each of which can be described as a feature vector .In contrast , many domains of interest are inherently multi - relational , consisting of entities connected by a rich set of relations .","label":"Background","metadata":{},"score":"60.47704"}
{"text":"Sentences and the on - the - fly ontology are represented in probabilistic logic .For inference , we use probabilistic logic frameworks like Markov Logic Networks ( MLN ) and Probabilistic Soft Logic ( PSL ) .This semantic parsing approach is evaluated on two tasks , Textual Entitlement ( RTE ) and Textual Similarity ( STS ) , both accomplished using inference in probabilistic logic .","label":"Background","metadata":{},"score":"60.86743"}
{"text":"Sentences and the on - the - fly ontology are represented in probabilistic logic .For inference , we use probabilistic logic frameworks like Markov Logic Networks ( MLN ) and Probabilistic Soft Logic ( PSL ) .This semantic parsing approach is evaluated on two tasks , Textual Entitlement ( RTE ) and Textual Similarity ( STS ) , both accomplished using inference in probabilistic logic .","label":"Background","metadata":{},"score":"60.86743"}
{"text":"Our major contribution was to show diversity can be enhanced using only the knowledge already contained in the ratings matrix [ Bridge & Kelly 2005 , Bridge & Kelly 2006 , Kelly & Bridge 2006 ] .John Paul received some support from the Adaptive Information Cluster , funded by Science Foundation Ireland .","label":"Background","metadata":{},"score":"61.041008"}
{"text":"Online Inference - Rule Learning from Natural - Language Extractions [ Details ] [ PDF ][Poster ] Sindhu Raghavan and Raymond J. Mooney In Proceedings of the 3rd Statistical Relational AI ( StaRAI-13 ) workshop at AAAI ' 13 , July 2013 .","label":"Background","metadata":{},"score":"61.07657"}
{"text":"Online Inference - Rule Learning from Natural - Language Extractions [ Details ] [ PDF ][Poster ] Sindhu Raghavan and Raymond J. Mooney In Proceedings of the 3rd Statistical Relational AI ( StaRAI-13 ) workshop at AAAI ' 13 , July 2013 .","label":"Background","metadata":{},"score":"61.07657"}
{"text":"Online Inference - Rule Learning from Natural - Language Extractions [ Details ] [ PDF ][Poster ] Sindhu Raghavan and Raymond J. Mooney In Proceedings of the 3rd Statistical Relational AI ( StaRAI-13 ) workshop at AAAI ' 13 , July 2013 .","label":"Background","metadata":{},"score":"61.07657"}
{"text":"ML ID : 291 .Real - World Semi - Supervised Learning of POS - Taggers for Low - Resource Languages [ Details ] [ PDF ] Dan Garrette and Jason Mielens and Jason Baldridge In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL-2013 ) , 583 - -592 , Sofia , Bulgaria , August 2013 .","label":"Background","metadata":{},"score":"61.25817"}
{"text":"One of the key challenges in grounded language acquisition is resolving the intentions of the expressions .Typically the task involves identifying a subset of records from a list of candidates as the correct meaning of a sentence .While most current work assume complete or partial independence be- tween the records , we examine a scenario in which they are strongly related .","label":"Background","metadata":{},"score":"61.507843"}
{"text":"ML ID : 316 .Knowledge Base Population using Stacked Ensembles of Information Extractors [ Details ] [ PDF ] Vidhoon Viswanathan Masters Thesis , Department of Computer Science , The University of Texas at Austin , May 2015 .The performance of relation extractors plays a significant role in automatic creation of knowledge bases from web corpus .","label":"Background","metadata":{},"score":"61.69248"}
{"text":"ML ID : 270 .Many real world problems can be modeled using a combination of hard and soft constraints .Markov Logic is a highly expressive language which represents the underlying constraints by attaching real - valued weights to formulas in first order logic .","label":"Background","metadata":{},"score":"61.70655"}
{"text":"Experiments on three plan recognition datasets show the benefit of our approach over existing methods .ML ID : 263 .Extending Bayesian Logic Programs for Plan Recognition and Machine Reading [ Details ] [ PDF ] [ Slides ] Sindhu V. Raghavan Technical Report , PhD proposal , Department of Computer Science , The University of Texas at Austin , May 2011 .","label":"Background","metadata":{},"score":"61.74404"}
{"text":"In this paper we introduce a new online algorithm that is an order of magnitude faster and surpasses the state - of - the - art results .We show that by changing the grammar of the formal meaning representation language and training on additional data collected from Amazon 's Mechanical Turk we can further improve the results .","label":"Background","metadata":{},"score":"61.80976"}
{"text":"Experimental evaluation over one artificial and two real - world datasets show the benefit of our approach .ML ID : 268 .Most existing learning methods for Markov Logic Networks ( MLNs ) use batch training , which becomes computationally expensive and eventually infeasible for large datasets with thousands of training examples which may not even all fit in main memory .","label":"Background","metadata":{},"score":"61.94324"}
{"text":"For most people , watching a brief video and describing what happened ( in words ) is an easy task .For machines , extracting the meaning from video pixels and generating a sentence description is a very complex problem .The goal of my research is to develop models that can automatically generate natural language ( NL ) descriptions for events in videos .","label":"Background","metadata":{},"score":"61.95964"}
{"text":"The system processes short English narratives and from a single narrative acquires a new schema for a stereotypical set of actions .During the understanding process , the system constructs explanations for characters ' actions in terms of the goals they were meant to achieve .","label":"Background","metadata":{},"score":"61.995354"}
{"text":"Integrating Logical Representations with Probabilistic Information using Markov Logic [ Details ] [ PDF ] [ Slides ] Dan Garrette , Katrin Erk , Raymond Mooney In Proceedings of the International Conference on Computational Semantics , 105 - -114 , Oxford , England , January 2011 .","label":"Background","metadata":{},"score":"62.015484"}
{"text":"S12 - 1105 [ bib ] : Yashar Mehdad ; Matteo Negri ; Jose Guilherme C. de Souza FBK : Cross - Lingual Textual Entailment Without Translation .S12 - 1106 [ bib ] : Darnes Vilariño ; David Pinto ; Mireya Tovar ; Saul León ; Esteban Castillo BUAP :","label":"Background","metadata":{},"score":"62.094772"}
{"text":"Central to our approach is vector composition which we operationalize in terms of additive and multiplicative functions .Under this framework , we introduce a wide range of composition models which we evaluate empirically on a sentence similarity task .Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments . .","label":"Background","metadata":{},"score":"62.178856"}
{"text":"Improving Learning of Markov Logic Networks using Transfer and Bottom - Up Induction [ Details ] [ PDF ] Lilyana Mihalkova Technical Report UT - AI - TR-07 - 341 , Artificial Intelligence Lab , University of Texas at Austin , Austin , TX , May 2007 .","label":"Background","metadata":{},"score":"62.241364"}
{"text":"This results in a new model , Max - Margin Markov Logic Networks ( M3LNs ) , that combines the expressiveness of MLNs with the predictive accuracy of structural Support Vector Machines ( SVMs ) .To train the proposed model , we design a new approximation algorithm for loss - augmented inference in MLNs based on Linear Programming ( LP ) .","label":"Background","metadata":{},"score":"62.257996"}
{"text":"Inducing Grammars from Linguistic Universals and Realistic Amounts of Supervision [ Details ] [ PDF ] Dan Garrette PhD Thesis , Department of Computer Science , The University of Texas at Austin , 2015 .The best performing NLP models to date are learned from large volumes of manually - annotated data .","label":"Background","metadata":{},"score":"62.28778"}
{"text":"These milestones provide a possible set of cognitive robotics goals and test - scenarios , thus acting as a research roadmap for future work on cognitive developmental robotics . ... the testing in robotics models of challenging research issues in embodiment literature .","label":"Background","metadata":{},"score":"62.399887"}
{"text":"S12 - 1064 [ bib ] : Katharina Wäschle ; Sascha Fendrich HDU : Cross - lingual Textual Entailment with SMT Features .S12 - 1065 [ bib ] : Miquel Esplà - Gomis ; Felipe Sánchez - Martìnez ; Mikel L. Forcada UAlacant : Using Online Machine Translation for Cross - Lingual Textual Entailment .","label":"Background","metadata":{},"score":"62.5039"}
{"text":"Experimental results on a plan recognition task demonstrate the effectiveness of this method .ML ID : 228 .Transfer Learning from Minimal Target Data by Mapping across Relational Domains [ Details ] [ PDF ] Lilyana Mihalkova and Raymond Mooney In Proceedings of the 21st","label":"Background","metadata":{},"score":"62.529488"}
{"text":"In plan recognition , the underlying cause or the top - level plan that resulted in the observed actions is not known or observed .Further , only a subset of the executed actions can be observed by the plan recognition system resulting in partially observed data .","label":"Background","metadata":{},"score":"62.622704"}
{"text":"ML ID : 271 .Learning Language from Ambiguous Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen PhD Thesis , Department of Computer Science , University of Texas at Austin , May 2012 .Building a computer system that can understand human languages has been one of the long - standing goals of artificial intelligence .","label":"Background","metadata":{},"score":"62.63877"}
{"text":"To address these limitations , statistical relational learning ( SRL ) , a new area in machine learning integrating both first - order logic and probabilistic graphical models , has emerged in the recent past .The advantage of SRL models is that they can handle both uncertainty and structured / relational data .","label":"Background","metadata":{},"score":"62.64824"}
{"text":"[ Show abstract ] [ Hide abstract ] ABSTRACT : The research interest in the recent years has progressed to improve the performance of image retrieval ( IR ) systems by reducing the semantic gap between the low - level features and the high - level concept .","label":"Background","metadata":{},"score":"62.653183"}
{"text":"[ Show abstract ] [ Hide abstract ] ABSTRACT : The research interest in the recent years has progressed to improve the performance of image retrieval ( IR ) systems by reducing the semantic gap between the low - level features and the high - level concept .","label":"Background","metadata":{},"score":"62.653183"}
{"text":"For future work , we propose to apply BLPs to the task of machine reading , which involves automatic extraction of knowledge from natural language text .Present day information extraction ( IE ) systems that are trained for machine reading are limited by their ability to extract only factual information that is stated explicitly in the text .","label":"Background","metadata":{},"score":"62.73758"}
{"text":"ML ID : 269 .Building a Persistent Workforce on Mechanical Turk for Multilingual Data Collection [ Details ] [ PDF ] [ Slides ] David L. Chen and William B. Dolan In Proceedings of The 3rd Human Computation Workshop ( HCOMP 2011 ) , August 2011 .","label":"Background","metadata":{},"score":"62.79265"}
{"text":"Therefore , we extend BLPs to use logical abduction to construct Bayesian networks and call the resulting model Bayesian Abductive Logic Programs ( BALPs ) .In the second part of the dissertation , we apply BLPs to the task of machine reading , which involves automatic extraction of knowledge from natural language text .","label":"Background","metadata":{},"score":"62.838554"}
{"text":"Knowledge Base Construction , and 3 .Inference The input natural sentences of the RTE / STS task are mapped to logical form using Boxer which is a rule based system built on top of a CCG parser , then they are used to formulate the RTE / STS problem in probabilistic logic .","label":"Background","metadata":{},"score":"62.887604"}
{"text":"Learning for Information Extraction : From Named Entity Recognition and Disambiguation To Relation Extraction [ Details ] [ PDF ] Razvan Constantin Bunescu PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .","label":"Background","metadata":{},"score":"62.889397"}
{"text":"We build on one particular SRL model , Markov logic networks ( MLNs ) , which consist of a set of weighted first - order - logic formulae and provide a principled way of defining a probability distribution over possible worlds .","label":"Background","metadata":{},"score":"62.911713"}
{"text":"ML ID : 316 .On the Proper Treatment of Quantifiers in Probabilistic Logic Semantics [ Details ] [ PDF ] [ Slides ] Islam Beltagy and Katrin Erk In Proceedings of the 11th International Conference on Computational Semantics ( IWCS-2015 ) , London , UK , April 2015 .","label":"Background","metadata":{},"score":"63.091587"}
{"text":"ML ID : 320 .Real - world videos often have complex dynamics ; and methods for generating open - domain video descriptions should be sensitive to temporal structure and allow both input ( sequence of frames ) and output ( sequence of words ) of variable length .","label":"Background","metadata":{},"score":"63.19883"}
{"text":"Despite a recent push towards large - scale object recognition , activity recognition remains limited to narrow domains and small vocabularies of actions .In this paper , we tackle the challenge of recognizing and describing activities \" in - the - wild \" .","label":"Background","metadata":{},"score":"63.27749"}
{"text":"Despite a recent push towards large - scale object recognition , activity recognition remains limited to narrow domains and small vocabularies of actions .In this paper , we tackle the challenge of recognizing and describing activities \" in - the - wild \" .","label":"Background","metadata":{},"score":"63.27749"}
{"text":"Pat wrote up this work for his Research Masters .He was supported by an award made by the Boole Centre for Research in Informatics , which was funded by the Higher Education Authority 's Programme for Research in Third Level Institutions Cycle 3 .","label":"Background","metadata":{},"score":"63.44473"}
{"text":"ML ID : 234 .Web searches tend to be short and ambiguous .It is therefore not surprising that Web query disambiguation is an actively researched topic .To provide a personalized experience for a user , most existing work relies on search engine log data in which the search activities of that particular user , as well as other users , are recorded over long periods of time .","label":"Background","metadata":{},"score":"63.44969"}
{"text":"S12 - 1042 [ bib ] : Emanuele Lapponi ; Erik Velldal ; Lilja Øvrelid ; Jonathon Read UiO 2 : Sequence - labeling Negation Using Dependency Features .S12 - 1043 [ bib ] : Amjad Abu Jbara ; Dragomir Radev UMichigan :","label":"Background","metadata":{},"score":"63.51647"}
{"text":"Logic and Databases : An Object - Oriented Approach .Chris Higgins successfully completed a D.Phil ., partly under my supervision , in which he formalised object - oriented databases .He used a logic programming formalisation : objects are theories , and inter - object communication operates at a metalogical level .","label":"Background","metadata":{},"score":"63.53092"}
{"text":"It is an abductive reasoning task that involves inferring cause from effect .In the first part of the dissertation , we develop an approach to abductive plan recognition using BLPs .Since BLPs employ logical deduction to construct the networks , they can not be used effectively for abductive plan recognition as is .","label":"Background","metadata":{},"score":"63.87812"}
{"text":"Latent Variable Models of Distributional Lexical Semantics [ Details ] [ PDF ] Joseph Reisinger PhD Thesis , Department of Computer Science , University of Texas at Austin , May 2012 .In order to respond to increasing demand for natural language interfaces - and provide meaningful insight into user query intent - fast , scalable lexical semantic models with flexible representations are needed .","label":"Background","metadata":{},"score":"63.982887"}
{"text":"This optimization problem can be solved by an efficient algorithm based on the cutting plane method .However , this cutting plane algorithm requires an efficient inference method as a subroutine .Unfortunately , exact inference in MLNs is intractable .So we develop a new approximation inference method for MLNs based on Linear Programming relaxation .","label":"Background","metadata":{},"score":"63.984642"}
{"text":"ML ID : 274 .Generative Models of Grounded Language Learning with Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joohyun Kim Technical Report , PhD proposal , Department of Computer Science , The University of Texas at Austin , June 2012 . \"","label":"Background","metadata":{},"score":"64.059525"}
{"text":"ML ID : 289 .Real - World Semi - Supervised Learning of POS - Taggers for Low - Resource Languages [ Details ] [ PDF ] Dan Garrette and Jason Mielens and Jason Baldridge In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL-2013 ) , 583 - -592 , Sofia , Bulgaria , August 2013 .","label":"Background","metadata":{},"score":"64.071335"}
{"text":"We employ syntactic , semantic , and encyclopedic information to guide our extraction , yielding concept - relation - feature triples ( e.g. , car be fast , car require petrol , car cause pollution ) , which approximate property - based conceptual representa - tions .","label":"Background","metadata":{},"score":"64.44567"}
{"text":"Inclusive yet Selective : Supervised Distributional Hypernymy Detection [ Details ] [ PDF ] Stephen Roller and Katrin Erk and Gemma Boleda In Proceedings of the 25th International Conference on Computational Linguistics ( COLING 2014 ) , 1025 - -1036 , Dublin , Ireland , August 2014 .","label":"Background","metadata":{},"score":"64.50186"}
{"text":"Inclusive yet Selective : Supervised Distributional Hypernymy Detection [ Details ] [ PDF ] Stephen Roller and Katrin Erk and Gemma Boleda In Proceedings of the 25th International Conference on Computational Linguistics ( COLING 2014 ) , 1025 - -1036 , Dublin , Ireland , August 2014 .","label":"Background","metadata":{},"score":"64.50186"}
{"text":"Formal Justification in Requirements Engineering .Simon Smith successfully completed a D.Phil ., partly under my supervision , in which he developed a way of structuring formal specifications to allow incremental re - proof of previously established properties following changes to the specification .","label":"Background","metadata":{},"score":"64.53006"}
{"text":"In this paper , we adopt a hybrid approach that combines logic - based and distributional semantics through probabilistic logic inference in Markov Logic Networks ( MLNs ) .We focus on textual entailment ( RTE ) , a task that can utilize the strengths of both representations .","label":"Background","metadata":{},"score":"64.61913"}
{"text":"It is an abductive reasoning task that involves inferring cause from effect .Most existing approaches to plan recognition use either first - order logic or probabilistic graphical models .While the former can- not handle uncertainty , the latter can not handle structured representations .","label":"Background","metadata":{},"score":"64.62973"}
{"text":"Experimental results indicate that global methods outperform the greedy approach when relational supervision is limited , while their benefits diminish as more pairwise constraints are provided .ML ID : 144 .The development of natural language interfaces ( NLI 's ) for databases has been a challenging problem in natural language processing ( NLP ) since the 1970 's .","label":"Background","metadata":{},"score":"65.009834"}
{"text":"ML ID : 291 .We present a holistic data - driven technique that generates natural - language descriptions for videos .We combine the output of state - of - the - art object and activity detectors with ' ' real - world ' ' knowledge to select the most probable subject - verb - object triplet for describing a video .","label":"Background","metadata":{},"score":"65.37004"}
{"text":"However , they all assume that the model 's structure ( set of logical clauses ) is given , and only learn the model 's parameters .However , the input structure is usually incomplete , so it should also be updated .","label":"Background","metadata":{},"score":"65.46663"}
{"text":"It involves learning uncertain common sense knowledge in the form of probabilistic first - order rules by mining a large corpus of automatically extracted facts using an existing rule learner .These rules are then used to derive additional facts from extracted information using BLP inference .","label":"Background","metadata":{},"score":"65.48715"}
{"text":"Such methods could offer valuable support for theoretical research on conceptual representation .However , existing methods do not target the full range of concept - relation - feature triples occurring in human - generated norms ( e.g. flute produce sound ) but rather focus on concept - feature pairs ( e.g. flute - sound ) or triples involving specific relations only ( e.g. is - a or part - of relations ) .","label":"Background","metadata":{},"score":"65.541245"}
{"text":"Many real - world problems involve data that both have complex structures and uncertainty .Statistical relational learning ( SRL ) is an emerging area of research that addresses the problem of learning from these noisy structured / relational data .Markov logic networks ( MLNs ) , sets of weighted first - order logic formulae , are a simple but powerful SRL formalism that generalizes both first - order logic and Markov networks .","label":"Background","metadata":{},"score":"65.77073"}
{"text":"In addition , there are a few recent attempts to combine both representations either on the logic side ( still , not a graded representation ) , or in the distribution side(not full logic ) .We propose using probabilistic logic to represent natural language semantics combining the expressivity and the automated inference of logic , and the gradedness of distributional representations .","label":"Background","metadata":{},"score":"65.812614"}
{"text":"In addition , there are a few recent attempts to combine both representations either on the logic side ( still , not a graded representation ) , or in the distribution side(not full logic ) .We propose using probabilistic logic to represent natural language semantics combining the expressivity and the automated inference of logic , and the gradedness of distributional representations .","label":"Background","metadata":{},"score":"65.812614"}
{"text":"Scripts represent knowledge of stereotypical event sequences that can aid text understanding .Initial statistical methods have been developed to learn probabilistic scripts from raw text corpora ; however , they utilize a very impoverished representation of events , consisting of a verb and one dependent argument .","label":"Background","metadata":{},"score":"66.309296"}
{"text":"Scripts represent knowledge of stereotypical event sequences that can aid text understanding .Initial statistical methods have been developed to learn probabilistic scripts from raw text corpora ; however , they utilize a very impoverished representation of events , consisting of a verb and one dependent argument .","label":"Background","metadata":{},"score":"66.309296"}
{"text":"Shem Ochuodho successfully completed a D.Phil ., partly under my supervision , in which he developed both a new data model and a new process model for supporting configurations management , with particular applications to telecoms software .Computing Presuppositions in an Incremental Natural Language Processing System .","label":"Background","metadata":{},"score":"66.53502"}
{"text":"I won funding from Enterprise Ireland for this Strategic Research Project , with industrial support from Interactive Multimedia Systems ( IMS ) .The project employed Alex Ferguson .We defined a new way of combining similarity measures [ Ferguson & Bridge 1999b ] and we investigated the range of ways in which users can interact with case - retrieval systems [ Ferguson & Bridge 2000c ] .","label":"Background","metadata":{},"score":"66.73412"}
{"text":"Markov logic networks ( MLNs ) are an expressive representation for statistical relational learning that generalizes both first - order logic and graphical models .Existing discriminative weight learning methods for MLNs all try to learn weights that optimize the Conditional Log Likelihood ( CLL ) of the training examples .","label":"Background","metadata":{},"score":"66.7753"}
{"text":"ML ID : 203 .Bottom - Up Learning of Markov Logic Network Structure [ Details ] [ PDF ] Lilyana Mihalkova and Raymond J. Mooney In Proceedings of 24th International Conference on Machine Learning ( ICML-2007 ) , Corvallis , OR , June 2007 .","label":"Background","metadata":{},"score":"66.784454"}
{"text":"Plan recognition is the task of predicting an agent 's top - level plans based on its observed actions .It is an abductive reasoning task that involves inferring cause from effect .In the first part of the dissertation , we develop an approach to abductive plan recognition using BLPs .","label":"Background","metadata":{},"score":"66.833015"}
{"text":"So it has been argued that the two are complementary .In this paper , we adopt a hybrid approach that combines logic - based and distributional semantics through probabilistic logic inference in Markov Logic Networks ( MLNs ) .We focus on textual entailment ( RTE ) , a task that can utilize the strengths of both representations .","label":"Background","metadata":{},"score":"67.0522"}
{"text":"Alan Wood and I won funding under the U.K. Department of Trade and Industry / Engineering and Physical Sciences Research Council 's Architectures for Integrated Knowledge - Manipulation Systems ( AIKMS ) programme .The industrial partner was Transtech Parallel Systems .","label":"Background","metadata":{},"score":"67.059265"}
{"text":"Learning for Collective Information Extraction [ Details ] [ PDF ] Razvan C. Bunescu Technical Report TR-05 - 02 , Department of Computer Sciences , University of Texas at Austin , October 2005 .Ph.D. proposal .An Information Extraction ( IE ) system analyses a set of documents with the aim of identifying certain types of entities and relations between them .","label":"Background","metadata":{},"score":"67.409424"}
{"text":"Since BLPs employ logical deduction to construct the net- works , they can not be used effectively for plan recognition .Therefore , we extend BLPs to use logical abduction to construct Bayesian networks and call the result- ing model Bayesian Abductive Logic Programs ( BALPs ) .","label":"Background","metadata":{},"score":"67.56024"}
{"text":"ML ID : 305 .This paper integrates techniques in natural language processing and computer vision to improve recognition and description of entities and activities in real - world videos .We propose a strategy for generating textual descriptions of videos by using a factor graph to combine visual detections with language statistics .","label":"Background","metadata":{},"score":"67.688286"}
{"text":"ML ID : 305 .This paper integrates techniques in natural language processing and computer vision to improve recognition and description of entities and activities in real - world videos .We propose a strategy for generating textual descriptions of videos by using a factor graph to combine visual detections with language statistics .","label":"Background","metadata":{},"score":"67.688286"}
{"text":"English Slot Filling ( SF ) task .The UT Austin system builds upon the output of an existing relation extractor by augmenting relations that are explicitly stated in the text with ones that are inferred from the stated relations using probabilistic rules that encode commonsense world knowledge .","label":"Background","metadata":{},"score":"67.82339"}
{"text":"English Slot Filling ( SF ) task .The UT Austin system builds upon the output of an existing relation extractor by augmenting relations that are explicitly stated in the text with ones that are inferred from the stated relations using probabilistic rules that encode commonsense world knowledge .","label":"Background","metadata":{},"score":"67.82339"}
{"text":"English Slot Filling ( SF ) task .The UT Austin system builds upon the output of an existing relation extractor by augmenting relations that are explicitly stated in the text with ones that are inferred from the stated relations using probabilistic rules that encode commonsense world knowledge .","label":"Background","metadata":{},"score":"67.82339"}
{"text":"English Slot Filling ( SF ) task .The UT Austin system builds upon the output of an existing relation extractor by augmenting relations that are explicitly stated in the text with ones that are inferred from the stated relations using probabilistic rules that encode commonsense world knowledge .","label":"Background","metadata":{},"score":"67.82339"}
{"text":"By only observing how humans follow navigation instructions , the system was able to infer the corresponding hidden navigation plans and parse previously unseen instructions in new environments for both English and Chinese data .With the rise in popularity of crowdsourcing , we also present results on collecting additional training data using Amazon 's Mechanical Turk .","label":"Background","metadata":{},"score":"68.16923"}
{"text":"Arguably the most advanced approach to abduction , especially for natural language processing , is weighted abduction , which uses logical formulas with costs to guide inference .But it has no clear probabilistic semantics .In this paper we propose an approach that implements weighted abduction in Markov logic , which uses weighted first - order formulas to represent probabilistic knowledge , pointing toward a sound probabilistic semantics for weighted abduction .","label":"Background","metadata":{},"score":"68.31273"}
{"text":"We represent natural language semantics by combining logical and distributional information in probabilistic logic .We use Markov Logic Networks ( MLN ) for the RTE task , and Probabilistic Soft Logic ( PSL ) for the STS task .The system is evaluated on the SICK dataset .","label":"Background","metadata":{},"score":"68.470436"}
{"text":"We represent natural language semantics by combining logical and distributional information in probabilistic logic .We use Markov Logic Networks ( MLN ) for the RTE task , and Probabilistic Soft Logic ( PSL ) for the STS task .The system is evaluated on the SICK dataset .","label":"Background","metadata":{},"score":"68.470436"}
{"text":"We represent natural language semantics by combining logical and distributional information in probabilistic logic .We use Markov Logic Networks ( MLN ) for the RTE task , and Probabilistic Soft Logic ( PSL ) for the STS task .The system is evaluated on the SICK dataset .","label":"Background","metadata":{},"score":"68.470436"}
{"text":"ML ID : 238 .Learning with Markov Logic Networks : Transfer Learning , Structure Learning , and an Application to Web Query Disambiguation [ Details ] [ PDF ] Lilyana Mihalkova PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2009 .","label":"Background","metadata":{},"score":"68.49866"}
{"text":"Bayesian Logic Programs ( BLPs ) , which integrate both first - order logic and Bayesian networks are a powerful SRL formalism developed in the recent past .In this dissertation , we develop approaches using BLPs to solve two real world tasks -- plan recognition and machine reading .","label":"Background","metadata":{},"score":"68.7583"}
{"text":"First - order logic provides a powerful and flexible mechanism for representing natural language semantics .However , it is an open question of how best to integrate it with uncertain , weighted knowledge , for example regarding word meaning .This paper describes a mapping between predicates of logical form and points in a vector space .","label":"Background","metadata":{},"score":"68.89281"}
{"text":"First - order logic provides a powerful and flexible mechanism for representing natural language semantics .However , it is an open question of how best to integrate it with uncertain , weighted knowledge , for example regarding word meaning .This paper describes a mapping between predicates of logical form and points in a vector space .","label":"Background","metadata":{},"score":"68.89281"}
{"text":"First - order logic provides a powerful and flexible mechanism for representing natural language semantics .However , it is an open question of how best to integrate it with uncertain , weighted knowledge , for example regarding word meaning .This paper describes a mapping between predicates of logical form and points in a vector space .","label":"Background","metadata":{},"score":"68.89281"}
{"text":"Statistical relational learning ( SRL ) is an emerging area of research that addresses the problem of learning from noisy structured / relational data .Markov logic networks ( MLNs ) , sets of weighted clauses , are a simple but powerful SRL formalism that combines the expressivity of first - order logic with the flexibility of probabilistic reasoning .","label":"Background","metadata":{},"score":"68.92027"}
{"text":"2006 ] .Feature - Based and Feature - Free Textual CBR for Spam Filtering .Sarah Jane Delany and I investigated textual Case - Based Reasoning ( CBR ) for spam filtering .We compared a feature - based approach that Sarah Jane had developed in her Ph.D. research with a feature - free approach , that used text compression in its similarity measure .","label":"Background","metadata":{},"score":"68.93234"}
{"text":"Most information extraction ( IE ) systems identify facts that are explicitly stated in text .However , in natural language , some facts are implicit , and identifying them requires \" reading between the lines \" .Human readers naturally use common sense knowledge to infer such implicit information from the explicitly stated facts .","label":"Background","metadata":{},"score":"68.97356"}
{"text":"Several real world tasks involve data that is uncertain and relational in nature .Traditional approaches like first - order logic and probabilistic models either deal with structured data or uncertainty , but not both .To address these limitations , statistical relational learning ( SRL ) , a new area in machine learning integrating both first - order logic and probabilistic graphical models , has emerged in the recent past .","label":"Background","metadata":{},"score":"69.55165"}
{"text":"ML ID : 315 .Solving the visual symbol grounding problem has long been a goal of artificial intelligence .The field appears to be advancing closer to this goal with recent breakthroughs in deep learning for natural language grounding in static images .","label":"Background","metadata":{},"score":"69.55603"}
{"text":"We present the results of one of the largest linguistic data collection efforts to date using Mechanical Turk , yielding 85 K English sentences and more than 1k sentences for each of a dozen more languages .ML ID : 265 .","label":"Background","metadata":{},"score":"69.65256"}
{"text":"Natural Language Processing is a broad area that includes various approaches to building computational systems that understand and generate language , as well as categorization and analysis of text documents , and cognitive models of human language processing .Learning Statistical Scripts with LSTM Recurrent Neural Networks [ Details ] [ PDF ] Karl Pichotta and Raymond J. Mooney To Appear In Proceedings of the 30th AAAI Conference on Artificial Intelligence ( AAAI-16 ) , Phoenix , Arizona , February 2016 .","label":"Background","metadata":{},"score":"69.71271"}
{"text":"But practical probabilistic logic frameworks usually assume a finite domain in which each entity corresponds to a constant in the logic ( domain closure assumption ) .They also assume a closed world where everything has a very low prior probability .","label":"Background","metadata":{},"score":"69.72493"}
{"text":"But practical probabilistic logic frameworks usually assume a finite domain in which each entity corresponds to a constant in the logic ( domain closure assumption ) .They also assume a closed world where everything has a very low prior probability .","label":"Background","metadata":{},"score":"69.72493"}
{"text":"ML ID : 304 .Using Markov logic to integrate logical and distributional information in natural - language semantics results in complex inference problems involving long , complicated formulae .Current inference methods for Markov logic are ineffective on such problems .","label":"Background","metadata":{},"score":"69.93367"}
{"text":"ML ID : 304 .Using Markov logic to integrate logical and distributional information in natural - language semantics results in complex inference problems involving long , complicated formulae .Current inference methods for Markov logic are ineffective on such problems .","label":"Background","metadata":{},"score":"69.93367"}
{"text":"Active Multitask Learning Using Both Latent and Supervised Shared Topics [ Details ] [ PDF ] [ Slides ] Ayan Acharya and Raymond J. Mooney and Joydeep Ghosh In Proceedings of the 2014 SIAM International Conference on Data Mining ( SDM14 ) , Philadelphia , Pennsylvania , April 2014 .","label":"Background","metadata":{},"score":"69.94668"}
{"text":"Andy Dearden , Michael Harrison and I received funding from British Telecom to investigate the applicability of knowledge - based systems , especially those that use Case - Based Reasoning , to British Telecom help desk functions [ Bridge & Dearden 1992a , Dearden & Bridge 1993 ] .","label":"Background","metadata":{},"score":"70.03979"}
{"text":"Max - Margin Weight Learning for Markov Logic Networks [ Details ] [ PDF ] Tuyen N. Huynh and Raymond J. Mooney In Proceedings of the International Workshop on Statistical Relational Learning ( SRL-09 ) , Leuven , Belgium , July 2009 .","label":"Background","metadata":{},"score":"70.58894"}
{"text":"Bayesian Logic Programs for Plan Recognition and Machine Reading [ Details ] [ PDF ] [ Slides ] Sindhu Raghavan PhD Thesis , Department of Computer Science , University of Texas at Austin , December 2012 .Several real world tasks involve data that is uncertain and relational in nature .","label":"Background","metadata":{},"score":"70.71813"}
{"text":"ML ID : 317 .Representing Meaning with a Combination of Logical Form and Vectors [ Details ] [ PDF ] Islam Beltagy and Stephen Roller and Pengxiang Cheng and Katrin Erk and Raymond J. Mooney arXiv preprint arXiv:1505.06816 [ cs .","label":"Background","metadata":{},"score":"70.94849"}
{"text":"As a result , they are widely used in domains like social network analysis , biological data analysis , and natural language processing .Bayesian Logic Programs ( BLPs ) , which integrate both first - order logic and Bayesian networks are a powerful SRL formalism developed in the recent past .","label":"Background","metadata":{},"score":"70.94916"}
{"text":"Our polyglot ranking approach integrates frequency statistics from translated corpora in 50 different languages .Our experimental evaluation demonstrates that combining statistical evidence from many parallel corpora using a novel ranking - oriented boosting algorithm produces a comprehensive set of English phrasal verbs , achieving performance comparable to a human - curated set .","label":"Background","metadata":{},"score":"70.95835"}
{"text":"Our polyglot ranking approach integrates frequency statistics from translated corpora in 50 different languages .Our experimental evaluation demonstrates that combining statistical evidence from many parallel corpora using a novel ranking - oriented boosting algorithm produces a comprehensive set of English phrasal verbs , achieving performance comparable to a human - curated set .","label":"Background","metadata":{},"score":"70.95835"}
{"text":"An advantage of using probabilistic logic is that more rules can be added from more resources easily by mapping them to logical rules and weighting them appropriately .The last component is the inference , where we solve the probabilistic logic inference problem using an appropriate probabilistic logic tool like Markov Logic Network ( MLN ) , or Probabilistic Soft Logic ( PSL ) .","label":"Background","metadata":{},"score":"71.25134"}
{"text":"An advantage of using probabilistic logic is that more rules can be added from more resources easily by mapping them to logical rules and weighting them appropriately .The last component is the inference , where we solve the probabilistic logic inference problem using an appropriate probabilistic logic tool like Markov Logic Network ( MLN ) , or Probabilistic Soft Logic ( PSL ) .","label":"Background","metadata":{},"score":"71.25134"}
{"text":"An advantage of using probabilistic logic is that more rules can be added from more resources easily by mapping them to logical rules and weighting them appropriately .The last component is the inference , where we solve the probabilistic logic inference problem using an appropriate probabilistic logic tool like Markov Logic Network ( MLN ) , or Probabilistic Soft Logic ( PSL ) .","label":"Background","metadata":{},"score":"71.25134"}
{"text":"Doing RTE and STS better is an indication of a better semantic understanding .Our system has three main components , 1 .Parsing and Task Representation , 2 .Knowledge Base Construction , and 3 .Inference The input natural sentences of the RTE / STS task are mapped to logical form using Boxer which is a rule based system built on top of a CCG parser , then they are used to formulate the RTE / STS problem in probabilistic logic .","label":"Background","metadata":{},"score":"71.255356"}
{"text":"Doing RTE and STS better is an indication of a better semantic understanding .Our system has three main components , 1 .Parsing and Task Representation , 2 .Knowledge Base Construction , and 3 .Inference The input natural sentences of the RTE / STS task are mapped to logical form using Boxer which is a rule based system built on top of a CCG parser , then they are used to formulate the RTE / STS problem in probabilistic logic .","label":"Background","metadata":{},"score":"71.255356"}
{"text":"Most work on weakly - supervised learning for part - of - speech taggers has been based on unrealistic assumptions about the amount and quality of training data .For this paper , we attempt to create true low - resource scenarios by allowing a linguist just two hours to annotate data and evaluating on the languages Kinyarwanda and Malagasy .","label":"Background","metadata":{},"score":"71.29466"}
{"text":"Most work on weakly - supervised learning for part - of - speech taggers has been based on unrealistic assumptions about the amount and quality of training data .For this paper , we attempt to create true low - resource scenarios by allowing a linguist just two hours to annotate data and evaluating on the languages Kinyarwanda and Malagasy .","label":"Background","metadata":{},"score":"71.29466"}
{"text":"It involves learning uncertain commonsense knowledge ( in the form of probabilistic first - order rules ) from natural language text by mining a large corpus of automatically extracted facts .These rules are then used to derive additional facts from extracted information using BLP inference .","label":"Background","metadata":{},"score":"71.569"}
{"text":"S12 - 1044 [ bib ] : James Paul White UWashington : Negation Resolution using Machine Learning Methods .S12 - 1045 [ bib ] : Md.Faisal Mahbub Chowdhury FBK : Exploiting Phrasal and Contextual Clues for Negation Scope Detection .","label":"Background","metadata":{},"score":"71.791275"}
{"text":"ML ID : 313 .Transcribing documents from the printing press era , a challenge in its own right , is more complicated when documents interleave multiple languages - a common feature of 16th century texts .Additionally , many of these documents precede consistent orthographic conventions , making the task even harder .","label":"Background","metadata":{},"score":"71.83455"}
{"text":"Our experimental evaluation proves that Stacking is useful for ensembling SF systems .We demonstrate new state - of - the - art results for KBP ESF task .Our proposed system achieves an F1 score of 47 .Given the complexity of developing Slot Filling systems from scratch , our promising results indicate that performance on Slot Filling tasks can be increased by ensembling existing systems in shorter timeframe .","label":"Background","metadata":{},"score":"72.59589"}
{"text":"ML ID : 257 .Most of the existing weight - learning algorithms for Markov Logic Networks ( MLNs ) use batch training which becomes computationally expensive and even infeasible for very large datasets since the training examples may not fit in main memory .","label":"Background","metadata":{},"score":"73.06885"}
{"text":"Later Dr. Christine Solnon and I generalised the work : we used ant algorithms for solving a whole class of problems that we refer to as ' subset selection problems ' [ Solnon & Bridge 2006 ] .This class includes constraint satisfaction problems but also maximum clique problems and multi - dimensional knapsack problems .","label":"Background","metadata":{},"score":"73.80952"}
{"text":"The smart suggestions idea is implemented in a family of systems , which we call GhostWriter systems .Information Recommendation .I worked with Francesco Ricci on advice - giving in conversational recommender systems .We have shown how such a system can infer some of its user 's preferences by observing the user 's queries , and then give advice about next possible actions based on what it has inferred .","label":"Background","metadata":{},"score":"73.94649"}
{"text":"Using natural language to write programs is a touchstone problem for computational linguistics .We present an approach that learns to map natural - language descriptions of simple \" if - then \" rules to executable code .By training and testing on a large corpus of naturally - occurring programs ( called \" recipes \" ) and their natural language descriptions , we demonstrate the ability to effectively map language to code .","label":"Background","metadata":{},"score":"74.361404"}
{"text":"Instead , we use distributional semantics to generate only the relevant part of an on - the - fly ontology .Sentences and the on - the - fly ontology are represented in probabilistic logic .For inference , we use probabilistic logic frameworks like Markov Logic Networks ( MLN ) and Probabilistic Soft Logic ( PSL ) .","label":"Background","metadata":{},"score":"74.62473"}
{"text":"Natural Language Semantics using Probabilistic Logic [ Details ] [ PDF ] [ Slides ] Islam Beltagy October 2014 .PhD proposal , Department of Computer Science , The University of Texas at Austin .With better natural language semantic representations , computers can do more applications more efficiently as a result of better understanding of natural text .","label":"Background","metadata":{},"score":"74.752335"}
{"text":"Natural Language Semantics using Probabilistic Logic [ Details ] [ PDF ] [ Slides ] Islam Beltagy October 2014 .PhD proposal , Department of Computer Science , The University of Texas at Austin .With better natural language semantic representations , computers can do more applications more efficiently as a result of better understanding of natural text .","label":"Background","metadata":{},"score":"74.752335"}
{"text":"Markov logic networks ( MLNs ) are a recently - developed SRL model that consists of weighted first - order clauses .MLNs can be viewed as templates that define Markov networks when provided with the set of constants present in a domain .","label":"Background","metadata":{},"score":"75.00772"}
{"text":"ML ID : 305 .Using Markov logic to integrate logical and distributional information in natural - language semantics results in complex inference problems involving long , complicated formulae .Current inference methods for Markov logic are ineffective on such problems .","label":"Background","metadata":{},"score":"75.096954"}
{"text":"Understanding natural language presents many challenging problems that lend themselves to statistical relational learning ( SRL ) .Historically , both logical and probabilistic methods have found wide application in natural language processing ( NLP ) .NLP inevitably involves reasoning about an arbitrary number of entities ( people , places , and things ) that have an unbounded set of complex relationships between them .","label":"Background","metadata":{},"score":"75.12341"}
{"text":"The system does not use any prior language knowledge and was able to learn to sportscast in both English and Korean .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans .","label":"Background","metadata":{},"score":"75.18523"}
{"text":"The attributes used were split into two categories : color attributes and other attributes .Our proposed model was found to be statistically significantly more accurate than the vision system alone for both sets of attributes .ML ID : 302 .","label":"Background","metadata":{},"score":"75.39519"}
{"text":"The attributes used were split into two categories : color attributes and other attributes .Our proposed model was found to be statistically significantly more accurate than the vision system alone for both sets of attributes .ML ID : 302 .","label":"Background","metadata":{},"score":"75.39519"}
{"text":"Experiments show the potential of the approach .ML ID : 301 .Probabilistic Soft Logic ( PSL ) is a recently developed framework for probabilistic logic .We use PSL to combine logical and distributional representations of natural - language meaning , where distributional information is represented in the form of weighted inference rules .","label":"Background","metadata":{},"score":"75.633606"}
{"text":"Since BLPs employ logical deduction to construct the networks , they can not be used effectively for plan recognition as is .Therefore , we extend BLPs to use logical abduction to construct Bayesian networks and call the resulting model Bayesian Abductive Logic Programs ( BALPs ) .","label":"Background","metadata":{},"score":"76.123245"}
{"text":"The method involves extracting candidate triples consisting of concepts , relations and features ( e.g. deer have antlers , flute produce sound ) from corpus data parsed for grammatical dependencies , and re - weighting the triples on the .The automatic approach is cost - effective and can gather large - scale frequency data from textual corpora .","label":"Background","metadata":{},"score":"76.16408"}
{"text":"Like BLPs , BALPs also combine first - order logic and Bayesian networks .However , unlike BLPs that use logical deduction to construct Bayes nets , BALPs employ logical abduction .As a result , BALPs are more suited for solving problems like plan / activity recognition and diagnosis that require abductive reasoning .","label":"Background","metadata":{},"score":"77.28642"}
{"text":"Hard constraints are represented as formulas with infinite weight .The theory is compiled into a ground Markov network over which probabilistic inference can be done .For many problems , hard constraints pose a significant challenge to the probabilistic inference engine .","label":"Background","metadata":{},"score":"77.804504"}
{"text":"Funded by the University of York , with support from the UK Department of Social Security , Michael Hirst and I applied Case - Based Reasoning ( CBR ) techniques to Department of Social Security Disability Living Allowance data .Early results showed CBR better predicting mobility awards than care awards .","label":"Background","metadata":{},"score":"78.7113"}
{"text":"ML ID : 202 .Statistical Relational Learning for Natural Language Information Extraction [ Details ] [ PDF ] Razvan Bunescu and Raymond J. Mooney In L. Getoor and B. Taskar , editors , Introduction to Statistical Relational Learning , 535 - 552 , Cambridge , MA , 2007 .","label":"Background","metadata":{},"score":"78.88787"}
{"text":"Statistical Script Learning with Recurrent Neural Nets [ Details ] [ PDF ] [ Slides ] Karl Pichotta December 2015 .PhD proposal , Department of Computer Science , The University of Texas at Austin .Statistical Scripts are probabilistic models of sequences of events .","label":"Background","metadata":{},"score":"79.90138"}
{"text":"ML ID : 301 .Probabilistic Soft Logic ( PSL ) is a recently developed framework for probabilistic logic .We use PSL to combine logical and distributional representations of natural - language meaning , where distributional information is represented in the form of weighted inference rules .","label":"Background","metadata":{},"score":"80.35617"}
{"text":"ML ID : 301 .Probabilistic Soft Logic ( PSL ) is a recently developed framework for probabilistic logic .We use PSL to combine logical and distributional representations of natural - language meaning , where distributional information is represented in the form of weighted inference rules .","label":"Background","metadata":{},"score":"80.35617"}
{"text":"Finally , we propose investigating the interface between models of event co - occurrence and coreference resolution , in particular by integrating script information into general coreference systems .ML ID : 326 .Natural Language Video Description using Deep Recurrent Neural Networks [ Details ] [ PDF ] [ Slides ] Subhashini Venugopalan November 2015 .","label":"Background","metadata":{},"score":"80.77141"}
{"text":"Grounded Language Learning Models for Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joo Hyun Kim PhD Thesis , Department of Computer Science , University of Texas at Austin , December 2013 .Communicating with natural language interfaces is a long - standing , ultimate goal for artificial intelligence ( AI ) agents to pursue , eventually .","label":"Background","metadata":{},"score":"81.16931"}
{"text":"Grounded Language Learning Models for Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joo Hyun Kim PhD Thesis , Department of Computer Science , University of Texas at Austin , December 2013 .Communicating with natural language interfaces is a long - standing , ultimate goal for artificial intelligence ( AI ) agents to pursue , eventually .","label":"Background","metadata":{},"score":"81.16931"}
{"text":"Using these models , natural language systems will be able to infer a more comprehensive semantic relations , which in turn may yield improved systems for question answering , text classification , machine translation , and information retrieval .ML ID : 309 .","label":"Background","metadata":{},"score":"87.0948"}
{"text":"The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .Publisher conditions are provided by RoMEO .Differing provisions from the publisher 's actual policy or licence agreement may be applicable .","label":"Background","metadata":{},"score":"106.46159"}
{"text":"The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .Publisher conditions are provided by RoMEO .Differing provisions from the publisher 's actual policy or licence agreement may be applicable .","label":"Background","metadata":{},"score":"106.46159"}
