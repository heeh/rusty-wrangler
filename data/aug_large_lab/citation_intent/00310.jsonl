{"text":"The focus is on aggressive dimensionality reduction .Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , ... \" .This paper is a comparative study of feature selection methods in statistical learning of text categorization .","label":"Background","metadata":{},"score":"24.89016"}
{"text":"The focus is on aggressive dimensionality reduction .Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , ... \" .This paper is a comparative study of feature selection methods in statistical learning of text categorization .","label":"Background","metadata":{},"score":"24.89016"}
{"text":"The focus is on aggressive dimensionality reduction .Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , ... \" .This paper is a comparative study of feature selection methods in statistical learning of text categorization .","label":"Background","metadata":{},"score":"24.89016"}
{"text":"The focus is on aggressive dimensionality reduction .Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , ... \" .This paper is a comparative study of feature selection methods in statistical learning of text categorization .","label":"Background","metadata":{},"score":"24.89016"}
{"text":"Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , ... \" .This paper is a comparative study of feature selection methods in statistical learning of text categorization .","label":"Background","metadata":{},"score":"26.051792"}
{"text":"We will discuss in detail issues pertaining to three different problems , namely document representation , classifier construction , and classifier evaluation . \" ...This paper is a comparative study of feature selection methods in statistical learning of text categorization .","label":"Background","metadata":{},"score":"31.224846"}
{"text":"Traditionally in text categorization , the same scoring or ranking criterion is adopted for all target dimensionalities , which considers both the discriminability and the coverage of a term , such as χ 2 or IG .In this paper , the poor accuracy at a low dimensionality is imputed to the small average vector length of the documents .","label":"Background","metadata":{},"score":"35.512375"}
{"text":"In this thesis , we propose a text categorization model using an artificial neural network trained by the Backpropagation learning algorithm as the text classifier .Due to the high dimensionality of the feature space typical for textual data , scalability is poor if the neural network is trained using this high dimensional raw data .","label":"Background","metadata":{},"score":"35.549965"}
{"text":"The results showed that the proposed model was able to achieve high categorization effectiveness as measured by precision and recall .Among the four dimensionality reduction techniques proposed , Principal Component Analysis was found to be the most effective in reducing the dimensionality of the feature space .","label":"Background","metadata":{},"score":"35.685883"}
{"text":"This survey discusses the main approaches to text categorization that fall within the machine learning paradigm .We will discuss in detail issues pertaining to three different problems , namely document representation , classifier construction , and classifier evaluation . \" ...","label":"Background","metadata":{},"score":"35.975216"}
{"text":"This survey discusses the main approaches to text categorization that fall within the machine learning paradigm .We will discuss in detail issues pertaining to three different problems , namely document representation , classifier construction , and classifier evaluation . \" ...","label":"Background","metadata":{},"score":"35.975216"}
{"text":"Easily constructed combinations of feature selectors are shown to improve peak R - precision and F1 at statistically significant levels . ...did this term achieve a higher fraction of the total achieved score across all the terms ?We refer to this approach as DLOR ( divide by length then OR ) .","label":"Background","metadata":{},"score":"36.84268"}
{"text":"Thus , unlike some other unsupervised dimensionalityreduction techniques , such as Latent Semantic Indexing , we are able to compress the feature space much more aggressively , while still maintaining high document classification accuracy .We also show that less aggressive clustering sometimes results in improved classification accuracy over classification without clustering .","label":"Background","metadata":{},"score":"37.4971"}
{"text":"Thus , unlike some other unsupervised dimensionalityreduction techniques , such as Latent Semantic Indexing , we are able to compress the feature space much more aggressively , while still maintaining high document classification accuracy .We also show that less aggressive clustering sometimes results in improved classification accuracy over classification without clustering .","label":"Background","metadata":{},"score":"37.4971"}
{"text":"Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , a Ø 2 -test ( CHI ) , and term strength ( TS ) .","label":"Background","metadata":{},"score":"37.7443"}
{"text":"Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , a Ø 2 -test ( CHI ) , and term strength ( TS ) .","label":"Background","metadata":{},"score":"37.7443"}
{"text":"Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , a Ø 2 -test ( CHI ) , and term strength ( TS ) .","label":"Background","metadata":{},"score":"37.7443"}
{"text":"Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , a Ø 2 -test ( CHI ) , and term strength ( TS ) .","label":"Background","metadata":{},"score":"37.7443"}
{"text":"Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , a Ø 2 -test ( CHI ) , and term strength ( TS ) .","label":"Background","metadata":{},"score":"37.7443"}
{"text":"In : Proceedings of the 4th annual symposium on document analysis and information retrieval , pp 317 - 332 .Yang Y , Pedersen JP ( 1997 )A comparative study on feature selection in text categorization .In : Proceedings of the 14th international conference on machine learning , pp 412 - 420 .","label":"Background","metadata":{},"score":"38.54982"}
{"text":"Also , the results produced often contained improper word associations reflecting some spurious aspect of the training corpus that did not stand for true collocations .In this paper , we describe a set of techniques based on statistical methods for retrieving and identifying collocations from large textual corpora .","label":"Background","metadata":{},"score":"39.417683"}
{"text":"TS compares favorably with the other methods with up to 50 % vocabulary redu ... . ... in linear regression and nearest neighbor classification .Moulinier et al .[16 ] used an inductive learning algorithm to obtain features in disjunctive normal form for news story categorization .","label":"Background","metadata":{},"score":"39.744736"}
{"text":"TS compares favorably with the other methods with up to 50 % vocabulary redu ... . ... in linear regression and nearest neighbor classification .Moulinier et al .[16 ] used an inductive learning algorithm to obtain features in disjunctive normal form for news story categorization .","label":"Background","metadata":{},"score":"39.744736"}
{"text":"The first three of these techniques are domain dependent term selection methods , namely the DF method , the CF - DF method and the TFxIDF method .The fourth technique is a domain independent feature extraction method based on a statistical multivariate data analysis technique called Principal Component Analysk .","label":"Background","metadata":{},"score":"39.874077"}
{"text":"Abstract .The performance of two online linear classifiers - the Perceptron and Littlestone 's Winnow - is explored for two anti - spam filtering benchmark corpora - PU1 and Ling - Spam .We study the performance for varying numbers of features , along with three different feature selection methods : information gain ( IG ) , document frequency ( DF ) and odds ratio .","label":"Background","metadata":{},"score":"39.97865"}
{"text":"A task - oriented evaluation was conducted using Reuters and CNN news stories .We found agglomerative document clustering highly effective ( 82 % in the F 1 measure ) for retrospective event detection , and single - pass clustering with time windowing a better choice for on - line alerting of novel events .","label":"Background","metadata":{},"score":"40.224495"}
{"text":"We address the problem of finding a subset of features that allows a supervised induction algorithm to induce small high - accuracy concepts .We examine notions of relevance and irrelevance , and show that the definitions used in the machine learning literature do not adequately partition the features ... \" .","label":"Background","metadata":{},"score":"40.430344"}
{"text":"The features selected should depend not only on the features and the target concept , but also on the induction algorithm .We describe a method for feature subset selection using cross - validation that is applicable to any induction algorithm , and discuss experiments conducted with ID3 and C4.5 on artificial and real datasets . .","label":"Background","metadata":{},"score":"40.889137"}
{"text":"This paper is a comparative study of feature selection in drug discovery .The focus is on aggressive dimensionality reduction .Five methods were evaluated , including information gain , mutual information , a χ 2-test , odds ratio , and GSS coefficient .","label":"Background","metadata":{},"score":"41.12122"}
{"text":"Comparisons with an optimized version of the traditional Rocchio 's algorithm adapted for text categorization , as well as at neural network classifiers are provided .The results show that the use of the hierarchical structure improves text categorization performance with respect to an equivalent at model .","label":"Background","metadata":{},"score":"41.604134"}
{"text":"This paper also describes various limitations of current recommendation methods and discusses possible extensions that can improve recommendation capabilities and make recommender systems applicable to an even broader range of applications .These extensions include , among others , an improvement of understanding of users and items , incorporation of the contextual information into the recommendation process , support for multcriteria ratings , and a provision of more flexible and less intrusive types of recommendations . . ..","label":"Background","metadata":{},"score":"41.93592"}
{"text":"This paper also describes various limitations of current recommendation methods and discusses possible extensions that can improve recommendation capabilities and make recommender systems applicable to an even broader range of applications .These extensions include , among others , an improvement of understanding of users and items , incorporation of the contextual information into the recommendation process , support for multcriteria ratings , and a provision of more flexible and less intrusive types of recommendations . . ..","label":"Background","metadata":{},"score":"41.93592"}
{"text":"The removal of irrelevant and redundant information often improves the performance of learning algorithms .This paper is a comparative study of feature selection in drug discovery .The focus is on aggressive dimensiona ... \" .Feature selection is frequently used as a preprocessing step to machine learning .","label":"Background","metadata":{},"score":"43.04808"}
{"text":"CrossRef .[ 6 ] .Harris Drucker , Vladimir Vapnik , and Dongui Wu .Automatic text categorization and its applications to text retrieval .IEEE Transactions on Neural Networks , 10(5 ) , 1999 .[ 7 ] .Norbert Gövert , Mounia Lalmas , and Norbert Fuhr .","label":"Background","metadata":{},"score":"43.35263"}
{"text":"We examine notions of relevance and irrelevance , and show that the definitions used in the machine learning literature do not adequately partition the features into useful categories of relevance .We present definitions for irrelevance and for two degrees of relevance .","label":"Background","metadata":{},"score":"43.36084"}
{"text":"The method attains an accuracy of 82.8 % on the full test set , but the accuracy rises above 95 % when the algorithm is allowed to abstain from classifying mild words . \" ...This paper presents a simple unsupervised learning algorithm for recognizing synonyms , based on statistical data acquired by querying a Web search engine .","label":"Background","metadata":{},"score":"43.58474"}
{"text":"Several approaches have been proposed to retrieve various types of collocations from the analysis of large samples of textual data .These techniques automatically produce large numbers of collocations along with statistical figures intended to reflect the relevance of the associations .","label":"Background","metadata":{},"score":"43.746796"}
{"text":"Different dimensionalities are expected under different practical resource restrictions of time or space .Traditionally in text categorization , the same scoring or r ... \" .In text categorization , term selection is an important step for the sake of both categorization accuracy and computational efficiency .","label":"Background","metadata":{},"score":"43.884464"}
{"text":"K. Tzeras and S. Artman .Automatic indexing based on bayesian inference networks .In SIGIR 93 , pages 22 - 34 , 1993 .[19 ] . Y.Yang .An evaluation of statistical approaches to text categorization .Information Retrieval Journal , 1999 .","label":"Background","metadata":{},"score":"44.24276"}
{"text":"In the research community the dominant approach to this problem is based on machine learning techniques : a general inductive process automatically builds a classifier by learning , from a set of preclassified documents , the characteristics of the categories .The advantages of this approach over the knowledge engineering approach ( consisting in the manual definition of a classifier by domain experts ) are a very good effectiveness , considerable savings in terms of expert labor power , and straightforward portability to different domains .","label":"Background","metadata":{},"score":"44.275528"}
{"text":"Text categorization - the assignment of natural language texts to one or more predefined categories based on their content - is an important component in many information organization and management tasks .We compare the effectiveness of five different automatic learning algorithms for text categorization in terms of learning speed , realtime classification speed , and classification accuracy .","label":"Background","metadata":{},"score":"44.36567"}
{"text":"Results from a large investigation of these combinations are summarized .Easily constructed combinations of feature selectors are shown to improve peak R - precision and F1 at statistically significant levels .We introduce several methods of combining feature selectors for text classification .","label":"Background","metadata":{},"score":"44.559776"}
{"text":"The first is the introduction of a new image representation called the \" Integral Image \" which allows the features used by our detector to be computed very quickly .The second is a learning algorithm , based on AdaBoost , which selects a small number of critical visual features and yields extremely efficient classifiers [ 6].","label":"Background","metadata":{},"score":"44.715195"}
{"text":"To achieve the best possible performance with a particular learning algorithm on a particular training set , a ... \" .In the feature subset selection problem , a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention , while ignoring the rest .","label":"Background","metadata":{},"score":"44.96968"}
{"text":"As an alternative , some critics of the Katz - Fodor theory ( e.g. ( Johnson - Laird , 1983 ) ) have abandoned the treatment of selectional constraints as semantic , instead treating them as indistinguishable from inferences made on the basis of factual knowledge .","label":"Background","metadata":{},"score":"45.03062"}
{"text":"The feature named \" irrelevant \" is uniformly random , and the feature \" correlated \" matches the class label 75 % of the time .The left subtree is the co .. \" ...Text categorization algorithms usually represent documents as bags of words and consequently have to deal with huge numbers of features .","label":"Background","metadata":{},"score":"45.30359"}
{"text":"TS compares favorably with the other methods with up to 50 % vocabulary redu ... .A major characteristic , or difficulty , of text categorization problems is the high dimensionality of the feature space .The ... .We f ... \" .","label":"Background","metadata":{},"score":"45.722137"}
{"text":"this paper , we will describe a simple rule - based approach to automated learning of linguistic knowledge .This approach has been shown for a number of tasks to capture information in a clearer and more direct fashion without a compromise in performance .","label":"Background","metadata":{},"score":"46.081112"}
{"text":"A comparison of classifiers and document representations for the routing problem .In : Proceedings of the 18th ACM international conference on research and development in information retrieval , pp 229 - 237 .Wiener ED , Pedersen JO , Weigend AS ( 1995 )","label":"Background","metadata":{},"score":"46.185352"}
{"text":"This article introduces a method for inferring the semantic orientation of a word from its statistical association with a set of positive and negative paradigm words .Two instances of this approach are evaluated , based on two different statistical measures of word association : pointwise mutual information ( PMI ) and latent semantic analysis ( LSA ) .","label":"Background","metadata":{},"score":"46.211346"}
{"text":"Dagan I , Karov Y , Roth D ( 1997 ) Mistake - driven learning in text categorization .In : Proceedings of the 2nd conference on empirical methods in natural language processing , pp 55 - 63 .Ng HT , Goh WB , Low KL ( 1997 )","label":"Background","metadata":{},"score":"46.284378"}
{"text":"A study on mutual information - based feature selection for text categorization .Journal of Computational Information Systems , 3 ( 3 ) .pp .1007 - 1012 .ISSN 1553 - 9105 .Abstract .Feature selection plays an important role in text categorization .","label":"Background","metadata":{},"score":"46.32203"}
{"text":"A method of determining the similarity of nouns on the basis of a metric derived from the distribution of subject , verb and object in a large text corpus is described .The resulting quasi - semantic classification of nouns demonstrates the plausibility of the distributional hypothesis , and has potential application to a variety of tasks , including automatic indexing , resolving nominal compounds , and determining the scope of modification . \" ...","label":"Background","metadata":{},"score":"46.388954"}
{"text":"While the rich literature provides valuable information about individual methods , clear conclusions about crossmethod comparison have been d .. \" ...Text categorization - the assignment of natural language texts to one or more predefined categories based on their content - is an important component in many information organization and management tasks .","label":"Background","metadata":{},"score":"46.73266"}
{"text":"Very accurate text classifiers can be learned automatically from training examples .Linear Support Vector Machines ( SVMs ) are particularly promising because they are very accurate , quick to train , and quick to evaluate . 1.1Keywords Text categorization , classification , support vector machines , machine learning , information management . \" ... Abstract .","label":"Background","metadata":{},"score":"46.735313"}
{"text":"In : Proceedings of the 20th ACM international conference on research and development in information retrieval , pp 67 - 73 .Zhang T ( 2001 ) Regularized Winnow methods .Adv Neural Inf Process Syst 13:703 - 709 .Kivinen J , Warmuth MK , Auer P ( 1997 )","label":"Background","metadata":{},"score":"46.795433"}
{"text":".. 5 Given the transform used , this result is similar to what would be obtained by a mutual information analysis , a method for capturing word dependencies often used in computational linguistics ( e.g .. Because of the transform , this poor result is still better than that obtained by a gross correlation over raw co - occurrence frequencies , a statistic often assumed to be the way statistical extracti ... . \" ...","label":"Background","metadata":{},"score":"46.801285"}
{"text":"We present two extensions to the algorithm that improve ... . \" ...This work focuses on algorithms which learn from examples to perform multiclass text and speech categorization tasks .Our approach is based on a new and improved family of boosting algorithms .","label":"Background","metadata":{},"score":"47.006096"}
{"text":"We present two extensions to the algorithm that improve ... . \" ...This work focuses on algorithms which learn from examples to perform multiclass text and speech categorization tasks .Our approach is based on a new and improved family of boosting algorithms .","label":"Background","metadata":{},"score":"47.006096"}
{"text":"This work focuses on algorithms which learn from examples to perform multiclass text and speech categorization tasks .Our approach is based on a new and improved family of boosting algorithms .We describe in detail an implementation , called BoosTexter , of the new boosting algorithms for text categorization tasks .","label":"Background","metadata":{},"score":"47.02648"}
{"text":"This work focuses on algorithms which learn from examples to perform multiclass text and speech categorization tasks .Our approach is based on a new and improved family of boosting algorithms .We describe in detail an implementation , called BoosTexter , of the new boosting algorithms for text categorization tasks .","label":"Background","metadata":{},"score":"47.02648"}
{"text":"The first is the introduction of a new image representation called the \" Integral Image \" which allows the features ... \" .This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates .","label":"Background","metadata":{},"score":"47.125587"}
{"text":"It is also demonstrated that both of these online classifiers perform much better than a standard Naïve Bayes method .The theoretical and implementation computational complexity of these two classifiers are very low , and they are very easily adaptively updated .","label":"Background","metadata":{},"score":"47.131058"}
{"text":"This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents .This is important because in many text classification problems obtaining training labels is expensive , while large quantities of unlabeled documents are readily available .","label":"Background","metadata":{},"score":"47.252663"}
{"text":"This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents .This is important because in many text classification problems obtaining training labels is expensive , while large quantities of unlabeled documents are readily available .","label":"Background","metadata":{},"score":"47.252663"}
{"text":"The feature set size was reduced by 99 % , while losing only a few percent in terms of sensitivity ( from 58.7 % to 52.5 % ) and specificity ( from 98.4 % to 97.2 % ) .In contrast to information gain and χ 2-test , mutual information had relatively poor performance due to its bias toward favoring rare features and its sensitivity to probability estimation errors .","label":"Background","metadata":{},"score":"47.29901"}
{"text":"The automated categorization ( or classification ) of texts into predefined categories has witnessed a booming interest in the last ten years , due to the increased availability of documents in digital form and the ensuing need to organize them .In the research community the dominant approach to this problem is based on machine learning techniques : a general inductive process automatically builds a classifier by learning , from a set of preclassified documents , the characteristics of the categories .","label":"Background","metadata":{},"score":"47.395775"}
{"text":"The automated categorization ( or classification ) of texts into predefined categories has witnessed a booming interest in the last ten years , due to the increased availability of documents in digital form and the ensuing need to organize them .In the research community the dominant approach to this problem is based on machine learning techniques : a general inductive process automatically builds a classifier by learning , from a set of preclassified documents , the characteristics of the categories .","label":"Background","metadata":{},"score":"47.395775"}
{"text":"This approach clusters words into groups based on the distribution of class labels associated with each word .Thus , unlike some other unsupervised dimensionalityreduction techniques , such as Latent Sem ... \" .This paper describes the application of Distributional Clustering [ 20 ] to document classification .","label":"Background","metadata":{},"score":"47.476772"}
{"text":"This approach clusters words into groups based on the distribution of class labels associated with each word .Thus , unlike some other unsupervised dimensionalityreduction techniques , such as Latent Sem ... \" .This paper describes the application of Distributional Clustering [ 20 ] to document classification .","label":"Background","metadata":{},"score":"47.476772"}
{"text":"Discriminability and coverage are separately measured ; by adjusting the ratio of their weights in a combined criterion , the expected average vector length can be reached , which means a good compromise between the specificity and the exhaustivity of the term subset .","label":"Background","metadata":{},"score":"47.684864"}
{"text":"Using IG thresholding with a knearest neighbor classifier on the Reuters corpus , removal of up to 98 % removal of unique terms actually yielded an improved classification accuracy ( measured by average precision ) .DF thresholding performed similarly .Indeed we found strong correlations between the DF , IG and CHI values of a term .","label":"Background","metadata":{},"score":"47.754387"}
{"text":"Using IG thresholding with a knearest neighbor classifier on the Reuters corpus , removal of up to 98 % removal of unique terms actually yielded an improved classification accuracy ( measured by average precision ) .DF thresholding performed similarly .Indeed we found strong correlations between the DF , IG and CHI values of a term .","label":"Background","metadata":{},"score":"47.754387"}
{"text":"Using IG thresholding with a knearest neighbor classifier on the Reuters corpus , removal of up to 98 % removal of unique terms actually yielded an improved classification accuracy ( measured by average precision ) .DF thresholding performed similarly .Indeed we found strong correlations between the DF , IG and CHI values of a term .","label":"Background","metadata":{},"score":"47.754387"}
{"text":"Using IG thresholding with a knearest neighbor classifier on the Reuters corpus , removal of up to 98 % removal of unique terms actually yielded an improved classification accuracy ( measured by average precision ) .DF thresholding performed similarly .Indeed we found strong correlations between the DF , IG and CHI values of a term .","label":"Background","metadata":{},"score":"47.754387"}
{"text":"Using IG thresholding with a knearest neighbor classifier on the Reuters corpus , removal of up to 98 % removal of unique terms actually yielded an improved classification accuracy ( measured by average precision ) .DF thresholding performed similarly .Indeed we found strong correlations between the DF , IG and CHI values of a term .","label":"Background","metadata":{},"score":"47.754387"}
{"text":"TS compares favorably with the other methods with up to 50 % vocabulary redu ... . by Paul Viola , Michael Jones - International Journal of Computer Vision , 2001 . \" ...This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates .","label":"Background","metadata":{},"score":"48.01217"}
{"text":"Our algorithm is based on an extended version of Harris ' Distributional Hypothesis , which states that words that occurred in the same contexts tend to be similar .Instead of using this hypothesis on words , we apply it to paths in the dependency trees of a parsed corpus .","label":"Background","metadata":{},"score":"48.324097"}
{"text":"However , even in these extended formulations the problem of tuning its parameters is still neglected .In this paper , a study on parameters of the Rocchio text classifier has been carried out to achieve its maximal accuracy .The result is a model for the automatic selection of parameters .","label":"Background","metadata":{},"score":"48.32908"}
{"text":"The results showed that Naïve Bayesian benefited significantly from the feature selection , while SVM performed better when all features were used .In this experiment , information gain and χ 2-test were most effective feature selection methods .Using information gain with a Naïve Bayesian classifier , removal of up to 96 % of the features yielded an improved classification accuracy measured by sensitivity .","label":"Background","metadata":{},"score":"48.415318"}
{"text":"The interesting observations might inspire further investigations . ...o the sparseness problem .Everyone of them adopt a criterion scoring and ranking the terms ; for a target dimensionality d , the term selection is simply done by picking out the top - d t .. \" ...","label":"Background","metadata":{},"score":"48.514072"}
{"text":"We extended e ... \" .This paper studies the effective use of information retrieval and machine learning techniques in a new task , event detection and tracking .The objective is to automatically detect novel events from chronologically - ordered streams of news stories , and track events of interest over time .","label":"Background","metadata":{},"score":"48.63073"}
{"text":"We explore the relation between optimal feature subset selection and relevance .Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain .We study the strengths and weaknesses of the wrapper approach andshow a series of improved designs .","label":"Background","metadata":{},"score":"48.69742"}
{"text":"The automated categorization ( or classification ) of texts into predefined categories has witnessed a booming interest in the last ten years , due to the increased availability of documents in digital form and the ensuing need to organize them .In the research community the dominant approach to this p ... \" .","label":"Background","metadata":{},"score":"48.76026"}
{"text":"A new general theory of acquired similarity and knowledge representation , latent semantic analysis ( LS ... \" .How do people know as much as they do with as little information as they get ?The problem takes many forms ; learning vocabulary from text is an especially dramatic and convenient case for research .","label":"Background","metadata":{},"score":"48.862427"}
{"text":"We conclude by describing the application of our system to automatic call - type identification from unconstrained spoken customer responses . \" ...The Rocchio relevance feedback algorithm is one of the most popular and widely applied learning methods from information retrieval .","label":"Background","metadata":{},"score":"48.894165"}
{"text":"We conclude by describing the application of our system to automatic call - type identification from unconstrained spoken customer responses . \" ...The Rocchio relevance feedback algorithm is one of the most popular and widely applied learning methods from information retrieval .","label":"Background","metadata":{},"score":"48.894165"}
{"text":"Morgan Kaufmann , 1997 .[ 11 ] .Ron Kohavi and George H. John .Wrappers for feature subset selection .Artificial Intelligence , 97(1 - 2):273 - 324 , 1997 .MATH CrossRef .[ 12 ] .Wai Lam and Chao Y. Ho .","label":"Background","metadata":{},"score":"48.91137"}
{"text":"Both works attempted to automatically acquire true collocations from corpora .Our work builds on Choueka 's , and has been developed contemporarily to Church 's .Choueka , Klein , and Neuwitz ( 1983 ) pro ... . \" ...One of the main challenges in question - answering is the potential mismatch between the expressions in questions and the expressions in texts .","label":"Background","metadata":{},"score":"48.95131"}
{"text":"The algorithm achieves an average accuracy of 74 % when evaluated on 410 reviews from Epinions , sampled from four different domains ( reviews of automobiles , banks , movies , and travel destinations ) .The accuracy ranges from 84 % for automobile reviews to 66 % for movie reviews . .","label":"Background","metadata":{},"score":"49.135544"}
{"text":"This new system has been applied successfully to several tasks taken from the machine learning literature . \" ... this paper , we will describe a simple rule - based approach to automated learning of linguistic knowledge .This approach has been shown for a number of tasks to capture information in a clearer and more direct fashion without a compromise in performance .","label":"Background","metadata":{},"score":"49.445705"}
{"text":"Text categorization algorithms usually represent documents as bags of words and consequently have to deal with huge numbers of features .Most previous studies found that the majority of these features are relevant for classification , and that the performance of text categorization with support vector machines peaks when no feature selection is performed . \" ... Abstract .","label":"Background","metadata":{},"score":"49.60884"}
{"text":"This paper presents a simple unsupervised learning algorithm for recognizing synonyms , based on statistical data acquired by querying a Web search engine .The algorithm , called PMI - IR , uses Pointwise Mutual Information ( PMI ) and Information Retrieval ( IR ) to measure the similarity of pairs of words .","label":"Background","metadata":{},"score":"49.618225"}
{"text":"In Proceedings of SIGIR-98 , 1998 .[ 13 ] .G : Salton and C. Buckley .Term - weighting approaches in automatic text retrieval .Information Processing and Management , 24(5):513 - 523 , 1988 .CrossRef .[14 ] .","label":"Background","metadata":{},"score":"49.63452"}
{"text":"For indirect compararions , kNN , LLSF and WORD were used as baselines , since they were evaluated on all versions of Reuters that exclude the unlabelled documents .As a global observation , kNN , LLSF and a neural network method had the best performance ; except for a Naive Bayes approach , the other learning algorithms also performed relatively well . . ..","label":"Background","metadata":{},"score":"49.97208"}
{"text":"We employed several distinct features for each page : bag - of - words , page structure , abstract , titles , and entity mentions .We report high accuracies for several of the classifiers built .As a result of this work , a Web service that classifies any Wikipedia page has been made available to the academic community . by J. Scott Olsson - Proc . the 15th ACM international conference on Information and knowledge management , 2006 . \" ...","label":"Background","metadata":{},"score":"49.97995"}
{"text":"Liere R , Tadepalli P ( 1998 )Active learning with committees in text categorization : preliminary results in comparing winnow and perceptron .In : Learning for text categorization , technical report WS-98 - 05 .AAAI Press , Menlo Park .","label":"Background","metadata":{},"score":"50.01452"}
{"text":"& Maes 1995 ) .We will call this approach content - based filtering , as it does not rely on social information ( in the form of other users ' ratings ) .Both social and content - base ... . \" ...","label":"Background","metadata":{},"score":"50.133125"}
{"text":"& Maes 1995 ) .We will call this approach content - based filtering , as it does not rely on social information ( in the form of other users ' ratings ) .Both social and content - base ... . \" ...","label":"Background","metadata":{},"score":"50.133125"}
{"text":"We chose kNN for event tracking because , in addit ... . \" ...This paper presents the design and evaluation of a text categorization method based on the Hierarchical Mixture of Experts model .This model uses a divide and conquer principle to define smaller categorization problems based on a predefined hierarchical structure .","label":"Background","metadata":{},"score":"50.5828"}
{"text":"this article , we will investigate the performance of two recently implemented machine - learning algorithms on a number of large text categorization problems .The two algorithms considered are set - valued RIPPER , a recent rule - learning algorithm [ Cohen A earlier version of this article appeared in Proceedings of the 19th Annual International ACM Conference on Research and Development in Information Retrieval ( SIGIR ) pp .","label":"Background","metadata":{},"score":"50.850327"}
{"text":"The algorithm first trains a classifier using the available labeled documents , and probabilistically labels the unlabeled documents .It then trains a new classifier using the labels for all the documents , and iterates to convergence .This basic EM procedure works well when the data conform to the generative assumptions of the model .","label":"Background","metadata":{},"score":"51.10893"}
{"text":"The algorithm first trains a classifier using the available labeled documents , and probabilistically labels the unlabeled documents .It then trains a new classifier using the labels for all the documents , and iterates to convergence .This basic EM procedure works well when the data conform to the generative assumptions of the model .","label":"Background","metadata":{},"score":"51.10893"}
{"text":"Adequate representation of natural language semantics requires access to vast amounts of common sense and domain - specific world knowledge .Prior work in the field was based on purely statistical techniques that did not make use of background knowledge , on limited lexicographic knowledge bases such as WordNet , or on huge manual efforts such as the CYC project .","label":"Background","metadata":{},"score":"51.239777"}
{"text":"In Proceedings of CIKM-99 .[ 8 ] .David J. Ittner , David D. Lewis , and David D. Ahn .Text categorization of low quality images .In Proceedings of SDAIR-95 , pages 301 - 315 , Las Vegas , US , 1995 .","label":"Background","metadata":{},"score":"51.488914"}
{"text":"Boosting trees for anti - spam email filtering .In : Proceedings of European conference on recent advances in NLP , pp 58 - 64 .Lewis DD , Schapire RE , Callan JP , Papka R ( 1996 )Training algorithms for linear text classifiers .","label":"Background","metadata":{},"score":"51.65472"}
{"text":"A controlled study using three classifiers , kNN , LLSF and WORD , was conducted to examine th ... \" .Abstract .This paper focuses on a comparative evaluation of a wide - range of text categorization methods , including previously published results on the Reuters corpus and new results of additional experiments .","label":"Background","metadata":{},"score":"51.70016"}
{"text":"In this dissertation , I suggest that an answer to this question lies in the representation of conceptual . ... act useful relationships between words . by Peter D. Turney , Michael L. Littman - ACM Transactions on Information Systems , 2003 . \" ...","label":"Background","metadata":{},"score":"51.71613"}
{"text":"By inducing global knowledge indirectly from local co - occurrence data in a large body of representative text , LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren .LSA uses no prior linguistic or perceptual similarity knowledge ; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions ( e.g. , 300 ) to represent objects and contexts .","label":"Background","metadata":{},"score":"51.769264"}
{"text":"The analysis gives theoretical insight into the heuristics used in the ... \" .The Rocchio relevance feedback algorithm is one of the most popular and widely applied learning methods from information retrieval .Here , a probabilistic analysis of this algorithm is presented in a text categorization framework .","label":"Background","metadata":{},"score":"51.891697"}
{"text":"The analysis gives theoretical insight into the heuristics used in the ... \" .The Rocchio relevance feedback algorithm is one of the most popular and widely applied learning methods from information retrieval .Here , a probabilistic analysis of this algorithm is presented in a text categorization framework .","label":"Background","metadata":{},"score":"51.891697"}
{"text":"Rocchio J ( 1971 )Relevance feedback in information retrieval .In : The SMART retrieval system : experiments in automatic document processing , pp 313 - 323 .Prentice Hall Inc. , Englewood Cliffs .Rosenblatt E ( 1988 )The perceptron : a probabilistic model for information storage and organization in the brain .","label":"Background","metadata":{},"score":"52.22664"}
{"text":"The experimental results show that both the Perceptron and Winnow perform much better when using IG or DF than using odds ratio .It is further demonstrated that when using IG or DF , the classifiers are insensitive to the number of features and the number of training iterations , and not greatly sensitive to the size of training set .","label":"Background","metadata":{},"score":"52.492992"}
{"text":"Learned text categorization by backpropagation neural network .Text categorization is the classification of unstructured text documents with respect to a set of one or more pre - defined categories .This task is often performed in automatic text indexing systems to assign subject categories to text documents .","label":"Background","metadata":{},"score":"52.530655"}
{"text":"The space has been bound by giving a feature selection interpretation of the Rocchio parameters .The benefit of the approach has been assessed via extensive cross evaluation over three corpora in two languages .Comparative analysis shows that the performances achieved are relatively close to the best TC models ( e.g. Support Vector Machines ) .","label":"Background","metadata":{},"score":"52.588753"}
{"text":"We present a tree - structured architecture for supervised learning .The statistical model underlying the architecture is a hi - erarchical mixture model in which both the mixture coefficients and the mixture components are generalized linear models ( GLIM 's ) .","label":"Background","metadata":{},"score":"52.64811"}
{"text":"In the Nineth Text REtrieval Conference ( TREC-9 ) , Gaithersburg , Maryland , 2000 .[ 3 ] .Christopher Buckley and Gerald Salton .Optimization of relevance feedback weights .In Proceedings of SIGIR-95 , pages 351 - 357 , Seattle , US , 1995 .","label":"Background","metadata":{},"score":"52.656902"}
{"text":"A set of experiments in the domain of face detection are presented .The system yields face detection performace comparable to the best previous systems [ 18 , 13 , 16 , 12 , 1].Implemented on a conventional desktop , face detection proceeds at 15 frames per second . \" ... Abstract .","label":"Background","metadata":{},"score":"52.761337"}
{"text":"Next , it places agents in context , defines them and then goes on , inter alia , to overview critically the rationales , hypotheses , goals , challenges and state - of - the - art demonstrators of the various agent types in our typology .","label":"Background","metadata":{},"score":"52.787525"}
{"text":"Next , it places agents in context , defines them and then goes on , inter alia , to overview critically the rationales , hypotheses , goals , challenges and state - of - the - art demonstrators of the various agent types in our typology .","label":"Background","metadata":{},"score":"52.787525"}
{"text":"This paper presents an overview of the field of recommender systems and describes the current generation of recommendation methods that are usually classified into the following three main categories : content - based , collaborative , and hybrid recommendation approaches .This paper also describes vario ... \" .","label":"Background","metadata":{},"score":"52.792847"}
{"text":"This paper presents an overview of the field of recommender systems and describes the current generation of recommendation methods that are usually classified into the following three main categories : content - based , collaborative , and hybrid recommendation approaches .This paper also describes vario ... \" .","label":"Background","metadata":{},"score":"52.792847"}
{"text":"Experimental results on common multilabel domains involving protein , document and scene classification show that better performance can be achieved compared to popular multilabel classification approaches . ... t label .We then selected the top 500 features based on the their maximum rank over all labels . 4.2","label":"Background","metadata":{},"score":"52.928215"}
{"text":"These techniques have been implemented and resulted in a lexicographic tool , Xtract .The techniques are described and some results are presented on a 10 million - word corpus of stock market news reports .A lexicographic evaluation of Xtract as a collocation retrieval tool has been made , and the estimated precision of Xtract is 80 % . .","label":"Background","metadata":{},"score":"52.963978"}
{"text":".. lored by many researchers in the Information Retrieval ( IR ) , and the Articial Intelligence ( AI ) communities .Interestingly it is only recently that resea ... \" ...The automated categorization ( or classification ) of texts into predefined categories has witnessed a booming interest in the last ten years , due to the increased availability of documents in digital form and the ensuing need to organize them .","label":"Background","metadata":{},"score":"53.33322"}
{"text":"On both tests , the algorithm obtains a score of 74 % .PMI - IR is contrasted with Latent Semantic Analysis ( LSA ) , which achieves a score of 64 % on the same 80 TOEFL questions .The paper discusses potential applications of the new unsupervised learning algorithm and some implications of the results for LSA and LSI ( Latent Semantic Indexing ) .","label":"Background","metadata":{},"score":"54.067047"}
{"text":"For example , the statement \" The number two is blue \" may be syntactically well formed , but at some level it is anomalous - BLUE is not a predicate that can be applied to numbers .According to the influential theory of ( Katz and Fodor , 1964 ) , a predicate associates a set of defining features with each argument , expressed within a restricted semantic vocabulary .","label":"Background","metadata":{},"score":"54.267975"}
{"text":"More formally , let ContentBasedP rofileðcÞ be th ... .by Kamal Nigam , Andrew Kachites Mccallum , Sebastian Thrun , Tom Mitchell - MACHINE LEARNING , 1999 . \" ...This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents .","label":"Background","metadata":{},"score":"54.473953"}
{"text":"More formally , let ContentBasedP rofileðcÞ be th ... .by Kamal Nigam , Andrew Kachites Mccallum , Sebastian Thrun , Tom Mitchell - MACHINE LEARNING , 1999 . \" ...This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents .","label":"Background","metadata":{},"score":"54.473953"}
{"text":"These experiments focus on the combination of classifiers ( relying on texts , images and addresses ) , dealing wi ... \" .In this paper , we describe the experiments that we have carried out during the European Research Project NetProtect II that aims at filtering harmful Web pages in order to protect children .","label":"Background","metadata":{},"score":"54.849762"}
{"text":"We are given a large database of customer transactions .Each transaction consists of items purchased by a customer in a visit .We present an efficient algorithm that generates all significant association rules between items in the database .The algorithm incorporates buffer management and novel esti ... \" .","label":"Background","metadata":{},"score":"55.157356"}
{"text":"\" ...The automated categorization ( or classification ) of texts into predefined categories has witnessed a booming interest in the last ten years , due to the increased availability of documents in digital form and the ensuing need to organize them .","label":"Background","metadata":{},"score":"55.217278"}
{"text":"Wesley T. Chuang , Asok Tiyyagura , Jihoon Yang , and Giovanni Giuffrida .A fast algorithm for hierarchical text classification .In Proceedings of DaWaK-00 , 2000 .[5 ] .William W. Cohen and Yoram Singer .Context - sensitive learning methods for text categorization .","label":"Background","metadata":{},"score":"55.863144"}
{"text":"This paper presents the design and evaluation of a text categorization method based on the Hierarchical Mixture of Experts model .This model uses a divide and conquer principle to define smaller categorization problems based on a predefined hierarchical structure .The final classifier is a hierarchical array of neural networks .","label":"Background","metadata":{},"score":"55.908356"}
{"text":"For instance , they may predict whether a user would be interested in seeing a particular movie .Social recomendation methods collect ratings of artifacts from many individuals and use nearest - neighbor techniques to make recommendatio ... \" .Recommendation systems make suggestions about artifacts to a user .","label":"Background","metadata":{},"score":"55.912743"}
{"text":"For instance , they may predict whether a user would be interested in seeing a particular movie .Social recomendation methods collect ratings of artifacts from many individuals and use nearest - neighbor techniques to make recommendatio ... \" .Recommendation systems make suggestions about artifacts to a user .","label":"Background","metadata":{},"score":"55.912743"}
{"text":"TS compares favorably with the other methods with up to 50 % vocabulary redu ... . ... mputations has a time complexity of O(V m ) .If one considers the twoway contingency table of a term t and a category c , where A is the number of times t and c co - occur , B is the number of time the t occurs without c , C is number of times c oc ... . \" ...","label":"Background","metadata":{},"score":"56.401207"}
{"text":"Comput .Sci . , Vol .44 , No . 5 , 2004 1825 Figure 1 .Effect of different feature selection methods in ... . \" ... Wikipedia is the largest organized knowledge repository on the Web , increasingly employed by natural language processing and search tools .","label":"Background","metadata":{},"score":"56.522644"}
{"text":"In particular , we focus on constructing Bayesian belief networks .Potential applications include computer - assisted hypothesis testing , automated scientific discovery , and automated construction of probabilistic expert systems .We extend the basic method to handle missing data and hidden ( latent ) variables .","label":"Background","metadata":{},"score":"56.949463"}
{"text":"Such a . ... document - classification task .This representation has been used w .. ...Agent software is a rapidly developing area of research .However , the overuse of the word ' agent ' has tended to mask the fact that , in reality , there is a truly heterogeneous body of research being carried out under this banner .","label":"Background","metadata":{},"score":"56.997475"}
{"text":"Such a . ... document - classification task .This representation has been used w .. ...Agent software is a rapidly developing area of research .However , the overuse of the word ' agent ' has tended to mask the fact that , in reality , there is a truly heterogeneous body of research being carried out under this banner .","label":"Background","metadata":{},"score":"56.997475"}
{"text":"The classification of a review is predicted by the average semantic orientation of the phrases in the review that contain adjectives or adverbs .A ... \" .This paper presents a simple unsupervised learning algorithm for classifying reviews as recommended ( thumbs up ) or not recommended ( thumbs down ) .","label":"Background","metadata":{},"score":"57.16323"}
{"text":"We use examples to show that our system discovers many inference rules easily missed by humans . ... unable to tell which SlotX filler occurred with which SlotY filler in the corpus .Mutual i .. \" ...A method of determining the similarity of nouns on the basis of a metric derived from the distribution of subject , verb and object in a large text corpus is described .","label":"Background","metadata":{},"score":"57.75093"}
{"text":"In all datasets we experiment with 9 different threshold values for RAKEL , ranging from 0.1 to 0.9 with a 0.1 step .We also exp ... . \" ...Adequate representation of natural language semantics requires access to vast amounts of common sense and domain - specific world knowledge .","label":"Background","metadata":{},"score":"57.79402"}
{"text":"One of the main challenges in question - answering is the potential mismatch between the expressions in questions and the expressions in texts .While humans appear to use inference rules such as \" X writes Y \" implies \" X is the author of Y \" in answering questions , such rules are generally unavailable to question - answering systems due to the inherent difficulty in constructing them .","label":"Background","metadata":{},"score":"58.204918"}
{"text":"It also suggests improvements which lead to a probabilistic variant of the Rocchio classifier .The Rocchio classifier , its probabilistic variant , and a naive Bayes classifier are compared on six text categorization tasks .The results show that the probabilistic algorithms are preferable to the heuristic Rocchio classifier not only because they are more well - founded , but also because they achieve better performance . by Mark Craven , Dan DiPasquo , Dayne Freitag , Andrew McCallum , Tom Mitchell , Kamal Nigam , Sean Slattery , 1998 . \" ...","label":"Background","metadata":{},"score":"58.426186"}
{"text":"It also suggests improvements which lead to a probabilistic variant of the Rocchio classifier .The Rocchio classifier , its probabilistic variant , and a naive Bayes classifier are compared on six text categorization tasks .The results show that the probabilistic algorithms are preferable to the heuristic Rocchio classifier not only because they are more well - founded , but also because they achieve better performance . by Mark Craven , Dan DiPasquo , Dayne Freitag , Andrew McCallum , Tom Mitchell , Kamal Nigam , Sean Slattery , 1998 . \" ...","label":"Background","metadata":{},"score":"58.426186"}
{"text":"In Text REtrieval Conference , pages 227 - 232 , 1997 .[17 ] .Amit Singhal , Mandar Mitra , and Christopher Buckley .Learning routing queries in a query zone .In Proceedings of SIGIR-97 , pages 25 - 32 , Philadelphia , US , 1997 .","label":"Background","metadata":{},"score":"58.534256"}
{"text":"Boosting and Rocchio applied to text filtering .In W. Bruce Croft , A. Moffat , C. J. van Rijsbergen , R. Wilkinson , and J. Zobel , editors , Proceedings of SIGIR-98 , pages 215 - 223 , Melbourne , AU , 1998 .","label":"Background","metadata":{},"score":"58.705185"}
{"text":"Many existing experiments show IG is one of the most effective methods , by contrast , MI has been demonstrated to have relatively poor performance .According to one existing MI method , the mutual information of a category c and a term t can be negative , which is in conflict with the definition of MI derived from information theory where it is always non - negative .","label":"Background","metadata":{},"score":"58.912365"}
{"text":"Artif Intell 97(1 - 2):325 - 343 MATH MathSciNet CrossRef .Bel N , Koster CHA , Villegas M ( 2003 ) Cross - lingual text categorization .In : Proceedings the 7th European conference on digital library , LNCS 2769 , pp 126 - 139 .","label":"Background","metadata":{},"score":"59.179672"}
{"text":"Deci ... . \" ...We present a tree - structured architecture for supervised learning .The statistical model underlying the architecture is a hi - erarchical mixture model in which both the mixture coefficients and the mixture components are generalized linear models ( GLIM 's ) .","label":"Background","metadata":{},"score":"59.221268"}
{"text":"However , w .. by William W. Cohen , Yoram Singer - ACM Transactions on Information Systems , 1996 . \" ... this article , we will investigate the performance of two recently implemented machine - learning algorithms on a number of large text categorization problems .","label":"Background","metadata":{},"score":"59.4104"}
{"text":"Wikipedia is the largest organized knowledge repository on the Web , increasingly employed by natural language processing and search tools .In this paper , we investigate the task of labeling Wikipedia pages with standard named entity tags , which can be used further by a range of information extraction and language processing tools .","label":"Background","metadata":{},"score":"59.444473"}
{"text":"Yiming Yang and Jan O. Pedersen .A comparative study on feature selection in text categorization .In Proceedings of ICML-97 , pages 412 - 420 , Nashville , US , 1997 .A study on mutual information - based feature selection for text categorization .","label":"Background","metadata":{},"score":"59.854973"}
{"text":"Results are presented of a preliminary evaluation of an algorithm for constructing a belief network from a database of cases .Finally , we relate the methods in this paper to previous work , and we discuss open problems . \" ...","label":"Background","metadata":{},"score":"59.95066"}
{"text":"Finally , Rocchio classifier has the advantage over k - nearest neighbor classifier in the classification process .The experimental results illustrate that the proposed model is an efficient method and gives generalization accuracy of about 98 % . ... \" ...","label":"Background","metadata":{},"score":"60.320007"}
{"text":"Littlestone N ( 1988 )Learning quickly when irrelevant attributes abound : a new linear - threshold algorithm .Mach Learn 2(4):285 - 318 .Grove AJ , Littlestone N , Schuurmans D ( 1997 )General convergence results for linear discriminant updates .","label":"Background","metadata":{},"score":"60.330074"}
{"text":"This paper proposes an ensemble method for multilabel classification .The RAndom k - labELsets ( RAKEL ) algorithm constructs each member of the ensemble by considering a small random subset of labels and learning a single - label classifier for the prediction of each element in the powerset of this subset .","label":"Background","metadata":{},"score":"60.331017"}
{"text":"Abstract : Text Categorization ( classification ) is the process of classifying documents into a predefined set of categories based on their content .In this paper , an intelligent Arabic text categorization system is presented .Machine learning algorithms are used in this system .","label":"Background","metadata":{},"score":"60.718628"}
{"text":"Abstract : Text Categorization ( classification ) is the process of classifying documents into a predefined set of categories based on their content .In this paper , an intelligent Arabic text categorization system is presented .Machine learning algorithms are used in this system .","label":"Background","metadata":{},"score":"60.718628"}
{"text":"A Study on Optimal Parameter Tuning for Rocchio Text Classifier .Abstract .Current trend in operational text categorization is the designing of fast classification tools .Several studies on improving accuracy of fast but less accurate classifiers have been recently carried out .","label":"Background","metadata":{},"score":"60.917503"}
{"text":"Importantly , due to the use of natural concepts , the ESA model is easy to explain to human users . in Section 4.2 , and rare features occurring in fewer than 3 documents are removed .The ... . \" ...","label":"Background","metadata":{},"score":"61.04574"}
{"text":"Many existing rule learning systems are computationally expensive on large noisy datasets .In this paper we evaluate the recently - proposed rule learning algorithm IREP on a large and diverse collection of benchmark problems .We show that while IREP is extremely efficient , it frequently gives error rates higher than those of C4.5 and C4.5rules .","label":"Background","metadata":{},"score":"61.175125"}
{"text":"Yiming Yang , Jaime Carbonell , Ralf Brown , Tom Pierce , Brian T. Archibald , Xin Liu - IEEE Intelligent Systems , 1999 . \" ...This paper studies the effective use of information retrieval and machine learning techniques in a new task , event detection and tracking .","label":"Background","metadata":{},"score":"61.350044"}
{"text":"Next , it places age ... \" .Agent software is a rapidly developing area of research .However , the overuse of the word ' agent ' has tended to mask the fact that , in reality , there is a truly heterogeneous body of research being carried out under this banner .","label":"Background","metadata":{},"score":"61.414"}
{"text":"Next , it places age ... \" .Agent software is a rapidly developing area of research .However , the overuse of the word ' agent ' has tended to mask the fact that , in reality , there is a truly heterogeneous body of research being carried out under this banner .","label":"Background","metadata":{},"score":"61.414"}
{"text":"An evaluation of Naive Bayesian anti - spam filtering .In : Proceedings of the workshop on machine learning in the new information age , 11th European conference on machine learning , pp 9 - 17 .Androutsopoulos I , Paliouras G , Michelakis E ( 2004 )","label":"Background","metadata":{},"score":"61.46517"}
{"text":"Androutsopoulos I , Koutsias J , Chandrinos KV , Spyropoulos CD ( 2000 )An experimental comparison of Naive Bayesian and keyword - based anti - spam filtering with encrypted personal e - mail messages .In : Proceedings of the 23rd annual international ACM SIGIR conference on research and development in information retrieval , pp 160 - 167 .","label":"Background","metadata":{},"score":"61.649445"}
{"text":"Moreover , the document is represented using several term weighting schemes and finally the k - nearest neighbor and Rocchio classifiers are used for classification process .Experiments are performed over self collected data corpus and the results show that the suggested hybrid method of statistical and light stemmers is the most suitable stemming algorithm for Arabic language .","label":"Background","metadata":{},"score":"62.178436"}
{"text":"In : Proceedings of 12th Chinese computer society conference on network and data communication , pp 211 - 215 .Sahami M , Dumais S , Heckerman D , Horvitz E ( 1998 )A Bayesian approach to filtering junk e - mail .","label":"Background","metadata":{},"score":"62.538074"}
{"text":"Cohen W ( 1995 )Fast effective rule induction .In : Machine learning : Proceedings of the 12th international conference , pp 115 - 123 .Drucker H , Wu D , Vapnik VN ( 1999 ) Support vector machines for spam categorization .","label":"Background","metadata":{},"score":"63.21011"}
{"text":"Hidalgo JMG ( 2002 )Evaluating cost - sensitive unsolicited bulk email categorization .In : Proceedings of ACM symposium on applied computing , pp 615 - 620 .Yang L , Xiaoping D , Ping L , Zhihui H , Chen G , Huanlin L ( 2002 )","label":"Background","metadata":{},"score":"63.211647"}
{"text":"CrossRef .[ 15 ] .Fabrizio Sebastiani .Machine learning in automated text categorization .ACM Computing Surveys , 34(1):1 - 47 , 2002 .CrossRef .[ 16 ] .Amit Singhal , John Choi , Donald Hindle , and Fernando C. N. Pereira .","label":"Background","metadata":{},"score":"63.593807"}
{"text":"Technical Report Report UBE - SOL , IMCR-008 , Internet Mail Consortium .Androutsopoulos I , Paliouras G , Karkaletsis V , Sakkis G , Spyropoulos CD , Stamatopoulos P ( 2000 ) Learning to filter spam e - mail : a comparison of a Naive Bayesian and a memory - based approach .","label":"Background","metadata":{},"score":"64.02276"}
{"text":"Each transaction consists of items purchased by a customer in a visit .We present an efficient algorithm that generates all significant association rules between items in the database .The algorithm incorporates buffer management and novel estimation and pruning techniques .","label":"Background","metadata":{},"score":"64.12689"}
{"text":".. s been considerable work in discovering classification rules : Given examples that belong to one of the prespecified classes , discover rules for classifying them .The algorithm we propose in this paper is targeted at discovering qualitative rules .However , the rules we discover are not classification rules .","label":"Background","metadata":{},"score":"64.352"}
{"text":"We also develop an on - line learning algorithm in which the pa - rameters are updated incrementally .Com - parative simulation results are presented in the robot dynamics domain . ... can be made with respect to the decision tree methodology in the machine learning literature .","label":"Background","metadata":{},"score":"64.418945"}
{"text":"PMI - IR has been empirically evaluated using 80 synonym test questions from the Test of English as a Foreign Language ( TOEFL ) , obtaining a score of 74 % ( Turney , 2001 ) .For comparison , Latent Semanti ... . \" ...","label":"Background","metadata":{},"score":"64.53709"}
{"text":"RIPPERk obtains error rates lower than or equivalent to C4.5rules on 22 of 37 benchmark problems , scales nearly linearly with the number of training examples , and can efficiently process noisy datasets containing hundreds of thousands of examples . \" ...","label":"Background","metadata":{},"score":"64.945946"}
{"text":"We test and compare different combination formulas ( Voting methods , logical methods , k Nearest Neighbors , evidence - based k Nearest Neighbors , Naive Bayes , Artificial Neural Network and Support Vector Machine ) on a five thousand webpages database .","label":"Background","metadata":{},"score":"65.10964"}
{"text":"Analysis and empirical evidence suggest that the evaluation results on some versions of Reuters were significantly affected by the inclusion of a large portion of unlabelled documents , mading those results difficult to interpret and leading to considerable confusions in the literature .","label":"Background","metadata":{},"score":"65.16139"}
{"text":"Positive semantic orientation indicates praise ( e.g. , \" honest \" , \" intrepid \" ) and negative semantic orientation indicates criticism ( e.g. , \" disturbing \" , \" superfluous \" ) .Semantic orientation varies in both direction ( positive or negative ) and degree ( mild to strong ) .","label":"Background","metadata":{},"score":"66.52353"}
{"text":"The RAndom k - labELsets ( RAKEL ) algorithm constructs each member of the ensemble by considering a small random subset of labels and learning a single - label classifier for the prediction of each element in the powerset of ... \" .","label":"Background","metadata":{},"score":"66.55947"}
{"text":"Positive semantic orientation indicates praise ( e.g. , \" honest \" , \" intrepid \" ) and negative semantic orientation indicates criticism ( e.g. , \" disturbing \" , \" superfluous \" ) .Semantic orientation varies in both direction ( positive or neg ... \" .","label":"Background","metadata":{},"score":"66.63995"}
{"text":"Rather , we find al .. \" ...This paper presents a Bayesian method for constructing probabilistic networks from databases .In particular , we focus on constructing Bayesian belief networks .Potential applications include computer - assisted hypothesis testing , automated scientific discovery , and automated construction of probabili ... \" .","label":"Background","metadata":{},"score":"66.973526"}
{"text":"T. Joachims .Text categorization with support vector machines : Learning with many relevant features .In In Proceedings of ECML-98 , pages 137 - 142 , 1998 .[ 10 ] .Thorsten Joachims .A probabilistic analysis of the rocchio algorithm with tfidf for text categorization .","label":"Background","metadata":{},"score":"67.02721"}
{"text":"There are two different MI based feature selection criteria which are referred to as MI in the TC literature .Actually , one of them should correctly be termed \" pointwise mutual information \" ( PMI ) .In this paper , we clarify the terminological confusion surrounding the notion of \" mutual information \" in TC , and detail an MI method derived correctly from information theory .","label":"Background","metadata":{},"score":"67.392586"}
{"text":"Social recomendation methods collect ratings of artifacts from many individuals and use nearest - neighbor techniques to make recommendations to a user concerning new artifacts .However , these methods do not use the significant amount of other information that is often available about the nature of each artifact --- such as cast lists or movie reviews , for example .","label":"Background","metadata":{},"score":"67.5175"}
{"text":"Social recomendation methods collect ratings of artifacts from many individuals and use nearest - neighbor techniques to make recommendations to a user concerning new artifacts .However , these methods do not use the significant amount of other information that is often available about the nature of each artifact --- such as cast lists or movie reviews , for example .","label":"Background","metadata":{},"score":"67.5175"}
{"text":"Share .References .[ 1 ] .Pivoted document length normalization .Technical Report TR95 - 1560 , Cornell University , Computer Science , 1995 .[ 2 ] .Avi Arampatzis , Jean Beney , C. H. A. Koster , and T. P. van der Weide .","label":"Background","metadata":{},"score":"67.524734"}
{"text":"TREC 11 experiments at CAS - ICT : filtering and web .In : Proceedings of the 11th text retrieval conference , pp 105 - 115 \" ...How do people know as much as they do with as little information as they get ?","label":"Background","metadata":{},"score":"67.9304"}
{"text":"The goal of the research described here is to automatically create a computer understandable world wide knowledge base whose content mirrors that of the World Wide Web .Such a ... \" .The World Wide Web is a vast source of information accessible to computers , but understandable only to humans .","label":"Background","metadata":{},"score":"68.82362"}
{"text":"The goal of the research described here is to automatically create a computer understandable world wide knowledge base whose content mirrors that of the World Wide Web .Such a ... \" .The World Wide Web is a vast source of information accessible to computers , but understandable only to humans .","label":"Background","metadata":{},"score":"68.82362"}
{"text":"It also proceeds to overview some other general issues which pertain to all the types of agents in the typology .This paper largely reviews software agents , and it also contains some strong opinions that are not necessarily widely accepted by the agent community . by Chumki Basu , Haym Hirsh , William Cohen - In Proceedings of the Fifteenth National Conference on Artificial Intelligence , 1998 . \" ...","label":"Background","metadata":{},"score":"69.08117"}
{"text":"It also proceeds to overview some other general issues which pertain to all the types of agents in the typology .This paper largely reviews software agents , and it also contains some strong opinions that are not necessarily widely accepted by the agent community . by Chumki Basu , Haym Hirsh , William Cohen - In Proceedings of the Fifteenth National Conference on Artificial Intelligence , 1998 . \" ...","label":"Background","metadata":{},"score":"69.08117"}
{"text":"References .Vaughan Nichols SJ ( 2003 )Saving private e - mail .IEEE Spectr 40(8):40 - 44 CrossRef .Whitworth B , Whitworth E ( 2004 )Spam and the social - technical gap .IEEE Comput 37(10):37 - 45 .","label":"Background","metadata":{},"score":"69.201614"}
{"text":"Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used : decision trees and Naive - Bayes . \" ...Many existing rule learning systems are computationally expensive on large noisy datasets .In this paper we evaluate the recently - proposed rule learning algorithm IREP on a large and diverse collection of benchmark problems .","label":"Background","metadata":{},"score":"70.336945"}
{"text":"Technical report 2004/2 , NCSR \" Demokritos \" .Schneider K ( 2003 )A comparison of event models for Naive Bayes anti - spam e - mail filtering .In : Proceedings of the 10th conference of the European chapter of the association for computational linguistics , pp 307 - 314 .","label":"Background","metadata":{},"score":"70.66884"}
{"text":"FOIL is based on ideas that have proved effective in attribute - value learning systems , but extends them to a first - order formalism .This new system has been applied successfully to several tasks ... \" .Abstract .This paper describes FOIL , a system that learns Horn clauses from data expressed as relations .","label":"Background","metadata":{},"score":"71.24471"}
{"text":"Recent work in lexicography indicates that collocations are pervasive in English ; apparently , they are common in all types of wri ... \" .Natural languages are full of collocations , recurrent combinations of words that co - occur more often than expected by chance and that correspond to arbitrary word usages .","label":"Background","metadata":{},"score":"72.102295"}
{"text":"We show that our method outperforms an existing social - filtering method in the domain of movie recommendations on a dataset of more than 45,000 movie ratings collected from a community of over 250 users .Introduction Recommendations are a part of everyday life .","label":"Background","metadata":{},"score":"72.18642"}
{"text":"We show that our method outperforms an existing social - filtering method in the domain of movie recommendations on a dataset of more than 45,000 movie ratings collected from a community of over 250 users .Introduction Recommendations are a part of everyday life .","label":"Background","metadata":{},"score":"72.18642"}
{"text":"Our method represents meaning in a high - dimensional space of concepts derived from Wikipedia , the largest encyclopedia in existence .We explicitly represent the meaning of any text in terms of Wikipedia - based concepts .We evaluate the effectiveness of our method on text categorization and on computing the degree of semantic relatedness between fragments of natural language text .","label":"Background","metadata":{},"score":"73.55851"}
{"text":"For example , the statement \" The number two is blue \" may be syntactically well formed , but at some level it is anomalous - BLUE is not a predicate that can be applied to numbers .According to the influential theo ... \" .","label":"Background","metadata":{},"score":"77.70538"}
{"text":"The analysis and promising experimental results indicate that the Perceptron and Winnow are two very competitive classifiers for anti - spam filtering .Keywords .Online linear classifier Perceptron Winnow Anti - spam filtering .This work was carried out while the first author was visiting Dublin City University supported by a China State Scholarship .","label":"Background","metadata":{},"score":"79.6738"}
{"text":"A phrase has a positive semantic orientation when it has good associations ( e.g. , \" subtle nuances \" ) and a negative semantic orientation when it has bad associations ( e.g. , \" very cavalier \" ) .In this paper , the semantic orientation of a phrase is calculated as the mutual information between the given phrase and the word \" excellent \" minus the mutual information between the given phrase and the word \" poor \" .","label":"Background","metadata":{},"score":"83.23589"}
{"text":"Thesis ( M.Phil . ) --Hong Kong University of Science and Technology , 1996","label":"Background","metadata":{},"score":"99.82846"}
