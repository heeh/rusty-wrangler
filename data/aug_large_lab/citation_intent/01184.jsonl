{"text":"The system consists of two components : an unlabeled dependency parser using Gibbs sampling which can incorporate sentence - level ( global ) features as well as token - leve ... \" .In this paper , we describe a two - stage multilingual dependency parser used for the multilingual track of the CoNLL 2007 shared task .","label":"Uses","metadata":{},"score":"44.17359"}
{"text":"The system consists of two components : an unlabeled dependency parser using Gibbs sampling which can incorporate sentence - level ( global ) features as well as token - leve ... \" .In this paper , we describe a two - stage multilingual dependency parser used for the multilingual track of the CoNLL 2007 shared task .","label":"Uses","metadata":{},"score":"44.17359"}
{"text":", 2004 ; Hall et al . , 2006 ) .MaltParser allows users to define feature models of arbitrary complexity .MaltParser currently includes two machine learning packages ( thanks to Sofia Cassel for her work on LIBLINEAR ) : .","label":"Uses","metadata":{},"score":"46.248253"}
{"text":"Documentation .Resources .Contact .MaltParser 0.4 in the CoNLL 2007 Shared Task .MaltParser 0.4 was used in the multi - lingual track of the CoNLL 2007 Shared Task in the systems that obtained the first and fifth best overall scores .","label":"Uses","metadata":{},"score":"46.59411"}
{"text":"..METU - Sabancı treebank ( Atalay et al . , 2003 ; Oflazer et al . , 2003 ) from the CoNLL shared task in 2006 .Whenever using CoNLL shared task data , we used the first 80 % of the data d .. \" ...","label":"Uses","metadata":{},"score":"47.160606"}
{"text":"..METU - Sabancı treebank ( Atalay et al . , 2003 ; Oflazer et al . , 2003 ) from the CoNLL shared task in 2006 .Whenever using CoNLL shared task data , we used the first 80 % of the data d .. \" ...","label":"Uses","metadata":{},"score":"47.160606"}
{"text":"The parsing methodology is based on three essential components : .Deterministic parsing algorithms for building labeled dependency graphs ( Kudo and Matsumoto,2002 ; Yamada and Matsumoto , 2003 ; Nivre,2003 ) .History - based models for predicting the next parser action at nondeterministic choice points ( Black et al . , 1992 ; Magerman , 1995 ; Ratnaparkhi , 1997 ; Collins , 1999 ) .","label":"Uses","metadata":{},"score":"48.49804"}
{"text":"However , the first release of the treebank , containing a seed data set of 225 sentences , was in Fall 2011 and the process of treebank development was published in the journal article Linguistic Issues in Language Technology , 7(18):1 - 10 , January 2012 .","label":"Uses","metadata":{},"score":"48.621742"}
{"text":"[ ps ] .Nivre , J. , J. Hall and J. Nilsson ( 2004 ) .Memory - Based Dependency Parsing .In Ng , H. T. and Riloff , E. ( eds . )Proceedings of the Eighth Conference on Computational Natural Language Learning ( CoNLL ) , May 6 - 7 , 2004 , Boston , Massachusetts , pp .","label":"Uses","metadata":{},"score":"48.979042"}
{"text":"A Fundamental Algorithm for Dependency Parsing .In Proceedings of the 39th Annual ACM Southeast Conference , pp .95 - 102 .Fan , R.-E. , Chang , K.-W. , Hsieh , C.-J. , Wang , X.-R. and Lin , C.-J. LIBLINEAR :","label":"Uses","metadata":{},"score":"49.44551"}
{"text":"In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP , 351 - 359 .Nivre , J. , Kuhlmann , M. and Hall , J. ( 2009 )","label":"Uses","metadata":{},"score":"50.8541"}
{"text":"In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP , 351 - 359 .Nivre , J. , Kuhlmann , M. and Hall , J. ( 2009 )","label":"Uses","metadata":{},"score":"50.8541"}
{"text":"In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .","label":"Uses","metadata":{},"score":"51.2317"}
{"text":"In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .","label":"Uses","metadata":{},"score":"51.2317"}
{"text":"49 - 56 .Ratnaparkhi , A. ( 1997 ) .A linear observed time statistical parser based on maximum entropy models .In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pp . 1 - 10 .","label":"Uses","metadata":{},"score":"51.450275"}
{"text":"The systems are described in Hall et al .( 2007 ) .More information is available at : .MaltParser 0.4 in the CoNLL - X Shared Task .In this system , MaltParser was combined with pseudo - projective parsing , which requires preprocessing of training data and post - processing of parser output ( Nivre and Nilsson 2005 ) .","label":"Uses","metadata":{},"score":"51.819435"}
{"text":"We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .We apply the framework to word segmentation , joint segmentation and POStagging , dependency parsing , and phrase - structure parsing .","label":"Uses","metadata":{},"score":"51.99814"}
{"text":"We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .We apply the framework to word segmentation , joint segmentation and POStagging , dependency parsing , and phrase - structure parsing .","label":"Uses","metadata":{},"score":"51.99814"}
{"text":"Experimental results show that the global features are useful in all the languages . ... mines unlabeled dependency structures only , and we attach dependency relation labels using Support Vector Machines afterwards . \" ...We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .","label":"Uses","metadata":{},"score":"52.19212"}
{"text":"Experimental results show that the global features are useful in all the languages . ... mines unlabeled dependency structures only , and we attach dependency relation labels using Support Vector Machines afterwards . \" ...We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .","label":"Uses","metadata":{},"score":"52.19212"}
{"text":"( 2006 ) .More information is available at : Documentation .Resources .Contact .Introduction .MaltParser is a system for data - driven dependency parsing , which can be used to induce a parsing model from treebank data and to parse new data using an induced model .","label":"Uses","metadata":{},"score":"52.491"}
{"text":"Information about different options can be found on the LIBLINEAR web site .Prediction strategy .From version 1.1 of MaltParser it is possible to choose different prediction strategies .Previously , MaltParser ( version 1.0.4 and earlier ) combined the prediction of the transition with the prediction of the arc label into one complex prediction with one feature model .","label":"Uses","metadata":{},"score":"52.976036"}
{"text":"Therefore another classitem_separator should be used in this case .Tools . by Kuzman Ganchev , Jennifer Gillenwater , Ben Taskar - In ACL - IJCNLP , 2009 . \" ...Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .","label":"Uses","metadata":{},"score":"53.091164"}
{"text":"Springer .Nilsson , J. , Löwe W. , Hall , J. and Nivre , J. ( 2009 )Natural Language Parsing for Fact Extraction from Source Code .In Proceedings of 17th IEEE International Conference on Program Comprehension , Vancouver , Canada , pp .","label":"Uses","metadata":{},"score":"53.097168"}
{"text":"Nilsson , J. , Löwe W. , Hall , J. and Nivre , J. ( 2009 )Parsing Formal Languages using Natural Language Parsing Techniques .In Proceedings of 11th International Conference on Parsing Technologies ( IWPT ) , Paris , France , pp . to appear .","label":"Uses","metadata":{},"score":"53.811737"}
{"text":"MaltParser 1.0.0 and later releases constitute a complete reimplementation of MaltParser in Java and are distributed with an open source license .The previous versions 0.1 - 0.4 of MaltParser were implemented in C. The Java implementation ( version 1.0.0 and later releases ) replaces the C implementation ( version 0 .","label":"Uses","metadata":{},"score":"55.050728"}
{"text":"Documentation .Resources .Contact .MaltParser is a system for data - driven dependency parsing , which can be used to induce a parsing model from treebank data and to parse new data using an induced model .MaltParser is developed by Johan Hall , Jens Nilsson and Joakim Nivre at Växjö University and Uppsala University , Sweden .","label":"Uses","metadata":{},"score":"55.330338"}
{"text":"Maven repository .Since version 1.7 , MaltParser is also available via the official Maven repository . org.maltparser maltparser 1.8.1 .MaltParser optimization .MaltParser is a fairly complex system with many parameters that need to be optimized .Simply using the system out of the box with default settings is therefore likely to result in suboptimal performance .","label":"Uses","metadata":{},"score":"55.80577"}
{"text":"It is possible to define your own feature model specification using the description above and using the --guide - features option to specify the feature model specification file .LIBLINEAR .Prediction strategy .From version 1.1 of MaltParser it is possible to choose different prediction strategies .","label":"Uses","metadata":{},"score":"56.369537"}
{"text":"In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ( COLING - ACL ) Main ConferencePoster Sessions , 316 - 323 .[ pdf ] .Nivre , J. , J. Hall and J. Nilsson ( 2006 )","label":"Uses","metadata":{},"score":"56.603165"}
{"text":"Dependency parsing is a central NLP task .In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .","label":"Uses","metadata":{},"score":"56.789078"}
{"text":"Dependency parsing is a central NLP task .In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .","label":"Uses","metadata":{},"score":"56.789078"}
{"text":"Hall , J. , J. Nivre and J. Nilsson ( 2006 ) .Discriminative Classifiers for Deterministic Dependency Parsing .In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics , pp .","label":"Uses","metadata":{},"score":"56.801712"}
{"text":"The beam - search decoder only requires the syntactic processing task to be broken into a sequence of decisions , such that , at each stage in the process , the decoder is able to consider the top - n candidates and generate all possibilities for the next stage .","label":"Uses","metadata":{},"score":"56.90072"}
{"text":"The beam - search decoder only requires the syntactic processing task to be broken into a sequence of decisions , such that , at each stage in the process , the decoder is able to consider the top - n candidates and generate all possibilities for the next stage .","label":"Uses","metadata":{},"score":"56.90072"}
{"text":"It continues with information about the learning models that are created , in this case only one LIBSVM model .It then saves the symbol table and all options ( which can not be changed later during parsing ) and stores everything in a configuration file named test.mco .","label":"Uses","metadata":{},"score":"56.92007"}
{"text":"In Human Language Technologies 2007 : The Conference of the North American Chapter of the Association for Computational Linguistics ; Proceedings of the Main Conference , pp .396 - 403 [ pdf ] .Nivre , J. , J. Hall , J. Nilsson , A. Chanev , G. Eryigit , S. Kübler , S. Marinov and E. Marsi ( 2007 ) .","label":"Uses","metadata":{},"score":"57.155342"}
{"text":"For more information about the parsing algorithm see the user guide : Parsing Algorithms .MaltParser 1.4.1 and later versions ( implemented in Java ) have the possibility of distinguishing between different kinds of null - values when extracting the feature vector .","label":"Uses","metadata":{},"score":"57.373253"}
{"text":"This simple framework performs surprisingly well , giving accuracy results competitive with the state - of - the - art on all the tasks we consider .The computational simplicity of the decoder and training algorithm leads to significantly higher test speeds and lower training times than their main alternatives , including log - linear and large - margin training algorithms and dynamic - programming for decoding .","label":"Uses","metadata":{},"score":"57.48086"}
{"text":"This simple framework performs surprisingly well , giving accuracy results competitive with the state - of - the - art on all the tasks we consider .The computational simplicity of the decoder and training algorithm leads to significantly higher test speeds and lower training times than their main alternatives , including log - linear and large - margin training algorithms and dynamic - programming for decoding .","label":"Uses","metadata":{},"score":"57.48086"}
{"text":"We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative improvement over the baseline approach that uses a fixed context window of adjacent words .","label":"Uses","metadata":{},"score":"57.84793"}
{"text":"We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative improvement over the baseline approach that uses a fixed context window of adjacent words .","label":"Uses","metadata":{},"score":"57.84793"}
{"text":"NB : Since version 1.7 the jar - file has been changed to maltparser-1.8.1.jar and is also available via the official Maven repository . org.maltparser maltparser 1.8.1 .NB : Parsers developed using MaltParser have achieved state - of - the - art accuracy for a number of languages .","label":"Uses","metadata":{},"score":"58.01274"}
{"text":"[ ps ] .Nivre , J. ( 2004 ) .Incrementality in Deterministic Dependency Parsing .In Incremental Parsing : Bringing Engineering and Cognition Together .Workshop at ACL-2004 , Barcelona , Spain , July 25 , 2004 .[ pdf ] .","label":"Uses","metadata":{},"score":"58.103523"}
{"text":"Black , E. , F. Jelinek , J. D. Lafferty , D. M. Magerman , R. L. Mercer and S. Roukos ( 1992 ) .Towards history - based grammars : Using richer models for probabilistic parsing .In Proceedings of the 5th DARPA Speech and Natural Language Workshop , pp .","label":"Uses","metadata":{},"score":"58.13172"}
{"text":"LIBLINEAR --A Library for Large Linear Classification ( Fan et al . , 2008 ) .MaltParser can also be turned into a phrase structure parser that recovers both continuous and discontinuous phrases with both phrase labels and grammatical functions ( Hall and Nivre , 2008a ; Hall and Nivre , 2008b ) .","label":"Uses","metadata":{},"score":"58.418045"}
{"text":"This paper presents novel improvements to the induction of translation lexicons from monolingual corpora using multilingual dependency parses .We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative ... \" .","label":"Uses","metadata":{},"score":"58.629833"}
{"text":"This paper presents novel improvements to the induction of translation lexicons from monolingual corpora using multilingual dependency parses .We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative ... \" .","label":"Uses","metadata":{},"score":"58.629833"}
{"text":"The tree with the maximal probability is outputted .The experiments are carried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser . ... arried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser .","label":"Uses","metadata":{},"score":"58.94332"}
{"text":"The tree with the maximal probability is outputted .The experiments are carried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser . ... arried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser .","label":"Uses","metadata":{},"score":"58.94332"}
{"text":"The results show that all three systems achieve competitive performance , with a best labeled attachment score over 88 % .All three parsers benefit from the use of automatically derived lemmas , while morphological features seem to be less important .","label":"Uses","metadata":{},"score":"59.028233"}
{"text":"The results show that all three systems achieve competitive performance , with a best labeled attachment score over 88 % .All three parsers benefit from the use of automatically derived lemmas , while morphological features seem to be less important .","label":"Uses","metadata":{},"score":"59.028236"}
{"text":"The UPDT has sequentially been split into 10 parts , of which segments 1 - 8 are used for training ( 80 % ) , 9 for development ( 10 % ) , and 10 for test ( 10 % ) sets .","label":"Uses","metadata":{},"score":"59.463116"}
{"text":"We discuss how the general framework is applied to each of the problems studied in this article , making comparisons with alternative learning and decoding algorithms .We also show how the comparability of candidates considered by the beam is an important factor in the performance .","label":"Uses","metadata":{},"score":"59.546715"}
{"text":"We discuss how the general framework is applied to each of the problems studied in this article , making comparisons with alternative learning and decoding algorithms .We also show how the comparability of candidates considered by the beam is an important factor in the performance .","label":"Uses","metadata":{},"score":"59.546715"}
{"text":"- Train a parser model using LibLinear .- Optimize the memory usage - Save the Liblinear model odm0.liblinear.moo Learning time : 00:00:01 ( 1290 ms ) Finished : Fri May 02 23:45:19 CEST 2014 .Most of the logging information is self - explaining : it tells you that the parser is started at a certain time and date and that it reads sentences from a specified file containing 32 sentences .","label":"Uses","metadata":{},"score":"59.621048"}
{"text":"Nivre , J. ( 2006 ) Inductive Dependency Parsing .Springer .Nivre , J. , Hall , J. and Nilsson , J. ( 2004 )Memory - Based Dependency Parsing .In Ng , H. T. and Riloff , E. ( eds . )","label":"Uses","metadata":{},"score":"59.841278"}
{"text":"MaltParser 1.1 and MaltParser 1.2 can be turned into a phrase structure parser that recovers both continuous and discontinuous phrases with both phrase labels and grammatical functions .Note : The implementation of phrase structure parsing has been removed in later releases of MaltParser .","label":"Uses","metadata":{},"score":"59.882973"}
{"text":"In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ( COLING / ACL ) , Sydney , Australia , pp .257 - 264 .[ pdf ] .Hall , J. , J. Nivre and J. Nilsson ( 2006 )","label":"Uses","metadata":{},"score":"59.99868"}
{"text":"For many languages and data sets , information about optimized settings can be found in the literature or on the web .Please make the effort to use this information in order to avoid misleading comparisons .You can also try MaltOptimizer , a new tool for automatic MaltParser optimization .","label":"Uses","metadata":{},"score":"60.30551"}
{"text":"With MaltParser 1.1 and later versions it is possible to divide the prediction of the parser action into several predictions .For example with the Nivre arc - eager algorithm , it is possible to first predict the transition ; if the transition is SHIFT or REDUCE the nondeterminism is resolved , but if the predicted transition is RIGHT - ARC or LEFT - ARC the parser continues to predict the arc label .","label":"Uses","metadata":{},"score":"60.46859"}
{"text":"Resources .Contact .Publications .Nivre , J. ( 2003 ) .An Efficient Algorithm for Projective Dependency Parsing .In Proceedings of the 8th International Workshop on Parsing Technologies ( IWPT 03 ) , Nancy , France , 23 - 25 April 2003 , pp .","label":"Uses","metadata":{},"score":"60.491196"}
{"text":"[ pdf ] .Hall , J. and Nivre , J. ( 2008 )Parsing Discontinuous Phrase Structure with Grammatical Functions .In Ranta , A. and Nordström , B. ( eds . )In Proceedings of the 6th International Conference on Natural Language Processing ( GoTAL 2008 ) , LNAI 5221 , Springer - Verlag , August 25 - 27 , 2008 , Gothenburg , Sweden , pp . 169 - 180 .","label":"Uses","metadata":{},"score":"60.75944"}
{"text":"This command will create a new directory test containing the following files : .Description .conllx.xml .XML document describing the data format .NivreEager.xml .XML document containing the feature model specification .odm0.libsvm.moo , odm0.libsvm.map .The LIBSVM model that is used for predicting the next parsing action .","label":"Uses","metadata":{},"score":"60.83661"}
{"text":"99 - 106 .[ pdf ] .Nivre , J. , J. Hall , J. Nilsson , G. Eryigit and S. Marinov ( 2006 ) .Labeled Pseudo - Projective Dependency Parsing with Support Vector Machines .In Proceedings of the Tenth Conference on Computational Natural Language Learning ( CoNLL ) .","label":"Uses","metadata":{},"score":"60.893612"}
{"text":"Hall , J. and J. Nivre ( 2008b )Parsing Discontinuous Phrase Structure with Grammatical Functions .In Proceedings of the 6th International Conference on Natural Language Processing ( GoTAL 2008 ) , August 25 - 27 , 2008 , Gothenburg , Sweden .","label":"Uses","metadata":{},"score":"61.01999"}
{"text":"For more information about how to use MaltParserService , please see the examples provided in the directory examples / apiexamples / srcex .References .Chang , C.-C. and Lin , C.-J. ( 2001 )LIBSVM : a library for support vector machines .","label":"Uses","metadata":{},"score":"61.03373"}
{"text":"MaltParser uses history - based feature models for predicting the next action in the deterministic derivation of a dependency structure , which means that it uses features of the partially built dependency structure together with features of the ( tagged ) input string .","label":"Uses","metadata":{},"score":"61.078125"}
{"text":"MaltParser uses history - based feature models for predicting the next action in the deterministic derivation of a dependency structure , which means that it uses features of the partially built dependency structure together with features of the ( tagged ) input string .","label":"Uses","metadata":{},"score":"61.078125"}
{"text":"MaltParser have seven pre - defined flow charts that describe what tasks MaltPasrer should perform .These seven flow charts are : .Name .Description . learn .Creates a Single Malt configuration and induces a parsing model from input data . parse .","label":"Uses","metadata":{},"score":"61.169594"}
{"text":"This robustness led to the third best overall average labeled attachment score in the task , despite using no discriminative methods .We also demonstrate that the parser is quite fast , and can provide even faster parsing times without much loss of accuracy . \" ...","label":"Uses","metadata":{},"score":"61.204914"}
{"text":"This robustness led to the third best overall average labeled attachment score in the task , despite using no discriminative methods .We also demonstrate that the parser is quite fast , and can provide even faster parsing times without much loss of accuracy . \" ...","label":"Uses","metadata":{},"score":"61.204914"}
{"text":"We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .","label":"Uses","metadata":{},"score":"61.27292"}
{"text":"We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .","label":"Uses","metadata":{},"score":"61.27292"}
{"text":"We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .","label":"Uses","metadata":{},"score":"61.272923"}
{"text":"We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .","label":"Uses","metadata":{},"score":"61.272923"}
{"text":"[ pdf ] .Nilsson J. , J. Nivre and J. Hall .( 2007 )Generalizing Graph Transformations in Data - Driven Dependency Parsing .In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics ( ACL ) , Prauge , Czech Republic , pp .","label":"Uses","metadata":{},"score":"61.333336"}
{"text":"MaltParser 1.4.1 ----------------------------------------------------------------------------- MALT ( Models and Algorithms for Language Technology ) Group Vaxjo University and Uppsala University Sweden -----------------------------------------------------------------------------Started : Sun Jun 27 15:58:46 CEST 2010 Data Format : file:////home / jha / dev / eclipse / malt / MaltParser / test2/conllx . xml Transition system : Arc - Eager Parser configuration : Nivre with NORMAL root handling Feature model : NivreEager.xml Learner : libsvm Oracle : Arc - Eager . 1 0s 3 MB . 10 1s 2 MB 32 1s 3 MB Creating LIBSVM model odm0.libsvm.mod Learning time : 00:00:03 ( 3500 ms ) Finished : Sun Jun 27 15:58:50 CEST 2010 .","label":"Uses","metadata":{},"score":"61.482166"}
{"text":"For example , it could look like this : -llo -s_4_-c_0.1 . guide .Contains options that are specific for the guide , which can be seen as an interface ( or glue ) between the parsing algorithm and the learner .","label":"Uses","metadata":{},"score":"61.483467"}
{"text":"In order to replicate the behavior of older versions , use the following settings : . Covington .Covington 's algorithm ( Covington 2001 ) is a quadratic - time algorithm for unrestricted dependency structures , which proceeds by trying to link each new token to each preceding token .","label":"Uses","metadata":{},"score":"61.50105"}
{"text":"Acknowledgments .References .De Marneffe , Marie - Catherine , Bill MacCartney , and Christopher D. Manning .Generating typed dependency parses from phrase structure parses .In Proceedings of the 5th International Conference on Language Resources and Evaluation ( LREC ) .","label":"Uses","metadata":{},"score":"61.903435"}
{"text":"By running experiments , which allows other programs to train a parser model or parse with a parser model .IO - handling is done by MaltParser .By first initializing a parser model and then calling the method parse ( ) for each sentence that should be parsed by MaltParser .","label":"Uses","metadata":{},"score":"62.00052"}
{"text":"During learning , the configuration is created and stored in a configuration file with the file suffix .mco .This configuration file can later be reused whenever the trained model is used to parse new data .Potentially there can be several types of configuration , but MaltParser 1.8.1 only knows one type : the Single Malt configuration ( singlemalt ) .","label":"Uses","metadata":{},"score":"62.19635"}
{"text":"Note :Usually this will result in a slight drop in accuracy but a significant decrease in learning time .The option data_split_structure specifies the data structure that should be used for splitting up the traning instances .For some learning methods ( like LIBSVM ) it is impractical to induce a single model based on all training instances .","label":"Uses","metadata":{},"score":"62.51358"}
{"text":"In Bunt , H. , Merlo , P. and Nivre , J. ( eds . )New Trends in Parsing Technology .Springer .Nivre , J. ( 2009 ) Non - Projective Dependency Parsing in Expected Linear Time .In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP , 351 - 359 .","label":"Uses","metadata":{},"score":"62.577785"}
{"text":"This command will display the following output : . html .Here you can see the basic usage and options .To get all available options : .Train a parsing model .Now we are ready to train our first parsing model .","label":"Uses","metadata":{},"score":"62.757095"}
{"text":"[ pdf ] Documentation .Resources .Contact .MaltParser 1.4.1 - Available options .All options are categorized into one of the following option groups : system , config , singlemalt , input , output , graph , nivre , 2planar , planar , covington , libsvm , liblinear , guide , pproj .","label":"Uses","metadata":{},"score":"62.76858"}
{"text":"Hall , J. ( 2006 )MaltParser : An Architecture for Labeled Inductive Dependency Parsing .Licentiate thesis , Växjö University .[ pdf ] .Nivre , J. ( 2006 ) Inductive Dependency Parsing .Springer .Nilsson , J. , J. Nivre and J. Hall .","label":"Uses","metadata":{},"score":"62.882366"}
{"text":"Partial trees .Since MaltParser 1.4 it is possible to parse with partial trees , i.e. , sentences may be input with a partial dependency structure , a subgraph of a complete dependency tree .To parse with partial trees you need to do the following : .","label":"Uses","metadata":{},"score":"62.990097"}
{"text":"Partial trees .Since MaltParser 1.4 it is possible to parse with partial trees , i.e. , sentences may be input with a partial dependency structure , a subgraph of a complete dependency tree .To parse with partial trees you need to do the following : .","label":"Uses","metadata":{},"score":"62.990097"}
{"text":"[ pdf ] .Hall , J. , J. Nilsson , J. Nivre , G. Eryigit , B. Megyesi , M. Nilsson and M. Saers ( 2007 ) .Single Malt or Blended ?A Study in Multilingual Parser Optimization .In Proceedings of the CoNLL Shared Task Session of EMNLP - CoNLL 2007 , 933 - -939 .","label":"Uses","metadata":{},"score":"63.097355"}
{"text":"In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics ( ACL ) , pp .276 - 283 .Nivre , J. ( 2003 ) .An Efficient Algorithm for Projective Dependency Parsing .In Proceedings of the 8th International Workshop on Parsing Technologies ( IWPT 03 ) , pp .","label":"Uses","metadata":{},"score":"63.114674"}
{"text":"Statistical Dependency Analysis with Support Vector Machines .In Proceedings of the 8th International Workshop on Parsing Technologies ( IWPT ) , pp .195 - 206 .Hall , J. and J. Nivre ( 2008a )A Dependency - Driven Parser for German Dependency and Constituency Representations .","label":"Uses","metadata":{},"score":"63.245316"}
{"text":"Hall , J. and J. Nivre ( 2008b )Parsing Discontinuous Phrase Structure with Grammatical Functions .In Ranta , A. and Nordstöm , B. ( eds . )In Proceedings of the 6th International Conference on Natural Language Processing ( GoTAL 2008 ) , LNAI 5221 , Springer - Verlag , August 25 - 27 , 2008 , Gothenburg , Sweden , pp . 169 - 180 .","label":"Uses","metadata":{},"score":"63.368584"}
{"text":"Hall , J. and J. Nivre ( 2008b )Parsing Discontinuous Phrase Structure with Grammatical Functions .In Ranta , A. and Nordström , B. ( eds . )In Proceedings of the 6th International Conference on Natural Language Processing ( GoTAL 2008 ) , LNAI 5221 , Springer - Verlag , August 25 - 27 , 2008 , Gothenburg , Sweden , pp . 169 - 180 .","label":"Uses","metadata":{},"score":"63.614082"}
{"text":"Unlike previous approaches , our framework does not require full projected parses , allowing partial , approximate transfer through linear expectation constraints on the space of distributions over trees .We consider several types of constraints that range from generic dependency conservation to language - specific annotation rules for auxiliary verb analysis .","label":"Uses","metadata":{},"score":"63.76684"}
{"text":"Unlike previous approaches , our framework does not require full projected parses , allowing partial , approximate transfer through linear expectation constraints on the space of distributions over trees .We consider several types of constraints that range from generic dependency conservation to language - specific annotation rules for auxiliary verb analysis .","label":"Uses","metadata":{},"score":"63.76684"}
{"text":"Journal of Machine Learning Research 9 , 1871 - 1874 .Hall , J. ( 2008 )Transition - Based Natural Language Parsing with Dependency and Constituency Representations .Acta Wexionensia , No 152/2008 , Computer Science , Växjö University ( PhD Thesis ) .","label":"Uses","metadata":{},"score":"63.884655"}
{"text":"It then saves the symbol table and all options ( which can not be changed later during parsing ) and stores everything in a configuration file named test.mco .Finally , the parser informs you about the learning time .Parse data with your parsing model .","label":"Uses","metadata":{},"score":"63.971607"}
{"text":"( If one of the address functions is undefined , a null - value is returned . )This feature function can be used to define features over the dependency graph predicted by another parser and given as input to MaltParser .","label":"Uses","metadata":{},"score":"64.31294"}
{"text":"( If one of the address functions is undefined , a null - value is returned . )This feature function can be used to define features over the dependency graph predicted by another parser and given as input to MaltParser .","label":"Uses","metadata":{},"score":"64.31294"}
{"text":"Parse data with your parsing model .We have now created a parsing model that we can use for parsing new sentences from the same language .It is important that unparsed sentences are formatted according to the format that was used during training ( except that the output columns for head and dependency relation are missing ) .","label":"Uses","metadata":{},"score":"64.378876"}
{"text":"There are two ways to call the MaltParserService : .By running experiments , which allows other programs to train a parser model or parse with a parser model .IO - handling is done by MaltParser .By first initializing a parser model and then calling the method parse ( ) for each sentence that should be parsed by MaltParser .","label":"Uses","metadata":{},"score":"64.5943"}
{"text":"Unfortunately the sentence in Figure 1(b ) is highly unusual in its amount of dependency conservation .To get a feel for the typical case , we used off - the - shelf parsers ( McDonald et al . , 2005 ) for E .. by Ivan Titov , James Henderson - IN PROCEEDINGS OF CONLL-2007 SHARED TASK .","label":"Uses","metadata":{},"score":"64.9726"}
{"text":"Unfortunately the sentence in Figure 1(b ) is highly unusual in its amount of dependency conservation .To get a feel for the typical case , we used off - the - shelf parsers ( McDonald et al . , 2005 ) for E .. by Ivan Titov , James Henderson - IN PROCEEDINGS OF CONLL-2007 SHARED TASK .","label":"Uses","metadata":{},"score":"64.9726"}
{"text":"The concurrent interface uses a more \" light - weighted \" parser and hopefully supports almost all features .One know exception is feature propagation is not supported in the new \" light - weighted \" parser .To compile the examples in srcex / org / maltparser / examples .","label":"Uses","metadata":{},"score":"65.08514"}
{"text":"This option tells the parser which format is used in the input data file .The format is defined in an XML file .For more information see the user guide : Input and output format .There are already two data format specification files in the MaltParser distribution ( included in malt.jar ) : . output .","label":"Uses","metadata":{},"score":"65.34092"}
{"text":"It is possible to define your own feature model specification using the description above and using the --guide - features option to specify the feature model specification file .Learner .MaltParser can be used with different learning algorithms to induce classifiers from training data .","label":"Uses","metadata":{},"score":"65.35623"}
{"text":"Kudo , T. and Y. Matsumoto ( 2002 ) .Japanese Dependency Analysis Using Cascaded Chunking .In Proceedings of the Sixth Workshop on Computational Language Learning ( CoNLL ) , pp .63 - 69 .Magerman , D. M. ( 1995 ) .","label":"Uses","metadata":{},"score":"65.53258"}
{"text":"It is important that unparsed sentences are formatted according to the format that was used during training ( except that the output columns for head and dependency relation are missing ) .In this case tokens are represented by the first six columns of the CoNLL data format .","label":"Uses","metadata":{},"score":"65.54734"}
{"text":"Nivre 's algorithm uses two data structures : .A stack Stack of partially processed tokens , where Stack[i ] is the i+1th token from the top of the stack , with the top being Stack[0 ] .A list Input of remaining input tokens , where Input[i ] is the i+1th token in the list , with the first token being Input[0 ] .","label":"Uses","metadata":{},"score":"65.57208"}
{"text":"Nivre 's algorithm uses two data structures : .A stack Stack of partially processed tokens , where Stack[i ] is the i+1th token from the top of the stack , with the top being Stack[0 ] .A list Input of remaining input tokens , where Input[i ] is the i+1th token in the list , with the first token being Input[0 ] .","label":"Uses","metadata":{},"score":"65.57208"}
{"text":"In addition , there are two options , allow shift and allow root , that controls the behavior of Covington 's algorithm .Covington 's algorithm uses four data structures : .A list Left of partially processed tokens , where Left[i ] is the i+1th token in the list , with the first token being Left[0 ] .","label":"Uses","metadata":{},"score":"65.60711"}
{"text":"Simply using the system \" out of the box \" with default settings is likely to result in sub - optimal performance and should not be used as a reference in comparative parser evaluations ( unless it is explicitly stated that it is a non - optimized version of the system ) .","label":"Uses","metadata":{},"score":"65.681335"}
{"text":"We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .","label":"Uses","metadata":{},"score":"65.755066"}
{"text":"We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .","label":"Uses","metadata":{},"score":"65.755066"}
{"text":"We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .","label":"Uses","metadata":{},"score":"65.7551"}
{"text":"We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .","label":"Uses","metadata":{},"score":"65.7551"}
{"text":"Propagation .Since MaltParser 1.4 it is possible to propagate column values towards the root of the dependency graph when a labeled transition is performed .The propagation is managed by a propagation specification file formatted in XML with the following attributes : .","label":"Uses","metadata":{},"score":"65.849174"}
{"text":"Propagation .Since MaltParser 1.4 it is possible to propagate column values towards the root of the dependency graph when a labeled transition is performed .The propagation is managed by a propagation specification file formatted in XML with the following attributes : .","label":"Uses","metadata":{},"score":"65.849174"}
{"text":"Flow chart .MaltParser have seven pre - defined flow charts that describe what tasks MaltPasrer should perform .These seven flow charts are : .Name .Description . learn .Creates a Single Malt configuration and induces a parsing model from input data . parse .","label":"Uses","metadata":{},"score":"66.47842"}
{"text":"MaltParser 1.4.1 ----------------------------------------------------------------------------- MALT ( Models and Algorithms for Language Technology ) Group Vaxjo University and Uppsala University Sweden -----------------------------------------------------------------------------Usage : java -jar malt.jar -f . html .Here you can see the basic usage and options .To get all available options : .","label":"Uses","metadata":{},"score":"66.543236"}
{"text":"In Proceedings of the 11th International Conference on Parsing Technologies ( IWPT'09 ) .Nivre , J. and J. Nilsson ( 2005 )Pseudo - Projective Dependency Parsing .In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics , pp .","label":"Uses","metadata":{},"score":"66.59505"}
{"text":"In Proceedings of the 11th International Conference on Parsing Technologies ( IWPT'09 ) .Nivre , J. and J. Nilsson ( 2005 )Pseudo - Projective Dependency Parsing .In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics , pp .","label":"Uses","metadata":{},"score":"66.59505"}
{"text":"In MaltParser 1.4.1 , the values of options in the output option group must match the values of corresponding options in the input option group .This restriction is likely to be removed in later releases .This option tells the parser which format is used for the output data file .","label":"Uses","metadata":{},"score":"66.60826"}
{"text":"This line tells MaltParser to create a parsing model named test.mco ( also know as a Single Malt configuration file ) from the data in the file examples / data / talbanken05_train.conll .The parsing model gets its name from the configuration name , which is specified by the option flag -c without the file suffix .","label":"Uses","metadata":{},"score":"66.707344"}
{"text":"It is possible to define your own input / output format and then supply the data format specification file with the format option .Currently , MaltParser only supports tab - separated data files , which means that a sentence in a data file in the CoNLL data format could look like this : .","label":"Uses","metadata":{},"score":"67.226006"}
{"text":"Covington 's algorithm uses four data structures : .A list Left of partially processed tokens , where Left[i ] is the i+1th token in the list , with the first token being Left[0 ] .A list Right of remaining input tokens , where Right[i ] is the i+1th token in the list , with the first token being Right[0 ] .","label":"Uses","metadata":{},"score":"67.336685"}
{"text":"A Dependency - Driven Parser for German Dependency and Constituency Representations .In Proceedings of the ACL Workshop on Parsing German ( PaGe08 ) , June 20 , 2008 , Columbus , Ohio , US , pp .x - x .","label":"Uses","metadata":{},"score":"67.59303"}
{"text":"A Dependency - Driven Parser for German Dependency and Constituency Representations .In Proceedings of the ACL Workshop on Parsing German ( PaGe08 ) , June 20 , 2008 , Columbus , Ohio , US , pp .x - x .","label":"Uses","metadata":{},"score":"67.59303"}
{"text":"Stanford Typed Dependencies Representation .In Proceedings of the COLING'08 Workshop on Cross - Framework and Cross - Domain Parser Evaluation .Nivre J. , Hall J. , and Nilsson J. 2006 .Maltparser : A data - driven parser - generator for dependency parsing .","label":"Uses","metadata":{},"score":"67.685005"}
{"text":"Version of MaltParser and when it was built .SETTINGS .All option settings divided into several categories .DEPENDENCIES .In some cases the parser self - corrects when an illegal combination of options is specified or some option is missing .","label":"Uses","metadata":{},"score":"67.69435"}
{"text":"Version of MaltParser and when it was built .SETTINGS .All option settings divided into several categories .DEPENDENCIES .In some cases the parser self - corrects when an illegal combination of options is specified or some option is missing .","label":"Uses","metadata":{},"score":"67.69435"}
{"text":"We generalize the evaluation to other word - types , and show that the performance can be increased to 18 % relative by preserving part - of - speech equivalencies during translation .We further differentiate ourselves from previous work by conducting a second evaluation which examines the accuracy of translating all word types , rather than just nouns .","label":"Uses","metadata":{},"score":"67.714966"}
{"text":"We generalize the evaluation to other word - types , and show that the performance can be increased to 18 % relative by preserving part - of - speech equivalencies during translation .We further differentiate ourselves from previous work by conducting a second evaluation which examines the accuracy of translating all word types , rather than just nouns .","label":"Uses","metadata":{},"score":"67.714966"}
{"text":"In MaltParser 1.4.1 , the values of options in the input option group must match the values of corresponding options in the output option group .This restriction is likely to be removed in later releases .The input data file is specified by the infile option .","label":"Uses","metadata":{},"score":"67.73555"}
{"text":"Hall , J. and J. Nivre ( 2008 )A Dependency - Driven Parser for German Dependency and Constituency Representations .In Proceedings of the ACL Workshop on Parsing German ( PaGe08 ) , June 20 , 2008 , Columbus , Ohio , US , pp .","label":"Uses","metadata":{},"score":"67.922226"}
{"text":"Example : .This feature function returns the number of words occurring between the token on top of the stack and the first token in the input buffer , with discrete categories 0 , 1 , 2 - 4 and 5- .","label":"Uses","metadata":{},"score":"68.12404"}
{"text":"Example : .This feature function returns the number of words occurring between the token on top of the stack and the first token in the input buffer , with discrete categories 0 , 1 , 2 - 4 and 5- .","label":"Uses","metadata":{},"score":"68.12404"}
{"text":"An Improved Oracle for Dependency Parsing with Online Reordering .In Proceedings of 11th International Conference on Parsing Technologies ( IWPT ) , Paris , France , pp . to appear .Nivre , J. ( 2009 ) Non - Projective Dependency Parsing in Expected Linear Time .","label":"Uses","metadata":{},"score":"68.32551"}
{"text":"Transition - Based Natural Language Parsing with Dependency and Constituency Representations .Acta Wexionensia , No 152/2008 , Computer Science , Växjö University ( PhD Thesis ) [ pdf ] .Nivre , J. ( 2008 ) Algorithms for Deterministic Incremental Dependency Parsing .","label":"Uses","metadata":{},"score":"68.414566"}
{"text":"Finally , the character encoding can be specified with the charset option and this option is used by MaltParser to define the java class Charset .Parsing Algorithm .Any deterministic parsing algorithm compatible with the MaltParser architecture can be implemented in the MaltParser package .","label":"Uses","metadata":{},"score":"68.51062"}
{"text":"MaltParser 1.1 and later versions can be turned into a phrase structure parser that recovers both continuous and discontinuous phrases with both phrase labels and grammatical functions .Each edge label in the dependency graph is a quadruple consisting of four sublabels ( DEPREL , HEADREL , PHRASE , ATTACH ) .","label":"Uses","metadata":{},"score":"68.58333"}
{"text":"Chang , C.-C. and Lin , C.-J. ( 2001 )LIBSVM : a library for support vector machines .Fan , R.-E. , Chang , K.-W. , Hsieh , C.-J. , Wang , X.-R. and Lin , C.-J. ( 2008 )LIBLINEAR :","label":"Uses","metadata":{},"score":"68.68506"}
{"text":"An Improved Oracle for Dependency Parsing with Online Reordering .In Proceedings of the 11th International Conference on Parsing Technologies ( IWPT ) , 73 - 76 .Start using MaltParser .This section contains a short guide to get familiar with MaltParser .","label":"Uses","metadata":{},"score":"68.71571"}
{"text":"The corpus is annotated with 31 part - of - speech tags .The treebank annotation scheme is based on Stanford Typed Dependencies ( de Marneffe et al . , 2006 ; de Marneffe and Manning , 2008 ) .Previous releases : .","label":"Uses","metadata":{},"score":"68.89392"}
{"text":"Covington 's algorithm ( Covington 2001 ) is a quadratic - time algorithm for unrestricted dependency structures , which proceeds by trying to link each new token to each preceding token .It can be run in a projective ( -a covproj ) mode , where the linking operation is restricted to projective dependency structures , or in a non - projective ( -a covnonproj ) mode , allowing non - projective ( but acyclic ) dependency structures .","label":"Uses","metadata":{},"score":"68.905"}
{"text":"We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .","label":"Uses","metadata":{},"score":"68.970146"}
{"text":"We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .","label":"Uses","metadata":{},"score":"68.970146"}
{"text":"We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .","label":"Uses","metadata":{},"score":"68.970146"}
{"text":"We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .","label":"Uses","metadata":{},"score":"68.970146"}
{"text":"Hall , J. , Nilsson , J. and Nivre , J. ( 2009 ) Single Malt or Blended ?A Study in Multilingual Parser Optimization .In Bunt , H. , Merlo , P. and Nivre , J. ( eds . )","label":"Uses","metadata":{},"score":"69.021866"}
{"text":"The information is grouped into different categories : .Category .Description .CONFIGURATION .The name and type of the configuration and the date when it was created .SYSTEM .Information about the system that was used when creating the configuration , such as processor , operating system and version of Java Runtime Environment ( JRE ) .","label":"Uses","metadata":{},"score":"69.070786"}
{"text":"Just like Nivre 's algorithm , the Planar algorithm uses two data structures : .A stack Stack of partially processed tokens , where Stack[i ] is the i+1th token from the top of the stack , with the top being Stack[0 ] .","label":"Uses","metadata":{},"score":"69.10066"}
{"text":"Just like Nivre 's algorithm , the Planar algorithm uses two data structures : .A stack Stack of partially processed tokens , where Stack[i ] is the i+1th token from the top of the stack , with the top being Stack[0 ] .","label":"Uses","metadata":{},"score":"69.10066"}
{"text":"Element .Description . experiment .All other elements must be enclosed by an experiment element . optioncontainer .It is possible to have one or more option containers , but MaltParser 1.4.1 only uses the first option container .Later releases may make use of multiple option containers , for instance , to build ensemble systems . optiongroup .","label":"Uses","metadata":{},"score":"69.14743"}
{"text":"Note :Usually this will result in a slight drop in accuracy but a significant decrease in learning time .The option data_split_threshold specifies the frequency threshold for training a separate model .For example , -T 100 means that all training sets that contain less than 100 instances will be merged into a default training set .","label":"Uses","metadata":{},"score":"69.47807"}
{"text":"It is not a good idea to use fine - grained features , such as LEMMA or FORM , since this would result in thousands of models .For some learning methods ( like LIBSVM ) it is impractical to induce a single model based on all training instances .","label":"Uses","metadata":{},"score":"69.57045"}
{"text":"Seraji , Mojgan .Morphosyntactic Corpora and Tools for Persian .Doctoral dissertation , Uppsala University .Studia Linguistica Upsaliensia 16 .[ pdf ] Start using MaltParser .This section contains a short guide to get familiar with MaltParser .We start by running MaltParser without any arguments by typing the following at the command line prompt ( it is important that you are in the malt-1.4.1 directory ) : .","label":"Uses","metadata":{},"score":"70.22565"}
{"text":"LIBLINEAR :A library for large linear classification .Journal of Machine Learning Research 9 , 1871 - 1874 .Hall , J. ( 2008 )Transition - Based Natural Language Parsing with Dependency and Constituency Representations .Acta Wexionensia , No 152/2008 , Computer Science , Växjö University ( PhD Thesis ) .","label":"Uses","metadata":{},"score":"70.24453"}
{"text":"The prediction strategy -gdsT.TRANS;A.DEPREL , A.HEADREL , A.PHRASE , A.ATTACH tells the parser to first predict the transition T.TRANS and if it is a left or right arc transition it continues to predict the sublabels A.DEPREL , A.HEADREL , A.PHRASE and A.ATTACH in that order .","label":"Uses","metadata":{},"score":"70.2686"}
{"text":"Combines the prediction of the transition ( T.TRANS ) and the arc label ( A.DEPREL ) .This is the default setting of MaltParser 1.1 and was the only setting available for previous versions of MaltParser .T.TRANS , A.DEPREL .First predicts the transition ( T.TRANS ) and continues to predict the arc label ( A.DEPREL ) if the transition requires an arc label .","label":"Uses","metadata":{},"score":"70.54248"}
{"text":"Combines the prediction of the transition ( T.TRANS ) and the arc label ( A.DEPREL ) .This is the default setting of MaltParser 1.1 and was the only setting available for previous versions of MaltParser .T.TRANS , A.DEPREL .First predicts the transition ( T.TRANS ) and continues to predict the arc label ( A.DEPREL ) if the transition requires an arc label .","label":"Uses","metadata":{},"score":"70.54248"}
{"text":"However , parsing accuracies for Arabic usually lag behind non - semitic languages .Moreover , whil ...Tools . by Kuzman Ganchev , Jennifer Gillenwater , Ben Taskar - In ACL - IJCNLP , 2009 . \" ...Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .","label":"Uses","metadata":{},"score":"70.637695"}
{"text":"Chang , C.-C. and C.-J. Lin ( 2001 ) .LIBSVM : A Library for Support Vector Machines .[ pdf ] .Collins , M. ( 1999 ) .Head - Driven Statistical Models for Natural Language Parsing .Ph . D. thesis , University of Pennsylvania .","label":"Uses","metadata":{},"score":"70.830666"}
{"text":"For more information see the user guide : Define your own input / output format .There are already two data format specification files in the MaltParser distribution ( included in malt.jar ) : . graph .By default , the maximum sentence length is 256 tokens .","label":"Uses","metadata":{},"score":"70.90527"}
{"text":"With the data_split_column , data_split_structure and data_split_threshold options it is possible to define how the guide should split up the training instances to train several models .Note :Usually this will result in a slight drop in accuracy but a significant decrease in learning time .","label":"Uses","metadata":{},"score":"70.99225"}
{"text":"The Stack algorithms are described in Nivre ( 2009 ) and Nivre , Kuhlmann and Hall ( 2009 ) .The Stack algorithms use three data structures : .A stack Stack of partially processed tokens , where Stack[i ] is the i+1th token from the top of the stack , with the top being Stack[0 ] .","label":"Uses","metadata":{},"score":"71.02917"}
{"text":"The Stack algorithms are described in Nivre ( 2009 ) and Nivre , Kuhlmann and Hall ( 2009 ) .The Stack algorithms use three data structures : .A stack Stack of partially processed tokens , where Stack[i ] is the i+1th token from the top of the stack , with the top being Stack[0 ] .","label":"Uses","metadata":{},"score":"71.02917"}
{"text":"It is possible to have one or more option containers , but MaltParser 1.8.1 only uses the first option container .Later releases may make use of multiple option containers , for instance , to build ensemble systems . optiongroup .There can be one or more option group elements within an option container .","label":"Uses","metadata":{},"score":"71.25612"}
{"text":"Natural Language Engineering , 13(2 ) , 95 - 135 .[ pdf ] .Hall , J. , J. Nivre and J. Nilsson .( 2007 )A hybrid constituency - dependency parser for Swedish .In Proceedings of NODALIDA-2007 , Tartu , Estonia , pp .","label":"Uses","metadata":{},"score":"71.644646"}
{"text":"During parsing , the parsing algorithm requests the prediction of parser actions from the guide , which means that the guide prepares the feature vectors that are sent to the classifier ( which makes use of the model induced in the learning phase ) .","label":"Uses","metadata":{},"score":"71.7514"}
{"text":"2-Planar .The 2-Planar algorithm ( Gómez - Rodríguez and Nivre , 2010 ) is a linear - time algorithm that can be used to parse 2-planar dependency structures , i.e. , those whose links may be coloured with two colours in such a way that no two same - coloured links cross .","label":"Uses","metadata":{},"score":"71.93561"}
{"text":"2-Planar .The 2-Planar algorithm ( Gómez - Rodríguez and Nivre , 2010 ) is a linear - time algorithm that can be used to parse 2-planar dependency structures , i.e. , those whose links may be coloured with two colours in such a way that no two same - coloured links cross .","label":"Uses","metadata":{},"score":"71.93561"}
{"text":"Inductive Dependency Parsing .MaltParser can be characterized as a data - driven parser - generator .While a traditional parser - generator constructs a parser given a grammar , a data - driven parser - generator constructs a parser given a treebank .","label":"Uses","metadata":{},"score":"72.28226"}
{"text":"The option --singlemalt - use_partial_tree need to be set to true by using the command line flag -up true .The two data columns should look like these : .Note : To benefit from the partial dependency structure , the parser model should also be trained on partial trees .","label":"Uses","metadata":{},"score":"72.66633"}
{"text":"The option --singlemalt - use_partial_tree need to be set to true by using the command line flag -up true .The two data columns should look like these : .Note : To benefit from the partial dependency structure , the parser model should also be trained on partial trees .","label":"Uses","metadata":{},"score":"72.66633"}
{"text":"In Proceedings of the fifth international conference on Language Resources and Evaluation ( LREC2006 ) , May 24 - 26 , 2006 , Genoa , Italy , pp .2216 - 2219 [ pdf ] .Nivre , J. ( 2007 ) .","label":"Uses","metadata":{},"score":"72.68798"}
{"text":"MaltParser can also be used to deprojectivize a projective file containing pseudo - projective encoding , with or without involving parsing , where it is assumed that the configuration pproj contains the same encoding scheme as during projectivization .It could look like this : .","label":"Uses","metadata":{},"score":"72.736404"}
{"text":"They also permit the use of well - understood , generalpurpose learning algorithms .There has been an increased interest in using probabilistic grammars in the Bayesian setting .To date , most of the literature has focused on using a Dirichlet prior .","label":"Uses","metadata":{},"score":"72.74596"}
{"text":"They also permit the use of well - understood , generalpurpose learning algorithms .There has been an increased interest in using probabilistic grammars in the Bayesian setting .To date , most of the literature has focused on using a Dirichlet prior .","label":"Uses","metadata":{},"score":"72.74596"}
{"text":"FEATURE MODEL .Outputs the content of the feature specification file .INTERFACE .Information about the interface to the learner , in this case LIBSVM .SETTINGS .All settings of specific learner options , in this case LIBSVM .Unpack a configuration .","label":"Uses","metadata":{},"score":"72.81383"}
{"text":"par ( see user guide of MaltParser 0.x ( C - impl )Feature Models ) .If no feature specification file is specified , the parser will use a default feature model specification for the given parsing algorithm that is included in the MaltParser distribution ( included in the malt.jar file ) .","label":"Uses","metadata":{},"score":"72.86099"}
{"text":"The Planar algorithm ( Gómez - Rodríguez and Nivre , 2010 ) is a linear - time algorithm limited to planar dependency structures , the set of structures that do not contain any crossing links .It works in a similar way to Nivre 's algorithm in arc - eager mode , but with more fine - grained transitions .","label":"Uses","metadata":{},"score":"72.965805"}
{"text":"The Planar algorithm ( Gómez - Rodríguez and Nivre , 2010 ) is a linear - time algorithm limited to planar dependency structures , the set of structures that do not contain any crossing links .It works in a similar way to Nivre 's algorithm in arc - eager mode , but with more fine - grained transitions .","label":"Uses","metadata":{},"score":"72.965805"}
{"text":"To train a default parsing model with MaltParser type the following at the command line prompt : .This line tells MaltParser to create a parsing model named test.mco ( also know as a Single Malt configuration file ) from the data in the file examples / data / talbanken05_train.conll .","label":"Uses","metadata":{},"score":"72.999115"}
{"text":"To run MaltParser with the above option file type : . xml .This command will create a configuration file example1.mco based on the settings in the option file .It is possible to override the options by command - line options , for example : . xml -a nivreeager .","label":"Uses","metadata":{},"score":"73.157"}
{"text":"For more information about how to use MaltParserService , please see the examples provided in the directory examples / apiexamples / srcex / org / maltparser / examples / old .To compile the old examples ( srcex / org / maltparser / examples / old ) used by MaltParser-1.7.2 and previous versions of MaltParser . javac -d classes -cp .","label":"Uses","metadata":{},"score":"73.35985"}
{"text":"The bottom half specifies that DEPREL values should be copied to the VALENCY field of the head , whenever an arc labeled by one of the labels listed in the FOR parameter is created .Provided that these labels denote valency - bound functions , this will have the effect of propagating information about satisfaction of valency constraints to the head .","label":"Uses","metadata":{},"score":"73.56106"}
{"text":"The bottom half specifies that DEPREL values should be copied to the VALENCY field of the head , whenever an arc labeled by one of the labels listed in the FOR parameter is created .Provided that these labels denote valency - bound functions , this will have the effect of propagating information about satisfaction of valency constraints to the head .","label":"Uses","metadata":{},"score":"73.56106"}
{"text":"First predicts the transition ( T.TRANS ) and if the transition does not require any arc label then the nondeterminism is resolved , but if the predicted transition requires an arc label then the parser continues to predict the arc label .","label":"Uses","metadata":{},"score":"73.65907"}
{"text":"First predicts the transition ( T.TRANS ) and if the transition does not require any arc label then the nondeterminism is resolved , but if the predicted transition requires an arc label then the parser continues to predict the arc label .","label":"Uses","metadata":{},"score":"73.65907"}
{"text":"The value returned is ( a category corresponding to ) the greatest integer in the normalization string that is smaller than or equal to the exact number .Example : .This feature function returns the number of left dependents of the token on top of the stack , with discrete categories 0 , 1 , 2 - 4 and 5- .","label":"Uses","metadata":{},"score":"73.70333"}
{"text":"The value returned is ( a category corresponding to ) the greatest integer in the normalization string that is smaller than or equal to the exact number .Example : .This feature function returns the number of left dependents of the token on top of the stack , with discrete categories 0 , 1 , 2 - 4 and 5- .","label":"Uses","metadata":{},"score":"73.70333"}
{"text":"Returns the ancestor of the graph node if defined ; otherwise , a null - value .panc .Returns the proper ancestor of the graph node if defined ; otherwise , a null - value .ldesc .Returns the leftmost descendant of the graph node if defined ; otherwise , a null - value .","label":"Uses","metadata":{},"score":"73.94821"}
{"text":"Returns the ancestor of the graph node if defined ; otherwise , a null - value .panc .Returns the proper ancestor of the graph node if defined ; otherwise , a null - value .ldesc .Returns the leftmost descendant of the graph node if defined ; otherwise , a null - value .","label":"Uses","metadata":{},"score":"73.94821"}
{"text":"Creates a configuration and projectivizes input data without inducing a parsing model .Get configuration information .Sometimes it is useful to get information about a configuration , for instance , to know which settings have been used when creating the configuration .","label":"Uses","metadata":{},"score":"74.24263"}
{"text":"Creates a configuration and projectivizes input data without inducing a parsing model .Get configuration information .Sometimes it is useful to get information about a configuration , for instance , to know which settings have been used when creating the configuration .","label":"Uses","metadata":{},"score":"74.24263"}
{"text":"In both cases , unattached tokens are attached to the special root node with the default label after parsing is completed .libsvm .There are many LIBSVM options ( see LIBSVM Documentation ) .Note that all whitespace is replaced by underscore if this option is specified in the command - line prompt .","label":"Uses","metadata":{},"score":"74.39491"}
{"text":"It will perform a left - to - right search to find the leftmost lexical child .If no lexical child can be found , the head - child of the phrase will be the leftmost phrase child and the lexical head will be the lexical child of the head child recursively .","label":"Uses","metadata":{},"score":"74.41265"}
{"text":"The kbest option indicates how many items the k - best list should contain .If -k -1 , all possible parser actions are ranked in the k - best list .If -k 1 , there is only one prediction in the k - best list .","label":"Uses","metadata":{},"score":"74.64105"}
{"text":"Their symbolic component is amenable to inspection by humans , while their probabilistic component helps resolve ambiguity .They also permit the use of well - understood , generalpurpose learn ... \" .Probabilistic grammars offer great flexibility in modeling discrete sequential data like natural language text .","label":"Uses","metadata":{},"score":"74.754944"}
{"text":"Their symbolic component is amenable to inspection by humans , while their probabilistic component helps resolve ambiguity .They also permit the use of well - understood , generalpurpose learn ... \" .Probabilistic grammars offer great flexibility in modeling discrete sequential data like natural language text .","label":"Uses","metadata":{},"score":"74.754944"}
{"text":"/data / swemalt - mini / swedish - swap . xml .Note that swemalt - mini . swemalt - mini . java -cp classes : . /maltparser-1.8.1.jar org.maltparser.examples.ParseSentence1 java -cp classes : . /maltparser-1.8.1.jar org.maltparser.examples.ParseSentence2 java -cp classes : . /maltparser-1.8.1.jar org.maltparser.examples.","label":"Uses","metadata":{},"score":"74.9673"}
{"text":"For example with the Nivre arc - eager algorithm , it is possible to first predict the transition ; if the transition is SHIFT or REDUCE the nondeterminism is resolved , but if the predicted transition is RIGHT - ARC or LEFT - ARC the parser continues to predict the arc label .","label":"Uses","metadata":{},"score":"75.38503"}
{"text":"none : Excludes all kinds of null - values when extracting the feature vector , this option value is not possible for learning methods that have symbolic feature vector encoding .one : Maps all kinds of null values to one symbol .","label":"Uses","metadata":{},"score":"75.45665"}
{"text":"CONFIGURATION Configuration name : test Configuration type : singlemalt Created : Sun Jul 15 11:59:37 CEST 2010 SYSTEM Operating system architecture : amd64 Operating system name : Linux JRE vendor name : Sun Microsystems Inc.The information is grouped into different categories : .","label":"Uses","metadata":{},"score":"75.60426"}
{"text":"We consider generative and di ... \" .Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .The wide availability of parallel text and accurate parsers in English has opened up the possibility of grammar induction through partial transfer across bitext .","label":"Uses","metadata":{},"score":"75.89798"}
{"text":"We consider generative and di ... \" .Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .The wide availability of parallel text and accurate parsers in English has opened up the possibility of grammar induction through partial transfer across bitext .","label":"Uses","metadata":{},"score":"75.89798"}
{"text":"Below you can see an example of a propagation specification file : .The top half specifies that POSTAG values should be copied to the CJ - POSTAG field of the head , whenever an arc with the label CJ ( for conjunct ) is created .","label":"Uses","metadata":{},"score":"76.020706"}
{"text":"Below you can see an example of a propagation specification file : .The top half specifies that POSTAG values should be copied to the CJ - POSTAG field of the head , whenever an arc with the label CJ ( for conjunct ) is created .","label":"Uses","metadata":{},"score":"76.020706"}
{"text":"Yet , various grammar parameters are expected to be correlated because the elements in language they represent share linguistic properties .In this paper , we suggest an alternative to the Dirichlet prior , a family of logistic normal distributions .We derive an inference algorithm for this family of distributions and experiment with the task of dependency grammar induction , demonstrating performance improvements with our priors on a set of six treebanks in different natural languages .","label":"Uses","metadata":{},"score":"76.03381"}
{"text":"Yet , various grammar parameters are expected to be correlated because the elements in language they represent share linguistic properties .In this paper , we suggest an alternative to the Dirichlet prior , a family of logistic normal distributions .We derive an inference algorithm for this family of distributions and experiment with the task of dependency grammar induction , demonstrating performance improvements with our priors on a set of six treebanks in different natural languages .","label":"Uses","metadata":{},"score":"76.03381"}
{"text":"All option settings that can not be changed during parsing . symboltables.sym .All distinct symbols in the training data , divided into different columns .For example , the column POSTAG in the CoNLL format has its own symbol table with all distinct values occurring in the training data . test_singlemalt . info .","label":"Uses","metadata":{},"score":"76.636215"}
{"text":"To globally model parsing actions of all steps that are taken on the inpu ... \" .Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .They only determine parsing actions stepwisely by a trained classifier .","label":"Uses","metadata":{},"score":"76.64011"}
{"text":"To globally model parsing actions of all steps that are taken on the inpu ... \" .Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .They only determine parsing actions stepwisely by a trained classifier .","label":"Uses","metadata":{},"score":"76.64011"}
{"text":"We present an evaluation measure that takes into account the possibility of incompatible token segmentation between the gold standard and the parsed data .Results indicate that ( a ) MST - parser performs better on Hebrew data than Malt - Parser , and ( b ) both parsers do not make good use of morphological information when parsing Hebrew . ... s on Hebrew dependency parsing .","label":"Uses","metadata":{},"score":"76.77693"}
{"text":"We present an evaluation measure that takes into account the possibility of incompatible token segmentation between the gold standard and the parsed data .Results indicate that ( a ) MST - parser performs better on Hebrew data than Malt - Parser , and ( b ) both parsers do not make good use of morphological information when parsing Hebrew . ... s on Hebrew dependency parsing .","label":"Uses","metadata":{},"score":"76.77697"}
{"text":"_ P IP _ 2 IP _ _ .Finally , the character encoding can be specified with the charset option and this option is used by MaltParser to define the java class Charset .Parsing Algorithm .Any deterministic parsing algorithm compatible with the MaltParser architecture can be implemented in the MaltParser package .","label":"Uses","metadata":{},"score":"77.17404"}
{"text":"The option is only relevant during processing ( parsing ) . save .The option is saved during learning and can not be overridden during processing ( parsing ) .All the option groups and options are described in detail below .","label":"Uses","metadata":{},"score":"77.20259"}
{"text":"Description .CONFIGURATION .The name and type of the configuration and the date when it was created .SYSTEM .Information about the system that was used when creating the configuration , such as processor , operating system and version of Java Runtime Environment ( JRE ) .","label":"Uses","metadata":{},"score":"77.28641"}
{"text":"Configuration .The purpose of the configuration is to gather information about all settings and files into one file .During learning , the configuration is created and stored in a configuration file with the file suffix .mco .This configuration file can later be reused whenever the trained model is used to parse new data .","label":"Uses","metadata":{},"score":"77.43099"}
{"text":"There are seven dependency graph address functions : . head .Returns the head of the graph node if defined ; otherwise , a null - value . ldep .Returns the leftmost ( left ) dependent of the graph node if defined ; otherwise , a null - value . rdep .","label":"Uses","metadata":{},"score":"77.43405"}
{"text":"There are seven dependency graph address functions : . head .Returns the head of the graph node if defined ; otherwise , a null - value . ldep .Returns the leftmost ( left ) dependent of the graph node if defined ; otherwise , a null - value . rdep .","label":"Uses","metadata":{},"score":"77.43405"}
{"text":"Unpack a configuration .This command will create a new directory test containing the following files : .File .All distinct symbols in the training data , divided into different columns .For example , the column POSTAG in the CoNLL format has its own symbol table with all distinct values occurring in the training data .","label":"Uses","metadata":{},"score":"77.58398"}
{"text":"Given that you have training data in the file train.negra formatted as above and a feature specification file , type the following at the command line prompt : .This command will create testps.mco containing a parser model for parsing phrase structure .","label":"Uses","metadata":{},"score":"77.632"}
{"text":"This option guarantees that the dependency graph obtained counting links to the dummy root node is planar and connected . full .Enforce full connectedness by not only not allowing to reduce the last node in a component , but not allowing to shift the last word if the graph is not connected .","label":"Uses","metadata":{},"score":"77.64549"}
{"text":"Maps a feature value onto a new set of values and takes as arguments a feature specification and one or more arguments that control the mapping .There is one feature map function : .Split .Splits the feature value into a set of feature values .","label":"Uses","metadata":{},"score":"77.93101"}
{"text":"Maps a feature value onto a new set of values and takes as arguments a feature specification and one or more arguments that control the mapping .There is one feature map function : .Split .Splits the feature value into a set of feature values .","label":"Uses","metadata":{},"score":"77.93101"}
{"text":"The reduce on switch option can be used to change the specific behaviour of Switch transitions , while the planar root handling option can be employed to change the algorithm 's behavior with respect to root tokens .The 2-Planar algorithm uses three data structures : .","label":"Uses","metadata":{},"score":"78.194565"}
{"text":"The reduce on switch option can be used to change the specific behaviour of Switch transitions , while the planar root handling option can be employed to change the algorithm 's behavior with respect to root tokens .The 2-Planar algorithm uses three data structures : .","label":"Uses","metadata":{},"score":"78.194565"}
{"text":"Note : There can be a slight differences in accuracy between using the internal LIBSVM learner and the external LIBSVM learner , due to different versions of LIBSVM and the precision in assigning floating - point parameters .liblinear .Liblinear have several options ( see liblinear Documentation ) that you can specify with this options .","label":"Uses","metadata":{},"score":"78.37192"}
{"text":"Returns the proper leftmost descendant of the graph node if defined ; otherwise , a null - value . rdesc .Returns the rightmost descendant of the graph node if defined ; otherwise , a null - value . prdesc .Returns the proper rightmost descendant of the graph node if defined ; otherwise , a null - value .","label":"Uses","metadata":{},"score":"78.55008"}
{"text":"Returns the proper leftmost descendant of the graph node if defined ; otherwise , a null - value . rdesc .Returns the rightmost descendant of the graph node if defined ; otherwise , a null - value . prdesc .Returns the proper rightmost descendant of the graph node if defined ; otherwise , a null - value .","label":"Uses","metadata":{},"score":"78.55008"}
{"text":"Now we are ready to train our first parsing model .In the directory examples / data there are two data files talbanken05_train . conll and talbanken05_test .conll , which contain very small portions of the Swedish treebank Talbanken05 .The example data sets are formatted according to the CoNLL data format .","label":"Uses","metadata":{},"score":"78.619995"}
{"text":"MaltParser API .From version MaltParser-1.8 there is a new interface to MaltParser located in org.maltparser.concurrent and contains following classes : .org.maltparser.concurrent.ConcurrentMaltParserModel .org.maltparser.concurrent.ConcurrentMaltParserService .org.maltparser.concurrent.ConcurrentUtils .This interface can only be used during parsing time and can hopefully be used in a multi - threaded environment .","label":"Uses","metadata":{},"score":"78.63649"}
{"text":"Takes three arguments , an address function , a relation name , and a normalization string , and returns the number of nodes having the specified relation to the node identified by the address function .Valid relation names are ldeps and rdeps and deps ( for left dependent , right dependent and dependent , respectively ) .","label":"Uses","metadata":{},"score":"78.9506"}
{"text":"INPUT .Input data in both learning and parsing mode , such as part - of - speech tags or word forms .DEPENDENCY_EDGE_LABEL .Column containing a dependency label .If the parser is to learn to produce labeled dependency graphs , these must be present in learning mode .","label":"Uses","metadata":{},"score":"78.97212"}
{"text":"The --graph - head_rules option ( -ghr flag ) specifies the URL or the path to a file that contains a list of head rules .MaltParser API .Other programs can invoke Maltparser in various ways , but the easiest way is to use the org.maltparser.","label":"Uses","metadata":{},"score":"79.01158"}
{"text":"In practice , however , this will probably have little impact for the parsing accuracy .Deprojectivize input data .MaltParser can also be used to deprojectivize a projective file containing pseudo - projective encoding , with or without involving parsing , where it is assumed that the configuration pproj contains the same encoding scheme as during projectivization .","label":"Uses","metadata":{},"score":"79.14471"}
{"text":"Later releases may contain additional configuration types .For example , one type could be an ensemble parser configuration containing many single malt configurations .In contrast to the system - verbosity option , the logging option controls the level of verbosity of an individual configuration .","label":"Uses","metadata":{},"score":"79.23852"}
{"text":"which will create a configuration based on the same setting except the parsing algorithm is now nivreeager instead of nivrestandard .If you want to create a configuration that has the same settings as the option file with command - line options , you need to type : .","label":"Uses","metadata":{},"score":"79.45082"}
{"text":"This option is deprecated , there is no upper limit of the sentence length . planar .none .Do n't enforce connectedness at all , words whose head the parser does n't know will be linked to the root node .","label":"Uses","metadata":{},"score":"79.667076"}
{"text":"( See Nivre & Nilsson ( 2005 ) for more details concerning the encoding schemes . )A dependency file can be projectivized using the head encoding by typing : .There is one additional option for the projectivization called covered_root , which is mainly used for handling dangling punctuation .","label":"Uses","metadata":{},"score":"79.76011"}
{"text":"( See Nivre & Nilsson ( 2005 ) for more details concerning the encoding schemes . )A dependency file can be projectivized using the head encoding by typing : .There is one additional option for the projectivization called covered_root , which is mainly used for handling dangling punctuation .","label":"Uses","metadata":{},"score":"79.76011"}
{"text":"Deterministic Dependency Parsing of English Text .In Proceedings of COLING 2004 , Geneva , Switzerland , August 23 - 27 , 2004 .[ pdf ] .Nivre , J. and J. Nilsson ( 2005 )Pseudo - Projective Dependency Parsing .","label":"Uses","metadata":{},"score":"80.08215"}
{"text":"most languages are projective .In Figure 8 An example Chinese dependency tree .Although non - projec ... . \" ...Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .","label":"Uses","metadata":{},"score":"80.13466"}
{"text":"most languages are projective .In Figure 8 An example Chinese dependency tree .Although non - projec ... . \" ...Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .","label":"Uses","metadata":{},"score":"80.13466"}
{"text":"Controlling MaltParser .MaltParser can be controlled by specifying values for a range of different options .The values for these option can be specified in different ways : .Method .Description .Example .Command - line option flag .","label":"Uses","metadata":{},"score":"80.28886"}
{"text":"Takes three arguments , two address functions and a normalization string , and returns the string distance ( number of intervening words ) between the words identified by the address functions .The list must start with 0 and be sorted in ascending order .","label":"Uses","metadata":{},"score":"80.349915"}
{"text":"Takes three arguments , two address functions and a normalization string , and returns the string distance ( number of intervening words ) between the words identified by the address functions .The list must start with 0 and be sorted in ascending order .","label":"Uses","metadata":{},"score":"80.349915"}
{"text":"LIBSVM .LIBSVM ( Chang and Lin 2001 ) is a machine learning package for support vector machines with different kernels .Information about different options can be found on the LIBSVM web site .LIBLINEAR .LIBLINEAR ( Fan et al .","label":"Uses","metadata":{},"score":"80.692726"}
{"text":"You can start to optimize the feature model by using this file examples / covnonproj_ps.xml .We use the Covington non - projective parsing algorithm , because it is capable of parsing non - projective dependency graphs ( a discontinuous phrase structure will result in a non - projective dependency graph ) .","label":"Uses","metadata":{},"score":"80.69806"}
{"text":"To differentiate the feature model when using sequential prediction you can specify two submodels for T.TRANS and A.DEPREL .Here is a truncated example : .When using branching prediction it is possible to use three submodels ( T.TRANS , RA.A.DEPREL and LA.A.DEPREL ) , where RA denotes the right arc model and LA the left arc model : .","label":"Uses","metadata":{},"score":"81.11719"}
{"text":"To differentiate the feature model when using sequential prediction you can specify two submodels for T.TRANS and A.DEPREL .Here is a truncated example : .When using branching prediction it is possible to use three submodels ( T.TRANS , RA.A.DEPREL and LA.A.DEPREL ) , where RA denotes the right arc model and LA the left arc model : .","label":"Uses","metadata":{},"score":"81.11719"}
{"text":"For instance , 14.4 % of section 23 is tagged differently by ( 1 ) and ( 2 ) 8 .5 The Neutral Edge Direction ( NED ) Me ... . by Shay B. Cohen , Noah A. Smith , Alex Clark , Dorota Glowacka , Colin De La Higuera , Mark Johnson , John Shawe - taylor . \" ...","label":"Uses","metadata":{},"score":"81.28746"}
{"text":"For instance , 14.4 % of section 23 is tagged differently by ( 1 ) and ( 2 ) 8 .5 The Neutral Edge Direction ( NED ) Me ... . by Shay B. Cohen , Noah A. Smith , Alex Clark , Dorota Glowacka , Colin De La Higuera , Mark Johnson , John Shawe - taylor . \" ...","label":"Uses","metadata":{},"score":"81.28746"}
{"text":"Same as DEPENDENCY_EDGE_LABEL , used by MaltParser version 1.0 - 1.1 .PHRASE_STRUCTURE_EDGE_LABEL .Column containing a phrase structure edge label .PHRASE_STRUCTURE_NODE_LABEL .Column containing a phrase category label .SECONDARY_EDGE_LABEL .Column containing a secondary edge label .HEAD .","label":"Uses","metadata":{},"score":"81.405365"}
{"text":"To parse type the following : .Controlling MaltParser .MaltParser can be controlled by specifying values for a range of different options .The values for these option can be specified in different ways : .Method .Description .Example .","label":"Uses","metadata":{},"score":"81.66054"}
{"text":"To parse type the following : .The input file must contain four columns : WORD , LEMMA , POS , MORPH .A test file can look like this : . ''Head - finding rules .It is possible to define your own head - finding rules in a file .","label":"Uses","metadata":{},"score":"81.674324"}
{"text":"If you want to create a configuration that has the same settings as the option file with command - line options , you need to type : .To parse using one of the three configurations you simply type : .Configuration .","label":"Uses","metadata":{},"score":"81.760956"}
{"text":"Here is an example ( examples / optionexample . xml ) : .To run MaltParser with the above option file type : . xml .This command will create a configuration file example1.mco based on the settings in the option file .","label":"Uses","metadata":{},"score":"81.96307"}
{"text":"A forest may be seen as a tree by considering all the roots linked to the dummy root node , but it need n't be planar when seen this way . reduceonly .The last node in a connected component can not be reduced .","label":"Uses","metadata":{},"score":"82.01941"}
{"text":"Takes three arguments , an address function , a relation name , and a normalization string , and returns the number of nodes having the specified relation to the node identified by the address function .Valid relation names are ldep , rdep and dep ( for left dependent , right dependent and dependent , respectively ) .","label":"Uses","metadata":{},"score":"82.08182"}
{"text":"ConcurrentExample1 java -cp classes : . /maltparser-1.8.1.jar org.maltparser.examples.ConcurrentExample2 java -cp classes : . /maltparser-1.8.1.jar org.maltparser.examples.ConcurrentExample3 .Old MaltParserService interface .Before MaltParser-1.8 there was another interface to MaltParser .Note that this interface can only be used in a single - threaded environment and the interface does n't use the light - weighted parser .","label":"Uses","metadata":{},"score":"82.34311"}
{"text":"Uppsala Persian Dependency Treebank : UPDT .Uppsala Persian Dependency Treebank ( UPDT ) ( Seraji , 2015 , Chapter 5 , pp .97 - 146 ) is a dependency - based syntactically annotated corpus .The treebank consists of 6000 sentences ( 151,671 tokens ) of written text in CoNLL - format and is developed through a bootstrapping procedure involving the open source data - driven dependency parser MaltParser ( Nivre et al . , 2006 ) , and manual validation of the annotation .","label":"Uses","metadata":{},"score":"82.345085"}
{"text":"If no lexical child can be found , then take the rightmost nonterminal child .Another example is CAT : AVP r r[LABEL : HD CAT : AVP ] , which first searches for an outgoing edge label HD if the parent nonterminal is labeled AVP .","label":"Uses","metadata":{},"score":"82.47642"}
{"text":"However , parsing accuracies for Arabic usually lag behind non - semitic languages .Moreover , whil ...","label":"Uses","metadata":{},"score":"82.7088"}
{"text":"To run the old examples .java -cp classes : . /maltparser-1.8.1.jar org.maltparser.examples.old.ReadWriteCoNLL ./data / talbanken05_test.conll out.conll ./appdata / dataformat / conllx .xml UTF-8 java -cp classes : . /maltparser-1.8.1.jar org.maltparser.examples.old.CreateDependencyGraph java -cp classes : . /maltparser-1.8.1.jar org.maltparser.examples.old.","label":"Uses","metadata":{},"score":"82.88838"}
{"text":"Nivre .Nivre 's algorithm ( Nivre 2003 , Nivre 2004 ) is a linear - time algorithm limited to projective dependency structures .It can be run in arc - eager ( -a nivreeager ) or arc - standard ( -a nivrestandard ) mode .","label":"Uses","metadata":{},"score":"82.946625"}
{"text":"Nivre .Nivre 's algorithm ( Nivre 2003 , Nivre 2004 ) is a linear - time algorithm limited to projective dependency structures .It can be run in arc - eager ( -a nivreeager ) or arc - standard ( -a nivrestandard ) mode .","label":"Uses","metadata":{},"score":"82.946625"}
{"text":"Example : .InputArcDir(PHEAD , Stack[0 ] ) .InputTable .Takes two arguments , a column name and an address function , and returns the column value for the node identified by the address function .The column name must correspond to a new column defined in a propagation specification and the address function must return a token node in the input string .","label":"Uses","metadata":{},"score":"82.99473"}
{"text":"Returns the predecessor of the graph node in the linear order of the input string if defined ; otherwise , a null - value . succ .Returns the successor of the graph node in the linear order of the input string if defined ; otherwise , a null - value .","label":"Uses","metadata":{},"score":"83.15223"}
{"text":"Returns the predecessor of the graph node in the linear order of the input string if defined ; otherwise , a null - value . succ .Returns the successor of the graph node in the linear order of the input string if defined ; otherwise , a null - value .","label":"Uses","metadata":{},"score":"83.15223"}
{"text":"This option specifies how a parser action is combined or divided .By default , arc label(s ) and transition are combined into one individual decision .For more information see the user guide : Prediction strategy .By default the combination of transition and dependency type into one class is separated by an underscore .","label":"Uses","metadata":{},"score":"83.42147"}
{"text":"Returns the next left ( same - side ) sibling of the graph node if defined ; otherwise , a null - value . rsib .Returns the next right ( same - side ) sibling of the graph node if defined ; otherwise , a null - value .","label":"Uses","metadata":{},"score":"83.45364"}
{"text":"Returns the next left ( same - side ) sibling of the graph node if defined ; otherwise , a null - value . rsib .Returns the next right ( same - side ) sibling of the graph node if defined ; otherwise , a null - value .","label":"Uses","metadata":{},"score":"83.45364"}
{"text":"FOR .A subset of values that can be copied ( other values will not be copied ) .If empty then all values will be copied .OVER .A subset of dependency labels that allow propagation when a labeled transition is performed .","label":"Uses","metadata":{},"score":"83.69012"}
{"text":"FOR .A subset of values that can be copied ( other values will not be copied ) .If empty then all values will be copied .OVER .A subset of dependency labels that allow propagation when a labeled transition is performed .","label":"Uses","metadata":{},"score":"83.69012"}
{"text":"Is a shorter version of Command - line option group and option name and can only be used when the option name is unambiguous .Option file .The option settings are specified in a option file , formatted in XML .","label":"Uses","metadata":{},"score":"84.14316"}
{"text":"Is a shorter version of Command - line option group and option name and can only be used when the option name is unambiguous .Option file .The option settings are specified in a option file , formatted in XML .","label":"Uses","metadata":{},"score":"84.14316"}
{"text":"conll , which contain very small portions of the Swedish treebank Talbanken05 .The example data sets are formatted according to the CoNLL data format .Note that these data sets are very small and that you need more training data to create a useful parsing model .","label":"Uses","metadata":{},"score":"84.161255"}
{"text":"The Projective Stack algorithm uses essentially the same transitions as the arc - standard version of Nivre 's algorithm and is limited to projective dependency trees .The Eager and Lazy Stack algorithms in addition make use of a swap transition , which makes it possible to derive arbitrary non - projective dependency trees .","label":"Uses","metadata":{},"score":"84.21474"}
{"text":"The configuration name is a name of your own choice .The option flag -i tells the parser where to find the input data .The last option flag -m specifies the processing mode learn ( as opposed to parse ) , since in this case we want to induce a model by using the default learning method ( LIBSVM ) .","label":"Uses","metadata":{},"score":"84.342804"}
{"text":"The latter specification format should be saved in a text file where the file name must end with the file suffix .par .Below you can see an example of the new XML format ( Nivre arc - eager default feature model ) : .","label":"Uses","metadata":{},"score":"84.651566"}
{"text":"The latter specification format should be saved in a text file where the file name must end with the file suffix .par .Below you can see an example of the new XML format ( Nivre arc - eager default feature model ) : .","label":"Uses","metadata":{},"score":"84.651566"}
{"text":"INPUT .Input data in both learning and parsing mode , such as part - of - speech tags or word forms .DEPENDENCY_EDGE_LABEL .Denote that the column contain a dependency label .If the parser is to learn to produce labeled dependency graph , these must be present in learning mode .","label":"Uses","metadata":{},"score":"84.68033"}
{"text":"( If the address function is undefined , a null - value is returned . )Example : .OutputColumn(DEPREL , Stack[0 ] ) .InputArc .Takes three arguments , a column name and two address functions , and returns LEFT , RIGHT or NULL depending on whether the column value defines a left - pointing , right - pointing or no arc between the two nodes identified by the address functions .","label":"Uses","metadata":{},"score":"84.72506"}
{"text":"( If the address function is undefined , a null - value is returned . )Example : .OutputColumn(DEPREL , Stack[0 ] ) .InputArc .Takes three arguments , a column name and two address functions , and returns LEFT , RIGHT or NULL depending on whether the column value defines a left - pointing , right - pointing or no arc between the two nodes identified by the address functions .","label":"Uses","metadata":{},"score":"84.72506"}
{"text":"/maltparser-1.8.1 . jar : . java .To run the examples you first need to create a Swedish parser model swemalt - mini .mco by using MaltParser : . java -jar . /maltparser-1.8.1.jar -w output -c swemalt - mini -i .","label":"Uses","metadata":{},"score":"84.780106"}
{"text":"The projecitivization and deprojectivization ( below ) , including the encoding schemes , are know as pseudo - projective transformations and are described in more detail in Nivre & Nilsson ( 2005 ) .The only difference compared to Nivre & Nilsson is that it is the most deeply nested non - projective arc that is lifted first , not the shortest one .","label":"Uses","metadata":{},"score":"85.456085"}
{"text":"The projecitivization and deprojectivization ( below ) , including the encoding schemes , are know as pseudo - projective transformations and are described in more detail in Nivre & Nilsson ( 2005 ) .The only difference compared to Nivre & Nilsson is that it is the most deeply nested non - projective arc that is lifted first , not the shortest one .","label":"Uses","metadata":{},"score":"85.456085"}
{"text":"If you have the LIBSVM package installed on your system then it is possible to use the C++ implementation of LIBSVM learner instead of the internal Java implementation ( libsvm.jar ) during learning time .It is very likely that the external C++ implementation is faster and uses less memory on your system .","label":"Uses","metadata":{},"score":"85.56364"}
{"text":"Name .Description . FROM .The data column from which the values are copied .TO .The data column to which the values are copied .This data column should not exist in the data format and the values are interpreted as sets .","label":"Uses","metadata":{},"score":"85.60675"}
{"text":"Name .Description . FROM .The data column from which the values are copied .TO .The data column to which the values are copied .This data column should not exist in the data format and the values are interpreted as sets .","label":"Uses","metadata":{},"score":"85.60675"}
{"text":"The file contains several head - finding rules ( one per row ) .The third column is a priority list of children .For example the first row CAT : AA r r[LABEL : HD ] indicates that the parser should first perform a right - to - left search for an outgoing edge with a label HD if the parent nonterminal is labeled AA .","label":"Uses","metadata":{},"score":"85.94151"}
{"text":"The column elements have three attributes : .Attribute .Description . name .The column name .Note that the column name can be used by an option and within a feature model specification as an identifier of the column . category .","label":"Uses","metadata":{},"score":"86.04545"}
{"text":"The column elements have three attributes : .Attribute .Description . name .The column name .Note that the column name can be used by an option and within a feature model specification as an identifier of the column . category .","label":"Uses","metadata":{},"score":"86.04545"}
{"text":"An inactive stack ( InactiveStack ) of partially processed tokens that may be linked on the other plane , where InactiveStack[i ] is the i+1th token from the top of the stack , with the top being InactiveStack[0 ] .A list Input of remaining input tokens , where Input[i ] is the i+1th token in the list , with the first token being Input[0 ] .","label":"Uses","metadata":{},"score":"86.166794"}
{"text":"An inactive stack ( InactiveStack ) of partially processed tokens that may be linked on the other plane , where InactiveStack[i ] is the i+1th token from the top of the stack , with the top being InactiveStack[0 ] .A list Input of remaining input tokens , where Input[i ] is the i+1th token in the list , with the first token being Input[0 ] .","label":"Uses","metadata":{},"score":"86.166794"}
{"text":"Example : .InputTable(CJ - POSTAG , Stack[0 ] ) .Exists .Takes an address function as argument and returns TRUE if the address function returns an existing node ( and FALSE otherwise ) .Example : . Exists(ldep(Stack[0 ] ) ) .","label":"Uses","metadata":{},"score":"87.04289"}
{"text":"To find out more about the different levels please consult the Apache log4j documentation .The default verbosity level is info , which means that all error , warning and informational messages are displayed . config .The configuration name is the name of the configuration and also the name of the MaltParser configuration file , which ends with the file suffix .","label":"Uses","metadata":{},"score":"87.210815"}
{"text":"TrainingExperiment java -cp classes : . /maltparser-1.8.1.jar org.maltparser.examples.old.ParsingExperiment java -cp classes : . /maltparser-1.8.1.jar org.maltparser.examples.old.ParseSentence1 java -cp classes : . /maltparser-1.8.1.jar org.maltparser.examples.old.ParseSentence2 java -cp classes : . /maltparser-1.8.1.jar org.maltparser.examples.old.ParseSentence3 .Other programs can invoke Maltparser in various ways , but the easiest way is to use the org.maltparser.","label":"Uses","metadata":{},"score":"87.23062"}
{"text":"The name is your own choice , but it is appropriate to give the configuration a name that reflects the content .This option must always be specified , except when the url option is used instead of name .It is possible to specify a URL to the configuration file instead of specifying the configuration name .","label":"Uses","metadata":{},"score":"87.44935"}
{"text":"Dependency Parsing of Turkish .Computational Linguistics 34(3 ) , 357 - 389 .Nivre , J. ( 2008 ) Algorithms for Deterministic Incremental Dependency Parsing .Computational Linguistics 34(4 ) , 513 - 553 .Hall , J. , Nilsson , J. and Nivre , J. ( 2010 ) Single Malt or Blended ?","label":"Uses","metadata":{},"score":"87.55719"}
{"text":"Boolean option , can take either true or false value . integer .Integer option , can take an integer value . string .String option , can take a string value . enum .Enum option , can only take a predefined value . stringenum .","label":"Uses","metadata":{},"score":"87.835075"}
{"text":"The head column defines the unlabeled structure of a dependency graph and is also output data of the parser in parsing mode . type .Defines the data type of the column and/or its treatment during learning and parsing : .STRING .","label":"Uses","metadata":{},"score":"88.17503"}
{"text":"rootnode : Distinguishes between NO NODE and ROOT NODE , and the NO VALUE null - value case is mapped to the ROOT NODE null - value for output columns .novalue : Distinguishes between NO NODE and ROOT NODE for both input and output columns , and NO VALUE for output columns . input .","label":"Uses","metadata":{},"score":"88.45174"}
{"text":"The system option group contains options that have a special status , because they control the overall system .These options can only have one value each .For instance , you can not specify more than one option file .There are several levels of verbosity for the system output stream , from showing all debugging messages ( which can be useful when modifying or extending the source code of MaltParser ) to turning off all messages .","label":"Uses","metadata":{},"score":"88.57095"}
{"text":"mco .The configuration name is a name of your own choice .The option flag -i tells the parser where to find the input data .The last option flag -m specifies the processing mode learn ( as opposed to parse ) , since in this case we want to induce a model by using the default learning method ( LIBSVM ) .","label":"Uses","metadata":{},"score":"88.58312"}
{"text":"A list Lookahead , which is a suffix of the buffer containing all nodes that have not been on Stack , where Lookahead[i ] is the i+1th token from the start of Lookahead .Note that it is only the swap transition that can move nodes from Stack back to the buffer , which means that for the Projective Stack algorithm Input will always be empty and Lookahead will always contain all the nodes in the buffer .","label":"Uses","metadata":{},"score":"88.871506"}
{"text":"A list Lookahead , which is a suffix of the buffer containing all nodes that have not been on Stack , where Lookahead[i ] is the i+1th token from the start of Lookahead .Note that it is only the swap transition that can move nodes from Stack back to the buffer , which means that for the Projective Stack algorithm Input will always be empty and Lookahead will always contain all the nodes in the buffer .","label":"Uses","metadata":{},"score":"88.871506"}
{"text":"The CoNLL data format specification file looks like this : .A data format specification file has two types of XML elements .First , there is the dataformat element with the attribute name , which gives the data format a name .","label":"Uses","metadata":{},"score":"88.97083"}
{"text":"The CoNLL data format specification file looks like this : .A data format specification file has two types of XML elements .First , there is the dataformat element with the attribute name , which gives the data format a name .","label":"Uses","metadata":{},"score":"88.97083"}
{"text":"These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation .Therefore , the standard evaluation does not provide a true indication of algorithm quality .We present a new measure , Neutral Edge Direction ( NED ) , and show that it greatly reduces this undesired phenomenon .","label":"Uses","metadata":{},"score":"89.157135"}
{"text":"These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation .Therefore , the standard evaluation does not provide a true indication of algorithm quality .We present a new measure , Neutral Edge Direction ( NED ) , and show that it greatly reduces this undesired phenomenon .","label":"Uses","metadata":{},"score":"89.157135"}
{"text":"Same as DEPENDENCY_EDGE_LABEL , used by MaltParser version 1.0 - 1.1 .PHRASE_STRUCTURE_EDGE_LABEL .Denote that the column contain a phrase structure edge label .PHRASE_STRUCTURE_NODE_LABEL .Denote that the column contain a phrase category label .SECONDARY_EDGE_LABEL .Denote that the column contain a secondary edge label .","label":"Uses","metadata":{},"score":"89.46352"}
{"text":"Type .Description .Address function .There are two types of address functions : parsing algorithm specific functions and dependency graph functions .The parsing algorithm specific functions have the form Data - structure[i ] , where Data - structure is a data structure used by a specific parsing algorithm and i is an offset from the start position in this data structure .","label":"Uses","metadata":{},"score":"89.76671"}
{"text":"Type .Description .Address function .There are two types of address functions : parsing algorithm specific functions and dependency graph functions .The parsing algorithm specific functions have the form Data - structure[i ] , where Data - structure is a data structure used by a specific parsing algorithm and i is an offset from the start position in this data structure .","label":"Uses","metadata":{},"score":"89.76671"}
{"text":"Merge three feature value into one feature value .The following specification defines a feature the value of which the part - of - speech of the three next input token are merged into one feature value .Merge3(InputColumn(POSTAG , Input[0 ] ) , InputColumn(POSTAG , Input[1 ] ) , InputColumn(POSTAG , Input[2 ] ) ) .","label":"Uses","metadata":{},"score":"90.26149"}
{"text":"Merge three feature value into one feature value .The following specification defines a feature the value of which the part - of - speech of the three next input token are merged into one feature value .Merge3(InputColumn(POSTAG , Input[0 ] ) , InputColumn(POSTAG , Input[1 ] ) , InputColumn(POSTAG , Input[2 ] ) ) .","label":"Uses","metadata":{},"score":"90.26149"}
{"text":"This , in turn , results in lots of ( unnecessary ) lifts , and can be avoided by using the covered_root flag -pcr .This option has four values : none , left , right and head .For the last three values , tokens like dangling punctuation are then attached to one of the tokens connected by the shortest arc covering the token , either the leftmost ( left ) , rightmost ( right ) , or head ( head ) token of the covering arc .","label":"Uses","metadata":{},"score":"90.2808"}
{"text":"This , in turn , results in lots of ( unnecessary ) lifts , and can be avoided by using the covered_root flag -pcr .This option has four values : none , left , right and head .For the last three values , tokens like dangling punctuation are then attached to one of the tokens connected by the shortest arc covering the token , either the leftmost ( left ) , rightmost ( right ) , or head ( head ) token of the covering arc .","label":"Uses","metadata":{},"score":"90.2808"}
{"text":"The following specification defines a feature the value of which the part - of - speech of the top token of the stack and the next input token are merged into one feature value .Merge(InputColumn(POSTAG , Stack[0 ] ) , InputColumn(POSTAG , Input[0 ] ) ) .","label":"Uses","metadata":{},"score":"90.67494"}
{"text":"The following specification defines a feature the value of which the part - of - speech of the top token of the stack and the next input token are merged into one feature value .Merge(InputColumn(POSTAG , Stack[0 ] ) , InputColumn(POSTAG , Input[0 ] ) ) .","label":"Uses","metadata":{},"score":"90.67494"}
{"text":"Stack .The Projective ( -a stackproj )Stack algorithm uses essentially the same transitions as the arc - standard version of Nivre 's algorithm and is limited to projective dependency trees .The Eager ( -a stackeager ) and Lazy ( -a stacklazy ) Stack algorithms in addition make use of a swap transition , which makes it possible to derive arbitrary non - projective dependency trees .","label":"Uses","metadata":{},"score":"90.896"}
{"text":"Example : .InputArc(PHEAD , Stack[0 ] ) .Exists .Takes an address function as argument and returns TRUE if the address function returns an existing node ( and FALSE otherwise ) .Example : . Exists(ldep(Stack[0 ] ) ) .","label":"Uses","metadata":{},"score":"91.55045"}
{"text":"IGNORE .The column value will be ignored and therefore will not be present in the output file . type .Defines the data type of the column and/or its treatment during learning and parsing : .STRING .The column value will be used as a string value in the feature model .","label":"Uses","metadata":{},"score":"91.555435"}
{"text":"Class option , can take a predefined value that corresponds to a class in the MaltParser distribution .If there is a default value it is specified by this attribute .usage .Indicates the usage of the option : . train .","label":"Uses","metadata":{},"score":"91.703964"}
{"text":"Note that is is only the encoding schemes head , path and head+path that actively try to recover the non - projective arcs .Input and output format .The format and encoding of the input and output data is controlled by the format , reader , writer and charset options in the input and output option group .","label":"Uses","metadata":{},"score":"92.52713"}
{"text":"Uses the option flag with a dash ( - ) before the option flag and a blank between the option flag and the value . -c test .Command - line option group and option name .Uses both the option group name and the option name to specify the option , with two dashes ( -- ) before the option group name and one dash ( - ) to separate the option group name and the option name .","label":"Uses","metadata":{},"score":"93.2767"}
{"text":"Note that command line option settings override the settings in the option file if options are specified twice .Option file .An option file is useful when you have many options that differ from the default value , as is often the case when you are training a parsing model .","label":"Uses","metadata":{},"score":"93.409134"}
{"text":"Note that command line option settings override the settings in the option file if options are specified twice .Option file .An option file is useful when you have many options that differ from the default value , as is often the case when you are training a parsing model .","label":"Uses","metadata":{},"score":"93.409134"}
{"text":"Command - line option group and option name .Uses both the option group name and the option name to specify the option , with two dashes ( -- ) before the option group name and one dash ( - ) to separate the option group name and the option name .","label":"Uses","metadata":{},"score":"93.5296"}
{"text":"InputArc(PHEAD , Stack[0 ] , Input[0 ] ) .InputArcDir .The column name must correspond to an input column of integer type in the data format and the address function must return a token node in the input string .( If the address function is undefined , a null - value is returned . )","label":"Uses","metadata":{},"score":"93.93393"}
{"text":"InputArc(PHEAD , Stack[0 ] , Input[0 ] ) .InputArcDir .The column name must correspond to an input column of integer type in the data format and the address function must return a token node in the input string .( If the address function is undefined , a null - value is returned . )","label":"Uses","metadata":{},"score":"93.93393"}
{"text":"The file deprojectivized.conll will contain the deprojectivized data .Note that is is only the encoding schemes head , path and head+path that actively try to recover the non - projective arcs .Input and output format .The format and encoding of the input and output data is controlled by the format , reader , writer and charset options in the input and output option group .","label":"Uses","metadata":{},"score":"94.45769"}
{"text":"It is possible to projectivize an input file , with or without involving parsing .All non - projective arcs in the input file are replaced by projective arcs by applying a lifting operation .The lifts are encoded in the dependency labels of the lifted arcs .","label":"Uses","metadata":{},"score":"94.62738"}
{"text":"Suffix .Extract the suffix of a feature value ( only InputColumn ) with a suffix length n .The following specification defines a feature the value of which is the four - character suffix of the word form ( FORM ) of the next input token .","label":"Uses","metadata":{},"score":"94.700294"}
{"text":"Suffix .Extract the suffix of a feature value ( only InputColumn ) with a suffix length n .The following specification defines a feature the value of which is the four - character suffix of the word form ( FORM ) of the next input token .","label":"Uses","metadata":{},"score":"94.700294"}
{"text":"Attribute .Description . name .The name of the option . type .There are following option types : . unary .The option has no value , this type is only used by the help option to indicate that help should be displayed .","label":"Uses","metadata":{},"score":"94.81192"}
{"text":"Prefix .The following specification defines a feature the value of which is the four - character prefix of the word form ( FORM ) of the next input token .Prefix(InputColumn(FORM , Input[0 ] ) , 4 ) .Merge .","label":"Uses","metadata":{},"score":"95.94363"}
{"text":"Prefix .The following specification defines a feature the value of which is the four - character prefix of the word form ( FORM ) of the next input token .Prefix(InputColumn(FORM , Input[0 ] ) , 4 ) .Merge .","label":"Uses","metadata":{},"score":"95.94363"}
{"text":"NO VALUE : The dependency graph node exists and is not the root , but has not yet been assigned a value for the output column requested ( e.g. , has not been assigned a head and therefore does not have a dependency type ) .","label":"Uses","metadata":{},"score":"97.02959"}
{"text":"option .An option group can consist of one or more option .The element option has two attributes : name that corresponds to an option name and value that is the value of the option .Please consult the description of all available options to see all legal option names and values .","label":"Uses","metadata":{},"score":"97.134315"}
{"text":"( If the address function is undefined , a null - value is returned . )Example : .InputColumn(POSTAG , Stack[0 ] ) .OutputColumn .Takes two arguments , a column name and an address function , and returns the column value for the node identified by the address function .","label":"Uses","metadata":{},"score":"98.55112"}
{"text":"( If the address function is undefined , a null - value is returned . )Example : .InputColumn(POSTAG , Stack[0 ] ) .OutputColumn .Takes two arguments , a column name and an address function , and returns the column value for the node identified by the address function .","label":"Uses","metadata":{},"score":"98.55112"}
{"text":"The single malt configuration contains seven deterministic parsing algorithms .Four algorithms produce projective dependency graphs : Nivre arc - eager , Nivre arc - standard , Covington projective and Stack projective .Three algorithms are able to produce non - projective graphs : Covington non - projective , Stack eager and Stack lazy .","label":"Uses","metadata":{},"score":"98.59232"}
{"text":"A feature function takes at least one address function as input and returns a feature value defined in terms of the input arguments .There are seven feature functions available : .InputColumn .Takes two arguments , a column name and an address function , and returns the column value for the node identified by the address function .","label":"Uses","metadata":{},"score":"98.81591"}
{"text":"A feature function takes at least one address function as input and returns a feature value defined in terms of the input arguments .There are seven feature functions available : .InputColumn .Takes two arguments , a column name and an address function , and returns the column value for the node identified by the address function .","label":"Uses","metadata":{},"score":"98.81591"}
{"text":"NO NODE :There exists no corresponding dependency graph node ( e.g. , because the lookahead extend beyond the end of the string ) , which means that the feature is really undefined .ROOT NODE :The dependency graph node is a root node , which means that it is not possible to extract an input column value ( for example , the word form or the part - of - speech ) .","label":"Uses","metadata":{},"score":"100.985565"}
{"text":"Projectivize input data .It is possible to projectivize an input file , with or without involving parsing .All non - projective arcs in the input file are replaced by projective arcs by applying a lifting operation .The lifts are encoded in the dependency labels of the lifted arcs .","label":"Uses","metadata":{},"score":"101.904594"}
{"text":"The attribute groupname specifies the option group name ( see description of all available options ) .option .An option group can consist of one or more option .The element option has two attributes : name that corresponds to an option name and value that is the value of the option .","label":"Uses","metadata":{},"score":"102.25986"}
{"text":"The dependency relation DEPREL is the grammatical function of the highest nonterminal of which the dependent is the lexical head .The attachment ATTACH is a non - negative integer that encodes the attachment level of the highest nonterminal of which it is the lexical head .","label":"Uses","metadata":{},"score":"106.239334"}
{"text":"The column value will be used as an integer value in the feature model .BOOLEAN .The column value will be used as a boolean value in the feature model .REAL .The column value will be used as a real value in the feature model . default .","label":"Uses","metadata":{},"score":"108.88922"}
{"text":"INTEGER .The column value will be stored as an integer value .BOOLEAN .The column value will be stored as a boolean value .ECHO .The column value will be stored as an integer value , but can not be used in the definition of features .","label":"Uses","metadata":{},"score":"110.23399"}
{"text":"The column value will be ignored and therefore will not be present in the output file . default .The default output for columns that have the column type IGNORE .It is possible to define your own input / output format and then supply the data format specification file with the format option .","label":"Uses","metadata":{},"score":"111.74928"}
{"text":"Covington projective .Left , Right .Covington non - projective .Left , Right , LeftContext , RightContext .Stack projective .Stack , Input , Lookahead .Planar .Stack , Input . 2-Planar .ActiveStack , InactiveStack , Input .","label":"Uses","metadata":{},"score":"113.608505"}
{"text":"Covington projective .Left , Right .Covington non - projective .Left , Right , LeftContext , RightContext .Stack projective .Stack , Input , Lookahead .Planar .Stack , Input . 2-Planar .ActiveStack , InactiveStack , Input .","label":"Uses","metadata":{},"score":"113.608505"}
