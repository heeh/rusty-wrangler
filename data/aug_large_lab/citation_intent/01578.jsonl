{"text":"Because of the predominance of GIZA++ , there are now several distributed implementations of it online .[ 11 ] .In phrase - based translation , the aim is to reduce the restrictions of word - based translation by translating whole sequences of words , where the lengths may differ .","label":"Uses","metadata":{},"score":"36.411274"}{"text":"This problem can be remedied to some degree by a more efficient data structure in GIZA++ , which requires the run of snt2cooc in advance on the corpus in parts and the merging on the resulting output .All you need to know is that running the training script with the option --parts n , e.g. --parts 3 may allow you to train on a corpus that was too large for a regular run .","label":"Uses","metadata":{},"score":"41.0251"}{"text":"For instance , this problem was the focus as a shared task at a recent data driven machine translation workshop .See also the systematic comparison by Och and Ney ( Computational Linguistics , 2003 ) .At this point , the most common tool to establish a word alignment is to use the toolkit GIZA++ .","label":"Uses","metadata":{},"score":"42.45951"}{"text":"We will later analyze the contribution of each component to the overall score .The typical processing pipeline is as follows .Given a parallel training corpus , long sentences are filtered out , and the remaining material is lowercased and tokenized .","label":"Uses","metadata":{},"score":"42.82964"}{"text":"This allows the use of a much wider range of parallel corpora for training , and can be combined with a standard phrase - table using conventional smoothing methods .Experimental results demonstrate BLEU improvements for triangulated models over a standard phrase - based system .","label":"Uses","metadata":{},"score":"43.35716"}{"text":"Then , additional features are used to rescore these translations .An n - best list is one way to represent multiple candidate translations .Such a set of possible translations can also be represented by word graphs ( Ueffing et al . , EMNLP 2002 ) or forest structures over parse trees ( Langkilde , EACL 2002 ) .","label":"Uses","metadata":{},"score":"43.73844"}{"text":"We achieve most gains from the use of larger training corpora and basic modeling , but also show promising results from integrating more linguistic annotation . \" ...In this paper , we investigate lexicon models for hierarchical phrase - based statistical machine translation .","label":"Uses","metadata":{},"score":"45.93321"}{"text":"Conf . on Language Resources and Evaluation , LREC'06 , 2006 . \" ...The IBM Models ( Brown et al . , 1993 ) enjoy great popularity in the machine translation community because they offer high quality word alignments and a free implementation is available with the GIZA + + Toolkit ( Och and Ney , 2003 ) .","label":"Uses","metadata":{},"score":"46.354904"}{"text":"See also the description by Zens ( 2002 ) .The alternative phrase - based methods differ in the way the phrase translation table is created , which we discuss in detail below .Model .The figure below illustrates the process of phrase - based translation .","label":"Uses","metadata":{},"score":"46.852657"}{"text":"We show that our algorithm leads not only to improved alignments but also to machine translation outputs of higher quality . ... evious work on discriminative training for wordalignment differed most strongly from our approach in that it generally views word - alignment as a supervised task .","label":"Uses","metadata":{},"score":"46.959297"}{"text":"We swap them and we use the mod - ied source training corpora to realign and to build the nal translation system .We have evaluated our reordering ap - proach both in alignment and translation quality .In addition , we have used two state - of - the - art SMT systems : a Phrased - based and an Ngram - based .","label":"Uses","metadata":{},"score":"47.183228"}{"text":"Methods for Learning Phrase Translations .Marcu and Wong .First , the exception : Marcu and Wong ( EMNLP , 2002 ) proposed to establish phrase correspondences directly in a parallel corpus .To learn such correspondences , they introduced a phrase - based joint probability model that simultaneously generates both the source and target sentences in a parallel corpus .","label":"Uses","metadata":{},"score":"47.490353"}{"text":"Work related to our learning curve experiments can also be found in [ 10 ] .It is important to remark that while there are many discussions about automatic evaluation of SMT systems , this work does not consider them .We work within the well - defined setting where a loss function has been agreed upon , that can measure the similarity between two sentences , and a paired training set has been provided .","label":"Uses","metadata":{},"score":"47.512856"}{"text":"In this paper we present a novel approach for inducing word alignments from sentence aligned data .We use a Conditional Random Field ( CRF ) , a discriminative model , which is estimated on a small supervised training set .The CRF is conditioned on both the source and target texts , and thus allows for t ... \" .","label":"Uses","metadata":{},"score":"47.624397"}{"text":"[ 7 ] .The word - based translation is not widely used today ; phrase - based systems are more common .Most phrase - based system are still using GIZA++ to align the corpus [ citation needed ] .The alignments are used to extract phrases or deduce syntax rules .","label":"Uses","metadata":{},"score":"47.679344"}{"text":"We introduce a semi - supervised approach to training for statistical machine translation that alternates the traditional Expectation Maximization step that is applied on a large training corpus with a discriminative step aimed at increasing word - alignment quality on a small , manually word - aligned sub ... \" .","label":"Uses","metadata":{},"score":"47.802475"}{"text":"5 ] and applied in their respective translation systems for phrase table smoothing .Chiang et al .[ 15 ] suggested morphology - based and provenance - based improvements to the Koehn - Och - Marcu method recently ...Learning to Translate : A Statistical and Computational Analysis .","label":"Uses","metadata":{},"score":"48.12487"}{"text":"In this paper , we investigate lexicon models for hierarchical phrase - based statistical machine translation .We explore sourceto - target models with phrase - level as well as sentence - level scoring and target - to - source models with scoring on phrase level only .","label":"Uses","metadata":{},"score":"48.16153"}{"text":"Although many language pairs would yield different translation performance , in this paper , we are not interested in the translation performance per se : we focus our attention on analyzing the SMT system as a learning system .Since our goal was to obtain high - accuracy learning curves , that can be trusted both for comparing different system settings and to extrapolate performance under unseen conditions , we conducted a large - scale series of tests , to reduce uncertainty in the estimations and to obtain the strongest possible signals .","label":"Uses","metadata":{},"score":"48.296936"}{"text":"The language model used is an m - gram model .The translation model comprises a stochastic lexicon and word position parameters .To capture dependencies between word groups in each of the two languages , alignment templates are used .We describe the components of the system and report results on the Verbmobil task .","label":"Uses","metadata":{},"score":"48.587387"}{"text":"Note that this approach is consistent with the approach taken by Marcu and Wong themselves , who use conditional models during decoding .Och and Ney .Och and Ney ( Computational Linguistics , 2003 ) propose a heuristic approach to refine the alignments obtained from GIZA++ .","label":"Uses","metadata":{},"score":"48.680424"}{"text":"The unfolding technique produces a different bilingual n - gram language model with reordered source words .Figure 1 : ... .Therefore , all models are combined in search and a single best hypothesis is output .4.2.4 Optimisation procedure Minimum - error training states that we can directly train our models according the an errorminimisation function on a certain development data , as discussed in § 2.4.1 .","label":"Uses","metadata":{},"score":"48.835632"}{"text":"In both approaches , the translation process is based on bilingual units related by word - to - word alignments ( pairs of source and target words ) , while the main di ... \" .This work summarizes a comparison between two approaches to Statistical Machine Translation ( SMT ) , namely Ngram - based and Phrase - based SMT .","label":"Uses","metadata":{},"score":"49.35563"}{"text":"He starts with phrase alignments based on the intersection of the two GIZA++ alignments and uses points of the union to expand these .See his presentation for details .Venugopal , Zhang , and Vogel .Venugopal et al .( ACL 2003 ) allows also for the collection of phrase pairs that are violated by the word alignment .","label":"Uses","metadata":{},"score":"49.554955"}{"text":"[ 9 ] .In parallel corpora single sentences in one language can be found translated into several sentences in the other and vice versa .Sentence aligning can be performed through the Gale - Church alignment algorithm .Sentence alignment is usually either provided by the corpus or obtained by aforementioned Gale - Church alignment algorithm .","label":"Uses","metadata":{},"score":"50.242317"}{"text":"Afterwards , we classify these pairs into groups , following recursively a co - occurrence block criterion , in order to infer reorderings .Inside the same group , we allow new internal combination in or - der to generalize the reorder to unseen pairs of blocks .","label":"Uses","metadata":{},"score":"50.53884"}{"text":"R. Zens , F.-J. Och , and H. Ney , \" Phrase - based statistical machine translation , \" in Proceedings of the 25th Annual German Conference on AI ( KI ' 02 ) , pp .18 - 32 , Springer , London , UK , 2002 .","label":"Uses","metadata":{},"score":"50.561295"}{"text":"Our results suggest that performance , as measured by BLEU , increases by a constant factor for each doubling of the data .Although that factor varies depending on corpus and language pair , this result seems consistent over all experimental conditions we tried .","label":"Uses","metadata":{},"score":"50.65013"}{"text":"We present an extensive experimental study of Phrase - based Statistical Machine Translation , from the point of view of its learning capabilities .Very accurate Learning Curves are obtained , using high - performance computing , and extrapolations of the projected performance of the system under different conditions are provided .","label":"Uses","metadata":{},"score":"50.695473"}{"text":"In order to compile GIZA++ you may need : . a recent version of the GNU compiler ( 2.95 or higher ) .a recent version of assembler and linker which do not have restrictions with respect to the length of symbol names .","label":"Uses","metadata":{},"score":"50.74919"}{"text":"4.2 Collocation Correction with Phrase - based SMT We implement our approach in the fram ... . \" ...We report on efforts to build large - scale translation systems for eight European language pairs .We achieve most gains from the use of larger training corpora and basic modeling , but also show promising results from integrating more linguistic annotation .","label":"Uses","metadata":{},"score":"51.22407"}{"text":"This yields an efficient algorithm for obtaining the exact solution of each line search in Powell 's method and therefore provides a way to iteratively optimize the log - linear weights . using MERT .A number of alternatives have been proposed , such as on - line discriminative training [ 19 , 20 ] .","label":"Uses","metadata":{},"score":"51.28997"}{"text":"We present a new generative alignment model which avoids these structural limitations , and show that it is effective when trained using both unsupervised and semi - supervised training methods . ... lar to work using discriminative log - linear models for alignment , which is similar to discriminative log - linear models used for the SMT decoding ( translation ) problem ( Och and Ney , 2002 ; Och , 2003 ) .","label":"Uses","metadata":{},"score":"51.39469"}{"text":"This is because the rate of improvement of translation performance is at best logarithmic with the training set size .We estimate that bridging the gap between training and test error would require about .paired bilingual sentences , which is larger than the current estimated size of the web .","label":"Uses","metadata":{},"score":"51.60977"}{"text":"We use a publicly available structured output SVM to create a max - margin syntactic aligner with a soft cohesion constraint .The resulting aligner is the first , to our knowledge , to use a discriminative learning method to train an ITG bitext parser . ... rence for links to appear near one another ( Vogel et al .","label":"Uses","metadata":{},"score":"51.68094"}{"text":"In addition , we introduce sentence - level restructuring transformations which aim at the assimilation of word order in related sentences .We have systematically investigated the amount of bilingual training data required to maintain an acceptable quality of machine translation .","label":"Uses","metadata":{},"score":"51.7715"}{"text":"It is possible to run the two GIZA++ separately on two machines with the switch --direction .When running one of the runs on one machine with --direction 1 and the other run on a different machine or CPU with --direction 2 , the processing time for training step 2 can be cut in half .","label":"Uses","metadata":{},"score":"51.822495"}{"text":"This learning curve reports BLEU score versus the percentage of perturbation applied .These results have been obtained using a fixed training set size equal to 62,995 and 629,957 pairs of sentences and Moses as translation system .Figure 7 : Unlearning curves .","label":"Uses","metadata":{},"score":"51.95041"}{"text":"We only add new alignment points that exist in the union of two word alignments .We also always require that a new alignment point connects at least one previously unaligned word .First , we expand to only directly adjacent alignment points .","label":"Uses","metadata":{},"score":"52.09261"}{"text":"They are automatically filled during the training phase , when a bilingual corpus is used to identify both phrases and their probabilities .Since future translations are produced by maximizing a scoring function estimating translation quality , using the content of the two tables , we see that the contents of the translation and language models tables correspond to the tunable parameters of the learning system .","label":"Uses","metadata":{},"score":"52.118248"}{"text":"By examining many samples of human - produced translation , SMT algorithms automatically learn how to translate .SMT has made tremendous strides in less than two decades , and many popular techniques have only emerged within the last few years .","label":"Uses","metadata":{},"score":"52.34498"}{"text":"Systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine translation output , but are often very computationally intensive .The complexity is exponential in the size of individual grammar rules due to arbitrary re - orderings between the two langu ... \" .","label":"Uses","metadata":{},"score":"52.418945"}{"text":"Core Algorithm .The phrase - based decoder we developed employs a beam search algorithm , similar to the one used by Jelinek ( book \" Statistical Methods for Speech Recognition \" , 1998 ) for speech recognition .The English output sentence is generated left to right in form of hypotheses .","label":"Uses","metadata":{},"score":"52.442024"}{"text":"Statistics on the phrase pair are accumulated over the entire corpus .In our experiments below , we rely on word - to - word IBM models [ 2 ] for alignment .Although more elaborate techniques have appeared more recently [ 13 , 14 ] , their impact on the resulting machine translation quality is still unclear [ 15 ] .","label":"Uses","metadata":{},"score":"52.55497"}{"text":"The IBM Models ( Brown et al . , 1993 ) enjoy great popularity in the machine translation community because they offer high quality word alignments and a free implementation is available with the GIZA + + Toolkit ( Och and Ney , 2003 ) .","label":"Uses","metadata":{},"score":"52.7797"}{"text":"First , we use chunks to refine the set of word alignments typically used as a starting point in SMT systems .Second , we extend an N - grambased SMT system with chunk tags to better account for long - distance reorderings .","label":"Uses","metadata":{},"score":"52.903873"}{"text":"First , we use chunks to refine the set of word alignments typically used as a starting point in SMT systems .Second , we extend an N - grambased SMT system with chunk tags to better account for long - distance reorderings .","label":"Uses","metadata":{},"score":"52.903873"}{"text":"Building on this work , we demonstrate substan ... \" .For many years , statistical machine translation relied on generative models to provide bilingual word alignments .In 2005 , several independent efforts showed that discriminative models could be used to enhance or replace the standard generative approach .","label":"Uses","metadata":{},"score":"52.911804"}{"text":"( 1993 ) .Starting from a DP - based solution to the traveling - salesman problem , we present a novel technique to restrict the possible word reorderings between source and target language in order to achieve an efficient search algorithm .","label":"Uses","metadata":{},"score":"53.003174"}{"text":"We begin with the context of the current research , and then move to a formal problem description and an overview of the four main subproblems : translational equivalence modeling , mathematical modeling , parameter estimation , and decoding .Along the way , we present a taxonomy of some different approaches within these areas .","label":"Uses","metadata":{},"score":"53.13978"}{"text":"f . )No smoothing is performed , although lexical weighting addresses the problem of sparse data .For more details , see our paper on phrase - based translation ( Koehn at al , HLT - NAACL 2003 ) .Tillmann .","label":"Uses","metadata":{},"score":"53.292984"}{"text":"Any way to enforce linguistic constraints might result in a reduced need for data , and ultimately in more complete models , given the same corpus [ 34 ] .Neither approach would change the statistical nature of the system , but they would help it bypass the phrase acquisition bottleneck .","label":"Uses","metadata":{},"score":"53.57775"}{"text":"^ a b F. Och and H. Ney .A Systematic Comparison of Various Statistical Alignment Models .Computational Linguistics , 29(1):19 - 51 .^ P. Koehn , F.J. Och , and D. Marcu ( 2003 ) .Statistical phrase based translation .","label":"Uses","metadata":{},"score":"53.747677"}{"text":"If the future cost estimates are inadequate , we may prune out hypotheses on the path to the best scoring translation .Using best - first search and an admissible heuristic allows pruning that is risk - free .In practice , however , this type of pruning does not sufficiently reduce the search space .","label":"Uses","metadata":{},"score":"54.069977"}{"text":"The search will prefer to start the sentence with the easy part and discount alternatives too early .So , our measure for pruning out hypotheses in our beam search does not only include the cost so far , but also an estimate of the future cost .","label":"Uses","metadata":{},"score":"54.0733"}{"text":"We therefore reach the conclusion that estimating entries in the phrase translation tables is the dominant factor in determining performance .What controls the creation of phrase - translation tables ?This is mostly limited by Zipf 's law , since the probability of encountering phrases that have not been seen in the training set does not vanish even after observing very large corpora .","label":"Uses","metadata":{},"score":"54.40016"}{"text":"The improvement of the translation results is demonstrated on two German - English corpora taken from the Verbmobil task and the Nespole ! task . \" ...In this article , we describe an efficient beam search algorithm for statistical machine translation based on dynamic programming ( DP ) .","label":"Uses","metadata":{},"score":"54.47167"}{"text":"There is no need to rerun GIZA++ .You could copy the necessary files from the corpus and the giza .Since you only need a new model directory , you can specify this with the parameter --model - dir , and stay within the precious root directory structure : .","label":"Uses","metadata":{},"score":"54.49386"}{"text":"Tree - based System Combination and Pre - ordering for Machine Translation .Among monolingual sub - tasks employed in machine translation , we will focus on the use of tree - based approaches for system combination and pre - ordering .","label":"Uses","metadata":{},"score":"54.5043"}{"text":"We use a Conditional Random Field ( CRF ) , a discriminative model , which is estimated on a small supervised training set .The CRF is conditioned on both the source and target texts , and thus allows for the use of arbitrary and overlapping features over these data .","label":"Uses","metadata":{},"score":"54.57793"}{"text":"Third , a packed forest is generated starting from the root symbol of the extracted grammar through non - terminal rewriting .The new hypothesis is produced by searching the best derivation in the forest .We demonstrate that our forest based approach competes with the confusion network based method under smaller hypothesis space .","label":"Uses","metadata":{},"score":"54.79003"}{"text":"The latter group is often approached with monolingual M - tools like monolingual word alignment [ Matusov et al ., 05 ; He et al ., 08 ] and the minimization of Bayes risk [ Kumar and Byrne , 02 ] ( on the outputs of combined systems ) .","label":"Uses","metadata":{},"score":"54.863525"}{"text":"We then introduce the concept of comparable states that allow us to define a beam of good hypotheses and prune out hypotheses that fall out of this beam .In a later section , we will describe how to generate an ( approximate ) n - best list .","label":"Uses","metadata":{},"score":"55.17019"}{"text":"Development and test sets are fixed .One instance of the SMT system has been run for each of all possible combinations of the language and translation training data sizes .BLEU score value has been associated to each pair : language and translation set size .","label":"Uses","metadata":{},"score":"55.233566"}{"text":"263 - 311 , 1994 .View at Google Scholar .P. Koehn , F. J. Och , and D. Marcu , \" Statistical phrase - based translation , \" in Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology , pp .","label":"Uses","metadata":{},"score":"55.353355"}{"text":"The training part is used to obtain the language model and phrase tables .The development set is used to estimate the log - linear weights . using MERT , and the test set is set aside during the estimation process in order to provide an unbiased estimate of the translation performance .","label":"Uses","metadata":{},"score":"55.367233"}{"text":"We obtain gains in ... \" .Word alignments that violate syntactic correspondences interfere with the extraction of string - to - tree transducer rules for syntaxbased machine translation .We present an algorithm for identifying and deleting incorrect word alignment links , using features of the extracted rules .","label":"Uses","metadata":{},"score":"55.508568"}{"text":"There is some effort in building syntax - based models that either use real syntax trees generated by syntactic parsers , or tree transfer methods motivated by syntactic reordering patterns .The phrase - based statistical machine translation model we present here was defined by Koehn et al .","label":"Uses","metadata":{},"score":"55.605408"}{"text":"Figure 3 : Chinese - English learning curve obtained using UN corpus and Portage .In all the figures , the curves are increasing linearly or slightly more slowly than that , suggesting a learning curve that is \" at best ' ' logarithmically increasing with the training set size .","label":"Uses","metadata":{},"score":"55.68563"}{"text":"Training the translation models requires several steps such as aligning words , computing the lexical translation , extracting and scoring the phrases , and creating the reordering model .When the models have been created , the development set is used to run the minimum error rate training ( MERT ) algorithm [ 17 ] to optimize their weights .","label":"Uses","metadata":{},"score":"55.737465"}{"text":"The high performance observed in the train - on - test conditions shows that there exists at least one choice of tunable parameters with which the phrase - based translation system can deliver much higher performance .This is useful to bound the space of \" possible performances , ' ' although in ideal situations .","label":"Uses","metadata":{},"score":"55.758972"}{"text":"A remaining disadvantage , however , is the high model complexity .This paper describes a word alignment training procedure for statistical machine translation that uses a simple and clear statistical model , different from the IBM models .The main idea of the algorithm is to generate a symmetric and monotonic alignment between the target sentence and a permutation graph representing different reorderings of the words in the source sentence .","label":"Uses","metadata":{},"score":"55.85558"}{"text":"Zhang et al .( 2003 ) proposes a phrase alignment method that is based on word alignments and tries to find a unique segmentation of the sentence pair , as it is done by Marcu and Wong directly .This enables them to estimate joint probability distributions , which can be marginalized into conditional probability distributions .","label":"Uses","metadata":{},"score":"55.88323"}{"text":"Data .We used three different sentence - aligned corpora , covering different language pairs and sizes : ( 1 ) Europarl Release v3 Spanish - English [ 7 ] , ( 2 ) UN Chinese - English corpus provided by the Linguistic Data Consortium , ( 3 ) Giga corpus French - English [ 8 ] .","label":"Uses","metadata":{},"score":"55.998104"}{"text":"We also provide insight into the way statistical machine translation learns from data , including the respective influence of translation and language models , the impact of phrase length on performance , and various unlearning and perturbation analyses .Our results support and illustrate the fact that performance improves by a constant amount for each doubling of the data , across different language pairs , and different systems .","label":"Uses","metadata":{},"score":"56.057407"}{"text":"To be consistent and to avoid anomalies due to overfitting or particular data combinations , each set of pairs of sentences has been randomly sampled .The number of pairs is fixed , and a program selects them randomly from the whole original training , development , or test set using a uniform distribution .","label":"Uses","metadata":{},"score":"56.063484"}{"text":"Results on Chinese - to - English and Arabic - to - English tracks using supplied data are reported . ... rdered search , which is guided by the N - gram model of the unfolded tuples and the additional feature models .","label":"Uses","metadata":{},"score":"56.150307"}{"text":"This article describes a machine translation system based on an automatic post - editing strategy : initially translate the input text into the target - language using a rule - based MT system , then automatically post - edit the output using a statistical phrase - based system .","label":"Uses","metadata":{},"score":"56.201256"}{"text":"This article describes a machine translation system based on an automatic post - editing strategy : initially translate the input text into the target - language using a rule - based MT system , then automatically post - edit the output using a statistical phrase - based system .","label":"Uses","metadata":{},"score":"56.201256"}{"text":"This trade - off between quality and time usage can also be found in speech recognition .As the translation systems are not able to store all native strings and their translations , a document is typically translated sentence by sentence , but even this is not enough .","label":"Uses","metadata":{},"score":"56.303493"}{"text":"Examples of this approach include DOP -based MT and , more recently , synchronous context - free grammars .Hierarchical phrase - based translation combines the strengths of phrase - based and syntax - based translation .It uses synchronous context - free grammar rules , but the grammars may be constructed by an extension of methods for phrase - based translation without reference to linguistically motivated syntactic constituents .","label":"Uses","metadata":{},"score":"56.37716"}{"text":"Of course , there are other ways to do machine translation .Most commercial systems use transfer rules and a rich translation lexicon .Machine translation research was focused on transfer - based systems in the 1980s and on knowledge based systems that use an interlingua representation as an intermediate step between input and output in the 1990s .","label":"Uses","metadata":{},"score":"56.43386"}{"text":"--max - phrase - length -- maximum length of phrases entered into phrase table ( default 7 ) .GIZA++ Options .GIZA++ takes a lot of parameters to specify the behavior of the training process and limits on sentence length , etc .","label":"Uses","metadata":{},"score":"56.506386"}{"text":"The extensions of GIZA++ were designed and written by Franz Josef Och .About GIZA++ .The program includes the following extensions to GIZA : .Model 4 ; .Model 5 ; .Alignment models depending on word classes ( software for producing word classes can be downloaded here ; .","label":"Uses","metadata":{},"score":"56.6642"}{"text":"The extended graph is traversed in decoding when a fullyinformed decision can be taken ( no preprocessing decision about reordering is taken ) .We also show how the N - gram translation model can be successfully used as reordering model when estimated with reordered source words ( to harmonize the source and target word order ) .","label":"Uses","metadata":{},"score":"56.7398"}{"text":"This unrealistic case is not affected by the Zipf 's law , because almost all the words necessary to translate the training material have , by definition , already been observed .The model is therefore able to match long phrases when producing the \" test on training set ' ' translations .","label":"Uses","metadata":{},"score":"56.759457"}{"text":"If we intersect the two alignments , we get a high - precision alignment of high - confidence alignment points .If we take the union of the two alignments , we get a high - recall alignment with additional alignment points .","label":"Uses","metadata":{},"score":"56.887188"}{"text":"Role of Training Set Size on Performance on New Sentences .In this section , we analyze how training set size affects the performance by creating learning curves ( BLEU score versus training set size ) .The general framework for this set of experiments consists of creating subsets of the complete corpus by subsampling from a uniform distribution without replacement .","label":"Uses","metadata":{},"score":"56.962395"}{"text":"One way to achieve this could be to either introduce an oracle to which the system can ask for annotation when needed or a process that uses linguistic knowledge to create new table entries based on existing table entries and some grammatical rules .","label":"Uses","metadata":{},"score":"56.988304"}{"text":"In this paper , we present the Thot toolkit , a set of tools to train phrase - based models for statistical machine translation , which is publicly available as open source software .The toolkit obtains phrase - based models from word - based alignment models ; to our knowledge , this functionality has not been offered by any publicly available toolkit .","label":"Uses","metadata":{},"score":"57.05425"}{"text":"Other researchers used augmented their systems with phrase translation , such as Yamada , who use phrase translation in a syntax - based model .Marcu introduced a joint - probability model for phrase translation .At this point , most competitive statistical machine translation systems use phrase translation , such as the CMU , IBM , ISI , and Google systems , to name just a few .","label":"Uses","metadata":{},"score":"57.156067"}{"text":"In particular , existing statistical systems for machine translation often treat different inflected forms of the same lemma as if they were independent of one another .The bilingual training data can be better exploited by explicitly taking into account the interdependencies of related inflected forms .","label":"Uses","metadata":{},"score":"57.215324"}{"text":"The decoder implements a beam search and is roughly similar to work by Tillmann ( PhD , 2001 ) and Och ( PhD , 2002 ) .In fact , by reframing Och 's alignment template model as a phrase translation model , the decoder is also suitable for his model , as well as other recently proposed phrase models .","label":"Uses","metadata":{},"score":"57.233604"}{"text":"Results on two translation directions are reported , namely from Arabic and Chinese into English , thoroughly explaining all language - related preprocessing and translation schemes .nce , we allow the source words to be reordered before extracting translation units from training sentence pairs by following the word - to - word alignments .","label":"Uses","metadata":{},"score":"57.335194"}{"text":"In each case , we found the same overall behaviour , of a logarithmic growth in performance with training set size .The question becomes as follows : on which aspect of these systems should we act to achieve better performance ?","label":"Uses","metadata":{},"score":"57.345024"}{"text":"Current phrase - based SMT systems perform poorly when using small training sets .This is a consequence of unreliable translation estimates and low coverage over source and target phrases .This paper presents a method which alleviates this problem by exploiting multiple translations of the same source phrase .","label":"Uses","metadata":{},"score":"57.374348"}{"text":"The impressive capability of current machine translation systems is not only a testament to an incredibly productive and creative research community , but can also be seen as a paradigm for other artificial intelligence tasks .Data - driven approaches to all main areas of AI currently deliver the state - of - the - art performance , from summarization to speech recognition to machine vision to information retrieval .","label":"Uses","metadata":{},"score":"57.42103"}{"text":"This decomposition is attractive as it splits the problem into two subproblems .Finding the best translation is done by picking up the one that gives the highest probability : . . .For a rigorous implementation of this one would have to perform an exhaustive search by going through all strings in the native language .","label":"Uses","metadata":{},"score":"57.53246"}{"text":"For each subset , a new instance of the PBSMT system has been created , for a total of 100 models .Each model has been tested on the test set and on a subset of 2,000 pairs the training set .","label":"Uses","metadata":{},"score":"57.565735"}{"text":"In Figure 8 , BLEU score as function of the development size is reported .The optimization procedure increases the quality of the translations .This improvement does not seem to be significant after a certain size of the development set .","label":"Uses","metadata":{},"score":"57.64702"}{"text":"While we refer to \" words swap ' ' when , given two entries of the translation model , we swap the target language phrases .Three different sets of experiments have been run applying \" numerical swap ' ' only to the language model , \" numerical swap ' ' only to the translation model and \" words swap ' ' only to the translation model .","label":"Uses","metadata":{},"score":"57.78219"}{"text":"Since the entire phrase translation table may be too big to fit into memory , we can restrict ourselves to these translation options to overcome such computational concerns .We may even generate a phrase translation table on demand that only includes valid translation options for a given input text .","label":"Uses","metadata":{},"score":"57.782654"}{"text":"We have isolated 4,000 pairs of sentences from the Europarl training set , and we have selected from the remaining part 629,957 pairs .A Moses model is trained using this set .Using the 4,000 sentences pairs , we have created 10 random subsets for each of the 16 chosen sizes , where each size can contain a number of pairs from 250 to 4,000 by a step of 250 pairs .","label":"Uses","metadata":{},"score":"57.804886"}{"text":"In any case , the addition of massive amounts of data from the same distribution will result in small improvements in the performance .The small error bars that we have obtained also allow us to regard the stability of the SMT when trained on the same training set size .","label":"Uses","metadata":{},"score":"57.80711"}{"text":"However , the difference in word order between two languages is one of t ... \" .Statistical Machine Translation ( SMT ) is based on alignment models which learn from bilingual corpora the word corre - spondences between source and target lan - guage .","label":"Uses","metadata":{},"score":"57.9013"}{"text":"Although the rate of improvement may depend on both the data and the estimation method , it is unlikely that the general shape of the learning curve will change without major changes in the modeling and inference phases .Possible research directions that address this issue include the integration of linguistic rules or the development of active learning procedures .","label":"Uses","metadata":{},"score":"58.053513"}{"text":"Are both unaligned ?What is the lexical probability for the potential point ?Och and Ney ( Computational Linguistics , 2003 ) are ambigous in their description about which alignment points are added in their refined method .We reimplemented their method for Moses , so we will describe this interpretation here .","label":"Uses","metadata":{},"score":"58.116318"}{"text":"However , this hard constraint can also rule out correct alignments , and its utility decreases as alignment models become more ... \" .Word alignment methods can gain valuable guidance by ensuring that their alignments maintain cohesion with respect to the phrases specified by a monolingual dependency tree .","label":"Uses","metadata":{},"score":"58.16863"}{"text":"For each subset , a new instance of the PBSMT system has been created , for a total of 200 models .Two hundred experiments have then been run on an independent test set ( of 2,000 sentences , also not included in any other phase of the experiment ) .","label":"Uses","metadata":{},"score":"58.18025"}{"text":"They contain different modules to preprocess data and train the language models and the translation models .These models can be tuned using minimum error rate training [ 17 ] .Both use standard external tools for training the language model , such as SRILM [ 23 ] , and Moses also uses GIZA++ [ 24 ] for word alignments .","label":"Uses","metadata":{},"score":"58.184956"}{"text":"In practice , the output from these systems needs to be edited to correct errors .A way of increasing the productivity of the whole translation process ( MT plus human work ) is to incorporate the human correction activities within the translation process itself , thereby shifting the MT paradigm to that of computer - assisted translation .","label":"Uses","metadata":{},"score":"58.211437"}{"text":"One effective way to do that is to post - edit the translations produced by a vanilla RBMT system using a specially - trained statistical machine translation ( SMT ) system .Our experiments indicate that this method is just as effective as manual customization of system dictionaries in reducing the need for manual post - editing . ... entence - length feature .","label":"Uses","metadata":{},"score":"58.228783"}{"text":"In Section 3.4 , we report the correlation coefficient between all the measures .Each correlation coefficient is computed using the results of the 160 experiments described above .Acknowledgments .This work is supported by the EU IST Project SMART ( FP6 - 033917 ) .","label":"Uses","metadata":{},"score":"58.303867"}{"text":"This is done by treating the parser 's derivation tree as a latent variable in a model that is trained to maximize reordering accuracy .We demonstrate that efficient large - margin training is possible by showing that two measures of reordering accuracy can be factored over the parse tree .","label":"Uses","metadata":{},"score":"58.31298"}{"text":"One , containing 1,159,914 pairs of sentences , has been used to train the model .This step has been done only once , and all the experiments use the same translation , language , and reordering models .The second set has 100,000 pairs of sentences , and it is used to randomly select the development sets .","label":"Uses","metadata":{},"score":"58.33718"}{"text":"The evaluation of a machine translation system is a lively and hotly debated topic in this field .Ideally , human beings can evaluate the quality of a translated sentence .However , this is unfeasible for rapid development of automatically trained systems with multiple parameter tuning , as human evaluation is expensive , slow , and sometimes inconsistent and subjective .","label":"Uses","metadata":{},"score":"58.39891"}{"text":"We investigate the learning - theoretic implications of this setting , including the interplay between approximation error and estimation error , model selection , and accuracy in parameters estimation .We do not address more general themes about the opportunity for SMT to be evaluated by automatic metrics .","label":"Uses","metadata":{},"score":"58.40785"}{"text":"Archives .Categories .Meta .Welcome .GIZA++ : Training of statistical translation models .GIZA++ is an extension of the program GIZA ( part of the SMT toolkit EGYPT ) which was developed by the Statistical Machine Translation team during the summer workshop in 1999 at the Center for Language and Speech Processing at Johns - Hopkins University ( CLSP / JHU ) .","label":"Uses","metadata":{},"score":"58.42611"}{"text":"Among possible methods , two stand out as particularly promising .The first is to generate phrase pairs by using grammatical or various linguistic rules ( e.g. , turning existing entries into new entries , by applying various forms of inflection ) .","label":"Uses","metadata":{},"score":"58.428726"}{"text":"In speech translation , HMMs can be trained from a source speech corpus , and the translation model can be learned automatically from a parallel training corpus . ... by Stephan Vogel , Franz Josef Och , Christof Tillmann , Sonja Nießen , Hassan Sawaf , Hermann Ney - Verbmobil : Foundations of Speech - toSpeech Translation , 2000 .","label":"Uses","metadata":{},"score":"58.60149"}{"text":"Using long phrases will help when the system has to translate sequences of words that match what was encountered in the training corpus , but this becomes increasingly unlikely as the phrases become longer .On the other hand , short sentences are more often reused , but may also be more ambiguous and lead to errors more often .","label":"Uses","metadata":{},"score":"58.654083"}{"text":"The unfolding technique produces a different bilingual N - gram language model with reordered source words .Usually , ... .by Josep M. Crego , Nizar Habash - In Proceedings of the Third Workshop on Statistical Machine Translation , 2008 . \" ...","label":"Uses","metadata":{},"score":"58.66758"}{"text":"Parameters can be passed on to GIZA++ with the switch --giza - option .Dealing with large training corpora .Training on large training corpora may become a problem for the GIZA++ word alignment tool .Since it stores the word translation table in memory , the size of this table may become too large for the available RAM of the machine .","label":"Uses","metadata":{},"score":"58.70365"}{"text":"[ 15 ] .SMT systems typically store different word forms as separate symbols without any relation to each other and word forms or phrases that were not in the training data can not be translated .This might be because of the lack of training data , changes in the human domain where the system is used , or differences in morphology .","label":"Uses","metadata":{},"score":"58.71273"}{"text":"Domain Adaptation usually means adjusting parameters to cope with a mismatch between old ( training ) and new domains .However , even when there is no new domain , there can be significant variation among and within documents .Can SMT performance benefit from the use of adaptation techniques to capture this variation ?","label":"Uses","metadata":{},"score":"58.741493"}{"text":"Bilingual word alignment forms the foundation of most approaches to statistical machine translation .Current word alignment methods are predominantly based on generative models .In this paper , we demonstrate a discriminative approach to training simple word alignment models that are comparable in accuracy to the more complex generative models normally used .","label":"Uses","metadata":{},"score":"58.774548"}{"text":"Our best model produces the lowest alignment error rate yet reported on Canadian Hansards bilingual data . ...e probabalistic models developed at IBM by Brown et al .( 1993 ) , sometimes augmented by an HMMbased model or Och and Ney 's \" Model 6 \" ( Och and Ney , 2003 ) . \" ...","label":"Uses","metadata":{},"score":"58.794903"}{"text":"This phrase - based machine translation approach relies on a specific representation of the translation process , such as the choice of contiguous word sequences ( phrases ) as basic units in the language and translation models .How far can this representation take us towards the target of improving translation quality ?","label":"Uses","metadata":{},"score":"58.824635"}{"text":"In practice this trade - off is easily observed , by noticing how the training error can be driven to zero by using a rich hypothesis class , which typically results into overfitting and increased test error .In the context of statistical machine translation ( SMT ) , where large bilingual corpora are used to train adaptive software to translate text , this task is further complicated by the peculiar distribution underlying the data , where the probability of encountering new words or expressions never vanishes .","label":"Uses","metadata":{},"score":"58.87967"}{"text":"Typically , these difficulties are caused by errors of the recognition process , which is carried out before the translation process ... . \" ...In this paper , we present the Thot toolkit , a set of tools to train phrase - based models for statistical machine translation , which is publicly available as open source software .","label":"Uses","metadata":{},"score":"59.009575"}{"text":"We also discuss the more general , and computationally more difficult , problem of finding good parsing strategies for non - binarizable rules , and present an approximate polynomial - time algorithm for this problem . \" ...For many years , statistical machine translation relied on generative models to provide bilingual word alignments .","label":"Uses","metadata":{},"score":"59.011303"}{"text":"Since the training is modular , you can start training at any of the seven training steps --first - step and end it at any subsequent step --last - step .Again , the nine training steps are : .Create configuration file .","label":"Uses","metadata":{},"score":"59.144947"}{"text":"The language pairs cover European as well as non - European languages , and the sizes range from 1.2 M to 22.5 M sentence pairs .We expect that translation between European languages will be easier than from Chinese to English ; however , we are not so much interested in the actual translation performance as in the way this performance evolves with increasing data and under a number of conditions .","label":"Uses","metadata":{},"score":"59.326065"}{"text":"Our findings are also consistent with the curves presented by [ 33 ] , although their results are limited to a much lower data set size ( less than . sentences ) and presented on a linear scale .Incidentally , that paper also presents a recent attempt into using active learning for improving MT and meets the challenge of \" diminishing returns ' ' identified in the learning curves : a constant performance improvement requires increasing amounts of data .","label":"Uses","metadata":{},"score":"59.361717"}{"text":"We show that our best approaches result in more accurate translations at no extra computational cost .Performance improvements were measured with two competitive SMT systems , respectively , translating from Arabic to English and from German to English .( Joint work with Arianna Bisazza , FBK ) .","label":"Uses","metadata":{},"score":"59.462646"}{"text":"When extracting longer phrases , we expect training set performance to be higher , but test performance to drop ( overfitting ) .Optimizing test performance requires the right trade - off .In this section , we analyze how the phrase length can affect the performance in terms of BLEU score .","label":"Uses","metadata":{},"score":"59.512093"}{"text":"One of our key findings is that the current performance of phrase - based statistical machine translation systems is not limited by the representation power of the hypothesis class , but rather by model estimation from data .In other words , we demonstrate that parameter choices exist that can deliver significantly higher performance , but that inferring them from finite samples is the problem .","label":"Uses","metadata":{},"score":"59.570885"}{"text":"( i ) Unlearning by Adding Noise .A percentage of noise has been added to each probability , . , in the Language model , including conditional probability , and translation model , bidirectional phrase translation probabilities and lexicalized weighting .","label":"Uses","metadata":{},"score":"59.576027"}{"text":"This is useful because the language model feature typically favours shorter sentences ( because each additional trigram can only lower the language model probability ) .This is a simple , yet effective feature .The process of training a machine translation system involves estimating the various parameters of the model : the log - linear parameters . as well as the parameters internal to the feature functions , such as the phrase translation probabilities and language model n -gram and backoff probabilities .","label":"Uses","metadata":{},"score":"59.70002"}{"text":"The complexity is exponential in the size of individual grammar rules due to arbitrary re - orderings between the two languages .We develop a theory of binarization for synchronous context - free grammars and present a linear - time algorithm for binarizing synchronous rules when possible .","label":"Uses","metadata":{},"score":"59.854828"}{"text":"The restrictions are generalized , and a set of four parameters to control the word reordering is introduced , which then can easily be adopted to new translation directions .The beam search procedure has been successfully tested on the Verbmobil task ( German to English , 8,000-word vocabulary ) and on the Canadian Hansards task ( French to English , 100,000-word vocabulary ) .","label":"Uses","metadata":{},"score":"59.95643"}{"text":"In the end , the best hypothesis of the ones that cover all foreign words is the final state of the best translation .We can read off the English words of the translation by following the back links in each hypothesis .","label":"Uses","metadata":{},"score":"60.075848"}{"text":"The context of a whole corpus of automatic translations rather than a single sentence is taken into account in order to achieve high alignment quality .The confusion network is rescored with a special language model , and the consensus translation is extracted as the best path .","label":"Uses","metadata":{},"score":"60.142082"}{"text":"The figure below gives pseudo - code for the algorithm we used for our beam search .For each number of foreign words covered , a hypothesis stack in created .The initial hypothesis is placed in the stack for hypotheses with no foreign words covered .","label":"Uses","metadata":{},"score":"60.16674"}{"text":"In our implementation , we store the information about hypotheses , hypothesis transitions , and additional arcs in a file that can be processed by the finite state toolkit Carmel , which we use to mine the n - best lists .","label":"Uses","metadata":{},"score":"60.209854"}{"text":"( 1993 ) .Starting from a DP - based solution to the traveling - salesman problem , we present a n ... \" .In this article , we describe an efficient beam search algorithm for statistical machine translation based on dynamic programming ( DP ) .","label":"Uses","metadata":{},"score":"60.47345"}{"text":"I. . ... andard word alignment and translation models described in Section IV - A1 .The system also used two large language models , both trained on the same data : a 4-gram language model using modified Kneser - Ney smoothing , and a suffix array language model with arbitrary history l .. \" ...","label":"Uses","metadata":{},"score":"60.742214"}{"text":"Does the performance improve with more data because certain parameters are estimated better , or just because the lists are growing ?In the second case , it is likely that more sophisticated statistical algorithms to improve the estimation of probabilities will have limited impact .","label":"Uses","metadata":{},"score":"60.824844"}{"text":"It has been shown that restricting the phrases to linguistic phrases ( syntactically motivated groups of words , see syntactic categories ) decreases the quality of translation .[ 12 ] .Syntax - based translation is based on the idea of translating syntactic units , rather than single words or strings of words ( as in phrase - based MT ) , i.e. ( partial ) parse trees of sentences / utterances .","label":"Uses","metadata":{},"score":"60.836205"}{"text":"Previous generative word alignment models have made structural assumptions such as the 1-to-1 , 1-to - N , or phrase - based consecutive word assumptions , while previous discriminative models have either made such ... \" .Word alignment is the problem of annotating parallel text with translational correspondence .","label":"Uses","metadata":{},"score":"60.871822"}{"text":"We present the PORTAGE statistical machine translation system which participated in the shared task of the ACL 2007 Second Workshop on Statistical Machine Translation .The focus of this description is on improvements which were incorporated into the system over the last year .","label":"Uses","metadata":{},"score":"61.014603"}{"text":"Briefly , the system performs a log - linear combination of a translation model and additional feature functions .The translation model is estimated as an N - gram of bilingual units called tuples , and the feature functions include a target language model , a word penalty , and lexical features , depending on the language pair and task .","label":"Uses","metadata":{},"score":"61.135933"}{"text":"We approximate the cost for a path through translation options by the product of the cost for each option .To illustrate this concept , refer to the figure below .The translation options cover different consecutive foreign words and carry an estimated cost c ij .","label":"Uses","metadata":{},"score":"61.25118"}{"text":"First , the absence of representative \" new \" data means that adaptation must take place solely on the basis of the current source document .Second , within - domain variation can occur at the sub - document level , requiring that different parts of a document be treated differently .","label":"Uses","metadata":{},"score":"61.252663"}{"text":"Also note that if the foreign words not covered so far are two ( or more ) disconnected sequences of foreign words , the combined cost is simply the product of the costs for each contiguous sequence .Since there are only n(n+1)/2 contiguous sequences for n words , the future cost estimates for these sequences can be easily precomputed and cached for each input sentence .","label":"Uses","metadata":{},"score":"61.27604"}{"text":"Possible questions , that are encouraged to be addressed during the workshop , include : . ways of applying M - tools to monolingual MT subtasks such as MT for morphologically rich languages and statistical post - editing . investigation of the suitability of B - tools or M - tools for monolingual MT subtasks .","label":"Uses","metadata":{},"score":"61.32425"}{"text":"However , it is much harder to detect and score global properties over such data structures .Additional Arcs in the Search Graph .Recall the process of state expansions .The generated hypotheses and the expansions that link them form a graph .","label":"Uses","metadata":{},"score":"61.372753"}{"text":"A lot of older compiler version do not fully support all features of STL that are used by GIZA++ .Therefore , frequently occur compiler , assembler or linker problems which are mostly due to the intensive use of STL within the program .","label":"Uses","metadata":{},"score":"61.50222"}{"text":"Our key assumption is that collocation errors are often caused by semantic similarity in the first language ( L1language ) of the writer .An analysis ... \" .We present a novel approach for automatic collocation error correction in learner English which is based on paraphrases extracted from parallel corpora .","label":"Uses","metadata":{},"score":"61.513252"}{"text":"In an age where the creation of intelligent behaviour is increasingly data driven , this is a question of great importance to all of artificial intelligence .In phrase - based approaches to statistical machine translation , translations are generated in response to some input source text .","label":"Uses","metadata":{},"score":"61.64386"}{"text":"The log - linear parameters are then estimated by minimum error rate training ( MERT ) .The weights .is the set of sentence pairs over which MERT is performed .Solving ( 3 ) is difficult because the decoding necessary to produce the hypothesis translation is expensive .","label":"Uses","metadata":{},"score":"61.878353"}{"text":"If we would do this , the search graph would only contain one path for each hypothesis in the last hypothesis stack ( which contains hypotheses that cover all foreign words ) .If we store information that there are multiple ways to reach a hypothesis , the number of possible paths also multiplies along the path when we traverse backward through the graph .","label":"Uses","metadata":{},"score":"61.959282"}{"text":"The model is l ... \" .We present a novel translation model based on tree - to - string alignment template ( TAT ) which describes the alignment be - tween a source parse tree and a target string .A TAT is capable of generating both terminals and non - terminals and per - forming reordering at both low and high levels .","label":"Uses","metadata":{},"score":"62.093872"}{"text":"All models are used during search , i.e. they are incorporated directly into the log - linear model combination of the decoder .Phrase table smoothing with triplet lexicon models and with discriminative word lexicons are novel contributions .We also propose a new regularization technique for IBM model 1 by means of the Kullback - Leibler divergence with the empirical unigram distribution as regularization term .","label":"Uses","metadata":{},"score":"62.097507"}{"text":"We begin the search in an initial state where no foreign input words are translated and no English output words have been generated .New states are created by extending the English output with a phrasal translation of that covers some of the foreign input words not yet translated .","label":"Uses","metadata":{},"score":"62.11714"}{"text":"This is done iteratively until no alignment point can be added anymore .In a final step , we add non - adjacent alignment points , with otherwise the same requirements .We collect all aligned phrase pairs that are consistent with the word alignment : The words in a legal phrase pair are only aligned to each other , and not to words outside .","label":"Uses","metadata":{},"score":"62.160427"}{"text":"Experimental results on the test data of the previous campaign are presented . ... to Canadian universities for research and education purposes . \" ...Current phrase - based SMT systems perform poorly when using small training sets .This is a consequence of unreliable translation estimates and low coverage over source and target phrases .","label":"Uses","metadata":{},"score":"62.16062"}{"text":"Performance of an SMT system is a function of the dimension of the training data that can be logarithmic as seen in the previous section .We have modelled this relation in the following way : . of the data as increasing set size .","label":"Uses","metadata":{},"score":"62.21791"}{"text":"Authors in [ 30 ] reported \" almost linear \" improvements in BLEU score by doubling the training set size .In the presentation [ 32 ] , the claim is that BLEU increases with each doubling of the training set size , by 0.5 and 2.5 BLEU points for the language and translation models , respectively , in the context of Arabic - English translation .","label":"Uses","metadata":{},"score":"62.23703"}{"text":"295 - 302 , Philadelphia , Pa , USA , 2001 .R. C. Moore , W.-T. Yih , and A. Bode , \" Improved discriminative bilingual word alignment , \" in Proceedings of the 21stInternational Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics ( ACL ' 06 ) , pp .","label":"Uses","metadata":{},"score":"62.337303"}{"text":"In speech recognition , the speech signal and the corresponding textual representation can be mapped to each other in blocks in order .This is not always the case with the same text in two languages .For SMT , the machine translator can only manage small sequences of words , and word order has to be thought of by the program designer .","label":"Uses","metadata":{},"score":"62.403767"}{"text":"Interestingly , within this framework , the adaptation of MT systems to the interactive scenario affects mainly the search process , allowing a great reuse of successful techniques and models .In this article , alignment templates , phrase - based models , and stochastic finite - state transducers are used to develop computer - assisted translation systems .","label":"Uses","metadata":{},"score":"62.427784"}{"text":"A Systematic Comparison of Various Statistical Alignment Models \" , Computational Linguistics , volume 29 , number 1 , pp .19 - 51 March 2003 .Acknowledgements .This work was supported by the National Science Foundation under Grant No .","label":"Uses","metadata":{},"score":"62.491955"}{"text":"Traditional approaches to machine translation ( MT ) [ 1 ] relied to a large extent on linguistic analysis .The ( relatively ) recent development of statistical approaches [ 2 ] and especially phrase - based machine translation , or PBMT [ 3 , 4 ] , has put the focus on the intensive use of large parallel corpora .","label":"Uses","metadata":{},"score":"62.76925"}{"text":"Monolingual word alignment for system combination and other MT - related applications .Combination of the output of multiple machine translation ( MT ) systems has been a hot research topic in the recent years , yielding very promising results .The word - level system combination methods that produce a consensus translation rely on monolingual word alignment between the different translation hypotheses .","label":"Uses","metadata":{},"score":"62.968643"}{"text":"The statistical translation models were initially word based ( Models 1 - 5 from IBM Hidden Markov model from Stephan Vogel [ 6 ] and Model 6 from Franz - Joseph Och [ 7 ] ) , but significant advances were made with the introduction of phrase based models .","label":"Uses","metadata":{},"score":"62.98752"}{"text":"If two words are generated , we take the unigram probability of the first word and the bigram probability of the second word , and so on .For a sequence of foreign words multiple overlapping translation options exist .We just described how we calculate the cost for each translation option .","label":"Uses","metadata":{},"score":"63.018074"}{"text":"We could base the judgment of what inferior hypotheses are on the cost of each hypothesis so far .However , this is generally a very bad criterion , since it biases the search to first translating the easy part of the sentence .","label":"Uses","metadata":{},"score":"63.02221"}{"text":"The noised probability is obtained as ., ten experiments have been run .In this case , we randomly select two fixed training set sizes equal to 62,995 and 629,957 pairs of sentences form the Europarl corpora and use Moses as translation system .","label":"Uses","metadata":{},"score":"63.036198"}{"text":"In each task , the following three pairs of languages were involved ( in both translation . ...SFSTs ) , alignment templates ( ATs ) , and phrase - based models ( PBMs ) are compared in this work .This article shows that 1 The terms prefix and suffix are used here to denote ... . by Christoph Tillmann , Hermann Ney - In Proc . of the COLING 2000 , JulyAugust , 2000 . \" ...","label":"Uses","metadata":{},"score":"63.048508"}{"text":"( default 0.5 ) .Basic Options .A number of parameters are required to point the training script to the correct training data .We will describe them in this section .Other options allow for partial training runs and alternative settings .","label":"Uses","metadata":{},"score":"63.132393"}{"text":"We also believe that in this particular situation , the presence of the error bars may help to better understand the stability of the system .Using the framework described above , four different settings have been set to produce learning curves , see Table 3 .","label":"Uses","metadata":{},"score":"63.38248"}{"text":"Tools . by Yang Liu , Qun Liu , Shouxun Lin - in Proceedings of COLING - ACL , 2006 . \" ...We present a novel translation model based on tree - to - string alignment template ( TAT ) which describes the alignment be - tween a source parse tree and a target string .","label":"Uses","metadata":{},"score":"63.465"}{"text":"The study has been carried out on two different translation tasks ( in terms of translation difficulty and amount of available training data ) , and allowing for distortion ( reordering ) in the decoding process .Thus it extends a previous work were both approaches were compared under monotone conditions .","label":"Uses","metadata":{},"score":"63.55906"}{"text":"( ii ) Unlearning by Randomization of Parameters .The second kind of noise that we add to the model is based on a swap of a particular quantity inside two entries of language or translation model .This is meant to test how robust the system is to perturbations of the all - important associations between phrases / numbers and to the associations between source / target phrases .","label":"Uses","metadata":{},"score":"63.880524"}{"text":"Our first concerns were to distinguish between approximation and estimation error : the performance limitations due to the use of a limited language model versus those due to the need to estimate the parameters of that model from a finite sample .","label":"Uses","metadata":{},"score":"63.913826"}{"text":"Results show how the ngram - based approach outperforms the phrase - based approach by achieving similar accuracy scores in less computational time and with less memory needs .nce reordered .This procedure poses additional difficulties when applied to the ngram - based approach , because the characteristics of the ngram - based translation model . by Josep M. Crego , Adrià De Gispert , José B. Mariño - in Proc .","label":"Uses","metadata":{},"score":"63.924156"}{"text":"A \" serial architecture \" would use the Hidden Markov and the language models for recognizing input utterance and the transducer for finding the translation .An \" integrated architecture \" , on the other hand , would integrate all the models in a single network where the search process takes place .","label":"Uses","metadata":{},"score":"64.05588"}{"text":"For the second set of experiments , data has been randomly sampled in training and test sets one thousand times .Training set has been used to estimate the alphas and the residual , and test set to predict the BLEU score values .","label":"Uses","metadata":{},"score":"64.10073"}{"text":"In the framework of the phrase - based model , not only may single words be translated individually , but also consecutive sequences of words as a phrase .Each such translation operation carries a translation cost , language model costs , and a distortion cost .","label":"Uses","metadata":{},"score":"64.23066"}{"text":"868 - 876 , 2007 .J. Blatz , E. Fitzgerald , G. Foster , et al . , \" Confidence estimation for machine translation , \" in Proceedings of the 20th international Conference on Computational Linguistics ( COLING ' 04 ) , vol .","label":"Uses","metadata":{},"score":"64.24123"}{"text":"When describing the phrase - based translation model so far , we did not discuss how to obtain the model parameters , especially the phrase probability translation table that maps foreign phrases to English phrases .Most recently published methods on extracting a phrase translation table from a parallel corpus start with a word alignment .","label":"Uses","metadata":{},"score":"64.33778"}{"text":"For each percentage value , ten experiments have been run .All the perturbations have been applied on a model trained with 629,957 pairs of sentences randomly selected form the Europal data using Moses as translation system .The unlearning curves are shown in Figure 7 .","label":"Uses","metadata":{},"score":"64.40547"}{"text":"Note that the inferior hypothesis can be part of the path to the second best translation .This is important for generating n - best lists .Beam Search .While the recombination of hypotheses as described above reduces the size of the search space , this is not enough for all but the shortest sentences .","label":"Uses","metadata":{},"score":"64.476654"}{"text":"Different statistical alignment models ( SAMs ) have been proposed .All these models fall into the category of singleword - based ( SWB ) SAM .Recent research in the field has demonstrated that phrase - based or context - based translation models outperform th ...","label":"Uses","metadata":{},"score":"64.51143"}{"text":"Clearly , all measures correlate strongly with each other , such that the choice of the performance measure is fairly arbitrary , as long as one is consistent .For this reason , we have chosen to use BLEU throughout this paper as it is the most widely used automatic score in machine translation .","label":"Uses","metadata":{},"score":"64.52852"}{"text":"However , the mapping between words is stored in a very redundant way within the TM , and this depends on the way the translation table is created , based on sentence alignments .Once an alignment has been found between two sentences , essentially every n -gram ( for every value of n ) is a candidate for insertion in the translation table .","label":"Uses","metadata":{},"score":"64.60341"}{"text":"Discriminative learning allows easy incorporation of any feature one might have access to during the alignment search .Because the features are handled so easily , ... . \" ...Word alignments that violate syntactic correspondences interfere with the extraction of string - to - tree transducer rules for syntaxbased machine translation .","label":"Uses","metadata":{},"score":"64.84121"}{"text":"^ a b D. Chiang ( 2005 ) .A Hierarchical Phrase - Based Model for Statistical Machine Translation .In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ( ACL'05 ) .^ P. Koehn , H. Hoang , A. Birch , C. Callison - Burch , M. Federico , N. Bertoldi , B. Cowan , W. Shen , C. Moran , R. Zens , C. Dyer , O. Bojar , A. Constantin , E. Herbst .","label":"Uses","metadata":{},"score":"64.87077"}{"text":"ISBN 0521874157 .Retrieved 22 March 2015 .Statistical machine translation is related to other data - driven methods in machine translation , such as the earlier work on example - based machine translation .Contrast this to systems that are based on hand - crafted rules .","label":"Uses","metadata":{},"score":"64.89938"}{"text":"^ Philipp Koehn , Franz Josef Och , Daniel Marcu : Statistical Phrase - Based Translation ( 2003 ) .^ Wołk , K. ; Marasek , K. \" Real - Time Statistical Speech Translation \" .Advances in Intelligent Systems and Computing ( Springer ) 275 : 107 - 114 .","label":"Uses","metadata":{},"score":"65.05218"}{"text":"However , combining those systems raises problems of how to achieve sentence segmentation , de - normalization and punctuation prediction needed for quality translations .[17 ] .^ Philipp Koehn ( 2009 ) .Statistical Machine Translation .Cambridge University Press .","label":"Uses","metadata":{},"score":"65.16164"}{"text":"Different location changes can be ranked with the help of the language model and the best can be selected .Recently , Skype voice communicator started testing speech translation .[14 ] However , machine translation is following technological trends in speech at a slower rate than speech recognition .","label":"Uses","metadata":{},"score":"65.26176"}{"text":"In other words , the essential limiting factor for phrase - based SMT systems seems to be the Zipf law found in natural language .Our large - scale analysis also suggests that the current bottleneck of the phrase - based SMT approach is the lack of sufficient data , not the function class used for the representation of translation systems .","label":"Uses","metadata":{},"score":"65.27879"}{"text":"Experimental results on WMT French - English data set confirm that our method significantly outperforms MERT on out - of - domain data sets , and performs marginally better than MERT on in - domain data sets , which validates the usefulness of MRC on both domain specific and general domain data .","label":"Uses","metadata":{},"score":"65.32329"}{"text":"Some will be quick to point out that maximizing , for example , BLEU may neither be necessary for , nor guarantee good translation performance .Although we acknowledge that automatic MT metrics may not tell the whole story as far as translation quality is concerned , our systematic study aims at characterizing the behaviour of SMT systems that are built by maximizing such metrics .","label":"Uses","metadata":{},"score":"65.47444"}{"text":"Relative Importance of TM and LM .In the previous section , experiments have been run using the same training set size for language and translation models .In general , there is a large difference in terms of cost of retrieving training data for language and translation models ; the former can be trained using monolingual data , while the second needs bilingual texts .","label":"Uses","metadata":{},"score":"65.56273"}{"text":"However , the difference in word order between two languages is one of the most important sources of errors in SMT .In this paper , we show that SMT can take advantatge of in - ductive learning in order to solve reorder - ing problems .","label":"Uses","metadata":{},"score":"65.672485"}{"text":"Starting from a DP - based solution to the traveling salesman problem , we present a novel technique to restrict the possible word reordering between source and target language in o ... \" .In this paper , we describe a search procedure for statistical machine translation ( MT ) based on dynamic programming ( DP ) .","label":"Uses","metadata":{},"score":"65.768776"}{"text":"F. J. Och and H. Weber , \" Improving statistical natural language translation with categories and rules , \" in Proceedings of the 17th International Conference on Computational Linguistics , vol .2 , pp .985 - 989 , Stroudsburg , Pa , USA , 1998 .","label":"Uses","metadata":{},"score":"65.82841"}{"text":"Current machine translation ( MT ) systems are still not perfect .In practice , the output from these systems needs to be edited to correct errors .A way of increasing the productivity of the whole translation process ( MT plus human work ) is to incorporate the human correction activities within the tra ... \" .","label":"Uses","metadata":{},"score":"65.904785"}{"text":"This has considerable speed advantages over computing future cost on the fly .N - Best Lists Generation .Usually , we expect the decoder to give us the best translation for a given input according to the model .But for some applications , we might also be interested in the second best translation , third best translation , and so on .","label":"Uses","metadata":{},"score":"66.00333"}{"text":"This paper is based on the work carried out in the framework of the Verbmobil project , which is a limited - domain speech translation task ( German - English ) .In the nal evaluation , the statistical approach was found to perform best among ve competing approaches .","label":"Uses","metadata":{},"score":"66.081276"}{"text":"This paper is based on the work carried out in the framework of the Verbmobil project , which is a limited - domain speech translation task ( German - English ) .In the nal evaluation , the statistical approach was found to perform best among ve competing approaches .","label":"Uses","metadata":{},"score":"66.081276"}{"text":"[ 9 ] .Statistical machine translation usually works less well for language pairs with significantly different word order .The benefits obtained for translation between Western European languages are not representative of results for other language pairs , owing to smaller training corpora and greater grammatical differences .","label":"Uses","metadata":{},"score":"66.15637"}{"text":"If you need a laptop and are unable to borrow one , please contact the organizers .Poster Presentation Each poster will have a table with two chairs and a 4-foot long by 3-foot high poster board ( big enough to accommodate A0 paper format ) .","label":"Uses","metadata":{},"score":"66.31905"}{"text":"In statistical machine translation , correspondences between the words in the source and the target language are learned from parallel corpora , and often little or no linguistic knowledge is used to structure the underlying models .In particular , existing statistical systems for machine translation o ... \" .","label":"Uses","metadata":{},"score":"66.4471"}{"text":"The path to that directory has to be specified with the parameter --root - dir .The root directory has to contain a sub directory ( called corpus ) that contains the training data .The training data is a parallel corpus , stored in two files , one for the English sentences , one for the foreign sentences .","label":"Uses","metadata":{},"score":"66.47173"}{"text":"The first statistical models were word based [ 2 , 11 ] , combining a Markovian language model with a generative word - to - word translation model , in a noisy channel model inspired by speech recognition research .Current state - of - the - art SMT uses phrase - based models , which generalized and superseded word - based models .","label":"Uses","metadata":{},"score":"66.47368"}{"text":"How much space for improvement is there , given new data or new statistical estimation methods or given different models with different complexities ?Before we present experimental results that address these questions , we will describe the setup that was used to obtain these results .","label":"Uses","metadata":{},"score":"66.48985"}{"text":"The main concern is the exponential explosion from the 2 n f possible configurations of foreign words covered by a hypothesis .Note this causes the problem of machine translation to become NP - complete ( Knight , Computational Linguistics , 1999 ) and thus dramatically harder than , for instance , speech recognition .","label":"Uses","metadata":{},"score":"66.500534"}{"text":"This paper addresses the problem of reordering in statistical machine translation ( SMT ) .We describe an elegant and efficient approach to couple reordering ( word order monotonization ) and decoding , which does not need for any additional model .","label":"Uses","metadata":{},"score":"66.553925"}{"text":"This paper addresses the problem of reordering in statistical machine translation ( SMT ) .We describe an elegant and efficient approach to couple reordering ( word order monotonization ) and decoding , which does not need for any additional model .","label":"Uses","metadata":{},"score":"66.553925"}{"text":"Feature function weights in the log - linear model are set using Och 's minimum ... . \" ...Abstract - This paper describes an approach for computing a consensus translation from the outputs of multiple machine translation ( MT ) systems .","label":"Uses","metadata":{},"score":"66.56494"}{"text":"We describe the details of our future cost estimation in the next section .Given the cost so far and the future cost estimation , we can prune out hypotheses that fall outside the beam .The beam size can be defined by threshold and histogram pruning .","label":"Uses","metadata":{},"score":"66.66905"}{"text":"Each derived hypothesis is placed in a stack based on the number of foreign words it covers . initialize hypothesisStack[0 .We proceed through these hypothesis stacks , going through each hypothesis in the stack , deriving new hypotheses for this hypothesis and placing them into the appropriate stack ( see figure below for an illustration ) .","label":"Uses","metadata":{},"score":"66.72842"}{"text":"An analysis of a large corpus of annotated learner English confirms this assumption .We evaluate our approach on real - world learner data and show that L1-induced paraphrases outperform traditional approaches based on edit distance , homophones , and WordNet synonyms . ... where f denotes a foreign phrase in the L1 language .","label":"Uses","metadata":{},"score":"66.792046"}{"text":"See the figure below for some examples what this means .All alignment points for words that are part of the phrase pair have to be in the phrase alignment box .It is fine to have unaligned words in a phrase alignment , even at the boundary .","label":"Uses","metadata":{},"score":"66.962105"}{"text":"Software .Several software packages are available for training PBSMT systems .In this work , we use both Moses [ 5 ] and Portage [ 6 ] .Moses is a complete open - source phrase - based translation toolkit for academic purposes , while Portage is a similar package available to partners of the National Research Council Canada .","label":"Uses","metadata":{},"score":"66.97597"}{"text":"A3.final.gz -rw - rw - r-- 1 koehn user 313 M Jul 13 04:07 en - de . cooc -rw - rw - r-- 1 koehn user 2.0 K Jul 13 04:07 en - de .Lexicalized Reordering Model .Partial Training .","label":"Uses","metadata":{},"score":"67.01492"}{"text":"Each phrase is translated into an English phrase , and English phrases in the output may be reordered .In this section , we will define the phrase - based machine translation model formally .The phrase translation model is based on the noisy channel model .","label":"Uses","metadata":{},"score":"67.14523"}{"text":"In ( a ) , \" words swap TM ' ' has been obtained by swapping the target phrases inside the TM .In ( b ) , two unlearning curves have been compared . \"Numerical swap LM ' ' has been obtained applying numerical swaps only to the LM and \" numerical swap TM ' ' applying numerical swaps only to the LM .","label":"Uses","metadata":{},"score":"67.2169"}{"text":"Unfortunately the relationship between alignment quality and statistical machine translation performance has not been well understood .In the recent literature the alignment task has frequently been decoupled from the ... \" .Automatic word alignment plays a critical role in statistical machine translation .","label":"Uses","metadata":{},"score":"67.35113"}{"text":"Qun Liu .Maximum Rank Correlation Training for Statistical Machine Translation .We propose Maximum Ranking Correlation ( MRC ) as an objective function in discriminative tuning of parameters in a linear model of Statistical Machine Translation ( SMT ) .We try to maximize the ranking correlation between sentence level BLEU ( SBLEU ) scores and model scores of the N - best list , while the MERT paradigm focuses on the potential 1-best candidates of the N - best list .","label":"Uses","metadata":{},"score":"67.35286"}{"text":"This setting has been applied to Europarl and Giga corpus datasets using Moses as SMT system . vary across the datasets and correspond to an increase of 1.3 to 1.5 BLEU point for the LM and 1.8 to 1.9 for the TM , for each doubling of the data .","label":"Uses","metadata":{},"score":"67.45745"}{"text":"ACL Workshop on SMT , 2007 . \" ...We present the PORTAGE statistical machine translation system which participated in the shared task of the ACL 2007 Second Workshop on Statistical Machine Translation .The focus of this description is on improvements which were incorporated into the system over the last year .","label":"Uses","metadata":{},"score":"67.51144"}{"text":"For example , if we were translating from English to French , each word in English could produce any number of French words- sometimes none at all .But there 's no way to group two English words producing a single French word .","label":"Uses","metadata":{},"score":"67.56154"}{"text":"Note that these are not phrases in the linguistic sense , but simply subsequences of words .For a sentence .referred to as a phrase table .Part of the overall MT training process is to estimate this table and the associated probabilities .","label":"Uses","metadata":{},"score":"67.56908"}{"text":"Statistical machine translation ( SMT ) treats the translation of natural language as a machine learning problem .By examining many samples of human - produced translation , SMT algorithms automatically learn how to translate .SMT has made tremendous strides in less than two decades , and many popular tec ... \" .","label":"Uses","metadata":{},"score":"67.64133"}{"text":"We conclude with background on n - best list generation .Translation Options .Given an input string of words , a number of phrase translations could be applied .We call each such applicable phrase translation a translation option .This is illustrated in the figure below , where a number of phrase translations for the Spanish input sentence Maria no daba uma bofetada a la bruja verde are given .","label":"Uses","metadata":{},"score":"67.71503"}{"text":".. a top - scoring MT system in the Chinese newswire track of the 2008 NIST evaluation .However , except for ( Fraser and Marcu , 2007b ) , none of these advances in alignment quality has improv ... . \" ...","label":"Uses","metadata":{},"score":"67.72979"}{"text":"Table 5 : Performance obtained training the regressor on 80 % of the data and testing on 20 % .This process has been iterated 1,000 times .Experiments have been performed independently on the Europarl and Giga corpus dataset .Role of Phrase Length in the Translation Table ( Model Selection ) .","label":"Uses","metadata":{},"score":"67.75037"}{"text":"The second concern was to distinguish between the role of the numerical and lexical parts in the language and translation models .Various perturbation experiments show that the accuracy in estimating the numerical parameters is not a crucial aspect of performance , while the estimation of the lexical parts of the tables is a major factor in determining performance .","label":"Uses","metadata":{},"score":"67.86551"}{"text":"Typically , the data is lowercased , no empty lines are allowed , and having multiple spaces between words may cause problems .Also , sentence length is limited to 100 words per sentence .The sentence length ratio for a sentence pair can be at most 9 ( i.e , having a 10-word sentence aligned to a 1-word sentence is disallowed ) .","label":"Uses","metadata":{},"score":"67.955574"}{"text":"P. Koehn , \" Statistical significance tests for machine translation evaluation , \" in Proceedings of the Conference on Empirical Methods in Natural Language Processing , pp .388 - 395 , Barcelona , Spain , 2004 . A. Stolcke , \" Srilm - an extensible language modeling toolkit , \" in Proceedings of the International Conference on Spoken Language Processing , Denver , Colo , USA , 2002 .","label":"Uses","metadata":{},"score":"68.01076"}{"text":"An automatic score measures the quality of machine - translated sentences by comparing them to a set of human translations , called reference sentences .The score needs to be able to discriminate good translations from bad ones , whilst considering aspects such as adequacy and fluency .","label":"Uses","metadata":{},"score":"68.062096"}{"text":"35 - 43 , Columbus , Ohio , USA , 2008 . Y. Al - Onaizan , J. Curin , M. Jahr , et al . , \" Statistical machine translation : final report , \" Tech .Rep. , Johns Hopkins University , Summer Workshop on Language Engineering , Center for Speech and Language Processing , Baltimore , Md , USA , 1999 .","label":"Uses","metadata":{},"score":"68.18657"}{"text":"We have created 10 random subsets of the complete Europarl corpus containing 629,957 pairs of sentences .For each subset , ten PBMT systems have been estimated .Each instance of Moses has been trained using a different maximum phrase length , from 1 to 10 .","label":"Uses","metadata":{},"score":"68.230156"}{"text":"In the recent literature the alignment task has frequently been decoupled from the translation task , and assumptions have been made about measuring alignment quality for machine translation which , it turns out , are not justified .In particular , none of the tens of papers published over the last five years has shown that significant decreases in Alignment Error Rate , AER ( Och and Ney , 2003 ) , result in significant increases in translation quality .","label":"Uses","metadata":{},"score":"68.29823"}{"text":"A search restriction especially useful for the translation direction from German to English is presented .The experimental tests are carried out on the Verbmobil task ( German - English , 8000-word vocabulary ) , which is a limited - domain spoken - language task . 1 Introduction The goal of machine translation is the translation of a text given in some source language into a target language .","label":"Uses","metadata":{},"score":"68.31606"}{"text":"Our method is related to work by Ueffing ( 2002 ) for generating n - best lists for IBM Model 4 .The first ideas of statistical machine translation were introduced by Warren Weaver in 1949 , [ 2 ] including the ideas of applying Claude Shannon 's information theory .","label":"Uses","metadata":{},"score":"68.40178"}{"text":"the last two English words generated ( needed for computing future language model costs ) .the end of the last foreign phrase covered ( needed for computing future distortion costs ) .the last added English phrase ( needed for reading the translation from a path of hypotheses ) .","label":"Uses","metadata":{},"score":"68.7724"}{"text":"Paths join when hypotheses are recombined .Usually , when we recombine hypotheses , we simply discard the worse hypothesis , since it can not possibly be part of the best path through the search graph ( in other words , part of the best translation ) .","label":"Uses","metadata":{},"score":"68.82149"}{"text":"F. J. Och , \" Minimum error rate training in statistical machine translation , \" in Proceedings of the 41st Annual Meeting on Association for Computational Linguistics , pp .160 - 167 , Sapporo , Japan , 2003 .W. H. Press , S. A. Teukolsky , W. T. Vetterling , and B. P. Flannery , Numerical Recipes in C++ , Cambridge University Press , Cambridge , Mass , USA , 2002 . A. Arun and P. Koehn , \" Online learning methods for discriminative training of phrase based statistical machine translation , \" in Proceedings of 11th the Machine Translation Summit , Copenhagen , Denmark , 2007 .","label":"Uses","metadata":{},"score":"68.834885"}{"text":"Results are presented regarding translation accuracy and computational efficiency , showing significant improvements in translation quality for both translation directions at a very low computational cost .Index Terms - statistical machine translation , reordering , N - gram translation model 1 . .","label":"Uses","metadata":{},"score":"68.843834"}{"text":"Google in [ 30 ] has shown that performance improves logarithmically in the linear scale with the number of tokens in the language model training set when this quantity is huge ( from billions to trillions of tokens ) .In this section , we are interested to understand whether there is a trade - off between the training data size used to build language and translation models and how performances are affected by their differences .","label":"Uses","metadata":{},"score":"68.87561"}{"text":"Figure 5 shows that the number of phrases peaks around 4-grams and 5-grams , then steadily decreases .This means that the phrase extraction algorithm finds it more and more difficult to extract longer phrases .We investigate this further by plotting the distribution of phrases actually used while translating .","label":"Uses","metadata":{},"score":"68.99018"}{"text":"In each case , we count the number of phrases of each length that were actually used to produce the translation .The right panel of Figure 5 reports these distribution .It shows that , while the models use a fair amount of longer phrases to translate the training material , these longer phrases are essentially never used for translating the test set : 98 % of the phrases are 5-grams or shorter .","label":"Uses","metadata":{},"score":"69.41258"}{"text":"Estimating a machine translation system is therefore similar to learning the mapping between the source / input and the target / output , a problem which has been extensively studied in statistics and in machine learning .This justifies our view of a typical phrase - based machine translation model as a learning system and motivates our analysis of the performance on that system .","label":"Uses","metadata":{},"score":"69.434845"}{"text":"BLEU and NIST are based on averaging n -gram precisions , combined with a length penalty which penalizes short translations containing only sure words .These metrics differ on the way the precisions are combined and on the length penalty .Meteor evaluates a translation by computing a score based on the word alignment between the translation and a given reference translation .","label":"Uses","metadata":{},"score":"69.46753"}{"text":"tried by MERT , new hypothesis translations are added to the list .As the number of hypotheses produced by the decoder is finite , this is guaranteed to converge , and in practice , it does fairly quickly .An additional difficulty is that the landscape of the cost , for example , BLEU , is piecewise constant and highly irregular .","label":"Uses","metadata":{},"score":"69.59006"}{"text":"Translation of training sentences allows us to estimate the training error .The learning curves in Figure 4 illustrate how the performance is affected by the phrase length .The \" test on test set ' ' curve is less influenced by the phrase length than the \" test on training set ' ' curve .","label":"Uses","metadata":{},"score":"69.6597"}{"text":"It is generally acknowledged that the performance of rule - based machine translation ( RMBT ) systems can be greatly improved through domain - specic system adaptation .To that end , RBMT users often choose to invest signicant re - sources into the development of ad hoc MT dictionaries .","label":"Uses","metadata":{},"score":"69.68192"}{"text":"It is generally acknowledged that the performance of rule - based machine translation ( RMBT ) systems can be greatly improved through domain - specic system adaptation .To that end , RBMT users often choose to invest signicant re - sources into the development of ad hoc MT dictionaries .","label":"Uses","metadata":{},"score":"69.68192"}{"text":"Similar models can be used for speech translation , and HMMs ( the acoustic models ) can be integrated into a finite - state transducer ( the translation model ) .Moreover , the translation process can be performed by searching for an optimal path of states in the integrated network .","label":"Uses","metadata":{},"score":"69.80506"}{"text":"Conclusion .Data - driven solutions to classic AI problems are now commonplace , ranging from computer vision to information retrieval tasks , and machine translation is one of the main successes of this approach .The idea of putting learning systems at the centre of all AI methodologies introduces however the need to understand the properties and limitations of these learning components .","label":"Uses","metadata":{},"score":"69.88808"}{"text":"On the other hand , optimization is really expensive in terms of computational cost .In Figure 9 , it increases roughly linearly with the development set size .It is nice to note how the computational time is strongly related to the number of optimization steps in Figure 10 . A.2 .","label":"Uses","metadata":{},"score":"69.92754"}{"text":"Recall that for excluding hypotheses from the beam we do not only have to consider the cost so far , but also an estimate of the future cost .While it is possible to calculate the cheapest possible future cost for each hypothesis , this is computationally so expensive that it would defeat the purpose of the beam search .","label":"Uses","metadata":{},"score":"70.11353"}{"text":"However , these models have some serious draw - backs .Most importantly , they only allow at most one English word to be aligned with each foreign word .To resolve this , some transformations are applied .First , the parallel corpus is aligned bidirectionally , e.g. , Spanish to English and English to Spanish .","label":"Uses","metadata":{},"score":"70.1567"}{"text":"Model Perturbation : Analysis and Unlearning Curves .Much research has focused on devising improved principles for the statistical estimation of the parameters in language and translation models .The introduction of discriminative graphical models has marked a departure from traditional maximum likelihood estimation principles , and various approaches have been proposed .","label":"Uses","metadata":{},"score":"70.161385"}{"text":"At a maximum , the points of the union of the two alignments are considered .To illustrate this , see the figure below .The intersection points are black , the additional points in the union are shaded grey .Och and Ney explore the space between intersection and union with expansion heuristics that start with the intersection and add additional alignment points .","label":"Uses","metadata":{},"score":"70.168015"}{"text":"The first unlearning curve ( Figure 6 ) , obtained by adding to each parameter a random number ( sampled from within a range ) proportional to its size , is meant to test the role of detailed tuning of parameters .","label":"Uses","metadata":{},"score":"70.400986"}{"text":"Average .and error on the Europarl and Giga corpus datasets are shown in Table 5 .The proposed model is able to approximate well enough the BLEU score using Moses as translation system and in - domain test sets .According to this setting and assuming that we are in the standard case where .","label":"Uses","metadata":{},"score":"70.49104"}{"text":"ISSN 2194 - 5357 .^ Wołk K. , Marasek K. ( 2014 ) .Polish - English Speech Statistical Machine Translation Systems for the IWSLT 2014 .Proceedings of the 11th International Workshop on Spoken Language Translation , Lake Tahoe , USA .","label":"Uses","metadata":{},"score":"70.57206"}{"text":"Projects such as Universal Speech Translation Advanced Research ( U - STAR1 , a continuation of the A - STAR project ) and EU - BRIDGE2 are currently conducting research in translation of full sentences recognized from spoken language .Recent years have seen a growing interest in combining speech recognition , machine translation and speech synthesis .","label":"Uses","metadata":{},"score":"70.66829"}{"text":"It has been distinguished between truly unknown words ( or stems ) and unseen forms of known stems .The unknown words are the direct effect of Zipf 's law in a language , as new words can come , but the training set is not flexible enough to cover them .","label":"Uses","metadata":{},"score":"70.75132"}{"text":"Both learning curves show a big improvement when moving from the word - to - word translation ( phrase length equal to one ) to the phrase - based model ( higher phrase lengths ) .Figure 4 : BLEU versus n -gram length .","label":"Uses","metadata":{},"score":"70.80538"}{"text":"e . f . ) , which reflects the probability that phrases .e . and .f . are translation equivalents ; ( ii ) and a joint distribution d(i , j ) , which reflects the probability that a phrase at position i is translated into a phrase at position j .","label":"Uses","metadata":{},"score":"70.81986"}{"text":"A.1 .Effect of Data Size in Optimization Set .In this section , we study the role of the optimization / development set with regard to the quality of translation .In particular , we analyze how different sizes of the development set affect the performance and the computational cost of the optimization phase .","label":"Uses","metadata":{},"score":"70.9032"}{"text":"Unfortunately , current estimation procedures are unable to reach such high - performing regions of the parameter space .This was also noted by a recent paper by Wisniewski et al . who note that \" the current bottleneck of translation performances is not the representation power of the [ phrase - based translation systems ] but rather in their scoring functions '' [ 38 ] .","label":"Uses","metadata":{},"score":"71.01764"}{"text":"These sites come from the Canadian government , the European Union , the United Nations , and other international organizations .In addition to covering a wide range of themes , they also contain documents with different styles and genres .We estimate that the rate of misaligned sentence pairs was around 13 % .","label":"Uses","metadata":{},"score":"71.025314"}{"text":"Note that we use the informal concept cost analogous to probability : A high cost is a low probability .Each search state ( hypothesis ) is represented by .a back link to the best previous state ( needed for finding the best translation of the sentence by back - tracking through the search states ) .","label":"Uses","metadata":{},"score":"71.08075"}{"text":"File Locations .A number of parameters allow you to break out of the rigid file name conventions of the training script .A typical use for this is that you want to try alternative training runs , but there is no need to repeat all the training steps .","label":"Uses","metadata":{},"score":"71.11354"}{"text":"This is reflected in the two main components of the typical SMT model : the language model and the translation model .The language model is typically built using a table of n -grams , with associated probabilities , which is sufficient to define a Markov chain .","label":"Uses","metadata":{},"score":"71.128586"}{"text":"In the talk , we will describe a variant of the edit distance alignment which can align a hypothesis with multiple reference translations .The application of this method is evaluation of speech translation with automatic sentence segmentation .In such cases the sentence boundaries in the MT hypothesis do not correspond to the reference sentence boundaries .","label":"Uses","metadata":{},"score":"71.15939"}{"text":"Typically , the number of words in translated sentences are different , because of compound words , morphology and idioms .The ratio of the lengths of sequences of translated words is called fertility , which tells how many foreign words each native word produces .","label":"Uses","metadata":{},"score":"71.203125"}{"text":"The set of experiments in Figure 7(a ) is harder to explain without discussing the inner workings of the translation model and Moses .Here , we swapped n -grams in the translation table , essentially breaking the connection between words and their translation .","label":"Uses","metadata":{},"score":"71.220566"}{"text":"Final states in the search are hypotheses that cover all foreign words .Among these the hypothesis with the lowest cost ( highest probability ) is selected as best translation .The algorithm described so far can be used for exhaustively searching through all possible translations .","label":"Uses","metadata":{},"score":"71.27202"}{"text":"The statistical translation approach uses two types of information : a translation model and a language model .The language model used is an m - gram model .The ... \" .In this article we describe the statistical approach to machine translation as implemented in the stattrans module of the Verbmobil system .","label":"Uses","metadata":{},"score":"71.46257"}{"text":"The search for the optimal translation in ( 2 ) is also referred to as decoding as , in the original analogy of the noisy channel , it corresponds to retrieving the clean message ., we usually assume that the feature functions decompose linearly across basic constituents of the sentences .","label":"Uses","metadata":{},"score":"71.62192"}{"text":"Enabling Monolingual Translation .What kind of assistance can we offer to an information seeker who is trying to decipher a foreign text in a language she is not familiar with .This talk present how advancements in computer aided translation tools can be used .","label":"Uses","metadata":{},"score":"71.73662"}{"text":"As this is an enormous search space , it is no wonder that both algorithmic and statistical challenges are encountered when training these systems .From a statistical learning point of view , this raises interesting questions : How much of the overall error of the translation system is due to representation limitations , and how much to the difficulty of extracting suitable Translation and Language model tables from a finite sample ?","label":"Uses","metadata":{},"score":"71.83558"}{"text":"So if we remove an n -gram , chances are that other similar ( longer or shorter ) n -grams are present and can take over .In this way , it is not possible to directly compare the unlearning curve for the n -grams part with that for the numeric part of the tables .","label":"Uses","metadata":{},"score":"71.89133"}{"text":"We introduce a novel system combination framework in which hypotheses are encoded as a confusion forest , a packed forest representing alternative trees .The forest is generated by taking syntactic consensus among parsed hypotheses : First , MT outputs are parsed .","label":"Uses","metadata":{},"score":"71.93119"}{"text":"Recombining hypothesis is a risk - free way to reduce the search space .Two hypotheses can be recombined if they agree in .the foreign words covered so far .If there are two paths that lead to two hypotheses that agree in these properties , we keep only the cheaper hypothesis , e.g. , the one with the least cost so far .","label":"Uses","metadata":{},"score":"71.97308"}{"text":"It is important to notice , however , that introducing a more aggressive type of noise ( Figure 7(b ) ) that essentially replaces entire parameters with random values does lead to a more significant decline in performance .This was obtained by swapping random entries , and so after 100 percent of swaps essentially every entry is a random number ( because the locations to swap are chosen with replacement ) .","label":"Uses","metadata":{},"score":"71.97687"}{"text":"cost from the previous to higher - cost hypothesis .The figure below gives an example for the generation of such an arc : in this case , the hypotheses 2 and 4 are equivalent in respect to the heuristic search , as detailed above .","label":"Uses","metadata":{},"score":"71.977745"}{"text":"In fact , a common belief in SMT is that learning curves follow logarithmic laws ; to analyze this in our experiments , we show all the learning curves in the linear log scale , where we can study if the curve has a linear behaviour .","label":"Uses","metadata":{},"score":"72.01007"}{"text":"These alignment models are similar to the concept of hidden Markov models ( HMM ) in speech recognition .The alignment mapping is j !The u .. by Francisco Casacuberta , Enrique Vidal , Juan Miguel Vilar , Dpt Sistemes , Informàtics Computació , 2002 . \" ...","label":"Uses","metadata":{},"score":"72.022705"}{"text":"Instructions for Presenters .Oral Presentation There will be a switcher with four RBG inputs for connecting laptops to the projector .Please connect your laptop to one of the inputs during the break before your session and make sure your presentation is visible .","label":"Uses","metadata":{},"score":"72.10095"}{"text":"Up to six state - of - the - art statistical phrase - based translation systems from different project partners were combined in the experiments .Significant improvements in translation quality from Spanish to English and from English to Spanish in comparison with the best of the individual MT systems were achieved under official evaluation conditions .","label":"Uses","metadata":{},"score":"72.10565"}{"text":"Due to the increasing demands for high quality translation , monolingual Machine Translation ( MT ) subtasks are frequently encountered in various occasions , where one MT task is decomposed into several subtasks some of which can be called ' monolingual ' .","label":"Uses","metadata":{},"score":"72.165276"}{"text":"Translation ( 1949 ) .In : Machine Translation of Languages , MIT Press , Cambridge , MA .^ S. Vogel , H. Ney and C. Tillmann .HMM - based Word Alignment in StatisticalTranslation .In COLING ' 96 : The 16th International Conference on Computational Linguistics , pp .","label":"Uses","metadata":{},"score":"72.19711"}{"text":"We apply this alignment model to both French - English and Romanian - English language pairs .An exception is Taskar et al .( 2005 ) who presented a word matching model for discriminative alignment which they they were able to solve optimally .","label":"Uses","metadata":{},"score":"72.39643"}{"text":"In both architectures , HMMs can be trained from a source - language speech corpus , and the translation model can be learned automatically from a parallel text training corpus .The experiments presented here correspond to speech - input translations from Spanish to English and from Italian to English , in applications involving the interaction ( by telephone ) of a customer with the front - desk of a hotel . by F. Casacuberta - IEEE Automatic Speech Recognition and Understanding Workhsop , ASRU'01 , 2001 . \" ...","label":"Uses","metadata":{},"score":"72.405106"}{"text":"1 I is translated into an English phrase .e . i .The English phrases may be reordered .Phrase translation is modeled by a probability distribution φ ( .f .e . i ) .Recall that due to the Bayes rule , the translation direction is inverted from a modeling standpoint .","label":"Uses","metadata":{},"score":"72.49078"}{"text":"This paper provides a description of TALP - Ngram , the tuple - based statistical machine translation system developed at the TALP Research Center of the UPC ( Universitat Politècnica de Catalunya ) .Briefly , the system performs a log - linear combination of a translation model and additional feature functio ... \" .","label":"Uses","metadata":{},"score":"72.78028"}{"text":"But very few attempts were made to develop transliteration systems for Indian languages to English or other languages .We can mention a transliteration system for ... . \" ... Statistical Machine Translation ( SMT ) is based on alignment models which learn from bilingual corpora the word corre - spondences between source and target lan - guage .","label":"Uses","metadata":{},"score":"72.98174"}{"text":"During decoding , the foreign input sentence f is segmented into a sequence of I phrases .f .1 I .We assume a uniform probability distribution over all possible segmentations .Each foreign phrase .f .i in .","label":"Uses","metadata":{},"score":"73.013855"}{"text":"For each model , we count the unknown words .Figure 11 shows unknown words as function of the training model .It is clear that small training sets are able to cover a small part of the word space .When increasing the dimension of the training set , the number of unknown words decreases .","label":"Uses","metadata":{},"score":"73.14494"}{"text":"In which alignment does the potential alignment point exist ?Foreign - English or English - foreign ?Does the potential point neighbor already established points ?Does neighboring mean directly adjacent ( block - distance ) , or also diagonally adjacent ?","label":"Uses","metadata":{},"score":"73.160904"}{"text":"Experimental systems have already been developed to assist foreign health workers in developing countries .Similar systems are already available on the market .For example , Apple 's iOS 8 allows users to dictate text messages .A built - in ASR system recognizes the speech and the recognition results are edited by an online system .","label":"Uses","metadata":{},"score":"73.17419"}{"text":"The proposed alignment method has been adopted by many international MT research projects .Finally , the talk will shortly consider another application of monolingual alignment : automatic document correction or postediting .We will elaborate whether a monolingual MT system can be used as a postediting system , as well as present an alternative document correction approach that makes use of the monolingual alignment to derive candidates for correction rules .","label":"Uses","metadata":{},"score":"73.21858"}{"text":"A briefly discussion about the presence of unknown words when we test on a subset of the training set is given by Section 4.3 .Figure 11 : Number of unknown words translating training and test sets versus training set size .","label":"Uses","metadata":{},"score":"73.367645"}{"text":"What is the best function class to map Spanish documents into English documents ?This is a question of linguistic nature and has been the subject of a long debate .With the growing availability of bilingual parallel corpora , the 1990 s saw the development of statistical machine translation ( SMT ) models .","label":"Uses","metadata":{},"score":"73.66898"}{"text":"Replacements are not allowed .These choices also depend on the high computational cost of the tuning algorithm .For each size , ten random sets have been selected .For each set , an instance of the system has been run .","label":"Uses","metadata":{},"score":"73.8696"}{"text":"TMs were limited to a phrase length of 7 words , and LMs were limited to 3 .Hardware .All the experiments have been run on high - performance clusters of machines .Additional information : ClearSpeed accelerator boards on the thick nodes ; SilverStorm Infiniband high - speed connectivity throughout for parallel code message passing ; General Parallel File System ( GPFS ) providing data access from all the nodes with a total of 11 terabytes of storage .","label":"Uses","metadata":{},"score":"73.96623"}{"text":"The alignment procedure is iterative and is especially well suited for non - monotonic alignment and alignment of synonyms .In the talk , the HMM alignment will be compared with the TER - based and other alignments .The advantages and drawbacks of each of these alignment methods will be discussed .","label":"Uses","metadata":{},"score":"74.0193"}{"text":"Richer hypothesis classes can fit the training data more accurately but generalize less well than poorer classes , a phenomenon known as overfitting .The choice of the appropriate expressive power , within a parametrized class of models , is called model selection and is one of the most crucial steps in the design of learning systems .","label":"Uses","metadata":{},"score":"74.07037"}{"text":"Role of Test Set Size on Measuring Performance .BLEU score , the metric used in this work to evaluate the quality of the translation , is test set dependent .It means that different test sets regardless of the dimension can produce variation in the value of the BLEU score .","label":"Uses","metadata":{},"score":"74.2612"}{"text":"Nowadays it is by far the most widely studied machine translation method .The idea behind statistical machine translation comes from information theory .A document is translated according to the probability distribution that a string in the target language ( for example , English ) is the translation of a string in the source language ( for example , French ) .","label":"Uses","metadata":{},"score":"74.30873"}{"text":"Both of these ideas of course are being pursued at the moment .It is of course important to remark that these limitations only refer to the current systems , where language is modelled as a Markov chain , and by entirely changing language model , different limitations could be found .","label":"Uses","metadata":{},"score":"74.57207"}{"text":"Small test set sizes produce a big variance in BLEU score .When increasing the test set size , the error bars tend to reduce .using two different test sets of the same size depend on the test set choice and not on different techniques .","label":"Uses","metadata":{},"score":"74.574936"}{"text":"The distortion feature controls the reordering between phrases .Note that only very short - range reordering may be handled within phrases .Long - range reordering must be handled by target phrase permutations .This feature allows to regulate the amount of reordering depending on , for example , the language pair .","label":"Uses","metadata":{},"score":"74.76247"}{"text":"I will describe strategies for dealing with these problems , and give preliminary results on the Hansard corpus .Marcello Federico .Improved word - reordering for Phrase - Based SMT .We discuss the word - reordering issues in phrase - based SMT and overview a few approaches we have been investigating to enhance the standard word re - ordering constraints used by popular tools like Moses .","label":"Uses","metadata":{},"score":"74.839005"}{"text":"Includes a variant of Model 3 and Model 4 which allow the training of the parameter p_0 ; .Various smoothing techniques for fertility , distortion / alignment parameters ; .Significant more efficient training of the fertility models ; .Correct implementation of pegging as described in ( Brown et al .","label":"Uses","metadata":{},"score":"74.84338"}{"text":"The graph of the hypothesis space can be also be viewed as a probabilistic finite state automaton .The hypotheses are states , and the records of back - links and the additionally stored arcs are state transitions .The added probability scores when expanding a hypothesis are the costs of the state transitions .","label":"Uses","metadata":{},"score":"75.0138"}{"text":"The way M - tools and B - tools are used for monolingual MT is an issue of particular interest for this workshop .This workshop is intended to provide the opportunity to discuss ideas and share opinions on the question of the applicability of M - tools or B - tools for monolingual MT subtasks , and on their respective strengths and weaknesses in specific settings .","label":"Uses","metadata":{},"score":"75.06891"}{"text":"2142 - 2147 , Genova , Italy , 2006 .N. Draper and H. Smith , Applied Regression Analysis , John Wiley & Sons , New York , NY , USA , 1981 .F. J. Och , \" Statistical machine translation : foundations and recent advances , \" in Proceedings of the Tutorial at MT Summit , 2005 .","label":"Uses","metadata":{},"score":"75.16688"}{"text":"Understanding how sophisticated behaviour can be learnt from data is hence not just a concern for machine learning , or to individual applied communities , such as statistical machine translation , but rather a general concern for modern artificial intelligence .The analysis of learning curves and the identification of the various limitations to performance are a crucial part of the machine learning method , and one where statistics and algorithms interact closely .","label":"Uses","metadata":{},"score":"75.258545"}{"text":"The underlying log - linear model may be interpreted as a maximum entropy model : . is linear in the log domain , which motivates the description of this framework as \" log - linear model ' ' [ 3 , 4 , 12 ] .","label":"Uses","metadata":{},"score":"75.402084"}{"text":"\" Test on training set ' ' is a test set selected by the training set for each training set size and no optimization phase .In the \" test on test set ' ' learning curve , there seems to be no significant advantage to using phrases longer than 4 words .","label":"Uses","metadata":{},"score":"75.56395"}{"text":"The models can be Hidden Markov Models for the accoustic part , language models for the source language and finite state transducers for the transfer between the sour ... \" .Speech - to - speech translation can be approached using finite state models and several ideas borrowed from automatic speech recognition .","label":"Uses","metadata":{},"score":"75.58589"}{"text":"We have incorporated some gazetteer lists in the system to increase the performance of the system .These lists are collected from the web and are in English .To make these English lists useful in the Hindi NER task , we have proposed a two - phase transliteration methodology .","label":"Uses","metadata":{},"score":"75.67966"}{"text":"The language model cost is usually calculated by a trigram language model .However , we do not know the preceding English words for a translation operation .Therefore , we approximate this cost by computing the language model score for the generated English words alone .","label":"Uses","metadata":{},"score":"75.756966"}{"text":"Some classification can be done by naming the typical order of subject ( S ) , verb ( V ) and object ( O ) in a sentence and one can talk , for instance , of SVO or VSO languages .","label":"Uses","metadata":{},"score":"75.92612"}{"text":"We have undertaken a large scale experimental and theoretical investigation of these questions .We use this data to inform a discussion about learning curves .We have also investigated the model - selection properties of n -gram size , where the n -grams are the phrases used as building blocks in the translation process .","label":"Uses","metadata":{},"score":"76.3622"}{"text":"This can either represent the effect of insufficient statistics in estimating them , or the use of imperfect parameter estimation biases .These parameters are probabilities , phrases , and associations between source / target phrases contained inside translation and language model tables .","label":"Uses","metadata":{},"score":"76.593445"}{"text":"These experiments suggest that the phrase length has a limited impact on actual test performance .Going to larger n- grams seems to bring little benefit in terms of performance as the model continues to prefer short phrases during the decoding phase .","label":"Uses","metadata":{},"score":"76.82448"}{"text":"This is a simple means to optimize performance .Usually , this factor is larger than 1 , biasing toward longer output .In summary , the best English output sentence e best given a foreign input sentence f according to our model is .","label":"Uses","metadata":{},"score":"76.8456"}{"text":"The test set is used to evaluate the quality of models on the data .All experiments using Moses have been run using the default parameter configuration .The training , development , and test set sentences are tokenized and lowercased .","label":"Uses","metadata":{},"score":"76.906586"}{"text":"A human error analysis indicates that long - distance reorderings are captured effectively . by Sujan Kumar Saha , Partha Sarathi Ghosh , Sudeshna Sarkar , Pabitra Mitra . \" ...Abstract - Named entities are perhaps the most important indexing element in text for most of the information extraction and mining tasks .","label":"Uses","metadata":{},"score":"76.99361"}{"text":"The file system is Ibrix and provides data access from all nodes , with a total of 17 TB of storage .Experiments using Portage are distributed over several CPUs , the total number of which depends on the various stages in the estimation process .","label":"Uses","metadata":{},"score":"77.02792"}{"text":"7sISI - University of Southern California ISI - TR-616 Acknowledgments This work was supporte ... . \" ...Bilingual word alignment forms the foundation of most approaches to statistical machine translation .Current word alignment methods are predominantly based on generative models .","label":"Uses","metadata":{},"score":"77.042984"}{"text":"Abstract - This paper describes an approach for computing a consensus translation from the outputs of multiple machine translation ( MT ) systems .The consensus translation is computed by weighted majority voting on a confusion network , similarly to the well - established ROVER approach of Fiscus for combining speech recognition hypotheses .","label":"Uses","metadata":{},"score":"77.08361"}{"text":"In such systems , HMMs ( the acoustic models ) are integrated into a n - gram or a stochastic finite - state grammar ( the language model ) .Similar models can be used for speech tra ... \" .Nowadays , hidden Markov models ( HMMs ) and n - grams are the basic components of the most successful speech recognition systems .","label":"Uses","metadata":{},"score":"77.90465"}{"text":"138 - 145 , Morgan Kaufmann Publishers , San Francisco , Calif , USA , 2002 .S. Banerjee and A. Lavie , \" Meteor : an automatic metric for mt evaluation with improved correlation with human judgments , \" in Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics , Ann Arbor , Mich , USA , 2005 .","label":"Uses","metadata":{},"score":"78.317955"}{"text":"Authors are invited to submit long papers ( up to 10 pages ) and short papers ( 2 - 4 pages ) .Long papers should describe unpublished , substantial and completed research .Short papers should be position papers , papers describing work in progress or short , focused contributions .","label":"Uses","metadata":{},"score":"78.55054"}{"text":"L. Specia , M. Turchi , Z. Wang , J. Shawe - Taylor , and C. Saunders , \" Improving the confidence of machine translation quality estimates , \" in Proceedings of 12th the Machine Translation Summit , 2009 . D. Vilar , J. Xu , L. F. D'Haro , and H. Ney , \" Error analysis of statistical machine translation output , \" in Proceedings of the 5th International Conference on Language Resources and Evaluation ( LREC ' 06 ) , Genova , Italy , 2006 .","label":"Uses","metadata":{},"score":"78.82295"}{"text":"The two effects interact with richer classes being better approximators of the target behaviour but requiring more training data to reliably identify the best hypothesis .The resulting trade - off , equally well known in statistics and in machine learning , can be expressed in terms of bias versus variance , capacity control , or model selection .","label":"Uses","metadata":{},"score":"78.89118"}{"text":"The toolkit output can be given in different formats in order to be used by other statistical machine translation tools like Pharaoh , which is a beam search decoder for phrase - based alignment models which was used in order to perform translation experiments with the generated models .","label":"Uses","metadata":{},"score":"79.13206"}{"text":"Understanding the most important reasons for failure of a PBSMT system is a fundamental task .In [ 39 ] , a classification of different types of error has been proposed .In this section , we focus our attention on a particular type of error : unknown words .","label":"Uses","metadata":{},"score":"79.65565"}{"text":"IIS-9820687 through the 1999 Workshop on Language Engineering , Center for Language and Speech Processing , Johns Hopkins University .Tools . by Josep M. Crego , Marta R. Costa - jussà , José B. Mariño , José A. R. Fonollosa - In Proceedings of the International Workshop on Spoken Language Technology ( IWSLT'05 , 2005 . \" ...","label":"Uses","metadata":{},"score":"79.661804"}{"text":"Background .Statistical Machine Translation as a research area started in the late 1980s with the Candide project at IBM .IBM 's original approach maps individual words to words and allows for deletion and insertion of words .Lately , various researchers have shown better translation quality with the use of phrase translation .","label":"Uses","metadata":{},"score":"80.006454"}{"text":"W. Locke and A. Booth , Machine Translation of Languages , MIT Press , Cambridge , Mass , USA , 1955 .P. F. Brown , S. D. Pietra , V. J. D. Pietra , and R. L. Mercer , \" The mathematic of statistical machine translation : parameter estimation , \" Computational Linguistics , vol .","label":"Uses","metadata":{},"score":"80.101776"}{"text":"S tag sequence 2 .Figure 2 shows an example of tuple extraction following regular and unfold techniques .Fig .2 .Unfold vs. regular tuple extraction .The N - gram translation model estimated with unfolded units does no ... .","label":"Uses","metadata":{},"score":"80.19072"}{"text":"Acknowledgement This work is supported by National High Technology Research and Development Program contract \" Generally Technical Research and Basic Database Establishment of Chinese Platform\"(Subj ... . by Er Fraser Daniel Marcu - In Technical Report ISI - TR-616 . html , ISI / University of Southern California , 2006 . \" ...","label":"Uses","metadata":{},"score":"80.25618"}{"text":"ACL 2007 , Demonstration Session , Prague , Czech Republic .^ Q. Gao , S. Vogel , \" Parallel Implementations of Word Alignment Tool \" , Software Engineering , Testing , and Quality Assurance for Natural Language Processing , pp .","label":"Uses","metadata":{},"score":"80.3452"}{"text":"( 2003 ) reviews these two methods and shows that the combining phrase tables generated by different methods improves results .Decoder .This section describes the Moses decoder from a more theoretical perspective .The decoder was originally developed for the phrase model proposed by Marcu and Wong .","label":"Uses","metadata":{},"score":"80.72676"}{"text":"The gentle decline in performance seems to suggest that fine tuning of parameters is not what controls the performance here , and that perhaps advanced statistical estimation or more observations of the same n -grams would not lead to much better performance .","label":"Uses","metadata":{},"score":"80.73041"}{"text":"This allows a quicker lookup than consulting the whole phrase translation table during decoding .The translation options are stored with the information .first foreign word covered .last foreign word covered .English phrase translation .phrase translation probability .","label":"Uses","metadata":{},"score":"81.81288"}{"text":"Given the first expanded hypothesis we generate a new hypothesis by translating no with did not .Now the first two foreign words Maria and no are marked as being covered .Following the back pointers of the hypotheses we can read of the ( partial ) translations of the sentence .","label":"Uses","metadata":{},"score":"82.381744"}{"text":"To translate a source sentence , we first employ a parser to pro - duce a source parse tree and then ap - ply TATs to transform the tree into a tar - get string .Our experiments show that the TAT - based model significantly outper - forms Pharaoh , a state - of - the - art decoder for phrase - based models . .","label":"Uses","metadata":{},"score":"82.49083"}{"text":"In many resource - poor languages gazetteer lists of proper size are not available , but sometimes relevant lists are available in English .Proper transliteration makes the English lists useful in the NER tasks for such languages .In this paper , we have described a Maximum Entropy based NER system for Hindi .","label":"Uses","metadata":{},"score":"82.9642"}{"text":"Furthermore , self - references that reveal the author 's identity , e.g. , \" We previously showed ( Smith , 1991 ) ... \" must be avoided .Instead , use citations such as \" Smith previously showed ( Smith , 1991 ) ... \" Papers that do not conform to these requirements will be rejected without review .","label":"Uses","metadata":{},"score":"83.488884"}{"text":"Patches to the code are most welcome .Feel free to send me mail asking for help , but please do not necessarily expect me to have time to help .Citation : .You are welcome to use the code under the terms of the licence for research or commercial purposes , however please acknowledge its use with a citation : .","label":"Uses","metadata":{},"score":"83.62545"}{"text":"Polish - English Speech Statistical Machine Translation Systems for the IWSLT 2013 .Proceedings of the 10th International Workshop on Spoken Language Translation , Heidelberg , Germany .pp .113 - 119 . --reordering - smooth -- specifies the smoothing constant to be used for training lexicalized reordering models .","label":"Uses","metadata":{},"score":"83.65239"}{"text":"Gazetteer lists are often used for the developme ... \" .Abstract - Named entities are perhaps the most important indexing element in text for most of the information extraction and mining tasks .Construction of a Named Entity Recognition ( NER ) system becomes challenging if proper resources are not available .","label":"Uses","metadata":{},"score":"83.88075"}{"text":"The maximum length of phrases is limited to 7 words .The maximum phrase length impacts the size of the phrase translation table , so shorter limits may be desirable , if phrase table size is an issue .Previous experiments have shown that performance increases only slightly when including phrases of more that 3 words .","label":"Uses","metadata":{},"score":"84.71488"}{"text":"The Europarl corpus contains material extracted from the proceedings of the European parliament , and the UN data contains material from the United Nations .Both therefore cover a wide range of themes , but are fairly homogeneous in terms of style and genre .","label":"Uses","metadata":{},"score":"84.82474"}{"text":"This paper describes TALPtuples , the 2007 N - gram - based statistical machine translation system developed at the TALP Research Center of the UPC ( Universitat Politècnica de Catalunya ) in Barcelona .Emphasis is put on improvements and extensions of the system of previous years .","label":"Uses","metadata":{},"score":"85.42723"}{"text":"This paper describes TALPtuples , the 2007 N - gram - based statistical machine translation system developed at the TALP Research Center of the UPC ( Universitat Politècnica de Catalunya ) in Barcelona .Emphasis is put on improvements and extensions of the system of previous years .","label":"Uses","metadata":{},"score":"85.42723"}{"text":"This is an active area of research in machine translation [ 35 - 37 ] .The results of the perturbation analysis in Section 5 suggest that the limiting factor in the translation tables is not in the numeric part of the model - the parameters being estimated - but in the phrases contained in it , the entries of the phrase table .","label":"Uses","metadata":{},"score":"85.918564"}{"text":"But since we want to keep the information about the path leading from hypothesis 3 to 2 , we store a record of this arc .The arc also contains the cost added from hypothesis 3 to 4 .Note that the cost from hypothesis 1 to hypothesis 2 does not have to be stored , since it can be recomputed from the hypothesis data structures .","label":"Uses","metadata":{},"score":"86.28044"}{"text":"The two corpus files have a common file stem ( say , euro ) and extensions indicating the language ( say , en and de ) .The file stem ( --corpus - file ) , and the language extensions ( --e and --f ) have to be specified to the training script . snt -rw - rw - r-- 1 koehn user 4.2 M Jul 12 19:56 de.vcb -rw - rw - r-- 1 koehn user 3.2 M Jul 12 19:42 de.vcb.classes -rw - rw - r-- 1 koehn user 2.6 M Jul 12 19:42 de.vcb.classes.cats -rw - rw - r-- 1 koehn user 104 M Jul 12 19:59 en - de - int - train . cooc -rw - rw - r-- 1 koehn user 2.0 K Jul 12 20:11 de - en .","label":"Uses","metadata":{},"score":"86.30802"}{"text":"Note that if you are only those who will not require visa to the US or who have already acquired visa to the US , please submit a paper .Note that this will not be included in the Proceedings , but will be presented in the form of posters .","label":"Uses","metadata":{},"score":"89.72748"}{"text":"185 - 188 , Prague , Czech Republic , 2007 .P. Koehn , \" Europarl : a parallel corpus for statistical machine translation , \" in Proceedings of the 10 th Machine Translation Summit , pp .79 - 86 , Phuket , Thailand , 2005 .","label":"Uses","metadata":{},"score":"89.790794"}{"text":"The proposed transliteration based gazetteer preparation methodology is also applicable for other languages .Apart from Hindi , we have applied the transliteration approach in Bengali NER task and also achieved performance improvement .Index Terms - Gazetteer list preparation , named entity recognition , natural language processing , transliteration .","label":"Uses","metadata":{},"score":"90.199005"}{"text":"12:30 - 12:45 Poster session .Jin'ichi Murakami Thoudam Doren Singh Benjamin Gottesman Saptina Dian Larasati Marianna J Martindale .12:45 - 14:00 Lunch 14:00 Long presentation session ( 2 ) .Jin'ichi Murakami ( short presen long paper , 14min ) Thoudam Doren Singh ( short presen long paper , 14min )","label":"Uses","metadata":{},"score":"90.48536"}{"text":"Solutions are the IBM - Models or the HMM - approach .Real - world training sets may override translations of , say , proper nouns .An example would be that \" I took the train to Berlin \" gets mis - translated as \" I took the train to Paris \" due to an abundance of \" train to Paris \" in the training set .","label":"Uses","metadata":{},"score":"93.189926"}{"text":"For example , using Canadian Hansard as the bilingual corpus , \" hear \" may almost invariably be translated to \" Bravo ! \" since in Parliament \" Hear , Hear ! \" becomes \" Bravo ! \"[ 13 ] .","label":"Uses","metadata":{},"score":"94.573395"}{"text":"In practice this is not really true .For example , the English word corner can be translated in Spanish by either rincón or esquina , depending on whether it is to mean its internal or external angle .Simple word - based translation ca n't translate between languages with different fertility .","label":"Uses","metadata":{},"score":"106.46974"}{"text":"Starting from the initial hypothesis , the first expansion is the foreign word Maria , which is translated as Mary .The foreign word is marked as translated ( marked by an asterisk ) .We may also expand the initial hypothesis by translating the foreign word bruja as witch .","label":"Uses","metadata":{},"score":"112.87833"}{"text":"Academic Editor : Peter Tino .Copyright © 2012 Marco Turchi et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .","label":"Uses","metadata":{},"score":"117.41693"}