{"text": "A method and an apparatus for providing syntactic analysis and data structure for translation knowledge in an example - based spoken language translation are provided .Syntactic analysis is performed on an input and on entries of a bilingual example database using at least one parse tree .", "label": "", "metadata": {}, "score": "31.999989"}
{"text": "Syntactic analysis is performed on at least one entry from the example database using the parse tree .At least one linguistic constituent of the input is determined , and a pragmatic type and a syntactic type of the linguistic constituent are determined .", "label": "", "metadata": {}, "score": "32.85285"}
{"text": "Syntactic analysis is performed on at least one entry from the example database using the parse tree .At least one linguistic constituent of the input is determined , and a pragmatic type and a syntactic type of the linguistic constituent are determined .", "label": "", "metadata": {}, "score": "32.85285"}
{"text": "Syntactic analysis is performed on at least one entry from the example database using the parse tree .At least one linguistic constituent of the input is determined , and a pragmatic type and a syntactic type of the linguistic constituent are determined .", "label": "", "metadata": {}, "score": "32.85285"}
{"text": "Syntactic analysis is performed on at least one entry from the example database using the parse tree .At least one linguistic constituent of the input is determined , and a pragmatic type and a syntactic type of the linguistic constituent are determined .", "label": "", "metadata": {}, "score": "32.85285"}
{"text": "Syntactic analysis is performed on at least one entry from the example database using the parse tree .At least one linguistic constituent of the input is determined , and a pragmatic type and a syntactic type of the linguistic constituent are determined .", "label": "", "metadata": {}, "score": "32.85285"}
{"text": "This is achieved by performing as much computation as possible with a Generalized Left - Right ( GLR ) parser , and by keeping the feature structure manipulations to a minimum , but the embodiment is not so limited .The nested structure comprises nested production rules within the nodes of the of the parse trees .", "label": "", "metadata": {}, "score": "34.962738"}
{"text": "This is achieved by performing as much computation as possible with a Generalized Left - Right ( GLR ) parser , and by keeping the feature structure manipulations to a minimum , but the embodiment is not so limited .The nested structure comprises nested production rules within the nodes of the of the parse trees .", "label": "", "metadata": {}, "score": "34.962738"}
{"text": "This is achieved by performing as much computation as possible with a Generalized Left - Right ( GLR ) parser , and by keeping the feature structure manipulations to a minimum , but the embodiment is not so limited .The nested structure comprises nested production rules within the nodes of the of the parse trees .", "label": "", "metadata": {}, "score": "34.962738"}
{"text": "This is achieved by performing as much computation as possible with a Generalized Left - Right ( GLR ) parser , and by keeping the feature structure manipulations to a minimum , but the embodiment is not so limited .The nested structure comprises nested production rules within the nodes of the of the parse trees .", "label": "", "metadata": {}, "score": "34.962738"}
{"text": "This is achieved by performing as much computation as possible with a Generalized Left - Right ( GLR ) parser , and by keeping the feature structure manipulations to a minimum , but the embodiment is not so limited .The nested structure comprises nested production rules within the nodes of the of the parse trees .", "label": "", "metadata": {}, "score": "34.962738"}
{"text": "A three - level model of sentence semantics including a comprehensive Case system provides the framework for TANKA 's representations .Text is first processed by the DIPETT parser , which can handle a wide variety of unedited sentences .The semantic analysis module HAIKU then semi - automatically extracts semantic patterns from the parse trees and composes them into domain knowledge representations .", "label": "", "metadata": {}, "score": "34.974773"}
{"text": "A three - level model of sentence semantics including a comprehensive Case system provides the framework for TANKA 's representations .Text is first processed by the DIPETT parser , which can handle a wide variety of unedited sentences .The semantic analysis module HAIKU then semi - automatically extracts semantic patterns from the parse trees and composes them into domain knowledge representations .", "label": "", "metadata": {}, "score": "34.974773"}
{"text": "The second type of processing , analogical processing or example - based processing , does not use a sequence of rules but instead uses a data driven approach .The rule based components perform syntactic and morphological analysis in the source language , and syntactic and morphological generation in the target language .", "label": "", "metadata": {}, "score": "35.281006"}
{"text": "The second type of processing , analogical processing or example - based processing , does not use a sequence of rules but instead uses a data driven approach .The rule based components perform syntactic and morphological analysis in the source language , and syntactic and morphological generation in the target language .", "label": "", "metadata": {}, "score": "35.281006"}
{"text": "The second type of processing , analogical processing or example - based processing , does not use a sequence of rules but instead uses a data driven approach .The rule based components perform syntactic and morphological analysis in the source language , and syntactic and morphological generation in the target language .", "label": "", "metadata": {}, "score": "35.281006"}
{"text": "The second type of processing , analogical processing or example - based processing , does not use a sequence of rules but instead uses a data driven approach .The rule based components perform syntactic and morphological analysis in the source language , and syntactic and morphological generation in the target language .", "label": "", "metadata": {}, "score": "35.281006"}
{"text": "The second type of processing , analogical processing or example - based processing , does not use a sequence of rules but instead uses a data driven approach .The rule based components perform syntactic and morphological analysis in the source language , and syntactic and morphological generation in the target language .", "label": "", "metadata": {}, "score": "35.281006"}
{"text": "Furthermore , at least one node comprises nested production rules .The nested production rules comprise production rules for different combinations of the linguistic constituents of the input .The syntactic analysis comprises recognizing linguistic constituents , ordering the linguistic constituents , representing the linguistic constituents using an adapted feature structure analysis representation , and manipulating the adapted feature structure analysis representation using a natural language parser .", "label": "", "metadata": {}, "score": "35.459755"}
{"text": "The default output of the parser is a set of predicate - argument relations .Alternatively , you can get both the phrase structures and predicate - argument relations either in a quasi - XML format or in a stand - off format .", "label": "", "metadata": {}, "score": "35.70923"}
{"text": "The default output of the parser is a set of predicate - argument relations .Alternatively , you can get both the phrase structures and predicate - argument relations either in a quasi - XML format or in a stand - off format .", "label": "", "metadata": {}, "score": "35.70923"}
{"text": "The run - time parser is driven by a table that is pre - generated by a compiler that accepts context - free grammars .One previous GLR parser supports grammatical specifications that consist of context - free grammar rules bundled with feature structure constraints .", "label": "", "metadata": {}, "score": "35.96238"}
{"text": "The run - time parser is driven by a table that is pre - generated by a compiler that accepts context - free grammars .One previous GLR parser supports grammatical specifications that consist of context - free grammar rules bundled with feature structure constraints .", "label": "", "metadata": {}, "score": "35.96238"}
{"text": "The run - time parser is driven by a table that is pre - generated by a compiler that accepts context - free grammars .One previous GLR parser supports grammatical specifications that consist of context - free grammar rules bundled with feature structure constraints .", "label": "", "metadata": {}, "score": "35.96238"}
{"text": "The run - time parser is driven by a table that is pre - generated by a compiler that accepts context - free grammars .One previous GLR parser supports grammatical specifications that consist of context - free grammar rules bundled with feature structure constraints .", "label": "", "metadata": {}, "score": "35.96238"}
{"text": "The run - time parser is driven by a table that is pre - generated by a compiler that accepts context - free grammars .One previous GLR parser supports grammatical specifications that consist of context - free grammar rules bundled with feature structure constraints .", "label": "", "metadata": {}, "score": "35.96238"}
{"text": "We present a method for individuating dependencies between the semantic class of predicates and their associated subcategorization frames , and describe an implementation which allows the cquisition of such dependencies from bracketed texts .Syntactic analysis is performed on an input and on entries of a bilingual example database using at least one parse tree .", "label": "", "metadata": {}, "score": "36.550774"}
{"text": "When the natural language processing system needs to generate an utterance , it passes a sentence to a module that translates the words into phonemic sequence and determines an intonational contour , and then passes this information on to a speech synthesis system , which produces the spoken output .", "label": "", "metadata": {}, "score": "36.70246"}
{"text": "When the natural language processing system needs to generate an utterance , it passes a sentence to a module that translates the words into phonemic sequence and determines an intonational contour , and then passes this information on to a speech synthesis system , which produces the spoken output .", "label": "", "metadata": {}, "score": "36.70246"}
{"text": "When the natural language processing system needs to generate an utterance , it passes a sentence to a module that translates the words into phonemic sequence and determines an intonational contour , and then passes this information on to a speech synthesis system , which produces the spoken output .", "label": "", "metadata": {}, "score": "36.70246"}
{"text": "When the natural language processing system needs to generate an utterance , it passes a sentence to a module that translates the words into phonemic sequence and determines an intonational contour , and then passes this information on to a speech synthesis system , which produces the spoken output .", "label": "", "metadata": {}, "score": "36.70246"}
{"text": "When the natural language processing system needs to generate an utterance , it passes a sentence to a module that translates the words into phonemic sequence and determines an intonational contour , and then passes this information on to a speech synthesis system , which produces the spoken output .", "label": "", "metadata": {}, "score": "36.70246"}
{"text": "These systems rely heavily on domain - specific , handcrafted knowledge to handle the myriad syntactic , semantic , and pragmatic ambiguities that pervade virtually all aspects of sentence analysis .Not surprisingly , however , generating this knowledge for new domain ... . by Cynthia A. Thompson , Raymond J. Mooney - Department of Computer Sciences , University of Texas , 1989 . \" ...", "label": "", "metadata": {}, "score": "36.71434"}
{"text": "These systems rely heavily on domain - specific , handcrafted knowledge to handle the myriad syntactic , semantic , and pragmatic ambiguities that pervade virtually all aspects of sentence analysis .Not surprisingly , however , generating this knowledge for new domain ... . by Cynthia A. Thompson , Raymond J. Mooney - Department of Computer Sciences , University of Texas , 1989 . \" ...", "label": "", "metadata": {}, "score": "36.71434"}
{"text": "Linguistic constituents of the input are determined , and a pragmatic type and a syntactic type of the linguistic constituents are determined .The order of the linguistic constituents in the input is retained .An output is provided comprising an identification of the input .", "label": "", "metadata": {}, "score": "37.21585"}
{"text": "Linguistic constituents of the input are determined , and a pragmatic type and a syntactic type of the linguistic constituents are determined .The order of the linguistic constituents in the input is retained .Statistical processing may be performed to resolve lexical ambiguities and local ambiguities .", "label": "", "metadata": {}, "score": "37.42263"}
{"text": "Furthermore , there is a need for the machine - aided interpersonal communication system to be portable so that the user can easily transport it .A typical language translation system functions by using natural language processing .Natural language processing is generally concerned with the attempt to recognize a large pattern or sentence by decomposing it into small subpattems according to linguistic rules .", "label": "", "metadata": {}, "score": "37.485825"}
{"text": "The method for providing syntactic analysis and data structure for translation knowledge in an embodiment of the present invention comprises performing syntactic analysis on the input using at least one parse tree comprising a number of nodes .Each node comprises at least one production rule .", "label": "", "metadata": {}, "score": "37.754623"}
{"text": "The method for providing syntactic analysis and data structure for translation knowledge in an embodiment of the present invention comprises performing syntactic analysis on the input using at least one parse tree comprising a number of nodes .Each node comprises at least one production rule .", "label": "", "metadata": {}, "score": "37.754623"}
{"text": "The method for providing syntactic analysis and data structure for translation knowledge in an embodiment of the present invention comprises performing syntactic analysis on the input using at least one parse tree comprising a number of nodes .Each node comprises at least one production rule .", "label": "", "metadata": {}, "score": "37.754623"}
{"text": "The method for providing syntactic analysis and data structure for translation knowledge in an embodiment of the present invention comprises performing syntactic analysis on the input using at least one parse tree comprising a number of nodes .Each node comprises at least one production rule .", "label": "", "metadata": {}, "score": "37.754623"}
{"text": "The method for providing syntactic analysis and data structure for translation knowledge in an embodiment of the present invention comprises performing syntactic analysis on the input using at least one parse tree comprising a number of nodes .Each node comprises at least one production rule .", "label": "", "metadata": {}, "score": "37.754623"}
{"text": "Typical syntactic representations of language are based on the notion of context - free grammars , which represent sentence structure in terms of what phrases are subparts of other phrases .This syntactic information is often presented in a tree form .", "label": "", "metadata": {}, "score": "37.93569"}
{"text": "Typical syntactic representations of language are based on the notion of context - free grammars , which represent sentence structure in terms of what phrases are subparts of other phrases .This syntactic information is often presented in a tree form .", "label": "", "metadata": {}, "score": "37.93569"}
{"text": "Typical syntactic representations of language are based on the notion of context - free grammars , which represent sentence structure in terms of what phrases are subparts of other phrases .This syntactic information is often presented in a tree form .", "label": "", "metadata": {}, "score": "37.93569"}
{"text": "Typical syntactic representations of language are based on the notion of context - free grammars , which represent sentence structure in terms of what phrases are subparts of other phrases .This syntactic information is often presented in a tree form .", "label": "", "metadata": {}, "score": "37.93569"}
{"text": "Typical syntactic representations of language are based on the notion of context - free grammars , which represent sentence structure in terms of what phrases are subparts of other phrases .This syntactic information is often presented in a tree form .", "label": "", "metadata": {}, "score": "37.93569"}
{"text": "Furthermore , there is a need for the machine - aided interpersonal communication system to be portable so that the user can easily transport it .A typical language translation system functions by using natural language processing .Natural language processing is generally concerned with the attempt to recognize a large pattern or sentence by decomposing it into small subpatterns according to linguistic rules .", "label": "", "metadata": {}, "score": "38.180912"}
{"text": "Furthermore , there is a need for the machine - aided interpersonal communication system to be portable so that the user can easily transport it .A typical language translation system functions by using natural language processing .Natural language processing is generally concerned with the attempt to recognize a large pattern or sentence by decomposing it into small subpatterns according to linguistic rules .", "label": "", "metadata": {}, "score": "38.180912"}
{"text": "Furthermore , there is a need for the machine - aided interpersonal communication system to be portable so that the user can easily transport it .A typical language translation system functions by using natural language processing .Natural language processing is generally concerned with the attempt to recognize a large pattern or sentence by decomposing it into small subpatterns according to linguistic rules .", "label": "", "metadata": {}, "score": "38.180912"}
{"text": "Similarly , a pattern - based machine translation system uses a context - free grammar that combines syntactic rules with translation patterns .Combined syntactic - semantic grammars such as used in transfer - based machine translation systems and the pattern - based machine translation systems make knowledge acquisition and maintenance very difficult , since syntactic analysis and analogical transfer rules become heavily interdependent .", "label": "", "metadata": {}, "score": "38.2259"}
{"text": "A method and apparatus for parsing in a spoken language translation system are provided .An input is received comprising at least one input sentence or expression .A parsing table is accessed and consulted for a next action , wherein the parser looks up in the next action in the parsing table .", "label": "", "metadata": {}, "score": "38.526733"}
{"text": "Similarly , a pattern - based machine translation system uses a context - free grammar that combines syntactic rules with translation patterns .Combined syntactic - semantic grammars such as used in transfer - based machine translation systems and the pattern - based machine translation systems make knowledge acquisition and maintenance very difficult , since syntactic analysis and analogical transfer rules become heavily inter - dependent .", "label": "", "metadata": {}, "score": "38.81139"}
{"text": "Similarly , a pattern - based machine translation system uses a context - free grammar that combines syntactic rules with translation patterns .Combined syntactic - semantic grammars such as used in transfer - based machine translation systems and the pattern - based machine translation systems make knowledge acquisition and maintenance very difficult , since syntactic analysis and analogical transfer rules become heavily inter - dependent .", "label": "", "metadata": {}, "score": "38.81139"}
{"text": "Similarly , a pattern - based machine translation system uses a context - free grammar that combines syntactic rules with translation patterns .Combined syntactic - semantic grammars such as used in transfer - based machine translation systems and the pattern - based machine translation systems make knowledge acquisition and maintenance very difficult , since syntactic analysis and analogical transfer rules become heavily inter - dependent .", "label": "", "metadata": {}, "score": "38.81139"}
{"text": "Similarly , a pattern - based machine translation system uses a context - free grammar that combines syntactic rules with translation patterns .Combined syntactic - semantic grammars such as used in transfer - based machine translation systems and the pattern - based machine translation systems make knowledge acquisition and maintenance very difficult , since syntactic analysis and analogical transfer rules become heavily inter - dependent .", "label": "", "metadata": {}, "score": "38.81139"}
{"text": "Regarding the spoken language translation system , one previous approach combines the syntactic rules for analysis together with the transfer patterns or transfer rules .As a result , the syntactic rules and the transfer rules become inter - dependent , and the system becomes less modular and difficult to extend in coverage or apply to a new translation domain .", "label": "", "metadata": {}, "score": "39.402138"}
{"text": "Regarding the spoken language translation system , one previous approach combines the syntactic rules for analysis together with the transfer patterns or transfer rules .As a result , the syntactic rules and the transfer rules become inter - dependent , and the system becomes less modular and difficult to extend in coverage or apply to a new translation domain .", "label": "", "metadata": {}, "score": "39.402138"}
{"text": "Regarding the spoken language translation system , one previous approach combines the syntactic rules for analysis together with the transfer patterns or transfer rules .As a result , the syntactic rules and the transfer rules become inter - dependent , and the system becomes less modular and difficult to extend in coverage or apply to a new translation domain .", "label": "", "metadata": {}, "score": "39.402138"}
{"text": "Regarding the spoken language translation system , one previous approach combines the syntactic rules for analysis together with the transfer patterns or transfer rules .As a result , the syntactic rules and the transfer rules become inter - dependent , and the system becomes less modular and difficult to extend in coverage or apply to a new translation domain .", "label": "", "metadata": {}, "score": "39.402138"}
{"text": "Regarding the spoken language translation system , one previous approach combines the syntactic rules for analysis together with the transfer patterns or transfer rules .As a result , the syntactic rules and the transfer rules become inter - dependent , and the system becomes less modular and difficult to extend in coverage or apply to a new translation domain .", "label": "", "metadata": {}, "score": "39.402138"}
{"text": "The parser begins with a lexicon of function words and creates a case base o ... \" .This paper describes a case - based approach to knowledge acquisition for natural language systems that simultaneously learns part of speech , word sense , and concept activation knowledge for all open class words in a corpus .", "label": "", "metadata": {}, "score": "39.81992"}
{"text": "The parser begins with a lexicon of function words and creates a case base o ... \" .This paper describes a case - based approach to knowledge acquisition for natural language systems that simultaneously learns part of speech , word sense , and concept activation knowledge for all open class words in a corpus .", "label": "", "metadata": {}, "score": "39.81992"}
{"text": "Furthermore , at least one node comprises nested production rules .The nested production rules comprise production rules for different combinations of the linguistic constituents of the input .The syntactic analysis comprises recognizing linguistic constituents comprising noun phrases , verb phrases , and prepositional phrases , ordering the linguistic constituents , representing the linguistic constituents using an adapted feature structure analysis representation , and manipulating the adapted feature structure analysis representation using a natural language parser .", "label": "", "metadata": {}, "score": "39.876705"}
{"text": "Once the morphological analyzer identifies the root and the inflection of the input word , it takes the formation from the dictionary , and inserts appropriate feature - value pairs for inflection into the output feature structure .This output format allows the AIM of an embodiment to be integrated with a syntactic parser that operates on feature structures , while also providing other STS components quick access to relevant features ( e.g. the ROOT of each word ) .", "label": "", "metadata": {}, "score": "40.132008"}
{"text": "Once the morphological analyzer identifies the root and the inflection of the input word , it takes the formation from the dictionary , and inserts appropriate feature - value pairs for inflection into the output feature structure .This output format allows the AIM of an embodiment to be integrated with a syntactic parser that operates on feature structures , while also providing other STS components quick access to relevant features ( e.g. the ROOT of each word ) .", "label": "", "metadata": {}, "score": "40.132008"}
{"text": "Once the morphological analyzer identifies the root and the inflection of the input word , it takes the formation from the dictionary , and inserts appropriate feature - value pairs for inflection into the output feature structure .This output format allows the AIM of an embodiment to be integrated with a syntactic parser that operates on feature structures , while also providing other STS components quick access to relevant features ( e.g. the ROOT of each word ) .", "label": "", "metadata": {}, "score": "40.132008"}
{"text": "Once the morphological analyzer identifies the root and the inflection of the input word , it takes the formation from the dictionary , and inserts appropriate feature - value pairs for inflection into the output feature structure .This output format allows the AIM of an embodiment to be integrated with a syntactic parser that operates on feature structures , while also providing other STS components quick access to relevant features ( e.g. the ROOT of each word ) .", "label": "", "metadata": {}, "score": "40.132008"}
{"text": "Once the morphological analyzer identifies the root and the inflection of the input word , it takes the formation from the dictionary , and inserts appropriate feature - value pairs for inflection into the output feature structure .This output format allows the AIM of an embodiment to be integrated with a syntactic parser that operates on feature structures , while also providing other STS components quick access to relevant features ( e.g. the ROOT of each word ) .", "label": "", "metadata": {}, "score": "40.132008"}
{"text": "At the same time , translation becomes more efficient and accurate when structural regularities are exploited .A new method of shallow syntactic analysis used in the present invention is powerful enough to handle a wide variety of grammatical patterns , yet robust enough to process spoken language .", "label": "", "metadata": {}, "score": "40.620266"}
{"text": "At the same time , translation becomes more efficient and accurate when structural regularities are exploited .A new method of shallow syntactic analysis used in the present invention is powerful enough to handle a wide variety of grammatical patterns , yet robust enough to process spoken language .", "label": "", "metadata": {}, "score": "40.620266"}
{"text": "At the same time , translation becomes more efficient and accurate when structural regularities are exploited .A new method of shallow syntactic analysis used in the present invention is powerful enough to handle a wide variety of grammatical patterns , yet robust enough to process spoken language .", "label": "", "metadata": {}, "score": "40.620266"}
{"text": "At the same time , translation becomes more efficient and accurate when structural regularities are exploited .A new method of shallow syntactic analysis used in the present invention is powerful enough to handle a wide variety of grammatical patterns , yet robust enough to process spoken language .", "label": "", "metadata": {}, "score": "40.620266"}
{"text": "At the same time , translation becomes more efficient and accurate when structural regularities are exploited .A new method of shallow syntactic analysis used in the present invention is powerful enough to handle a wide variety of grammatical patterns , yet robust enough to process spoken language .", "label": "", "metadata": {}, "score": "40.620266"}
{"text": "syntactic analyzer .The authors present the resources used and the adaptations required to .deal with the corpus .A similar method for dealing with corpora of .other Romance languages is envisaged .TREEBAKNS FOR OTHER LANGUAGES .Chapter 13 .", "label": "", "metadata": {}, "score": "41.312946"}
{"text": "This reduces the amount of example data required to obtain reasonable coverage , thereby increasing efficiency .Second , structural analysis enables the STS to correctly combine different parts of examples to cover the input .For high accuracy , the substitution of parts of the input must operate on syntactic constituents rather than on , for example , substrings of the input .", "label": "", "metadata": {}, "score": "41.386635"}
{"text": "This reduces the amount of example data required to obtain reasonable coverage , thereby increasing efficiency .Second , structural analysis enables the STS to correctly combine different parts of examples to cover the input .For high accuracy , the substitution of parts of the input must operate on syntactic constituents rather than on , for example , substrings of the input .", "label": "", "metadata": {}, "score": "41.386635"}
{"text": "This reduces the amount of example data required to obtain reasonable coverage , thereby increasing efficiency .Second , structural analysis enables the STS to correctly combine different parts of examples to cover the input .For high accuracy , the substitution of parts of the input must operate on syntactic constituents rather than on , for example , substrings of the input .", "label": "", "metadata": {}, "score": "41.386635"}
{"text": "This reduces the amount of example data required to obtain reasonable coverage , thereby increasing efficiency .Second , structural analysis enables the STS to correctly combine different parts of examples to cover the input .For high accuracy , the substitution of parts of the input must operate on syntactic constituents rather than on , for example , substrings of the input .", "label": "", "metadata": {}, "score": "41.386635"}
{"text": "This reduces the amount of example data required to obtain reasonable coverage , thereby increasing efficiency .Second , structural analysis enables the STS to correctly combine different parts of examples to cover the input .For high accuracy , the substitution of parts of the input must operate on syntactic constituents rather than on , for example , substrings of the input .", "label": "", "metadata": {}, "score": "41.386635"}
{"text": "Method and apparatus for providing syntactic analysis and data structure for translation knowledge in example - based language translation US 6243669 B1 .Abstract .Syntactic analysis is performed on an input and on entries of a bilingual example database using at least one parse tree .", "label": "", "metadata": {}, "score": "41.43727"}
{"text": "Then , given an unknownwordand the context in which it occurs , the parser retrieves definitions from the case base to infer the word 's syntactic and semantic features .By encoding context as part of a definition , the meaning of a word can change dynamically in response to surrounding phrases without the need for explicit lexical disambiguation heuristics .", "label": "", "metadata": {}, "score": "41.7369"}
{"text": "Then , given an unknownwordand the context in which it occurs , the parser retrieves definitions from the case base to infer the word 's syntactic and semantic features .By encoding context as part of a definition , the meaning of a word can change dynamically in response to surrounding phrases without the need for explicit lexical disambiguation heuristics .", "label": "", "metadata": {}, "score": "41.7369"}
{"text": "Natural language processing systems further comprise interpretation processes that map from one representation to the other .For instance , the process that maps a sentence to its syntactic structure and logical form is called parsing , and it is performed by a component called a parser .", "label": "", "metadata": {}, "score": "42.376118"}
{"text": "Natural language processing systems further comprise interpretation processes that map from one representation to the other .For instance , the process that maps a sentence to its syntactic structure and logical form is called parsing , and it is performed by a component called a parser .", "label": "", "metadata": {}, "score": "42.376118"}
{"text": "Natural language processing systems further comprise interpretation processes that map from one representation to the other .For instance , the process that maps a sentence to its syntactic structure and logical form is called parsing , and it is performed by a component called a parser .", "label": "", "metadata": {}, "score": "42.376118"}
{"text": "Natural language processing systems further comprise interpretation processes that map from one representation to the other .For instance , the process that maps a sentence to its syntactic structure and logical form is called parsing , and it is performed by a component called a parser .", "label": "", "metadata": {}, "score": "42.376118"}
{"text": "Natural language processing systems further comprise interpretation processes that map from one representation to the other .For instance , the process that maps a sentence to its syntactic structure and logical form is called parsing , and it is performed by a component called a parser .", "label": "", "metadata": {}, "score": "42.376118"}
{"text": "A method and apparatus for adaptive speech recognition hypothesis construction and selection in a spoken language translation system are provided .A number of ordered recognition hypotheses are generated and presented in response to a received speech input comprising natural spoken language .", "label": "", "metadata": {}, "score": "42.470585"}
{"text": "Unlike with purely statistical collocational analyses , the framework of a semantic theory allows the automatic construction of predictions about deeper semantic relationships among words appearing in collocational systems .We illustrate the approach for the acquisition of lexical information for several classes of nominals , and how such techniques can fine - tune the lexical structures acquired from an initial seeding of a machine - readable dictionary .", "label": "", "metadata": {}, "score": "42.802376"}
{"text": "Unlike with purely statistical collocational analyses , the framework of a semantic theory allows the automatic construction of predictions about deeper semantic relationships among words appearing in collocational systems .We illustrate the approach for the acquisition of lexical information for several classes of nominals , and how such techniques can fine - tune the lexical structures acquired from an initial seeding of a machine - readable dictionary .", "label": "", "metadata": {}, "score": "42.802376"}
{"text": "At each recursive step , after detailed matching has been performed , additional information in the input that is not covered by the example is handled , as well as redundant information from the example , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "42.84295"}
{"text": "At each recursive step , after detailed matching has been performed , additional information in the input that is not covered by the example is handled , as well as redundant information from the example , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "42.84295"}
{"text": "At each recursive step , after detailed matching has been performed , additional information in the input that is not covered by the example is handled , as well as redundant information from the example , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "42.84295"}
{"text": "At each recursive step , after detailed matching has been performed , additional information in the input that is not covered by the example is handled , as well as redundant information from the example , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "42.84295"}
{"text": "At each recursive step , after detailed matching has been performed , additional information in the input that is not covered by the example is handled , as well as redundant information from the example , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "42.84295"}
{"text": "The output feature structure is provided , at step 2634 , wherein the output comprises a structural analysis of the input .The structural analysis of an embodiment comprises a plurality of parse trees and sentential feature structures , but is not so limited .", "label": "", "metadata": {}, "score": "43.026413"}
{"text": "The output feature structure is provided , at step 2634 , wherein the output comprises a structural analysis of the input .The structural analysis of an embodiment comprises a plurality of parse trees and sentential feature structures , but is not so limited .", "label": "", "metadata": {}, "score": "43.026413"}
{"text": "The output feature structure is provided , at step 2634 , wherein the output comprises a structural analysis of the input .The structural analysis of an embodiment comprises a plurality of parse trees and sentential feature structures , but is not so limited .", "label": "", "metadata": {}, "score": "43.026413"}
{"text": "The output feature structure is provided , at step 2634 , wherein the output comprises a structural analysis of the input .The structural analysis of an embodiment comprises a plurality of parse trees and sentential feature structures , but is not so limited .", "label": "", "metadata": {}, "score": "43.026413"}
{"text": "The output feature structure is provided , at step 2634 , wherein the output comprises a structural analysis of the input .The structural analysis of an embodiment comprises a plurality of parse trees and sentential feature structures , but is not so limited .", "label": "", "metadata": {}, "score": "43.026413"}
{"text": "The parsing engine 2506 operates on the input sentences 2550 to provide an output 2554 comprising parse trees and sentential feature structures .The integration of feature structures and the parsing engine follows the augmented GLR algorithm of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "43.543655"}
{"text": "The parsing engine 2506 operates on the input sentences 2550 to provide an output 2554 comprising parse trees and sentential feature structures .The integration of feature structures and the parsing engine follows the augmented GLR algorithm of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "43.543655"}
{"text": "The parsing engine 2506 operates on the input sentences 2550 to provide an output 2554 comprising parse trees and sentential feature structures .The integration of feature structures and the parsing engine follows the augmented GLR algorithm of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "43.543655"}
{"text": "The parsing engine 2506 operates on the input sentences 2550 to provide an output 2554 comprising parse trees and sentential feature structures .The integration of feature structures and the parsing engine follows the augmented GLR algorithm of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "43.543655"}
{"text": "The parsing engine 2506 operates on the input sentences 2550 to provide an output 2554 comprising parse trees and sentential feature structures .The integration of feature structures and the parsing engine follows the augmented GLR algorithm of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "43.543655"}
{"text": "The target language syntactic representation 512 is used to perform target language syntactic generation , at step 514 .A sequence of target language morpheme specifications 516 are produced , and are used in target language morphological generation , at step 518 .", "label": "", "metadata": {}, "score": "43.65352"}
{"text": "The target language syntactic representation 512 is used to perform target language syntactic generation , at step 514 .A sequence of target language morpheme specifications 516 are produced , and are used in target language morphological generation , at step 518 .", "label": "", "metadata": {}, "score": "43.65352"}
{"text": "The target language syntactic representation 512 is used to perform target language syntactic generation , at step 514 .A sequence of target language morpheme specifications 516 are produced , and are used in target language morphological generation , at step 518 .", "label": "", "metadata": {}, "score": "43.65352"}
{"text": "The target language syntactic representation 512 is used to perform target language syntactic generation , at step 514 .A sequence of target language morpheme specifications 516 are produced , and are used in target language morphological generation , at step 518 .", "label": "", "metadata": {}, "score": "43.65352"}
{"text": "The target language syntactic representation 512 is used to perform target language syntactic generation , at step 514 .A sequence of target language morpheme specifications 516 are produced , and are used in target language morphological generation , at step 518 .", "label": "", "metadata": {}, "score": "43.65352"}
{"text": "dependency / determination relation .Solutions were found for .problematic structures , as coordination , ellipses , ambiguity , and . apposition .Two modes of annotation were employed : first , manual . annotation , then the Collins parser was trained on such annotated data .", "label": "", "metadata": {}, "score": "44.14294"}
{"text": "During analysis using this system , the example annotations assist in the selection of the analysis rule that should be applied .This approach suffers from the same lack of modularity and inter - dependence as the previous approach .Still another previous approach to natural language translation performs a dependency analysis first , and then performs an example - based transfer .", "label": "", "metadata": {}, "score": "44.24724"}
{"text": "During analysis using this system , the example annotations assist in the selection of the analysis rule that should be applied .This approach suffers from the same lack of modularity and inter - dependence as the previous approach .Still another previous approach to natural language translation performs a dependency analysis first , and then performs an example - based transfer .", "label": "", "metadata": {}, "score": "44.24724"}
{"text": "During analysis using this system , the example annotations assist in the selection of the analysis rule that should be applied .This approach suffers from the same lack of modularity and inter - dependence as the previous approach .Still another previous approach to natural language translation performs a dependency analysis first , and then performs an example - based transfer .", "label": "", "metadata": {}, "score": "44.24724"}
{"text": "During analysis using this system , the example annotations assist in the selection of the analysis rule that should be applied .This approach suffers from the same lack of modularity and inter - dependence as the previous approach .Still another previous approach to natural language translation performs a dependency analysis first , and then performs an example - based transfer .", "label": "", "metadata": {}, "score": "44.24724"}
{"text": "During analysis using this system , the example annotations assist in the selection of the analysis rule that should be applied .This approach suffers from the same lack of modularity and inter - dependence as the previous approach .Still another previous approach to natural language translation performs a dependency analysis first , and then performs an example - based transfer .", "label": "", "metadata": {}, "score": "44.24724"}
{"text": "The shallow syntactic analysis module identifies the syntactic type and the pragmatic type of the input , and matching is constrained according to these types .In addition , a fast match is performed based on the syntactic head of the constituents to be matched ; this can be constrained to equality , or to a thesaurus - based measure of close semantic similarity .", "label": "", "metadata": {}, "score": "44.58826"}
{"text": "The shallow syntactic analysis module identifies the syntactic type and the pragmatic type of the input , and matching is constrained according to these types .In addition , a fast match is performed based on the syntactic head of the constituents to be matched ; this can be constrained to equality , or to a thesaurus - based measure of close semantic similarity .", "label": "", "metadata": {}, "score": "44.58826"}
{"text": "The shallow syntactic analysis module identifies the syntactic type and the pragmatic type of the input , and matching is constrained according to these types .In addition , a fast match is performed based on the syntactic head of the constituents to be matched ; this can be constrained to equality , or to a thesaurus - based measure of close semantic similarity .", "label": "", "metadata": {}, "score": "44.58826"}
{"text": "The shallow syntactic analysis module identifies the syntactic type and the pragmatic type of the input , and matching is constrained according to these types .In addition , a fast match is performed based on the syntactic head of the constituents to be matched ; this can be constrained to equality , or to a thesaurus - based measure of close semantic similarity .", "label": "", "metadata": {}, "score": "44.58826"}
{"text": "The shallow syntactic analysis module identifies the syntactic type and the pragmatic type of the input , and matching is constrained according to these types .In addition , a fast match is performed based on the syntactic head of the constituents to be matched ; this can be constrained to equality , or to a thesaurus - based measure of close semantic similarity .", "label": "", "metadata": {}, "score": "44.58826"}
{"text": "In the second step , the hypothesis construction component takes this information , and constructs an ordered list of entire utterances that are recognition hypotheses for the entire speech input .As an intermediate step , the STS of an embodiment may also construct a word graph , but is not so limited .", "label": "", "metadata": {}, "score": "44.593433"}
{"text": "In the second step , the hypothesis construction component takes this information , and constructs an ordered list of entire utterances that are recognition hypotheses for the entire speech input .As an intermediate step , the STS of an embodiment may also construct a word graph , but is not so limited .", "label": "", "metadata": {}, "score": "44.593433"}
{"text": "In the second step , the hypothesis construction component takes this information , and constructs an ordered list of entire utterances that are recognition hypotheses for the entire speech input .As an intermediate step , the STS of an embodiment may also construct a word graph , but is not so limited .", "label": "", "metadata": {}, "score": "44.593433"}
{"text": "In the second step , the hypothesis construction component takes this information , and constructs an ordered list of entire utterances that are recognition hypotheses for the entire speech input .As an intermediate step , the STS of an embodiment may also construct a word graph , but is not so limited .", "label": "", "metadata": {}, "score": "44.593433"}
{"text": "In the second step , the hypothesis construction component takes this information , and constructs an ordered list of entire utterances that are recognition hypotheses for the entire speech input .As an intermediate step , the STS of an embodiment may also construct a word graph , but is not so limited .", "label": "", "metadata": {}, "score": "44.593433"}
{"text": "The effect of this will be that the hypothesis construction component adapts to the utterances that the user makes , and learns to favor utterances that the user is more likely to make .Then , these utterances will appear higher and higher on the ordered list of utterance hypotheses , and the speech translator becomes relatively easier to use .", "label": "", "metadata": {}, "score": "44.70054"}
{"text": "The effect of this will be that the hypothesis construction component adapts to the utterances that the user makes , and learns to favor utterances that the user is more likely to make .Then , these utterances will appear higher and higher on the ordered list of utterance hypotheses , and the speech translator becomes relatively easier to use .", "label": "", "metadata": {}, "score": "44.70054"}
{"text": "The effect of this will be that the hypothesis construction component adapts to the utterances that the user makes , and learns to favor utterances that the user is more likely to make .Then , these utterances will appear higher and higher on the ordered list of utterance hypotheses , and the speech translator becomes relatively easier to use .", "label": "", "metadata": {}, "score": "44.70054"}
{"text": "The effect of this will be that the hypothesis construction component adapts to the utterances that the user makes , and learns to favor utterances that the user is more likely to make .Then , these utterances will appear higher and higher on the ordered list of utterance hypotheses , and the speech translator becomes relatively easier to use .", "label": "", "metadata": {}, "score": "44.70054"}
{"text": "The effect of this will be that the hypothesis construction component adapts to the utterances that the user makes , and learns to favor utterances that the user is more likely to make .Then , these utterances will appear higher and higher on the ordered list of utterance hypotheses , and the speech translator becomes relatively easier to use .", "label": "", "metadata": {}, "score": "44.70054"}
{"text": "The example based component uses an example database comprising a large number of stored pairs of corresponding expressions in the source and target language .As such , morphological analysis comprises the use of a source language dictionary and source language morphological rules .", "label": "", "metadata": {}, "score": "44.70437"}
{"text": "The example based component uses an example database comprising a large number of stored pairs of corresponding expressions in the source and target language .As such , morphological analysis comprises the use of a source language dictionary and source language morphological rules .", "label": "", "metadata": {}, "score": "44.70437"}
{"text": "The example based component uses an example database comprising a large number of stored pairs of corresponding expressions in the source and target language .As such , morphological analysis comprises the use of a source language dictionary and source language morphological rules .", "label": "", "metadata": {}, "score": "44.70437"}
{"text": "The example based component uses an example database comprising a large number of stored pairs of corresponding expressions in the source and target language .As such , morphological analysis comprises the use of a source language dictionary and source language morphological rules .", "label": "", "metadata": {}, "score": "44.70437"}
{"text": "The example based component uses an example database comprising a large number of stored pairs of corresponding expressions in the source and target language .As such , morphological analysis comprises the use of a source language dictionary and source language morphological rules .", "label": "", "metadata": {}, "score": "44.70437"}
{"text": "In performing a shift action , a next item of the input string is shifted onto a stack or intermediate data structure of the parser .A new parse node is generated , and a feature structure or lexical feature structure of the shifted input item is obtained from a morphological analyzer and associated with the new parse node .", "label": "", "metadata": {}, "score": "45.651596"}
{"text": "Moreover , the dictionary format may be reused for design implementation and usage of a morphological generator .In evaluating the performance of the AIM of an embodiment , experiments were conducted to compare the AIM and a typical two - level morphological analyzer in terms of speed and memory requirements .", "label": "", "metadata": {}, "score": "45.846565"}
{"text": "Manual correction followed .For the lexical analysis , a .morphocentric lexical knowledge - base ( LKB ) was used .The lexical .analyzer uses as input the output from the POS tagger and applies to .it the knowledge in the LKB .", "label": "", "metadata": {}, "score": "45.899834"}
{"text": "an output coupled to the at least one processor , the output capable of providing at least one structural analysis of the at least one input .The apparatus of claim 13 , wherein the processor is further configured to translate by : . applying at least one grammar rule to the at least one component when the at least one next action is determined to be a reduce action ; . executing at least one feature structure manipulation corresponding to the at least one grammar rule ; and . determining whether the at least one feature structure manipulation succeeds .", "label": "", "metadata": {}, "score": "46.01676"}
{"text": "24 .As discussed herein , an embodiment of the present invention comprises a powerful parser for natural language .A parser is a software module that takes as input a sentence of a language and returns a structural analysis , typically in the form of a syntax tree .", "label": "", "metadata": {}, "score": "46.25932"}
{"text": "24 .As discussed herein , an embodiment of the present invention comprises a powerful parser for natural language .A parser is a software module that takes as input a sentence of a language and returns a structural analysis , typically in the form of a syntax tree .", "label": "", "metadata": {}, "score": "46.25932"}
{"text": "24 .As discussed herein , an embodiment of the present invention comprises a powerful parser for natural language .A parser is a software module that takes as input a sentence of a language and returns a structural analysis , typically in the form of a syntax tree .", "label": "", "metadata": {}, "score": "46.25932"}
{"text": "24 .As discussed herein , an embodiment of the present invention comprises a powerful parser for natural language .A parser is a software module that takes as input a sentence of a language and returns a structural analysis , typically in the form of a syntax tree .", "label": "", "metadata": {}, "score": "46.25932"}
{"text": "24 .As discussed herein , an embodiment of the present invention comprises a powerful parser for natural language .A parser is a software module that takes as input a sentence of a language and returns a structural analysis , typically in the form of a syntax tree .", "label": "", "metadata": {}, "score": "46.25932"}
{"text": "This creates shallow syntactic representations , which comprise , among other linguistic information , the pragmatic type 1104 and the sentence type 1106 of the expression or sentence .A matching and transfer is then performed , wherein an initial fast match 1108 is performed that quickly checks compatibility of the input and the example database .", "label": "", "metadata": {}, "score": "46.317528"}
{"text": "This creates shallow syntactic representations , which comprise , among other linguistic information , the pragmatic type 1104 and the sentence type 1106 of the expression or sentence .A matching and transfer is then performed , wherein an initial fast match 1108 is performed that quickly checks compatibility of the input and the example database .", "label": "", "metadata": {}, "score": "46.317528"}
{"text": "This creates shallow syntactic representations , which comprise , among other linguistic information , the pragmatic type 1104 and the sentence type 1106 of the expression or sentence .A matching and transfer is then performed , wherein an initial fast match 1108 is performed that quickly checks compatibility of the input and the example database .", "label": "", "metadata": {}, "score": "46.317528"}
{"text": "This creates shallow syntactic representations , which comprise , among other linguistic information , the pragmatic type 1104 and the sentence type 1106 of the expression or sentence .A matching and transfer is then performed , wherein an initial fast match 1108 is performed that quickly checks compatibility of the input and the example database .", "label": "", "metadata": {}, "score": "46.317528"}
{"text": "This creates shallow syntactic representations , which comprise , among other linguistic information , the pragmatic type 1104 and the sentence type 1106 of the expression or sentence .A matching and transfer is then performed , wherein an initial fast match 1108 is performed that quickly checks compatibility of the input and the example database .", "label": "", "metadata": {}, "score": "46.317528"}
{"text": "The AIM of an embodiment of the present invention is easy to maintain since the direct correspondence between the transfer knowledge base and the dictionary is preserved .The sequential rule application provides for advantages in that the morphological analysis is faster , less computationally complex , always returns an analysis , provides reliable and accurate performance , and provides for ease of maintenance of rule sets .", "label": "", "metadata": {}, "score": "46.342224"}
{"text": "Furthermore , there is a possibility of reducing the ROM size by optimizing the feature structure representations .Regarding modularity , as the AIM is a modular part of the translation system , it can easily be used and integrated into other applications and tools ( e.g. for word extraction from large corpora ) .", "label": "", "metadata": {}, "score": "46.38883"}
{"text": "It takes an input comprising a set of grammar rules bundled with feature structure manipulations or operations 2552 .It converts the feature structure manipulations or operations to instructions in a programming language , such as a C program .Formal variables are replaced by expressions that represent references to the appropriate memory locations at parser run - time .", "label": "", "metadata": {}, "score": "46.41603"}
{"text": "It takes an input comprising a set of grammar rules bundled with feature structure manipulations or operations 2552 .It converts the feature structure manipulations or operations to instructions in a programming language , such as a C program .Formal variables are replaced by expressions that represent references to the appropriate memory locations at parser run - time .", "label": "", "metadata": {}, "score": "46.41603"}
{"text": "It takes an input comprising a set of grammar rules bundled with feature structure manipulations or operations 2552 .It converts the feature structure manipulations or operations to instructions in a programming language , such as a C program .Formal variables are replaced by expressions that represent references to the appropriate memory locations at parser run - time .", "label": "", "metadata": {}, "score": "46.41603"}
{"text": "It takes an input comprising a set of grammar rules bundled with feature structure manipulations or operations 2552 .It converts the feature structure manipulations or operations to instructions in a programming language , such as a C program .Formal variables are replaced by expressions that represent references to the appropriate memory locations at parser run - time .", "label": "", "metadata": {}, "score": "46.41603"}
{"text": "Conceptually , the structural analysis component of an embodiment comprises two steps , but is not so limited .The first step comprises parsing with a context - free grammar , while the second step comprises producing feature structures for the input sentence .", "label": "", "metadata": {}, "score": "46.494102"}
{"text": "Conceptually , the structural analysis component of an embodiment comprises two steps , but is not so limited .The first step comprises parsing with a context - free grammar , while the second step comprises producing feature structures for the input sentence .", "label": "", "metadata": {}, "score": "46.494102"}
{"text": "Conceptually , the structural analysis component of an embodiment comprises two steps , but is not so limited .The first step comprises parsing with a context - free grammar , while the second step comprises producing feature structures for the input sentence .", "label": "", "metadata": {}, "score": "46.494102"}
{"text": "Conceptually , the structural analysis component of an embodiment comprises two steps , but is not so limited .The first step comprises parsing with a context - free grammar , while the second step comprises producing feature structures for the input sentence .", "label": "", "metadata": {}, "score": "46.494102"}
{"text": "Conceptually , the structural analysis component of an embodiment comprises two steps , but is not so limited .The first step comprises parsing with a context - free grammar , while the second step comprises producing feature structures for the input sentence .", "label": "", "metadata": {}, "score": "46.494102"}
{"text": "Furthermore , the shallow syntactic analyzer can also be integrated with a statistical processing component which may help resolve lexical ambiguities and other local ambiguities to reduce the burden of the example - data processing , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "46.498913"}
{"text": "Furthermore , the shallow syntactic analyzer can also be integrated with a statistical processing component which may help resolve lexical ambiguities and other local ambiguities to reduce the burden of the example - data processing , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "46.498913"}
{"text": "Furthermore , the shallow syntactic analyzer can also be integrated with a statistical processing component which may help resolve lexical ambiguities and other local ambiguities to reduce the burden of the example - data processing , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "46.498913"}
{"text": "Furthermore , the shallow syntactic analyzer can also be integrated with a statistical processing component which may help resolve lexical ambiguities and other local ambiguities to reduce the burden of the example - data processing , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "46.498913"}
{"text": "Furthermore , the shallow syntactic analyzer can also be integrated with a statistical processing component which may help resolve lexical ambiguities and other local ambiguities to reduce the burden of the example - data processing , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "46.498913"}
{"text": "The AIM receives a string of words as an input and returns the analysis of each word in the form of a lexical feature structure , a linguistic data structure that contains feature - value pairs for strings , symbols , and numbers .", "label": "", "metadata": {}, "score": "46.567215"}
{"text": "The AIM receives a string of words as an input and returns the analysis of each word in the form of a lexical feature structure , a linguistic data structure that contains feature - value pairs for strings , symbols , and numbers .", "label": "", "metadata": {}, "score": "46.567215"}
{"text": "The AIM receives a string of words as an input and returns the analysis of each word in the form of a lexical feature structure , a linguistic data structure that contains feature - value pairs for strings , symbols , and numbers .", "label": "", "metadata": {}, "score": "46.567215"}
{"text": "The AIM receives a string of words as an input and returns the analysis of each word in the form of a lexical feature structure , a linguistic data structure that contains feature - value pairs for strings , symbols , and numbers .", "label": "", "metadata": {}, "score": "46.567215"}
{"text": "The AIM receives a string of words as an input and returns the analysis of each word in the form of a lexical feature structure , a linguistic data structure that contains feature - value pairs for strings , symbols , and numbers .", "label": "", "metadata": {}, "score": "46.567215"}
{"text": "A typical language translation system functions by using natural language processing .Natural language processing is generally concerned with the attempt to recognize a large pattern or sentence by decomposing it into small subpatterns according to linguistic rules .Until recently , however , natural language processing systems have not been accurate or fast enough to support useful applications in the field of language translation , particularly in the field of spoken language translation .", "label": "", "metadata": {}, "score": "46.57693"}
{"text": "presented : its consisting applications and the architecture of the . tool .In the end the usages of the obtained data are presented : . improvement of a translation system , enrichment of dictionaries , . improvement at the level of analysis .", "label": "", "metadata": {}, "score": "46.589653"}
{"text": "A morphological analysis is performed , at step 502 , producing a sequence of analyzed morphemes 504 .A syntactic source language analysis is performed , at step 506 , on the sequence of analyzed morphemes 504 .The syntactic source language analysis produces a source language syntactic representation 508 .", "label": "", "metadata": {}, "score": "46.640797"}
{"text": "A morphological analysis is performed , at step 502 , producing a sequence of analyzed morphemes 504 .A syntactic source language analysis is performed , at step 506 , on the sequence of analyzed morphemes 504 .The syntactic source language analysis produces a source language syntactic representation 508 .", "label": "", "metadata": {}, "score": "46.640797"}
{"text": "A morphological analysis is performed , at step 502 , producing a sequence of analyzed morphemes 504 .A syntactic source language analysis is performed , at step 506 , on the sequence of analyzed morphemes 504 .The syntactic source language analysis produces a source language syntactic representation 508 .", "label": "", "metadata": {}, "score": "46.640797"}
{"text": "A morphological analysis is performed , at step 502 , producing a sequence of analyzed morphemes 504 .A syntactic source language analysis is performed , at step 506 , on the sequence of analyzed morphemes 504 .The syntactic source language analysis produces a source language syntactic representation 508 .", "label": "", "metadata": {}, "score": "46.640797"}
{"text": "A morphological analysis is performed , at step 502 , producing a sequence of analyzed morphemes 504 .A syntactic source language analysis is performed , at step 506 , on the sequence of analyzed morphemes 504 .The syntactic source language analysis produces a source language syntactic representation 508 .", "label": "", "metadata": {}, "score": "46.640797"}
{"text": "In the hybrid approach , decision trees are used to specify the features to be included in k - nearest neighbor case retrieval .Results from the experiments show that the hybrid approach outperforms both the decision ... .Moreover , the approaches tend to fall into one of two categories : statistically - based methods that acquire ( usually syntactic ) lexical knowledge ( e .. \" ...", "label": "", "metadata": {}, "score": "46.798203"}
{"text": "In the hybrid approach , decision trees are used to specify the features to be included in k - nearest neighbor case retrieval .Results from the experiments show that the hybrid approach outperforms both the decision ... .Moreover , the approaches tend to fall into one of two categories : statistically - based methods that acquire ( usually syntactic ) lexical knowledge ( e .. \" ...", "label": "", "metadata": {}, "score": "46.798203"}
{"text": "It takes an input comprising a set of grammar rules bundled with feature structure manipulations or operations 2552 .It converts the feature structure manipulations or operations to instructions in a programming language , such as a C program .Formal variables are replaced by expressions that represent references to the appropriate memory locations at parser runtime .", "label": "", "metadata": {}, "score": "46.81147"}
{"text": "The AIM of an embodiment of the present invention provides for increased overall performance of a speech translation system while providing the necessary and sufficient morphological analysis .As discussed herein , the AIM is fast in that it analyzes the input four times as fast as a typical two level analyzer .", "label": "", "metadata": {}, "score": "46.85976"}
{"text": "Another approach to creating a language model is to use other types of basic probabilities .For example , syntactic analysis may be performed , and the basic probabilities may make reference to the probabilities of certain grammar rules used in the analysis .", "label": "", "metadata": {}, "score": "47.02964"}
{"text": "Another approach to creating a language model is to use other types of basic probabilities .For example , syntactic analysis may be performed , and the basic probabilities may make reference to the probabilities of certain grammar rules used in the analysis .", "label": "", "metadata": {}, "score": "47.02964"}
{"text": "Another approach to creating a language model is to use other types of basic probabilities .For example , syntactic analysis may be performed , and the basic probabilities may make reference to the probabilities of certain grammar rules used in the analysis .", "label": "", "metadata": {}, "score": "47.02964"}
{"text": "Another approach to creating a language model is to use other types of basic probabilities .For example , syntactic analysis may be performed , and the basic probabilities may make reference to the probabilities of certain grammar rules used in the analysis .", "label": "", "metadata": {}, "score": "47.02964"}
{"text": "Another approach to creating a language model is to use other types of basic probabilities .For example , syntactic analysis may be performed , and the basic probabilities may make reference to the probabilities of certain grammar rules used in the analysis .", "label": "", "metadata": {}, "score": "47.02964"}
{"text": "As a result , a need has developed for a machine - aided interpersonal communication system that accepts natural fluent speech input one language and provides an accurate near real - time output comprising natural fluent speech in another language .This system would relieve users of the need to possess specialized linguistic or translational knowledge .", "label": "", "metadata": {}, "score": "47.04241"}
{"text": "In terms of inflectional information encoding , three types of lexical entries are discerned by the AIM of an embodiment : .( 1 ) Entries to which default inflectional rules apply : these entries do not have to contain any inflectional information .", "label": "", "metadata": {}, "score": "47.0704"}
{"text": "In terms of inflectional information encoding , three types of lexical entries are discerned by the AIM of an embodiment : .( 1 ) Entries to which default inflectional rules apply : these entries do not have to contain any inflectional information .", "label": "", "metadata": {}, "score": "47.0704"}
{"text": "In terms of inflectional information encoding , three types of lexical entries are discerned by the AIM of an embodiment : .( 1 ) Entries to which default inflectional rules apply : these entries do not have to contain any inflectional information .", "label": "", "metadata": {}, "score": "47.0704"}
{"text": "In terms of inflectional information encoding , three types of lexical entries are discerned by the AIM of an embodiment : .( 1 ) Entries to which default inflectional rules apply : these entries do not have to contain any inflectional information .", "label": "", "metadata": {}, "score": "47.0704"}
{"text": "In terms of inflectional information encoding , three types of lexical entries are discerned by the AIM of an embodiment : .( 1 ) Entries to which default inflectional rules apply : these entries do not have to contain any inflectional information .", "label": "", "metadata": {}, "score": "47.0704"}
{"text": "that takes a raw , untagged text corpus as its only input ( no open - class dictionary ) and generates a partial list of verbs occurring in the text and the subcategorization frames ( SFs ) in which they occur .", "label": "", "metadata": {}, "score": "47.09304"}
{"text": "that takes a raw , untagged text corpus as its only input ( no open - class dictionary ) and generates a partial list of verbs occurring in the text and the subcategorization frames ( SFs ) in which they occur .", "label": "", "metadata": {}, "score": "47.09304"}
{"text": "The computer readable medium of claim 34 , wherein the method further comprises : . generating at least one target language syntactic representation ; . performing target language syntactic generation using at least one set of target language syntactic generation rules ; . generating at least one sequence of target language morpheme specifications ; and .", "label": "", "metadata": {}, "score": "47.14374"}
{"text": "We present a method for individuating dependencies between the semantic class of predicates and their associated subcategorization frames , and describe an implementation which allows the cquisition of such dependencies from bracketed texts .Tools . \" ... that takes a raw , untagged text corpus as its only input ( no open - class dictionary ) and generates a partial list of verbs occurring in the text and the subcategorization frames ( SFs ) in which they occur .", "label": "", "metadata": {}, "score": "47.21852"}
{"text": "In performing a reduce action , a grammar rule and an associated compiled feature structure manipulation are applied .When the manipulations succeed , a new parse node is generated comprising the new feature structures resulting from the successful feature structure manipulations .", "label": "", "metadata": {}, "score": "47.3786"}
{"text": "Chapter 10 .Building a Treebank for French .A newspaper corpus , representative of contemporary written French , was . subject to automatic tagging ( segmentation with special attention to .compounds , tagging relying on trigram method , and retagging making use . of contextual information ) and parsing ( surface and shallow . annotation , theory- neutral , with the aim of identifying sentence . boundaries and limited embedding ) .", "label": "", "metadata": {}, "score": "47.649498"}
{"text": "The stack comprises at least one parsing state , and at least one representation of each input word is shifted onto the at least one graph - structured stack .A new parse node is generated , and a feature structure or lexical feature structure of the shifted input item is obtained from a morphological analyzer and associated with the new parse node .", "label": "", "metadata": {}, "score": "47.736214"}
{"text": "Moreover , the source to target language transfer comprises the use of at least one example database and a thesaurus describing similarity between words .Target language syntactic generation comprises the use of target language syntactic generation rules .Additionally , target language morphological generation comprises the use of a target language dictionary and target language morphological generation rules .", "label": "", "metadata": {}, "score": "47.759796"}
{"text": "Moreover , the source to target language transfer comprises the use of at least one example database and a thesaurus describing similarity between words .Target language syntactic generation comprises the use of target language syntactic generation rules .Additionally , target language morphological generation comprises the use of a target language dictionary and target language morphological generation rules .", "label": "", "metadata": {}, "score": "47.759796"}
{"text": "Moreover , the source to target language transfer comprises the use of at least one example database and a thesaurus describing similarity between words .Target language syntactic generation comprises the use of target language syntactic generation rules .Additionally , target language morphological generation comprises the use of a target language dictionary and target language morphological generation rules .", "label": "", "metadata": {}, "score": "47.759796"}
{"text": "Moreover , the source to target language transfer comprises the use of at least one example database and a thesaurus describing similarity between words .Target language syntactic generation comprises the use of target language syntactic generation rules .Additionally , target language morphological generation comprises the use of a target language dictionary and target language morphological generation rules .", "label": "", "metadata": {}, "score": "47.759796"}
{"text": "Moreover , the source to target language transfer comprises the use of at least one example database and a thesaurus describing similarity between words .Target language syntactic generation comprises the use of target language syntactic generation rules .Additionally , target language morphological generation comprises the use of a target language dictionary and target language morphological generation rules .", "label": "", "metadata": {}, "score": "47.759796"}
{"text": "TAGGIT [ 35 ] was used to generate an initial tagging of the Brown corpus , which was then hand - edited .( Thus it provided the data that has since been used to train other taggers [ 20]. )", "label": "", "metadata": {}, "score": "47.760902"}
{"text": "TAGGIT [ 35 ] was used to generate an initial tagging of the Brown corpus , which was then hand - edited .( Thus it provided the data that has since been used to train other taggers [ 20]. )", "label": "", "metadata": {}, "score": "47.760902"}
{"text": "The previous alternatives include not performing morphological analysis , and using two - level morphological analysis .The problem with this approach is that the system is required to have a large amount of memory to accommodate the dictionary and , because of the access time required , the language processing is inefficient .", "label": "", "metadata": {}, "score": "47.915108"}
{"text": "The previous alternatives include not performing morphological analysis , and using two - level morphological analysis .The problem with this approach is that the system is required to have a large amount of memory to accommodate the dictionary and , because of the access time required , the language processing is inefficient .", "label": "", "metadata": {}, "score": "47.915108"}
{"text": "The previous alternatives include not performing morphological analysis , and using two - level morphological analysis .The problem with this approach is that the system is required to have a large amount of memory to accommodate the dictionary and , because of the access time required , the language processing is inefficient .", "label": "", "metadata": {}, "score": "47.915108"}
{"text": "The previous alternatives include not performing morphological analysis , and using two - level morphological analysis .The problem with this approach is that the system is required to have a large amount of memory to accommodate the dictionary and , because of the access time required , the language processing is inefficient .", "label": "", "metadata": {}, "score": "47.915108"}
{"text": "Moreover , some light - verb and copula constructions can not be handled without the power to exchange feature values between the verb and its object .Still another previous approach to performing syntactic analysis in example - based translation systems is to separate syntactic analysis from example - based transfer , and perform dependency analysis on both the input string and the example data .", "label": "", "metadata": {}, "score": "48.325268"}
{"text": "Moreover , some light - verb and copula constructions can not be handled without the power to exchange feature values between the verb and its object .Still another previous approach to performing syntactic analysis in example - based translation systems is to separate syntactic analysis from example - based transfer , and perform dependency analysis on both the input string and the example data .", "label": "", "metadata": {}, "score": "48.325268"}
{"text": "Moreover , some light - verb and copula constructions can not be handled without the power to exchange feature values between the verb and its object .Still another previous approach to performing syntactic analysis in example - based translation systems is to separate syntactic analysis from example - based transfer , and perform dependency analysis on both the input string and the example data .", "label": "", "metadata": {}, "score": "48.325268"}
{"text": "Moreover , some light - verb and copula constructions can not be handled without the power to exchange feature values between the verb and its object .Still another previous approach to performing syntactic analysis in example - based translation systems is to separate syntactic analysis from example - based transfer , and perform dependency analysis on both the input string and the example data .", "label": "", "metadata": {}, "score": "48.325268"}
{"text": "Moreover , some light - verb and copula constructions can not be handled without the power to exchange feature values between the verb and its object .Still another previous approach to performing syntactic analysis in example - based translation systems is to separate syntactic analysis from example - based transfer , and perform dependency analysis on both the input string and the example data .", "label": "", "metadata": {}, "score": "48.325268"}
{"text": "In evaluating the performance of the AIM of an embodiment , experiments were conducted to compare the AIM and a typical two - level morphological analyzer in terms of speed and memory requirements .The programs were tested on Sun Ultra 2 workstations using 5000-word dictionaries for both analyzers in the appropriate formats .", "label": "", "metadata": {}, "score": "48.514496"}
{"text": "In evaluating the performance of the AIM of an embodiment , experiments were conducted to compare the AIM and a typical two - level morphological analyzer in terms of speed and memory requirements .The programs were tested on Sun Ultra 2 workstations using 5000-word dictionaries for both analyzers in the appropriate formats .", "label": "", "metadata": {}, "score": "48.514496"}
{"text": "In evaluating the performance of the AIM of an embodiment , experiments were conducted to compare the AIM and a typical two - level morphological analyzer in terms of speed and memory requirements .The programs were tested on Sun Ultra 2 workstations using 5000-word dictionaries for both analyzers in the appropriate formats .", "label": "", "metadata": {}, "score": "48.514496"}
{"text": "In evaluating the performance of the AIM of an embodiment , experiments were conducted to compare the AIM and a typical two - level morphological analyzer in terms of speed and memory requirements .The programs were tested on Sun Ultra 2 workstations using 5000-word dictionaries for both analyzers in the appropriate formats .", "label": "", "metadata": {}, "score": "48.514496"}
{"text": "The sorting of all entries by root feature makes the dictionary easier to organize and maintain and maximizes usability for the purposes of morphological analysis .Furthermore , the AIM dictionary structure makes it easy to add new features to the dictionary entries .", "label": "", "metadata": {}, "score": "48.5207"}
{"text": "The sorting of all entries by root feature makes the dictionary easier to organize and maintain and maximizes usability for the purposes of morphological analysis .Furthermore , the AIM dictionary structure makes it easy to add new features to the dictionary entries .", "label": "", "metadata": {}, "score": "48.5207"}
{"text": "The sorting of all entries by root feature makes the dictionary easier to organize and maintain and maximizes usability for the purposes of morphological analysis .Furthermore , the AIM dictionary structure makes it easy to add new features to the dictionary entries .", "label": "", "metadata": {}, "score": "48.5207"}
{"text": "The sorting of all entries by root feature makes the dictionary easier to organize and maintain and maximizes usability for the purposes of morphological analysis .Furthermore , the AIM dictionary structure makes it easy to add new features to the dictionary entries .", "label": "", "metadata": {}, "score": "48.5207"}
{"text": "information , such as figurative usage , idiomatic expressions , . etc . ) .The first two types of annotations were performed . semi - automatically , while the other two were performed manually .There . are two innovations brought about by this treebank : sense tagging .", "label": "", "metadata": {}, "score": "48.59716"}
{"text": "For these reasons , research has turned from the traditional rule - based framework towards more flexible approaches , such as example - based translation .The method and apparatus of an embodiment of the present invention increase the linguistic efficiency and accuracy of example - based translation by exploiting as many linguistic regularities as possible , without attempting analysis that is too deep or too differentiated to be performed efficiently and accurately on spoken language .", "label": "", "metadata": {}, "score": "48.626167"}
{"text": "For these reasons , research has turned from the traditional rule - based framework towards more flexible approaches , such as example - based translation .The method and apparatus of an embodiment of the present invention increase the linguistic efficiency and accuracy of example - based translation by exploiting as many linguistic regularities as possible , without attempting analysis that is too deep or too differentiated to be performed efficiently and accurately on spoken language .", "label": "", "metadata": {}, "score": "48.626167"}
{"text": "For these reasons , research has turned from the traditional rule - based framework towards more flexible approaches , such as example - based translation .The method and apparatus of an embodiment of the present invention increase the linguistic efficiency and accuracy of example - based translation by exploiting as many linguistic regularities as possible , without attempting analysis that is too deep or too differentiated to be performed efficiently and accurately on spoken language .", "label": "", "metadata": {}, "score": "48.626167"}
{"text": "For these reasons , research has turned from the traditional rule - based framework towards more flexible approaches , such as example - based translation .The method and apparatus of an embodiment of the present invention increase the linguistic efficiency and accuracy of example - based translation by exploiting as many linguistic regularities as possible , without attempting analysis that is too deep or too differentiated to be performed efficiently and accurately on spoken language .", "label": "", "metadata": {}, "score": "48.626167"}
{"text": "For these reasons , research has turned from the traditional rule - based framework towards more flexible approaches , such as example - based translation .The method and apparatus of an embodiment of the present invention increase the linguistic efficiency and accuracy of example - based translation by exploiting as many linguistic regularities as possible , without attempting analysis that is too deep or too differentiated to be performed efficiently and accurately on spoken language .", "label": "", "metadata": {}, "score": "48.626167"}
{"text": "Morphological analysis is the process of analyzing words into morphemes , identifying root forms and grammatical categories , and detecting lexical ambiguity and out - of - vocabulary words .The output of the analysis can be used as input to a parser and other natural language processing modules .", "label": "", "metadata": {}, "score": "48.660072"}
{"text": "Morphological analysis is the process of analyzing words into morphemes , identifying root forms and grammatical categories , and detecting lexical ambiguity and out - of - vocabulary words .The output of the analysis can be used as input to a parser and other natural language processing modules .", "label": "", "metadata": {}, "score": "48.660072"}
{"text": "Morphological analysis is the process of analyzing words into morphemes , identifying root forms and grammatical categories , and detecting lexical ambiguity and out - of - vocabulary words .The output of the analysis can be used as input to a parser and other natural language processing modules .", "label": "", "metadata": {}, "score": "48.660072"}
{"text": "Morphological analysis is the process of analyzing words into morphemes , identifying root forms and grammatical categories , and detecting lexical ambiguity and out - of - vocabulary words .The output of the analysis can be used as input to a parser and other natural language processing modules .", "label": "", "metadata": {}, "score": "48.660072"}
{"text": "Morphological analysis is the process of analyzing words into morphemes , identifying root forms and grammatical categories , and detecting lexical ambiguity and out - of - vocabulary words .The output of the analysis can be used as input to a parser and other natural language processing modules .", "label": "", "metadata": {}, "score": "48.660072"}
{"text": "A method and an apparatus for performing spoken language translation are provided .A speech input is received comprising at least one source language .The speech input comprises words , sentences , and phrases in a natural spoken language .Source expressions are recognized in the source language .", "label": "", "metadata": {}, "score": "48.75315"}
{"text": "went on being manually assigned .The separately produced morphological .and analytical syntactic annotations are then merged together , all . possible discrepancies being manually solved .The third level of . annotation , the tectogramatical one , describes the meaning of the . sentences by means of tectogrammatical functions and the information . structure of sentences .", "label": "", "metadata": {}, "score": "48.795273"}
{"text": "words , with null subjects and ellipses , ' ' se''-constructions , . etc .There are three levels of annotations : syntactic categories , . syntactic functions , morpho - syntactic features and some semantic .features .The annotation and debugging tools are also presented in the . paper , alongside with some error statistics , current state of the .", "label": "", "metadata": {}, "score": "48.884815"}
{"text": "The treatment of irregular forms as separate entries in the AIM does not impose much additional burden in terms of the number of entries and complexity , but aids organization and increases usability and ease of maintenance .The sorting of all entries by root feature makes the dictionary easier to organize and maintain and maximizes usability for the purposes of morphological analysis .", "label": "", "metadata": {}, "score": "48.939743"}
{"text": "Sentence syntax is the basis for organizing semantic relations in TANKA , a project that aims to acquire knowledge from technical text .Other hallmarks include an absence of precoded domain - specific knowledge ; significant use of public - domain generic linguistic information sources ; involvement of the ... \" .", "label": "", "metadata": {}, "score": "48.940872"}
{"text": "Sentence syntax is the basis for organizing semantic relations in TANKA , a project that aims to acquire knowledge from technical text .Other hallmarks include an absence of precoded domain - specific knowledge ; significant use of public - domain generic linguistic information sources ; involvement of the ... \" .", "label": "", "metadata": {}, "score": "48.940872"}
{"text": "When the parser has analyzed the entire input successfully and generated at least one packed shared parse forest , the next action is an accept action .The accept action is performed , and a rebuilding procedure is performed on the context - free tree structure of the input sentence generated by the parser .", "label": "", "metadata": {}, "score": "48.945656"}
{"text": "While the same basic techniques for parsing , semantic interpretation , and contextual interpretation may be used for spoken or written language , there are some significant differences that affect system design .For instance , with spoken input the system has to deal with uncertainty .", "label": "", "metadata": {}, "score": "49.14499"}
{"text": "While the same basic techniques for parsing , semantic interpretation , and contextual interpretation may be used for spoken or written language , there are some significant differences that affect system design .For instance , with spoken input the system has to deal with uncertainty .", "label": "", "metadata": {}, "score": "49.14499"}
{"text": "While the same basic techniques for parsing , semantic interpretation , and contextual interpretation may be used for spoken or written language , there are some significant differences that affect system design .For instance , with spoken input the system has to deal with uncertainty .", "label": "", "metadata": {}, "score": "49.14499"}
{"text": "While the same basic techniques for parsing , semantic interpretation , and contextual interpretation may be used for spoken or written language , there are some significant differences that affect system design .For instance , with spoken input the system has to deal with uncertainty .", "label": "", "metadata": {}, "score": "49.14499"}
{"text": "Encouraging experimental results are described and evaluated . ... algorithm has verb detection , subcategorization frame detection , and subcategorization frame decision phases .The last stage uses statistical models of word frequency distributions .Basili et al .( 1992 : 96 ) argue that statistical pattern - matching approaches \" are based on the ( strong ) assumption that synt ... . \" ...", "label": "", "metadata": {}, "score": "49.237648"}
{"text": "Encouraging experimental results are described and evaluated . ... algorithm has verb detection , subcategorization frame detection , and subcategorization frame decision phases .The last stage uses statistical models of word frequency distributions .Basili et al .( 1992 : 96 ) argue that statistical pattern - matching approaches \" are based on the ( strong ) assumption that synt ... . \" ...", "label": "", "metadata": {}, "score": "49.237648"}
{"text": "In order to ensure the cleanness of the parsed corpus , one has two . problems to solve : the decision ( i.e. the correctness of the analysis ) .and the consistency ( of the analysis throughout the corpus ) .", "label": "", "metadata": {}, "score": "49.275177"}
{"text": "Parser Evaluation .John Carroll , Guido Minnen , Ted Briscoe .The emergence of syntactic parsers triggered the need for methods .evaluating them .In fact , this has become a real branch in the field . of NLP research .", "label": "", "metadata": {}, "score": "49.358307"}
{"text": "Generation of the recognition hypotheses comprises assigning basic probabilities to at least one basic component of the speech input using language models and calculating an overall probability of each of the recognition hypotheses using the assigned basic probabilities .Translations may be provided along with the recognition hypotheses .", "label": "", "metadata": {}, "score": "49.477253"}
{"text": "A best hypothesis in the source language is presented to a user as well as alternatives to a portion of the best hypothesis in the source language .The user may choose among the alternatives or correct one of the alternatives .", "label": "", "metadata": {}, "score": "49.491478"}
{"text": "an output coupled to the at least one processor , wherein the output provides the synthesized speech output .The portable apparatus of claim 13 , wherein translating the recognized expression includes minimizing misrecognitions of the expression in the source language , wherein the misrecognitions result from factors comprising noise and speaker variation .", "label": "", "metadata": {}, "score": "49.60284"}
{"text": "Hypothesis generation is adapted in response to the selected best hypotheses .An output is provided comprising the best hypothesis .The input is translated in response to the selected best hypothesis , and a synthesized translated speech output is provided .", "label": "", "metadata": {}, "score": "49.68515"}
{"text": "An output is provided comprising the best hypothesis ; moreover , the input is translated in response to the selected best hypothesis , and a synthesized translated speech output is provided . translating the at least one speech input in response to the best hypothesis ; and .", "label": "", "metadata": {}, "score": "49.804672"}
{"text": "managing the process .But once the tool for grammatical queries . search facility ( Fuzzy tree Fragment ) is created , it can also be used .not only for correction , but also for searching and browsing the .corpus for linguistic queries , so a post - project use of the tool .", "label": "", "metadata": {}, "score": "49.820824"}
{"text": "Furthermore , misrecognitions are minimized by the generation of candidate recognized source expressions by processing the intermediate data structures using models comprising a general language model and a domain model .A recognized source expression is selected and confirmed by a user through a user interface .", "label": "", "metadata": {}, "score": "49.8936"}
{"text": "Tools . \" ... that takes a raw , untagged text corpus as its only input ( no open - class dictionary ) and generates a partial list of verbs occurring in the text and the subcategorization frames ( SFs ) in which they occur .", "label": "", "metadata": {}, "score": "49.9116"}
{"text": "Instead , the STS of an embodiment analyzes the input , detects or determines the meaning of the input ( e.g. question , statement , etc . ) , and renders that meaning in the appropriate way in a target language .", "label": "", "metadata": {}, "score": "49.949577"}
{"text": "Instead , the STS of an embodiment analyzes the input , detects or determines the meaning of the input ( e.g. question , statement , etc . ) , and renders that meaning in the appropriate way in a target language .", "label": "", "metadata": {}, "score": "49.949577"}
{"text": "Instead , the STS of an embodiment analyzes the input , detects or determines the meaning of the input ( e.g. question , statement , etc . ) , and renders that meaning in the appropriate way in a target language .", "label": "", "metadata": {}, "score": "49.949577"}
{"text": "Instead , the STS of an embodiment analyzes the input , detects or determines the meaning of the input ( e.g. question , statement , etc . ) , and renders that meaning in the appropriate way in a target language .", "label": "", "metadata": {}, "score": "49.949577"}
{"text": "Instead , the STS of an embodiment analyzes the input , detects or determines the meaning of the input ( e.g. question , statement , etc . ) , and renders that meaning in the appropriate way in a target language .", "label": "", "metadata": {}, "score": "49.949577"}
{"text": "The STS performs speech recognition in the source language while optionally allowing the user to confirm the recognized expression , or allowing the user to choose from a sequence of candidate recognitions .The STS translates the recognized expression from the source language to a target language .", "label": "", "metadata": {}, "score": "49.957443"}
{"text": "The STS performs speech recognition in the source language while optionally allowing the user to confirm the recognized expression , or allowing the user to choose from a sequence of candidate recognitions .The STS translates the recognized expression from the source language to a target language .", "label": "", "metadata": {}, "score": "49.957443"}
{"text": "The STS performs speech recognition in the source language while optionally allowing the user to confirm the recognized expression , or allowing the user to choose from a sequence of candidate recognitions .The STS translates the recognized expression from the source language to a target language .", "label": "", "metadata": {}, "score": "49.957443"}
{"text": "The STS performs speech recognition in the source language while optionally allowing the user to confirm the recognized expression , or allowing the user to choose from a sequence of candidate recognitions .The STS translates the recognized expression from the source language to a target language .", "label": "", "metadata": {}, "score": "49.957443"}
{"text": "The STS performs speech recognition in the source language while optionally allowing the user to confirm the recognized expression , or allowing the user to choose from a sequence of candidate recognitions .The STS translates the recognized expression from the source language to a target language .", "label": "", "metadata": {}, "score": "49.957443"}
{"text": "starting the treebank , so its resources could be used for the . latter .The authors provide reasons for their choosing of the grammar .formalism used for the representation of lexico - grammatical . information , namely Information - based Case Grammar .", "label": "", "metadata": {}, "score": "50.317802"}
{"text": "Bod , R. ( 1998 )Spoken Dialogue Interpretation with the DOP Model , .Proceedings COLING - ACL'98 , Montreal , Canada .Charniak , E. ( 1996 )Tree - bank Grammars .AAAI-96 .Proccedings of the .Thirteenth national Conference of Artificial Intelligence , .", "label": "", "metadata": {}, "score": "50.401905"}
{"text": "Formally , a context - free grammar of a language is a four - tuple comprising nonterminal vocabularies , terminal vocabularies , a finite set of production rules , and a starting symbol for all productions .The nonterminal and terminal vocabularies are disjoint .", "label": "", "metadata": {}, "score": "50.53073"}
{"text": "Formally , a context - free grammar of a language is a four - tuple comprising nonterminal vocabularies , terminal vocabularies , a finite set of production rules , and a starting symbol for all productions .The nonterminal and terminal vocabularies are disjoint .", "label": "", "metadata": {}, "score": "50.53073"}
{"text": "Formally , a context - free grammar of a language is a four - tuple comprising nonterminal vocabularies , terminal vocabularies , a finite set of production rules , and a starting symbol for all productions .The nonterminal and terminal vocabularies are disjoint .", "label": "", "metadata": {}, "score": "50.53073"}
{"text": "Formally , a context - free grammar of a language is a four - tuple comprising nonterminal vocabularies , terminal vocabularies , a finite set of production rules , and a starting symbol for all productions .The nonterminal and terminal vocabularies are disjoint .", "label": "", "metadata": {}, "score": "50.53073"}
{"text": "Formally , a context - free grammar of a language is a four - tuple comprising nonterminal vocabularies , terminal vocabularies , a finite set of production rules , and a starting symbol for all productions .The nonterminal and terminal vocabularies are disjoint .", "label": "", "metadata": {}, "score": "50.53073"}
{"text": "The output format of the AIM of an embodiment of the present invention makes it easy to integrate the AIM with a syntactic parser which also operates on feature structures .Furthermore , it provides for quick access to relevant individual features ( e.g. root , grammatical category ) .", "label": "", "metadata": {}, "score": "50.57927"}
{"text": "The output format of the AIM of an embodiment of the present invention makes it easy to integrate the AIM with a syntactic parser which also operates on feature structures .Furthermore , it provides for quick access to relevant individual features ( e.g. root , grammatical category ) .", "label": "", "metadata": {}, "score": "50.57927"}
{"text": "The output format of the AIM of an embodiment of the present invention makes it easy to integrate the AIM with a syntactic parser which also operates on feature structures .Furthermore , it provides for quick access to relevant individual features ( e.g. root , grammatical category ) .", "label": "", "metadata": {}, "score": "50.57927"}
{"text": "The output format of the AIM of an embodiment of the present invention makes it easy to integrate the AIM with a syntactic parser which also operates on feature structures .Furthermore , it provides for quick access to relevant individual features ( e.g. root , grammatical category ) .", "label": "", "metadata": {}, "score": "50.57927"}
{"text": "relation or even to a certain word .Two scores are calculated : recall . and precision .The author goes on with the presentation of MINIPAR , a principle - based .broad coverage English parser ( Berwick et al .", "label": "", "metadata": {}, "score": "50.593185"}
{"text": "Grammar ( CFG ) from a treebank , according to Charniak 1996 .A set of .regular expression based annotation principles are then developed and .applied to the CFG , resulting an annotated CFG .The annotated rules .are rematched against the treebank trees , the result being . f(unctional)-structures .", "label": "", "metadata": {}, "score": "50.601418"}
{"text": "During parsing operations , the parser may perform shift actions and reduce actions .If the next action is determined to be a shift action then a shift action is performed wherein the next item of the input string is shifted onto a stack or intermediate data structure of the parser .", "label": "", "metadata": {}, "score": "50.645645"}
{"text": "The feature structure constraints of an embodiment are performed when a reduce operation is executed , but the embodiment is not so limited .The parser of an embodiment has advantages over typical parsers , in that it provides for flexible feature structure representation and complete manipulation .", "label": "", "metadata": {}, "score": "50.738895"}
{"text": "The feature structure constraints of an embodiment are performed when a reduce operation is executed , but the embodiment is not so limited .The parser of an embodiment has advantages over typical parsers , in that it provides for flexible feature structure representation and complete manipulation .", "label": "", "metadata": {}, "score": "50.738895"}
{"text": "the feature structure constraints of an embodiment are performed when a reduce operation is executed , but the embodiment is not so limited .The parser of an embodiment has advantages over typical parsers , in that it provides for flexible feature structure representation and complete manipulation .", "label": "", "metadata": {}, "score": "50.738895"}
{"text": "The feature structure constraints of an embodiment are performed when a reduce operation is executed , but the embodiment is not so limited .The parser of an embodiment has advantages over typical parsers , in that it provides for flexible feature structure representation and complete manipulation .", "label": "", "metadata": {}, "score": "50.738895"}
{"text": "The feature structure constraints of an embodiment are performed when a reduce operation is executed , but the embodiment is not so limited .The parser of an embodiment has advantages over typical parsers , in that it provides for flexible feature structure representation and complete manipulation .", "label": "", "metadata": {}, "score": "50.738895"}
{"text": "Moreover , each sentence is . hand annotated with the list of linguistic phenomena they display , . choosing from nine groups of hierarchies of such phenomena .Sentences . are annotated with attribute - value matrices ( AVMs ) , whose content is . restricted by an HPSG signature .", "label": "", "metadata": {}, "score": "50.800438"}
{"text": "This signal is then processed to extract various features , such as the intensity of sound at different frequencies and the change in intensity over time .These features serve as the input to a speech recognition system , which generally uses Hidden Markov Model ( HMM ) techniques to identify the most likely sequence of words that could have produced the speech signal .", "label": "", "metadata": {}, "score": "50.803265"}
{"text": "This signal is then processed to extract various features , such as the intensity of sound at different frequencies and the change in intensity over time .These features serve as the input to a speech recognition system , which generally uses Hidden Markov Model ( HMM ) techniques to identify the most likely sequence of words that could have produced the speech signal .", "label": "", "metadata": {}, "score": "50.803265"}
{"text": "This signal is then processed to extract various features , such as the intensity of sound at different frequencies and the change in intensity over time .These features serve as the input to a speech recognition system , which generally uses Hidden Markov Model ( HMM ) techniques to identify the most likely sequence of words that could have produced the speech signal .", "label": "", "metadata": {}, "score": "50.803265"}
{"text": "This signal is then processed to extract various features , such as the intensity of sound at different frequencies and the change in intensity over time .These features serve as the input to a speech recognition system , which generally uses Hidden Markov Model ( HMM ) techniques to identify the most likely sequence of words that could have produced the speech signal .", "label": "", "metadata": {}, "score": "50.803265"}
{"text": "This signal is then processed to extract various features , such as the intensity of sound at different frequencies and the change in intensity over time .These features serve as the input to a speech recognition system , which generally uses Hidden Markov Model ( HMM ) techniques to identify the most likely sequence of words that could have produced the speech signal .", "label": "", "metadata": {}, "score": "50.803265"}
{"text": "The computer readable medium of claim 34 , wherein the grammar rule - based processing comprises : . syntactic and morphological analysis in the at least one source language ; and . syntactic and morphological generation in the at least one target language .", "label": "", "metadata": {}, "score": "50.91596"}
{"text": "An output that is representative of the revised version of the best hypothesis in a target language is presented to the user .These and other features , aspects , and advantages of the present invention will be apparent from the accompanying drawings and from the detailed description and appended claims which follow .", "label": "", "metadata": {}, "score": "51.117733"}
{"text": "A method and apparatus for adaptive speech recognition hypothesis are provided , wherein a number of ordered recognition hypotheses are generated and presented in response to a received speech input comprising natural spoken language .Generation of the recognition hypotheses comprises assigning basic probabilities to at least one basic component of the speech input using language models and calculating an overall probability of each of the recognition hypotheses using the assigned basic probabilities .", "label": "", "metadata": {}, "score": "51.134094"}
{"text": "GRAMMAR INDUCTION WITH TREEBANKS .Chapter 19 .Extracting Stochastic Grammars from Treebanks .Rens Bod .The assumption ( see Scha 1990 , 1992 , Bod 1992 , 1995 , 1998 ) .constituting the basis of this article is that ' ' human language . perception and production processes may very well work with . representations of concrete past language experiences , and that .", "label": "", "metadata": {}, "score": "51.210987"}
{"text": "( identification of phrase boundaries and labeling of constituents ) and .functional annotation ( with functional relations ) , lexico- semantic . annotation ( distinguishing among single lexical items , semantically .complex units and title sense units ; specification of senses for each .", "label": "", "metadata": {}, "score": "51.215225"}
{"text": "Two other sources are used for the project - specific . formats of the annotation scheme : Data Category Specification ( DCS ) .( the description of the set of data categories used within a certain . annotation scheme ) and Dialect Specification ( defining the . project - specific format for syntactic annotation ) .", "label": "", "metadata": {}, "score": "51.26304"}
{"text": "capture more dependencies than small ones ) ; the larger the lexical . context ( up to a certain depth , which seems to be corpus - specific ) , . the better accuracy ( as more lexical dependencies are taken into . account ) ; the low frequency subtrees have an important contribution to .", "label": "", "metadata": {}, "score": "51.432526"}
{"text": "when using the high - speed setting ( \" mogura \" ) .Other useful features are : .Output parse results in an XML format : specify the option \" -xml \" .The parser adds XML tags to an original text , and it is useful when parse results are merged with other processing results ( e.g. named entities ) .", "label": "", "metadata": {}, "score": "51.463142"}
{"text": "when using the high - speed setting ( \" mogura \" ) .Other useful features are : .Output parse results in an XML format : specify the option \" -xml \" .The parser adds XML tags to an original text , and it is useful when parse results are merged with other processing results ( e.g. named entities ) .", "label": "", "metadata": {}, "score": "51.463142"}
{"text": "Encoding Syntactic Annotation .Nancy Ide , Laurent Romary .The emerge of treebanks , alongside with the proliferation of . annotation schemes , triggered the need for a general framework to .accommodate these annotation schemes and the different theoretical and . practical approaches .", "label": "", "metadata": {}, "score": "51.55313"}
{"text": "The STS of an embodiment is able to handle entire sentences in addition to individual words and short phrases .Therefore , each input expression may be quite long resulting in a greater chance of error by a typical speech recognizer .", "label": "", "metadata": {}, "score": "51.574177"}
{"text": "The STS of an embodiment is able to handle entire sentences in addition to individual words and short phrases .Therefore , each input expression may be quite long resulting in a greater chance of error by a typical speech recognizer .", "label": "", "metadata": {}, "score": "51.574177"}
{"text": "The STS of an embodiment is able to handle entire sentences in addition to individual words and short phrases .Therefore , each input expression may be quite long resulting in a greater chance of error by a typical speech recognizer .", "label": "", "metadata": {}, "score": "51.574177"}
{"text": "The STS of an embodiment is able to handle entire sentences in addition to individual words and short phrases .Therefore , each input expression may be quite long resulting in a greater chance of error by a typical speech recognizer .", "label": "", "metadata": {}, "score": "51.574177"}
{"text": "The STS of an embodiment is able to handle entire sentences in addition to individual words and short phrases .Therefore , each input expression may be quite long resulting in a greater chance of error by a typical speech recognizer .", "label": "", "metadata": {}, "score": "51.574177"}
{"text": "( i.e. it tries to define the relations between the affected words ) .useful in guiding the detection of errors .Although the hierarchy was .a fine- grained one , in the annotation process only a pool of 16 error . types were to be detected and classified .", "label": "", "metadata": {}, "score": "51.837654"}
{"text": "stressing the fact that the problems encountered for each language . are , at great extent , the same , thus a certain redundancy in the .papers collected in this volume .PART I. BUILDING TREEBANKS .The chapters of the first part are grouped according to the language .", "label": "", "metadata": {}, "score": "51.974815"}
{"text": "Partial parsing techniques , like tagging techniques , aim for reliability and robustness in the face of t ... \" .m we can carve o # next . 'Partial parsing ' is a cover term for a range of di#erent techniques for recovering some but not all of the information contained in a traditional syntactic analysis .", "label": "", "metadata": {}, "score": "52.04532"}
{"text": "Partial parsing techniques , like tagging techniques , aim for reliability and robustness in the face of t ... \" .m we can carve o # next . 'Partial parsing ' is a cover term for a range of di#erent techniques for recovering some but not all of the information contained in a traditional syntactic analysis .", "label": "", "metadata": {}, "score": "52.04532"}
{"text": "The parser of an embodiment of the present invention is used for speech - to - speech translation and integrates feature structure manipulations into a GLR parsing algorithm by introducing a flexible representation and a safe ambiguity packing mechanism .The feature structure unifications are invoked when a new parse node is created .", "label": "", "metadata": {}, "score": "52.258865"}
{"text": "The parser of an embodiment of the present invention is used for speech - to - speech translation and integrates feature structure manipulations into a GLR parsing algorithm by introducing a flexible representation and a safe ambiguity packing mechanism .The feature structure unifications are invoked when a new parse node is created .", "label": "", "metadata": {}, "score": "52.258865"}
{"text": "The parser of an embodiment of the present invention is used for speech - to - speech translation and integrates feature structure manipulations into a GLR parsing algorithm by introducing a flexible representation and a safe ambiguity packing mechanism .The feature structure unifications are invoked when a new parse node is created .", "label": "", "metadata": {}, "score": "52.258865"}
{"text": "The parser of an embodiment of the present invention is used for speech - to - speech translation and integrates feature structure manipulations into a GLR parsing algorithm by introducing a flexible representation and a safe ambiguity packing mechanism .The feature structure unifications are invoked when a new parse node is created .", "label": "", "metadata": {}, "score": "52.258865"}
{"text": "The parser of an embodiment of the present invention is used for speech - to - speech translation and integrates feature structure manipulations into a GLR parsing algorithm by introducing a flexible representation and a safe ambiguity packing mechanism .The feature structure unifications are invoked when a new parse node is created .", "label": "", "metadata": {}, "score": "52.258865"}
{"text": "The lexicon learned consists of words paired with meaning representations .WOLFIE is part of an integrated system ... \" .This paper describes a system , WOLIm ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with representations of their meaning .", "label": "", "metadata": {}, "score": "52.30418"}
{"text": "The lexicon learned consists of words paired with meaning representations .WOLFIE is part of an integrated system ... \" .This paper describes a system , WOLIm ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with representations of their meaning .", "label": "", "metadata": {}, "score": "52.30418"}
{"text": "This is performed one or more times recursively , as shown in FIG .11 herein .The syntactic analysis of an embodiment of the present invention comprises a shallow analysis to recognize linguistic constituents such as noun phrases , verb phrases and prepositional phrases .", "label": "", "metadata": {}, "score": "52.32544"}
{"text": "This is performed one or more times recursively , as shown in FIG .11 herein .The syntactic analysis of an embodiment of the present invention comprises a shallow analysis to recognize linguistic constituents such as noun phrases , verb phrases and prepositional phrases .", "label": "", "metadata": {}, "score": "52.32544"}
{"text": "This is performed one or more times recursively , as shown in FIG .11 herein .The syntactic analysis of an embodiment of the present invention comprises a shallow analysis to recognize linguistic constituents such as noun phrases , verb phrases and prepositional phrases .", "label": "", "metadata": {}, "score": "52.32544"}
{"text": "This is performed one or more times recursively , as shown in FIG .11 herein .The syntactic analysis of an embodiment of the present invention comprises a shallow analysis to recognize linguistic constituents such as noun phrases , verb phrases and prepositional phrases .", "label": "", "metadata": {}, "score": "52.32544"}
{"text": "This is performed one or more times recursively , as shown in FIG .11 herein .The syntactic analysis of an embodiment of the present invention comprises a shallow analysis to recognize linguistic constituents such as noun phrases , verb phrases and prepositional phrases .", "label": "", "metadata": {}, "score": "52.32544"}
{"text": "Chapter 18 .Dependency - based Evaluation of MINIPAR .Dekang Lin .The author presents a dependency - based method for evaluating parsers . performance .To represent a dependency tree he makes use of a set of . tuples for each node in the tree , specifying the word , its grammatical . category , its head ( if the case , and also its position with respect to .", "label": "", "metadata": {}, "score": "52.44091"}
{"text": "synthesizing at least one speech output in response to the translated at least one speech input .The apparatus of claim 14 , wherein the at least one processor is further configured to translate by presenting a plurality of translations corresponding with the the plurality of recognition hypotheses .", "label": "", "metadata": {}, "score": "52.53225"}
{"text": "the results achieved so far and the open questions .The addressees are .linguists , including computational linguists , psycholinguists , and . sociolinguists .The book is organized in two parts : Building treebanks ( 15 chapters , . pp . 1 - 277 ) and Using treebanks ( 6 chapters , pp .", "label": "", "metadata": {}, "score": "52.55021"}
{"text": "The results reported here were obtained using a data- oriented parsing .( DOP ) model ( presented in section 2 of the paper ) which was applied to .two corpora of phrase structure trees : Air Travel Information System .", "label": "", "metadata": {}, "score": "52.718384"}
{"text": "The target language generation component needs a certain amount of syntactic knowledge and syntactic operations to produce grammatically correct output .A tag question in English is one example of such a purely syntax - driven operation .Finally , syntax is required to model spoken language phenomena .", "label": "", "metadata": {}, "score": "52.732685"}
{"text": "The target language generation component needs a certain amount of syntactic knowledge and syntactic operations to produce grammatically correct output .A tag question in English is one example of such a purely syntax - driven operation .Finally , syntax is required to model spoken language phenomena .", "label": "", "metadata": {}, "score": "52.732685"}
{"text": "The target language generation component needs a certain amount of syntactic knowledge and syntactic operations to produce grammatically correct output .A tag question in English is one example of such a purely syntax - driven operation .Finally , syntax is required to model spoken language phenomena .", "label": "", "metadata": {}, "score": "52.732685"}
{"text": "The target language generation component needs a certain amount of syntactic knowledge and syntactic operations to produce grammatically correct output .A tag question in English is one example of such a purely syntax - driven operation .Finally , syntax is required to model spoken language phenomena .", "label": "", "metadata": {}, "score": "52.732685"}
{"text": "The target language generation component needs a certain amount of syntactic knowledge and syntactic operations to produce grammatically correct output .A tag question in English is one example of such a purely syntax - driven operation .Finally , syntax is required to model spoken language phenomena .", "label": "", "metadata": {}, "score": "52.732685"}
{"text": "The information in the feature structures of an embodiment of the present invention originates at the lexical level in the morphological analysis component .The feature structure manipulation annotations on the context - free grammar rules pass this information on to higher - level constituents , apply tests to it , and re - arrange it depending on the syntactic structure of the expression .", "label": "", "metadata": {}, "score": "52.761154"}
{"text": "The information in the feature structures of an embodiment of the present invention originates at the lexical level in the morphological analysis component .The feature structure manipulation annotations on the context - free grammar rules pass this information on to higher - level constituents , apply tests to it , and re - arrange it depending on the syntactic structure of the expression .", "label": "", "metadata": {}, "score": "52.761154"}
{"text": "The information in the feature structures of an embodiment of the present invention originates at the lexical level in the morphological analysis component .The feature structure manipulation annotations on the context - free grammar rules pass this information on to higher - level constituents , apply tests to it , and re - arrange it depending on the syntactic structure of the expression .", "label": "", "metadata": {}, "score": "52.761154"}
{"text": "The information in the feature structures of an embodiment of the present invention originates at the lexical level in the morphological analysis component .The feature structure manipulation annotations on the context - free grammar rules pass this information on to higher - level constituents , apply tests to it , and re - arrange it depending on the syntactic structure of the expression .", "label": "", "metadata": {}, "score": "52.761154"}
{"text": "The information in the feature structures of an embodiment of the present invention originates at the lexical level in the morphological analysis component .The feature structure manipulation annotations on the context - free grammar rules pass this information on to higher - level constituents , apply tests to it , and re - arrange it depending on the syntactic structure of the expression .", "label": "", "metadata": {}, "score": "52.761154"}
{"text": "The computer readable medium of claim 25 , wherein the method further comprises : . applying at least one grammar rule to the at least one component when the at least one next action is determined to be a reduce action ; . executing at least one feature structure manipulation corresponding to the at least one grammar rule ; and . determining whether the at least one feature structure manipulation succeeds .", "label": "", "metadata": {}, "score": "52.823433"}
{"text": "However , syntactic ambiguity was too high .That is why , . which better deals with long - distance dependencies , ellipses and other . complex phenomena .He points out the need for a deep parsing , instead .of the shallow one , his reason being , besides the lower ambiguity , the . practical orientation of the former .", "label": "", "metadata": {}, "score": "53.03363"}
{"text": "A method and apparatus for adaptive speech recognition hypothesis are provided , wherein a number of ordered recognition hypotheses are generated and presented in response to a received speech input comprising natural spoken language .Method and apparatus for adaptive speech recognition hypothesis construction and selection in a spoken language translation system US 6278968 B1 .", "label": "", "metadata": {}, "score": "53.044548"}
{"text": "lexical / structural context useful for further parsing ) ; the use of . subtrees with non - headwords have a good impact on the performance of .the model ( as they contain syntactic relations for those .non - headwords , which can not be found in other subtrees ) .", "label": "", "metadata": {}, "score": "53.144432"}
{"text": "Another previous GLR parser accepts arbitrary context - free grammar rules and semantic actions .The problem with this parser is that its two - stage design is impractical for large - scale natural language parsing because most actions must be duplicated in the second instruction set .", "label": "", "metadata": {}, "score": "53.146072"}
{"text": "Another previous GLR parser accepts arbitrary context - free grammar rules and semantic actions .The problem with this parser is that its two - stage design is impractical for large - scale natural language parsing because most actions must be duplicated in the second instruction set .", "label": "", "metadata": {}, "score": "53.146072"}
{"text": "Another previous GLR parser accepts arbitrary context - free grammar rules and semantic actions .The problem with this parser is that its two - stage design is impractical for large - scale natural language parsing because most actions must be duplicated in the second instruction set .", "label": "", "metadata": {}, "score": "53.146072"}
{"text": "Another previous GLR parser accepts arbitrary context - free grammar rules and semantic actions .The problem with this parser is that its two - stage design is impractical for large - scale natural language parsing because most actions must be duplicated in the second instruction set .", "label": "", "metadata": {}, "score": "53.146072"}
{"text": "Another previous GLR parser accepts arbitrary context - free grammar rules and semantic actions .The problem with this parser is that its two - stage design is impractical for large - scale natural language parsing because most actions must be duplicated in the second instruction set .", "label": "", "metadata": {}, "score": "53.146072"}
{"text": "manipulating the adapted feature structure analysis representation using at least one natural language parser .The method of claim 1 , wherein a separation is provided between domain - independent linguistic knowledge and domain - dependent linguistic knowledge .The method of claim 1 , further comprising performing statistical processing to resolve lexical ambiguities and local ambiguities .", "label": "", "metadata": {}, "score": "53.21136"}
{"text": "In a portable unit , a method for performing spoken language translation .The method includes the steps of receiving at least one speech input comprising at least one source language , and recognizing at least one source expression of the at least one source language .", "label": "", "metadata": {}, "score": "53.231052"}
{"text": "The analyzer 2104 of an embodiment takes the output 2154 from the tokenizer 2102 , a sequence of tokens , and analyzes each word by consulting the dictionary 2158 and a set of analysis rules 2156 .The dictionaries 2158 comprise lexicons in the format of feature structures .", "label": "", "metadata": {}, "score": "53.258743"}
{"text": "The computer readable medium of claim 25 , wherein the step of translating comprises : . performing morphological analysis of the recognized at least one source expression using at least one source language dictionary and at least one source language morphological rule ; . generating at least one sequence of analyzed morphemes ; . performing syntactic source language analysis using grammar rule - based processing and example - based processing ; . generating at least one source language syntactic representation ; and .", "label": "", "metadata": {}, "score": "53.29431"}
{"text": "The first objective was not .always easy to achieve via structural differences , that is why a set . of easily identifiable roles were defined , although sometimes these .ones proved difficult to apply , too .The Penn Treebank ( PTB ) project . also produced dysfluency annotation of transcribed conversations , . labeling complete and incomplete utterances , non - sentence elements .", "label": "", "metadata": {}, "score": "53.333405"}
{"text": "A computer readable medium containing executable instructions which , when executed in a processing system , causes the system to perform a method for spoken language translation , the method comprising : . receiving ( 302 ) at least one speech input ; . generating ( 402 ) a plurality of recognition hypotheses in response to the at least one speech input taking into consideration a potential variability in the at least one speech input ; .", "label": "", "metadata": {}, "score": "53.369617"}
{"text": "We evaluate it in experiments that explore two of many practical applications of the technique and conclude that the case - based method provides a promising approach to automated dictionary construction and knowledge acquisition for sentence analysis in limited domains .In addition , we present a novel case retrieval algorithm that uses decision trees to improve the performance of a k - nearest neighbor similarity metric . .", "label": "", "metadata": {}, "score": "53.468998"}
{"text": "We evaluate it in experiments that explore two of many practical applications of the technique and conclude that the case - based method provides a promising approach to automated dictionary construction and knowledge acquisition for sentence analysis in limited domains .In addition , we present a novel case retrieval algorithm that uses decision trees to improve the performance of a k - nearest neighbor similarity metric . .", "label": "", "metadata": {}, "score": "53.468998"}
{"text": "analyzed new input by combining fragments of representations from . annotated corpus ' ' .So , the idea is to use an already annotated corpus . as a stochastic grammar .The idea is not new , but the aim of the .", "label": "", "metadata": {}, "score": "53.50317"}
{"text": "A new parse node is generated , at step 2610 .A feature structure or lexical feature structure of the shifted input item is obtained from the morphological analyzer and associated with the new parse node , at step 2612 .At step 2614 , the new node is placed on the stack or intermediate data structure , and operation continues at step 2604 , at which the parsing table is consulted for a next action .", "label": "", "metadata": {}, "score": "53.70784"}
{"text": "A new parse node is generated , at step 2610 .A feature structure or lexical feature structure of the shifted input item is obtained from the morphological analyzer and associated with the new parse node , at step 2612 .At step 2614 , the new node is placed on the stack or intermediate data structure , and operation continues at step 2604 , at which the parsing table is consulted for a next action .", "label": "", "metadata": {}, "score": "53.70784"}
{"text": "A new parse node is generated , at step 2610 .A feature structure or lexical feature structure of the shifted input item is obtained from the morphological analyzer and associated with the new parse node , at step 2612 .At step 2614 , the new node is placed on the stack or intermediate data structure , and operation continues at step 2604 , at which the parsing table is consulted for a next action .", "label": "", "metadata": {}, "score": "53.70784"}
{"text": "A new parse node is generated , at step 2610 .A feature structure or lexical feature structure of the shifted input item is obtained from the morphological analyzer and associated with the new parse node , at step 2612 .At step 2614 , the new node is placed on the stack or intermediate data structure , and operation continues at step 2604 , at which the parsing table is consulted for a next action .", "label": "", "metadata": {}, "score": "53.70784"}
{"text": "A new parse node is generated , at step 2610 .A feature structure or lexical feature structure of the shifted input item is obtained from the morphological analyzer and associated with the new parse node , at step 2612 .At step 2614 , the new node is placed on the stack or intermediate data structure , and operation continues at step 2604 , at which the parsing table is consulted for a next action .", "label": "", "metadata": {}, "score": "53.70784"}
{"text": "The hybrid rule - based / analogical approach of the present invention comprises methods for example combination , fast match , and best match .FIG .11 is a matching and transfer algorithm of a translation component of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "53.891396"}
{"text": "The hybrid rule - based / analogical approach of the present invention comprises methods for example combination , fast match , and best match .FIG .11 is a matching and transfer algorithm of a translation component of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "53.891396"}
{"text": "The hybrid rule - based / analogical approach of the present invention comprises methods for example combination , fast match , and best match .FIG .11 is a matching and transfer algorithm of a translation component of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "53.891396"}
{"text": "The hybrid rule - based / analogical approach of the present invention comprises methods for example combination , fast match , and best match .FIG .11 is a matching and transfer algorithm of a translation component of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "53.891396"}
{"text": "The hybrid rule - based / analogical approach of the present invention comprises methods for example combination , fast match , and best match .FIG .11 is a matching and transfer algorithm of a translation component of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "53.891396"}
{"text": "This process examines the local context , or the current character and its immediate neighbors , and uses a small set of tokenization rules 2152 .In an embodiment , the tokenizer makes a break at the following places with the corresponding effect , but is not so limited : . space character ( space , return , tab , End - of - Sentence ( EOS ) ) ; .", "label": "", "metadata": {}, "score": "53.964752"}
{"text": "This process examines the local context , or the current character and its immediate neighbors , and uses a small set of tokenization rules 2152 .In an embodiment , the tokenizer makes a break at the following places with the corresponding effect , but is not so limited : . space character ( space , return , tab , End - of - Sentence ( EOS ) ) ; .", "label": "", "metadata": {}, "score": "53.964752"}
{"text": "This process examines the local context , or the current character and its immediate neighbors , and uses a small set of tokenization rules 2152 .In an embodiment , the tokenizer makes a break at the following places with the corresponding effect , but is not so limited : . space character ( space , return , tab , End - of - Sentence ( EOS ) ) ; .", "label": "", "metadata": {}, "score": "53.964752"}
{"text": "The main features of the Enju parser are : .Accurate deep analysis - the parser can output both phrase structures and predicate - argument structures .The accuracy of predicate - argument relations is around 90 % for newswire articles and biomedical papers .", "label": "", "metadata": {}, "score": "54.046925"}
{"text": "The main features of the Enju parser are : .Accurate deep analysis - the parser can output both phrase structures and predicate - argument structures .The accuracy of predicate - argument relations is around 90 % for newswire articles and biomedical papers .", "label": "", "metadata": {}, "score": "54.046925"}
{"text": "The system of claim 43 , wherein the means for performing syntactic analysis further comprises : . a means for recognizing linguistic constituents selected from a group comprising noun phrases , verb phrases , and prepositional phrases ; . a means for ordering the linguistic constituents ; . a means for representing the linguistic constituents using an adapted feature structure analysis representation ; and .", "label": "", "metadata": {}, "score": "54.04878"}
{"text": "The method of claim 1 , wherein the at least one input comprises spoken language .An apparatus for spoken language translation comprising : . at least one processor ; . an input coupled to the at least one processor , the input capable of receiving speech signals , the at least one processor configured to identify constituents of the received speech signals by , . performing syntactic analysis on at least one entry from at least one example database using the at least one parse tree ; . determining at least one linguistic constituent of the at least one input ; . determining a pragmatic type and a syntactic type of the at least one linguistic constituent ; . retaining an order of the at least one linguistic constituent in the at least one input ; and .", "label": "", "metadata": {}, "score": "54.11448"}
{"text": "layers of syntactic annotation , the constituency and the functional .ones , grounded by language specific phenomena ( such as free .constituent order and pro - drop property ) and by further usages of the . obtained treebank which is compatible with different approaches to . syntax .", "label": "", "metadata": {}, "score": "54.1158"}
{"text": "The previous alternatives include not performing morphological analysis , and using two - level morphological analysis . \" walking \" . . .all have to be listed ) .The problem with this approach is that the system is required to have a large amount of memory to accommodate the dictionary and , because of the access time required , the language processing is inefficient .", "label": "", "metadata": {}, "score": "54.123695"}
{"text": "If the parser is unable to analyze the input , the next action is a fail action and operation continues at step 2606 , at which the analysis stops .During parsing operations , the parser may perform shift actions and reduce actions , but is not so limited .", "label": "", "metadata": {}, "score": "54.26625"}
{"text": "If the parser is unable to analyze the input , the next action is a fail action and operation continues at step 2606 , at which the analysis stops .During parsing operations , the parser may perform shift actions and reduce actions , but is not so limited .", "label": "", "metadata": {}, "score": "54.26625"}
{"text": "If the parser is unable to analyze the input , the next action is a fail action and operation continues at step 2606 , at which the analysis stops .During parsing operations , the parser may perform shift actions and reduce actions , but is not so limited .", "label": "", "metadata": {}, "score": "54.26625"}
{"text": "If the parser is unable to analyze the input , the next action is a fail action and operation continues at step 2606 , at which the analysis stops .During parsing operations , the parser may perform shift actions and reduce actions , but is not so limited .", "label": "", "metadata": {}, "score": "54.26625"}
{"text": "If the parser is unable to analyze the input , the next action is a fail action and operation continues at step 2606 , at which the analysis stops .During parsing operations , the parser may perform shift actions and reduce actions , but is not so limited .", "label": "", "metadata": {}, "score": "54.26625"}
{"text": "First , dependency analysis is not detailed enough to account for many natural language expressions as the matching is essentially performed on the words in the input .Second , this approach is limited to using examples that all have the same degree of linguistic specificity .", "label": "", "metadata": {}, "score": "54.283752"}
{"text": "First , dependency analysis is not detailed enough to account for many natural language expressions as the matching is essentially performed on the words in the input .Second , this approach is limited to using examples that all have the same degree of linguistic specificity .", "label": "", "metadata": {}, "score": "54.283752"}
{"text": "First , dependency analysis is not detailed enough to account for many natural language expressions as the matching is essentially performed on the words in the input .Second , this approach is limited to using examples that all have the same degree of linguistic specificity .", "label": "", "metadata": {}, "score": "54.283752"}
{"text": "First , dependency analysis is not detailed enough to account for many natural language expressions as the matching is essentially performed on the words in the input .Second , this approach is limited to using examples that all have the same degree of linguistic specificity .", "label": "", "metadata": {}, "score": "54.283752"}
{"text": "First , dependency analysis is not detailed enough to account for many natural language expressions as the matching is essentially performed on the words in the input .Second , this approach is limited to using examples that all have the same degree of linguistic specificity .", "label": "", "metadata": {}, "score": "54.283752"}
{"text": "The shift action shifts onto a stack or intermediate data structure of the parser the next item of the input string .The stack or intermediate data structure of an embodiment comprises at least one graph - structured stack that is maintained .", "label": "", "metadata": {}, "score": "54.313004"}
{"text": "The shift action shifts onto a stack or intermediate data structure of the parser the next item of the input string .The stack or intermediate data structure of an embodiment comprises at least one graph - structured stack that is maintained .", "label": "", "metadata": {}, "score": "54.313004"}
{"text": "The shift action shifts onto a stack or intermediate data structure of the parser the next item of the input string .The stack or intermediate data structure of an embodiment comprises at least one graph - structured stack that is maintained .", "label": "", "metadata": {}, "score": "54.313004"}
{"text": "The shift action shifts onto a stack or intermediate data structure of the parser the next item of the input string .The stack or intermediate data structure of an embodiment comprises at least one graph - structured stack that is maintained .", "label": "", "metadata": {}, "score": "54.313004"}
{"text": "The shift action shifts onto a stack or intermediate data structure of the parser the next item of the input string .The stack or intermediate data structure of an embodiment comprises at least one graph - structured stack that is maintained .", "label": "", "metadata": {}, "score": "54.313004"}
{"text": "Moreover , the syntactic analysis does not try to identify grammatical functions ( direct object , indirect object ) or thematic roles ( agent , experiencer ) of each constituents .In an embodiment of the present invention , the format of the analysis representation is that of an adapted feature structure representation .", "label": "", "metadata": {}, "score": "54.38108"}
{"text": "Moreover , the syntactic analysis does not try to identify grammatical functions ( direct object , indirect object ) or thematic roles ( agent , experiencer ) of each constituents .In an embodiment of the present invention , the format of the analysis representation is that of an adapted feature structure representation .", "label": "", "metadata": {}, "score": "54.38108"}
{"text": "Moreover , the syntactic analysis does not try to identify grammatical functions ( direct object , indirect object ) or thematic roles ( agent , experiencer ) of each constituents .In an embodiment of the present invention , the format of the analysis representation is that of an adapted feature structure representation .", "label": "", "metadata": {}, "score": "54.38108"}
{"text": "Moreover , the syntactic analysis does not try to identify grammatical functions ( direct object , indirect object ) or thematic roles ( agent , experiencer ) of each constituents .In an embodiment of the present invention , the format of the analysis representation is that of an adapted feature structure representation .", "label": "", "metadata": {}, "score": "54.38108"}
{"text": "Moreover , the syntactic analysis does not try to identify grammatical functions ( direct object , indirect object ) or thematic roles ( agent , experiencer ) of each constituents .In an embodiment of the present invention , the format of the analysis representation is that of an adapted feature structure representation .", "label": "", "metadata": {}, "score": "54.38108"}
{"text": "For all these 3 annotation schemes a 2-step methodology was adopted : . an automatic step ( represented by PARTS and Brill taggers for POS . tagging , the Fidditch deterministic parser for syntactic bracketing , . and a mere Perl script identifying common non - sentential elements ) .", "label": "", "metadata": {}, "score": "54.38951"}
{"text": "Spoken language is characterized by a number of properties that defy analysis by traditional rule - based methods .Although spoken utterances typically consist of shorter , less complex syntactic structures , they often contain fragments and extra items , such as interjections and filled pauses .", "label": "", "metadata": {}, "score": "54.41668"}
{"text": "Spoken language is characterized by a number of properties that defy analysis by traditional rule - based methods .Although spoken utterances typically consist of shorter , less complex syntactic structures , they often contain fragments and extra items , such as interjections and filled pauses .", "label": "", "metadata": {}, "score": "54.41668"}
{"text": "Spoken language is characterized by a number of properties that defy analysis by traditional rule - based methods .Although spoken utterances typically consist of shorter , less complex syntactic structures , they often contain fragments and extra items , such as interjections and filled pauses .", "label": "", "metadata": {}, "score": "54.41668"}
{"text": "Spoken language is characterized by a number of properties that defy analysis by traditional rule - based methods .Although spoken utterances typically consist of shorter , less complex syntactic structures , they often contain fragments and extra items , such as interjections and filled pauses .", "label": "", "metadata": {}, "score": "54.41668"}
{"text": "Spoken language is characterized by a number of properties that defy analysis by traditional rule - based methods .Although spoken utterances typically consist of shorter , less complex syntactic structures , they often contain fragments and extra items , such as interjections and filled pauses .", "label": "", "metadata": {}, "score": "54.41668"}
{"text": "Fast and Scalable HPSG Parsing .Traitement automatique des langues ( TAL ) .Association pour le Traitement Automatique des Langues .A method and apparatus for parsing in a spoken language translation system are provided , wherein an input is received comprising at least one input sentence or expression .", "label": "", "metadata": {}, "score": "54.53962"}
{"text": "The AIM of an embodiment of the present invention provides computational efficiency , ease of maintenance of dictionaries , accurate performance for the intended application , and ease of integration with other tools and components .The AIM of an embodiment identifies the word root and reduces the remaining morphemes of the input word to features .", "label": "", "metadata": {}, "score": "54.674965"}
{"text": "The AIM of an embodiment of the present invention provides computational efficiency , ease of maintenance of dictionaries , accurate performance for the intended application , and ease of integration with other tools and components .The AIM of an embodiment identifies the word root and reduces the remaining morphemes of the input word to features .", "label": "", "metadata": {}, "score": "54.674965"}
{"text": "The AIM of an embodiment of the present invention provides computational efficiency , ease of maintenance of dictionaries , accurate performance for the intended application , and ease of integration with other tools and components .The AIM of an embodiment identifies the word root and reduces the remaining morphemes of the input word to features .", "label": "", "metadata": {}, "score": "54.674965"}
{"text": "The AIM of an embodiment of the present invention provides computational efficiency , ease of maintenance of dictionaries , accurate performance for the intended application , and ease of integration with other tools and components .The AIM of an embodiment identifies the word root and reduces the remaining morphemes of the input word to features .", "label": "", "metadata": {}, "score": "54.674965"}
{"text": "The AIM of an embodiment of the present invention provides computational efficiency , ease of maintenance of dictionaries , accurate performance for the intended application , and ease of integration with other tools and components .The AIM of an embodiment identifies the word root and reduces the remaining morphemes of the input word to features .", "label": "", "metadata": {}, "score": "54.674965"}
{"text": "The computer readable medium of claim 29 , wherein the at least one input comprises spoken language .A spoken language translation system , comprising : . a means for receiving at least one input ; . a means for performing syntactic analysis on at least one entry from at least one example database using the at least one parse tree ; . a means for determining at least one linguistic constituent of the at least one input ; . a means for determining a pragmatic type and a syntactic type of the at least one linguistic constituent ; . a means for retaining an order of the at least one linguistic constituent in the at least one input ; and .", "label": "", "metadata": {}, "score": "54.768448"}
{"text": "density , accessibility , electronic availability ) .Their annotation was .3-phased : developing of a typology of grammatical errors in the target . language ( German ) , manual annotation on paper , and annotation by means . of computer tools .", "label": "", "metadata": {}, "score": "54.778114"}
{"text": "generating a feature structure for the at least one parse node by coping a feature structure of the lexicon .The computer readable medium of claim 25 , wherein the at least one input expression comprises a grammatical sentence , wherein the grammatical sentence comprises at least one spoken word , wherein at least one feature structure is available for each lexicon of the at least one spoken word .", "label": "", "metadata": {}, "score": "54.785942"}
{"text": "this paper we outline a research program for computational linguistics , making extensive use of text corpora .We demonstrate how a semantic framework for lexical knowledge can suggest richer relationships among words in text beyond that of simple co - occurrence .", "label": "", "metadata": {}, "score": "54.83552"}
{"text": "this paper we outline a research program for computational linguistics , making extensive use of text corpora .We demonstrate how a semantic framework for lexical knowledge can suggest richer relationships among words in text beyond that of simple co - occurrence .", "label": "", "metadata": {}, "score": "54.83552"}
{"text": "Consequently , unlike a translation system that uses a complete table of input and output words to formulate the translation , the STS of an embodiment of the present invention creates the translation dynamically .Furthermore , the STS processes natural spoken language , meaning that the STS handles ungrammatical speech as often produced by individuals .", "label": "", "metadata": {}, "score": "54.841385"}
{"text": "Consequently , unlike a translation system that uses a complete table of input and output words to formulate the translation , the STS of an embodiment of the present invention creates the translation dynamically .Furthermore , the STS processes natural spoken language , meaning that the STS handles ungrammatical speech as often produced by individuals .", "label": "", "metadata": {}, "score": "54.841385"}
{"text": "Consequently , unlike a translation system that uses a complete table of input and output words to formulate the translation , the STS of an embodiment of the present invention creates the translation dynamically .Furthermore , the STS processes natural spoken language , meaning that the STS handles ungrammatical speech as often produced by individuals .", "label": "", "metadata": {}, "score": "54.841385"}
{"text": "Consequently , unlike a translation system that uses a complete table of input and output words to formulate the translation , the STS of an embodiment of the present invention creates the translation dynamically .Furthermore , the STS processes natural spoken language , meaning that the STS handles ungrammatical speech as often produced by individuals .", "label": "", "metadata": {}, "score": "54.841385"}
{"text": "Consequently , unlike a translation system that uses a complete table of input and output words to formulate the translation , the STS of an embodiment of the present invention creates the translation dynamically .Furthermore , the STS processes natural spoken language , meaning that the STS handles ungrammatical speech as often produced by individuals .", "label": "", "metadata": {}, "score": "54.841385"}
{"text": "When the speech input is garbled or ungrammatical , identification of the exact utterance may not be possible .Prior systems that operate by attempting to identify exact utterances may produce no output or an incorrect output when it is not possible to perform an identification .", "label": "", "metadata": {}, "score": "54.858627"}
{"text": "When the speech input is garbled or ungrammatical , identification of the exact utterance may not be possible .Prior systems that operate by attempting to identify exact utterances may produce no output or an incorrect output when it is not possible to perform an identification .", "label": "", "metadata": {}, "score": "54.858627"}
{"text": "When the speech input is garbled or ungrammatical , identification of the exact utterance may not be possible .Prior systems that operate by attempting to identify exact utterances may produce no output or an incorrect output when it is not possible to perform an identification .", "label": "", "metadata": {}, "score": "54.858627"}
{"text": "When the speech input is garbled or ungrammatical , identification of the exact utterance may not be possible .Prior systems that operate by attempting to identify exact utterances may produce no output or an incorrect output when it is not possible to perform an identification .", "label": "", "metadata": {}, "score": "54.858627"}
{"text": "When the speech input is garbled or ungrammatical , identification of the exact utterance may not be possible .Prior systems that operate by attempting to identify exact utterances may produce no output or an incorrect output when it is not possible to perform an identification .", "label": "", "metadata": {}, "score": "54.858627"}
{"text": "The method further includes receiving an indication of a choice of one of the alternatives from the user , and presenting a revised version of the best hypothesis including the alternative chosen to the user .In a language translation system , a method for providing a guide for a user , comprising : . receiving an input that is representative of at least one word in a source language ; . generating at least one recognition hypothesis in the source language in response to the input ; . determining a best hypothesis from the at least one recognition hypothesis in the source language ; . presenting the best hypothesis in the source language to a user ; . presenting alternatives to a portion of the best hypothesis in the source language to the user ; . receiving an indication of a choice of one of the alternatives from the user ; and .", "label": "", "metadata": {}, "score": "54.967575"}
{"text": "a source language representation of a back - translation of the target language representation of the group of words .The method of claim 24 , further comprising receiving an indication from the user that the revised best hypothesis is acceptable .", "label": "", "metadata": {}, "score": "55.017357"}
{"text": "The completeness of the output list increases monotonically with the total number of occurrences of each verb in the corpus .Fakse positive rates are one to three percent of observations . \" ... m we can carve o # next . '", "label": "", "metadata": {}, "score": "55.01824"}
{"text": "The completeness of the output list increases monotonically with the total number of occurrences of each verb in the corpus .Fakse positive rates are one to three percent of observations . \" ... m we can carve o # next . '", "label": "", "metadata": {}, "score": "55.01824"}
{"text": "Abstract .In a portable unit , a method for performing spoken language translation .The method includes the steps of receiving at least one speech input comprising at least one source language , and recognizing at least one source expression of the at least one source language .", "label": "", "metadata": {}, "score": "55.070084"}
{"text": "Pragmatic knowledge concerns how sentences are used in different situations and how use affects the interpretation of the sentence .The typical natural language processor , however , has realized only limited success because these processors operate only within a narrow framework .", "label": "", "metadata": {}, "score": "55.098442"}
{"text": "Pragmatic knowledge concerns how sentences are used in different situations and how use affects the interpretation of the sentence .The typical natural language processor , however , has realized only limited success because these processors operate only within a narrow framework .", "label": "", "metadata": {}, "score": "55.098442"}
{"text": "Pragmatic knowledge concerns how sentences are used in different situations and how use affects the interpretation of the sentence .The typical natural language processor , however , has realized only limited success because these processors operate only within a narrow framework .", "label": "", "metadata": {}, "score": "55.098442"}
{"text": "Pragmatic knowledge concerns how sentences are used in different situations and how use affects the interpretation of the sentence .The typical natural language processor , however , has realized only limited success because these processors operate only within a narrow framework .", "label": "", "metadata": {}, "score": "55.098442"}
{"text": "Pragmatic knowledge concerns how sentences are used in different situations and how use affects the interpretation of the sentence .The typical natural language processor , however , has realized only limited success because these processors operate only within a narrow framework .", "label": "", "metadata": {}, "score": "55.098442"}
{"text": "with verbs ) and a manual one .Chapter 8 .An HPSG - Annotated Test Suite for Polish .The aim of the paper is to present the construction of a test - suite .for Polish , consisting of written sentences , both correct and . incorrect ones , the latter being manually annotated with correctness . markers .", "label": "", "metadata": {}, "score": "55.09856"}
{"text": "Bod , R. ( 1992 )Data Oriented Parsing ( DOP ) , Proceedings COLING ' 92 , .Nantes , France .Bod , R. ( 1995 ) Enriching Linguistics with Statistics : Performance .Models of Natural Language , ILLC Dissertation Series 1995 - 14 , .", "label": "", "metadata": {}, "score": "55.254486"}
{"text": "Regarding the handling of inflectional morphology , an embodiment of the present invention comprises a reduced number of dictionary entries and a reduction in the number of entries in the translation knowledge base .The AIM of an embodiment of the present invention is easy to maintain since the direct correspondence between the transfer knowledge base and the dictionary is preserved .", "label": "", "metadata": {}, "score": "55.408928"}
{"text": "Regarding the handling of inflectional morphology , an embodiment of the present invention comprises a reduced number of dictionary entries and a reduction in the number of entries in the translation knowledge base .The AIM of an embodiment of the present invention is easy to maintain since the direct correspondence between the transfer knowledge base and the dictionary is preserved .", "label": "", "metadata": {}, "score": "55.408928"}
{"text": "Regarding the handling of inflectional morphology , an embodiment of the present invention comprises a reduced number of dictionary entries and a reduction in the number of entries in the translation knowledge base .The AIM of an embodiment of the present invention is easy to maintain since the direct correspondence between the transfer knowledge base and the dictionary is preserved .", "label": "", "metadata": {}, "score": "55.408928"}
{"text": "Regarding the handling of inflectional morphology , an embodiment of the present invention comprises a reduced number of dictionary entries and a reduction in the number of entries in the translation knowledge base .The AIM of an embodiment of the present invention is easy to maintain since the direct correspondence between the transfer knowledge base and the dictionary is preserved .", "label": "", "metadata": {}, "score": "55.408928"}
{"text": "followed by manual validation .The resulting treebank was used for .evaluating lemmatizers and for training taggers .Chapter 11 .Building the Italian Syntactic - Semantic Treebank .Simonetta Montemagni , Francesco Barsotti , Marco Battista , Nicoletta .Calzolari , Ornella Corazzari , Alessandro Lenci , Antonio Zampolli , .", "label": "", "metadata": {}, "score": "55.517258"}
{"text": "The path from the .lexical anchor to the root of the tree is called a head - chain .There . are two more additional operations involved : each subtree of the head- .chain is copied and the copied tree is processed individually by the . decomposition operation , thus allowing a phrase to occur both in head .", "label": "", "metadata": {}, "score": "55.736923"}
{"text": "tools : Annotate and DiET .The annotation with the former one has a . tree - format : the nodes are the error types , and the edges are .descriptive information on these types ; thus , a rich representation of .", "label": "", "metadata": {}, "score": "55.86583"}
{"text": "The method of claim 1 , wherein performing syntactic analysis further comprises generalizing at least one surface variation in the at least one input and the at least one example database , wherein efficiency of the spoken language translation is increased .", "label": "", "metadata": {}, "score": "55.89522"}
{"text": "The grammar rules of an embodiment comprise English parsing grammar rules and Japanese parsing grammar rules , and the grammar rules may comprise context - free grammar rules , but are not so limited .The parsing table generator takes the grammar rules and creates a data structure that encodes the operations of the parser .", "label": "", "metadata": {}, "score": "55.903656"}
{"text": "The grammar rules of an embodiment comprise English parsing grammar rules and Japanese parsing grammar rules , and the grammar rules may comprise context - free grammar rules , but are not so limited .The parsing table generator takes the grammar rules and creates a data structure that encodes the operations of the parser .", "label": "", "metadata": {}, "score": "55.903656"}
{"text": "The grammar rules of an embodiment comprise English parsing grammar rules and Japanese parsing grammar rules , and the grammar rules may comprise context - free grammar rules , but are not so limited .The parsing table generator takes the grammar rules and creates a data structure that encodes the operations of the parser .", "label": "", "metadata": {}, "score": "55.903656"}
{"text": "The grammar rules of an embodiment comprise English parsing grammar rules and Japanese parsing grammar rules , and the grammar rules may comprise context - free grammar rules , but are not so limited .The parsing table generator takes the grammar rules and creates a data structure that encodes the operations of the parser .", "label": "", "metadata": {}, "score": "55.903656"}
{"text": "The grammar rules of an embodiment comprise English parsing grammar rules and Japanese parsing grammar rules , and the grammar rules may comprise context - free grammar rules , but are not so limited .The parsing table generator takes the grammar rules and creates a data structure that encodes the operations of the parser .", "label": "", "metadata": {}, "score": "55.903656"}
{"text": "This information is called a language model because it is a mathematical model that is used to assign probabilities to utterances .These utterance probabilities are derived from probabilities of parts of the utterance , of certain segments , or of other derived features or characteristics .", "label": "", "metadata": {}, "score": "55.930866"}
{"text": "This information is called a language model because it is a mathematical model that is used to assign probabilities to utterances .These utterance probabilities are derived from probabilities of parts of the utterance , of certain segments , or of other derived features or characteristics .", "label": "", "metadata": {}, "score": "55.930866"}
{"text": "This information is called a language model because it is a mathematical model that is used to assign probabilities to utterances .These utterance probabilities are derived from probabilities of parts of the utterance , of certain segments , or of other derived features or characteristics .", "label": "", "metadata": {}, "score": "55.930866"}
{"text": "This information is called a language model because it is a mathematical model that is used to assign probabilities to utterances .These utterance probabilities are derived from probabilities of parts of the utterance , of certain segments , or of other derived features or characteristics .", "label": "", "metadata": {}, "score": "55.930866"}
{"text": "This information is called a language model because it is a mathematical model that is used to assign probabilities to utterances .These utterance probabilities are derived from probabilities of parts of the utterance , of certain segments , or of other derived features or characteristics .", "label": "", "metadata": {}, "score": "55.930866"}
{"text": "The . scheme makes use of a grammatical relation hierarchy , containing types . of syntactic dependencies between heads and dependents .Based on .EAGLES lexicon / syntax standards ( Barnett et al .1996 ) , this hierarchy .aims at being language- and application- independent .", "label": "", "metadata": {}, "score": "55.999603"}
{"text": "The method of claim 9 , further comprising : . generating at least one target language syntactic representation ; . performing target language syntactic generation using at least one set of target language syntactic generation rules ; . generating at least one sequence of target language morpheme specifications ; and .", "label": "", "metadata": {}, "score": "56.141"}
{"text": "Human annotators need to concentrate only on the .problematic cases , which are assigned different probabilities by . statistical tagger and parser .Accuracy is ensured by annotating the . same set of sentences by two different annotators .Differences are . discussed and after agreeing on them , modifications are applied to the . annotation .", "label": "", "metadata": {}, "score": "56.33011"}
{"text": "FIG .14 is an illustration of a display of another embodiment which may be particularly useful to a user who has some knowledge of the target language .The alternate hypotheses of an input in the source language are translated .", "label": "", "metadata": {}, "score": "56.483185"}
{"text": "FIG .14 is an illustration of a display of another embodiment which may be particularly useful to a user who has some knowledge of the target language .The alternate hypotheses of an input in the source language are translated .", "label": "", "metadata": {}, "score": "56.483185"}
{"text": "FIG .14 is an illustration of a display of another embodiment which may be particularly useful to a user who has some knowledge of the target language .The alternate hypotheses of an input in the source language are translated .", "label": "", "metadata": {}, "score": "56.483185"}
{"text": "FIG .14 is an illustration of a display of another embodiment which may be particularly useful to a user who has some knowledge of the target language .The alternate hypotheses of an input in the source language are translated .", "label": "", "metadata": {}, "score": "56.483185"}
{"text": "FIG .14 is an illustration of a display of another embodiment which may be particularly useful to a user who has some knowledge of the target language .The alternate hypotheses of an input in the source language are translated .", "label": "", "metadata": {}, "score": "56.483185"}
{"text": "A computer readable medium containing executable instructions which , when executed in a processing system , cause the system to perform a method for performing language translation , the method comprising : . receiving an input that is representative of at least one word in a source language ; . generating at least one recognition hypothesis in the source language in response to the input ; . selecting a best hypothesis from the at least one recognition hypothesis in the source language ; . presenting the best hypothesis in the source language to a user ; . presenting alternatives to a portion of the best hypothesis in the source language to the user ; . receiving an indication of a choice of one of the alternatives from the user ; and .", "label": "", "metadata": {}, "score": "56.555126"}
{"text": "In some embodiments of the present invention that include a self - contained portable unit , the source language recognition and translation capabilities of the unit may be remotely extended .For example , various communication methods may be used to retrieve additional words and/or phrases and their translations from remotely located hardware and software to be stored in the unit .", "label": "", "metadata": {}, "score": "56.594833"}
{"text": "generating a feature structure for the at least one parse node by coping a feature structure of the lexicon .The apparatus of claim 13 , wherein the at least one input expression comprises a grammatical sentence , wherein the grammatical sentence comprises at least one spoken word , wherein at least one feature structure is available for each lexicon of the at least one spoken word .", "label": "", "metadata": {}, "score": "56.84399"}
{"text": "Contents .Overview .Enju is a syntactic parser for English .With a wide - coverage probabilistic HPSG grammar [ 1 - 7 ] and an efficient parsing algorithm [ 8 - 11 ] , this parser can effectively analyze syntactic / semantic structures of English sentences and provide a user with phrase structures and predicate - argument structures .", "label": "", "metadata": {}, "score": "56.85637"}
{"text": "A Uniform Method for Automatically Extracting Stochastic .Lexicalized Tree Grammars from Treebanks and HPSG .As the title states it , the paper presents a uniform method for .automatically extraction of stochastic lexicalized tree grammars .( SLTG ) from treebanks ( allowing corpus - based analysis of grammars ) and .", "label": "", "metadata": {}, "score": "56.908993"}
{"text": "The dictionary format of an AIM of an embodiment of the present invention provides three different types of entries wherein a minimum to a large amount of information may be encoded .Each entry of a dictionary is a lexical feature structure , wherein the data structure of a dictionary is an array with elements comprising a key and a lexical feature structure .", "label": "", "metadata": {}, "score": "56.915844"}
{"text": "The dictionary format of an AIM of an embodiment of the present invention provides three different types of entries wherein a minimum to a large amount of information may be encoded .Each entry of a dictionary is a lexical feature structure , wherein the data structure of a dictionary is an array with elements comprising a key and a lexical feature structure .", "label": "", "metadata": {}, "score": "56.915844"}
{"text": "The dictionary format of an AIM of an embodiment of the present invention provides three different types of entries wherein a minimum to a large amount of information may be encoded .Each entry of a dictionary is a lexical feature structure , wherein the data structure of a dictionary is an array with elements comprising a key and a lexical feature structure .", "label": "", "metadata": {}, "score": "56.915844"}
{"text": "The dictionary format of an AIM of an embodiment of the present invention provides three different types of entries wherein a minimum to a large amount of information may be encoded .Each entry of a dictionary is a lexical feature structure , wherein the data structure of a dictionary is an array with elements comprising a key and a lexical feature structure .", "label": "", "metadata": {}, "score": "56.915844"}
{"text": "However , it was modified so .that to take advantage of phrase - structure grammar , too : flat . structures , no empty categories , treatment of the head as a .grammatical function expressed by labeling , not by the syntactic . structure , allowance of crossing branches ( which give rise to a large . number of errors ) , a more explicit annotation of grammatical .", "label": "", "metadata": {}, "score": "56.958847"}
{"text": "If a parse node is a packed node , which means that a local ambiguity packing happened , then a disjunctive feature structure is used to represent the packed ambiguities .In a typical GLR parser , in which the root node is a packed node and the feature structure of the root node 2554 is the final output of the parsing , local ambiguity packing is used to save storage for parse trees .", "label": "", "metadata": {}, "score": "57.14981"}
{"text": "If a parse node is a packed node , which means that a local ambiguity packing happened , then a disjunctive feature structure is used to represent the packed ambiguities .In a typical GLR parser , in which the root node is a packed node and the feature structure of the root node 2554 is the final output of the parsing , local ambiguity packing is used to save storage for parse trees .", "label": "", "metadata": {}, "score": "57.14981"}
{"text": "If a parse node is a packed node , which means that a local ambiguity packing happened , then a disjunctive feature structure is used to represent the packed ambiguities .In a typical GLR parser , in which the root node is a packed node and the feature structure of the root node 2554 is the final output of the parsing , local ambiguity packing is used to save storage for parse trees .", "label": "", "metadata": {}, "score": "57.14981"}
{"text": "If a parse node is a packed node , which means that a local ambiguity packing happened , then a disjunctive feature structure is used to represent the packed ambiguities .In a typical GLR parser , in which the root node is a packed node and the feature structure of the root node 2554 is the final output of the parsing , local ambiguity packing is used to save storage for parse trees .", "label": "", "metadata": {}, "score": "57.14981"}
{"text": "If a parse node is a packed node , which means that a local ambiguity packing happened , then a disjunctive feature structure is used to represent the packed ambiguities .In a typical GLR parser , in which the root node is a packed node and the feature structure of the root node 2554 is the final output of the parsing , local ambiguity packing is used to save storage for parse trees .", "label": "", "metadata": {}, "score": "57.14981"}
{"text": "Component ( ICE- GB ) and by pointing out the fact that the use of two . parsers ( i.e. , TOSCA and Survey parser ) increased the number of . inconsistencies in the corpus , thus the necessity of a . post - correction .", "label": "", "metadata": {}, "score": "57.23873"}
{"text": "This last measure can be .used to illustrate the parser accuracy .The evaluation of grammatical .relations provides information about levels of precision and recall .for groups or single relations .Thus , they are useful for indicating .", "label": "", "metadata": {}, "score": "57.352776"}
{"text": "The natural language processor employs many types of knowledge and stores different types of knowledge in different knowledge structures that separate the knowledge into organized types .A typical natural language processor also uses very complex capabilities .The knowledge and capabilities of the typical natural language processor must be reduced in complexity and refined to make the natural language processor manageable and useful because a natural language processor must have more than a reasonably correct response to an input sentence .", "label": "", "metadata": {}, "score": "57.505474"}
{"text": "The natural language processor employs many types of knowledge and stores different types of knowledge in different knowledge structures that separate the knowledge into organized types .A typical natural language processor also uses very complex capabilities .The knowledge and capabilities of the typical natural language processor must be reduced in complexity and refined to make the natural language processor manageable and useful because a natural language processor must have more than a reasonably correct response to an input sentence .", "label": "", "metadata": {}, "score": "57.505474"}
{"text": "The natural language processor employs many types of knowledge and stores different types of knowledge in different knowledge structures that separate the knowledge into organized types .A typical natural language processor also uses very complex capabilities .The knowledge and capabilities of the typical natural language processor must be reduced in complexity and refined to make the natural language processor manageable and useful because a natural language processor must have more than a reasonably correct response to an input sentence .", "label": "", "metadata": {}, "score": "57.505474"}
{"text": "The natural language processor employs many types of knowledge and stores different types of knowledge in different knowledge structures that separate the knowledge into organized types .A typical natural language processor also uses very complex capabilities .The knowledge and capabilities of the typical natural language processor must be reduced in complexity and refined to make the natural language processor manageable and useful because a natural language processor must have more than a reasonably correct response to an input sentence .", "label": "", "metadata": {}, "score": "57.505474"}
{"text": "The natural language processor employs many types of knowledge and stores different types of knowledge in different knowledge structures that separate the knowledge into organized types .A typical natural language processor also uses very complex capabilities .The knowledge and capabilities of the typical natural language processor must be reduced in complexity and refined to make the natural language processor manageable and useful because a natural language processor must have more than a reasonably correct response to an input sentence .", "label": "", "metadata": {}, "score": "57.505474"}
{"text": "When the parser has analyzed the entire input successfully and generated at least one packed shared parse forest , the next action is an accept action , and operation continues at step 2630 , at which the accept action is performed .", "label": "", "metadata": {}, "score": "57.52009"}
{"text": "When the parser has analyzed the entire input successfully and generated at least one packed shared parse forest , the next action is an accept action , and operation continues at step 2630 , at which the accept action is performed .", "label": "", "metadata": {}, "score": "57.52009"}
{"text": "When the parser has analyzed the entire input successfully and generated at least one packed shared parse forest , the next action is an accept action , and operation continues at step 2630 , at which the accept action is performed .", "label": "", "metadata": {}, "score": "57.52009"}
{"text": "When the parser has analyzed the entire input successfully and generated at least one packed shared parse forest , the next action is an accept action , and operation continues at step 2630 , at which the accept action is performed .", "label": "", "metadata": {}, "score": "57.52009"}
{"text": "When the parser has analyzed the entire input successfully and generated at least one packed shared parse forest , the next action is an accept action , and operation continues at step 2630 , at which the accept action is performed .", "label": "", "metadata": {}, "score": "57.52009"}
{"text": "can be defined for comparing annotations , for merging them or for . designing tools for visualization , editing , extraction , etc .A . concrete AML results from the combination of a virtual AML and Dialect .Specification .The abstract model ensures the coherence and . consistency of the annotation schemes .", "label": "", "metadata": {}, "score": "57.58405"}
{"text": "Finally , we discuss the potential that corpus studies have for enriching the data set for theoretical linguistic research , as well as helping to confirm or disconfirm linguistic hypotheses .The availability of on - line corpora is rapidly changing the field of natural language processing ( NLP ) from one dominated by theoretical models of often very specific linguistic phenomena to one guided by computational models that simultaneously account for a wide variety of phenomena that occur in real - world text .", "label": "", "metadata": {}, "score": "57.63201"}
{"text": "Finally , we discuss the potential that corpus studies have for enriching the data set for theoretical linguistic research , as well as helping to confirm or disconfirm linguistic hypotheses .The availability of on - line corpora is rapidly changing the field of natural language processing ( NLP ) from one dominated by theoretical models of often very specific linguistic phenomena to one guided by computational models that simultaneously account for a wide variety of phenomena that occur in real - world text .", "label": "", "metadata": {}, "score": "57.63201"}
{"text": "An output is provided comprising at least one recognized source expression 306 , but the embodiment is not so limited .FIG .5 is a system diagram of translation from a source language to a target language 308 in a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "57.643585"}
{"text": "An output is provided comprising at least one recognized source expression 306 , but the embodiment is not so limited .FIG .5 is a system diagram of translation from a source language to a target language 308 in a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "57.643585"}
{"text": "An output is provided comprising at least one recognized source expression 306 , but the embodiment is not so limited .FIG .5 is a system diagram of translation from a source language to a target language 308 in a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "57.643585"}
{"text": "An output is provided comprising at least one recognized source expression 306 , but the embodiment is not so limited .FIG .5 is a system diagram of translation from a source language to a target language 308 in a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "57.643585"}
{"text": "An output is provided comprising at least one recognized source expression 306 , but the embodiment is not so limited .FIG .5 is a system diagram of translation from a source language to a target language 308 in a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "57.643585"}
{"text": "A spoken language translation system , comprising : . a means for receiving ( 302 ) at least one speech input ; . a means for generating ( 402 ) a plurality of recognition hypotheses in response to the at least one speech input taking into consideration a potential variability in the at least one speech input ; . a means for receiving information indicative of ( 1802 ) a best hypothesis from the plurality of recognition hypotheses ; . a means for adapting ( 1810 ) hypothesis generation in response to the best hypothesis ; and .", "label": "", "metadata": {}, "score": "57.66407"}
{"text": "checking , as in most cases .The language - specific phenomena ( for . instance , constructions with nominal predicates ) are given a short .presentation , along with the solution adopted in the annotation .process .The treebank aims at being used as a reliable resource by .", "label": "", "metadata": {}, "score": "57.698807"}
{"text": "3 is a system diagram of the speech translation system of an embodiment of the present invention .FIG .4 is a flowchart of source language speech recognition of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "57.739433"}
{"text": "3 is a system diagram of the speech translation system of an embodiment of the present invention .FIG .4 is a flowchart of source language speech recognition of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "57.739433"}
{"text": "The method of claim 1 , wherein the step of translating comprises : . performing morphological analysis of the recognized at least one source expression using at least one source language dictionary and at least one source language morphological rule ; . generating at least one sequence of analyzed morphemes ; . performing syntactic source language analysis using grammar rule - based processing and example - based processing ; . generating at least one source language syntactic representation ; and .", "label": "", "metadata": {}, "score": "57.75631"}
{"text": "In an alternate embodiment , an alternative set of adjective default rules may be used for comparative / superlative forms , wherein the alternative set of adjective default rules comprise , but are not limited to , rules that for : .", "label": "", "metadata": {}, "score": "57.89811"}
{"text": "In an alternate embodiment , an alternative set of adjective default rules may be used for comparative / superlative forms , wherein the alternative set of adjective default rules comprise , but are not limited to , rules that for : .", "label": "", "metadata": {}, "score": "57.89811"}
{"text": "In an alternate embodiment , an alternative set of adjective default rules may be used for comparative / superlative forms , wherein the alternative set of adjective default rules comprise , but are not limited to , rules that for : .", "label": "", "metadata": {}, "score": "57.89811"}
{"text": "In an alternate embodiment , an alternative set of adjective default rules may be used for comparative / superlative forms , wherein the alternative set of adjective default rules comprise , but are not limited to , rules that for : .", "label": "", "metadata": {}, "score": "57.89811"}
{"text": "The computer readable medium of claim 27 , wherein the method further comprises : . presenting the plurality of recognition hypotheses ; . translating the at least one speech input in response to the best hypothesis ; and .synthesizing at least one speech output in response to the translated at least one speech input .", "label": "", "metadata": {}, "score": "57.91154"}
{"text": "In order to achieve good translational coverage with high quality translation without exhaustively listing every possible input in the example database , an embodiment of the present invention captures syntactic regularities .Capturing syntactic regularities supports example - based translation in an embodiment of the present invention in four ways , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "57.972366"}
{"text": "In order to achieve good translational coverage with high quality translation without exhaustively listing every possible input in the example database , an embodiment of the present invention captures syntactic regularities .Capturing syntactic regularities supports example - based translation in an embodiment of the present invention in four ways , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "57.972366"}
{"text": "In order to achieve good translational coverage with high quality translation without exhaustively listing every possible input in the example database , an embodiment of the present invention captures syntactic regularities .Capturing syntactic regularities supports example - based translation in an embodiment of the present invention in four ways , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "57.972366"}
{"text": "In order to achieve good translational coverage with high quality translation without exhaustively listing every possible input in the example database , an embodiment of the present invention captures syntactic regularities .Capturing syntactic regularities supports example - based translation in an embodiment of the present invention in four ways , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "57.972366"}
{"text": "In order to achieve good translational coverage with high quality translation without exhaustively listing every possible input in the example database , an embodiment of the present invention captures syntactic regularities .Capturing syntactic regularities supports example - based translation in an embodiment of the present invention in four ways , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "57.972366"}
{"text": "Spoken language occurs a phrase at a time , and contains considerable intonational information that is not captured in written form .It also contains many repairs , in which the speaker corrects or rephrases something that was just said .In addition , spoken dialogue has a rich interaction of acknowledgment and confirmation that maintains the conversation , which does not appear in written forms .", "label": "", "metadata": {}, "score": "57.973816"}
{"text": "between these two phases of the language are presented .The neural - network based POS tagger was trained on a set of words .manually tagged for each of the texts in the Medieval Portuguese . corpus .It was then used to extract a dictionary and to tag the rest .", "label": "", "metadata": {}, "score": "58.052483"}
{"text": "The computer readable medium of claim 29 , wherein the method further comprises : . receiving at least one speech input comprising at least one source language expression ; . performing the syntactic analysis on the at least one source language expression and the at least one example database to recognize linguistic constituents ; . searching the at least one example database to find an expression pair having a source language portion most similar to the at least one source language expression ; . generating at least one target language expression using a target language portion of the expression pair ; and . providing at least one speech output comprising the at least one target language expression .", "label": "", "metadata": {}, "score": "58.07791"}
{"text": "13 - 17 are all present in a single system as different modes of operation , and a user may choose between the different modes of operation .The speech recognition and hypothesis / hypotheses construction steps are carried out separately , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "58.078964"}
{"text": "13 - 17 are all present in a single system as different modes of operation , and a user may choose between the different modes of operation .The speech recognition and hypothesis / hypotheses construction steps are carried out separately , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "58.078964"}
{"text": "13 - 17 are all present in a single system as different modes of operation , and a user may choose between the different modes of operation .The speech recognition and hypothesis / hypotheses construction steps are carried out separately , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "58.078964"}
{"text": "13 - 17 are all present in a single system as different modes of operation , and a user may choose between the different modes of operation .The speech recognition and hypothesis / hypotheses construction steps are carried out separately , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "58.078964"}
{"text": "13 - 17 are all present in a single system as different modes of operation , and a user may choose between the different modes of operation .The speech recognition and hypothesis / hypotheses construction steps are carried out separately , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "58.078964"}
{"text": "The method of claim 9 , wherein the grammar rule - based processing comprises : . syntactic and morphological analysis in the at least one source language ; and . syntactic and morphological generation in the at least one target language .", "label": "", "metadata": {}, "score": "58.119377"}
{"text": "The method of claim 2 , wherein the intermediate source language data structure comprises at least one word graph and at least one n - best list .The method of claim 3 , wherein the model comprises a general language model and a domain model .", "label": "", "metadata": {}, "score": "58.14351"}
{"text": "FIG .24 is a list of top level features to indicate special inflections in an English morphological analyzer of an embodiment of the present invention .FIG .25 is a parser implementation of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "58.23054"}
{"text": "FIG .24 is a list of top level features to indicate special inflections in an English morphological analyzer of an embodiment of the present invention .FIG .25 is a parser implementation of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "58.23054"}
{"text": "FIG .24 is a list of top level features to indicate special inflections in an English morphological analyzer of an embodiment of the present invention .FIG .25 is a parser implementation of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "58.23054"}
{"text": "FIG .24 is a list of top level features to indicate special inflections in an English morphological analyzer of an embodiment of the present invention .FIG .25 is a parser implementation of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "58.23054"}
{"text": "FIG .24 is a list of top level features to indicate special inflections in an English morphological analyzer of an embodiment of the present invention .FIG .25 is a parser implementation of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "58.23054"}
{"text": "An appropriate feature structure 2160 is constructed for the word , inserting features associated with the inflection type in question .If the token can be analyzed , the feature structure of the token with newly generated morphological features is output .", "label": "", "metadata": {}, "score": "58.298676"}
{"text": "An appropriate feature structure 2160 is constructed for the word , inserting features associated with the inflection type in question .If the token can be analyzed , the feature structure of the token with newly generated morphological features is output .", "label": "", "metadata": {}, "score": "58.298676"}
{"text": "An appropriate feature structure 2160 is constructed for the word , inserting features associated with the inflection type in question .If the token can be analyzed , the feature structure of the token with newly generated morphological features is output .", "label": "", "metadata": {}, "score": "58.298676"}
{"text": "Statistically - based methods that acquire ( usual ... . \" ... this paper we outline a research program for computational linguistics , making extensive use of text corpora .We demonstrate how a semantic framework for lexical knowledge can suggest richer relationships among words in text beyond that of simple co - occurrence .", "label": "", "metadata": {}, "score": "58.36814"}
{"text": "Statistically - based methods that acquire ( usual ... . \" ... this paper we outline a research program for computational linguistics , making extensive use of text corpora .We demonstrate how a semantic framework for lexical knowledge can suggest richer relationships among words in text beyond that of simple co - occurrence .", "label": "", "metadata": {}, "score": "58.36814"}
{"text": "However , linguistic behavior can not be completely accounted for without also taking into account another aspect of what makes humans intelligent - their general world knowledge and their reasoning abilities .For example , to answer questions or to participate in a conversation , a person not only must have knowledge about the structure of the language being used , but also must know about the world in general and the conversational setting in particular .", "label": "", "metadata": {}, "score": "58.47529"}
{"text": "However , linguistic behavior can not be completely accounted for without also taking into account another aspect of what makes humans intelligent - their general world knowledge and their reasoning abilities .For example , to answer questions or to participate in a conversation , a person not only must have knowledge about the structure of the language being used , but also must know about the world in general and the conversational setting in particular .", "label": "", "metadata": {}, "score": "58.47529"}
{"text": "However , linguistic behavior can not be completely accounted for without also taking into account another aspect of what makes humans intelligent - their general world knowledge and their reasoning abilities .For example , to answer questions or to participate in a conversation , a person not only must have knowledge about the structure of the language being used , but also must know about the world in general and the conversational setting in particular .", "label": "", "metadata": {}, "score": "58.47529"}
{"text": "However , linguistic behavior can not be completely accounted for without also taking into account another aspect of what makes humans intelligent - their general world knowledge and their reasoning abilities .For example , to answer questions or to participate in a conversation , a person not only must have knowledge about the structure of the language being used , but also must know about the world in general and the conversational setting in particular .", "label": "", "metadata": {}, "score": "58.47529"}
{"text": "However , linguistic behavior can not be completely accounted for without also taking into account another aspect of what makes humans intelligent - their general world knowledge and their reasoning abilities .For example , to answer questions or to participate in a conversation , a person not only must have knowledge about the structure of the language being used , but also must know about the world in general and the conversational setting in particular .", "label": "", "metadata": {}, "score": "58.47529"}
{"text": "8 shows an example - based translation system architecture using syntactic analysis of an embodiment of the present invention .The translation system architecture of an embodiment comprises a shallow syntactic analyzer 804 , an example based transfer 806 , and a target expression generator 808 , but is not so limited .", "label": "", "metadata": {}, "score": "58.524925"}
{"text": "8 shows an example - based translation system architecture using syntactic analysis of an embodiment of the present invention .The translation system architecture of an embodiment comprises a shallow syntactic analyzer 804 , an example based transfer 806 , and a target expression generator 808 , but is not so limited .", "label": "", "metadata": {}, "score": "58.524925"}
{"text": "8 shows an example - based translation system architecture using syntactic analysis of an embodiment of the present invention .The translation system architecture of an embodiment comprises a shallow syntactic analyzer 804 , an example based transfer 806 , and a target expression generator 808 , but is not so limited .", "label": "", "metadata": {}, "score": "58.524925"}
{"text": "8 shows an example - based translation system architecture using syntactic analysis of an embodiment of the present invention .The translation system architecture of an embodiment comprises a shallow syntactic analyzer 804 , an example based transfer 806 , and a target expression generator 808 , but is not so limited .", "label": "", "metadata": {}, "score": "58.524925"}
{"text": "8 shows an example - based translation system architecture using syntactic analysis of an embodiment of the present invention .The translation system architecture of an embodiment comprises a shallow syntactic analyzer 804 , an example based transfer 806 , and a target expression generator 808 , but is not so limited .", "label": "", "metadata": {}, "score": "58.524925"}
{"text": "Consequently , spoken language is typically the most natural , most efficient , and most expressive means of communicating information , intentions , and wishes .Speakers of different languages , however , face a formidable problem in that they can not effectively communicate in the face of their language barrier .", "label": "", "metadata": {}, "score": "58.599487"}
{"text": "Consequently , spoken language is typically the most natural , most efficient , and most expressive means of communicating information , intentions , and wishes .Speakers of different languages , however , face a formidable problem in that they can not effectively communicate in the face of their language barrier .", "label": "", "metadata": {}, "score": "58.599487"}
{"text": "Consequently , spoken language is typically the most natural , most efficient , and most expressive means of communicating information , intentions , and wishes .Speakers of different languages , however , face a formidable problem in that they can not effectively communicate in the face of their language barrier .", "label": "", "metadata": {}, "score": "58.599487"}
{"text": "Consequently , spoken language is typically the most natural , most efficient , and most expressive means of communicating information , intentions , and wishes .Speakers of different languages , however , face a formidable problem in that they can not effectively communicate in the face of their language barrier .", "label": "", "metadata": {}, "score": "58.599487"}
{"text": "This is the study of context - independent meaning - the meaning a sentence has regardless of the context in which it is used .The representation of the context - independent meaning of a sentence is called its logical form .", "label": "", "metadata": {}, "score": "58.684772"}
{"text": "This is the study of context - independent meaning - the meaning a sentence has regardless of the context in which it is used .The representation of the context - independent meaning of a sentence is called its logical form .", "label": "", "metadata": {}, "score": "58.684772"}
{"text": "This is the study of context - independent meaning - the meaning a sentence has regardless of the context in which it is used .The representation of the context - independent meaning of a sentence is called its logical form .", "label": "", "metadata": {}, "score": "58.684772"}
{"text": "This is the study of context - independent meaning - the meaning a sentence has regardless of the context in which it is used .The representation of the context - independent meaning of a sentence is called its logical form .", "label": "", "metadata": {}, "score": "58.684772"}
{"text": "This is the study of context - independent meaning - the meaning a sentence has regardless of the context in which it is used .The representation of the context - independent meaning of a sentence is called its logical form .", "label": "", "metadata": {}, "score": "58.684772"}
{"text": "The parsing table generator 2502 provides an output comprising a parsing table 2522 that is stored as a file in an embodiment .The feature structure operation compiler 2504 receives an input comprising a set of grammar rules bundled with feature structure manipulations or operations 2552 .", "label": "", "metadata": {}, "score": "58.69745"}
{"text": "The parsing table generator 2502 provides an output comprising a parsing table 2522 that is stored as a file in an embodiment .The feature structure operation compiler 2504 receives an input comprising a set of grammar rules bundled with feature structure manipulations or operations 2552 .", "label": "", "metadata": {}, "score": "58.69745"}
{"text": "The parsing table generator 2502 provides an output comprising a parsing table 2522 that is stored as a file in an embodiment .The feature structure operation compiler 2504 receives an input comprising a set of grammar rules bundled with feature structure manipulations or operations 2552 .", "label": "", "metadata": {}, "score": "58.69745"}
{"text": "The parsing table generator 2502 provides an output comprising a parsing table 2522 that is stored as a file in an embodiment .The feature structure operation compiler 2504 receives an input comprising a set of grammar rules bundled with feature structure manipulations or operations 2552 .", "label": "", "metadata": {}, "score": "58.69745"}
{"text": "The parsing table generator 2502 provides an output comprising a parsing table 2522 that is stored as a file in an embodiment .The feature structure operation compiler 2504 receives an input comprising a set of grammar rules bundled with feature structure manipulations or operations 2552 .", "label": "", "metadata": {}, "score": "58.69745"}
{"text": "For these reasons , the translation method of an accurate spoken language translation system needs to be more flexible and robust , wherein the translation component is able to handle input that has incorrectly added or deleted or substituted words .To provide flexibility and robustness , a typical speech translation system uses many different types of translation knowledge , thereby resulting in an example specificity problem of how an example - based system can use examples with different grades of linguistic specificity .", "label": "", "metadata": {}, "score": "58.698116"}
{"text": "For these reasons , the translation method of an accurate spoken language translation system needs to be more flexible and robust , wherein the translation component is able to handle input that has incorrectly added or deleted or substituted words .To provide flexibility and robustness , a typical speech translation system uses many different types of translation knowledge , thereby resulting in an example specificity problem of how an example - based system can use examples with different grades of linguistic specificity .", "label": "", "metadata": {}, "score": "58.698116"}
{"text": "For these reasons , the translation method of an accurate spoken language translation system needs to be more flexible and robust , wherein the translation component is able to handle input that has incorrectly added or deleted or substituted words .To provide flexibility and robustness , a typical speech translation system uses many different types of translation knowledge , thereby resulting in an example specificity problem of how an example - based system can use examples with different grades of linguistic specificity .", "label": "", "metadata": {}, "score": "58.698116"}
{"text": "For these reasons , the translation method of an accurate spoken language translation system needs to be more flexible and robust , wherein the translation component is able to handle input that has incorrectly added or deleted or substituted words .To provide flexibility and robustness , a typical speech translation system uses many different types of translation knowledge , thereby resulting in an example specificity problem of how an example - based system can use examples with different grades of linguistic specificity .", "label": "", "metadata": {}, "score": "58.698116"}
{"text": "For these reasons , the translation method of an accurate spoken language translation system needs to be more flexible and robust , wherein the translation component is able to handle input that has incorrectly added or deleted or substituted words .To provide flexibility and robustness , a typical speech translation system uses many different types of translation knowledge , thereby resulting in an example specificity problem of how an example - based system can use examples with different grades of linguistic specificity .", "label": "", "metadata": {}, "score": "58.698116"}
{"text": "Marked nodes , when found , are rebuilt .The feature structure of the root node is rebuilt at the end .Thus , a method and apparatus for a spoken language translation system have been provided .Although the present invention has been described with reference to specific exemplary embodiments , it will be evident that various modifications and changes may be made to these embodiments without departing from the broader spirit and scope of the invention as set forth in the claims .", "label": "", "metadata": {}, "score": "58.732254"}
{"text": "Marked nodes , when found , are rebuilt .The feature structure of the root node is rebuilt at the end .Thus , a method and apparatus for a spoken language translation system have been provided .Although the present invention has been described with reference to specific exemplary embodiments , it will be evident that various modifications and changes may be made to these embodiments without departing from the broader spirit and scope of the invention as set forth in the claims .", "label": "", "metadata": {}, "score": "58.732254"}
{"text": "Marked nodes , when found , are rebuilt .The feature structure of the root node is rebuilt at the end .Thus , a method and apparatus for a spoken language translation system have been provided .Although the present invention has been described with reference to specific exemplary embodiments , it will be evident that various modifications and changes may be made to these embodiments without departing from the broader spirit and scope of the invention as set forth in the claims .", "label": "", "metadata": {}, "score": "58.732254"}
{"text": "Marked nodes , when found , are rebuilt .The feature structure of the root node is rebuilt at the end .Thus , a method and apparatus for a spoken language translation system have been provided .Although the present invention has been described with reference to specific exemplary embodiments , it will be evident that various modifications and changes may be made to these embodiments without departing from the broader spirit and scope of the invention as set forth in the claims .", "label": "", "metadata": {}, "score": "58.732254"}
{"text": "Marked nodes , when found , are rebuilt .The feature structure of the root node is rebuilt at the end .Thus , a method and apparatus for a spoken language translation system have been provided .Although the present invention has been described with reference to specific exemplary embodiments , it will be evident that various modifications and changes may be made to these embodiments without departing from the broader spirit and scope of the invention as set forth in the claims .", "label": "", "metadata": {}, "score": "58.732254"}
{"text": "WOLFIE is part of an integrated system that learns to parse novel sentences into semantic representations , such as logical database queries .Experimental results are presented demonstrating WOLFIE 'S ability to learn useful lexicons for a database interface in four different natural lan- guages .", "label": "", "metadata": {}, "score": "58.883373"}
{"text": "WOLFIE is part of an integrated system that learns to parse novel sentences into semantic representations , such as logical database queries .Experimental results are presented demonstrating WOLFIE 'S ability to learn useful lexicons for a database interface in four different natural lan- guages .", "label": "", "metadata": {}, "score": "58.883373"}
{"text": "Chapter 21 .From Treebank Resources to LFG F - Structures .Anette Frank , Louisa Sadler , Josef van Genabith , Andy Way .This paper presents two methods for automatic f - structure . annotation .The first one consists in extracting a Context-", "label": "", "metadata": {}, "score": "58.99164"}
{"text": "The example based transfer 806 accesses and uses at least one bilingual example database 816 , but is not so limited .The target expression generator 808 accesses and uses target language generation grammar 818 , but is not so limited .", "label": "", "metadata": {}, "score": "59.06067"}
{"text": "The example based transfer 806 accesses and uses at least one bilingual example database 816 , but is not so limited .The target expression generator 808 accesses and uses target language generation grammar 818 , but is not so limited .", "label": "", "metadata": {}, "score": "59.06067"}
{"text": "The example based transfer 806 accesses and uses at least one bilingual example database 816 , but is not so limited .The target expression generator 808 accesses and uses target language generation grammar 818 , but is not so limited .", "label": "", "metadata": {}, "score": "59.06067"}
{"text": "The example based transfer 806 accesses and uses at least one bilingual example database 816 , but is not so limited .The target expression generator 808 accesses and uses target language generation grammar 818 , but is not so limited .", "label": "", "metadata": {}, "score": "59.06067"}
{"text": "The example based transfer 806 accesses and uses at least one bilingual example database 816 , but is not so limited .The target expression generator 808 accesses and uses target language generation grammar 818 , but is not so limited .", "label": "", "metadata": {}, "score": "59.06067"}
{"text": "In performing spoken language translation , operation begins when a source language speech input 302 is received .Source language speech recognition is performed , at step 304 , and a recognized source expression 306 is produced .The recognized source expression 306 is translated from the source language to the target language , at step 308 .", "label": "", "metadata": {}, "score": "59.102757"}
{"text": "In performing spoken language translation , operation begins when a source language speech input 302 is received .Source language speech recognition is performed , at step 304 , and a recognized source expression 306 is produced .The recognized source expression 306 is translated from the source language to the target language , at step 308 .", "label": "", "metadata": {}, "score": "59.102757"}
{"text": "In performing spoken language translation , operation begins when a source language speech input 302 is received .Source language speech recognition is performed , at step 304 , and a recognized source expression 306 is produced .The recognized source expression 306 is translated from the source language to the target language , at step 308 .", "label": "", "metadata": {}, "score": "59.102757"}
{"text": "In performing spoken language translation , operation begins when a source language speech input 302 is received .Source language speech recognition is performed , at step 304 , and a recognized source expression 306 is produced .The recognized source expression 306 is translated from the source language to the target language , at step 308 .", "label": "", "metadata": {}, "score": "59.102757"}
{"text": "In performing spoken language translation , operation begins when a source language speech input 302 is received .Source language speech recognition is performed , at step 304 , and a recognized source expression 306 is produced .The recognized source expression 306 is translated from the source language to the target language , at step 308 .", "label": "", "metadata": {}, "score": "59.102757"}
{"text": "The computer readable medium of claim 29 , wherein performing syntactic analysis further comprises generalizing at least one surface variation in the at least one input and the at least one example database , wherein efficiency of the spoken language translation is increased .", "label": "", "metadata": {}, "score": "59.11295"}
{"text": "S. Wallis draws a distinction between longitudinal ( that is , . working through a corpus sentence - by - sentence , until it is completed ) .and transverse ( i.e. working through a corpus construction - by- .construction ) correction , bringing arguments in favor of the latter : . less time - consuming , control of the accuracy of the analysis and of . its consistency .", "label": "", "metadata": {}, "score": "59.16821"}
{"text": "The AIM tokenizer was used to break up each input sentence into tokens before performing the morphological analysis .The results showed the AIM to be approximately 42 times faster than the typical two - level morphological analyzer .The AIM of an embodiment of the present invention provides for increased overall performance of a speech translation system while providing the necessary and sufficient morphological analysis .", "label": "", "metadata": {}, "score": "59.30484"}
{"text": "The AIM tokenizer was used to break up each input sentence into tokens before performing the morphological analysis .The results showed the AIM to be approximately 42 times faster than the typical two - level morphological analyzer .The AIM of an embodiment of the present invention provides for increased overall performance of a speech translation system while providing the necessary and sufficient morphological analysis .", "label": "", "metadata": {}, "score": "59.30484"}
{"text": "The AIM tokenizer was used to break up each input sentence into tokens before performing the morphological analysis .The results showed the AIM to be approximately 42 times faster than the typical two - level morphological analyzer .The AIM of an embodiment of the present invention provides for increased overall performance of a speech translation system while providing the necessary and sufficient morphological analysis .", "label": "", "metadata": {}, "score": "59.30484"}
{"text": "The AIM tokenizer was used to break up each input sentence into tokens before performing the morphological analysis .The results showed the AIM to be approximately 42 times faster than the typical two - level morphological analyzer .The AIM of an embodiment of the present invention provides for increased overall performance of a speech translation system while providing the necessary and sufficient morphological analysis .", "label": "", "metadata": {}, "score": "59.30484"}
{"text": "At step 2622 , the feature structure manipulations are executed .A determination is made , at step 2624 , whether the manipulations fail or succeed .If the manipulations fail then application of the rule fails , and operation continues at step 2604 , at which the parsing table is consulted for a next action .", "label": "", "metadata": {}, "score": "59.3848"}
{"text": "At step 2622 , the feature structure manipulations are executed .A determination is made , at step 2624 , whether the manipulations fail or succeed .If the manipulations fail then application of the rule fails , and operation continues at step 2604 , at which the parsing table is consulted for a next action .", "label": "", "metadata": {}, "score": "59.3848"}
{"text": "At step 2622 , the feature structure manipulations are executed .A determination is made , at step 2624 , whether the manipulations fail or succeed .If the manipulations fail then application of the rule fails , and operation continues at step 2604 , at which the parsing table is consulted for a next action .", "label": "", "metadata": {}, "score": "59.3848"}
{"text": "At step 2622 , the feature structure manipulations are executed .A determination is made , at step 2624 , whether the manipulations fail or succeed .If the manipulations fail then application of the rule fails , and operation continues at step 2604 , at which the parsing table is consulted for a next action .", "label": "", "metadata": {}, "score": "59.3848"}
{"text": "At step 2622 , the feature structure manipulations are executed .A determination is made , at step 2624 , whether the manipulations fail or succeed .If the manipulations fail then application of the rule fails , and operation continues at step 2604 , at which the parsing table is consulted for a next action .", "label": "", "metadata": {}, "score": "59.3848"}
{"text": "Maria Teresa Pazienza , Dario Saracino , Fabio Zanzotto , Nadia Mana , .Fabio Pianesi , Rodolfo Delmonte .The paper presents the syntactic - semantic annotation of a balanced .corpus and of a specialized one .Four levels of annotations were .", "label": "", "metadata": {}, "score": "59.39618"}
{"text": "Spoken language is typically the most natural , most efficient , and most expressive means of communicating information , intentions , and wishes .At the same time , speakers of different languages face a formidable language barrier .FIG .1 is a computer system 100 hosting the speech translation system ( STS ) of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "59.441566"}
{"text": "Spoken language is typically the most natural , most efficient , and most expressive means of communicating information , intentions , and wishes .At the same time , speakers of different languages face a formidable language barrier .FIG .1 is a computer system 100 hosting the speech translation system ( STS ) of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "59.441566"}
{"text": "Spoken language is typically the most natural , most efficient , and most expressive means of communicating information , intentions , and wishes .At the same time , speakers of different languages face a formidable language barrier .FIG .1 is a computer system 100 hosting the speech translation system ( STS ) of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "59.441566"}
{"text": "Spoken language is typically the most natural , most efficient , and most expressive means of communicating information , intentions , and wishes .At the same time , speakers of different languages face a formidable language barrier .FIG .1 is a computer system 100 hosting the speech translation system ( STS ) of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "59.441566"}
{"text": "Spoken language is typically the most natural , most efficient , and most expressive means of communicating information , intentions , and wishes .At the same time , speakers of different languages face a formidable language barrier .FIG .1 is a computer system 100 hosting the speech translation system ( STS ) of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "59.441566"}
{"text": "Furthermore , possible splits of the sequence of tokens are determined , and a determination is made as to whether each split is valid .Morphological rules are applied to rule out unwanted splits and to assign proper morphological information to corresponding features .", "label": "", "metadata": {}, "score": "59.4775"}
{"text": "Furthermore , possible splits of the sequence of tokens are determined , and a determination is made as to whether each split is valid .Morphological rules are applied to rule out unwanted splits and to assign proper morphological information to corresponding features .", "label": "", "metadata": {}, "score": "59.4775"}
{"text": "Furthermore , possible splits of the sequence of tokens are determined , and a determination is made as to whether each split is valid .Morphological rules are applied to rule out unwanted splits and to assign proper morphological information to corresponding features .", "label": "", "metadata": {}, "score": "59.4775"}
{"text": "Furthermore , possible splits of the sequence of tokens are determined , and a determination is made as to whether each split is valid .Morphological rules are applied to rule out unwanted splits and to assign proper morphological information to corresponding features .", "label": "", "metadata": {}, "score": "59.4775"}
{"text": "However , this .representation is built bottom - up , the error - type being added .last .DiET offers a better method for configuring an annotation . schema , that is why the annotation was performed with this latter . tool .", "label": "", "metadata": {}, "score": "59.510162"}
{"text": "The dictionaries 2158 comprise lexicons in the format of feature structures .An appropriate feature structure 2160 is constructed for the word , inserting features associated with the inflection type in question .If the token can be analyzed , the feature structure of the token with newly generated morphological features is output .", "label": "", "metadata": {}, "score": "59.532845"}
{"text": "generating at least one word graph .The apparatus of claim 20 , wherein recognizing at least one word comprises : . using acoustic information comprising at least one word pronunciation dictionary and at least one acoustic model to generate at least one hypothesis for the at least one word ; and .", "label": "", "metadata": {}, "score": "59.83849"}
{"text": "If the next action is determined to be a reduce action then a reduce action is performed .The feature structure manipulations are executed , and a determination is made whether the manipulations fail or succeed .If the manipulations fail then application of the rule fails , and the parsing table is consulted for a next action .", "label": "", "metadata": {}, "score": "60.047997"}
{"text": "In addition , translation accuracy is improved in the present invention by adding examples with more specific context , provided that the example specificity problem can be solved .The most challenging problem in example - based translation , however , relates to the need to combine examples of different grades of linguistic specificity .", "label": "", "metadata": {}, "score": "60.250275"}
{"text": "In addition , translation accuracy is improved in the present invention by adding examples with more specific context , provided that the example specificity problem can be solved .The most challenging problem in example - based translation , however , relates to the need to combine examples of different grades of linguistic specificity .", "label": "", "metadata": {}, "score": "60.250275"}
{"text": "In addition , translation accuracy is improved in the present invention by adding examples with more specific context , provided that the example specificity problem can be solved .The most challenging problem in example - based translation , however , relates to the need to combine examples of different grades of linguistic specificity .", "label": "", "metadata": {}, "score": "60.250275"}
{"text": "In addition , translation accuracy is improved in the present invention by adding examples with more specific context , provided that the example specificity problem can be solved .The most challenging problem in example - based translation , however , relates to the need to combine examples of different grades of linguistic specificity .", "label": "", "metadata": {}, "score": "60.250275"}
{"text": "In addition , translation accuracy is improved in the present invention by adding examples with more specific context , provided that the example specificity problem can be solved .The most challenging problem in example - based translation , however , relates to the need to combine examples of different grades of linguistic specificity .", "label": "", "metadata": {}, "score": "60.250275"}
{"text": "Speed was tested using a corpus of 11,491 sentences containing 92,379 tokens ( words , numbers , punctuation , etc . ) , including some out - of - vocabulary words .The AIM tokenizer was used to break up each input sentence into tokens before performing the morphological analysis .", "label": "", "metadata": {}, "score": "60.37728"}
{"text": "The method of claim 1 , wherein the at least one structural analysis comprises a plurality of parse trees and sentential feature structures .The method of claim 1 , wherein the at least one feature structure comprises information from at least one lexical level of at least one morphological analysis .", "label": "", "metadata": {}, "score": "60.40823"}
{"text": "Morphological rules are applied to rule out unwanted splits and to assign proper morphological information to corresponding features .FIG .22 shows a sample input 2202 and output 2204 of an AIM of an embodiment of the present invention .Example input and output feature structures of an embodiment of the present invention follow , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "60.45096"}
{"text": "Other hallmarks include an absence of precoded domain - specific knowledge ; significant use of public - domain generic linguistic information sources ; involvement of the user as a judge and source of expertise ; and learning from the meaning representations produced during processing .", "label": "", "metadata": {}, "score": "60.57827"}
{"text": "Other hallmarks include an absence of precoded domain - specific knowledge ; significant use of public - domain generic linguistic information sources ; involvement of the user as a judge and source of expertise ; and learning from the meaning representations produced during processing .", "label": "", "metadata": {}, "score": "60.57827"}
{"text": "POS tags also contain syntactic .functions , thus serving as a basis for syntactic bracketing , which was .modified during the project from a skeletal context free bracketing .with limited empty categories and no indication of non - contiguous . structures and dependencies to a style of annotation which aimed at .", "label": "", "metadata": {}, "score": "60.66799"}
{"text": "The method of claim 1 , wherein each level of the at least one level of nested production rules comprises a production rule for a combination of the at least one linguistic constituent of the at least one input .The method of claim 1 , further comprising : . receiving at least one speech input comprising at least one source language expression ; . performing the syntactic analysis on the at least one source language expression and the at least one example database to recognize linguistic constituents ; . searching the at least one example database to find an expression pair having a source language portion most similar to the at least one source language expression ; . generating at least one target language expression using a target language portion of the expression pair ; and . providing at least one speech output comprising the at least one target language expression .", "label": "", "metadata": {}, "score": "60.724953"}
{"text": "the concepts they work with : the principles of inheritance , the .phrasal categories , etc . .Sinica treebank is not a mere syntactically annotated corpora , but . also a semantically annotated one , containing thematic . information .", "label": "", "metadata": {}, "score": "60.785805"}
{"text": "The effect is that the correct hypothesis will be presented to the user as the most likely hypothesis more and more often as the user uses the device .FIG .12 shows the hypothesis selection components of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "61.00982"}
{"text": "The effect is that the correct hypothesis will be presented to the user as the most likely hypothesis more and more often as the user uses the device .FIG .12 shows the hypothesis selection components of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "61.00982"}
{"text": "The effect is that the correct hypothesis will be presented to the user as the most likely hypothesis more and more often as the user uses the device .FIG .12 shows the hypothesis selection components of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "61.00982"}
{"text": "The effect is that the correct hypothesis will be presented to the user as the most likely hypothesis more and more often as the user uses the device .FIG .12 shows the hypothesis selection components of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "61.00982"}
{"text": "The effect is that the correct hypothesis will be presented to the user as the most likely hypothesis more and more often as the user uses the device .FIG .12 shows the hypothesis selection components of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "61.00982"}
{"text": "Some embodiments , such as cellular telephone and PDA embodiments , allow users to remotely update vocabularies using various communication methods in order to add new words or names or expressions and their translations .In some embodiments , translation may be performed remotely at an internet server and transmitted using internet telephony .", "label": "", "metadata": {}, "score": "61.034203"}
{"text": "Some embodiments , such as cellular telephone and PDA embodiments , allow users to remotely update vocabularies using various communication methods in order to add new words or names or expressions and their translations .In some embodiments , translation may be performed remotely at an internet server and transmitted using internet telephony .", "label": "", "metadata": {}, "score": "61.034203"}
{"text": "Some embodiments , such as cellular telephone and PDA embodiments , allow users to remotely update vocabularies using various communication methods in order to add new words or names or expressions and their translations .In some embodiments , translation may be performed remotely at an internet server and transmitted using internet telephony .", "label": "", "metadata": {}, "score": "61.034203"}
{"text": "Some embodiments , such as cellular telephone and PDA embodiments , allow users to remotely update vocabularies using various communication methods in order to add new words or names or expressions and their translations .In some embodiments , translation may be performed remotely at an internet server and transmitted using internet telephony .", "label": "", "metadata": {}, "score": "61.034203"}
{"text": "Some embodiments , such as cellular telephone and PDA embodiments , allow users to remotely update vocabularies using various communication methods in order to add new words or names or expressions and their translations .In some embodiments , translation may be performed remotely at an internet server and transmitted using internet telephony .", "label": "", "metadata": {}, "score": "61.034203"}
{"text": "Annotation principles define projection constraints . which associate partial c(onstituent)- structures with their . corresponding partial f - structures .When these principles are applied . to flat set - based encoding of treebank trees , they induce the .f - structure .", "label": "", "metadata": {}, "score": "61.05174"}
{"text": "We introduce a performance task for machine learning systems called semi - flexible prediction that lies between the classification task performed by decision tree algorithms and the flexible prediction task performed by conceptual clustering systems .In semi - flexible prediction , learning should improve prediction of a specific set of features known a priori rather than a single known feature ( as in classification ) or an arbitrary set of features ( as in conceptual clustering ) .", "label": "", "metadata": {}, "score": "61.126747"}
{"text": "We introduce a performance task for machine learning systems called semi - flexible prediction that lies between the classification task performed by decision tree algorithms and the flexible prediction task performed by conceptual clustering systems .In semi - flexible prediction , learning should improve prediction of a specific set of features known a priori rather than a single known feature ( as in classification ) or an arbitrary set of features ( as in conceptual clustering ) .", "label": "", "metadata": {}, "score": "61.126747"}
{"text": "One embodiment further comprises the step of minimizing misrecognitions of the at least one source expression , wherein the misrecognitions result from factors comprising noise and speaker variation . receiving at least one speech input comprising at least one source language ; . translating the at least one source expression from the at least one source language to at least one target language ; . synthesizing at least one speech output from the translated at least one target language ; and . providing the at least one speech output .", "label": "", "metadata": {}, "score": "61.23063"}
{"text": "Problems are also prevalent in previous approaches to performing syntactic analysis in example - based translation systems .One previous approach performs dependency analysis to obtain surface word dependency graphs for the input and the examples of the example database .The problem , however , with this approach is that dependency grammar lacks the expressiveness required for many common spoken language constructions .", "label": "", "metadata": {}, "score": "61.292854"}
{"text": "Problems are also prevalent in previous approaches to performing syntactic analysis in example - based translation systems .One previous approach performs dependency analysis to obtain surface word dependency graphs for the input and the examples of the example database .The problem , however , with this approach is that dependency grammar lacks the expressiveness required for many common spoken language constructions .", "label": "", "metadata": {}, "score": "61.292854"}
{"text": "Problems are also prevalent in previous approaches to performing syntactic analysis in example - based translation systems .One previous approach performs dependency analysis to obtain surface word dependency graphs for the input and the examples of the example database .The problem , however , with this approach is that dependency grammar lacks the expressiveness required for many common spoken language constructions .", "label": "", "metadata": {}, "score": "61.292854"}
{"text": "Problems are also prevalent in previous approaches to performing syntactic analysis in example - based translation systems .One previous approach performs dependency analysis to obtain surface word dependency graphs for the input and the examples of the example database .The problem , however , with this approach is that dependency grammar lacks the expressiveness required for many common spoken language constructions .", "label": "", "metadata": {}, "score": "61.292854"}
{"text": "Problems are also prevalent in previous approaches to performing syntactic analysis in example - based translation systems .One previous approach performs dependency analysis to obtain surface word dependency graphs for the input and the examples of the example database .The problem , however , with this approach is that dependency grammar lacks the expressiveness required for many common spoken language constructions .", "label": "", "metadata": {}, "score": "61.292854"}
{"text": "The computer readable medium of claim 27 , wherein generating the plurality of recognition hypotheses comprises : . assigning basic probabilities to at least one basic component of the at least one speech input using at least one language model ; and . calculating an overall probability of each of the plurality of recognition hypotheses using the assigned basic probabilities .", "label": "", "metadata": {}, "score": "61.32811"}
{"text": "5 is a flowchart of translation from a source language to a target language in a speech translation system of an embodiment of the present invention .FIG .6 is a context - free phrase structure tree of an embodiment of the present invention obtained by parsing the input \" I want to make a reservation for three people for tomorrow evening . \"", "label": "", "metadata": {}, "score": "61.369312"}
{"text": "5 is a flowchart of translation from a source language to a target language in a speech translation system of an embodiment of the present invention .FIG .6 is a context - free phrase structure tree of an embodiment of the present invention obtained by parsing the input \" I want to make a reservation for three people for tomorrow evening . \"", "label": "", "metadata": {}, "score": "61.369312"}
{"text": "5 is a flowchart of translation from a source language to a target language in a speech translation system of an embodiment of the present invention .FIG .6 is a context - free phrase structure tree of an embodiment of the present invention obtained by parsing the input \" I want to make a reservation for three people for tomorrow evening . \"", "label": "", "metadata": {}, "score": "61.369312"}
{"text": "5 is a flowchart of translation from a source language to a target language in a speech translation system of an embodiment of the present invention .FIG .6 is a context - free phrase structure tree of an embodiment of the present invention obtained by parsing the input \" I want to make a reservation for three people for tomorrow evening . \"", "label": "", "metadata": {}, "score": "61.369312"}
{"text": "5 is a flowchart of translation from a source language to a target language in a speech translation system of an embodiment of the present invention .FIG .6 is a context - free phrase structure tree of an embodiment of the present invention obtained by parsing the input \" I want to make a reservation for three people for tomorrow evening . \"", "label": "", "metadata": {}, "score": "61.369312"}
{"text": "subgrammars ) , with the future aim at merging the two SLTGs to improve .the coverage of treebank grammars on unseen data and to ease . adaptation of treebanks to new domains .The major operation in the extraction of SLTG is the recursive . top - down tree decomposition according to the head principle , thus each .", "label": "", "metadata": {}, "score": "61.559776"}
{"text": "Demo and web interface .Unlike conventional parsers using CFGs , the default output of the parser is a set of predicate - argument relations , so the user can easily acquire semantic relations among words in an input sentence without the burden of analyzing its deep - syntactic structure .", "label": "", "metadata": {}, "score": "61.64248"}
{"text": "Demo and web interface .Unlike conventional parsers using CFGs , the default output of the parser is a set of predicate - argument relations , so the user can easily acquire semantic relations among words in an input sentence without the burden of analyzing its deep - syntactic structure .", "label": "", "metadata": {}, "score": "61.64248"}
{"text": "18 is a flowchart for language model adaptation of a speech translation system of an embodiment of the present invention .FIG .19 shows an entry to which default inflectional rules apply in an embodiment of the present invention .FIG .", "label": "", "metadata": {}, "score": "61.65822"}
{"text": "18 is a flowchart for language model adaptation of a speech translation system of an embodiment of the present invention .FIG .19 shows an entry to which default inflectional rules apply in an embodiment of the present invention .FIG .", "label": "", "metadata": {}, "score": "61.65822"}
{"text": "18 is a flowchart for language model adaptation of a speech translation system of an embodiment of the present invention .FIG .19 shows an entry to which default inflectional rules apply in an embodiment of the present invention .FIG .", "label": "", "metadata": {}, "score": "61.65822"}
{"text": "18 is a flowchart for language model adaptation of a speech translation system of an embodiment of the present invention .FIG .19 shows an entry to which default inflectional rules apply in an embodiment of the present invention .FIG .", "label": "", "metadata": {}, "score": "61.65822"}
{"text": "18 is a flowchart for language model adaptation of a speech translation system of an embodiment of the present invention .FIG .19 shows an entry to which default inflectional rules apply in an embodiment of the present invention .FIG .", "label": "", "metadata": {}, "score": "61.65822"}
{"text": "The adjective default rules comprise , but are not limited to , rules that for : .In an alternate embodiment , an alternative set of adjective default rules may be used for comparative / superlative forms , wherein the alternative set of adjective default rules comprise , but are not limited to , rules that for : .", "label": "", "metadata": {}, "score": "61.67794"}
{"text": "using the extracted grammar for recognizing sentences with less or no . modifiers than the seen ones .There results a SLTG which is processed . by a two - phase stochastic parser .The rest of the paper describes the . extraction of SLTG from PTB and from NEGRA treebank , on the one hand , . and from a set of parse trees with an English HPSG , on the other , and .", "label": "", "metadata": {}, "score": "61.678238"}
{"text": "The apparatus of claim 15 , wherein the at least one input comprises spoken language .A computer readable medium containing executable instructions which , when executed in a processing system , causes the system to perform a method for spoken language translation , the method comprising : . receiving at least one input ; . performing syntactic analysis on at least one entry from at least one example database using the at least one parse tree ; . determining at least one linguistic constituent of the at least one input ; . determining a pragmatic type and a syntactic type of the at least one linguistic constituent ; . retaining an order of the at least one linguistic constituent in the at least one input ; and . providing at least one output comprising an identification of the at least one input .", "label": "", "metadata": {}, "score": "61.78741"}
{"text": "ideally for each token in the input data the lemma and the associated . MTag .Whenever more than one lemma and/or an MTag are produced , manual .disambiguation is needed .For the analytical ( syntactic ) level of . annotation the dependency structure was used .", "label": "", "metadata": {}, "score": "61.925552"}
{"text": "The apparatus of claim 15 , wherein a separation is provided between domain - independent linguistic knowledge and domain - dependent linguistic knowledge .The apparatus of claim 15 , wherein the at least one processor is further configured to identify by performing statistical processing to resolve lexical ambiguities and local ambiguities .", "label": "", "metadata": {}, "score": "61.955235"}
{"text": "Parsing accuracy improves , while parsing speed gets slower .Output n - best parse results : specify the option \" -N \" .This is an experimental function , and parsing speed gets slower .You can alternatively use a high - speed parser by using the command \" mogura \" .", "label": "", "metadata": {}, "score": "61.98838"}
{"text": "Parsing accuracy improves , while parsing speed gets slower .Output n - best parse results : specify the option \" -N \" .This is an experimental function , and parsing speed gets slower .You can alternatively use a high - speed parser by using the command \" mogura \" .", "label": "", "metadata": {}, "score": "61.98838"}
{"text": "Example - based translation is a method for translation that uses bilingual example pairs to encode translation correspondences or translation knowledge .An example - based translation system uses an example database , a stored set of corresponding words , phrases , expressions , or sentences in the source and target languages .", "label": "", "metadata": {}, "score": "62.069916"}
{"text": "Example - based translation is a method for translation that uses bilingual example pairs to encode translation correspondences or translation knowledge .An example - based translation system uses an example database , a stored set of corresponding words , phrases , expressions , or sentences in the source and target languages .", "label": "", "metadata": {}, "score": "62.069916"}
{"text": "Example - based translation is a method for translation that uses bilingual example pairs to encode translation correspondences or translation knowledge .An example - based translation system uses an example database , a stored set of corresponding words , phrases , expressions , or sentences in the source and target languages .", "label": "", "metadata": {}, "score": "62.069916"}
{"text": "Example - based translation is a method for translation that uses bilingual example pairs to encode translation correspondences or translation knowledge .An example - based translation system uses an example database , a stored set of corresponding words , phrases , expressions , or sentences in the source and target languages .", "label": "", "metadata": {}, "score": "62.069916"}
{"text": "Example - based translation is a method for translation that uses bilingual example pairs to encode translation correspondences or translation knowledge .An example - based translation system uses an example database , a stored set of corresponding words , phrases , expressions , or sentences in the source and target languages .", "label": "", "metadata": {}, "score": "62.069916"}
{"text": "papers here focus on different types of languages , displaying .grammatical phenomena and different ways of dealing with them , these .papers can serve as a repository of solutions to various problems .encountered when trying to design a corpus , to establish a certain . annotation scheme to be used for a treebank , to develop annotation . tools .", "label": "", "metadata": {}, "score": "62.109364"}
{"text": "using the correction to generate a best hypothesis in the source language in response to a subsequent input that is similar to the input .The method of claim 1 , wherein the input received is spoken words .The method of claim 1 , wherein the input received is an output of a keyboard device .", "label": "", "metadata": {}, "score": "62.11719"}
{"text": "The acoustic speech recognition component 1202 accesses and uses at least one word pronunciation dictionary 1222 and at least one acoustic model 1224 to generate at least one data structure 1204 encoding hypothesized words and their corresponding positions and time .The data structure information 1204 is used for utterance hypothesis construction 1206 , wherein an ordered list of utterance hypotheses 1208 are produced .", "label": "", "metadata": {}, "score": "62.252945"}
{"text": "The acoustic speech recognition component 1202 accesses and uses at least one word pronunciation dictionary 1222 and at least one acoustic model 1224 to generate at least one data structure 1204 encoding hypothesized words and their corresponding positions and time .The data structure information 1204 is used for utterance hypothesis construction 1206 , wherein an ordered list of utterance hypotheses 1208 are produced .", "label": "", "metadata": {}, "score": "62.252945"}
{"text": "The acoustic speech recognition component 1202 accesses and uses at least one word pronunciation dictionary 1222 and at least one acoustic model 1224 to generate at least one data structure 1204 encoding hypothesized words and their corresponding positions and time .The data structure information 1204 is used for utterance hypothesis construction 1206 , wherein an ordered list of utterance hypotheses 1208 are produced .", "label": "", "metadata": {}, "score": "62.252945"}
{"text": "The acoustic speech recognition component 1202 accesses and uses at least one word pronunciation dictionary 1222 and at least one acoustic model 1224 to generate at least one data structure 1204 encoding hypothesized words and their corresponding positions and time .The data structure information 1204 is used for utterance hypothesis construction 1206 , wherein an ordered list of utterance hypotheses 1208 are produced .", "label": "", "metadata": {}, "score": "62.252945"}
{"text": "The acoustic speech recognition component 1202 accesses and uses at least one word pronunciation dictionary 1222 and at least one acoustic model 1224 to generate at least one data structure 1204 encoding hypothesized words and their corresponding positions and time .The data structure information 1204 is used for utterance hypothesis construction 1206 , wherein an ordered list of utterance hypotheses 1208 are produced .", "label": "", "metadata": {}, "score": "62.252945"}
{"text": "It also contains many repairs , in which the speaker corrects or rephrases something that was just said .In addition , spoken dialogue has a rich interaction of acknowledgment and confirmation that maintains the conversation , which does not appear in written forms .", "label": "", "metadata": {}, "score": "62.278725"}
{"text": "It also contains many repairs , in which the speaker corrects or rephrases something that was just said .In addition , spoken dialogue has a rich interaction of acknowledgment and confirmation that maintains the conversation , which does not appear in written forms .", "label": "", "metadata": {}, "score": "62.278725"}
{"text": "It also contains many repairs , in which the speaker corrects or rephrases something that was just said .In addition , spoken dialogue has a rich interaction of acknowledgment and confirmation that maintains the conversation , which does not appear in written forms .", "label": "", "metadata": {}, "score": "62.278725"}
{"text": "It also contains many repairs , in which the speaker corrects or rephrases something that was just said .In addition , spoken dialogue has a rich interaction of acknowledgment and confirmation that maintains the conversation , which does not appear in written forms .", "label": "", "metadata": {}, "score": "62.278725"}
{"text": "3 is a system diagram of the speech translation system of an embodiment of the present invention .The STS of an embodiment is a system that performs speech - to - speech translation for use in facilitating communication between individuals that do not speak the same language , but is not so limited .", "label": "", "metadata": {}, "score": "62.37637"}
{"text": "3 is a system diagram of the speech translation system of an embodiment of the present invention .The STS of an embodiment is a system that performs speech - to - speech translation for use in facilitating communication between individuals that do not speak the same language , but is not so limited .", "label": "", "metadata": {}, "score": "62.37637"}
{"text": "3 is a system diagram of the speech translation system of an embodiment of the present invention .The STS of an embodiment is a system that performs speech - to - speech translation for use in facilitating communication between individuals that do not speak the same language , but is not so limited .", "label": "", "metadata": {}, "score": "62.37637"}
{"text": "3 is a system diagram of the speech translation system of an embodiment of the present invention .The STS of an embodiment is a system that performs speech - to - speech translation for use in facilitating communication between individuals that do not speak the same language , but is not so limited .", "label": "", "metadata": {}, "score": "62.37637"}
{"text": "3 is a system diagram of the speech translation system of an embodiment of the present invention .The STS of an embodiment is a system that performs speech - to - speech translation for use in facilitating communication between individuals that do not speak the same language , but is not so limited .", "label": "", "metadata": {}, "score": "62.37637"}
{"text": "A detailed or best match 1110 is performed as an optimization procedure over operations to insert , delete or join ( match up ) 1112 parts of the syntactic representation .This provides a flexible way to match that does not require all parts of the structure to be accounted for since insertions and deletions are possible .", "label": "", "metadata": {}, "score": "62.588852"}
{"text": "A detailed or best match 1110 is performed as an optimization procedure over operations to insert , delete or join ( match up ) 1112 parts of the syntactic representation .This provides a flexible way to match that does not require all parts of the structure to be accounted for since insertions and deletions are possible .", "label": "", "metadata": {}, "score": "62.588852"}
{"text": "A detailed or best match 1110 is performed as an optimization procedure over operations to insert , delete or join ( match up ) 1112 parts of the syntactic representation .This provides a flexible way to match that does not require all parts of the structure to be accounted for since insertions and deletions are possible .", "label": "", "metadata": {}, "score": "62.588852"}
{"text": "A detailed or best match 1110 is performed as an optimization procedure over operations to insert , delete or join ( match up ) 1112 parts of the syntactic representation .This provides a flexible way to match that does not require all parts of the structure to be accounted for since insertions and deletions are possible .", "label": "", "metadata": {}, "score": "62.588852"}
{"text": "A detailed or best match 1110 is performed as an optimization procedure over operations to insert , delete or join ( match up ) 1112 parts of the syntactic representation .This provides a flexible way to match that does not require all parts of the structure to be accounted for since insertions and deletions are possible .", "label": "", "metadata": {}, "score": "62.588852"}
{"text": "Fast and Scalable HPSG Parsing .Traitement automatique des langues ( TAL ) .Association pour le Traitement Automatique des Langues .Contents .Overview .Enju is a syntactic parser for English .With a wide - coverage probabilistic HPSG grammar [ 1 - 7 ] and an efficient parsing algorithm [ 8 - 11 ] , this parser can effectively analyze syntactic / semantic structures of English sentences and provide a user with phrase structures and predicate - argument structures .", "label": "", "metadata": {}, "score": "62.593464"}
{"text": "2 is a computer system memory hosting the speech translation system of an embodiment of the present invention .FIG .3 is a system diagram of the speech translation system of an embodiment of the present invention .FIG .4 is a flowchart of source language speech recognition of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "62.811333"}
{"text": "2 is a computer system memory hosting the speech translation system of an embodiment of the present invention .FIG .3 is a system diagram of the speech translation system of an embodiment of the present invention .FIG .4 is a flowchart of source language speech recognition of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "62.811333"}
{"text": "2 is a computer system memory hosting the speech translation system of an embodiment of the present invention .FIG .3 is a system diagram of the speech translation system of an embodiment of the present invention .FIG .4 is a flowchart of source language speech recognition of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "62.811333"}
{"text": "The adapted feature structure representation contains two sub - feature structures for corresponding source language expression and target language expressions .Any correspondence between constituents and the source language expression and the target language expression is indicated by indices .The syntactic analyzer of an embodiment of the present invention is implemented in a parser having a mechanism to manipulate feature structure representations .", "label": "", "metadata": {}, "score": "62.889893"}
{"text": "The adapted feature structure representation contains two sub - feature structures for corresponding source language expression and target language expressions .Any correspondence between constituents and the source language expression and the target language expression is indicated by indices .The syntactic analyzer of an embodiment of the present invention is implemented in a parser having a mechanism to manipulate feature structure representations .", "label": "", "metadata": {}, "score": "62.889893"}
{"text": "The adapted feature structure representation contains two sub - feature structures for corresponding source language expression and target language expressions .Any correspondence between constituents and the source language expression and the target language expression is indicated by indices .The syntactic analyzer of an embodiment of the present invention is implemented in a parser having a mechanism to manipulate feature structure representations .", "label": "", "metadata": {}, "score": "62.889893"}
{"text": "The adapted feature structure representation contains two sub - feature structures for corresponding source language expression and target language expressions .Any correspondence between constituents and the source language expression and the target language expression is indicated by indices .The syntactic analyzer of an embodiment of the present invention is implemented in a parser having a mechanism to manipulate feature structure representations .", "label": "", "metadata": {}, "score": "62.889893"}
{"text": "The adapted feature structure representation contains two sub - feature structures for corresponding source language expression and target language expressions .Any correspondence between constituents and the source language expression and the target language expression is indicated by indices .The syntactic analyzer of an embodiment of the present invention is implemented in a parser having a mechanism to manipulate feature structure representations .", "label": "", "metadata": {}, "score": "62.889893"}
{"text": "This paper shows that decision trees can be used to improve the performance of casebased learning ( CBL ) systems .We introduce a performance task for machine learning systems called semi - flexible prediction that lies between the classification task performed by decision tree algorithms and the flexib ... \" .", "label": "", "metadata": {}, "score": "62.937515"}
{"text": "This paper shows that decision trees can be used to improve the performance of casebased learning ( CBL ) systems .We introduce a performance task for machine learning systems called semi - flexible prediction that lies between the classification task performed by decision tree algorithms and the flexib ... \" .", "label": "", "metadata": {}, "score": "62.937515"}
{"text": "An apparatus for spoken language translation comprising : . at least one processor ( 102 ) ; . an input ( 125 ) coupled to the at least one processor , the input capable of receiving at least one speech input , the at least one processor configured to translate the at least one speech input by , . generating ( 402 ) a plurality of recognition hypotheses in response to the at least one speech input taking into consideration a potential variability in the at least one speech input ; . receiving information indicative of ( 1802 ) a best hypothesis from the plurality of recognition hypotheses ; . adapting ( 1810 ) hypothesis generation in response to the best hypothesis ; . an output ( 126 ) coupled to the at least one processor , the output capable of providing the best hypothesis .", "label": "", "metadata": {}, "score": "62.940033"}
{"text": "Virtuele Gramatica 's en Creatieve Algoritmen , .Gramma / TTT 1(1 ) .Sinclair , J. ( 1992 )The automatic analysis of corpora .In J. Svartvik .( Ed . )Directions in Corpus Linguistics .Proceeedings of Nobel .", "label": "", "metadata": {}, "score": "63.03154"}
{"text": "To . perform the evaluation , for the parser generated trees ( called here . answers ) and the manually constructed trees ( called keys ) dependency .trees are generated and compared on a word - by- word basis .Very . important , a selective evaluation is also possible : one can measure .", "label": "", "metadata": {}, "score": "63.113712"}
{"text": "The method of claim 27 , further comprising : . receiving an acceptance of the revised version of the best hypothesis in the source language ; and .presenting an output that is representative of the best hypothesis in a target language .", "label": "", "metadata": {}, "score": "63.20071"}
{"text": "For instance , sentences of the form .subject- intransitive verb are rather infrequent in English corpus , . contrary to what can be found in some linguistics textbooks .Chapter 3 .Bank of English and beyond .The aim of this paper is twofold .", "label": "", "metadata": {}, "score": "63.32019"}
{"text": "In a language translation system , a method for providing a guide for a user .Method and apparatus for interactive source language expression recognition and alternative hypothesis presentation and selection US 6282507 B1 .Abstract .In a language translation system , a method for providing a guide for a user .", "label": "", "metadata": {}, "score": "63.403847"}
{"text": "Consequently , a change of domain only affects the lexicon and example database , but the embodiment is not so limited .FIG .10 shows an example of a bilingual example data representation 1000 of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "63.46345"}
{"text": "Consequently , a change of domain only affects the lexicon and example database , but the embodiment is not so limited .FIG .10 shows an example of a bilingual example data representation 1000 of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "63.46345"}
{"text": "Consequently , a change of domain only affects the lexicon and example database , but the embodiment is not so limited .FIG .10 shows an example of a bilingual example data representation 1000 of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "63.46345"}
{"text": "Consequently , a change of domain only affects the lexicon and example database , but the embodiment is not so limited .FIG .10 shows an example of a bilingual example data representation 1000 of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "63.46345"}
{"text": "Consequently , a change of domain only affects the lexicon and example database , but the embodiment is not so limited .FIG .10 shows an example of a bilingual example data representation 1000 of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "63.46345"}
{"text": "using the correction to generate a best hypothesis in the source language in response to a subsequent input that is similar to the input .The method of claim 27 , wherein the input received is spoken words .The method of claim 27 , wherein the input received is an output of a keyboard device .", "label": "", "metadata": {}, "score": "63.50724"}
{"text": "the English Constraint Grammar ( ENGCG ) system used for annotating . corpora for compiling the second edition of the Collins COBUILD .Dictionary of English , and also the methodology adopted taking into .consideration the huge amount of data that was to be dealt with ; thus , . manual inspection was possible only for some random fragments of the . data and automatic methods were created for monitoring them .", "label": "", "metadata": {}, "score": "63.567703"}
{"text": "This matching procedure is implemented using a dynamic programming algorithm that minimizes the overall match cost , which is defined in a recursive manner over arcs in the trees .The three possible actions ( insert , delete , join ) incur costs that depend on the labels of the arcs , the costs for the node values of the arcs , and costs based on feature - values and thesaurus - based semantic similarity for words .", "label": "", "metadata": {}, "score": "63.764305"}
{"text": "This matching procedure is implemented using a dynamic programming algorithm that minimizes the overall match cost , which is defined in a recursive manner over arcs in the trees .The three possible actions ( insert , delete , join ) incur costs that depend on the labels of the arcs , the costs for the node values of the arcs , and costs based on feature - values and thesaurus - based semantic similarity for words .", "label": "", "metadata": {}, "score": "63.764305"}
{"text": "This matching procedure is implemented using a dynamic programming algorithm that minimizes the overall match cost , which is defined in a recursive manner over arcs in the trees .The three possible actions ( insert , delete , join ) incur costs that depend on the labels of the arcs , the costs for the node values of the arcs , and costs based on feature - values and thesaurus - based semantic similarity for words .", "label": "", "metadata": {}, "score": "63.764305"}
{"text": "This matching procedure is implemented using a dynamic programming algorithm that minimizes the overall match cost , which is defined in a recursive manner over arcs in the trees .The three possible actions ( insert , delete , join ) incur costs that depend on the labels of the arcs , the costs for the node values of the arcs , and costs based on feature - values and thesaurus - based semantic similarity for words .", "label": "", "metadata": {}, "score": "63.764305"}
{"text": "This matching procedure is implemented using a dynamic programming algorithm that minimizes the overall match cost , which is defined in a recursive manner over arcs in the trees .The three possible actions ( insert , delete , join ) incur costs that depend on the labels of the arcs , the costs for the node values of the arcs , and costs based on feature - values and thesaurus - based semantic similarity for words .", "label": "", "metadata": {}, "score": "63.764305"}
{"text": "The step of recursively rebuilding comprises marking each of the nodes for which the feature structures are to be rebuilt .At least one log is maintained comprising each of the nodes for which the feature structure is to be rebuilt .", "label": "", "metadata": {}, "score": "63.847878"}
{"text": "The step of recursively rebuilding comprises marking each of the nodes for which the feature structures are to be rebuilt .At least one log is maintained comprising each of the nodes for which the feature structure is to be rebuilt .", "label": "", "metadata": {}, "score": "63.847878"}
{"text": "The step of recursively rebuilding comprises marking each of the nodes for which the feature structures are to be rebuilt .At least one log is maintained comprising each of the nodes for which the feature structure is to be rebuilt .", "label": "", "metadata": {}, "score": "63.847878"}
{"text": "The step of recursively rebuilding comprises marking each of the nodes for which the feature structures are to be rebuilt .At least one log is maintained comprising each of the nodes for which the feature structure is to be rebuilt .", "label": "", "metadata": {}, "score": "63.847878"}
{"text": "The step of recursively rebuilding comprises marking each of the nodes for which the feature structures are to be rebuilt .At least one log is maintained comprising each of the nodes for which the feature structure is to be rebuilt .", "label": "", "metadata": {}, "score": "63.847878"}
{"text": "In a language translation system , a method for providing a guide for a user , comprising : . receiving an input that is representative of at least one word in a source language ; . generating at least one recognition hypothesis in the source language in response to the input ; . generating at least one recognition hypothesis in a target language in response to the input ; . presenting the at least one recognition hypothesis in the source language and the at least one recognition hypothesis in a target language as a list of pairs ordered according to likelihood of being correct ; . accepting a choice of one pair of the list of pairs from a user , wherein a chosen pair comprises a best hypothesis in the source language and a best hypothesis in the target language ; . indicating a portion of the best hypothesis in the source language to the user , wherein the portion has at least one alternative expression ; . presenting the at least one alternative expression to the user ; . accepting a choice of one of the at least one alternative expressions ; and .", "label": "", "metadata": {}, "score": "63.858418"}
{"text": "Furthermore , it provides for quick access to relevant individual features ( e.g. root , grammatical category ) .The AIM of an embodiment of the present invention comprises English morphological rules comprising rules for verbs , rules for nouns , rules for adjectives , rules for adverbs , rules for auxiliaries and modals , rules for determiners , and rules for pronouns .", "label": "", "metadata": {}, "score": "63.87829"}
{"text": "LINGUIST List 15.1589 .Tue May 18 2004 .What follows is a review or discussion note contributed to our Book Discussion Forum .We expect discussions to be informal and interactive ; and the author of the book discussed is cordially invited to join in .", "label": "", "metadata": {}, "score": "63.95249"}
{"text": "Difficult maintenance results when the rules become more interdependent as the coverage expands and it becomes difficult to improve the performance .An embodiment of the present invention addresses the problem of how much syntactic analysis should be performed and how the syntactic analysis should be integrated with example - based machine translation so that the advantages of syntactic analysis and example - based processing are maximized without suffering from the flaws of rule - based systems .", "label": "", "metadata": {}, "score": "63.969208"}
{"text": "Difficult maintenance results when the rules become more interdependent as the coverage expands and it becomes difficult to improve the performance .An embodiment of the present invention addresses the problem of how much syntactic analysis should be performed and how the syntactic analysis should be integrated with example - based machine translation so that the advantages of syntactic analysis and example - based processing are maximized without suffering from the flaws of rule - based systems .", "label": "", "metadata": {}, "score": "63.969208"}
{"text": "Difficult maintenance results when the rules become more interdependent as the coverage expands and it becomes difficult to improve the performance .An embodiment of the present invention addresses the problem of how much syntactic analysis should be performed and how the syntactic analysis should be integrated with example - based machine translation so that the advantages of syntactic analysis and example - based processing are maximized without suffering from the flaws of rule - based systems .", "label": "", "metadata": {}, "score": "63.969208"}
{"text": "Difficult maintenance results when the rules become more interdependent as the coverage expands and it becomes difficult to improve the performance .An embodiment of the present invention addresses the problem of how much syntactic analysis should be performed and how the syntactic analysis should be integrated with example - based machine translation so that the advantages of syntactic analysis and example - based processing are maximized without suffering from the flaws of rule - based systems .", "label": "", "metadata": {}, "score": "63.969208"}
{"text": "Difficult maintenance results when the rules become more interdependent as the coverage expands and it becomes difficult to improve the performance .An embodiment of the present invention addresses the problem of how much syntactic analysis should be performed and how the syntactic analysis should be integrated with example - based machine translation so that the advantages of syntactic analysis and example - based processing are maximized without suffering from the flaws of rule - based systems .", "label": "", "metadata": {}, "score": "63.969208"}
{"text": "FIG .21 is an Analyzer for Inflectional Morphology ( AIM ) 2100 of an embodiment of the present invention .The AIM 2100 comprises two main modules , a tokenizer 2102 and a morphological analyzer 2104 , but is not so limited .", "label": "", "metadata": {}, "score": "64.05958"}
{"text": "FIG .21 is an Analyzer for Inflectional Morphology ( AIM ) 2100 of an embodiment of the present invention .The AIM 2100 comprises two main modules , a tokenizer 2102 and a morphological analyzer 2104 , but is not so limited .", "label": "", "metadata": {}, "score": "64.05958"}
{"text": "FIG .21 is an Analyzer for Inflectional Morphology ( AIM ) 2100 of an embodiment of the present invention .The AIM 2100 comprises two main modules , a tokenizer 2102 and a morphological analyzer 2104 , but is not so limited .", "label": "", "metadata": {}, "score": "64.05958"}
{"text": "FIG .21 is an Analyzer for Inflectional Morphology ( AIM ) 2100 of an embodiment of the present invention .The AIM 2100 comprises two main modules , a tokenizer 2102 and a morphological analyzer 2104 , but is not so limited .", "label": "", "metadata": {}, "score": "64.05958"}
{"text": "FIG .21 is an Analyzer for Inflectional Morphology ( AIM ) 2100 of an embodiment of the present invention .The AIM 2100 comprises two main modules , a tokenizer 2102 and a morphological analyzer 2104 , but is not so limited .", "label": "", "metadata": {}, "score": "64.05958"}
{"text": "Phonetic and phonological knowledge concerns how words are related to the sounds that realize them .Such knowledge is crucial for speech based systems .Morphological knowledge concerns how words are constructed from more basic units called morphemes .A morpheme is the primitive unit in a language , for example , the word friendly is derivable from the meaning of the noun friend and the suffix -ly , which transforms a noun into an adjective .", "label": "", "metadata": {}, "score": "64.126976"}
{"text": "Phonetic and phonological knowledge concerns how words are related to the sounds that realize them .Such knowledge is crucial for speech based systems .Morphological knowledge concerns how words are constructed from more basic units called morphemes .A morpheme is the primitive unit in a language , for example , the word friendly is derivable from the meaning of the noun friend and the suffix - ly , which transforms a noun into an adjective .", "label": "", "metadata": {}, "score": "64.126976"}
{"text": "Phonetic and phonological knowledge concerns how words are related to the sounds that realize them .Such knowledge is crucial for speech based systems .Morphological knowledge concerns how words are constructed from more basic units called morphemes .A morpheme is the primitive unit in a language , for example , the word friendly is derivable from the meaning of the noun friend and the suffix -ly , which transforms a noun into an adjective .", "label": "", "metadata": {}, "score": "64.126976"}
{"text": "Phonetic and phonological knowledge concerns how words are related to the sounds that realize them .Such knowledge is crucial for speech based systems .Morphological knowledge concerns how words are constructed from more basic units called morphemes .A morpheme is the primitive unit in a language , for example , the word friendly is derivable from the meaning of the noun friend and the suffix -ly , which transforms a noun into an adjective .", "label": "", "metadata": {}, "score": "64.126976"}
{"text": "Phonetic and phonological knowledge concerns how words are related to the sounds that realize them .Such knowledge is crucial for speech based systems .Morphological knowledge concerns how words are constructed from more basic units called morphemes .A morpheme is the primitive unit in a language , for example , the word friendly is derivable from the meaning of the noun friend and the suffix -ly , which transforms a noun into an adjective .", "label": "", "metadata": {}, "score": "64.126976"}
{"text": "A Generalized Left - to - Right ( Generalized LR or GLR ) parsing algorithm was developed as an extension of the Left - to - Right ( LR ) parsing algorithm to provide for efficient parsing of natural language .The graph - structured stack was also introduced for handling ambiguities in natural language .", "label": "", "metadata": {}, "score": "64.17938"}
{"text": "A Generalized Left - to - Right ( Generalized LR or GLR ) parsing algorithm was developed as an extension of the Left - to - Right ( LR ) parsing algorithm to provide for efficient parsing of natural language .The graph - structured stack was also introduced for handling ambiguities in natural language .", "label": "", "metadata": {}, "score": "64.17938"}
{"text": "A Generalized Left - to - Right ( Generalized LR or GLR ) parsing algorithm was developed as an extension of the Left - to - Right ( LR ) parsing algorithm to provide for efficient parsing of natural language .The graph - structured stack was also introduced for handling ambiguities in natural language .", "label": "", "metadata": {}, "score": "64.17938"}
{"text": "A Generalized Left - to - Right ( Generalized LR or GLR ) parsing algorithm was developed as an extension of the Left - to - Right ( LR ) parsing algorithm to provide for efficient parsing of natural language .The graph - structured stack was also introduced for handling ambiguities in natural language .", "label": "", "metadata": {}, "score": "64.17938"}
{"text": "A Generalized Left - to - Right ( Generalized LR or GLR ) parsing algorithm was developed as an extension of the Left - to - Right ( LR ) parsing algorithm to provide for efficient parsing of natural language .The graph - structured stack was also introduced for handling ambiguities in natural language .", "label": "", "metadata": {}, "score": "64.17938"}
{"text": "The problem with this parser is that it is implemented in List Processing ( LISP ) , which is not efficient for practical use .Furthermore , its feature structure manipulations allow only unique slot - names , which is not suitable for shallow syntactic analysis where multiple slots are routinely needed .", "label": "", "metadata": {}, "score": "64.51072"}
{"text": "The problem with this parser is that it is implemented in List Processing ( LISP ) , which is not efficient for practical use .Furthermore , its feature structure manipulations allow only unique slot - names , which is not suitable for shallow syntactic analysis where multiple slots are routinely needed .", "label": "", "metadata": {}, "score": "64.51072"}
{"text": "The problem with this parser is that it is implemented in List Processing ( LISP ) , which is not efficient for practical use .Furthermore , its feature structure manipulations allow only unique slot - names , which is not suitable for shallow syntactic analysis where multiple slots are routinely needed .", "label": "", "metadata": {}, "score": "64.51072"}
{"text": "The problem with this parser is that it is implemented in List Processing ( LISP ) , which is not efficient for practical use .Furthermore , its feature structure manipulations allow only unique slot - names , which is not suitable for shallow syntactic analysis where multiple slots are routinely needed .", "label": "", "metadata": {}, "score": "64.51072"}
{"text": "The problem with this parser is that it is implemented in List Processing ( LISP ) , which is not efficient for practical use .Furthermore , its feature structure manipulations allow only unique slot - names , which is not suitable for shallow syntactic analysis where multiple slots are routinely needed .", "label": "", "metadata": {}, "score": "64.51072"}
{"text": "The level of shallow syntactic analysis performed by an embodiment of the present invention is very robust and general as it does not depend on particular domains or situations .The shallow syntactic analysis performed in an embodiment of the present invention is performed both on the example data and on the input string .", "label": "", "metadata": {}, "score": "64.545425"}
{"text": "The level of shallow syntactic analysis performed by an embodiment of the present invention is very robust and general as it does not depend on particular domains or situations .The shallow syntactic analysis performed in an embodiment of the present invention is performed both on the example data and on the input string .", "label": "", "metadata": {}, "score": "64.545425"}
{"text": "The level of shallow syntactic analysis performed by an embodiment of the present invention is very robust and general as it does not depend on particular domains or situations .The shallow syntactic analysis performed in an embodiment of the present invention is performed both on the example data and on the input string .", "label": "", "metadata": {}, "score": "64.545425"}
{"text": "The level of shallow syntactic analysis performed by an embodiment of the present invention is very robust and general as it does not depend on particular domains or situations .The shallow syntactic analysis performed in an embodiment of the present invention is performed both on the example data and on the input string .", "label": "", "metadata": {}, "score": "64.545425"}
{"text": "The level of shallow syntactic analysis performed by an embodiment of the present invention is very robust and general as it does not depend on particular domains or situations .The shallow syntactic analysis performed in an embodiment of the present invention is performed both on the example data and on the input string .", "label": "", "metadata": {}, "score": "64.545425"}
{"text": "The efficiency is significantly improved as the possibility of storing dictionary feature structures in read - only memory ( ROM ) reduces the amount of random access memory ( RAM ) required for working memory .Furthermore , there is a possibility of reducing the ROM size by optimizing the feature structure representations .", "label": "", "metadata": {}, "score": "64.5459"}
{"text": "The efficiency is significantly improved as the possibility of storing dictionary feature structures in read - only memory ( ROM ) reduces the amount of random access memory ( RAM ) required for working memory .Furthermore , there is a possibility of reducing the ROM size by optimizing the feature structure representations .", "label": "", "metadata": {}, "score": "64.5459"}
{"text": "The efficiency is significantly improved as the possibility of storing dictionary feature structures in read - only memory ( ROM ) reduces the amount of random access memory ( RAM ) required for working memory .Furthermore , there is a possibility of reducing the ROM size by optimizing the feature structure representations .", "label": "", "metadata": {}, "score": "64.5459"}
{"text": "The efficiency is significantly improved as the possibility of storing dictionary feature structures in read - only memory ( ROM ) reduces the amount of random access memory ( RAM ) required for working memory .Furthermore , there is a possibility of reducing the ROM size by optimizing the feature structure representations .", "label": "", "metadata": {}, "score": "64.5459"}
{"text": "It will be evident , however , to one skilled in the art that the present invention may be practiced without these specific details .In other instances , well known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the present invention .", "label": "", "metadata": {}, "score": "64.6442"}
{"text": "It will be evident , however , to one skilled in the art that the present invention may be practiced without these specific details .In other instances , well known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the present invention .", "label": "", "metadata": {}, "score": "64.6442"}
{"text": "It will be evident , however , to one skilled in the art that the present invention may be practiced without these specific details .In other instances , well known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the present invention .", "label": "", "metadata": {}, "score": "64.6442"}
{"text": "It will be evident , however , to one skilled in the art that the present invention may be practiced without these specific details .In other instances , well known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the present invention .", "label": "", "metadata": {}, "score": "64.6442"}
{"text": "It will be evident , however , to one skilled in the art that the present invention may be practiced without these specific details .In other instances , well known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the present invention .", "label": "", "metadata": {}, "score": "64.6442"}
{"text": "( PERSON 3RD ) .( TENSE PRES ) .( NUMBER SING ) ) .( ( ROOT \" leaf \" ) .( CAT NOUN ) .( NUMBER PLURAL ) ) ) .The dictionary format of an AIM of an embodiment of the present invention provides three different types of entries wherein a minimum to a large amount of information may be encoded .", "label": "", "metadata": {}, "score": "64.83539"}
{"text": "The system of claim 40 , further comprising : . a means for presenting the plurality of recognition hypotheses ; . a means for translating the at least one speech input in response to the best hypothesis ; and .a means for synthesizing at least one speech output in response to the translated at least one speech input .", "label": "", "metadata": {}, "score": "64.84558"}
{"text": "The rules for adjectives of an embodiment comprise default rules , rules for adjectives ending in \" e \" , rules for adjectives ending in \" y \" , rules for consonant doubling , and rules for irregular adjectives , but are not so limited .", "label": "", "metadata": {}, "score": "64.9075"}
{"text": "The rules for adjectives of an embodiment comprise default rules , rules for adjectives ending in \" e \" , rules for adjectives ending in \" y \" , rules for consonant doubling , and rules for irregular adjectives , but are not so limited .", "label": "", "metadata": {}, "score": "64.9075"}
{"text": "The rules for adjectives of an embodiment comprise default rules , rules for adjectives ending in \" e \" , rules for adjectives ending in \" y \" , rules for consonant doubling , and rules for irregular adjectives , but are not so limited .", "label": "", "metadata": {}, "score": "64.9075"}
{"text": "The rules for adjectives of an embodiment comprise default rules , rules for adjectives ending in \" e \" , rules for adjectives ending in \" y \" , rules for consonant doubling , and rules for irregular adjectives , but are not so limited .", "label": "", "metadata": {}, "score": "64.9075"}
{"text": "For instance , with spoken input the system has to deal with uncertainty .In written language the system knows exactly what words are to be processed .With spoken language it only has a guess at what was said .In addition , spoken language is structurally quite different than written language .", "label": "", "metadata": {}, "score": "65.02612"}
{"text": "The third problem with this approach is that for a match to be found , all arcs in the dependency tree are required to be matched .This means that it is not possible to delete or insert words .This kind of precise match is not useful for translating spoken language .", "label": "", "metadata": {}, "score": "65.210266"}
{"text": "The third problem with this approach is that for a match to be found , all arcs in the dependency tree are required to be matched .This means that it is not possible to delete or insert words .This kind of precise match is not useful for translating spoken language .", "label": "", "metadata": {}, "score": "65.210266"}
{"text": "The third problem with this approach is that for a match to be found , all arcs in the dependency tree are required to be matched .This means that it is not possible to delete or insert words .This kind of precise match is not useful for translating spoken language .", "label": "", "metadata": {}, "score": "65.210266"}
{"text": "The third problem with this approach is that for a match to be found , all arcs in the dependency tree are required to be matched .This means that it is not possible to delete or insert words .This kind of precise match is not useful for translating spoken language .", "label": "", "metadata": {}, "score": "65.210266"}
{"text": "The third problem with this approach is that for a match to be found , all arcs in the dependency tree are required to be matched .This means that it is not possible to delete or insert words .This kind of precise match is not useful for translating spoken language .", "label": "", "metadata": {}, "score": "65.210266"}
{"text": "question formulated above receives an affirmative answer if the final .aim of the corpus is not a study of the parser performance , but of .language variation .GERMAN TREEBANKS .Chapter 5 .Syntactic Annotation of a German Newspaper Corpus .", "label": "", "metadata": {}, "score": "65.33754"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings , in which like references indicate similar elements and in which : .FIG .1 is a computer system hosting the speech translation system ( STS ) of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "65.392975"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings , in which like references indicate similar elements and in which : .FIG .1 is a computer system hosting the speech translation system ( STS ) of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "65.392975"}
{"text": "The feature structure can be generated either in shift action 2706 or reduce action 2708 , but the embodiment is not so limited .When a shift action 2706 is performed , a new parse node is created for the new shifted symbol .", "label": "", "metadata": {}, "score": "65.41396"}
{"text": "The feature structure can be generated either in shift action 2706 or reduce action 2708 , but the embodiment is not so limited .When a shift action 2706 is performed , a new parse node is created for the new shifted symbol .", "label": "", "metadata": {}, "score": "65.41396"}
{"text": "The feature structure can be generated either in shift action 2706 or reduce action 2708 , but the embodiment is not so limited .When a shift action 2706 is performed , a new parse node is created for the new shifted symbol .", "label": "", "metadata": {}, "score": "65.41396"}
{"text": "The feature structure can be generated either in shift action 2706 or reduce action 2708 , but the embodiment is not so limited .When a shift action 2706 is performed , a new parse node is created for the new shifted symbol .", "label": "", "metadata": {}, "score": "65.41396"}
{"text": "The feature structure can be generated either in shift action 2706 or reduce action 2708 , but the embodiment is not so limited .When a shift action 2706 is performed , a new parse node is created for the new shifted symbol .", "label": "", "metadata": {}, "score": "65.41396"}
{"text": "Therefore , the STS of an embodiment has very high translation accuracy , accuracy that greatly improves the usefulness as a communication aid .The STS of an embodiment of the present invention performs speech translation by integrating two types of processing .", "label": "", "metadata": {}, "score": "65.47507"}
{"text": "Therefore , the STS of an embodiment has very high translation accuracy , accuracy that greatly improves the usefulness as a communication aid .The STS of an embodiment of the present invention performs speech translation by integrating two types of processing .", "label": "", "metadata": {}, "score": "65.47507"}
{"text": "Therefore , the STS of an embodiment has very high translation accuracy , accuracy that greatly improves the usefulness as a communication aid .The STS of an embodiment of the present invention performs speech translation by integrating two types of processing .", "label": "", "metadata": {}, "score": "65.47507"}
{"text": "Therefore , the STS of an embodiment has very high translation accuracy , accuracy that greatly improves the usefulness as a communication aid .The STS of an embodiment of the present invention performs speech translation by integrating two types of processing .", "label": "", "metadata": {}, "score": "65.47507"}
{"text": "Therefore , the STS of an embodiment has very high translation accuracy , accuracy that greatly improves the usefulness as a communication aid .The STS of an embodiment of the present invention performs speech translation by integrating two types of processing .", "label": "", "metadata": {}, "score": "65.47507"}
{"text": "The method of claim 1 , further comprising : . receiving an acceptance of the revised version of the best hypothesis in the source language ; and .presenting an output that is representative of the revised version of the best hypothesis in a target language .", "label": "", "metadata": {}, "score": "65.53537"}
{"text": "The safe ambiguity packing 2704 of an embodiment of the present invention comprises retaining log information during parsing , and rebuilding the feature structure of nodes as needed when parsing is finished , but is not so limited .In retaining log information , the original data structure of a parse node is augmented to incorporate log information that indicates how the feature structure of the parse node has been constructed .", "label": "", "metadata": {}, "score": "65.80076"}
{"text": "The safe ambiguity packing 2704 of an embodiment of the present invention comprises retaining log information during parsing , and rebuilding the feature structure of nodes as needed when parsing is finished , but is not so limited .In retaining log information , the original data structure of a parse node is augmented to incorporate log information that indicates how the feature structure of the parse node has been constructed .", "label": "", "metadata": {}, "score": "65.80076"}
{"text": "The safe ambiguity packing 2704 of an embodiment of the present invention comprises retaining log information during parsing , and rebuilding the feature structure of nodes as needed when parsing is finished , but is not so limited .In retaining log information , the original data structure of a parse node is augmented to incorporate log information that indicates how the feature structure of the parse node has been constructed .", "label": "", "metadata": {}, "score": "65.80076"}
{"text": "The safe ambiguity packing 2704 of an embodiment of the present invention comprises retaining log information during parsing , and rebuilding the feature structure of nodes as needed when parsing is finished , but is not so limited .In retaining log information , the original data structure of a parse node is augmented to incorporate log information that indicates how the feature structure of the parse node has been constructed .", "label": "", "metadata": {}, "score": "65.80076"}
{"text": "The safe ambiguity packing 2704 of an embodiment of the present invention comprises retaining log information during parsing , and rebuilding the feature structure of nodes as needed when parsing is finished , but is not so limited .In retaining log information , the original data structure of a parse node is augmented to incorporate log information that indicates how the feature structure of the parse node has been constructed .", "label": "", "metadata": {}, "score": "65.80076"}
{"text": "Another alternate embodiment has multiple processors hosting the speech recognition module , the translation module , and the models .For still another embodiment , a number of different model devices may be hosted on a single processor .The present invention may be embodied in a portable unit that is easily carried by a user .", "label": "", "metadata": {}, "score": "65.87802"}
{"text": "Another alternate embodiment has multiple processors hosting the speech recognition module , the translation module , and the models .For still another embodiment , a number of different model devices may be hosted on a single processor .The present invention may be embodied in a portable unit that is easily carried by a user .", "label": "", "metadata": {}, "score": "65.87802"}
{"text": "Another alternate embodiment has multiple processors hosting the speech recognition module , the translation module , and the models .For still another embodiment , a number of different model devices may be hosted on a single processor .The present invention may be embodied in a portable unit that is easily carried by a user .", "label": "", "metadata": {}, "score": "65.87802"}
{"text": "Another alternate embodiment has multiple processors hosting the speech recognition module , the translation module , and the models .For still another embodiment , a number of different model devices may be hosted on a single processor .The present invention may be embodied in a portable unit that is easily carried by a user .", "label": "", "metadata": {}, "score": "65.87802"}
{"text": "Another alternate embodiment has multiple processors hosting the speech recognition module , the translation module , and the models .For still another embodiment , a number of different model devices may be hosted on a single processor .The present invention may be embodied in a portable unit that is easily carried by a user .", "label": "", "metadata": {}, "score": "65.87802"}
{"text": "The system of claim 43 , wherein a separation is provided between domain - independent linguistic knowledge and domain - dependent linguistic knowledge .The system of claim 43 , further comprising a means for performing statistical processing to resolve lexical ambiguities and local ambiguities .", "label": "", "metadata": {}, "score": "65.91145"}
{"text": "combining entries of the example database based on the at least one syntactic constituent .The method of claim 1 , wherein the example database is a multilingual example database , and wherein the expression pair is a multilingual expression group .", "label": "", "metadata": {}, "score": "66.128845"}
{"text": "When a reduce action 2708 is performed , the set of feature structure actions associated with the reduce action is performed first .If none of the feature structure actions indicates failure , then a new parse node is created and associated with the resulting feature structure .", "label": "", "metadata": {}, "score": "66.16329"}
{"text": "When a reduce action 2708 is performed , the set of feature structure actions associated with the reduce action is performed first .If none of the feature structure actions indicates failure , then a new parse node is created and associated with the resulting feature structure .", "label": "", "metadata": {}, "score": "66.16329"}
{"text": "When a reduce action 2708 is performed , the set of feature structure actions associated with the reduce action is performed first .If none of the feature structure actions indicates failure , then a new parse node is created and associated with the resulting feature structure .", "label": "", "metadata": {}, "score": "66.16329"}
{"text": "When a reduce action 2708 is performed , the set of feature structure actions associated with the reduce action is performed first .If none of the feature structure actions indicates failure , then a new parse node is created and associated with the resulting feature structure .", "label": "", "metadata": {}, "score": "66.16329"}
{"text": "When a reduce action 2708 is performed , the set of feature structure actions associated with the reduce action is performed first .If none of the feature structure actions indicates failure , then a new parse node is created and associated with the resulting feature structure .", "label": "", "metadata": {}, "score": "66.16329"}
{"text": "Since these labels are very straightforward and few in number for each grammatical category , this scheme does not impose too much of a burden on the process of adding new entries to the dictionary .( 3 ) Entries that have irregular inflections : irregular inflections are represented as separate entries with an additional string - feature slot ( SURFACE ) that contains the surface form .", "label": "", "metadata": {}, "score": "66.27191"}
{"text": "Since these labels are very straightforward and few in number for each grammatical category , this scheme does not impose too much of a burden on the process of adding new entries to the dictionary .( 3 ) Entries that have irregular inflections : irregular inflections are represented as separate entries with an additional string - feature slot ( SURFACE ) that contains the surface form .", "label": "", "metadata": {}, "score": "66.27191"}
{"text": "Since these labels are very straightforward and few in number for each grammatical category , this scheme does not impose too much of a burden on the process of adding new entries to the dictionary .( 3 ) Entries that have irregular inflections : irregular inflections are represented as separate entries with an additional string - feature slot ( SURFACE ) that contains the surface form .", "label": "", "metadata": {}, "score": "66.27191"}
{"text": "The apparatus of claim 44 , wherein translating the recognized expression includes minimizing misrecognitions of the expression in the source language , wherein the misrecognitions result from factors comprising noise and speaker variation .The apparatus of claim 45 wherein the intermediate source language data structure comprises at least one word graph and at least one n - best list .", "label": "", "metadata": {}, "score": "66.28291"}
{"text": "The apparatus of claim 15 , wherein the syntactic analysis comprises generalizing at least one surface variation in the at least one input and the at least one example database , wherein efficiency of the spoken language translation is increased .The apparatus of claim 15 , wherein the at least one processor is further configured to identify by : . determining at least one syntactic constituent of the at least one input ; and .", "label": "", "metadata": {}, "score": "66.436295"}
{"text": "Each line in the output represents a predicate - argument relation between two words .For instance , the second line in the first example indicates that there is an \" ARG1 ( logical subject ) \" relation between the predicate \" run \" and the argument \" he \" .", "label": "", "metadata": {}, "score": "66.43891"}
{"text": "Each line in the output represents a predicate - argument relation between two words .For instance , the second line in the first example indicates that there is an \" ARG1 ( logical subject ) \" relation between the predicate \" run \" and the argument \" he \" .", "label": "", "metadata": {}, "score": "66.43891"}
{"text": "( ( ROOT \" saw \" ) .( CAT NOUN ) ) .A second example comprises input and output feature structures for one morphological split : .( TENSE PRES ) .( NUMBER SING ) ) ) .Input string : studied .", "label": "", "metadata": {}, "score": "66.731285"}
{"text": "( ( ROOT \" saw \" ) .( CAT NOUN ) ) .A second example comprises input and output feature structures for one morphological split : .( TENSE PRES ) .( NUMBER SING ) ) ) .Input string : studied .", "label": "", "metadata": {}, "score": "66.731285"}
{"text": "( ( ROOT \" saw \" ) .( CAT NOUN ) ) .A second example comprises input and output feature structures for one morphological split : .( TENSE PRES ) .( NUMBER SING ) ) ) .Input string : studied .", "label": "", "metadata": {}, "score": "66.731285"}
{"text": "The digitized speech signals are processed by at least one processor 208 using algorithms and data stored in the components 220 - 260 of the memory 200 .The speech recognition module 220 of an embodiment of the present invention comprises a speech recognizer 222 and a hypothesis construction module 224 , but is not so limited .", "label": "", "metadata": {}, "score": "66.79187"}
{"text": "The digitized speech signals are processed by at least one processor 208 using algorithms and data stored in the components 220 - 260 of the memory 200 .The speech recognition module 220 of an embodiment of the present invention comprises a speech recognizer 222 and a hypothesis construction module 224 , but is not so limited .", "label": "", "metadata": {}, "score": "66.79187"}
{"text": "The digitized speech signals are processed by at least one processor 208 using algorithms and data stored in the components 220 - 260 of the memory 200 .The speech recognition module 220 of an embodiment of the present invention comprises a speech recognizer 222 and a hypothesis construction module 224 , but is not so limited .", "label": "", "metadata": {}, "score": "66.79187"}
{"text": "The digitized speech signals are processed by at least one processor 208 using algorithms and data stored in the components 220 - 260 of the memory 200 .The speech recognition module 220 of an embodiment of the present invention comprises a speech recognizer 222 and a hypothesis construction module 224 , but is not so limited .", "label": "", "metadata": {}, "score": "66.79187"}
{"text": "The digitized speech signals are processed by at least one processor 208 using algorithms and data stored in the components 220 - 260 of the memory 200 .The speech recognition module 220 of an embodiment of the present invention comprises a speech recognizer 222 and a hypothesis construction module 224 , but is not so limited .", "label": "", "metadata": {}, "score": "66.79187"}
{"text": "presented in this paper is an abstract model , theory and tagset . independent , that can be instantiated in different ways , according to .the annotator 's approach and goal .This abstract model uses two .knowledge sources : Data Category Registry ( an inventory of data .", "label": "", "metadata": {}, "score": "66.85473"}
{"text": "The method of claim 1 , further comprising presenting a plurality of translations corresponding with the plurality of recognition hypotheses .The method of claim 1 , wherein the plurality of recognition hypotheses is ordered .The method of claim 1 , wherein the at least one speech input comprises spoken language comprising at least one source language .", "label": "", "metadata": {}, "score": "66.88162"}
{"text": "FIG .20 shows an entry 2000 that has an irregular inflection in an embodiment of the present invention .Having separate entries for each irregular form does add some complexity to dictionary maintenance , but the irregularly inflected forms are limited in number .", "label": "", "metadata": {}, "score": "67.2336"}
{"text": "FIG .20 shows an entry 2000 that has an irregular inflection in an embodiment of the present invention .Having separate entries for each irregular form does add some complexity to dictionary maintenance , but the irregularly inflected forms are limited in number .", "label": "", "metadata": {}, "score": "67.2336"}
{"text": "FIG .20 shows an entry 2000 that has an irregular inflection in an embodiment of the present invention .Having separate entries for each irregular form does add some complexity to dictionary maintenance , but the irregularly inflected forms are limited in number .", "label": "", "metadata": {}, "score": "67.2336"}
{"text": "The system of claim 40 , wherein the means for generating the plurality of recognition hypotheses comprises : . a means for assigning basic probabilities to at least one basic component of the at least one speech input using at least one language model ; and .", "label": "", "metadata": {}, "score": "67.24519"}
{"text": "26 is a flowchart for a method of parsing in a spoken language translation system of an embodiment of the present invention .Operation begins at step 2602 , at which at least one input is received comprising at least one input sentence or expression .", "label": "", "metadata": {}, "score": "67.24913"}
{"text": "26 is a flowchart for a method of parsing in a spoken language translation system of an embodiment of the present invention .Operation begins at step 2602 , at which at least one input is received comprising at least one input sentence or expression .", "label": "", "metadata": {}, "score": "67.24913"}
{"text": "26 is a flowchart for a method of parsing in a spoken language translation system of an embodiment of the present invention .Operation begins at step 2602 , at which at least one input is received comprising at least one input sentence or expression .", "label": "", "metadata": {}, "score": "67.24913"}
{"text": "26 is a flowchart for a method of parsing in a spoken language translation system of an embodiment of the present invention .Operation begins at step 2602 , at which at least one input is received comprising at least one input sentence or expression .", "label": "", "metadata": {}, "score": "67.24913"}
{"text": "26 is a flowchart for a method of parsing in a spoken language translation system of an embodiment of the present invention .Operation begins at step 2602 , at which at least one input is received comprising at least one input sentence or expression .", "label": "", "metadata": {}, "score": "67.24913"}
{"text": "the following facts : principles are partial , underspecified and match .unseen configurations , partial annotations are generated instead of . failure , the constraint solver cope with conflicting information .DISCUSSION .Although this was not the objective of the book , its first part can be . used as a textbook for those venturing to construct a treebank .", "label": "", "metadata": {}, "score": "67.27422"}
{"text": "User selection - configuration is accomplished through a user interface 1298 .The user selection is used as an adaptation input 1226 to the speech translation system language models 1228 .The best utterance hypothesis 1212 is used as an input to the translation component 1214 and the speech synthesis component 1216 of the speech translation system , which produce a translated speech output 1299 .", "label": "", "metadata": {}, "score": "67.282364"}
{"text": "User selection - configuration is accomplished through a user interface 1298 .The user selection is used as an adaptation input 1226 to the speech translation system language models 1228 .The best utterance hypothesis 1212 is used as an input to the translation component 1214 and the speech synthesis component 1216 of the speech translation system , which produce a translated speech output 1299 .", "label": "", "metadata": {}, "score": "67.282364"}
{"text": "User selection - configuration is accomplished through a user interface 1298 .The user selection is used as an adaptation input 1226 to the speech translation system language models 1228 .The best utterance hypothesis 1212 is used as an input to the translation component 1214 and the speech synthesis component 1216 of the speech translation system , which produce a translated speech output 1299 .", "label": "", "metadata": {}, "score": "67.282364"}
{"text": "User selection - configuration is accomplished through a user interface 1298 .The user selection is used as an adaptation input 1226 to the speech translation system language models 1228 .The best utterance hypothesis 1212 is used as an input to the translation component 1214 and the speech synthesis component 1216 of the speech translation system , which produce a translated speech output 1299 .", "label": "", "metadata": {}, "score": "67.282364"}
{"text": "User selection - configuration is accomplished through a user interface 1298 .The user selection is used as an adaptation input 1226 to the speech translation system language models 1228 .The best utterance hypothesis 1212 is used as an input to the translation component 1214 and the speech synthesis component 1216 of the speech translation system , which produce a translated speech output 1299 .", "label": "", "metadata": {}, "score": "67.282364"}
{"text": "The method of claim 10 , wherein the basic probabilities are based on grammatical functions selected from a group comprising subjects , verbs , and objects .The method of claim 10 , wherein adapting hypothesis generation comprises : . analyzing the best hypothesis ; . generating a list comprising the at least one basic component of the best hypothesis and the assigned basic probability ; . assigning credit to the at least one basic component of the best hypothesis by raising the assigned basic probability ; and .", "label": "", "metadata": {}, "score": "67.40061"}
{"text": "The apparatus of claim 13 , wherein the at least one structural analysis comprises a plurality of parse trees and sentential feature structures .The apparatus of claim 13 , wherein the at least one feature structure comprises information from at least one lexical level of at least one morphological analysis .", "label": "", "metadata": {}, "score": "67.51196"}
{"text": "The check for updated nodes is performed upon local ambiguity packing .The ancestors of an updated node should be rebuilt to reflect the new changes .Consequently , all nodes that need to be rebuilt in the parse tree are marked .", "label": "", "metadata": {}, "score": "67.520035"}
{"text": "The check for updated nodes is performed upon local ambiguity packing .The ancestors of an updated node should be rebuilt to reflect the new changes .Consequently , all nodes that need to be rebuilt in the parse tree are marked .", "label": "", "metadata": {}, "score": "67.520035"}
{"text": "The check for updated nodes is performed upon local ambiguity packing .The ancestors of an updated node should be rebuilt to reflect the new changes .Consequently , all nodes that need to be rebuilt in the parse tree are marked .", "label": "", "metadata": {}, "score": "67.520035"}
{"text": "The check for updated nodes is performed upon local ambiguity packing .The ancestors of an updated node should be rebuilt to reflect the new changes .Consequently , all nodes that need to be rebuilt in the parse tree are marked .", "label": "", "metadata": {}, "score": "67.520035"}
{"text": "The check for updated nodes is performed upon local ambiguity packing .The ancestors of an updated node should be rebuilt to reflect the new changes .Consequently , all nodes that need to be rebuilt in the parse tree are marked .", "label": "", "metadata": {}, "score": "67.520035"}
{"text": "Once located , the feature structure of the farthermost marked node is rebuilt .The feature structures of each marked node in succession along the branch path between the farthermost marked node and the root node are rebuilt , and the root node feature structures are rebuilt .", "label": "", "metadata": {}, "score": "67.639496"}
{"text": "Once located , the feature structure of the farthermost marked node is rebuilt .The feature structures of each marked node in succession along the branch path between the farthermost marked node and the root node are rebuilt , and the root node feature structures are rebuilt .", "label": "", "metadata": {}, "score": "67.639496"}
{"text": "Once located , the feature structure of the farthermost marked node is rebuilt .The feature structures of each marked node in succession along the branch path between the farthermost marked node and the root node are rebuilt , and the root node feature structures are rebuilt .", "label": "", "metadata": {}, "score": "67.639496"}
{"text": "Once located , the feature structure of the farthermost marked node is rebuilt .The feature structures of each marked node in succession along the branch path between the farthermost marked node and the root node are rebuilt , and the root node feature structures are rebuilt .", "label": "", "metadata": {}, "score": "67.639496"}
{"text": "Once located , the feature structure of the farthermost marked node is rebuilt .The feature structures of each marked node in succession along the branch path between the farthermost marked node and the root node are rebuilt , and the root node feature structures are rebuilt .", "label": "", "metadata": {}, "score": "67.639496"}
{"text": "The method of claim 3 , wherein , when multiple subgroups exist , a largest subgroup is used as the portion of the best hypothesis in the source language .The method of claim 4 , further comprising receiving a correction of the portion of the best hypothesis in the source language .", "label": "", "metadata": {}, "score": "67.661415"}
{"text": "a database of wordforms .The aim of the former database is to evaluate . computational grammars for Polish .TREEBANKS FOR ROMANCE LANGUAGES .Chapter 9 .Developing a Syntactic Annotation Scheme and Tools for a .Spanish Treebank .The paper reports on building an annotated Spanish corpora , based on . newspaper articles .", "label": "", "metadata": {}, "score": "67.71169"}
{"text": "The method of claim 15 , wherein the input received is an output of an optical character recognition ( OCR ) process .In a language translation system , an interactive method for translating a group of words , comprising : . receiving an input that represents the group of words in a source language ; . displaying at least one candidate hypothesis to the user , wherein the at least one candidate hypothesis comprises : . a source language representation of the group of words in the source language that is based upon a translation module 's understanding of the input ; . a target language representation of the group of words in a target language that is based upon the translation module 's interpretation of the source language representation ; and .", "label": "", "metadata": {}, "score": "67.72274"}
{"text": "Chapter 2 .Thoughts on Two Decades of Drawing Trees .Geoffrey Sampson .The author exploits the idea that the annotation of both written and .( transcribed ) oral corpora makes obvious the deficiencies of . theoretical linguistics and may even contradict some widely accepted .", "label": "", "metadata": {}, "score": "67.75653"}
{"text": "The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings , in which like references indicate similar elements and in which : .FIG .1 is a computer system hosting the speech translation system ( STS ) of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "67.82654"}
{"text": "13 - 17 .In other embodiments , the alternative hypotheses are displayed with numbers and the user may choose among them by speaking or entering a number corresponding to the choice .In various embodiments , recognition hypotheses may be the result of a speech recognition process , a handwriting recognition process , an optical character recognition process , or user entry on a keyboard device .", "label": "", "metadata": {}, "score": "67.874115"}
{"text": "13 - 17 .In other embodiments , the alternative hypotheses are displayed with numbers and the user may choose among them by speaking or entering a number corresponding to the choice .In various embodiments , recognition hypotheses may be the result of a speech recognition process , a handwriting recognition process , an optical character recognition process , or user entry on a keyboard device .", "label": "", "metadata": {}, "score": "67.874115"}
{"text": "13 - 17 .In other embodiments , the alternative hypotheses are displayed with numbers and the user may choose among them by speaking or entering a number corresponding to the choice .In various embodiments , recognition hypotheses may be the result of a speech recognition process , a handwriting recognition process , an optical character recognition process , or user entry on a keyboard device .", "label": "", "metadata": {}, "score": "67.874115"}
{"text": "13 - 17 .In other embodiments , the alternative hypotheses are displayed with numbers and the user may choose among them by speaking or entering a number corresponding to the choice .In various embodiments , recognition hypotheses may be the result of a speech recognition process , a handwriting recognition process , an optical character recognition process , or user entry on a keyboard device .", "label": "", "metadata": {}, "score": "67.874115"}
{"text": "13 - 17 .In other embodiments , the alternative hypotheses are displayed with numbers and the user may choose among them by speaking or entering a number corresponding to the choice .In various embodiments , recognition hypotheses may be the result of a speech recognition process , a handwriting recognition process , an optical character recognition process , or user entry on a keyboard device .", "label": "", "metadata": {}, "score": "67.874115"}
{"text": "Chapter 6 .Annotation of Error Types for German Newsgroup Corpus .Markus Becker , Andrew Bredenkamp , Berthold Crysmann , Judith Klein .This paper contributes to the presentation of the applications used .for the development of controlled language and grammar checking . applications for German .", "label": "", "metadata": {}, "score": "68.00485"}
{"text": "This process examines the local context , or the current character and its immediate neighbors , and uses a small set of tokenization rules 2152 .In an embodiment , the tokenizer makes a break at the following places with the corresponding effect , but is not so limited : . space character ( space , return , tab , End - of - Sentence ( EOS ) ) ; . period + EOS ( \" Peter likes fish . \" question mark ( \" Does Peter like fish ? \" exclamation mark ( \" Fish ! \"", "label": "", "metadata": {}, "score": "68.00868"}
{"text": "The method of claim 1 , wherein the at least one input expression comprises a grammatical sentence , wherein the grammatical sentence comprises at least one spoken word , wherein at least one feature structure is available for each lexicon of the at least one spoken word .", "label": "", "metadata": {}, "score": "68.01655"}
{"text": "The . dependency - based method presented above is used for evaluating this . parser .One interesting outcome of this evaluation is that the parser .performs better on longer sentences than on shorter ones .This may be .the outcome of having trained the parser on press reportage , with long . sentences , while the shorter sentences are found in fiction , the genre .", "label": "", "metadata": {}, "score": "68.09542"}
{"text": "a means for renormalizing the basic probabilities of the at least one language model .Descripci\u00f3n .FIELD OF THE INVENTION .This invention relates to speech or voice translation systems .More particularly , this invention relates to a spoken language translation system that performs speech - to - speech translation .", "label": "", "metadata": {}, "score": "68.13371"}
{"text": "This process examines the local context , or the current character and its immediate neighbors , and uses a small set of tokenization rules 2152 .In an embodiment , the tokenizer makes a break at the following places with the corresponding effect , but is not so limited : . space character ( space , return , tab , End - of - Sentence ( EOS ) ) ; . period + EOS ( \" Peter likes fish . \" question mark ( \" Does Peter like fish ? \"", "label": "", "metadata": {}, "score": "68.25386"}
{"text": "The system of claim 43 , wherein each level of the at least one level of nested production rules comprises a production rule for a combination of the at least one linguistic constituent of the at least one input .The system of claim 43 , further comprising : . a means for receiving at least one speech input comprising at least one source language expression ; . a means for performing the syntactic analysis on the at least one source language expression and the at least one example database to recognize linguistic constituents ; . a means for searching the at least one example database to find an expression pair having a source language portion most similar to the at least one source language expression ; . a means for generating at least one target language expression using a target language portion of the expression pair ; and .", "label": "", "metadata": {}, "score": "68.27515"}
{"text": "Automatic translation by analogy of an embodiment of the present invention comprises the use of bilingual pairs of examples to represent what has been described as translation knowledge , the information about how equivalent meanings are expressed in the source and target languages .", "label": "", "metadata": {}, "score": "68.42815"}
{"text": "Automatic translation by analogy of an embodiment of the present invention comprises the use of bilingual pairs of examples to represent what has been described as translation knowledge , the information about how equivalent meanings are expressed in the source and target languages .", "label": "", "metadata": {}, "score": "68.42815"}
{"text": "Automatic translation by analogy of an embodiment of the present invention comprises the use of bilingual pairs of examples to represent what has been described as translation knowledge , the information about how equivalent meanings are expressed in the source and target languages .", "label": "", "metadata": {}, "score": "68.42815"}
{"text": "Automatic translation by analogy of an embodiment of the present invention comprises the use of bilingual pairs of examples to represent what has been described as translation knowledge , the information about how equivalent meanings are expressed in the source and target languages .", "label": "", "metadata": {}, "score": "68.42815"}
{"text": "Automatic translation by analogy of an embodiment of the present invention comprises the use of bilingual pairs of examples to represent what has been described as translation knowledge , the information about how equivalent meanings are expressed in the source and target languages .", "label": "", "metadata": {}, "score": "68.42815"}
{"text": "A method and apparatus for interactive source language expression recognition and alternative hypothesis presentation and selection are described .In one embodiment , the present invention is a system performing natural spoken language translation .In one embodiment , the present invention receives as input natural spoken language in a source language from a user .", "label": "", "metadata": {}, "score": "68.51173"}
{"text": "With spoken language it only has a guess at what was said .In addition , spoken language is structurally quite different than written language .In fact , sometimes a transcript of perfectly understandable speech is not comprehensible when read .", "label": "", "metadata": {}, "score": "68.882225"}
{"text": "With spoken language it only has a guess at what was said .In addition , spoken language is structurally quite different than written language .In fact , sometimes a transcript of perfectly understandable speech is not comprehensible when read .", "label": "", "metadata": {}, "score": "68.882225"}
{"text": "With spoken language it only has a guess at what was said .In addition , spoken language is structurally quite different than written language .In fact , sometimes a transcript of perfectly understandable speech is not comprehensible when read .", "label": "", "metadata": {}, "score": "68.882225"}
{"text": "With spoken language it only has a guess at what was said .In addition , spoken language is structurally quite different than written language .In fact , sometimes a transcript of perfectly understandable speech is not comprehensible when read .", "label": "", "metadata": {}, "score": "68.882225"}
{"text": "The method of claim 1 , wherein generating the plurality of recognition hyotheses comprises : . assigning basic probabilities to at least one basic component of the at least one speech input using at least one language model ; and . calculating an overall probability of each of the plurality of recognition hypotheses using the assigned basic probabilities .", "label": "", "metadata": {}, "score": "69.059204"}
{"text": "If the token can be analyzed , the feature structure of the token with newly generated morphological features is output .If the analyzer 2104 finds more than one valid analysis of the word , it returns a multiple feature structure ; if the analyzer 2104 is unable to find an analysis , it returns a special feature structure for an unknown word .", "label": "", "metadata": {}, "score": "69.273254"}
{"text": "FIG .13 is an illustration of one embodiment of a display screen .The best utterance hypothesis 1302 is displayed .In this case , the best utterance hypothesis is the sentence \" I want to recognize speech . \"In addition to forming alternative utterance hypotheses and displaying the best utterance hypothesis , the present invention recognizes segments of the best utterance hypothesis that may have alternative hypotheses .", "label": "", "metadata": {}, "score": "69.48677"}
{"text": "FIG .13 is an illustration of one embodiment of a display screen .The best utterance hypothesis 1302 is displayed .In this case , the best utterance hypothesis is the sentence \" I want to recognize speech . \"In addition to forming alternative utterance hypotheses and displaying the best utterance hypothesis , the present invention recognizes segments of the best utterance hypothesis that may have alternative hypotheses .", "label": "", "metadata": {}, "score": "69.48677"}
{"text": "FIG .13 is an illustration of one embodiment of a display screen .The best utterance hypothesis 1302 is displayed .In this case , the best utterance hypothesis is the sentence \" I want to recognize speech . \"In addition to forming alternative utterance hypotheses and displaying the best utterance hypothesis , the present invention recognizes segments of the best utterance hypothesis that may have alternative hypotheses .", "label": "", "metadata": {}, "score": "69.48677"}
{"text": "FIG .13 is an illustration of one embodiment of a display screen .The best utterance hypothesis 1302 is displayed .In this case , the best utterance hypothesis is the sentence \" I want to recognize speech . \"In addition to forming alternative utterance hypotheses and displaying the best utterance hypothesis , the present invention recognizes segments of the best utterance hypothesis that may have alternative hypotheses .", "label": "", "metadata": {}, "score": "69.48677"}
{"text": "FIG .13 is an illustration of one embodiment of a display screen .The best utterance hypothesis 1302 is displayed .In this case , the best utterance hypothesis is the sentence \" I want to recognize speech . \"In addition to forming alternative utterance hypotheses and displaying the best utterance hypothesis , the present invention recognizes segments of the best utterance hypothesis that may have alternative hypotheses .", "label": "", "metadata": {}, "score": "69.48677"}
{"text": "The system of claim 43 , wherein the means for performing syntactic analysis further comprises a means for generalizing at least one surface variation in the at least one input and the at least one example database .The system of claim 43 , further comprising : . a means for determining at least one syntactic constituent of the at least one input ; and .", "label": "", "metadata": {}, "score": "69.557175"}
{"text": "The rules for nouns of an embodiment comprise default rules , zero plural rules , zero singular rules , identical singular and plural form rules , and rules for nouns with particular endings , but are not so limited .The noun default rules comprise , but are not limited to , rules that for : .", "label": "", "metadata": {}, "score": "69.57239"}
{"text": "The rules for nouns of an embodiment comprise default rules , zero plural rules , zero singular rules , identical singular and plural form rules , and rules for nouns with particular endings , but are not so limited .The noun default rules comprise , but are not limited to , rules that for : .", "label": "", "metadata": {}, "score": "69.57239"}
{"text": "The rules for nouns of an embodiment comprise default rules , zero plural rules , zero singular rules , identical singular and plural form rules , and rules for nouns with particular endings , but are not so limited .The noun default rules comprise , but are not limited to , rules that for : .", "label": "", "metadata": {}, "score": "69.57239"}
{"text": "The rules for nouns of an embodiment comprise default rules , zero plural rules , zero singular rules , identical singular and plural form rules , and rules for nouns with particular endings , but are not so limited .The noun default rules comprise , but are not limited to , rules that for : .", "label": "", "metadata": {}, "score": "69.57239"}
{"text": "The computer readable medium of claim 36 , wherein the basic probabilities are based on grammatical functions comprising subjects , verbs , and objects , wherein the basic probability is of the form .The computer readable medium of claim 36 , wherein adapting hypothesis generation comprises : . analyzing the best hypothesis ; . generating a list comprising the at least one basic component of the best hypothesis and the assigned basic probability ; . assigning credit to the at least one basic component of the best hypothesis by raising the assigned basic probability ; and .", "label": "", "metadata": {}, "score": "69.73006"}
{"text": "presenting the best hypothesis , including the chosen alternative , to the user in the target language .The method of claim 13 , further including accepting a confirmation of the best alternative with the chosen alternative from the user .The method of claim 13 , further including : . accepting a correction to the portion of the best hypothesis in the source language ; . presenting the best hypothesis including the correction in the source language to the user ; and .", "label": "", "metadata": {}, "score": "69.794876"}
{"text": "9 shows a bilingual example database of an embodiment of the present invention .FIG .10 shows an example of a bilingual example data representation of an embodiment of the present invention .FIG .11 is a matching and transfer algorithm of a translation component of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "69.858665"}
{"text": "9 shows a bilingual example database of an embodiment of the present invention .FIG .10 shows an example of a bilingual example data representation of an embodiment of the present invention .FIG .11 is a matching and transfer algorithm of a translation component of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "69.858665"}
{"text": "9 shows a bilingual example database of an embodiment of the present invention .FIG .10 shows an example of a bilingual example data representation of an embodiment of the present invention .FIG .11 is a matching and transfer algorithm of a translation component of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "69.858665"}
{"text": "9 shows a bilingual example database of an embodiment of the present invention .FIG .10 shows an example of a bilingual example data representation of an embodiment of the present invention .FIG .11 is a matching and transfer algorithm of a translation component of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "69.858665"}
{"text": "9 shows a bilingual example database of an embodiment of the present invention .FIG .10 shows an example of a bilingual example data representation of an embodiment of the present invention .FIG .11 is a matching and transfer algorithm of a translation component of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "69.858665"}
{"text": "The effects of the consonant doubling rules with examples follow : . \"In an embodiment , verbs that end in \" e \" immediately preceded by a consonant are handled by the rules as follows , but are not so limited : . 3rd person singular , default rule ( add \" s \" ) applies ; .", "label": "", "metadata": {}, "score": "70.09254"}
{"text": "The effects of the consonant doubling rules with examples follow : .In an embodiment , verbs that end in \" e \" immediately preceded by a consonant are handled by the rules as follows , but are not so limited : . 3rd person singular , default rule ( add \" s \" ) applies ; .", "label": "", "metadata": {}, "score": "70.106995"}
{"text": "The effects of the consonant doubling rules with examples follow : .In an embodiment , verbs that end in \" e \" immediately preceded by a consonant are handled by the rules as follows , but are not so limited : . 3rd person singular , default rule ( add \" s \" ) applies ; .", "label": "", "metadata": {}, "score": "70.106995"}
{"text": "Moreover , a meaning of the speech input is detected , and the meaning is rendered in the synthesized translated output .Embodiments of the invention comprise a portable unit that performs a method for spoken language translation .One such embodiment is a laptop computer , while another such embodiment is a cellular telephone .", "label": "", "metadata": {}, "score": "70.20383"}
{"text": "FIG .23 is a list of the inflection types 2302 handled by an English morphological analyzer of an embodiment of the present invention .FIG .24 is a list of top level features 2402 to indicate special inflections in an English morphological analyzer of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "70.309784"}
{"text": "FIG .23 is a list of the inflection types 2302 handled by an English morphological analyzer of an embodiment of the present invention .FIG .24 is a list of top level features 2402 to indicate special inflections in an English morphological analyzer of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "70.309784"}
{"text": "FIG .23 is a list of the inflection types 2302 handled by an English morphological analyzer of an embodiment of the present invention .FIG .24 is a list of top level features 2402 to indicate special inflections in an English morphological analyzer of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "70.309784"}
{"text": "FIG .23 is a list of the inflection types 2302 handled by an English morphological analyzer of an embodiment of the present invention .FIG .24 is a list of top level features 2402 to indicate special inflections in an English morphological analyzer of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "70.309784"}
{"text": "FIG .23 is a list of the inflection types 2302 handled by an English morphological analyzer of an embodiment of the present invention .FIG .24 is a list of top level features 2402 to indicate special inflections in an English morphological analyzer of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "70.309784"}
{"text": "Automated Creation of a Medieval Portuguese Partial Treebank .Xavier , Gracia Vicente .The novelty of the approach presented in this paper arises from the .use of tools and resources developed for Contemporary Portuguese to .the annotation of a corpus of Medieval Portuguese .", "label": "", "metadata": {}, "score": "70.372345"}
{"text": "The method of claim 29 , wherein , when multiple subgroups exist , a largest subgroup is used as the portion of the best hypothesis in the source language .The method of claim 30 , further comprising receiving a correction of the portion of the best hypothesis in the source language .", "label": "", "metadata": {}, "score": "70.42747"}
{"text": "A characteristic of this project is the interactive annotation process . which makes use of the TnT statistical tagger and second order Markov .models for POS tagging .Syntactic structure is built incrementally , . using cascaded Markov models .A graphical user interface allows for .", "label": "", "metadata": {}, "score": "70.48132"}
{"text": "b. ( ( ROOT \" saw \" ) .( ( CAT NOUN ) ) .Lexical f - structure output by morphological analyzer : .( SURFACE \" saw \" ) .( CAT VERB ) .( TRANS INTRANS ) .", "label": "", "metadata": {}, "score": "70.77953"}
{"text": "b. ( ( ROOT \" saw \" ) .( ( CAT NOUN ) ) .Lexical f - structure output by morphological analyzer : .( SURFACE \" saw \" ) .( CAT VERB ) .( TRANS INTRANS ) .", "label": "", "metadata": {}, "score": "70.77953"}
{"text": "b. ( ( ROOT \" saw \" ) .( ( CAT NOUN ) ) .Lexical f - structure output by morphological analyzer : .( SURFACE \" saw \" ) .( CAT VERB ) .( TRANS INTRANS ) .", "label": "", "metadata": {}, "score": "70.77953"}
{"text": "b. ( ( ROOT \" saw \" ) .( ( CAT NOUN ) ) .Lexical f - structure output by morphological analyzer : .( SURFACE \" saw \" ) .( CAT VERB ) .( TRANS INTRANS ) .", "label": "", "metadata": {}, "score": "70.77953"}
{"text": "The apparatus of claim 15 , wherein the example database is a bilingual example database , and wherein the expression pair is a bilingual expression pair .The apparatus of claim 15 , wherein the syntactic analysis comprises : . recognizing linguistic constituents selected from a group comprising noun phrases , verb phrases , and prepositional phrases ; . ordering the linguistic constituents ; . representing the linguistic constituents using an adapted feature structure analysis representation ; and .", "label": "", "metadata": {}, "score": "70.78327"}
{"text": "manipulating the adapted feature structure analysis representation using at least one natural language parser .The computer readable medium of claim 29 , wherein a separation is provided between domain - independent linguistic knowledge and domain - dependent linguistic knowledge .The computer readable medium of claim 29 , wherein the method further comprises performing statistical processing to resolve lexical ambiguities and local ambiguities .", "label": "", "metadata": {}, "score": "70.94914"}
{"text": "The part - of - speech ( POS ) tagset is . based on that of the Brown Corpus , but adjusted to serve the . stochastic orientation of Penn Treebank and its concern with sparse .data , and reduced to eliminate lexical and syntactic . redundancies .", "label": "", "metadata": {}, "score": "70.99005"}
{"text": "These and other features , aspects , and advantages of the present invention will be apparent from the accompanying drawings and from the detailed description and appended claims which follow .BRIEF DESCRIPTION OF THE DRAWINGS .The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings , in which like references indicate similar elements and in which : .", "label": "", "metadata": {}, "score": "71.058624"}
{"text": "These and other features , aspects , and advantages of the present invention will be apparent from the accompanying drawings and from the detailed description and appended claims which follow .BRIEF DESCRIPTION OF THE DRAWINGS .The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings , in which like references indicate similar elements and in which : .", "label": "", "metadata": {}, "score": "71.058624"}
{"text": "The free word order of Japanese . raised a problem which remained unsolved : predicate - argument relation . in embedded sentences .Chapter 15 .Building a Turkish Treebank .The aims of realizing the Turkish treebank is to be representative and . to contain all the relevant information for its potential users .", "label": "", "metadata": {}, "score": "71.20496"}
{"text": "It also contains a preface ( pp .xi ) , an . introduction ( pp . xiii - xxvi ) , a list of contributing authors and their . affiliation ( pp .391- 397 ) , and an index of topics ( pp .", "label": "", "metadata": {}, "score": "71.208015"}
{"text": "In a typical domain , the required example database grows to a considerable size .For example , in an embodiment of the present invention , the database comprises approximately 10,000 example pairs .Thus , it is not possible to carry out detailed matching of the input to every example , and the search space for the best match problem must be constrained in some way .", "label": "", "metadata": {}, "score": "71.24969"}
{"text": "In a typical domain , the required example database grows to a considerable size .For example , in an embodiment of the present invention , the database comprises approximately 10,000 example pairs .Thus , it is not possible to carry out detailed matching of the input to every example , and the search space for the best match problem must be constrained in some way .", "label": "", "metadata": {}, "score": "71.24969"}
{"text": "In a typical domain , the required example database grows to a considerable size .For example , in an embodiment of the present invention , the database comprises approximately 10,000 example pairs .Thus , it is not possible to carry out detailed matching of the input to every example , and the search space for the best match problem must be constrained in some way .", "label": "", "metadata": {}, "score": "71.24969"}
{"text": "An output device 280 provides translated output in response to the received speech signals .The STS of an embodiment may be hosted on a processor , but is not so limited .For an alternate embodiment , the STS may comprise some combination of hardware and software components that are hosted on different processors .", "label": "", "metadata": {}, "score": "71.270164"}
{"text": "An output device 280 provides translated output in response to the received speech signals .The STS of an embodiment may be hosted on a processor , but is not so limited .For an alternate embodiment , the STS may comprise some combination of hardware and software components that are hosted on different processors .", "label": "", "metadata": {}, "score": "71.270164"}
{"text": "An output device 280 provides translated output in response to the received speech signals .The STS of an embodiment may be hosted on a processor , but is not so limited .For an alternate embodiment , the STS may comprise some combination of hardware and software components that are hosted on different processors .", "label": "", "metadata": {}, "score": "71.270164"}
{"text": "An output device 280 provides translated output in response to the received speech signals .The STS of an embodiment may be hosted on a processor , but is not so limited .For an alternate embodiment , the STS may comprise some combination of hardware and software components that are hosted on different processors .", "label": "", "metadata": {}, "score": "71.270164"}
{"text": "An output device 280 provides translated output in response to the received speech signals .The STS of an embodiment may be hosted on a processor , but is not so limited .For an alternate embodiment , the STS may comprise some combination of hardware and software components that are hosted on different processors .", "label": "", "metadata": {}, "score": "71.270164"}
{"text": "A apparatus comprising a computer readable medium containing executable instructions which , when executed in a processing system , cause the system to perform the steps of a method for performing spoken language translation , the method comprising : . receiving a speech input in a source language ; . translating the recognized at least one source expression from the source language to a target language ; . synthesizing a speech output from the recognized at least one expression in the target language ; and . outputting the at least one speech output .", "label": "", "metadata": {}, "score": "71.29112"}
{"text": "discontinuities favor the usage of the dependency framework .Its . typical problems ( pro - drop phenomenon , verb ellipsis , etc . ) are given .the solution adopted in the annotation process .PART II .USING TREEBANKS .", "label": "", "metadata": {}, "score": "71.39945"}
{"text": "Consequently , the present invention solves the example specificity problem by dividing it into three sub - problems : best match ; fast match ; and , example combination .The best match sub - problem involves finding the best match from the example database given an input .", "label": "", "metadata": {}, "score": "71.52562"}
{"text": "Consequently , the present invention solves the example specificity problem by dividing it into three sub - problems : best match ; fast match ; and , example combination .The best match sub - problem involves finding the best match from the example database given an input .", "label": "", "metadata": {}, "score": "71.52562"}
{"text": "Consequently , the present invention solves the example specificity problem by dividing it into three sub - problems : best match ; fast match ; and , example combination .The best match sub - problem involves finding the best match from the example database given an input .", "label": "", "metadata": {}, "score": "71.52562"}
{"text": "Consequently , the present invention solves the example specificity problem by dividing it into three sub - problems : best match ; fast match ; and , example combination .The best match sub - problem involves finding the best match from the example database given an input .", "label": "", "metadata": {}, "score": "71.52562"}
{"text": "Consequently , the present invention solves the example specificity problem by dividing it into three sub - problems : best match ; fast match ; and , example combination .The best match sub - problem involves finding the best match from the example database given an input .", "label": "", "metadata": {}, "score": "71.52562"}
{"text": "18 is a flowchart for language model adaptation of a speech translation system of an embodiment of the present invention .The fundamental idea for carrying out the adaptation is to take the correct or best utterance hypothesis 1802 that was selected by the user , and to analyze 1804 it according to the language model .", "label": "", "metadata": {}, "score": "71.52872"}
{"text": "18 is a flowchart for language model adaptation of a speech translation system of an embodiment of the present invention .The fundamental idea for carrying out the adaptation is to take the correct or best utterance hypothesis 1802 that was selected by the user , and to analyze 1804 it according to the language model .", "label": "", "metadata": {}, "score": "71.52872"}
{"text": "18 is a flowchart for language model adaptation of a speech translation system of an embodiment of the present invention .The fundamental idea for carrying out the adaptation is to take the correct or best utterance hypothesis 1802 that was selected by the user , and to analyze 1804 it according to the language model .", "label": "", "metadata": {}, "score": "71.52872"}
{"text": "18 is a flowchart for language model adaptation of a speech translation system of an embodiment of the present invention .The fundamental idea for carrying out the adaptation is to take the correct or best utterance hypothesis 1802 that was selected by the user , and to analyze 1804 it according to the language model .", "label": "", "metadata": {}, "score": "71.52872"}
{"text": "18 is a flowchart for language model adaptation of a speech translation system of an embodiment of the present invention .The fundamental idea for carrying out the adaptation is to take the correct or best utterance hypothesis 1802 that was selected by the user , and to analyze 1804 it according to the language model .", "label": "", "metadata": {}, "score": "71.52872"}
{"text": "26 is a flowchart for a method of parsing in a spoken language translation system of an embodiment of the present invention .FIG .27 is a parsing engine of an embodiment of the present invention .DETAILED DESCRIPTION .A method and an apparatus for a spoken language translation system are provided .", "label": "", "metadata": {}, "score": "71.62296"}
{"text": "26 is a flowchart for a method of parsing in a spoken language translation system of an embodiment of the present invention .FIG .27 is a parsing engine of an embodiment of the present invention .DETAILED DESCRIPTION .A method and an apparatus for a spoken language translation system are provided .", "label": "", "metadata": {}, "score": "71.62296"}
{"text": "26 is a flowchart for a method of parsing in a spoken language translation system of an embodiment of the present invention .FIG .27 is a parsing engine of an embodiment of the present invention .DETAILED DESCRIPTION .A method and an apparatus for a spoken language translation system are provided .", "label": "", "metadata": {}, "score": "71.62296"}
{"text": "26 is a flowchart for a method of parsing in a spoken language translation system of an embodiment of the present invention .FIG .27 is a parsing engine of an embodiment of the present invention .DETAILED DESCRIPTION .A method and an apparatus for a spoken language translation system are provided .", "label": "", "metadata": {}, "score": "71.62296"}
{"text": "26 is a flowchart for a method of parsing in a spoken language translation system of an embodiment of the present invention .FIG .27 is a parsing engine of an embodiment of the present invention .DETAILED DESCRIPTION .A method and an apparatus for a spoken language translation system are provided .", "label": "", "metadata": {}, "score": "71.62296"}
{"text": "1 and the elements of FIG .2 .The modules shown in the memory of FIG .2 may be stored in random access memory ( RAM ) of the laptop , or may be variously stored in RAM and read only memory ( ROM ) .", "label": "", "metadata": {}, "score": "71.64366"}
{"text": "1 and the elements of FIG .2 .The modules shown in the memory of FIG .2 may be stored in random access memory ( RAM ) of the laptop , or may be variously stored in RAM and read only memory ( ROM ) .", "label": "", "metadata": {}, "score": "71.64366"}
{"text": "1 and the elements of FIG .2 .The modules shown in the memory of FIG .2 may be stored in random access memory ( RAM ) of the laptop , or may be variously stored in RAM and read only memory ( ROM ) .", "label": "", "metadata": {}, "score": "71.64366"}
{"text": "1 and the elements of FIG .2 .The modules shown in the memory of FIG .2 may be stored in random access memory ( RAM ) of the laptop , or may be variously stored in RAM and read only memory ( ROM ) .", "label": "", "metadata": {}, "score": "71.64366"}
{"text": "1 and the elements of FIG .2 .The modules shown in the memory of FIG .2 may be stored in random access memory ( RAM ) of the laptop , or may be variously stored in RAM and read only memory ( ROM ) .", "label": "", "metadata": {}, "score": "71.64366"}
{"text": "Speech is the predominant mode of human communication because it is very efficient and convenient .Certainly , written language is very important , and much of the knowledge that is passed from generation to generation is in written form , but speech is a preferred mode for everyday interaction .", "label": "", "metadata": {}, "score": "72.05149"}
{"text": "16 shows a display of another embodiment for systems with bi - directional translation capability .The speech recognition hypotheses are displayed as hypothesis sets 1602 , 1604 and 1606 .Each of hypothesis sets 1602 , 1604 and 1606 include a source language hypothesis , a target language translation of the source language hypothesis , and a source language back - translation of the target language translation .", "label": "", "metadata": {}, "score": "72.06978"}
{"text": "16 shows a display of another embodiment for systems with bi - directional translation capability .The speech recognition hypotheses are displayed as hypothesis sets 1602 , 1604 and 1606 .Each of hypothesis sets 1602 , 1604 and 1606 include a source language hypothesis , a target language translation of the source language hypothesis , and a source language back - translation of the target language translation .", "label": "", "metadata": {}, "score": "72.06978"}
{"text": "16 shows a display of another embodiment for systems with bi - directional translation capability .The speech recognition hypotheses are displayed as hypothesis sets 1602 , 1604 and 1606 .Each of hypothesis sets 1602 , 1604 and 1606 include a source language hypothesis , a target language translation of the source language hypothesis , and a source language back - translation of the target language translation .", "label": "", "metadata": {}, "score": "72.06978"}
{"text": "16 shows a display of another embodiment for systems with bi - directional translation capability .The speech recognition hypotheses are displayed as hypothesis sets 1602 , 1604 and 1606 .Each of hypothesis sets 1602 , 1604 and 1606 include a source language hypothesis , a target language translation of the source language hypothesis , and a source language back - translation of the target language translation .", "label": "", "metadata": {}, "score": "72.06978"}
{"text": "16 shows a display of another embodiment for systems with bi - directional translation capability .The speech recognition hypotheses are displayed as hypothesis sets 1602 , 1604 and 1606 .Each of hypothesis sets 1602 , 1604 and 1606 include a source language hypothesis , a target language translation of the source language hypothesis , and a source language back - translation of the target language translation .", "label": "", "metadata": {}, "score": "72.06978"}
{"text": "The computer readable medium of claim 26 , wherein the intermediate source language data structure comprises at least one word graph and at least one n - best list .The computer readable medium of claim 27 , wherein the method further comprises remotely extending a set of source language expressions stored on the portable apparatus , comprising receiving source language expressions via a communication medium .", "label": "", "metadata": {}, "score": "72.23718"}
{"text": "The verb default rules comprise , but are not limited to , rules that : .The rules for consonant doubling apply to verbs ending in one of the following consonants immediately preceded by a short vowel .When the rules for consonant doubling apply , the final consonant is doubled for present participle , simple past and past participle forms .", "label": "", "metadata": {}, "score": "72.36911"}
{"text": "combining entries of the example database based on the at least one syntactic constituent .The computer readable medium of claim 29 , wherein the example database is a bilingual example database , and wherein the expression pair is a bilingual expression pair .", "label": "", "metadata": {}, "score": "72.36979"}
{"text": "The rules for verbs of an embodiment comprise default rules , consonant doubling rules , final letter \" e \" rules , final letter \" y \" rules , and irregular verb rules , but are not so limited .The verb default rules comprise , but are not limited to , rules that : .", "label": "", "metadata": {}, "score": "72.38516"}
{"text": "The rules for verbs of an embodiment comprise default rules , consonant doubling rules , final letter \" e \" rules , final letter \" y \" rules , and irregular verb rules , but are not so limited .The verb default rules comprise , but are not limited to , rules that : .", "label": "", "metadata": {}, "score": "72.38516"}
{"text": "The rules for verbs of an embodiment comprise default rules , consonant doubling rules , final letter \" e \" rules , final letter \" y \" rules , and irregular verb rules , but are not so limited .The verb default rules comprise , but are not limited to , rules that : .", "label": "", "metadata": {}, "score": "72.38516"}
{"text": "The rules for verbs of an embodiment comprise default rules , consonant doubling rules , final letter \" e \" rules , final letter \" y \" rules , and irregular verb rules , but are not so limited .The verb default rules comprise , but are not limited to , rules that : .", "label": "", "metadata": {}, "score": "72.38516"}
{"text": "The apparatus of claim 14 , wherein generating a plurality of recognition hypotheses comprises : . assigning basic probabilities to at least one basic component of the at least one speech input using at least one language model ; and . calculating an overall probability of each of the plurality of recognition hypotheses using the assigned basic probabilities .", "label": "", "metadata": {}, "score": "72.475334"}
{"text": "The conclusion .drawn from the experiments is that almost all constraints decrease the . performance of the model : the most probable parse ( which takes into . consideration overlapping subtrees ) gives better results than the most . probable derivation ( which does not takes it into consideration ) ; the .", "label": "", "metadata": {}, "score": "72.495804"}
{"text": "The target language speech synthesis produces a target language speech output 314 that represents the source language speech input 302 .FIG .4 is a system diagram of source language speech recognition 304 of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "72.54667"}
{"text": "The target language speech synthesis produces a target language speech output 314 that represents the source language speech input 302 .FIG .4 is a system diagram of source language speech recognition 304 of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "72.54667"}
{"text": "The target language speech synthesis produces a target language speech output 314 that represents the source language speech input 302 .FIG .4 is a system diagram of source language speech recognition 304 of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "72.54667"}
{"text": "The target language speech synthesis produces a target language speech output 314 that represents the source language speech input 302 .FIG .4 is a system diagram of source language speech recognition 304 of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "72.54667"}
{"text": "The target language speech synthesis produces a target language speech output 314 that represents the source language speech input 302 .FIG .4 is a system diagram of source language speech recognition 304 of a speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "72.54667"}
{"text": "Report of the EAGLES Working .Group on Computational Lexicons , ftp://ftp.ilc.pi.cnr.it/pub/eagles/lexicons/synlex.ps.gz .Berwick , R.C. , S.P. Abney , C. Tenny ( Eds . )( 1991 )Principle - Based .Parsing : Computation and Psycholinguistics .Kluwer Academic .", "label": "", "metadata": {}, "score": "72.620674"}
{"text": "The rules for adjectives ending in \" y \" comprise , but are not limited to , rules for : .The rules for irregular adjectives comprise , but are not limited to , rules wherein the following adjectives have irregular comparative and superlative forms which should have separate dictionary entries : . \"", "label": "", "metadata": {}, "score": "72.63573"}
{"text": "The rules for adjectives ending in \" y \" comprise , but are not limited to , rules for : .The rules for irregular adjectives comprise , but are not limited to , rules wherein the following adjectives have irregular comparative and superlative forms which should have separate dictionary entries : . \"", "label": "", "metadata": {}, "score": "72.63573"}
{"text": "Directory .Verginica Barbu Mititelu , .Institute for Artificial Intelligence , Romanian Academy .The book is a collection of 21 papers on building and using parsed .corpora , most of them formerly presented at workshops and conferences .( ATALA , LINC , LREC , EACL ) .", "label": "", "metadata": {}, "score": "72.652985"}
{"text": "The method of claim 1 , further comprising : .The method of claim 7 , wherein recognizing at least one word comprises : . using acoustic information comprising at least one word pronunciation dictionary and at least one acoustic model to generate at least one hypothesis for the at least one word ; and .", "label": "", "metadata": {}, "score": "72.67944"}
{"text": "In an embodiment , verbs that end in \" y \" immediately preceded by a consonant are handled by the rules as follows , but are not so limited : . present participle : apply default rule ( add \" \" ing \" ) .", "label": "", "metadata": {}, "score": "72.81192"}
{"text": "t .i .e .In a typical domain , the required example database grows to a considerable size .For example , in an embodiment of the present invention , the database comprises approximately 10,000 example pairs .Thus , it is not possible to carry out detailed matching of the input to every example , and the search space for the best match problem must be constrained in some way .", "label": "", "metadata": {}, "score": "72.901024"}
{"text": "t .i .e .In a typical domain , the required example database grows to a considerable size .For example , in an embodiment of the present invention , the database comprises approximately 10,000 example pairs .Thus , it is not possible to carry out detailed matching of the input to every example , and the search space for the best match problem must be constrained in some way .", "label": "", "metadata": {}, "score": "72.901024"}
{"text": "FIG .2 is a computer system memory 200 hosting the speech translation system of an embodiment of the present invention .An input device 202 provides speech signals to a digitizer and bus interface 204 .The digitizer or feature extractor 204 samples and digitizes the speech signals for further processing .", "label": "", "metadata": {}, "score": "72.93854"}
{"text": "FIG .2 is a computer system memory 200 hosting the speech translation system of an embodiment of the present invention .An input device 202 provides speech signals to a digitizer and bus interface 204 .The digitizer or feature extractor 204 samples and digitizes the speech signals for further processing .", "label": "", "metadata": {}, "score": "72.93854"}
{"text": "FIG .2 is a computer system memory 200 hosting the speech translation system of an embodiment of the present invention .An input device 202 provides speech signals to a digitizer and bus interface 204 .The digitizer or feature extractor 204 samples and digitizes the speech signals for further processing .", "label": "", "metadata": {}, "score": "72.93854"}
{"text": "FIG .2 is a computer system memory 200 hosting the speech translation system of an embodiment of the present invention .An input device 202 provides speech signals to a digitizer and bus interface 204 .The digitizer or feature extractor 204 samples and digitizes the speech signals for further processing .", "label": "", "metadata": {}, "score": "72.93854"}
{"text": "FIG .2 is a computer system memory 200 hosting the speech translation system of an embodiment of the present invention .An input device 202 provides speech signals to a digitizer and bus interface 204 .The digitizer or feature extractor 204 samples and digitizes the speech signals for further processing .", "label": "", "metadata": {}, "score": "72.93854"}
{"text": "The present invention overcomes these problems .The speech recognition component of an embodiment identifies a number of possibilities , and the user may choose from these possibilities , or speech recognition hypotheses , the correct or best hypothesis .An embodiment of the user interface 1298 of FIG .", "label": "", "metadata": {}, "score": "72.964264"}
{"text": "The present invention overcomes these problems .The speech recognition component of an embodiment identifies a number of possibilities , and the user may choose from these possibilities , or speech recognition hypotheses , the correct or best hypothesis .An embodiment of the user interface 1298 of FIG .", "label": "", "metadata": {}, "score": "72.964264"}
{"text": "The present invention overcomes these problems .The speech recognition component of an embodiment identifies a number of possibilities , and the user may choose from these possibilities , or speech recognition hypotheses , the correct or best hypothesis .An embodiment of the user interface 1298 of FIG .", "label": "", "metadata": {}, "score": "72.964264"}
{"text": "The present invention overcomes these problems .The speech recognition component of an embodiment identifies a number of possibilities , and the user may choose from these possibilities , or speech recognition hypotheses , the correct or best hypothesis .An embodiment of the user interface 1298 of FIG .", "label": "", "metadata": {}, "score": "72.964264"}
{"text": "The present invention overcomes these problems .The speech recognition component of an embodiment identifies a number of possibilities , and the user may choose from these possibilities , or speech recognition hypotheses , the correct or best hypothesis .An embodiment of the user interface 1298 of FIG .", "label": "", "metadata": {}, "score": "72.964264"}
{"text": "The resulting general syntactic analyzer can be used to quickly construct a new example database for a different domain .Typical rule - based syntactic analysis is known to have flaws that include brittleness , ambiguities , and difficult maintenance .Brittleness is a condition wherein , if the rule fails , there will be no output .", "label": "", "metadata": {}, "score": "72.976166"}
{"text": "The resulting general syntactic analyzer can be used to quickly construct a new example database for a different domain .Typical rule - based syntactic analysis is known to have flaws that include brittleness , ambiguities , and difficult maintenance .Brittleness is a condition wherein , if the rule fails , there will be no output .", "label": "", "metadata": {}, "score": "72.976166"}
{"text": "The resulting general syntactic analyzer can be used to quickly construct a new example database for a different domain .Typical rule - based syntactic analysis is known to have flaws that include brittleness , ambiguities , and difficult maintenance .Brittleness is a condition wherein , if the rule fails , there will be no output .", "label": "", "metadata": {}, "score": "72.976166"}
{"text": "The resulting general syntactic analyzer can be used to quickly construct a new example database for a different domain .Typical rule - based syntactic analysis is known to have flaws that include brittleness , ambiguities , and difficult maintenance .Brittleness is a condition wherein , if the rule fails , there will be no output .", "label": "", "metadata": {}, "score": "72.976166"}
{"text": "The resulting general syntactic analyzer can be used to quickly construct a new example database for a different domain .Typical rule - based syntactic analysis is known to have flaws that include brittleness , ambiguities , and difficult maintenance .Brittleness is a condition wherein , if the rule fails , there will be no output .", "label": "", "metadata": {}, "score": "72.976166"}
{"text": "Completing Parsed Corpora .Sean Wallis .A more challenging title for this paper could have been : ' ' Do we need .linguists for constructing treebanks ? ' 'For answering this question , .S. Wallis starts by giving us a brief overview of the phases of the . annotation employed on International Corpus of English ?", "label": "", "metadata": {}, "score": "73.80125"}
{"text": "( 3 ) Entries that have irregular inflections : irregular inflections are represented as separate entries with an additional string - feature slot ( SURFACE ) that contains the surface form .These irregular form entries can also contain any other kind of relevant information for that particular inflected form .", "label": "", "metadata": {}, "score": "74.02977"}
{"text": "( 3 ) Entries that have irregular inflections : irregular inflections are represented as separate entries with an additional string - feature slot ( SURFACE ) that contains the surface form .These irregular form entries can also contain any other kind of relevant information for that particular inflected form .", "label": "", "metadata": {}, "score": "74.02977"}
{"text": "FIG .25 is a parser implementation of an embodiment of the present invention .The parser comprises an parsing table generator 2502 , a feature structure ( F - structure ) operation compiler 2504 , and a GLR parsing engine 2506 with feature structure constraint application .", "label": "", "metadata": {}, "score": "74.03944"}
{"text": "FIG .25 is a parser implementation of an embodiment of the present invention .The parser comprises an parsing table generator 2502 , a feature structure ( F - structure ) operation compiler 2504 , and a GLR parsing engine 2506 with feature structure constraint application .", "label": "", "metadata": {}, "score": "74.03944"}
{"text": "FIG .25 is a parser implementation of an embodiment of the present invention .The parser comprises an parsing table generator 2502 , a feature structure ( F - structure ) operation compiler 2504 , and a GLR parsing engine 2506 with feature structure constraint application .", "label": "", "metadata": {}, "score": "74.03944"}
{"text": "FIG .25 is a parser implementation of an embodiment of the present invention .The parser comprises an parsing table generator 2502 , a feature structure ( F - structure ) operation compiler 2504 , and a GLR parsing engine 2506 with feature structure constraint application .", "label": "", "metadata": {}, "score": "74.03944"}
{"text": "FIG .25 is a parser implementation of an embodiment of the present invention .The parser comprises an parsing table generator 2502 , a feature structure ( F - structure ) operation compiler 2504 , and a GLR parsing engine 2506 with feature structure constraint application .", "label": "", "metadata": {}, "score": "74.03944"}
{"text": "Keh - Jiann Chen , Chi - Ching Lou , Ming - Chung Chang , Feng - Yi Chen , .Chao - Jan Chen , Chu - Ren Huang , Zhao - Ming Gao .The paper reports on the construction of a treebank for Mandarin .", "label": "", "metadata": {}, "score": "74.04686"}
{"text": "In an embodiment , verbs that end in \" e \" immediately preceded by a consonant are handled by the rules as follows , but are not so limited : . 3rd person singular , default rule ( add \" s \" ) applies ; .", "label": "", "metadata": {}, "score": "74.07913"}
{"text": "The computer readable medium of claim 25 , wherein the at least one structural analysis comprises a plurality of parse trees and sentential feature structures .The computer readable medium of claim 25 , wherein the at least one feature structure comprises information from at least one lexical level of at least one morphological analysis .", "label": "", "metadata": {}, "score": "74.13958"}
{"text": "The method of claim 1 , wherein the at least one speech input comprises natural spoken language , wherein the natural spoken language comprises at least one word , at least one phrase , and at least one sentence .The method of claim 1 , further comprising : . detecting at least one meaning of the at least one speech input , wherein the at least one meaning comprises statements and questions ; and .", "label": "", "metadata": {}, "score": "74.17572"}
{"text": "Inflectional morphology deals with morphemes that function as grammatical markers , such as the plural marker -s- , or the past - tense marker -ed in English .Derivational morphology deals with prefixes or suffixes that alter the stem 's syntactic category or semantic content , such as un- and -ment in the word unemployment .", "label": "", "metadata": {}, "score": "74.22408"}
{"text": "Inflectional morphology deals with morphemes that function as grammatical markers , such as the plural marker -s- , or the past - tense marker -ed in English .Derivational morphology deals with prefixes or suffixes that alter the stem 's syntactic category or semantic content , such as un- and -ment in the word unemployment .", "label": "", "metadata": {}, "score": "74.22408"}
{"text": "Inflectional morphology deals with morphemes that function as grammatical markers , such as the plural marker -s- , or the past - tense marker -ed in English .Derivational morphology deals with prefixes or suffixes that alter the stem 's syntactic category or semantic content , such as un- and -ment in the word unemployment .", "label": "", "metadata": {}, "score": "74.22408"}
{"text": "Inflectional morphology deals with morphemes that function as grammatical markers , such as the plural marker -s- , or the past - tense marker -ed in English .Derivational morphology deals with prefixes or suffixes that alter the stem 's syntactic category or semantic content , such as un- and -ment in the word unemployment .", "label": "", "metadata": {}, "score": "74.22408"}
{"text": "Inflectional morphology deals with morphemes that function as grammatical markers , such as the plural marker -s- , or the past - tense marker -ed in English .Derivational morphology deals with prefixes or suffixes that alter the stem 's syntactic category or semantic content , such as un- and -ment in the word unemployment .", "label": "", "metadata": {}, "score": "74.22408"}
{"text": "R\u00e9sum\u00e9 .A method and apparatus for parsing in a spoken language translation system are provided , wherein an input is received comprising at least one input sentence or expression .A parsing table is accessed and consulted for a next action , wherein the parser looks up in the next action in the parsing table .", "label": "", "metadata": {}, "score": "74.2695"}
{"text": "A list of basic components in the hypotheses is generated 1806 , and credit is assigned to these basic units by raising the probabilities for the basic units 1808 .Then , all the basic probabilities in the language model are re - normalized 1810 which has the effect of slightly lowering all other basic probabilities .", "label": "", "metadata": {}, "score": "74.29428"}
{"text": "A list of basic components in the hypotheses is generated 1806 , and credit is assigned to these basic units by raising the probabilities for the basic units 1808 .Then , all the basic probabilities in the language model are re - normalized 1810 which has the effect of slightly lowering all other basic probabilities .", "label": "", "metadata": {}, "score": "74.29428"}
{"text": "A list of basic components in the hypotheses is generated 1806 , and credit is assigned to these basic units by raising the probabilities for the basic units 1808 .Then , all the basic probabilities in the language model are re - normalized 1810 which has the effect of slightly lowering all other basic probabilities .", "label": "", "metadata": {}, "score": "74.29428"}
{"text": "A list of basic components in the hypotheses is generated 1806 , and credit is assigned to these basic units by raising the probabilities for the basic units 1808 .Then , all the basic probabilities in the language model are re - normalized 1810 which has the effect of slightly lowering all other basic probabilities .", "label": "", "metadata": {}, "score": "74.29428"}
{"text": "A list of basic components in the hypotheses is generated 1806 , and credit is assigned to these basic units by raising the probabilities for the basic units 1808 .Then , all the basic probabilities in the language model are re - normalized 1810 which has the effect of slightly lowering all other basic probabilities .", "label": "", "metadata": {}, "score": "74.29428"}
{"text": "The apparatus of claim 15 , wherein each level of the at least one level of nested production rules comprises a production rule for a combination of the at least one linguistic constituent of the at least one input .The apparatus of claim 15 , wherein the at least one processor is further configured to identify by : . receiving at least one speech input comprising at least one source language expression ; . performing the syntactic analysis on the at least one source language expression and the at least one example database to recognize linguistic constituents ; . searching the at least one example database to find an expression pair having a source language portion most similar to the at least one source language expression ; . generating at least one target language expression using a target language portion of the expression pair ; and . providing at least one speech output comprising the at least one target language expression .", "label": "", "metadata": {}, "score": "74.34604"}
{"text": "The rules for adjectives ending in \" y \" comprise , but are not limited to , rules for : .The rules for irregular adjectives comprise , but are not limited to , rules wherein the following adjectives have irregular comparative and superlative forms which should have separate dictionary entries : .", "label": "", "metadata": {}, "score": "74.45179"}
{"text": "The rules for adjectives ending in \" y \" comprise , but are not limited to , rules for : .The rules for irregular adjectives comprise , but are not limited to , rules wherein the following adjectives have irregular comparative and superlative forms which should have separate dictionary entries : .", "label": "", "metadata": {}, "score": "74.45179"}
{"text": "The rules for adjectives ending in \" y \" comprise , but are not limited to , rules for : .The rules for irregular adjectives comprise , but are not limited to , rules wherein the following adjectives have irregular comparative and superlative forms which should have separate dictionary entries : .", "label": "", "metadata": {}, "score": "74.45179"}
{"text": "( CAT VERB ) .( VFORM PAST - PART ) ) .( ( ROOT \" study \" ) .( CAT VERB ) .( VFORM PAST ) ) ) .A third example comprises input and output feature structures for multiple morphological splits : .", "label": "", "metadata": {}, "score": "74.50072"}
{"text": "( CAT VERB ) .( VFORM PAST - PART ) ) .( ( ROOT \" study \" ) .( CAT VERB ) .( VFORM PAST ) ) ) .A third example comprises input and output feature structures for multiple morphological splits : .", "label": "", "metadata": {}, "score": "74.50072"}
{"text": "( CAT VERB ) .( VFORM PAST - PART ) ) .( ( ROOT \" study \" ) .( CAT VERB ) .( VFORM PAST ) ) ) .A third example comprises input and output feature structures for multiple morphological splits : .", "label": "", "metadata": {}, "score": "74.50072"}
{"text": "FIG .21 is an Analyzer for Inflectional Morphology ( AIM ) of an embodiment of the present invention .FIG .22 shows a sample input and output of an AIM of an embodiment of the present invention .FIG .", "label": "", "metadata": {}, "score": "74.7715"}
{"text": "FIG .21 is an Analyzer for Inflectional Morphology ( AIM ) of an embodiment of the present invention .FIG .22 shows a sample input and output of an AIM of an embodiment of the present invention .FIG .", "label": "", "metadata": {}, "score": "74.7715"}
{"text": "FIG .21 is an Analyzer for Inflectional Morphology ( AIM ) of an embodiment of the present invention .FIG .22 shows a sample input and output of an AIM of an embodiment of the present invention .FIG .", "label": "", "metadata": {}, "score": "74.7715"}
{"text": "FIG .21 is an Analyzer for Inflectional Morphology ( AIM ) of an embodiment of the present invention .FIG .22 shows a sample input and output of an AIM of an embodiment of the present invention .FIG .", "label": "", "metadata": {}, "score": "74.7715"}
{"text": "FIG .21 is an Analyzer for Inflectional Morphology ( AIM ) of an embodiment of the present invention .FIG .22 shows a sample input and output of an AIM of an embodiment of the present invention .FIG .", "label": "", "metadata": {}, "score": "74.7715"}
{"text": "12 shows the hypothesis selection components of a speech translation system of an embodiment of the present invention .FIG .13 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .14 is a diagram of a one embodiment of a display with alternative utterance hypotheses .", "label": "", "metadata": {}, "score": "74.780205"}
{"text": "12 shows the hypothesis selection components of a speech translation system of an embodiment of the present invention .FIG .13 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .14 is a diagram of a one embodiment of a display with alternative utterance hypotheses .", "label": "", "metadata": {}, "score": "74.780205"}
{"text": "12 shows the hypothesis selection components of a speech translation system of an embodiment of the present invention .FIG .13 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .14 is a diagram of a one embodiment of a display with alternative utterance hypotheses .", "label": "", "metadata": {}, "score": "74.780205"}
{"text": "12 shows the hypothesis selection components of a speech translation system of an embodiment of the present invention .FIG .13 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .14 is a diagram of a one embodiment of a display with alternative utterance hypotheses .", "label": "", "metadata": {}, "score": "74.780205"}
{"text": "12 shows the hypothesis selection components of a speech translation system of an embodiment of the present invention .FIG .13 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .14 is a diagram of a one embodiment of a display with alternative utterance hypotheses .", "label": "", "metadata": {}, "score": "74.780205"}
{"text": "19 shows an entry 1900 to which default inflectional rules apply in an embodiment of the present invention .( 2 ) Entries to which special inflectional rules apply : these entries comprise one or more features that indicate special morphographic changes or the ( in)ability to undergo certain inflections that are normally possible within a grammatical category .", "label": "", "metadata": {}, "score": "74.80621"}
{"text": "19 shows an entry 1900 to which default inflectional rules apply in an embodiment of the present invention .( 2 ) Entries to which special inflectional rules apply : these entries comprise one or more features that indicate special morphographic changes or the ( in)ability to undergo certain inflections that are normally possible within a grammatical category .", "label": "", "metadata": {}, "score": "74.80621"}
{"text": "19 shows an entry 1900 to which default inflectional rules apply in an embodiment of the present invention .( 2 ) Entries to which special inflectional rules apply : these entries comprise one or more features that indicate special morphographic changes or the ( in)ability to undergo certain inflections that are normally possible within a grammatical category .", "label": "", "metadata": {}, "score": "74.80621"}
{"text": "19 shows an entry 1900 to which default inflectional rules apply in an embodiment of the present invention .( 2 ) Entries to which special inflectional rules apply : these entries comprise one or more features that indicate special morphographic changes or the ( in)ability to undergo certain inflections that are normally possible within a grammatical category .", "label": "", "metadata": {}, "score": "74.80621"}
{"text": "19 shows an entry 1900 to which default inflectional rules apply in an embodiment of the present invention .( 2 ) Entries to which special inflectional rules apply : these entries comprise one or more features that indicate special morphographic changes or the ( in)ability to undergo certain inflections that are normally possible within a grammatical category .", "label": "", "metadata": {}, "score": "74.80621"}
{"text": "up .For its evaluation three measures are calculated : precision ( the . number of bracketing matches with respect to the total number of . bracketings returned by the parser ) , recall ( the number of bracketing .matches with respect to the number of bracketings in the corpus ) and .", "label": "", "metadata": {}, "score": "74.9135"}
{"text": "In addition , natural speech of people is not perfectly complete and grammatical - it also includes repeated words , omissions , and incomplete sentences .English morphology is a relatively well understood linguistic phenomenon , but its computational treatment in natural language processing and the design and integration of a morphological analyzer with other components of a system can be performed using one of two previous approaches .", "label": "", "metadata": {}, "score": "74.9166"}
{"text": "In addition , natural speech of people is not perfectly complete and grammatical - it also includes repeated words , omissions , and incomplete sentences .English morphology is a relatively well understood linguistic phenomenon , but its computational treatment in natural language processing and the design and integration of a morphological analyzer with other components of a system can be performed using one of two previous approaches .", "label": "", "metadata": {}, "score": "74.9166"}
{"text": "In addition , natural speech of people is not perfectly complete and grammatical - it also includes repeated words , omissions , and incomplete sentences .English morphology is a relatively well understood linguistic phenomenon , but its computational treatment in natural language processing and the design and integration of a morphological analyzer with other components of a system can be performed using one of two previous approaches .", "label": "", "metadata": {}, "score": "74.9166"}
{"text": "In addition , natural speech of people is not perfectly complete and grammatical - it also includes repeated words , omissions , and incomplete sentences .English morphology is a relatively well understood linguistic phenomenon , but its computational treatment in natural language processing and the design and integration of a morphological analyzer with other components of a system can be performed using one of two previous approaches .", "label": "", "metadata": {}, "score": "74.9166"}
{"text": "In addition , natural speech of people is not perfectly complete and grammatical - it also includes repeated words , omissions , and incomplete sentences .English morphology is a relatively well understood linguistic phenomenon , but its computational treatment in natural language processing and the design and integration of a morphological analyzer with other components of a system can be performed using one of two previous approaches .", "label": "", "metadata": {}, "score": "74.9166"}
{"text": "The user may choose or reject the selected hypothesis pair 1516 by activating \" OK \" 1518 or \" cancel \" 1519 .If the user has an adequate understanding of the target language , the embodiment of FIG .15 allows the user to confirm both the speech recognition result and the translation result .", "label": "", "metadata": {}, "score": "74.95763"}
{"text": "The user may choose or reject the selected hypothesis pair 1516 by activating \" OK \" 1518 or \" cancel \" 1519 .If the user has an adequate understanding of the target language , the embodiment of FIG .15 allows the user to confirm both the speech recognition result and the translation result .", "label": "", "metadata": {}, "score": "74.95763"}
{"text": "The user may choose or reject the selected hypothesis pair 1516 by activating \" OK \" 1518 or \" cancel \" 1519 .If the user has an adequate understanding of the target language , the embodiment of FIG .15 allows the user to confirm both the speech recognition result and the translation result .", "label": "", "metadata": {}, "score": "74.95763"}
{"text": "The user may choose or reject the selected hypothesis pair 1516 by activating \" OK \" 1518 or \" cancel \" 1519 .If the user has an adequate understanding of the target language , the embodiment of FIG .15 allows the user to confirm both the speech recognition result and the translation result .", "label": "", "metadata": {}, "score": "74.95763"}
{"text": "The user may choose or reject the selected hypothesis pair 1516 by activating \" OK \" 1518 or \" cancel \" 1519 .If the user has an adequate understanding of the target language , the embodiment of FIG .15 allows the user to confirm both the speech recognition result and the translation result .", "label": "", "metadata": {}, "score": "74.95763"}
{"text": "In some laptop embodiments , a conventional processor may be used to perform calculations according to the methods described herein .In other laptop embodiments , a digital signal processor ( DSP ) may be used to perform some or all of the calculations .", "label": "", "metadata": {}, "score": "75.115425"}
{"text": "In some laptop embodiments , a conventional processor may be used to perform calculations according to the methods described herein .In other laptop embodiments , a digital signal processor ( DSP ) may be used to perform some or all of the calculations .", "label": "", "metadata": {}, "score": "75.115425"}
{"text": "In some laptop embodiments , a conventional processor may be used to perform calculations according to the methods described herein .In other laptop embodiments , a digital signal processor ( DSP ) may be used to perform some or all of the calculations .", "label": "", "metadata": {}, "score": "75.115425"}
{"text": "In some laptop embodiments , a conventional processor may be used to perform calculations according to the methods described herein .In other laptop embodiments , a digital signal processor ( DSP ) may be used to perform some or all of the calculations .", "label": "", "metadata": {}, "score": "75.115425"}
{"text": "In some laptop embodiments , a conventional processor may be used to perform calculations according to the methods described herein .In other laptop embodiments , a digital signal processor ( DSP ) may be used to perform some or all of the calculations .", "label": "", "metadata": {}, "score": "75.115425"}
{"text": "The apparatus of claim 23 , wherein the basic probabilities are based on grammatical functions comprising subjects , verbs , and objects , wherein the basic probability is of the form .The apparatus of claim 23 , wherein adapting hypothesis generation comprises : . analyzing the best hypothesis ; . generating a list comprising the at least one basic component of the best hypothesis and the assigned basic probability ; . assigning credit to the at least one basic component of the best hypothesis by raising the assigned basic probability ; and .", "label": "", "metadata": {}, "score": "75.12443"}
{"text": "This paper is a presentation of the syntactic annotation of the NEGRA . newspaper corpus .Language - specific reasons ( free word order , among .others ) , corpus structure ( frequently elliptical constructions ) and .the characteristics of the formalism contributed to the choosing of .", "label": "", "metadata": {}, "score": "75.229126"}
{"text": "similar to the structure of the whole book , namely it has two parts , .entitled Building treebanks and Using treebanks , respectively .After .making the terminological distinction between tagged corpora and . parsed corpora ( or treebanks ) , the author emphasizes the reasons for .", "label": "", "metadata": {}, "score": "75.24267"}
{"text": "When the rules for consonant doubling apply , the final consonant is doubled for present participle , simple past and past participle forms .If the verb is irregular , consonant doubling should regularly occur for the present participle form .Third person singular verb forms remain unaffected by this rule .", "label": "", "metadata": {}, "score": "75.44021"}
{"text": "When the rules for consonant doubling apply , the final consonant is doubled for present participle , simple past and past participle forms .If the verb is irregular , consonant doubling should regularly occur for the present participle form .Third person singular verb forms remain unaffected by this rule .", "label": "", "metadata": {}, "score": "75.44021"}
{"text": "When the rules for consonant doubling apply , the final consonant is doubled for present participle , simple past and past participle forms .If the verb is irregular , consonant doubling should regularly occur for the present participle form .Third person singular verb forms remain unaffected by this rule .", "label": "", "metadata": {}, "score": "75.44021"}
{"text": "When the rules for consonant doubling apply , the final consonant is doubled for present participle , simple past and past participle forms .If the verb is irregular , consonant doubling should regularly occur for the present participle form .Third person singular verb forms remain unaffected by this rule .", "label": "", "metadata": {}, "score": "75.44021"}
{"text": "The method of claim 5 , wherein the at least one set of grammar rules comprise context - free grammar rules , wherein the context - free grammar rules use a plurality of non - terminal symbols .The method of claim 5 , wherein the at least one set of grammar rules comprise English parsing grammar rules and Japanese parsing grammar rules .", "label": "", "metadata": {}, "score": "75.77858"}
{"text": "The adverb default rules comprise , but are not limited to , rules that for : .The rules for irregular adverbs comprise , but are not limited to , rules wherein : .The morphological rules of an embodiment of the present invention treat auxiliaries and modals as irregular verbs , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "75.84813"}
{"text": "The adverb default rules comprise , but are not limited to , rules that for : .The rules for irregular adverbs comprise , but are not limited to , rules wherein : .The morphological rules of an embodiment of the present invention treat auxiliaries and modals as irregular verbs , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "75.84813"}
{"text": "The adverb default rules comprise , but are not limited to , rules that for : .The rules for irregular adverbs comprise , but are not limited to , rules wherein : .The morphological rules of an embodiment of the present invention treat auxiliaries and modals as irregular verbs , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "75.84813"}
{"text": "The adverb default rules comprise , but are not limited to , rules that for : .The rules for irregular adverbs comprise , but are not limited to , rules wherein : .The morphological rules of an embodiment of the present invention treat auxiliaries and modals as irregular verbs , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "75.84813"}
{"text": "The adverb default rules comprise , but are not limited to , rules that for : .The rules for irregular adverbs comprise , but are not limited to , rules wherein : .The morphological rules of an embodiment of the present invention treat auxiliaries and modals as irregular verbs , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "75.84813"}
{"text": "( 83 % ) , followed , at huge distance , by grammatical ones ( 16 % ) .TREEBANKS FOR SLAVIC LANGUAGES .Chapter 7 .The Prague Dependency Treebank .For the annotation of the Czech newspaper corpus , a 3-level structure . was used .", "label": "", "metadata": {}, "score": "75.9207"}
{"text": "ones .Both take into consideration the characteristics of Turkish , . especially its rich inflectional and derivational morphology .Thus , .each word is annotated for each of its morphemes , as this information . may be necessary for syntax .", "label": "", "metadata": {}, "score": "76.077805"}
{"text": "Lexical f - structure output by morphological analyzer : .( CAT VERB ) .( PERSON 3RD ) .( TENSE PRES ) .( NUMBER SING ) ) .( ( ROOT \" leaf \" ) .( CAT NOUN ) .", "label": "", "metadata": {}, "score": "76.164314"}
{"text": "Lexical f - structure output by morphological analyzer : .( CAT VERB ) .( PERSON 3RD ) .( TENSE PRES ) .( NUMBER SING ) ) .( ( ROOT \" leaf \" ) .( CAT NOUN ) .", "label": "", "metadata": {}, "score": "76.164314"}
{"text": "Lexical f - structure output by morphological analyzer : .( CAT VERB ) .( PERSON 3RD ) .( TENSE PRES ) .( NUMBER SING ) ) .( ( ROOT \" leaf \" ) .( CAT NOUN ) .", "label": "", "metadata": {}, "score": "76.164314"}
{"text": "MIT Press .Scha , R. ( 1990 )Taaltheorie en Taaltechnologie ; Competence en .Performance , in Q.A.M. de Kort and G.L.J. Leerdam ( Eds . )Computertoepassingen in de Neerlandistiek , Almere : Landelijke .Vereniging van Neerlandici ( LVVN - jaarboek ) .", "label": "", "metadata": {}, "score": "76.47158"}
{"text": "20 shows an entry 2000 that has an irregular inflection in an embodiment of the present invention .Having separate entries for each irregular form does add some complexity to dictionary maintenance , but the irregularly inflected forms are limited in number .", "label": "", "metadata": {}, "score": "76.76313"}
{"text": "20 shows an entry 2000 that has an irregular inflection in an embodiment of the present invention .Having separate entries for each irregular form does add some complexity to dictionary maintenance , but the irregularly inflected forms are limited in number .", "label": "", "metadata": {}, "score": "76.76313"}
{"text": "17 shows yet another embodiment of a display .Hypothesis set 1702 is displayed in response to a source language input .Hypothesis set 1702 includes the best hypothesis source language recognition \" I want to recognize speech . \" , along with the target language translation of the best hypothesis source language recognition and the back - translation \" I would like to understand speech .", "label": "", "metadata": {}, "score": "76.94972"}
{"text": "17 shows yet another embodiment of a display .Hypothesis set 1702 is displayed in response to a source language input .Hypothesis set 1702 includes the best hypothesis source language recognition \" I want to recognize speech . \" , along with the target language translation of the best hypothesis source language recognition and the back - translation \" I would like to understand speech .", "label": "", "metadata": {}, "score": "76.94972"}
{"text": "17 shows yet another embodiment of a display .Hypothesis set 1702 is displayed in response to a source language input .Hypothesis set 1702 includes the best hypothesis source language recognition \" I want to recognize speech . \" , along with the target language translation of the best hypothesis source language recognition and the back - translation \" I would like to understand speech .", "label": "", "metadata": {}, "score": "76.94972"}
{"text": "17 shows yet another embodiment of a display .Hypothesis set 1702 is displayed in response to a source language input .Hypothesis set 1702 includes the best hypothesis source language recognition \" I want to recognize speech . \" , along with the target language translation of the best hypothesis source language recognition and the back - translation \" I would like to understand speech .", "label": "", "metadata": {}, "score": "76.94972"}
{"text": "17 shows yet another embodiment of a display .Hypothesis set 1702 is displayed in response to a source language input .Hypothesis set 1702 includes the best hypothesis source language recognition \" I want to recognize speech . \" , along with the target language translation of the best hypothesis source language recognition and the back - translation \" I would like to understand speech .", "label": "", "metadata": {}, "score": "76.94972"}
{"text": "Furthermore , the global economy brings together business people of all nationalities in the execution of multinational business dealings , a forum requiring efficient and accurate communication .As a result , a need has developed for a machineaided interpersonal communication system that accepts natural fluent speech input one language and provides an accurate near real - time output comprising natural fluent speech in another language .", "label": "", "metadata": {}, "score": "76.999664"}
{"text": "The computer readable medium of claim 27 , wherein the method further comprises : . recognizing at least one word of the at least one speech input ; and .generating at least one word graph .The computer readable medium of claim 33 , wherein recognizing at least one word comprises : . using acoustic information comprising at least one word pronunciation dictionary and at least one acoustic model to generate at least one hypothesis for the at least one word ; and .", "label": "", "metadata": {}, "score": "77.03737"}
{"text": "The feature structure operation compiler 2504 provides an output comprising C language source code for the compiled feature structure functions 2524 , but is not so limited .The feature structure functions 2524 are compiled and linked with the GLR parsing engine 2506 .", "label": "", "metadata": {}, "score": "77.04849"}
{"text": "The feature structure operation compiler 2504 provides an output comprising C language source code for the compiled feature structure functions 2524 , but is not so limited .The feature structure functions 2524 are compiled and linked with the GLR parsing engine 2506 .", "label": "", "metadata": {}, "score": "77.04849"}
{"text": "The feature structure operation compiler 2504 provides an output comprising C language source code for the compiled feature structure functions 2524 , but is not so limited .The feature structure functions 2524 are compiled and linked with the GLR parsing engine 2506 .", "label": "", "metadata": {}, "score": "77.04849"}
{"text": "The feature structure operation compiler 2504 provides an output comprising C language source code for the compiled feature structure functions 2524 , but is not so limited .The feature structure functions 2524 are compiled and linked with the GLR parsing engine 2506 .", "label": "", "metadata": {}, "score": "77.04849"}
{"text": "The feature structure operation compiler 2504 provides an output comprising C language source code for the compiled feature structure functions 2524 , but is not so limited .The feature structure functions 2524 are compiled and linked with the GLR parsing engine 2506 .", "label": "", "metadata": {}, "score": "77.04849"}
{"text": "In this case the source language is English and the target language is Japanese .In one embodiment , the source language - target language pairs are displayed as an ordered list with the most likely hypothesis listed first and the least likely hypothesis listed last .", "label": "", "metadata": {}, "score": "77.26576"}
{"text": "In this case the source language is English and the target language is Japanese .In one embodiment , the source language - target language pairs are displayed as an ordered list with the most likely hypothesis listed first and the least likely hypothesis listed last .", "label": "", "metadata": {}, "score": "77.26576"}
{"text": "In this case the source language is English and the target language is Japanese .In one embodiment , the source language - target language pairs are displayed as an ordered list with the most likely hypothesis listed first and the least likely hypothesis listed last .", "label": "", "metadata": {}, "score": "77.26576"}
{"text": "In this case the source language is English and the target language is Japanese .In one embodiment , the source language - target language pairs are displayed as an ordered list with the most likely hypothesis listed first and the least likely hypothesis listed last .", "label": "", "metadata": {}, "score": "77.26576"}
{"text": "In this case the source language is English and the target language is Japanese .In one embodiment , the source language - target language pairs are displayed as an ordered list with the most likely hypothesis listed first and the least likely hypothesis listed last .", "label": "", "metadata": {}, "score": "77.26576"}
{"text": "of the first part address to treebanks for other languages ( Sinica , .Japanese , Turkish ) .ENGLISH TREEBANKS .Ch .The Penn Treebank : an Overview .Ann Taylor , Mitchell Marcus , and Beatrice Santorini .The authors present the annotation schemes and the methodology used .", "label": "", "metadata": {}, "score": "77.28096"}
{"text": "Use a parsing model for the biomedical domain : specify the option \" -genia \" .Use a parsing model for the literature domain : specify the option \" -brown \" .Use a supertagger : run \" mogura -super \" .", "label": "", "metadata": {}, "score": "77.29225"}
{"text": "Use a parsing model for the biomedical domain : specify the option \" -genia \" .Use a parsing model for the literature domain : specify the option \" -brown \" .Use a supertagger : run \" mogura -super \" .", "label": "", "metadata": {}, "score": "77.29225"}
{"text": "In one embodiment , if there are multiple segments that have alternative hypotheses , the largest segment is chosen as the highlighted segment .The user may activate the highlighted segment 1304 by , for example , moving a cursor to the highlighted segment 1304 and clicking a mouse button .", "label": "", "metadata": {}, "score": "77.500565"}
{"text": "In one embodiment , if there are multiple segments that have alternative hypotheses , the largest segment is chosen as the highlighted segment .The user may activate the highlighted segment 1304 by , for example , moving a cursor to the highlighted segment 1304 and clicking a mouse button .", "label": "", "metadata": {}, "score": "77.500565"}
{"text": "In one embodiment , if there are multiple segments that have alternative hypotheses , the largest segment is chosen as the highlighted segment .The user may activate the highlighted segment 1304 by , for example , moving a cursor to the highlighted segment 1304 and clicking a mouse button .", "label": "", "metadata": {}, "score": "77.500565"}
{"text": "In one embodiment , if there are multiple segments that have alternative hypotheses , the largest segment is chosen as the highlighted segment .The user may activate the highlighted segment 1304 by , for example , moving a cursor to the highlighted segment 1304 and clicking a mouse button .", "label": "", "metadata": {}, "score": "77.500565"}
{"text": "In one embodiment , if there are multiple segments that have alternative hypotheses , the largest segment is chosen as the highlighted segment .The user may activate the highlighted segment 1304 by , for example , moving a cursor to the highlighted segment 1304 and clicking a mouse button .", "label": "", "metadata": {}, "score": "77.500565"}
{"text": "Furthermore , the global economy brings together business people of all nationalities in the execution of multinational business dealings , a forum requiring efficient and accurate communication .As a result , a need has developed for a machine - aided interpersonal communication system that accepts natural fluent speech input one language and provides an accurate near real - time output comprising natural fluent speech in another language .", "label": "", "metadata": {}, "score": "77.50368"}
{"text": "Furthermore , the global economy brings together business people of all nationalities in the execution of multinational business dealings , a forum requiring efficient and accurate communication .As a result , a need has developed for a machine - aided interpersonal communication system that accepts natural fluent speech input one language and provides an accurate near real - time output comprising natural fluent speech in another language .", "label": "", "metadata": {}, "score": "77.50368"}
{"text": "Furthermore , the global economy brings together business people of all nationalities in the execution of multinational business dealings , a forum requiring efficient and accurate communication .As a result , a need has developed for a machine - aided interpersonal communication system that accepts natural fluent speech input one language and provides an accurate near real - time output comprising natural fluent speech in another language .", "label": "", "metadata": {}, "score": "77.50368"}
{"text": "The selected source language - target language pair 1414 is displayed with \" OK \" 1416 and \" cancel \" 1418 so that the user may select or reject source language - target language pair 1414 .FIG .15 is another embodiment of the present invention which is especially useful for users with some knowledge of the target language .", "label": "", "metadata": {}, "score": "77.61836"}
{"text": "The selected source language - target language pair 1414 is displayed with \" OK \" 1416 and \" cancel \" 1418 so that the user may select or reject source language - target language pair 1414 .FIG .15 is another embodiment of the present invention which is especially useful for users with some knowledge of the target language .", "label": "", "metadata": {}, "score": "77.61836"}
{"text": "The selected source language - target language pair 1414 is displayed with \" OK \" 1416 and \" cancel \" 1418 so that the user may select or reject source language - target language pair 1414 .FIG .15 is another embodiment of the present invention which is especially useful for users with some knowledge of the target language .", "label": "", "metadata": {}, "score": "77.61836"}
{"text": "The selected source language - target language pair 1414 is displayed with \" OK \" 1416 and \" cancel \" 1418 so that the user may select or reject source language - target language pair 1414 .FIG .15 is another embodiment of the present invention which is especially useful for users with some knowledge of the target language .", "label": "", "metadata": {}, "score": "77.61836"}
{"text": "The selected source language - target language pair 1414 is displayed with \" OK \" 1416 and \" cancel \" 1418 so that the user may select or reject source language - target language pair 1414 .FIG .15 is another embodiment of the present invention which is especially useful for users with some knowledge of the target language .", "label": "", "metadata": {}, "score": "77.61836"}
{"text": "marking each of a plurality of nodes for which at least one feature structure is to be rebuilt ; . maintaining at least one log comprising each of the plurality of nodes for which the at least one feature structure is to be rebuilt ; . locating at least one farthermost marked node from a root node when traversing at least one branch path of the at least one packed shared parse forest ; . rebuilding the at least one feature structure of the at least one farthermost marked node ; . rebuilding the at least one feature structure of each marked node in succession along the at least one branch path between the at least one farthermost marked and the root node ; and . rebuilding the root node .", "label": "", "metadata": {}, "score": "77.70803"}
{"text": "Self - contained portable embodiments include hardware and software for receiving a natural spoken language input , performing translation , performing speech synthesis on the translation , and outputting translated natural spoken language .Embodiments that are not self - contained include hardware and software for receiving natural spoken language input , digitizing the input , and transmitting the digitized input via various communication methods to remote hardware and software which performs translation .", "label": "", "metadata": {}, "score": "77.78453"}
{"text": "Description .FIELD OF THE INVENTION .This invention relates to speech or voice translation systems .More particularly , this invention relates to a spoken language translation system that performs speech - to - speech translation .BACKGROUND .Speech is the predominant mode of human communication because it is very efficient and convenient .", "label": "", "metadata": {}, "score": "77.849"}
{"text": "For example , one PDA embodiment may perform voice translation functions , voice memo functions , voice e - mail functions , and voice calendar functions , but is not so limited .Another embodiment smaller in size than a laptop computer is a telephone .", "label": "", "metadata": {}, "score": "77.909065"}
{"text": "For example , one PDA embodiment may perform voice translation functions , voice memo functions , voice e - mail functions , and voice calendar functions , but is not so limited .Another embodiment smaller in size than a laptop computer is a telephone .", "label": "", "metadata": {}, "score": "77.909065"}
{"text": "For example , one PDA embodiment may perform voice translation functions , voice memo functions , voice e - mail functions , and voice calendar functions , but is not so limited .Another embodiment smaller in size than a laptop computer is a telephone .", "label": "", "metadata": {}, "score": "77.909065"}
{"text": "For example , one PDA embodiment may perform voice translation functions , voice memo functions , voice e - mail functions , and voice calendar functions , but is not so limited .Another embodiment smaller in size than a laptop computer is a telephone .", "label": "", "metadata": {}, "score": "77.909065"}
{"text": "For example , one PDA embodiment may perform voice translation functions , voice memo functions , voice e - mail functions , and voice calendar functions , but is not so limited .Another embodiment smaller in size than a laptop computer is a telephone .", "label": "", "metadata": {}, "score": "77.909065"}
{"text": "Third person singular verb forms remain unaffected by this rule .Verbs that end in a short vowel plus one of the consonants listed , but do not follow the consonant doubling rule ( exceptions and irregular verbs ) are not be tagged with this feature in the dictionary .", "label": "", "metadata": {}, "score": "78.17719"}
{"text": "( ( ROOT \" saw \" ) .( CAT NOUN ) ) .A second example comprises input and output feature structures for one morphological split : .Lexical f - structure output by morphological analyzer : .( CAT NOUN ) .", "label": "", "metadata": {}, "score": "78.21472"}
{"text": "Speakers of different languages , however , face a formidable problem in that they can not effectively communicate in the face of their language barrier .This poses a real problem in today 's world because of the ease and frequency of travel between countries .", "label": "", "metadata": {}, "score": "78.365524"}
{"text": "( CAT VERB ) .( VFORM PAST ) ) ) .A third example comprises input and output feature structures for multiple morphological splits : .( CAT NOUN ) ) .Lexical f - structure output by morphological analyzer : .", "label": "", "metadata": {}, "score": "78.446045"}
{"text": "The method of claim 21 , further comprising accepting an indication from the user of a best hypothesis of the at least one candidate hypotheses .The method of claim 22 , further comprising : . indicating a subgroup of words in a source language representation portion of the best hypothesis , wherein there are alternative source language representations for the subgroup ; and . displaying at least one alternative source language representation of the subgroup .", "label": "", "metadata": {}, "score": "78.51671"}
{"text": "respect : they are clear , accessible and the information is introduced .gradually .The second part of the book has a more reduced group of .addressees than the first one , due to its technical details involved . by the presentation of different application in computer linguistics : .", "label": "", "metadata": {}, "score": "78.77664"}
{"text": "The computer readable medium of claim 25 , wherein the speech input comprises natural spoken language , wherein the natural spoken language comprises at least one word , at least one phrase , and at least one sentence .The computer readable medium of claim 25 , wherein the method further comprises : . detecting at least one meaning of the speech input , wherein the at least one meaning comprises statements and questions ; and .", "label": "", "metadata": {}, "score": "78.83359"}
{"text": "FIG .6 is a context - free phrase structure tree 600 of an embodiment of the present invention obtained by parsing the input \" I want to make a reservation for three people for tomorrow evening at seven o'clock . \" The context - free grammar of an embodiment identifies syntactic constituents comprising noun phrases 602 , verb phrases 604 , adjective phrases ( not shown ) , adverb phrases ( not shown ) , and post - positional phrases ( not shown ) , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "79.53491"}
{"text": "FIG .6 is a context - free phrase structure tree 600 of an embodiment of the present invention obtained by parsing the input \" I want to make a reservation for three people for tomorrow evening at seven o'clock . \" The context - free grammar of an embodiment identifies syntactic constituents comprising noun phrases 602 , verb phrases 604 , adjective phrases ( not shown ) , adverb phrases ( not shown ) , and post - positional phrases ( not shown ) , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "79.53491"}
{"text": "FIG .6 is a context - free phrase structure tree 600 of an embodiment of the present invention obtained by parsing the input \" I want to make a reservation for three people for tomorrow evening at seven o'clock . \" The context - free grammar of an embodiment identifies syntactic constituents comprising noun phrases 602 , verb phrases 604 , adjective phrases ( not shown ) , adverb phrases ( not shown ) , and post - positional phrases ( not shown ) , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "79.53491"}
{"text": "FIG .6 is a context - free phrase structure tree 600 of an embodiment of the present invention obtained by parsing the input \" I want to make a reservation for three people for tomorrow evening at seven o'clock . \" The context - free grammar of an embodiment identifies syntactic constituents comprising noun phrases 602 , verb phrases 604 , adjective phrases ( not shown ) , adverb phrases ( not shown ) , and post - positional phrases ( not shown ) , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "79.53491"}
{"text": "FIG .6 is a context - free phrase structure tree 600 of an embodiment of the present invention obtained by parsing the input \" I want to make a reservation for three people for tomorrow evening at seven o'clock . \" The context - free grammar of an embodiment identifies syntactic constituents comprising noun phrases 602 , verb phrases 604 , adjective phrases ( not shown ) , adverb phrases ( not shown ) , and post - positional phrases ( not shown ) , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "79.53491"}
{"text": "i .i .i . m .e .e .n . ) delete . cost .e .C .i .i . m .e .e .n . ) join .cost .i .", "label": "", "metadata": {}, "score": "79.567345"}
{"text": "i .i .i . m .e .e .n . ) delete . cost .e .C .i .i . m .e .e .n . ) join .cost .i .", "label": "", "metadata": {}, "score": "79.567345"}
{"text": "1 is a computer system hosting the speech translation system ( STS ) of an embodiment of the present invention .FIG .2 is a computer system memory hosting the speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "80.2053"}
{"text": "1 is a computer system hosting the speech translation system ( STS ) of an embodiment of the present invention .FIG .2 is a computer system memory hosting the speech translation system of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "80.2053"}
{"text": "The apparatus of claim 15 , wherein minimizing misrecognitions further comprises receiving an indication of a selection of one of the at least one source recognition hypothesis .The apparatus of claim 16 , wherein the apparatus is a portable computer comprising a read only memory ( ROM ) that stores at least one of a speech recognition module , a translation module , and a speech synthesis module .", "label": "", "metadata": {}, "score": "80.65512"}
{"text": "Berlin : Mouton de Gruyter , pp .379 - 397 .ABOUT THE REVIEWER .Verginica Barbu Mititelu is a researcher at the Romanian Institute for .Artificial Intelligence and a PhD candidate at the Bucharest .University .She has been involved in the development of a treebank for .", "label": "", "metadata": {}, "score": "80.65546"}
{"text": "C .i .i .i . m .e .e .n . ) delete .cos .t .e .C .i .i . m .e .e .n . ) join .", "label": "", "metadata": {}, "score": "80.69534"}
{"text": "C .i .i .i . m .e .e .n . ) delete .cos .t .e .C .i .i . m .e .e .n . ) join .", "label": "", "metadata": {}, "score": "80.69534"}
{"text": "In an embodiment , nouns ending in \" ss \" , \" sh \" , \" ch \" , \" x \" , \" o \" are handled by the rules as follows , but are not so limited : . plural , insert \" e \" at the end of the root and apply plural formation default rule ( add \" s \" ) ( e.g. \" wish \" ; \" dress \" ; \" fox \" ; \" tomato \" ) ; .", "label": "", "metadata": {}, "score": "80.8911"}
{"text": "The method of claim 1 , wherein the input received is an output of an optical character recognition ( OCR ) process .The method of claim 1 , wherein the input received is an output of one of a group comprising a handwriting recognition process and an optical character recognition ( OCR ) process .", "label": "", "metadata": {}, "score": "81.84908"}
{"text": "( ( ROOT \" study \" ) .( CAT VERB ) .( PERSON 3RD ) .( TENSE PRES ) .( NUMBER SING ) ) ) .Input string : studied .( CAT VERB ) .( VFORM PAST - PART ) ) .", "label": "", "metadata": {}, "score": "81.87059"}
{"text": "The apparatus of claim 16 , wherein the apparatus is a personal data assistant ( PDA ) device .Apparatus of claim 13 , wherein the speech signals comprise analog audio signals generated by natural spoken language , and wherein the natural spoken language comprises at least one word , at least one phrase , and at least one sentence .", "label": "", "metadata": {}, "score": "81.871925"}
{"text": "recursively rebuilding the at least one node .The computer readable medium of claim 27 , wherein recursively rebuilding comprises : . marking each of a plurality of nodes for which at least one feature structure is to be rebuilt ; . maintaining at least one log comprising each of the plurality of nodes for which the at least one feature structure is to be rebuilt ; . locating at least one farthermost marked node from a root node when traversing at least one branch path of the at least one packed shared parse forest ; . rebuilding the at least one feature structure of the at least one farthermost marked node ; . rebuilding the at least one feature structure of each marked node in succession along the at least one branch path between the at least one farthermost marked and the root node ; and . rebuilding the root node .", "label": "", "metadata": {}, "score": "81.97914"}
{"text": "information from it were developed .Chapter 14 .Building a Japanese Parsed Corpus .Sadao Kurohashi , Makoto Nagao .The morphological and syntactic annotation of a Japanese newspaper .corpus is presented in this paper .It developed in parallel with the . improvement of the morphological analyzer JUMAN and of the dependency . structure analyzer KNP ( chosen in accordance with the characteristics . of Japanese ) .", "label": "", "metadata": {}, "score": "82.025055"}
{"text": "The computer readable medium of claim 27 , wherein the plurality of recognition hypotheses is ordered .The computer readable medium of claim 27 , wherein the at least one speech input comprises spoken language comprising at least one source language .", "label": "", "metadata": {}, "score": "82.701096"}
{"text": "The apparatus of claim 14 , wherein the at least one speech input comprises spoken language comprising at least one source language .The apparatus of claim 14 , wherein the potential variability is attributable to one or more of user accent , user pronunciation , volume level , microphone positions , and background noise .", "label": "", "metadata": {}, "score": "82.722305"}
{"text": "FIG .9 shows a bilingual example database 900 of an embodiment of the present invention .The bilingual example database 900 comprises a large database of pre - translated bilingual expression pairs 902 , but is not so limited .When an input expression 904 is received into the bilingual example database 900 , the STS of an embodiment consults the bilingual example database 900 to find the expression pair 999 whose source language portion ExJi is most similar to the input 904 .", "label": "", "metadata": {}, "score": "82.884544"}
{"text": "FIG .9 shows a bilingual example database 900 of an embodiment of the present invention .The bilingual example database 900 comprises a large database of pre - translated bilingual expression pairs 902 , but is not so limited .When an input expression 904 is received into the bilingual example database 900 , the STS of an embodiment consults the bilingual example database 900 to find the expression pair 999 whose source language portion ExEi is most similar to the input 904 .", "label": "", "metadata": {}, "score": "83.1157"}
{"text": "FIG .9 shows a bilingual example database 900 of an embodiment of the present invention .The bilingual example database 900 comprises a large database of pre - translated bilingual expression pairs 902 , but is not so limited .When an input expression 904 is received into the bilingual example database 900 , the STS of an embodiment consults the bilingual example database 900 to find the expression pair 999 whose source language portion ExEi is most similar to the input 904 .", "label": "", "metadata": {}, "score": "83.1157"}
{"text": "FIG .9 shows a bilingual example database 900 of an embodiment of the present invention .The bilingual example database 900 comprises a large database of pre - translated bilingual expression pairs 902 , but is not so limited .When an input expression 904 is received into the bilingual example database 900 , the STS of an embodiment consults the bilingual example database 900 to find the expression pair 999 whose source language portion ExEi is most similar to the input 904 .", "label": "", "metadata": {}, "score": "83.1157"}
{"text": "FIG .9 shows a bilingual example database 900 of an embodiment of the present invention .The bilingual example database 900 comprises a large database of pre - translated bilingual expression pairs 902 , but is not so limited .When an input expression 904 is received into the bilingual example database 900 , the STS of an embodiment consults the bilingual example database 900 to find the expression pair 999 whose source language portion ExEi is most similar to the input 904 .", "label": "", "metadata": {}, "score": "83.1157"}
{"text": "The sentence 1314 is the translated input as modified by the user .If the sentence 1314 is acceptable to the user it may be selected for translation by activating the \" OK \" 1316 .If the sentence 1314 is not acceptable , it may be rejected by activating the \" cancel \" 1318 .", "label": "", "metadata": {}, "score": "83.50772"}
{"text": "The sentence 1314 is the translated input as modified by the user .If the sentence 1314 is acceptable to the user it may be selected for translation by activating the \" OK \" 1316 .If the sentence 1314 is not acceptable , it may be rejected by activating the \" cancel \" 1318 .", "label": "", "metadata": {}, "score": "83.50772"}
{"text": "The sentence 1314 is the translated input as modified by the user .If the sentence 1314 is acceptable to the user it may be selected for translation by activating the \" OK \" 1316 .If the sentence 1314 is not acceptable , it may be rejected by activating the \" cancel \" 1318 .", "label": "", "metadata": {}, "score": "83.50772"}
{"text": "The sentence 1314 is the translated input as modified by the user .If the sentence 1314 is acceptable to the user it may be selected for translation by activating the \" OK \" 1316 .If the sentence 1314 is not acceptable , it may be rejected by activating the \" cancel \" 1318 .", "label": "", "metadata": {}, "score": "83.50772"}
{"text": "The sentence 1314 is the translated input as modified by the user .If the sentence 1314 is acceptable to the user it may be selected for translation by activating the \" OK \" 1316 .If the sentence 1314 is not acceptable , it may be rejected by activating the \" cancel \" 1318 .", "label": "", "metadata": {}, "score": "83.50772"}
{"text": "C .i .i .i . m .e .e .e .n . min .C .i .i . m .e .e .e .n . ) add .cos .t .", "label": "", "metadata": {}, "score": "83.618614"}
{"text": "C .i .i .i . m .e .e .e .n . min .C .i .i . m .e .e .e .n . ) add .cos .t .", "label": "", "metadata": {}, "score": "83.618614"}
{"text": "The system bus 101 is also coupled to receive inputs from a keyboard 122 , a pointing device 123 , and a speech signal input device 125 , but is not so limited .The system bus 101 provides outputs to a display device 121 , a hard copy device 124 , and an output device 126 , but is not so limited .", "label": "", "metadata": {}, "score": "83.89136"}
{"text": "The system bus 101 is also coupled to receive inputs from a keyboard 122 , a pointing device 123 , and a speech signal input device 125 , but is not so limited .The system bus 101 provides outputs to a display device 121 , a hard copy device 124 , and an output device 126 , but is not so limited .", "label": "", "metadata": {}, "score": "83.89136"}
{"text": "The system bus 101 is also coupled to receive inputs from a keyboard 122 , a pointing device 123 , and a speech signal input device 125 , but is not so limited .The system bus 101 provides outputs to a display device 121 , a hard copy device 124 , and an output device 126 , but is not so limited .", "label": "", "metadata": {}, "score": "83.89136"}
{"text": "The system bus 101 is also coupled to receive inputs from a keyboard 122 , a pointing device 123 , and a speech signal input device 125 , but is not so limited .The system bus 101 provides outputs to a display device 121 , a hard copy device 124 , and an output device 126 , but is not so limited .", "label": "", "metadata": {}, "score": "83.89136"}
{"text": "The system bus 101 is also coupled to receive inputs from a keyboard 122 , a pointing device 123 , and a speech signal input device 125 , but is not so limited .The system bus 101 provides outputs to a display device 121 , a hard copy device 124 , and an output device 126 , but is not so limited .", "label": "", "metadata": {}, "score": "83.89136"}
{"text": "15 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .16 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .17 is a diagram of a one embodiment of a display with alternative utterance hypotheses .", "label": "", "metadata": {}, "score": "84.007904"}
{"text": "15 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .16 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .17 is a diagram of a one embodiment of a display with alternative utterance hypotheses .", "label": "", "metadata": {}, "score": "84.007904"}
{"text": "15 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .16 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .17 is a diagram of a one embodiment of a display with alternative utterance hypotheses .", "label": "", "metadata": {}, "score": "84.007904"}
{"text": "15 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .16 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .17 is a diagram of a one embodiment of a display with alternative utterance hypotheses .", "label": "", "metadata": {}, "score": "84.007904"}
{"text": "15 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .16 is a diagram of a one embodiment of a display with alternative utterance hypotheses .FIG .17 is a diagram of a one embodiment of a display with alternative utterance hypotheses .", "label": "", "metadata": {}, "score": "84.007904"}
{"text": "The effects of the consonant doubling rules with examples follow : . \" ship \" ; \" shop \" ; \" slip \" ; \" step \" ; \" stop \" ; tip \" ; \" trap \" ; \" wrap \" ) ; . put \" ; \" set \" ; \" shut \" ; \" sit \" ; \" upset \" ) ; . \"", "label": "", "metadata": {}, "score": "84.25956"}
{"text": "recursively rebuilding the at least one node .The apparatus of claim 15 , wherein recursively rebuilding comprises : . marking each of a plurality of nodes for which at least one feature structure is to be rebuilt ; . maintaining at least one log comprising each of the plurality of nodes for which the at least one feature structure is to be rebuilt ; . locating at least one farthermost marked node from a root node when traversing at least one branch path of the at least one packed shared parse forest ; . rebuilding the at least one feature structure of the at least one farthermost marked node ; . rebuilding the at least one feature structure of each marked node in succession along the at least one branch path between the at least one farthermost marked and the root node ; and . rebuilding the root node .", "label": "", "metadata": {}, "score": "84.38667"}
{"text": "The apparatus of claim 18 , wherein the apparatus further comprises a graphical user interface ( GUI ) , including a display , wherein the display displays the at least one source recognition hypothesis .The apparatus of claim 19 , wherein the indication of the selection of one of the at least one source recognition hypothesis is entered by a user through the GUI .", "label": "", "metadata": {}, "score": "84.39522"}
{"text": "FIG .7 is a final feature structure 700 of an embodiment of the present invention representing a shallow syntactic analysis of the input \" I want to make a reservation for three people for tomorrow evening .\" The shallow syntactic analysis described herein may be applied to the example pairs as well as to the input , and it is general enough to be used across different domains .", "label": "", "metadata": {}, "score": "84.87727"}
{"text": "FIG .7 is a final feature structure 700 of an embodiment of the present invention representing a shallow syntactic analysis of the input \" I want to make a reservation for three people for tomorrow evening .\" The shallow syntactic analysis described herein may be applied to the example pairs as well as to the input , and it is general enough to be used across different domains .", "label": "", "metadata": {}, "score": "84.87727"}
{"text": "FIG .7 is a final feature structure 700 of an embodiment of the present invention representing a shallow syntactic analysis of the input \" I want to make a reservation for three people for tomorrow evening .\" The shallow syntactic analysis described herein may be applied to the example pairs as well as to the input , and it is general enough to be used across different domains .", "label": "", "metadata": {}, "score": "84.87727"}
{"text": "FIG .7 is a final feature structure 700 of an embodiment of the present invention representing a shallow syntactic analysis of the input \" I want to make a reservation for three people for tomorrow evening .\" The shallow syntactic analysis described herein may be applied to the example pairs as well as to the input , and it is general enough to be used across different domains .", "label": "", "metadata": {}, "score": "84.87727"}
{"text": "FIG .7 is a final feature structure 700 of an embodiment of the present invention representing a shallow syntactic analysis of the input \" I want to make a reservation for three people for tomorrow evening .\" The shallow syntactic analysis described herein may be applied to the example pairs as well as to the input , and it is general enough to be used across different domains .", "label": "", "metadata": {}, "score": "84.87727"}
{"text": "C .i .i .i . m .e .e .e .n . min .C .i .i . m .e .e .e .n . ) add . cost .i .", "label": "", "metadata": {}, "score": "85.758095"}
{"text": "C .i .i .i . m .e .e .e .n . min .C .i .i . m .e .e .e .n . ) add . cost .i .", "label": "", "metadata": {}, "score": "85.758095"}
{"text": "Cursor 1312 is shown activating the alternative \" beach \" .In one embodiment , the user corrections to alternatives are stored with an indication of a slightly greater likelihood of being correct .Over time , if the particular correction is made repeatedly , it accrues more likelihood of being a correct alternative each time it is chosen .", "label": "", "metadata": {}, "score": "85.92629"}
{"text": "Cursor 1312 is shown activating the alternative \" beach \" .In one embodiment , the user corrections to alternatives are stored with an indication of a slightly greater likelihood of being correct .Over time , if the particular correction is made repeatedly , it accrues more likelihood of being a correct alternative each time it is chosen .", "label": "", "metadata": {}, "score": "85.92629"}
{"text": "Cursor 1312 is shown activating the alternative \" beach \" .In one embodiment , the user corrections to alternatives are stored with an indication of a slightly greater likelihood of being correct .Over time , if the particular correction is made repeatedly , it accrues more likelihood of being a correct alternative each time it is chosen .", "label": "", "metadata": {}, "score": "85.92629"}
{"text": "Cursor 1312 is shown activating the alternative \" beach \" .In one embodiment , the user corrections to alternatives are stored with an indication of a slightly greater likelihood of being correct .Over time , if the particular correction is made repeatedly , it accrues more likelihood of being a correct alternative each time it is chosen .", "label": "", "metadata": {}, "score": "85.92629"}
{"text": "Cursor 1312 is shown activating the alternative \" beach \" .In one embodiment , the user corrections to alternatives are stored with an indication of a slightly greater likelihood of being correct .Over time , if the particular correction is made repeatedly , it accrues more likelihood of being a correct alternative each time it is chosen .", "label": "", "metadata": {}, "score": "85.92629"}
{"text": "22 shows a sample input 2202 and output 2204 of an AIM of an embodiment of the present invention .Example input and output feature structures of an embodiment of the present invention follow , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "86.23345"}
{"text": "22 shows a sample input 2202 and output 2204 of an AIM of an embodiment of the present invention .Example input and output feature structures of an embodiment of the present invention follow , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "86.23345"}
{"text": "22 shows a sample input 2202 and output 2204 of an AIM of an embodiment of the present invention .Example input and output feature structures of an embodiment of the present invention follow , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "86.23345"}
{"text": "22 shows a sample input 2202 and output 2204 of an AIM of an embodiment of the present invention .Example input and output feature structures of an embodiment of the present invention follow , but the embodiment is not so limited .", "label": "", "metadata": {}, "score": "86.23345"}
{"text": "7 is a final feature structure of an embodiment of the present invention representing a shallow syntactic analysis of the input \" I want to make a reservation for three people for tomorrow evening . \"FIG .8 shows an example - based translation system architecture using syntactic analysis of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "86.541824"}
{"text": "7 is a final feature structure of an embodiment of the present invention representing a shallow syntactic analysis of the input \" I want to make a reservation for three people for tomorrow evening . \"FIG .8 shows an example - based translation system architecture using syntactic analysis of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "86.541824"}
{"text": "7 is a final feature structure of an embodiment of the present invention representing a shallow syntactic analysis of the input \" I want to make a reservation for three people for tomorrow evening . \"FIG .8 shows an example - based translation system architecture using syntactic analysis of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "86.541824"}
{"text": "7 is a final feature structure of an embodiment of the present invention representing a shallow syntactic analysis of the input \" I want to make a reservation for three people for tomorrow evening . \"FIG .8 shows an example - based translation system architecture using syntactic analysis of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "86.541824"}
{"text": "7 is a final feature structure of an embodiment of the present invention representing a shallow syntactic analysis of the input \" I want to make a reservation for three people for tomorrow evening . \"FIG .8 shows an example - based translation system architecture using syntactic analysis of an embodiment of the present invention .", "label": "", "metadata": {}, "score": "86.541824"}
{"text": "The apparatus of claim 17 , wherein the at least one set of grammar rules comprise context - free grammar rules , wherein the context - free grammar rules use approximately 78 non - terminal symbols .The apparatus of claim 17 , wherein the at least one set of grammar rules comprise English parsing grammar rules and Japanese parsing grammar rules .", "label": "", "metadata": {}, "score": "87.24471"}
{"text": "27 is a parsing engine 2506 of an embodiment of the present invention .The parsing engine 2506 comprises feature structure actions 2702 and safe ambiguity packing 2704 , but is not so limited .Moreover , the parsing engine 2506 comprises a graph - structured stack 2710 as a general device for efficient handling of nondeterminism in the stack .", "label": "", "metadata": {}, "score": "87.37101"}
{"text": "27 is a parsing engine 2506 of an embodiment of the present invention .The parsing engine 2506 comprises feature structure actions 2702 and safe ambiguity packing 2704 , but is not so limited .Moreover , the parsing engine 2506 comprises a graph - structured stack 2710 as a general device for efficient handling of nondeterminism in the stack .", "label": "", "metadata": {}, "score": "87.37101"}
{"text": "27 is a parsing engine 2506 of an embodiment of the present invention .The parsing engine 2506 comprises feature structure actions 2702 and safe ambiguity packing 2704 , but is not so limited .Moreover , the parsing engine 2506 comprises a graph - structured stack 2710 as a general device for efficient handling of nondeterminism in the stack .", "label": "", "metadata": {}, "score": "87.37101"}
{"text": "27 is a parsing engine 2506 of an embodiment of the present invention .The parsing engine 2506 comprises feature structure actions 2702 and safe ambiguity packing 2704 , but is not so limited .Moreover , the parsing engine 2506 comprises a graph - structured stack 2710 as a general device for efficient handling of nondeterminism in the stack .", "label": "", "metadata": {}, "score": "87.37101"}
{"text": "27 is a parsing engine 2506 of an embodiment of the present invention .The parsing engine 2506 comprises feature structure actions 2702 and safe ambiguity packing 2704 , but is not so limited .Moreover , the parsing engine 2506 comprises a graph - structured stack 2710 as a general device for efficient handling of nondeterminism in the stack .", "label": "", "metadata": {}, "score": "87.37101"}
{"text": "The method of claim 15 , wherein presenting comprises displaying on a display device .The method of claim 15 , wherein the input comprises spoken words .The method of claim 15 , wherein the input received is an output of a keyboard device .", "label": "", "metadata": {}, "score": "88.09211"}
{"text": "Display 1306 includes the best utterance hypothesis and several alternative hypotheses for segment 1304 .The alternative hypotheses vary in one segment .In this case , the segment is the highlighted word 1308 , \" peach \" .When the highlighted segment 1308 is activated by the user , the alternatives 1310 to \" peach \" appear .", "label": "", "metadata": {}, "score": "88.562904"}
{"text": "Display 1306 includes the best utterance hypothesis and several alternative hypotheses for segment 1304 .The alternative hypotheses vary in one segment .In this case , the segment is the highlighted word 1308 , \" peach \" .When the highlighted segment 1308 is activated by the user , the alternatives 1310 to \" peach \" appear .", "label": "", "metadata": {}, "score": "88.562904"}
{"text": "Display 1306 includes the best utterance hypothesis and several alternative hypotheses for segment 1304 .The alternative hypotheses vary in one segment .In this case , the segment is the highlighted word 1308 , \" peach \" .When the highlighted segment 1308 is activated by the user , the alternatives 1310 to \" peach \" appear .", "label": "", "metadata": {}, "score": "88.562904"}
{"text": "Display 1306 includes the best utterance hypothesis and several alternative hypotheses for segment 1304 .The alternative hypotheses vary in one segment .In this case , the segment is the highlighted word 1308 , \" peach \" .When the highlighted segment 1308 is activated by the user , the alternatives 1310 to \" peach \" appear .", "label": "", "metadata": {}, "score": "88.562904"}
{"text": "Display 1306 includes the best utterance hypothesis and several alternative hypotheses for segment 1304 .The alternative hypotheses vary in one segment .In this case , the segment is the highlighted word 1308 , \" peach \" .When the highlighted segment 1308 is activated by the user , the alternatives 1310 to \" peach \" appear .", "label": "", "metadata": {}, "score": "88.562904"}
{"text": "Furthermore , surface variations are reduced into features .For example , \" I eat an apple \" and \" I ate an apple \" will have the same analysis except that the second one has the feature indicating that the tense is past .", "label": "", "metadata": {}, "score": "88.76843"}
{"text": "Furthermore , surface variations are reduced into features .For example , \" I eat an apple \" and \" I ate an apple \" will have the same analysis except that the second one has the feature indicating that the tense is past .", "label": "", "metadata": {}, "score": "88.76843"}
{"text": "Furthermore , surface variations are reduced into features .For example , \" I eat an apple \" and \" I ate an apple \" will have the same analysis except that the second one has the feature indicating that the tense is past .", "label": "", "metadata": {}, "score": "88.76843"}
{"text": "Furthermore , surface variations are reduced into features .For example , \" I eat an apple \" and \" I ate an apple \" will have the same analysis except that the second one has the feature indicating that the tense is past .", "label": "", "metadata": {}, "score": "88.76843"}
{"text": "Furthermore , surface variations are reduced into features .For example , \" I eat an apple \" and \" I ate an apple \" will have the same analysis except that the second one has the feature indicating that the tense is past .", "label": "", "metadata": {}, "score": "88.76843"}
{"text": "FIELD OF THE INVENTION .This invention relates to speech or voice translation systems .More particularly , this invention relates to a spoken language translation system that performs speech - to - speech translation .BACKGROUND .Speech is the predominant mode of human communication because it is very efficient and convenient .", "label": "", "metadata": {}, "score": "89.92771"}
{"text": "FIELD OF THE INVENTION .This invention relates to speech or voice translation systems .More particularly , this invention relates to a spoken language translation system that performs speech - to - speech translation .BACKGROUND .Speech is the predominant mode of human communication because it is very efficient and convenient .", "label": "", "metadata": {}, "score": "89.92771"}
{"text": "FIELD OF THE INVENTION .This invention relates to speech or voice translation systems .More particularly , this invention relates to a spoken language translation system that performs speech - to - speech translation .BACKGROUND .Speech is the predominant mode of human communication because it is very efficient and convenient .", "label": "", "metadata": {}, "score": "89.92771"}
{"text": "REFERENCES .Barnett , R. , N. Calzolari , S. Flores , P. Hellwig , P. Kahrel , .G. Leech , M. Melera , S. Montemagni , J. Odijk , V. Pirrelli , . A. Sanfilippo , S. Teufel , M. Villegas , L. Zaysser ( 1996 ) EAGLES .", "label": "", "metadata": {}, "score": "90.24056"}
{"text": "The noun default rules comprise , but are not limited to , rules that for : .Regarding the zero singular noun rules , some nouns do not have a singular form and are marked as such .These nouns behave like singular forms ( e.g. no article ; verb takes a plural form ; quantifiers to express number ) ( e.g. \" scissors \" ; \" trousers \" ; \" binoculars \" ; \" clippers \" ) .", "label": "", "metadata": {}, "score": "90.32582"}
{"text": "The apparatus of claim 47 , wherein the apparatus is a portable computer comprising a memory means that stores at least one of a speech recognition module , a translation module , and a speech synthesis module .The apparatus of claim 48 , wherein the apparatus further comprises a digital signal processing means that performs calculations required for speech recognition , translation and synthesis .", "label": "", "metadata": {}, "score": "90.350365"}
{"text": "The apparatus of claim 39 , wherein transmitting includes using light modulation .The apparatus of claim 39 , wherein transmitting includes using a cellular telephone frequency spectrum .A apparatus for spoken language translation comprising : . at least one processing means ; . an input means coupled to the at least one processing means , wherein the input means receives speech signals comprising an expression in a source language , the at least one processing means configured to translate the received speech signals by , . translating the recognized expression in the source language to an expression in a target language ; and . synthesizing a speech output from the expression in the target language ; and .", "label": "", "metadata": {}, "score": "90.358505"}
{"text": "The apparatus of claim 38 , wherein the first form is natural spoken language , wherein the second form is a digital form , and wherein converting the output in the second form includes performing speech synthesis .The apparatus of claim 39 , wherein transmitting includes using a frequency modulation ( FM ) spectrum .", "label": "", "metadata": {}, "score": "90.741516"}
{"text": "Cursor 1608 is shown activating the target language hypothesis of hypothesis set 1606 , which causes hypothesis set 1606 to be displayed as selected hypothesis set 1610 .The user may accept or reject selected hypothesis set 1610 by activating \" OK \" 1612 or \" cancel \" 1614 \" .", "label": "", "metadata": {}, "score": "92.5285"}
{"text": "Cursor 1608 is shown activating the target language hypothesis of hypothesis set 1606 , which causes hypothesis set 1606 to be displayed as selected hypothesis set 1610 .The user may accept or reject selected hypothesis set 1610 by activating \" OK \" 1612 or \" cancel \" 1614 \" .", "label": "", "metadata": {}, "score": "92.5285"}
{"text": "Cursor 1608 is shown activating the target language hypothesis of hypothesis set 1606 , which causes hypothesis set 1606 to be displayed as selected hypothesis set 1610 .The user may accept or reject selected hypothesis set 1610 by activating \" OK \" 1612 or \" cancel \" 1614 \" .", "label": "", "metadata": {}, "score": "92.5285"}
{"text": "Cursor 1608 is shown activating the target language hypothesis of hypothesis set 1606 , which causes hypothesis set 1606 to be displayed as selected hypothesis set 1610 .The user may accept or reject selected hypothesis set 1610 by activating \" OK \" 1612 or \" cancel \" 1614 \" .", "label": "", "metadata": {}, "score": "92.5285"}
{"text": "Cursor 1608 is shown activating the target language hypothesis of hypothesis set 1606 , which causes hypothesis set 1606 to be displayed as selected hypothesis set 1610 .The user may accept or reject selected hypothesis set 1610 by activating \" OK \" 1612 or \" cancel \" 1614 \" .", "label": "", "metadata": {}, "score": "92.5285"}
{"text": "The computer readable medium of claim 29 , wherein the at least one set of grammar rules comprise context - free grammar rules , wherein the context - free grammar rules use approximately 78 non - terminal symbols .The computer readable medium of claim 29 , wherein the at least one set of grammar rules comprise English parsing grammar rules and Japanese parsing grammar rules .", "label": "", "metadata": {}, "score": "93.401535"}
{"text": "These nouns behave like singular forms ( e.g. no article ; verb takes a plural form ; quantifiers to express number ) ( e.g. \" scissors \" ; \" trousers \" ; \" binoculars \" ; \" clippers \" ) .Regarding the identical singular and plural form noun rules , for some words , plural and singular have identical surface forms , which do behave like regular singular and plural forms ( e.g. with respect to verb forms ) and have countable instances ( e.g. \" sheep \" ) .", "label": "", "metadata": {}, "score": "93.864044"}
{"text": "These nouns behave like singular forms ( e.g. no article ; verb takes a plural form ; quantifiers to express number ) ( e.g. \" scissors \" ; \" trousers \" ; \" binoculars \" ; \" clippers \" ) .Regarding the identical singular and plural form noun rules , for some words , plural and singular have identical surface forms , which do behave like regular singular and plural forms ( e.g. with respect to verb forms ) and have countable instances ( e.g. \" sheep \" ) .", "label": "", "metadata": {}, "score": "93.864044"}
{"text": "These nouns behave like singular forms ( e.g. no article ; verb takes a plural form ; quantifiers to express number ) ( e.g. \" scissors \" ; \" trousers \" ; \" binoculars \" ; \" clippers \" ) .Regarding the identical singular and plural form noun rules , for some words , plural and singular have identical surface forms , which do behave like regular singular and plural forms ( e.g. with respect to verb forms ) and have countable instances ( e.g. \" sheep \" ) .", "label": "", "metadata": {}, "score": "93.864044"}
{"text": "These nouns behave like singular forms ( e.g. no article ; verb takes a plural form ; quantifiers to express number ) ( e.g. \" scissors \" ; \" trousers \" ; \" binoculars \" ; \" clippers \" ) .Regarding the identical singular and plural form noun rules , for some words , plural and singular have identical surface forms , which do behave like regular singular and plural forms ( e.g. with respect to verb forms ) and have countable instances ( e.g. \" sheep \" ) .", "label": "", "metadata": {}, "score": "93.864044"}
{"text": "A speech recognizer 402 operates on the source language speech input 302 to produce an intermediate data structure in coding multiple hypotheses 404 .A hypothesis construction module 406 produces at least one speech recognition hypothesis 408 from the coded multiple hypotheses 404 .", "label": "", "metadata": {}, "score": "94.04628"}
{"text": "A speech recognizer 402 operates on the source language speech input 302 to produce an intermediate data structure in coding multiple hypotheses 404 .A hypothesis construction module 406 produces at least one speech recognition hypothesis 408 from the coded multiple hypotheses 404 .", "label": "", "metadata": {}, "score": "94.04628"}
{"text": "A speech recognizer 402 operates on the source language speech input 302 to produce an intermediate data structure in coding multiple hypotheses 404 .A hypothesis construction module 406 produces at least one speech recognition hypothesis 408 from the coded multiple hypotheses 404 .", "label": "", "metadata": {}, "score": "94.04628"}
{"text": "A speech recognizer 402 operates on the source language speech input 302 to produce an intermediate data structure in coding multiple hypotheses 404 .A hypothesis construction module 406 produces at least one speech recognition hypothesis 408 from the coded multiple hypotheses 404 .", "label": "", "metadata": {}, "score": "94.04628"}
{"text": "A speech recognizer 402 operates on the source language speech input 302 to produce an intermediate data structure in coding multiple hypotheses 404 .A hypothesis construction module 406 produces at least one speech recognition hypothesis 408 from the coded multiple hypotheses 404 .", "label": "", "metadata": {}, "score": "94.04628"}
{"text": "Highlighted segment 1508 has alternative hypotheses .The alternative hypotheses to highlighted segment 1508 differ in a segment that , in this case , is one word indicated by highlighted word 1510 .The alternatives 1512 are displayed for the user .", "label": "", "metadata": {}, "score": "94.2206"}
{"text": "Highlighted segment 1508 has alternative hypotheses .The alternative hypotheses to highlighted segment 1508 differ in a segment that , in this case , is one word indicated by highlighted word 1510 .The alternatives 1512 are displayed for the user .", "label": "", "metadata": {}, "score": "94.2206"}
{"text": "Highlighted segment 1508 has alternative hypotheses .The alternative hypotheses to highlighted segment 1508 differ in a segment that , in this case , is one word indicated by highlighted word 1510 .The alternatives 1512 are displayed for the user .", "label": "", "metadata": {}, "score": "94.2206"}
{"text": "Highlighted segment 1508 has alternative hypotheses .The alternative hypotheses to highlighted segment 1508 differ in a segment that , in this case , is one word indicated by highlighted word 1510 .The alternatives 1512 are displayed for the user .", "label": "", "metadata": {}, "score": "94.2206"}
{"text": "Highlighted segment 1508 has alternative hypotheses .The alternative hypotheses to highlighted segment 1508 differ in a segment that , in this case , is one word indicated by highlighted word 1510 .The alternatives 1512 are displayed for the user .", "label": "", "metadata": {}, "score": "94.2206"}
{"text": "The size of an embodiment of the present invention is only limited by current hardware size .A pen embodiment and a wristwatch embodiments are envisioned .For example , elements of the present invention may reside on one or more remote servers that are accessed using a telephone call or a video conference call .", "label": "", "metadata": {}, "score": "94.89511"}
{"text": "The size of an embodiment of the present invention is only limited by current hardware size .A pen embodiment and a wristwatch embodiments are envisioned .For example , elements of the present invention may reside on one or more remote servers that are accessed using a telephone call or a video conference call .", "label": "", "metadata": {}, "score": "94.89511"}
{"text": "The size of an embodiment of the present invention is only limited by current hardware size .A pen embodiment and a wristwatch embodiments are envisioned .For example , elements of the present invention may reside on one or more remote servers that are accessed using a telephone call or a video conference call .", "label": "", "metadata": {}, "score": "94.89511"}
{"text": "The size of an embodiment of the present invention is only limited by current hardware size .A pen embodiment and a wristwatch embodiments are envisioned .For example , elements of the present invention may reside on one or more remote servers that are accessed using a telephone call or a video conference call .", "label": "", "metadata": {}, "score": "94.89511"}
{"text": "The size of an embodiment of the present invention is only limited by current hardware size .A pen embodiment and a wristwatch embodiments are envisioned .For example , elements of the present invention may reside on one or more remote servers that are accessed using a telephone call or a video conference call .", "label": "", "metadata": {}, "score": "94.89511"}
{"text": "( \" Peter likes fish . \" question mark ( \" Does Peter like fish ? \" exclamation mark ( \" Fish ! \"colon ( except between numbers ) .The analyzer 2104 of an embodiment takes the output 2154 from the tokenizer 2102 , a sequence of tokens , and analyzes each word by consulting the dictionary 2158 and a set of analysis rules 2156 .", "label": "", "metadata": {}, "score": "95.796295"}
{"text": "( \" Peter likes fish . \" question mark ( \" Does Peter like fish ? \" exclamation mark ( \" Fish ! \"colon ( except between numbers ) .The analyzer 2104 of an embodiment takes the output 2154 from the tokenizer 2102 , a sequence of tokens , and analyzes each word by consulting the dictionary 2158 and a set of analysis rules 2156 .", "label": "", "metadata": {}, "score": "95.796295"}
{"text": "( \" Peter likes fish . \" question mark ( \" Does Peter like fish ? \" exclamation mark ( \" Fish ! \"colon ( except between numbers ) .The analyzer 2104 of an embodiment takes the output 2154 from the tokenizer 2102 , a sequence of tokens , and analyzes each word by consulting the dictionary 2158 and a set of analysis rules 2156 .", "label": "", "metadata": {}, "score": "95.796295"}
{"text": "The method of claim 27 , wherein the input received is an output of an optical character recognition ( OCR ) process .The method of claim 27 , wherein presenting comprises displaying words on a display device .The method of claim 27 , wherein the display device is a touch - sensitive screen , and wherein receiving an indication of a choice of one of the alternatives from the user is a consequence of the user touching the touch screen .", "label": "", "metadata": {}, "score": "95.82552"}
{"text": "Hypothesis set 1714 includes the selected source language hypothesis \" I want to wreck a nice beach \" along with the target language translation of the selected source language hypothesis and the back - translation \" I would like to destroy a good beach .", "label": "", "metadata": {}, "score": "110.68288"}
{"text": "Hypothesis set 1714 includes the selected source language hypothesis \" I want to wreck a nice beach \" along with the target language translation of the selected source language hypothesis and the back - translation \" I would like to destroy a good beach .", "label": "", "metadata": {}, "score": "110.68288"}
{"text": "Hypothesis set 1714 includes the selected source language hypothesis \" I want to wreck a nice beach \" along with the target language translation of the selected source language hypothesis and the back - translation \" I would like to destroy a good beach .", "label": "", "metadata": {}, "score": "110.68288"}
{"text": "Hypothesis set 1714 includes the selected source language hypothesis \" I want to wreck a nice beach \" along with the target language translation of the selected source language hypothesis and the back - translation \" I would like to destroy a good beach .", "label": "", "metadata": {}, "score": "110.68288"}
{"text": "Hypothesis set 1714 includes the selected source language hypothesis \" I want to wreck a nice beach \" along with the target language translation of the selected source language hypothesis and the back - translation \" I would like to destroy a good beach .", "label": "", "metadata": {}, "score": "110.68288"}
{"text": "VBZ .VB .verb_arg12 .ARG2 . company . company .NN .NN .Enju can also output both phrase structures and predicate - argument structures in a quasi - XML format .The following pages show the phrase structure and the predicate argument structure for the sentence \" It 's falling like a stone , said Danny Linger , a pit trader who was standing outside the London International Financial Futures Exchange .", "label": "", "metadata": {}, "score": "115.13719"}
{"text": "VBZ .VB .verb_arg12 .ARG2 . company . company .NN .NN .Enju can also output both phrase structures and predicate - argument structures in a quasi - XML format .The following pages show the phrase structure and the predicate argument structure for the sentence \" It 's falling like a stone , said Danny Linger , a pit trader who was standing outside the London International Financial Futures Exchange .", "label": "", "metadata": {}, "score": "115.13719"}
{"text": "The alternative hypotheses differ in one segment .The segment is the single final word indicated by the alternative 1708 , which is \" peach \" .Cursor 1712 is shown selecting the alternative \" beach \" from among alternatives 1710 .", "label": "", "metadata": {}, "score": "124.160126"}
{"text": "The alternative hypotheses differ in one segment .The segment is the single final word indicated by the alternative 1708 , which is \" peach \" .Cursor 1712 is shown selecting the alternative \" beach \" from among alternatives 1710 .", "label": "", "metadata": {}, "score": "124.160126"}
{"text": "The alternative hypotheses differ in one segment .The segment is the single final word indicated by the alternative 1708 , which is \" peach \" .Cursor 1712 is shown selecting the alternative \" beach \" from among alternatives 1710 .", "label": "", "metadata": {}, "score": "124.160126"}
{"text": "The alternative hypotheses differ in one segment .The segment is the single final word indicated by the alternative 1708 , which is \" peach \" .Cursor 1712 is shown selecting the alternative \" beach \" from among alternatives 1710 .", "label": "", "metadata": {}, "score": "124.160126"}
{"text": "The alternative hypotheses differ in one segment .The segment is the single final word indicated by the alternative 1708 , which is \" peach \" .Cursor 1712 is shown selecting the alternative \" beach \" from among alternatives 1710 .", "label": "", "metadata": {}, "score": "124.160126"}
