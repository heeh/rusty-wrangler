{"text": "There has been substantial research in search technology directed towards the goal of imposing structure on both data and queries .Several previous systems , such as set forth in U.S. Pat .Nos . 5,309,359 and 5,404,295 , deal with manual or semi - automatic annotation of data so as to impose a structure for queries to be matched to .", "label": "", "metadata": {}, "score": "25.120388"}
{"text": "There has been substantial research in search technology directed towards the goal of imposing structure on both data and queries .Several previous systems , such as set forth in U.S. Pat .Nos . 5,309,359 and 5,404,295 , deal with manual or semi - automatic annotation of data so as to impose a structure for queries to be matched to .", "label": "", "metadata": {}, "score": "25.120388"}
{"text": "These can act as filters , to select what variables or features from a potentially large dataset should be used to actually classify the dataset .It also notes that the most relevant variables are not necessarily the most useful when building a predictor or evaluator and so it is not simply a statistical matter of selecting the most popular variables .", "label": "", "metadata": {}, "score": "25.555954"}
{"text": "The process is repeated until a desired level of classifier accuracy is achieved , or the budget available for feature acquisition is exhausted .They propose that specific solutions to the AFA problem differ based on the method used to score and rank queries .", "label": "", "metadata": {}, "score": "26.449194"}
{"text": "The proposed method is valuable as it presents a direction to AFA with a far lesser computational expense by removing the need for the first time , of training a classifier for every combination of instance , feature and feature - value tuples which would be impractical for several domains .", "label": "", "metadata": {}, "score": "26.501938"}
{"text": "In the Liddy et al . system , clustering provides , the needed capability to perform visualization of result sets and to graphically modify queries to provide feedback based on result set quality .Another approach to natural - language processing for information retrieval is set forth in U.S. Pat .", "label": "", "metadata": {}, "score": "27.18644"}
{"text": "In the Liddy et al . system , clustering provides , the needed capability to perform visualization of result sets and to graphically modify queries to provide feedback based on result set quality .Another approach to natural - language processing for information retrieval is set forth in U.S. Pat .", "label": "", "metadata": {}, "score": "27.18644"}
{"text": "We present a novel approach to classification , based on a tight coupling of instancebased learning and a genetic algorithm .In contrast to the usual instance - based learning setting , we do not rely on ( parts of ) the given training set as the basis of a nearestneighbor classifier , but we try to employ artificially generated instances as concept prototypes .", "label": "", "metadata": {}, "score": "27.875965"}
{"text": "Ideally , documents and queries should both be mapped to a common logical structure that permits direct comparison by meaning , not by keywords .Previous generations of search engines have relied on a variety of techniques for searching a database containing the full text of the documents being searched .", "label": "", "metadata": {}, "score": "28.096025"}
{"text": "Ideally , documents and queries should both be mapped to a common logical structure that permits direct comparison by meaning , not by keywords .Previous generations of search engines have relied on a variety of techniques for searching a database containing the full text of the documents being searched .", "label": "", "metadata": {}, "score": "28.096025"}
{"text": "The aim of the new heuristic is to try to \" optimise some global evaluation \" through a similar matching process .This evaluation applies to the data or problem set more as a whole , rather than evaluating each solution as a separate entity .", "label": "", "metadata": {}, "score": "28.866104"}
{"text": "These notions are more important for an algorithm that is deciding which features to keep or ignore .Relevance to just the target concept can sometimes be used to try and prove the algorithm itself rather than its evaluating results .The new heuristic has potential for feature selection and would probably belong to category 2 .", "label": "", "metadata": {}, "score": "29.356216"}
{"text": "This sort of process might be preferable for the feature selection problem that has been described , or the heuristic might , in general , be more suitable for a different class or type of problem .The clustering heuristics that have been described in Section 3 are intended to categorise similar datasets through a matching process , where the datasets with the most similar characteristics are grouped together .", "label": "", "metadata": {}, "score": "30.000462"}
{"text": "CONCLUSIONS AND FUTURE WORK In this paper we have presented a novel ACO - based au- tomatic programming algorithm guided by a CFG for multi- class classification .This algorithm , called GBAP , uses two complementary heuristic measures that conduct the search process for valid solutions , and offers as well the opportunity to the user to modify the complexity of the rules mined by simply varying the number of derivations allowed for the grammar .", "label": "", "metadata": {}, "score": "30.226477"}
{"text": "It is evident that integration of the predictions from disparate methods often would yields higher accuracy compared to the results obtained from a single method[6 ] .The predictions from different classifiers are input into a meta - learner , which combine the predictions to generate a final best predicted classification .", "label": "", "metadata": {}, "score": "30.876087"}
{"text": "A concept - based indexing and search system indexes collections of documents with ontology - based predicate structures through automated and/or human - assisted methods .The system extracts the concepts behind user queries to return only those documents that match those concepts .", "label": "", "metadata": {}, "score": "30.924778"}
{"text": "Tests have shown that it could be useful , for example , for selecting feature groups or best values out of partial information sets .Each dataset contains only parts of the whole solution or picture , when combining and evaluating these parts produce new solutions and parts that are closer to the whole picture .", "label": "", "metadata": {}, "score": "31.314785"}
{"text": "The main challenge therefore lies in optimising over this exponentially large label space subject to label correlations .Existing solutions take either of two approaches .The first assumes , a priori , that there are no label correlations and independently trains a classifier for each label ( as is done in the 1-vs - All heuristic ) .", "label": "", "metadata": {}, "score": "31.378609"}
{"text": "From the perspective of machine learning for PPI prediction , it would be desirable that those experiments be carried out which when used in training the classifier , the accuracy of the classifier is improved the most .That is , the utility of the feature - acquisition is measured in terms of how much acquired features contribute to improving the accuracy of the classifier .", "label": "", "metadata": {}, "score": "31.485142"}
{"text": "On the whole , the system generates both conceptual and term - based representations of the documents and queries .In U.S. Pat .No .5,873,056 , Liddy et al . additionally discloses a system that accounts for lexical ambiguity based on the fact that words generally have different meanings across multiple domains .", "label": "", "metadata": {}, "score": "31.564339"}
{"text": "On the whole , the system generates both conceptual and term - based representations of the documents and queries .In U.S. Pat .No .5,873,056 , Liddy et al . additionally discloses a system that accounts for lexical ambiguity based on the fact that words generally have different meanings across multiple domains .", "label": "", "metadata": {}, "score": "31.564339"}
{"text": "Furthermore , systems such as Katz provide only for encoding of questions , not for encoding of the documents themselves .Another approach is set forth in Liddy et al , U.S. Pat .No .5,963,940 , which discloses a natural - language information retrieval system .", "label": "", "metadata": {}, "score": "31.701225"}
{"text": "Furthermore , systems such as Katz provide only for encoding of questions , not for encoding of the documents themselves .Another approach is set forth in Liddy et al , U.S. Pat .No .5,963,940 , which discloses a natural - language information retrieval system .", "label": "", "metadata": {}, "score": "31.701225"}
{"text": "These complex concept patterns are used as the inputs to a self - adaptive feature map , which then automatically creates a cluster model that represents the statistical probability distribution of the documents in the proposed matching set .A sample document from the matching set is shown to the user , who can specify that the example is either \" similar to the desired documents \" or \" not very similar to the desired documents .", "label": "", "metadata": {}, "score": "31.75043"}
{"text": "These complex concept patterns are used as the inputs to a self - adaptive feature map , which then automatically creates a cluster model that represents the statistical probability distribution of the documents in the proposed matching set .A sample document from the matching set is shown to the user , who can specify that the example is either \" similar to the desired documents \" or \" not very similar to the desired documents .", "label": "", "metadata": {}, "score": "31.75043"}
{"text": "The selection of a consequent for each rule mined and the selection of the rules that make up the classifier is based on the use of a niching approach .The performance of GBAP is compared against other classification techniques on 18 varied data sets .", "label": "", "metadata": {}, "score": "31.868181"}
{"text": "The individual decisions of each classifier are merged to classify new instances[8 ] .Multiple classifiers are assembled to generate a classifier with higher accuracy and improved performance .In the proposed system the outcome of the similarity measure and the SVM classifier are stacked to obtain a classifier with increased accuracy Figure 2 : Examples of spam images a ) image with embedded text b ) image with text and picture 5.1 .", "label": "", "metadata": {}, "score": "31.999979"}
{"text": "The selection of a consequent for each rule mined and the selection of the rules that make up the classifier are based on the use of a niching approach .The performance of GBAP is compared against other classification techniques on 18 varied data sets .", "label": "", "metadata": {}, "score": "32.121136"}
{"text": "The Braden - Harder et al system provides a mechanism for the retrieval and ranking of documents containing these logical triples .The various grammatical relationships discussed previously are assigned numerical weights , and documents are ranked by the occurrence of those relations between the content words .", "label": "", "metadata": {}, "score": "32.245964"}
{"text": "The Braden - Harder et al system provides a mechanism for the retrieval and ranking of documents containing these logical triples .The various grammatical relationships discussed previously are assigned numerical weights , and documents are ranked by the occurrence of those relations between the content words .", "label": "", "metadata": {}, "score": "32.245964"}
{"text": "The framework proposed by Melville et.al [ 16 ] , is an iterative model wherein in each iteration a set of missing features , which provide the highest expected improvement to classifier accuracy at minimal cost , are chosen and queried .", "label": "", "metadata": {}, "score": "32.495117"}
{"text": "In all of these methods , it is assumed that a training data set is available , and that the pending goal is to develop an algorithm to learn to model the relation between feature space and labels given represented by the training data .", "label": "", "metadata": {}, "score": "32.513397"}
{"text": "As a result , the system of Wical automatically builds extensions to the core ontology by scoring words that frequently appear in the context of known concepts as probably related concepts .The scoring algorithm of Wical is fairly conservative , and should generally produce reliable results over large corpuses of data .", "label": "", "metadata": {}, "score": "32.585808"}
{"text": "As a result , the system of Wical automatically builds extensions to the core ontology by scoring words that frequently appear in the context of known concepts as probably related concepts .The scoring algorithm of Wical is fairly conservative , and should generally produce reliable results over large corpuses of data .", "label": "", "metadata": {}, "score": "32.585808"}
{"text": "We argue that this stems from three ca ... \" .While large - scale taxonomies - especially for web pages - have been in existence for some time , approaches to automatically classify documents into these taxonomies have met with limited success compared to the more general progress made in text classification .", "label": "", "metadata": {}, "score": "32.66648"}
{"text": "This partitioning is based on the global pattern of concepts across the entire document , as opposed to the individual concepts used in the other stages of processing within the system .This is , in effect , a higher - level meta - search through concept - pattern space , providing greater discrimination and more refined selection capabilities .", "label": "", "metadata": {}, "score": "32.68413"}
{"text": "This partitioning is based on the global pattern of concepts across the entire document , as opposed to the individual concepts used in the other stages of processing within the system .This is , in effect , a higher - level meta - search through concept - pattern space , providing greater discrimination and more refined selection capabilities .", "label": "", "metadata": {}, "score": "32.68413"}
{"text": "This would be strengthened by the count and count additions , associated with each feature and new solution .The work arose from looking at the problem of aggregating distributed information sources or concepts autonomously , to try to formulate more complex real - world entities .", "label": "", "metadata": {}, "score": "32.694244"}
{"text": "The system according to . claim 1 , wherein the system further comprises means for arranging the classifiers in serial , parallel , or hybrid organization , wherein in serial configuration of the classifiers , the classifiers are organized in a cascade method .", "label": "", "metadata": {}, "score": "32.78637"}
{"text": "We present a method for learning heuristics employed by an automated proverto control its inference machine .The hub of the method is the adaptation of theparameters of a heuristic .Adaptation is accomplished by a genetic algorithm .The necessary guidance during the learning process is provided by a proof prob - lem and a proof of it found in the past .", "label": "", "metadata": {}, "score": "32.974663"}
{"text": "Thus , we perform a benchmarking experimental study where several classification techniques are considered , using a wide variety of data sets .The results obtained are promising and they show that our approach performs accurately , building understandable classifiers .The remainder of this paper is organized as follows .", "label": "", "metadata": {}, "score": "33.012024"}
{"text": "A model or classifier is inferred in a training stage by analyzing the values of the predicting attributes that describe each instance , as well as the class to which each instance belongs to .Thus , classification is considered to be supervised learning , in contrast to unsupervised learning , where instances are unlabelled .", "label": "", "metadata": {}, "score": "33.106018"}
{"text": "Thus , two methods are provided for indexing new documents , both of which are realized in the component .The first method involves the retrieval of new documents to answer user queries , which do not already have documents matched to them .", "label": "", "metadata": {}, "score": "33.35749"}
{"text": "Thus , two methods are provided for indexing new documents , both of which are realized in the component .The first method involves the retrieval of new documents to answer user queries , which do not already have documents matched to them .", "label": "", "metadata": {}, "score": "33.35749"}
{"text": "Nevertheless , notice that this adopted configuration should be tuned when classifying a particular data set .V. RESULTS AND DISCUSSION The performance and the understandability of the model proposed is compared to other classification algorithms .The aim of this section is to analyze statistically and interpret the experimental results obtained .", "label": "", "metadata": {}, "score": "33.405884"}
{"text": "On the other hand , a method and system for concept - based searching according to the present invention has the capabilities of an ontology - based search system plus it can search for logically structured groupings of items from the ontology .", "label": "", "metadata": {}, "score": "33.4134"}
{"text": "On the other hand , a method and system for concept - based searching according to the present invention has the capabilities of an ontology - based search system plus it can search for logically structured groupings of items from the ontology .", "label": "", "metadata": {}, "score": "33.4134"}
{"text": "Feature Selection Equations .Existing feature selection usually involves categorising or clustering into distinct groups .This is also often a supervised process , with known clusters being used to train the classifier , so that it can then recognise these clusters in other datasets as well .", "label": "", "metadata": {}, "score": "33.479935"}
{"text": "Implementations of the system of Liddy et al . have been used to provide input to machine reasoning systems .The Liddy et al . system makes further provisions for subject codes , used to tag the domain of human knowledge that a word represents .", "label": "", "metadata": {}, "score": "33.558884"}
{"text": "Implementations of the system of Liddy et al . have been used to provide input to machine reasoning systems .The Liddy et al . system makes further provisions for subject codes , used to tag the domain of human knowledge that a word represents .", "label": "", "metadata": {}, "score": "33.558884"}
{"text": "The evaluations on these datasets are as yet preliminary .Rigorous testing and analysis is to be carried out in future , with our method as well as previous methods , to understand what the domain - characteristics may be that lead to the success or failure by different methods in these domains .", "label": "", "metadata": {}, "score": "33.66574"}
{"text": "It was proposed by Abbass et al . as a method of automatic programming employing ACO as its search strategy and a tree adjoining grammar ( TAG ) to build programs .TAGs are compact contex - sensitive grammars that use tree manipulation operations for syntactic analysis , and they can distinguish between derivation and derivation trees as well .", "label": "", "metadata": {}, "score": "33.755222"}
{"text": "A second approach is manual document organization .A typical document categorization search engine , Yahoo ! , does not contain an inverted index , but rather a classification of documents manually categorized in a hierarchical list .When a user queries Yahoo ! , a keyword - based search is run against the words used to classify documents , rather than the documents themselves .", "label": "", "metadata": {}, "score": "34.11641"}
{"text": "A second approach is manual document organization .A typical document categorization search engine , Yahoo ! , does not contain an inverted index , but rather a classification of documents manually categorized in a hierarchical list .When a user queries Yahoo ! , a keyword - based search is run against the words used to classify documents , rather than the documents themselves .", "label": "", "metadata": {}, "score": "34.11641"}
{"text": "While the framework is built around distributed and autonomous objectives , the system is also useful as a test platform for more general AI problems .As such , a centralised component has been added , allowing for heuristic searches to evaluate the situation and feedback the results .", "label": "", "metadata": {}, "score": "34.440536"}
{"text": "The author also has an interest in developing a more brain - like or cognitive model .While the distributed part of this model has been written about recently [ 18 ] , there is also possibly a centralised part to the model as well .", "label": "", "metadata": {}, "score": "34.47586"}
{"text": "A user query is converted to one or more predicates .The ranking and comparison algorithm is designed to rank the similarity between two predicate structures .In order to determine precisely the information converted by the predicate , the algorithm implements a modifier strategy to adjust the weight for each factor that modifies the information converted to the system .", "label": "", "metadata": {}, "score": "34.491287"}
{"text": "A user query is converted to one or more predicates .The ranking and comparison algorithm is designed to rank the similarity between two predicate structures .In order to determine precisely the information converted by the predicate , the algorithm implements a modifier strategy to adjust the weight for each factor that modifies the information converted to the system .", "label": "", "metadata": {}, "score": "34.491287"}
{"text": "Implementation Details .The problem solving framework has now been implemented as part of the licas system [ 1 ] .Licas provides a framework for building distributed service - based networks of information sources , for example .The individual services can self - organise through a novel linking mechanism and can also display autonomous behaviours .", "label": "", "metadata": {}, "score": "34.567818"}
{"text": "It is not a case of categorising the different datasets individually into similar groups , but rather , trying to evolve all solutions in the most robust way , in order to arrive at an optimal collective solution value .The whole search space belongs to the same single problem .", "label": "", "metadata": {}, "score": "34.57756"}
{"text": "We present a heuristic method for active feature acquisition to calculate the utility of acquiring a missing feature .This heuristic takes into account the change in belief of the classification model induced by the acquisition of the feature under consideration .", "label": "", "metadata": {}, "score": "34.63011"}
{"text": "The classification algorithm and the choice of demographic class drive the choice of components .Components are defined as an artifact that is one of the individual parts of which a composite entity is made up .Another embodiment is shown in .", "label": "", "metadata": {}, "score": "34.814964"}
{"text": "The system relies on a database of documents subject to the processing discussed above , but further extends the subject field coding by applying it to a plurality of languages .This system includes part - of - speech tagging to assist in concept disambiguation , which is an optional step in the previously discussed system .", "label": "", "metadata": {}, "score": "34.878464"}
{"text": "The system relies on a database of documents subject to the processing discussed above , but further extends the subject field coding by applying it to a plurality of languages .This system includes part - of - speech tagging to assist in concept disambiguation , which is an optional step in the previously discussed system .", "label": "", "metadata": {}, "score": "34.878464"}
{"text": "It aims to construct not only accurate but also comprehensible classifiers .In contrast to other ACO classification algorithms , our proposal provides more expres- sive power , because the grammar allows to control several aspects related to comprehensibility , such as the definition .", "label": "", "metadata": {}, "score": "34.92195"}
{"text": "The introductory sections in [ 4 ] make some interesting points .They note that hyperheuristics were initially developed as \" heuristics to choose heuristics \" .They are not intended to operate on the problem data itself , as a metaheuristic would do .", "label": "", "metadata": {}, "score": "35.042183"}
{"text": "As a result , there is a pressing need to develop search engines that bridge the gap between the meaning of an input query and pre - indexed documents .Existing approaches will not solve this problem , because it is impossible to determine the meaning of input queries from terms alone .", "label": "", "metadata": {}, "score": "35.22278"}
{"text": "As a result , there is a pressing need to develop search engines that bridge the gap between the meaning of an input query and pre - indexed documents .Existing approaches will not solve this problem , because it is impossible to determine the meaning of input queries from terms alone .", "label": "", "metadata": {}, "score": "35.22278"}
{"text": "These evaluations can be better or worse than the true value and might vary around some distribution or mean of the true value .Each group of features or concepts can also be different in each solution part , but related or derived from a larger set .", "label": "", "metadata": {}, "score": "35.33378"}
{"text": "The aims of the current project are to develop a hyperheuristic framework for evaluating information sources , to try to combine sources that might be related .The problem itself however might not be a typical categorisation one , but one that tries to realise some global function over the whole set of problem data .", "label": "", "metadata": {}, "score": "35.4087"}
{"text": "The main goal is to build a hyper - plane for separation .The basic form of hyper - plane can be generated as a linear function of the attributes .SVMs are fast to learn and highly effective in learning - based spam filters .", "label": "", "metadata": {}, "score": "35.512924"}
{"text": "The system requires previous training on a corpus of text tagged with subject field codes , in order to learn the correlations between the appearance of different subject field codes .Once such training has been performed , a semantic vector can be produced for any new document that the system encounters .", "label": "", "metadata": {}, "score": "35.57188"}
{"text": "The system requires previous training on a corpus of text tagged with subject field codes , in order to learn the correlations between the appearance of different subject field codes .Once such training has been performed , a semantic vector can be produced for any new document that the system encounters .", "label": "", "metadata": {}, "score": "35.57188"}
{"text": "A comparative study of previous research work showed a higher accuracy for the SVM classifier together with a distance measure used to determine the similarity of features with a query image or feature set [ 7 , 3 ] .Such a technique has also been termed as near duplicate detection method , which can be termed as an ultimate guise for similarity search .", "label": "", "metadata": {}, "score": "35.58954"}
{"text": "The system can perform off - line searches for unanswered user queries and notify the user when a match is found . creating a query predicate structure representing logical relationships between words in said natural language query , said predicate structure containing a predicate and an argument ; . matching said query predicate structure to said document predicate structures in said predicate libraries ; and .", "label": "", "metadata": {}, "score": "35.62294"}
{"text": "While this approach is useful to users , so far as it means that other humans have employed common sense to filter out documents that clearly do not match , it is limited by two factors .The first factor is that it does not scale to the number of documents now available on the web , as the directory only can grow as quickly as human editors can read and classify pages .", "label": "", "metadata": {}, "score": "35.669945"}
{"text": "While this approach is useful to users , so far as it means that other humans have employed common sense to filter out documents that clearly do not match , it is limited by two factors .The first factor is that it does not scale to the number of documents now available on the web , as the directory only can grow as quickly as human editors can read and classify pages .", "label": "", "metadata": {}, "score": "35.669945"}
{"text": "While such an approach guarantees that a question will be answered if the question has been previously asked , the process is limited by the efficiency of the tagging system .The Katz system can provide fully automatic tagging of text .", "label": "", "metadata": {}, "score": "35.72162"}
{"text": "While such an approach guarantees that a question will be answered if the question has been previously asked , the process is limited by the efficiency of the tagging system .The Katz system can provide fully automatic tagging of text .", "label": "", "metadata": {}, "score": "35.72162"}
{"text": "Results are shown in Figure 2 .We found that our method performs slightly better than the other method , and when combined with the fact that it does not require retraining the classifier numerous times , it clearly presents an advantage .", "label": "", "metadata": {}, "score": "35.74585"}
{"text": "The next component of the system is the comparison and ranking module 170 .The basic premise of relevancy searching is that results are sorted , or ranked according to certain criteria .The system provides a comparison and ranking algorithm , described below , to determine the similarity between a query from a user and a document , and rank each document based upon a set of criteria .", "label": "", "metadata": {}, "score": "35.87107"}
{"text": "The next component of the system is the comparison and ranking module 170 .The basic premise of relevancy searching is that results are sorted , or ranked according to certain criteria .The system provides a comparison and ranking algorithm , described below , to determine the similarity between a query from a user and a document , and rank each document based upon a set of criteria .", "label": "", "metadata": {}, "score": "35.87107"}
{"text": "Experiments with artificial datasets show that - due to the ability to find concise and accurate concept descriptions that contain few , but typical instances - this classification approach is considerably robust against noise , untypical training instances and irrelevant attributes .", "label": "", "metadata": {}, "score": "36.31214"}
{"text": "In the event of a match , the documents matching the query are sent to a ranking and formatting component ( not discussed ) to produce the search results in a user - friendly format , this is then returned to the user .", "label": "", "metadata": {}, "score": "36.435463"}
{"text": "In the event of a match , the documents matching the query are sent to a ranking and formatting component ( not discussed ) to produce the search results in a user - friendly format , this is then returned to the user .", "label": "", "metadata": {}, "score": "36.435463"}
{"text": "If only a few experiments can be carried out to acquire missing features , which proteins should be studied and which features of those proteins should be determined ?From the perspective of machine learning for PPI prediction , it would be desirable that those features be acquired which when used in training the classifier , the accuracy of the classifier is improved the most .", "label": "", "metadata": {}, "score": "36.51406"}
{"text": "These features are fed to a classifier .After obtaining a classification for the text features and the low level features the two classifiers are stacked to obtain a ensemble - classifier with improved performance .Block Diagram .International Journal on Natural Language Computing ( IJNLC )", "label": "", "metadata": {}, "score": "36.545258"}
{"text": "Next , how the Finance - domain - specific classifier is used to classify documents is discussed .FIG .14 is a flow diagram illustrating Finance - domain - specific classifier classification process .As shown in the FIG .14 , the concept based search and retrieval system accepts an input document for classification , in step 700 .", "label": "", "metadata": {}, "score": "36.67648"}
{"text": "Next , how the Finance - domain - specific classifier is used to classify documents is discussed .FIG .14 is a flow diagram illustrating Finance - domain - specific classifier classification process .As shown in the FIG .14 , the concept based search and retrieval system accepts an input document for classification , in step 700 .", "label": "", "metadata": {}, "score": "36.67648"}
{"text": "Most notable characteristic of this method is that it does not require re - training of the classification model on every possible combination of instance , feature and feature - value tuples .For this reason , our method is far less computationally expensive as compared with previous AFA strategies .", "label": "", "metadata": {}, "score": "36.750267"}
{"text": "The better solution score is more likely to meet the selection criteria .Paper [ 10 ] is also very interesting and tries to develop a hierarchical clustering algorithm that might be more applicable to the aims of the current project .", "label": "", "metadata": {}, "score": "36.99306"}
{"text": "Anyone conversant with the art would recognize that there could be other embodiments of the component information .Training , Testing , and Bootstrapping Classifiers .FIG .16 describes the steps is an exemplary case that could be followed for creating an accurate and generalized model classifier .", "label": "", "metadata": {}, "score": "37.002518"}
{"text": "While the framework can include autonomous and distributed behaviour , the problem - solving part can perform more complex centralised optimisation operations and then feed the results back into the network .The problem - solving system is based on a novel type of evaluation mechanism that prefers comparisons between solution results , over maximisation .", "label": "", "metadata": {}, "score": "37.018253"}
{"text": "Searching for information using the keyword approach requires the user to input a set of words , which can range from a single word to a natural language sentence .Normally , the input is parsed into an unstructured set of keywords .", "label": "", "metadata": {}, "score": "37.148693"}
{"text": "Searching for information using the keyword approach requires the user to input a set of words , which can range from a single word to a natural language sentence .Normally , the input is parsed into an unstructured set of keywords .", "label": "", "metadata": {}, "score": "37.148693"}
{"text": "Digital Object Identifier ? where domain experts can use the model inferred as a decision- support system , decision trees and decision rules are especially interesting .These techniques have a high - level representation and , therefore , they allow the user to interpret and understand the knowledge extracted .", "label": "", "metadata": {}, "score": "37.17359"}
{"text": "5,794,050 , to Dahlgren et al .Dahlgren et al . discloses a na\u00efve semantic system that incorporates modules for text processing based upon parsing , formal semantics and discourse coherence , as well as relying on a na\u00efve semantic lexicon that stores word meanings in terms of a hierarchical semantic network .", "label": "", "metadata": {}, "score": "37.39135"}
{"text": "5,794,050 , to Dahlgren et al .Dahlgren et al . discloses a na\u00efve semantic system that incorporates modules for text processing based upon parsing , formal semantics and discourse coherence , as well as relying on a na\u00efve semantic lexicon that stores word meanings in terms of a hierarchical semantic network .", "label": "", "metadata": {}, "score": "37.39135"}
{"text": "The system extracts the concepts behind user queries to return only those documents that match those concepts .The concept based search and retrieval system comprehends the intent behind a query from a user , and returns results matching that intent .", "label": "", "metadata": {}, "score": "37.489006"}
{"text": "If a query term is a proper noun , other terms in the semantic network are not activated , even those that are also nouns , as the terms are unlikely to be similar .Schultz further discloses a relevance - scoring algorithm , which compares the query terms to the text information fields that serve as metadata within an information retrieval system .", "label": "", "metadata": {}, "score": "37.56613"}
{"text": "If a query term is a proper noun , other terms in the semantic network are not activated , even those that are also nouns , as the terms are unlikely to be similar .Schultz further discloses a relevance - scoring algorithm , which compares the query terms to the text information fields that serve as metadata within an information retrieval system .", "label": "", "metadata": {}, "score": "37.56613"}
{"text": "As a result , the present invention provides significant improvements in scalability and coverage .The present concept - based indexing and search system also presents an advantage to the information retrieval systems of Liddy et al .The monolingual implementation of Liddy et al . constructs vector representations of document content , with vectors containing complex nominals , proper nouns , text structure , and logical make - up of the query .", "label": "", "metadata": {}, "score": "37.810165"}
{"text": "As a result , the present invention provides significant improvements in scalability and coverage .The present concept - based indexing and search system also presents an advantage to the information retrieval systems of Liddy et al .The monolingual implementation of Liddy et al . constructs vector representations of document content , with vectors containing complex nominals , proper nouns , text structure , and logical make - up of the query .", "label": "", "metadata": {}, "score": "37.810165"}
{"text": "Most of these actually belong to clustering algorithms that would try to measure how similar two individual data objects are , although some individual objects can be represented by cluster means .This is not actually what the matching process described in this paper is trying to do and so it already shows a possible difference in the use of the new hyperheuristic algorithm .", "label": "", "metadata": {}, "score": "37.826447"}
{"text": "In other words , these are the feature values which are available for acquisition by the AFA system .To apply AFA , we need to discretize the real valued features .To do that we apply the commonly applied Maximum Description Length ( MDL ) based discretization method proposed by Fayyad and Irani [ 25 ] .", "label": "", "metadata": {}, "score": "37.837635"}
{"text": "No .5,794,050 .The Dahlgren system uses a semantic network similar to the ontologies employed in the system of present invention .However , it relies on a complicated grammatical system for the generation of formal structures , where complicated grammatical information is needed to eliminate possible choices in the parser .", "label": "", "metadata": {}, "score": "37.860497"}
{"text": "No .5,794,050 .The Dahlgren system uses a semantic network similar to the ontologies employed in the system of present invention .However , it relies on a complicated grammatical system for the generation of formal structures , where complicated grammatical information is needed to eliminate possible choices in the parser .", "label": "", "metadata": {}, "score": "37.860497"}
{"text": "The author therefore finds the hyperheuristic that uses comparisons more attractive as the centralised component for his current cognitive model .A decision would be formed through more neuronal areas firing relevant signals when the input is received .References .K. Greer , \" A stochastic hyper - heuristic for optimising through comparisons , \" in Proceedings of the 3rd International Symposium on Knowledge Acquisition and Modeling ( KAM'10 ) , pp .", "label": "", "metadata": {}, "score": "37.955517"}
{"text": "At this stage , the feature map represents clusters of documents , which are relatively more or less similar to each other .When it is determined that the set of located matches exceeds a user - specified too many matches parameter , the document clustering component 180 selects one example document from one of the larger clusters of documents within the feature map .", "label": "", "metadata": {}, "score": "38.015846"}
{"text": "At this stage , the feature map represents clusters of documents , which are relatively more or less similar to each other .When it is determined that the set of located matches exceeds a user - specified too many matches parameter , the document clustering component 180 selects one example document from one of the larger clusters of documents within the feature map .", "label": "", "metadata": {}, "score": "38.015846"}
{"text": "This work proposes a framework for a spam detection system .The proposed detection system attempts to extract embedded text together with the visual feature like color , texture , shape and hence used to calculate a similarity measure with a query image .", "label": "", "metadata": {}, "score": "38.07008"}
{"text": "We present a kernel - based algorithm for hierarchical text classification where the documents are allowed to belong to more than one category at a time .The classification model is a variant of the Maximum Margin Markov Network framework , where the classification hierarchy is represented as a Markov tree equipped with an exponential family defined on the edges .", "label": "", "metadata": {}, "score": "38.191917"}
{"text": "However , such techniques do not involve manipulation or reparsing of the documents and do not constitute an advance on any of the previously discussed indexing systems .The concept - based indexing and search system of the present invention has distinct advantages over the approach set forth in the Katz and the other previously set forth patents .", "label": "", "metadata": {}, "score": "38.243187"}
{"text": "However , such techniques do not involve manipulation or reparsing of the documents and do not constitute an advance on any of the previously discussed indexing systems .The concept - based indexing and search system of the present invention has distinct advantages over the approach set forth in the Katz and the other previously set forth patents .", "label": "", "metadata": {}, "score": "38.243187"}
{"text": "Clusters are then pruned by virtue of a lack of common ontological features among the words in the sentence .Sentences whose words do not have similar meaning at equal levels of abstraction are judged as erroneous parses .These structures can then be searched in a manner equivalent to the technique set forth in the Braden - Harder patent .", "label": "", "metadata": {}, "score": "38.273163"}
{"text": "Clusters are then pruned by virtue of a lack of common ontological features among the words in the sentence .Sentences whose words do not have similar meaning at equal levels of abstraction are judged as erroneous parses .These structures can then be searched in a manner equivalent to the technique set forth in the Braden - Harder patent .", "label": "", "metadata": {}, "score": "38.273163"}
{"text": "The links are made more accurate through a path description made up of metadata or concepts that relate to the association between the linked services or nodes .So there is not a great deal of computation that takes place to create these links .", "label": "", "metadata": {}, "score": "38.418064"}
{"text": "Evaluations are repeated until a leaf is reached , assigning the document to the category that denotes the leaf reached .There are many algorithms used for computing the learning tree .The most popular ones are ID3 , C4.5 and C5 .", "label": "", "metadata": {}, "score": "38.435665"}
{"text": "The matching process then matches solutions by removing any solutions that are between them in the grid and grouping the matched ones together for evolving into a new solution .This process therefore also removes solutions as well as evolving the potentially better ones and in that sense is self - regulating .", "label": "", "metadata": {}, "score": "38.499077"}
{"text": "c ) bootstrapping to obtain the best classifier , or .d ) testing classifiers using testing data , . whereby generating best said one or a plurality of classifiers .The method according to .claim 7 , wherein the method further comprises a step of arranging the classifiers in serial , parallel , or hybrid organization , . wherein in serial configuration of the classifiers , the classifiers are organized in a cascade method .", "label": "", "metadata": {}, "score": "38.529045"}
{"text": "Saar - Tsechansky et al .create the reduced consideration set ' S ' by giving preference to missing features in instances which are misclassified or instances which have high uncertainty as to their label according to the induced classifier model [ 18 ] .", "label": "", "metadata": {}, "score": "38.543613"}
{"text": "Each predicate library is compared to the original query predicate structure(s ) for relevancy and is assigned a score based on the relevancy .A special scoring algorithm used specifically for the concept based search and retrieval system 100 accomplishes this .", "label": "", "metadata": {}, "score": "38.54751"}
{"text": "Each predicate library is compared to the original query predicate structure(s ) for relevancy and is assigned a score based on the relevancy .A special scoring algorithm used specifically for the concept based search and retrieval system 100 accomplishes this .", "label": "", "metadata": {}, "score": "38.54751"}
{"text": "To understand this phenomenon , we studied the decision trees that were constructed in each iteration .The decision trees built have the Gene Ontology biological process and molecular function at the higher levels and the localization features in the lower levels of the tree .", "label": "", "metadata": {}, "score": "38.550716"}
{"text": "For example , only Caucasian images are used for training , bootstrapping , and testing the Caucasian gender classifier .Similarly , in the exemplary case of age category classification could be a five - class age classifier based on SVM classifier .", "label": "", "metadata": {}, "score": "38.58738"}
{"text": "Online].Available : http : //dx.doi.org/10.1109/4235.585893 [ 58 ] J. Dem\u02c7 sar , \" Statistical comparisons of classifiers over multiple data sets , \" J. Mach .Learn .Res . , vol .7 , pp . 1 - 30 , 2006 .", "label": "", "metadata": {}, "score": "38.63243"}
{"text": "Gregory et al .proposed an active feature acquisition approach that they specifically evaluated on two sequence labeling tasks [ 19 ] .Their approach also required re - training of classifiers .In expected utility based approaches for AFA , the usefulness of acquiring a missing feature is estimated by retraining the classifier for each of the possible values that the missing feature can take and then calculating the expected improvement in classifier accuracy .", "label": "", "metadata": {}, "score": "38.80871"}
{"text": "We are going to present two methods that allow to exploit previous expe - rience in the area of automated deduction .The first method adapts ( learns)the parameters of a heuristic employed for controlling the application of infer - ence rules in order to find a known proof with as little redundant search effortas possible .", "label": "", "metadata": {}, "score": "38.964104"}
{"text": "In this work we propose a novel heuristic to measure the utility of acquiring a missing feature value without the need of retraining of the classifier multiple times .Methods .Proposed active feature selection strategy .Consider a training data set with N instances and a classifier ' C ' trained on this data .", "label": "", "metadata": {}, "score": "39.118927"}
{"text": "With the incorporation of genetic programming , there is also the option of using \" heuristics to generate heuristics \" .The hyperheuristic can select which heuristics are mutated , or changed , for the next evaluation stage .The problem solving system of licas currently only uses heuristics to generate new heuristics , inside a genetic programming framework .", "label": "", "metadata": {}, "score": "39.18721"}
{"text": "As a result , the Braden - Harder et al system replaces a keyword search based upon individual lexical items with a keyword search based upon logical triples .U.S. Pat .No .5,694,523 to Wical discloses a content processing system that relies on ontologies and a detailed computational grammar with approximately 210 grammatical objects .", "label": "", "metadata": {}, "score": "39.258698"}
{"text": "As a result , the Braden - Harder et al system replaces a keyword search based upon individual lexical items with a keyword search based upon logical triples .U.S. Pat .No .5,694,523 to Wical discloses a content processing system that relies on ontologies and a detailed computational grammar with approximately 210 grammatical objects .", "label": "", "metadata": {}, "score": "39.258698"}
{"text": "It is currently turned into dynamic links , to update the network structure .Testing .A set of tests have been created to test the problem solving framework for usefulness as a feature selector .The tests are designed mainly to determine if the problem - solving process is constructive , that is , it is doing something in an intelligent manner and not simply trying to match things in a random way .", "label": "", "metadata": {}, "score": "39.350014"}
{"text": "Some variations entail the use of different mechanisms for pruning , pheromone updating , heuristic function , or they are designed for including interval rules , dealing with continuous attributes , extracting fuzzy classification rules or being applied to multi - label or hierarchical classification .", "label": "", "metadata": {}, "score": "39.42131"}
{"text": "Given a set of L labels , a data point can be tagged with any of the 2 L possible subsets .The main challenge therefore lies in optimising over this ... \" .We propose a max - margin formulation for the multi - label classification problem where the goal is to tag a data point with a set of pre - specified labels .", "label": "", "metadata": {}, "score": "39.50952"}
{"text": "Based on such feedback , the persistent agent can attempt to find documents that could answer similar queries in the future by creating persistent agents that attempt to find ontological predicate structures that match the query .The persistent agent maintains a collection of predicate structures extracted from the query .", "label": "", "metadata": {}, "score": "39.566383"}
{"text": "Based on such feedback , the persistent agent can attempt to find documents that could answer similar queries in the future by creating persistent agents that attempt to find ontological predicate structures that match the query .The persistent agent maintains a collection of predicate structures extracted from the query .", "label": "", "metadata": {}, "score": "39.566383"}
{"text": "In other words , a query in natural language is parsed into the representation format of first - order logic and the previously described na\u00efve semantics .U.S. Pat .No .5,933,822 , to Braden - Harder et al . , provides yet another natural language search capability that imposes logical structure on otherwise unformatted , unstructured text .", "label": "", "metadata": {}, "score": "39.57041"}
{"text": "In other words , a query in natural language is parsed into the representation format of first - order logic and the previously described na\u00efve semantics .U.S. Pat .No .5,933,822 , to Braden - Harder et al . , provides yet another natural language search capability that imposes logical structure on otherwise unformatted , unstructured text .", "label": "", "metadata": {}, "score": "39.57041"}
{"text": "Methods for retrieving documents and creating indexes include Monier 's System for adding a new entry to a web page table upon receiving web page including a link to another web page not having a corresponding entry in a web page table , as set forth in U.S. Pat .", "label": "", "metadata": {}, "score": "39.614994"}
{"text": "Methods for retrieving documents and creating indexes include Monier 's System for adding a new entry to a web page table upon receiving web page including a link to another web page not having a corresponding entry in a web page table , as set forth in U.S. Pat .", "label": "", "metadata": {}, "score": "39.614994"}
{"text": "Once a document is found that closely matches the query , a notification is sent to the user .In addition , the document is indexed accordingly and placed in the data repository .The concept based search and retrieval system 100 may also fail to produce a valid response if the query is formulated in terms not previously included in the ontology .", "label": "", "metadata": {}, "score": "39.6484"}
{"text": "Once a document is found that closely matches the query , a notification is sent to the user .In addition , the document is indexed accordingly and placed in the data repository .The concept based search and retrieval system 100 may also fail to produce a valid response if the query is formulated in terms not previously included in the ontology .", "label": "", "metadata": {}, "score": "39.6484"}
{"text": "As the data grows it becomes more and more difficult to find it .Early pioneers in information retrieval from the Internet developed novel approaches , which can be categorized in two main areas : automated keyword indexing and manual document categorization .", "label": "", "metadata": {}, "score": "39.673447"}
{"text": "As the data grows it becomes more and more difficult to find it .Early pioneers in information retrieval from the Internet developed novel approaches , which can be categorized in two main areas : automated keyword indexing and manual document categorization .", "label": "", "metadata": {}, "score": "39.673447"}
{"text": "It is to be noted that the goal of AFA is th e creation of optimal training set that would result in the best classifier , and not the determination of the best classification model itself .Subsequent to creation of training data with active feature acquisition , any state - of - the - art method such as random forest based methods may be applied to learn the classification model .", "label": "", "metadata": {}, "score": "39.70644"}
{"text": "The resulting system is a text level semantic representation of a document rather than a representation of each and every word in the document .The present system imposes a logical structure on text , and a semantic representation is the form used for storage .", "label": "", "metadata": {}, "score": "39.720776"}
{"text": "The resulting system is a text level semantic representation of a document rather than a representation of each and every word in the document .The present system imposes a logical structure on text , and a semantic representation is the form used for storage .", "label": "", "metadata": {}, "score": "39.720776"}
{"text": "Preliminary experiments show that some of our algorithms also exhibit a good practical performance .a are ( Cohn et al . , 1990 ) and ( Freund et al . , 1997 ) .Most previous studies consider the case when instance ...", "label": "", "metadata": {}, "score": "39.84833"}
{"text": "In this paper we present three classes ofexperts working in a goal oriented fashion .This allows one to collect \" good \" intermediate resultsand to forget \" useless \" ones .Completion based proof methods are frequently reADgarded to have the disadvantage of being not goal oriented .", "label": "", "metadata": {}, "score": "39.85871"}
{"text": "These sorts of problems can be solved by generating random solutions as part of a search process .Each solution is then changed in some way to improve it , until an optimal solution is obtained .The next stage of each search process is then directed by optimising the new solution set .", "label": "", "metadata": {}, "score": "39.974617"}
{"text": "Inferring informational goals and preferred level of detail of answers based on application employed by the user based at least on informational content being displayed to the user at the query is received .Methods and apparatus for extracting and correlating text information derived from comment and product databases for use in identifying product improvements based on comment and product database commonalities Affiliated with .", "label": "", "metadata": {}, "score": "40.093834"}
{"text": "This work uses an enhancement of the algorithm .The embedded text is fed into an OCR system where the extracted text is converted to text strings .The text strings are compared to the dataset of spam text .A distance measure is calculated to find the similarity between the extracted text and the spam text .", "label": "", "metadata": {}, "score": "40.127007"}
{"text": "\" This appears to state that it is not always obvious or clear when a particular solution should be selected .As with nature , some level of randomness can be used to make an incorrect or imperfect selection process more robust .", "label": "", "metadata": {}, "score": "40.13977"}
{"text": "The features collected consider the color , shape and texture of an image .A two class SVM classifier with the RBF ( non - linear ) kernel was used [ 7 ] .Wang et al .( 2007 ) [ 11 ] in their work used numerous set of features , extracted by existing image spam filters ( in this case they are used only as feature extractors , not as classifiers ) .", "label": "", "metadata": {}, "score": "40.16899"}
{"text": "The conclusions will also try to tie this in with a more cognitive model , which is something that the author is currently working on .The rest of this paper is organised as follows .Section 2 summarises the main features of hyperheuristics and why they are useful .", "label": "", "metadata": {}, "score": "40.176395"}
{"text": "The advantages of the present system are the provision of a semantic representation of comparable utility with significantly reduced processing requirements , and no need to train the system to produce semantic representations of text content .While training is needed to enable document categorization in the present system , which improves the precision of retrieval , generation of the semantic representation is independent of the categorization algorithm .", "label": "", "metadata": {}, "score": "40.17771"}
{"text": "The advantages of the present system are the provision of a semantic representation of comparable utility with significantly reduced processing requirements , and no need to train the system to produce semantic representations of text content .While training is needed to enable document categorization in the present system , which improves the precision of retrieval , generation of the semantic representation is independent of the categorization algorithm .", "label": "", "metadata": {}, "score": "40.17771"}
{"text": "The concept - based indexing and search system of the present invention has a number of advantages over the conventional systems discussed previously .These advantages fall into two categories : improvements in the precision of information retrieval , and improvements in the user interface .", "label": "", "metadata": {}, "score": "40.223045"}
{"text": "The concept - based indexing and search system of the present invention has a number of advantages over the conventional systems discussed previously .These advantages fall into two categories : improvements in the precision of information retrieval , and improvements in the user interface .", "label": "", "metadata": {}, "score": "40.223045"}
{"text": "Still another object of the present invention is to provide a concept - based search that can perform off - line searches for unanswered user queries and notify the user when a match is found .BRIEF DESCRIPTION OF THE DRAWINGS .", "label": "", "metadata": {}, "score": "40.30214"}
{"text": "Still another object of the present invention is to provide a concept - based search that can perform off - line searches for unanswered user queries and notify the user when a match is found .BRIEF DESCRIPTION OF THE DRAWINGS .", "label": "", "metadata": {}, "score": "40.30214"}
{"text": "If the user requests more documents different than the example , the document clustering component 180 presents a new example or examples from a cluster or clusters as far from the original cluster as possible .This , in essence , bisects the multidimensional concept pattern space .", "label": "", "metadata": {}, "score": "40.335014"}
{"text": "If the user requests more documents different than the example , the document clustering component 180 presents a new example or examples from a cluster or clusters as far from the original cluster as possible .This , in essence , bisects the multidimensional concept pattern space .", "label": "", "metadata": {}, "score": "40.335014"}
{"text": "If the underlying framework is unintelligent , relying more on statistical updates , then the stochastic element could help to provide more robust solutions .Also , because there is no inherent intelligence , there should be no bias towards any particular solution , where the statistical process should determine this for itself .", "label": "", "metadata": {}, "score": "40.404495"}
{"text": "Type of features acquired in different stages of active feature acquisition .The X - axis shows the iteration number .The bars show the amount of missing values acquired for each feature type in that iteration .Performance of the proposed AFA heuristic method on other classification tasks .", "label": "", "metadata": {}, "score": "40.525375"}
{"text": "Algorithms can range from something like nearest neighbour , which can calculate attribute distances based on all available information , to weighted feature selection , or even techniques for learning logical descriptions .The definition of relevance can mean [ 12 ] the following .", "label": "", "metadata": {}, "score": "40.526726"}
{"text": "GBAP is founded on the use of a CFG that restricts the search space , which adopts the shape of a derivation tree .\" A concept - based indexing and search system indexes collections of documents with ontology - based predicate structures through automated and/or human - assisted methods .", "label": "", "metadata": {}, "score": "40.634247"}
{"text": "When no query exists to compare the document against , every predicate within the document is treated as a predicate library to be scored .The document - indexing mode is fully automated .Once queries are made available to the concept based search and retrieval system 100 or a spider is brought online , the indexing operation requires no further human action to occur .", "label": "", "metadata": {}, "score": "40.70038"}
{"text": "When no query exists to compare the document against , every predicate within the document is treated as a predicate library to be scored .The document - indexing mode is fully automated .Once queries are made available to the concept based search and retrieval system 100 or a spider is brought online , the indexing operation requires no further human action to occur .", "label": "", "metadata": {}, "score": "40.70038"}
{"text": "( 2 ) Strongly or weakly relevant to a sample or distribution .( 3 ) Relevant as a complexity measure .( 4 ) Incremental usefulness .Relevant to a target concept means that a change in the variable 's value can change its classification allocated by the target concept .", "label": "", "metadata": {}, "score": "40.728657"}
{"text": "26 , pp .159 - 190 , 2006 .[ 3 ] H.-J. Huang and C.-N. Hsu , \" Bayesian classification for data from the same unknown class , \" IEEE Transactions on Systems , Man , and Cybernetics , Part B , vol .", "label": "", "metadata": {}, "score": "40.81172"}
{"text": "The researchers further emphasized that multiple filters can work better than an individual filter thus justifying the design goal of making the system commercial .Table 1 .International Journal on Natural Language Computing ( IJNLC )Vol . 3 , No.3 , June 2014 137 5 .", "label": "", "metadata": {}, "score": "40.8368"}
{"text": "Description .BACKGROUND OF THE INVENTION .Field of the Invention .The present invention relates to a concept - based search and retrieval system .More particularly , the present invention relates to a system that indexes collections of documents with ontology - based predicate structures through automated and/or human - assisted methods .", "label": "", "metadata": {}, "score": "40.904587"}
{"text": "Description .BACKGROUND OF THE INVENTION .Field of the Invention .The present invention relates to a concept - based search and retrieval system .More particularly , the present invention relates to a system that indexes collections of documents with ontology - based predicate structures through automated and/or human - assisted methods .", "label": "", "metadata": {}, "score": "40.904587"}
{"text": "Possible storage implementations may consist of a relational or object oriented database .Databases are generally used to store massive quantities of data generated by search engine indexes .By abstracting the underlying storage interface , a variety of solutions can be implemented without modification of other components .", "label": "", "metadata": {}, "score": "40.923737"}
{"text": "Possible storage implementations may consist of a relational or object oriented database .Databases are generally used to store massive quantities of data generated by search engine indexes .By abstracting the underlying storage interface , a variety of solutions can be implemented without modification of other components .", "label": "", "metadata": {}, "score": "40.923737"}
{"text": "It is shown that the number of subproblems need only be logarithmic in the total number of label values , making this approach radically more efficient than others .We also state and prove performance guarantees for this method , and test it empirically .", "label": "", "metadata": {}, "score": "40.948723"}
{"text": "It is built up purely through the feedback of the system use and does not use any centralised or knowledgeable algorithm .The problem solver is then more of a centralised solution .It can be sent the information from the network sources , use heuristic search and evaluations to perform a more complex problem - solving operation and then feed these results back into the network , to allow the sources to update themselves through the more complex search procedure .", "label": "", "metadata": {}, "score": "41.03785"}
{"text": "This paper ( Revised version of a white paper \" Unsupervised Problem - Solving by Optimising through Comparisons , \" originally published on DCS and Scribd , October 2011 . ) describes the implementation and functionality of a centralised problem solving system that is included as part of the distributed \" licas \" system .", "label": "", "metadata": {}, "score": "41.044617"}
{"text": "The information to be combined can be partial in nature , or change over time .It is therefore difficult to evaluate accurately what pieces of information would belong together .Additional data could make an evaluation better or worse and so some sort of comparison or matching process might be preferred .", "label": "", "metadata": {}, "score": "41.071236"}
{"text": "FIG .6 illustrates the Bayes classifier 130 example collection stage for a domain - specific classifier .The system provides a collection of example documents , which contains both documents relevant to the specific domain and documents irrelevant to the specific domain .", "label": "", "metadata": {}, "score": "41.082146"}
{"text": "FIG .6 illustrates the Bayes classifier 130 example collection stage for a domain - specific classifier .The system provides a collection of example documents , which contains both documents relevant to the specific domain and documents irrelevant to the specific domain .", "label": "", "metadata": {}, "score": "41.082146"}
{"text": "Experiments done in previous work showed that a simple hierarchy of Support Vectors Machines ( SVM ) with a top - down evaluation scheme has a surprisingly good ... \" .We study hierarchical classification in the general case when an instance could belong to more than one class node in the underlying taxonomy .", "label": "", "metadata": {}, "score": "41.167572"}
{"text": "3.1.6 Classifier Combinations The Classifier Combinations approach is based on the concept of implementing various methods to the same data and the output merged to obtain single and best results .Bagging , boosting and stacking are major techniques of this category .", "label": "", "metadata": {}, "score": "41.193512"}
{"text": "This is where intelligence is required , to help the heuristic to select what potential solutions should be explored further .The problem solving process is restricted to the information that is available in any potential solution .The search process can then reveal more information that was not originally known , but if the search space is very large , any solution will still only be an estimate or approximation of the true answer .", "label": "", "metadata": {}, "score": "41.25642"}
{"text": "This greatly reduces the processing power required to index documents .From the foregoing , it is an object of the present invention to provide a concept based search and retrieval system having improved functionality over conventional search and retrieval systems with equivalent efficiency in returning web pages .", "label": "", "metadata": {}, "score": "41.317482"}
{"text": "This greatly reduces the processing power required to index documents .From the foregoing , it is an object of the present invention to provide a concept based search and retrieval system having improved functionality over conventional search and retrieval systems with equivalent efficiency in returning web pages .", "label": "", "metadata": {}, "score": "41.317482"}
{"text": "It would be interesting to see how to address active learning in domains with sparse - label and sparse - feature space .The Active Information Approaches proposed in [ 18 ] may be a starting point in this direction .The active learning and active feature acquisition approaches we considered evaluate the utility only at a particular instance / missing - feature level .", "label": "", "metadata": {}, "score": "41.370464"}
{"text": "The output of these component demographic classifiers is cascaded to another classifier , which produces the demographic information .In this invention , demographic information is generated from the output of demographic category classifiers ( such as ethnicity / gender / age ) .", "label": "", "metadata": {}, "score": "41.382454"}
{"text": "The problem solver itself can actually solve problems using either a hill - climbing approach or the new matching process , but this paper is concerned with the matching process only .This paper describes the new heuristic and considers the system integration details in particular .", "label": "", "metadata": {}, "score": "41.429794"}
{"text": "A few algorithms have been developed for AFA in other application domains which calculate utility of feature - acquisition based on the accuracy of the current model and its confidence in the prediction .Melville et al .proposed a framework for performing active feature acquisition [ 16 ] , which is described here briefly .", "label": "", "metadata": {}, "score": "41.50692"}
{"text": "It remains to be seen whether the proposed heuristic method has particular advantage in PPI - prediction like domains , i.e. when ( i ) the data has several missing values , or ( ii ) the positive instances are an extremely rare category among the unlabeled instances .", "label": "", "metadata": {}, "score": "41.543816"}
{"text": "For example , U.S. Pat .No .5,721,902 , to Schultz , discloses a technique employing hidden Markov models to determine the part of speech of words in a sentence or sentence fragment .Once the part of speech has been selected , the word is applied to a sentence network to determine the expansion words corresponding to the query term .", "label": "", "metadata": {}, "score": "41.576836"}
{"text": "For example , U.S. Pat .No .5,721,902 , to Schultz , discloses a technique employing hidden Markov models to determine the part of speech of words in a sentence or sentence fragment .Once the part of speech has been selected , the word is applied to a sentence network to determine the expansion words corresponding to the query term .", "label": "", "metadata": {}, "score": "41.576836"}
{"text": "An advantage of the present invention over the conventional systems is in the area of retrieval and ranking of indexed documents .The concept - based indexing and search system of the present invention is an improvement over the Katz system in that it transforms the text into a formal representation that matches a variety of possible questions .", "label": "", "metadata": {}, "score": "41.694702"}
{"text": "An advantage of the present invention over the conventional systems is in the area of retrieval and ranking of indexed documents .The concept - based indexing and search system of the present invention is an improvement over the Katz system in that it transforms the text into a formal representation that matches a variety of possible questions .", "label": "", "metadata": {}, "score": "41.694702"}
{"text": "Each matching phase is probably also associated with an evolution of the related solutions , to produce offspring that would then more closely match or solve the problem .The correct evolutions are not known beforehand and so it is consistency through matching that is used to decide which solutions to evolve .", "label": "", "metadata": {}, "score": "41.767536"}
{"text": "The parsing process produces a set of directed , acyclic graphs corresponding to the logical form of the sentence .The graphs are then re - parsed into logical form triples similar to the T - expressions set forth in Katz .", "label": "", "metadata": {}, "score": "41.920135"}
{"text": "The parsing process produces a set of directed , acyclic graphs corresponding to the logical form of the sentence .The graphs are then re - parsed into logical form triples similar to the T - expressions set forth in Katz .", "label": "", "metadata": {}, "score": "41.920135"}
{"text": "This invention has at least one demographic category and each category includes at two or more demographic sub - category ( such as male / female ) .In order to improve the accuracy of demographic information , the different demographic category and sub - category classifiers may be arranged in serial / parallel / hybrid organization .", "label": "", "metadata": {}, "score": "42.141487"}
{"text": "This document is presented to the user along with a choice of \" more documents like this \" or \" documents different than this .If the user requests similar documents , the document clustering component 180 presents those documents clustered closest to the example document within the feature map , up to the user - specified maximum number .", "label": "", "metadata": {}, "score": "42.223526"}
{"text": "This document is presented to the user along with a choice of \" more documents like this \" or \" documents different than this .If the user requests similar documents , the document clustering component 180 presents those documents clustered closest to the example document within the feature map , up to the user - specified maximum number .", "label": "", "metadata": {}, "score": "42.223526"}
{"text": "2001])[6 ] generates multiple classifiers ( for prediction or classification ) , extracting weights and uniting the predictions from these classifiers into a single predicted classification .The idea of stacking ( Stacked Generalization)[8 ] is another approach of combining the predicted output of several models .", "label": "", "metadata": {}, "score": "42.229965"}
{"text": "In this example , a range of available classifiers has not been defined .However , it is still worthwhile to explain why this sentence would be likely to be classified as financial .Each word is independently considered as an attribute of the document .", "label": "", "metadata": {}, "score": "42.258354"}
{"text": "In this example , a range of available classifiers has not been defined .However , it is still worthwhile to explain why this sentence would be likely to be classified as financial .Each word is independently considered as an attribute of the document .", "label": "", "metadata": {}, "score": "42.258354"}
{"text": "If the two sets are the same , for example , the equation computes to the value 1 .If there are no elements the same , then it computes to 0 .The Jaccard distance measure is then the opposite of this and measures the dissimilarity between two datasets .", "label": "", "metadata": {}, "score": "42.271217"}
{"text": "CGBA - SD appears to be a very promising algorithm that discovers comprehensible subgroups and behaves better than other algorithms as measures by complexity , interest , and precision indicate .The results obtained were validated by means of a series of nonparametric tests .", "label": "", "metadata": {}, "score": "42.31588"}
{"text": "In this paper , we introduce a refined evaluation scheme which turns the hierarchical SVM classifier into an approximator of the Bayes optimal classifier with respect to a simple stochastic model for the labels .Experiments on synthetic datasets , generated according to this stochastic model , show that our refined algorithm outperforms the simple hierarchical SVM .", "label": "", "metadata": {}, "score": "42.369698"}
{"text": "FIG .8 shows the detailed view of Hierarchical Fusion of classifier for component information .In Hierarchical Classifier , a Sub - Category Demographic Classifier is made for each component .The output of each Component Sub - Category Demographic Classifier is fed to a Fusion Classifier to give the Demographic Output .", "label": "", "metadata": {}, "score": "42.448112"}
{"text": "These examples are referred to as the Example Set .After learning from them , the classifier is said to be trained .A trained classifier is capable of answering questions whose form is similar to the forms of the questions in the example set .", "label": "", "metadata": {}, "score": "42.526814"}
{"text": "These examples are referred to as the Example Set .After learning from them , the classifier is said to be trained .A trained classifier is capable of answering questions whose form is similar to the forms of the questions in the example set .", "label": "", "metadata": {}, "score": "42.526814"}
{"text": "The system according to . claim 1 , wherein the classifiers comprise means for passing component demographic classifier results to the hierarchical fusion classifiers , . wherein the hierarchical fusion classifiers are multi - level classifiers , . wherein component information from each component may be preprocessed differently , and .", "label": "", "metadata": {}, "score": "42.531334"}
{"text": "It also creates an empty object that represents the classifier , which will contain the remaining - winner - ants of the competition that takes place in the niching algorithm in each generation .The algorithm starts with the minimum number of derivations that are nec- essary to find a solution in the space of states and computes the derivation step for each generation .", "label": "", "metadata": {}, "score": "42.570595"}
{"text": "This method is computationally intensive for several classifiers types and for several domains .Therefore , in order to evaluate the utility of a single missing feature of a given instance , the classifier is to be retrained ' K ' times .", "label": "", "metadata": {}, "score": "42.71459"}
{"text": "The evaluation and evolution process in simply an intersection of the dataset features .During the comparison , if both datasets have certain features in common , their distribution from the mean for those features only is calculated and this is taken to be the similarity score .", "label": "", "metadata": {}, "score": "42.771667"}
{"text": "We consider multi - label prediction problems with large output spaces under the assumption of output sparsity - that the target vectors have small support .We develop a general theory for a variant of the popular ECOC ( error correcting output code ) scheme , based on ideas from compressed sensing for exploiting this sparsity .", "label": "", "metadata": {}, "score": "42.77864"}
{"text": "The maximum number of derivations is also incremented by the derivation step .After finishing all the generations , the default rule is added to the classifier and the classifier is run on the test set , computing the predictive accuracy .", "label": "", "metadata": {}, "score": "42.792233"}
{"text": "No .5,056,021 , discloses a simpler technique for creating searchable conceptual structures .The technique of Ausborn uses a database of words organized into levels of abstraction , with concepts arranged as clusters of related words .The levels of abstraction are implemented in thesauri , and are equivalent to hierarchical levels of an ontology .", "label": "", "metadata": {}, "score": "42.842457"}
{"text": "No .5,056,021 , discloses a simpler technique for creating searchable conceptual structures .The technique of Ausborn uses a database of words organized into levels of abstraction , with concepts arranged as clusters of related words .The levels of abstraction are implemented in thesauri , and are equivalent to hierarchical levels of an ontology .", "label": "", "metadata": {}, "score": "42.842457"}
{"text": "The low level features considered are color features , texture features and shape features .These features after being extracted will be used to train a SVM classifier .Stacked generalization , or stacking , is an approach for constructing classifier ensembles [ 8].", "label": "", "metadata": {}, "score": "42.895294"}
{"text": "The heuristic , goalADoriented criteriaare on the one hand based on so - called \" measures \" measuring occurrences andnesting of function symbols , and on the other hand based on matching subterms .We also deal with the property of goal - oriented heuristics to be particularly helpfulin certain stages of a proof .", "label": "", "metadata": {}, "score": "42.920876"}
{"text": "Traditional training techniques for classifiers , such as multi - layer perceptions ( MLP ) , use empirical risk minimization and only guarantee minimum error over the training set .In contrast , the SVM machinery uses structural risk minimization that minimizes a bound on the generalization error and therefore should perform better on novel data .", "label": "", "metadata": {}, "score": "42.98874"}
{"text": "The third purpose is identifying the key content of the discourse in a content extractor .The forgoing steps are performed in parallel , and require additional processing of the theme - structured output in order to generate textual summaries , or graphical views of the concepts within a document .", "label": "", "metadata": {}, "score": "43.0431"}
{"text": "The third purpose is identifying the key content of the discourse in a content extractor .The forgoing steps are performed in parallel , and require additional processing of the theme - structured output in order to generate textual summaries , or graphical views of the concepts within a document .", "label": "", "metadata": {}, "score": "43.0431"}
{"text": "This is described further in the paper .New Stochastic Hyperheuristic Framework .The new hyperheuristic framework was first introduced in [ 2 ] .Essentially , it uses a matching evaluation over a maximising one .However , it also tries to maximise the matching score and so will favour higher scoring matches over lower scoring ones .", "label": "", "metadata": {}, "score": "43.04867"}
{"text": "Average rankings of all the algorithms considered are sum- marized at the bottom of Table IV .Looking at these ranking values , it can be noticed that the lowest ranking value , i.e. , the best global position , is obtained by our proposal .", "label": "", "metadata": {}, "score": "43.08597"}
{"text": "This mode generates multiple queries as a result of a single user query , and thus requires more processing power and time to perform as efficiently as exact match mode .For this reason .The concept based search and retrieval system 100 only switches to document predicate mode when no exact matches are found .", "label": "", "metadata": {}, "score": "43.150917"}
{"text": "This mode generates multiple queries as a result of a single user query , and thus requires more processing power and time to perform as efficiently as exact match mode .For this reason .The concept based search and retrieval system 100 only switches to document predicate mode when no exact matches are found .", "label": "", "metadata": {}, "score": "43.150917"}
{"text": "The list of documents is filtered according to some ranking algorithm before being returned to the user .Ranking algorithms provided by full - text , keyword - based search engines generally compute document scores based upon the frequency of the term within the document , where more mentions yield a higher score , as well as its position , earlier mentions leading to a higher score .", "label": "", "metadata": {}, "score": "43.197098"}
{"text": "The list of documents is filtered according to some ranking algorithm before being returned to the user .Ranking algorithms provided by full - text , keyword - based search engines generally compute document scores based upon the frequency of the term within the document , where more mentions yield a higher score , as well as its position , earlier mentions leading to a higher score .", "label": "", "metadata": {}, "score": "43.197098"}
{"text": "The processing time for an image was reported to be in milliseconds .Comparison Wu et al .( 2005)[9 ] proposed a one class SVM classifier .Several one - class classifiers were trained using different percentage of outliers for each classifier .", "label": "", "metadata": {}, "score": "43.250362"}
{"text": "Among others , this result subsumes a previous result for determinization of weighted string automata using factorizations ( Kirsten and M\u00e4urer , 2005 ) and two previous results for weighted tree automata , one of ... \" .We present a determinization construction for weighted tree automata using factorizations . \" ...", "label": "", "metadata": {}, "score": "43.26774"}
{"text": "The philosophy behind the algorithm is described more completely in [ 2 ] .It would work particularly well for problems that might require some sort of symbolic evaluation instead of a numerical one .In that case , an exact evaluation of what value is \" better \" might not be possible and so some sort of matching evaluation would be required instead .", "label": "", "metadata": {}, "score": "43.295185"}
{"text": "The model 's predictions are properly normalized probabilities .In addition , the model automatically takes into account information provided by phrase overlaps , and does not suffer from reference translation reachability problems .We have implemented an open source translation system Sinuhe based on the proposed translation model .", "label": "", "metadata": {}, "score": "43.373936"}
{"text": "Most of this section has been taken from the literature review on hyperheuristics [ 3 ] .Many real - world problems that require some level of intelligence are difficult to solve .If all of the potential solutions can be realised , then the best one will be available and can be selected .", "label": "", "metadata": {}, "score": "43.41478"}
{"text": "This repeated bisecting of concept pattern space efficiently homes in on the exact meaning the user intended and , with minimal effort , provides users with the precise results from the document search .When the document clustering component 180 is not actively processing user queries , it can also be used to pre - cluster documents stored in the data repository 150 as \" known documents .", "label": "", "metadata": {}, "score": "43.689537"}
{"text": "This repeated bisecting of concept pattern space efficiently homes in on the exact meaning the user intended and , with minimal effort , provides users with the precise results from the document search .When the document clustering component 180 is not actively processing user queries , it can also be used to pre - cluster documents stored in the data repository 150 as \" known documents .", "label": "", "metadata": {}, "score": "43.689537"}
{"text": "While a single heuristic can get stuck in locally optimal solutions , if several heuristics are compared , then a more universal picture can be obtained .This can lead to better solutions somewhere else in the search space .The main drawback is that hyperheuristics need to be configured , or fine - tuned with the correct parameter settings , to work well .", "label": "", "metadata": {}, "score": "43.732906"}
{"text": "Based on this the content analysis has been divided into two modules .International Journal on Natural Language Computing ( IJNLC )Vol . 3 , No.3 , June 2014 138 form the image body .The similarity measure will be calculated between the text extracted from the image and the text in the body of a spam message .", "label": "", "metadata": {}, "score": "43.787838"}
{"text": "The tree structures are created through the use of a context - free grammar , and may be implemented through a variety of techniques .Post - parser filters 125 are used to eliminate parse trees based on rules about improbable syntactic structures , and rules about conflicting ontological specifications .", "label": "", "metadata": {}, "score": "43.790604"}
{"text": "The tree structures are created through the use of a context - free grammar , and may be implemented through a variety of techniques .Post - parser filters 125 are used to eliminate parse trees based on rules about improbable syntactic structures , and rules about conflicting ontological specifications .", "label": "", "metadata": {}, "score": "43.790604"}
{"text": "Each feature therefore had a random score , but more commonly , this score would be closer to the mean value of the distribution .The matching process therefore should match the more common scores and therefore choose those related solutions for evolving further .", "label": "", "metadata": {}, "score": "43.863556"}
{"text": "We argue that a principle reason for this failure is not dealing with multiple , equivalent translations .We present a tr ... \" .Large - scale discriminative machine translation promises to further the state - of - the - art , but has failed to deliver convincing gains over current heuristic frequency count systems .", "label": "", "metadata": {}, "score": "43.872498"}
{"text": "Each rule is represented as a derivation tree that shows a solution described using the language denoted by the grammar .The algorithm includes mechanisms to adapt the diversity of the population by self - adapting the probabilities of recombination and mutation .", "label": "", "metadata": {}, "score": "44.00492"}
{"text": "In their invention , they did not use components for classifying age and did not have a mechanism for fusion of classifier results .Furthermore , their system can not be applied in the current form for ethnicity and gender classification .", "label": "", "metadata": {}, "score": "44.00591"}
{"text": "They note that while this can lead to mistrust in its use , it is also a more natural or bioinspired way of solving a problem .A key factor with this hyperheuristic , or for comparisons with other ones , is where in the process the randomness is applied .", "label": "", "metadata": {}, "score": "44.015503"}
{"text": "These predicates contain a plurality of keywords , which may be brokered to other search facilities to retrieve their indexed documents relating to the user 's query .Alternatively , a spider may be used to retrieve documents automatically from the web , without prior knowledge of their content .", "label": "", "metadata": {}, "score": "44.05138"}
{"text": "These predicates contain a plurality of keywords , which may be brokered to other search facilities to retrieve their indexed documents relating to the user 's query .Alternatively , a spider may be used to retrieve documents automatically from the web , without prior knowledge of their content .", "label": "", "metadata": {}, "score": "44.05138"}
{"text": "The distance measure is then compared to a threshold .The threshold is set different for each feature space .Based on the threshold value it is decided if the image is spam or legitimate .The labels from different feature spaces are then combined using logical operators ( OR , or AND ) , or by voting [ 9 ] .", "label": "", "metadata": {}, "score": "44.15483"}
{"text": "We conclude that HMC trees should definitely be considered in HMC tasks where interpretable models are desired .In addition , one can also take the hierarchy constraint into account during training by restricting the training set for the classifier for class c to those instances belonging to the parent class o .. \" ...", "label": "", "metadata": {}, "score": "44.321503"}
{"text": "Although the heuristic works well in practice , there is much room for improvement .In this paper , we propose a novel approach to improve this heuristic .The approach transforms the ordering search problem into a quadratic optimization problem and uses the solution of the optimization problem to extract the optimal ordering .", "label": "", "metadata": {}, "score": "44.471096"}
{"text": "The optimization is facilitated with a dynamic programming based algorithm that computes best update directions in the feasible set .Experiments show . \" ...We consider multi - label prediction problems with large output spaces under the assumption of output sparsity - that the target vectors have small support .", "label": "", "metadata": {}, "score": "44.492195"}
{"text": "To prevent several thousand file reads for computing gene expression feature for a protein pair , we preprocess the gene expression data in each category into a single file .This file has for each protein a vector of gene expression values corresponding to the microarray experiment .", "label": "", "metadata": {}, "score": "44.575928"}
{"text": "If the user declares that the example is not similar to the documents desired , the document clustering component 180 presents another example , this one chosen from a document cluster far from the first example 's cluster .The user may again decide if this new sample is \" similar to \" or \" not similar to \" the desired documents .", "label": "", "metadata": {}, "score": "44.582485"}
{"text": "If the user declares that the example is not similar to the documents desired , the document clustering component 180 presents another example , this one chosen from a document cluster far from the first example 's cluster .The user may again decide if this new sample is \" similar to \" or \" not similar to \" the desired documents .", "label": "", "metadata": {}, "score": "44.582485"}
{"text": "These communication components allow for quick integration between completely separate systems .The query ontological parser 120 is a component of the system , which transforms user queries entered in natural language into predicates , the formal representation system used within the concept based search and retrieval system of the present invention .", "label": "", "metadata": {}, "score": "44.61051"}
{"text": "These communication components allow for quick integration between completely separate systems .The query ontological parser 120 is a component of the system , which transforms user queries entered in natural language into predicates , the formal representation system used within the concept based search and retrieval system of the present invention .", "label": "", "metadata": {}, "score": "44.61051"}
{"text": "A method of performing concept - based searching of text documents as recited in .claim 12 , further comprising the step of using said ontology to develop said feature map to cluster said concept patterns .An apparatus for use in an information retrieval system for retrieving information in response to a query , comprising : . a query ontological parser that transforms a natural language query into predicate structures ; . an ontology providing information about words , said information comprising lexical semantic representation and syntactic types ; . a document ontological parser that transforms documents into predicate structures ; . a Bayes classifier probabilistically classifying said documents and said query ; . adaptive filters for filtering said documents against said query to produce a set of said documents matching said query ; and .", "label": "", "metadata": {}, "score": "44.62125"}
{"text": "A method of performing concept - based searching of text documents as recited in .claim 12 , further comprising the step of using said ontology to develop said feature map to cluster said concept patterns .An apparatus for use in an information retrieval system for retrieving information in response to a query , comprising : . a query ontological parser that transforms a natural language query into predicate structures ; . an ontology providing information about words , said information comprising lexical semantic representation and syntactic types ; . a document ontological parser that transforms documents into predicate structures ; . a Bayes classifier probabilistically classifying said documents and said query ; . adaptive filters for filtering said documents against said query to produce a set of said documents matching said query ; and .", "label": "", "metadata": {}, "score": "44.62125"}
{"text": "Under these circumstances , the document clustering component 180 provides an intelligent , adaptive filter to focus user attention on those documents most likely to meet user needs and interests .The document clustering component 180 uses adaptive self - organizing feature map technology to appropriately and dynamically cluster the documents returned by the system as matches for the concepts in the user 's query .", "label": "", "metadata": {}, "score": "44.649918"}
{"text": "Under these circumstances , the document clustering component 180 provides an intelligent , adaptive filter to focus user attention on those documents most likely to meet user needs and interests .The document clustering component 180 uses adaptive self - organizing feature map technology to appropriately and dynamically cluster the documents returned by the system as matches for the concepts in the user 's query .", "label": "", "metadata": {}, "score": "44.649918"}
{"text": "151 - 163 .[51 ] J. \u00b4 Avila , E.Gibaja , A. Zafra , algorithm to learn discriminant functions with multi - label patterns , \" in Intelligent Data Engineering and Automated Learning - IDEAL 2009 , 2009 , pp .", "label": "", "metadata": {}, "score": "44.650703"}
{"text": "Tools . by Juho Rousu , Craig Saunders , Sandor Szedmak , John Shawe - Taylor - JOURNAL OF MACHINE LEARNING RESEARCH , 2006 . \" ...We present a kernel - based algorithm for hierarchical text classification where the documents are allowed to belong to more than one category at a time .", "label": "", "metadata": {}, "score": "44.668396"}
{"text": "This not only results in finding proofsfaster , but also enables the prover to prove theorems it could not handle before .We present an overview of various learning techniques used in automated theorem provers .We characterize the main problems arising in this context and classify the solutions to these problems from published approaches .", "label": "", "metadata": {}, "score": "44.74817"}
{"text": "The scoring function measures what the expected improvement is in the accuracy of a classifier if we know the value of a particular missing feature given the cost involved in obtaining it .Given that a feature value f i is missing for an instance and it can take any of the K values ( V 1 , V 2 , ...", "label": "", "metadata": {}, "score": "44.798447"}
{"text": "This classification output is fused together using Classifier Fusion 1000 to give Classifier Output 900 .In hybrid configuration ( see .FIGS .11 and 12 ) , serial and parallel configuration is used in conjunction to improve the accuracy .", "label": "", "metadata": {}, "score": "44.952827"}
{"text": "Background .Machine learning approaches for classification learn the pattern of the feature space of different classes , or learn a boundary that separates the feature space into different classes .The features of the data instances are usually available , and it is only the class - labels of the instances that are unavailable .", "label": "", "metadata": {}, "score": "44.968143"}
{"text": "The first approach defines an independent single - label clas - sification task for each class ( SC ) .Obviously , the hierarchy introduces dependencies between the classes .While they are ignored by the first ap - proach , they are exploited by the second approach , named hierarchical single - label classification ( HSC ) .", "label": "", "metadata": {}, "score": "44.98806"}
{"text": "However , if exact match fails to turn up appropriate results , or if document predicate mode is set as the default , the query ontological parser 120 will generate additional predicates , using both synonyms and higher - level concepts .", "label": "", "metadata": {}, "score": "45.00595"}
{"text": "However , if exact match fails to turn up appropriate results , or if document predicate mode is set as the default , the query ontological parser 120 will generate additional predicates , using both synonyms and higher - level concepts .", "label": "", "metadata": {}, "score": "45.00595"}
{"text": "The system according to . claim 1 , wherein the classifiers comprise one or a plurality of demographic classifiers , . wherein said demographic classifier comprises a combination of two or more : . a ) means for collecting data , . wherein the data is divided into three mutually disjoint parts , including training set , bootstrapping set , and testing set , .", "label": "", "metadata": {}, "score": "45.01407"}
{"text": "For each source sentence S , a matching score is computed over al ..The novel decoding algorithm can handle tens of thousands of rules efficiently .An improvement over a standard phrase - based decoder is shown on an Arabic - English translation task with respect to translation accuracy and speed for large re - order window sizes .", "label": "", "metadata": {}, "score": "45.04164"}
{"text": "Concerning the assignment of the consequent , GBAP fol- lows a niching approach quite similar to that employed in [ 51 ] , whose purpose is to evolve different multiple rules for predicting each class in the data set while preserving the diversity .", "label": "", "metadata": {}, "score": "45.11853"}
{"text": "In addition , a context - free grammar ( CFG ) is used during the learning process .All generated individuals must adhere to this gram- mar , which also provides flexibility to apply the developed algorithm to a variety of problems with minor changes .", "label": "", "metadata": {}, "score": "45.12197"}
{"text": "The main goal of hyperheuristics is to develop algorithms that are more generally applicable .Paper [ 4 ] is a recent survey of hyperheuristics .As noted in [ 5 ] , a heuristic can be considered as a \" rule of thumb \" or \" educated guess \" that reduces the search required to find a solution .", "label": "", "metadata": {}, "score": "45.17022"}
{"text": "Using the disambiguation algorithm , the semantic vectors produced by the system are said to accommodate the problem that frequently used words in natural language tend to have many senses and therefore , many subject codes .In U.S. Pat .No .", "label": "", "metadata": {}, "score": "45.19129"}
{"text": "Using the disambiguation algorithm , the semantic vectors produced by the system are said to accommodate the problem that frequently used words in natural language tend to have many senses and therefore , many subject codes .In U.S. Pat .No .", "label": "", "metadata": {}, "score": "45.19129"}
{"text": "Hierarchical multi - label classification ( HMC ) is a variant of classification where instances may belong to multiple classes at the same time and these classes are organized in a hierarchy .This article presents several approaches to the induction of decision trees for HMC , as well as an em ... \" .", "label": "", "metadata": {}, "score": "45.24175"}
{"text": "Such data are called multi - label . ...Better results were found compared to an instantiation of HBR using perceptrons .Other important contributions of [ 54 ] are the definition of a hierarchical loss function ( see Section 7.1.1 ) and a th ... . by Nicol\u00f2 Cesa - Bianchi , Claudio Gentile , Luca Zaniboni - IN : ICML ' 06 : PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON MACHINE LEARNING , 2006 . \" ...", "label": "", "metadata": {}, "score": "45.277225"}
{"text": "We consider only protein pairs where individual proteins have gene ontology annotations and at least one of tissue or domain annotations .This is to ensure that the feature vector is reasonably filled .A training and test data set of 10,000 instances each was generated .", "label": "", "metadata": {}, "score": "45.303177"}
{"text": "Introduction .This paper describes the implementation and functionality of a centralised problem - solving system that is included as part of the distributed \" licas \" service - based framework [ 1 ] .The licas ( lightweight ( internet - based ) communication for autonomic services ) system is an open source framework for building service - based networks , similar to what you would do on a Cloud or SOA platform .", "label": "", "metadata": {}, "score": "45.316895"}
{"text": "These steps are repeated until some criteria are satisfied , but notice that new populations of programs are generated according to the pheromone tables .This approach was used to solve symbolic regression problems and a multiplexor problem with relative success .", "label": "", "metadata": {}, "score": "45.39954"}
{"text": "If a noun is found and it satisfies the restrictions of the adjective , the adjective filter will apply the selectional features of the adjective to the noun by adding all of the adjective 's selectional features to the noun 's set of selectional features .", "label": "", "metadata": {}, "score": "45.43128"}
{"text": "If a noun is found and it satisfies the restrictions of the adjective , the adjective filter will apply the selectional features of the adjective to the noun by adding all of the adjective 's selectional features to the noun 's set of selectional features .", "label": "", "metadata": {}, "score": "45.43128"}
{"text": "This classifier is then used to calculate a threshold that optimizes the cost on a different set of pre - classified instances ( the validation set ) .When a new instance needs to be classified , the threshold decides the category of the instance as positive ( spam ) or negative ( legitimate ) .", "label": "", "metadata": {}, "score": "45.483845"}
{"text": "A method of performing concept - based searching of text documents as recited in . claim 5 , wherein said step of transforming said natural language query comprises the steps of : . transforming said natural language query into multiple sequences of part - of - speech - tagged ontological concepts from said ontology ; . reducing the number of said multiple sequences based on rules relating to sequences of syntactic tags ; . creating syntactic tree structures , based on said syntactic tags , representing grammatical relations between said ontological concepts ; and . reducing the number of said tree structures based on rules relating to improbable syntactic structures , and rules concerning conflicting ontological specifications .", "label": "", "metadata": {}, "score": "45.49444"}
{"text": "A method of performing concept - based searching of text documents as recited in . claim 5 , wherein said step of transforming said natural language query comprises the steps of : . transforming said natural language query into multiple sequences of part - of - speech - tagged ontological concepts from said ontology ; . reducing the number of said multiple sequences based on rules relating to sequences of syntactic tags ; . creating syntactic tree structures , based on said syntactic tags , representing grammatical relations between said ontological concepts ; and . reducing the number of said tree structures based on rules relating to improbable syntactic structures , and rules concerning conflicting ontological specifications .", "label": "", "metadata": {}, "score": "45.49444"}
{"text": "No .5,309,359 to Katz , a process by which human operators select subdivisions of text to be annotated , and then tag them with questions in a natural language , is presented .These questions are then converted automatically into a structured form by means of a parser , using concept - relation - concept triples known as T - expressions .", "label": "", "metadata": {}, "score": "45.53316"}
{"text": "No .5,309,359 to Katz , a process by which human operators select subdivisions of text to be annotated , and then tag them with questions in a natural language , is presented .These questions are then converted automatically into a structured form by means of a parser , using concept - relation - concept triples known as T - expressions .", "label": "", "metadata": {}, "score": "45.53316"}
{"text": "As the concept based search and retrieval system 100 begins to produce potential matches for a specific user query , the document clustering component 180 begins to train itself on those matches .Each document is represented by one or more concept pattern vectors , and , as a document is added to the list of possible matches , those concept pattern vectors are fed to a self - adaptive feature map constructed specifically for this query .", "label": "", "metadata": {}, "score": "45.782875"}
{"text": "As the concept based search and retrieval system 100 begins to produce potential matches for a specific user query , the document clustering component 180 begins to train itself on those matches .Each document is represented by one or more concept pattern vectors , and , as a document is added to the list of possible matches , those concept pattern vectors are fed to a self - adaptive feature map constructed specifically for this query .", "label": "", "metadata": {}, "score": "45.782875"}
{"text": "Hierarchical multi - label classification ( HMC ) is a variant of classification where instances may belong to multiple classes at the same time and these classes are organized in a hierarchy .This article presents several approaches to the induction of decision trees for HMC , as well as an empirical study of their use in functional genomics .", "label": "", "metadata": {}, "score": "45.78707"}
{"text": "This fact allows us to prove performance bounds that hold for an arbitrary sequence of instances .In particular , we show that our sampling strategy approximates the margin of the Bayes optimal classifier to any desired accuracy \u03b5 by asking \u00d5 ( d / \u03b52 ) queries ( in the RKHS case d is replaced by a suitable spectral quantity ) .", "label": "", "metadata": {}, "score": "45.858047"}
{"text": "We present a new phrase - based conditional exponential family translation model for statistical machine translation .The model operates on a feature representation in which sentence level translations are represented by enumerating all the known phrase level translations that occur inside them .", "label": "", "metadata": {}, "score": "45.89574"}
{"text": "Then , a consequent is assigned to each ant .To conclude the niching algorithm , the winner ants are assigned to the classifier , replacing the previous rules .Afterwards , each ant created in this generation of the algo- rithm reinforces the amount of pheromones of the transitions followed only if it has a fitness greater than the threshold value .", "label": "", "metadata": {}, "score": "45.98419"}
{"text": "al , Pat No .( Application )US20030026483A1 , describes a method for object detection using features .They used expectation maximization to assess a joint probability of which features are most relevant .Their invention defines a statistical model in which shape variability is modeled in a probabilistic setting .", "label": "", "metadata": {}, "score": "45.995445"}
{"text": "More specifically , it introduces a new pheromone placement method that tends to put in a derivation step an amount of pheromone proportional to the depth of the path ; and it also employs a specific heuristic function to control the path termination .", "label": "", "metadata": {}, "score": "46.032146"}
{"text": "Consequently , when a new instance needs to be classified , it is matched to the stored documents and assigned the more appropriate category based on its similarity to those stored in every class .The most popular one in this category is k - Nearest Neighbors ( kNN ) .", "label": "", "metadata": {}, "score": "46.064754"}
{"text": "The pattern those predicates make within a document constitutes the concept pattern of that document .The concept pattern of a document is more revealing than any single predicate within the document when trying to determine the contents of a document .", "label": "", "metadata": {}, "score": "46.072266"}
{"text": "The pattern those predicates make within a document constitutes the concept pattern of that document .The concept pattern of a document is more revealing than any single predicate within the document when trying to determine the contents of a document .", "label": "", "metadata": {}, "score": "46.072266"}
{"text": "This can be illustrated as the risk of missing significant and genuine messages because messages considered spam be removed or , preferably saved in a quarantine that can be later searched .Thresholding is another method for making algorithms cost - sensitive .", "label": "", "metadata": {}, "score": "46.075603"}
{"text": "m . )N .GE1 . m .GE .m . )N .GE2 . m .GE .m . )N .Two gene expression features are computed .They are the mean and standard deviation of the correlation values ( PPC m ) for the 70 categories .", "label": "", "metadata": {}, "score": "46.162533"}
{"text": "This mode exercises all of the components provided by the concept - based search and retrieval system 100 , and demonstrates all of the benefits of the present invention .However , due to the current state of technology ( namely processing power , storage devices and access times , and Internet access speeds ) other modes are used to allow users to gain real - time results from their searches .", "label": "", "metadata": {}, "score": "46.206127"}
{"text": "This mode exercises all of the components provided by the concept - based search and retrieval system 100 , and demonstrates all of the benefits of the present invention .However , due to the current state of technology ( namely processing power , storage devices and access times , and Internet access speeds ) other modes are used to allow users to gain real - time results from their searches .", "label": "", "metadata": {}, "score": "46.206127"}
{"text": "The evolution algorithm evolves using an intersection and so the sums for single datasets will generally be larger than for evolved sets .A hill - climbing approach did not work as well for this type of problem , because maximising the count would prefer the original datasets with all of their features and largest values , over an evolved one with only subsets of those features .", "label": "", "metadata": {}, "score": "46.212852"}
{"text": "SUMMARY OF THE INVENTION .The forgoing and other deficiencies are addressed by the present invention , which is directed to a concept - based indexing and search system .More particularly , the present invention relates to system that indexes collections of documents with ontology - based predicate structures through automated and/or human - assisted methods .", "label": "", "metadata": {}, "score": "46.227684"}
{"text": "SUMMARY OF THE INVENTION .The forgoing and other deficiencies are addressed by the present invention , which is directed to a concept - based indexing and search system .More particularly , the present invention relates to system that indexes collections of documents with ontology - based predicate structures through automated and/or human - assisted methods .", "label": "", "metadata": {}, "score": "46.227684"}
{"text": "FIG .11 shows an exemplary embodiment of the Hybrid Configuration of classifiers .FIG .12 shows another exemplary embodiment of the Hybrid Configuration of classifiers .FIG .13 shows an exemplary embodiment of the Parallel Configuration for multiple Category Demographic Classifiers ( for e.g. , two or more categories of age , gender , or ethnicity ) .", "label": "", "metadata": {}, "score": "46.23974"}
{"text": "Each source can be used to create a service that is initialised with the information and then run on the network .The paths to the data sources can be specified in the script - currently file paths .The mediator then periodically asks the services for their recent evaluations or information and invokes the problem solver to cluster or solve the information set as best it can .", "label": "", "metadata": {}, "score": "46.328896"}
{"text": "And the other involved the discretization of such data sets con- taining numerical attributes , by applying Fayyad and Irani 's discretization algorithm [ 53].The replacement of missing values was done before partitioning the data set , and the discretization was applied for each specific training set , using the same intervals found to discretize the corresponding test set .", "label": "", "metadata": {}, "score": "46.353863"}
{"text": "\" The key idea in hyper - heuristics is to use members of a set of known and reasonably understood heuristics to transform the state of a problem .The key observation is a simple one : the strength of a heuristic often lies in its ability to make some good decisions on the route to fabricating an excellent solution .", "label": "", "metadata": {}, "score": "46.36422"}
{"text": "Automated collection of demographic information has numerous application and has the potential of not only enhancing the existing HCI system but can also serve as platform for passive surveillance ( for e.g. , alerting medical authorities if there is a accident in old age home ) .", "label": "", "metadata": {}, "score": "46.424484"}
{"text": "In practice , phrase - based or block - based translation models which ... . \" ...We present a new phrase - based conditional exponential family translation model for statistical machine translation .The model operates on a feature representation in which sentence level translations are represented by enumerating all the known phrase level translations that occur inside them .", "label": "", "metadata": {}, "score": "46.501854"}
{"text": "( 2005 ) [ 9 ] is the first one who proposed an image classification technique [ 7 ] .The proposed technique computed the chosen features on all the images attached to an email .International Journal on Natural Language Computing ( IJNLC ) Vol .", "label": "", "metadata": {}, "score": "46.501907"}
{"text": "Our preliminary studies demonstrate that NNR - based interpolation is a simple tool that nevertheless has enough potential to beseriously considered for cancer research or related research .The team work method is a concept for distributing automated theoremprovers and so to activate several experts to work on a given problem .", "label": "", "metadata": {}, "score": "46.609608"}
{"text": "However , the document is also relevant to questions which do not contain exact matches of any of the predicates above , such as : . \" How did investors react to the agreement on financial legislation ?This would parse into the query predicates react and on .", "label": "", "metadata": {}, "score": "46.73092"}
{"text": "However , the document is also relevant to questions which do not contain exact matches of any of the predicates above , such as : . \" How did investors react to the agreement on financial legislation ?This would parse into the query predicates react and on .", "label": "", "metadata": {}, "score": "46.73092"}
{"text": "For this reason , active learning methods can contribute to the domain of molecular biology , and guide the selection of molecule - experiment combinations that yield maximum benefit towards characterizing other molecules by computational methods .We have previously applied active learning for label acquisition for protein - protein interaction prediction [ 27 ] .", "label": "", "metadata": {}, "score": "46.73156"}
{"text": "The classifier C i predicts what the probability is that a missing feature will take a particular value when the other feature values and the class label for an instance are known .It finds the expected utility for various missing values across all the instances .", "label": "", "metadata": {}, "score": "46.78974"}
{"text": "This component information is fed to classifiers to extract demographic information .The classifier module comprise of fusion classifiers based on Data Level or Hierarchical Fusion model .In data level fusion model , the component information from various components is concatenated in one vector for classification .", "label": "", "metadata": {}, "score": "46.946716"}
{"text": "Keber and Schuster published another grammar - based work called generalized ant programming ( GAP ) [ 43 ] , which uses a CFG instead of TAG , and where ants generate a program by following a path in the space of states .", "label": "", "metadata": {}, "score": "46.948563"}
{"text": "Thus , the smaller the number of rules and the number of conditions appearing in them , the smaller the complexity of the classifier .Table V summarizes both the classifier 's rule set complexity , by the average number of rules found per data set , and the complexity of the rules , by the average number of conditions per rule .", "label": "", "metadata": {}, "score": "47.10502"}
{"text": "[5 ] S. Haykin , Neural Networks and Learning Machines , 3rd ed .Pearson , 2009 .[ 6 ] S. U. Guan and F. Zhu , \" An incremental approach to genetic - algorithms- based classification , \" IEEE Transactions on Systems , Man , and Cyber- netics , Part B , vol .", "label": "", "metadata": {}, "score": "47.238388"}
{"text": "This relies on probability densities that can be unknown or hard to estimate .With discrete or nominal variables however , it can be written as . is the probability of them occurring together .The value is therefore a measure of the dependency between the target and the variable in question .", "label": "", "metadata": {}, "score": "47.27832"}
{"text": "Because this training process is computationally extremely simple , it can be performed in real - time environments with little operational time penalty .In addition , the size of the vicinity of the feature map being adjusted with each input pattern is similarly adjusted , typically reduced , until only a single node 's weight vector is adjusted with each new pattern .", "label": "", "metadata": {}, "score": "47.336376"}
{"text": "Because this training process is computationally extremely simple , it can be performed in real - time environments with little operational time penalty .In addition , the size of the vicinity of the feature map being adjusted with each input pattern is similarly adjusted , typically reduced , until only a single node 's weight vector is adjusted with each new pattern .", "label": "", "metadata": {}, "score": "47.336376"}
{"text": "We present two such heuristics .The first heuristic attempts to re - enact aproof of a proof problem found in the past in a flexible way in order to find a proofof a similar problem .The second heuristic employs \" features \" in connection withpast proof experience to prune the search space .", "label": "", "metadata": {}, "score": "47.347385"}
{"text": "We conjecture this is due to a higher noise rate for the training labels in the low levels of the taxonomy . by Celine Vens , Jan Struyf , Er Schietgat , Hendrik Blockeel - Machine Learning , 2008 . \" ...", "label": "", "metadata": {}, "score": "47.384216"}
{"text": "The algorithm and novel nature of the process can be briefly described as follows .The solutions and the problem datasets are randomly placed into a grid and then a game is played to try and optimise the total cost over the whole grid .", "label": "", "metadata": {}, "score": "47.40663"}
{"text": "11 is a diagram of a parser tree according to one variation of the present invention ; .FIG .12 is a flow chart of an example of classification collection flow according to one variation of the present invention ; .", "label": "", "metadata": {}, "score": "47.53094"}
{"text": "11 is a diagram of a parser tree according to one variation of the present invention ; .FIG .12 is a flow chart of an example of classification collection flow according to one variation of the present invention ; .", "label": "", "metadata": {}, "score": "47.53094"}
{"text": "The user just has to specify the basic blocks that make up any program or individual , and how individuals are evaluated .Concretely , GP uses genetic algorithms as the search technique .In this paper we first look at the AP works published in the literature , to prove that the development of AP algorithms and their application to DM is still an unexplored and promising research area .", "label": "", "metadata": {}, "score": "47.774002"}
{"text": "By incorporating correlation priors we can overcome training set biases and improve prediction accuracy .We provide a principled interpretation of the 1-vs - All method and show . \" ...We introduce a new algorithm for binary classification in the selective sampling protocol .", "label": "", "metadata": {}, "score": "47.779533"}
{"text": "However , the predicates they occur within can still be found through the full power of the concept based search and retrieval system 100 retrieval system .Finally , the document is stored in the data repository 150 .Multiple references to the page are generated , each one consisting of a predicate from the list above and a link to the document .", "label": "", "metadata": {}, "score": "47.826073"}
{"text": "However , the predicates they occur within can still be found through the full power of the concept based search and retrieval system 100 retrieval system .Finally , the document is stored in the data repository 150 .Multiple references to the page are generated , each one consisting of a predicate from the list above and a link to the document .", "label": "", "metadata": {}, "score": "47.826073"}
{"text": "These component demographic classifier 800 , 801 , and 802 results are passed to multi - level classifiers called Hierarchical Fusion 803 classifier .The Hierarchical Fusion 803 classifier may perform fusion on the basis of Majority Voting , Support Vector Machine , Hidden Markov Model , Bayesian Networks , Neural Networks , CART , or any other technique available in the classification literature .", "label": "", "metadata": {}, "score": "47.857876"}
{"text": "It should be pointed out that , depending on both the dimensionality of the data set addressed and the number of derivations permitted from the grammar , it may suppose an excessive computational cost to keep in memory the whole space of states .", "label": "", "metadata": {}, "score": "47.89488"}
{"text": "Section 4 describes the new hyperheuristic framework in more detail , including implementation details .Section 5 describes some tests results that show the heuristic working in an unsupervised manner .Section 6 gives some conclusions on the work and Section 7 describes future possibilities in the area of a more cognitive model .", "label": "", "metadata": {}, "score": "47.903038"}
{"text": "The term concept as used herein means an abstract formal representation of meaning , which corresponds to multiple generic or specific words in multiple languages .Concepts may represent the meanings of individual words or phrase , or the meanings of entire sentences .", "label": "", "metadata": {}, "score": "47.913826"}
{"text": "The term concept as used herein means an abstract formal representation of meaning , which corresponds to multiple generic or specific words in multiple languages .Concepts may represent the meanings of individual words or phrase , or the meanings of entire sentences .", "label": "", "metadata": {}, "score": "47.913826"}
{"text": "Any Lexeme whose text is in that set and whose concept is a verb is identified as a modal verb , and will be removed .The adverb filter removes Lexemes containing adverb concepts from sentences .Adverbs detail the meaning of the verbs they accompany , but do not change them .", "label": "", "metadata": {}, "score": "47.9181"}
{"text": "Any Lexeme whose text is in that set and whose concept is a verb is identified as a modal verb , and will be removed .The adverb filter removes Lexemes containing adverb concepts from sentences .Adverbs detail the meaning of the verbs they accompany , but do not change them .", "label": "", "metadata": {}, "score": "47.9181"}
{"text": "The alert reader will immediately notice an objection to this whole idea .Good decisions are not necessarily easily recognisable in isolation .It is a sequence of decisions that builds a solution , and so there can be considerable epistasis involved - that is , a non - linear interdependence between the parts .", "label": "", "metadata": {}, "score": "47.92881"}
{"text": "This is similar to the normal functionality of knowledge bases , and Dahlgren et al . claim that their knowledge is completely represented in first order logic for fast deductive methods .Natural language retrieval is performed by Dahlgren et al . 's system using a two - stage process referred to as digestion and search .", "label": "", "metadata": {}, "score": "47.969444"}
{"text": "This is similar to the normal functionality of knowledge bases , and Dahlgren et al . claim that their knowledge is completely represented in first order logic for fast deductive methods .Natural language retrieval is performed by Dahlgren et al . 's system using a two - stage process referred to as digestion and search .", "label": "", "metadata": {}, "score": "47.969444"}
{"text": "Online].[ 27 ] D. Martens , M. De Backer , J. Vanthienen , M. Snoeck , and B. Baesens , \" Classification with ant colony optimization , \" IEEE Transactions on Evolutionary Computation , vol .11 , pp .", "label": "", "metadata": {}, "score": "48.034042"}
{"text": "The data repository 150 might not have enough indexed documents at the time of the search .A persistent agent - based approach takes advantage of unanswered queries to index new documents capable of answering later queries about the same subject or to notify the user of the original query when such document is found .", "label": "", "metadata": {}, "score": "48.062172"}
{"text": "The data repository 150 might not have enough indexed documents at the time of the search .A persistent agent - based approach takes advantage of unanswered queries to index new documents capable of answering later queries about the same subject or to notify the user of the original query when such document is found .", "label": "", "metadata": {}, "score": "48.062172"}
{"text": "The output classifier is an ordered rule list in which discovered rules are sorted in descending order by their fitness .A default rule predicting the majority class of the training set is added at the bottom of the classifier .Once the model has been learned from the training set , to classify a new instance , the label assigned corresponds to the consequent of the first rule in the classifier whose antecedent matches the instance .", "label": "", "metadata": {}, "score": "48.06575"}
{"text": "A method of performing concept - based searching of text documents as recited in . claim 5 , wherein said step of transforming a natural language query into predicate structures comprises the steps of : . removing words that serve as placeholders in English - language ; . removing lexemes representing adjective concepts ; . grouping proper nouns into single lexical nouns ; . removing modal verbs ; . removing lexemes containing adverb concepts ; and .", "label": "", "metadata": {}, "score": "48.08448"}
{"text": "A method of performing concept - based searching of text documents as recited in . claim 5 , wherein said step of transforming a natural language query into predicate structures comprises the steps of : . removing words that serve as placeholders in English - language ; . removing lexemes representing adjective concepts ; . grouping proper nouns into single lexical nouns ; . removing modal verbs ; . removing lexemes containing adverb concepts ; and .", "label": "", "metadata": {}, "score": "48.08448"}
{"text": "It is worth noting at this point that every algorithm used in the experimentation was run over the same discretized partitions of the data sets previously mentioned , even in the case of those capable of handling numerical values .Bojarczuk - GP is a GP algorithm for classification rule min- ing that reports good accuracy and comprehensibility results when applied to medical data sets .", "label": "", "metadata": {}, "score": "48.08761"}
{"text": "claim 20 , wherein said ranking module determines similarity between said predicate structure of said query and each predicate structure of said documents returned from said data repository .An apparatus for use in an information retrieval system for retrieving information in response to a query comprising : . a query ontological parser that transforms a natural language query into predicate structures ; . an ontology providing information about words , said information comprising syntactic uses and definitions ; . a document ontological parser that transforms documents into predicate structures ; . a Bayes classifier probabilistically classifying said documents and said query ; . adaptive filters for filtering said predicate structures of said documents against said predicate structures of said query to group said documents according to similarity of concept patterns contained in said documents relative to said query or additional feedback ; and .", "label": "", "metadata": {}, "score": "48.178635"}
{"text": "claim 20 , wherein said ranking module determines similarity between said predicate structure of said query and each predicate structure of said documents returned from said data repository .An apparatus for use in an information retrieval system for retrieving information in response to a query comprising : . a query ontological parser that transforms a natural language query into predicate structures ; . an ontology providing information about words , said information comprising syntactic uses and definitions ; . a document ontological parser that transforms documents into predicate structures ; . a Bayes classifier probabilistically classifying said documents and said query ; . adaptive filters for filtering said predicate structures of said documents against said predicate structures of said query to group said documents according to similarity of concept patterns contained in said documents relative to said query or additional feedback ; and .", "label": "", "metadata": {}, "score": "48.178635"}
{"text": "[Online].1007/978 - 3 - 642 - 04394 - 9\\ 69 [ 52 ] A. Frank and A. Asuncion , \" UCI machine learning repository , \" 2010 .[Online].[54 ] C. C. Bojarczuk , H. S. Lopes , A. A. Freitas , and E. L. Michalkiewicz , \" A constrained - syntax genetic programming system for discovering clas- sification rules : application to medical data sets , \" Artificial Intelligence in Medicine , vol .", "label": "", "metadata": {}, "score": "48.180595"}
{"text": "Documents with the most keywords that match the input query are retrieved .Some ranking process generally follows this retrieval , and orders the returned documents by how many times the query words appear within them .The problem with this approach is that no attempt is made to identify the meaning of the query and to compare that meaning with the meaning of the documents .", "label": "", "metadata": {}, "score": "48.207108"}
{"text": "Documents with the most keywords that match the input query are retrieved .Some ranking process generally follows this retrieval , and orders the returned documents by how many times the query words appear within them .The problem with this approach is that no attempt is made to identify the meaning of the query and to compare that meaning with the meaning of the documents .", "label": "", "metadata": {}, "score": "48.207108"}
{"text": "Test Algorithm .A more complete description of how the new hyper - heuristic framework works is given in [ 2 ] .This section includes algorithms specifically for the test that was carried out .The test data was created from Algorithm 1 . Conclusions .", "label": "", "metadata": {}, "score": "48.268547"}
{"text": "Using components for demographic classification gives better results as compared to currently known techniques .Moreover , the described system and technique can be used to extract demographic information in more robust manner than currently known methods , in environments where high degree of variability in size , shape , color , texture , pose , and occlusion exists .", "label": "", "metadata": {}, "score": "48.281025"}
{"text": "12 is a flow diagram illustrating the first stage of constructing a Finance - domain - specific classifier .Topic editors collect a set of example documents contains both documents relevant to and documents irrelevant to Finance domain .This operation is shown in step 500 of FIG .", "label": "", "metadata": {}, "score": "48.40673"}
{"text": "12 is a flow diagram illustrating the first stage of constructing a Finance - domain - specific classifier .Topic editors collect a set of example documents contains both documents relevant to and documents irrelevant to Finance domain .This operation is shown in step 500 of FIG .", "label": "", "metadata": {}, "score": "48.40673"}
{"text": "A method of performing concept - based searching of text documents as recited in . claim 5 , wherein said step of transforming said text documents comprises the steps of . transforming said documents into multiple sequences of part - of - speech - tagged ontological concepts from said ontology ; . reducing the number of said multiple sequences based on rules relating to sequences of syntactic tags ; . creating syntactic tree structures representing grammatical relations between said ontological concepts based on said syntactic tags ; and . reducing the number of said tree structures based on rules relating to improbable syntactic structures , and rules concerning conflicting ontological specifications .", "label": "", "metadata": {}, "score": "48.44412"}
{"text": "A method of performing concept - based searching of text documents as recited in . claim 5 , wherein said step of transforming said text documents comprises the steps of . transforming said documents into multiple sequences of part - of - speech - tagged ontological concepts from said ontology ; . reducing the number of said multiple sequences based on rules relating to sequences of syntactic tags ; . creating syntactic tree structures representing grammatical relations between said ontological concepts based on said syntactic tags ; and . reducing the number of said tree structures based on rules relating to improbable syntactic structures , and rules concerning conflicting ontological specifications .", "label": "", "metadata": {}, "score": "48.44412"}
{"text": "When the dataset size is large and has several missing values , the time for evaluating the expected utility would be very high .To overcome this , the authors ( Melville et al ) proposed Sampled Expected Utility wherein a random subset of instances ( S ) with missing feature values are selected randomly and are evaluated by the above procedure .", "label": "", "metadata": {}, "score": "48.51976"}
{"text": "They system did not use components for classification .Moreover , they did not show that their system could be applied to Ethnicity and age classification .Gutta et .Their system did not use components for classification purpose .Wiskott et .", "label": "", "metadata": {}, "score": "48.548187"}
{"text": "After the theme parser processor has generated this information , it is considered to be theme - structured output , which may be used for three distinct purposes .One purpose is providing the topics of the discourse in a topic extractor .", "label": "", "metadata": {}, "score": "48.56298"}
{"text": "After the theme parser processor has generated this information , it is considered to be theme - structured output , which may be used for three distinct purposes .One purpose is providing the topics of the discourse in a topic extractor .", "label": "", "metadata": {}, "score": "48.56298"}
{"text": "We present a translation model which models derivations as a latent variable , in both training and decoding , and is fully discriminative and globally optimised .Results show that accounting for multiple derivations does indeed improve performance .Additionally , we show that regularisation is essential for maximum conditional likelihood models in order to avoid degenerate solutions .", "label": "", "metadata": {}, "score": "48.575756"}
{"text": "The success of the test was then calculated as follows .Some of the final clusters contained the original solution datasets , while others contained the evolved solution datasets .If the process is constructive or intelligent , then the evolved solutions should be closer to the mean value than the original ones .", "label": "", "metadata": {}, "score": "48.60591"}
{"text": "The present invention defines a method and a system for gathering demographic information ( such as ethnicity / gender / age ) using image components in a facial image .In accordance with this invention , demographic information refers to one or more of the age , gender , or ethnicity demographic categories .", "label": "", "metadata": {}, "score": "48.668865"}
{"text": "Figure 1 is a schematic of the general problem solving framework .The problem solving is performed locally and not distributed throughout all of the network services or nodes .Any test problem can be configured using a test script .The licas system also has a GUI that can be used to run the tests .", "label": "", "metadata": {}, "score": "48.733936"}
{"text": "al , describes a classification methodology for detection , recognition , and identification of age and gender using Left and Right Eye and region between the eyes .Their system is restricted only to the eyes and does not include any other component of human body or facial feature for classification .", "label": "", "metadata": {}, "score": "48.817497"}
{"text": "The graph shows F - score of the heuristic method proposed here with that proposed by Melville et al .Axes descriptions are same as in Figure 1 .Next , we analyzed what types of features are being selected for querying in the AFA procedure .", "label": "", "metadata": {}, "score": "48.824287"}
{"text": "A heuristic learned ( adapted ) this way canthen be applied profitably when searching for a proof of a similar problem .So , our method can be used to train a proof heuristic for a class of similar problems .A number of experiments ( with an automated prover for purely equationallogic ) show that adapted heuristics are not only able to speed up enormously thesearch for the proof learned during adaptation .", "label": "", "metadata": {}, "score": "48.828724"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 20 , wherein said adaptive filters comprise a feature map that clusters said matching documents according to concept patterns in said query and produces a cluster model representing a statistical probability distribution of said matching documents .", "label": "", "metadata": {}, "score": "48.86272"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 20 , wherein said adaptive filters comprise a feature map that clusters said matching documents according to concept patterns in said query and produces a cluster model representing a statistical probability distribution of said matching documents .", "label": "", "metadata": {}, "score": "48.86272"}
{"text": "Two different kinds of Bayes classifiers are defined in this system .One is document domain specific classifier , which is used to determine if an input document 391 belongs to a specific domain or not .FIG .9 shows how a document domain specific classifier reasons .", "label": "", "metadata": {}, "score": "48.863655"}
{"text": "Two different kinds of Bayes classifiers are defined in this system .One is document domain specific classifier , which is used to determine if an input document 391 belongs to a specific domain or not .FIG .9 shows how a document domain specific classifier reasons .", "label": "", "metadata": {}, "score": "48.863655"}
{"text": "A method of performing concept - based searching of text documents as recited in . claim 5 , wherein words and associated probabilities , comprising a statistically - derived category , are used to determine if a particular document belongs to a specific domain .", "label": "", "metadata": {}, "score": "48.875412"}
{"text": "A method of performing concept - based searching of text documents as recited in . claim 5 , wherein words and associated probabilities , comprising a statistically - derived category , are used to determine if a particular document belongs to a specific domain .", "label": "", "metadata": {}, "score": "48.875412"}
{"text": "The dataset designed by Dredze et al .( 2005)[10 ] will be used for initial analysis .This work promises to enhance the spam filtering domain in future .REFERENCES [ 1 ] Godwin Caruana , Maozhen Li , \" A Survey of Emerging Approaches to Spam Filtering \" , ACM Computing Surveys , Vol .", "label": "", "metadata": {}, "score": "48.90557"}
{"text": "International Journal on Natural Language Computing ( IJNLC )Vol . 3 , No.3 , June 2014 134 Another advanced Machine Learning procedure which provides the concept of weighted prediction , also called voting , is the Boosting technique .The concept of boosting ( applied to spam detection by Carreras et al .", "label": "", "metadata": {}, "score": "48.906925"}
{"text": "f .i . ) j .K .P .f .i .V .j .y .L . m . )f .i .V .j . )The estimated change \u0394\u03c1 is a heuristic to estimate how much of a change would be induced into the current classifier ' C ' if it is retrained with ' p ' having feature value f i set to V j .", "label": "", "metadata": {}, "score": "48.911133"}
{"text": "It has been found that simple text- categorization techniques are not sufficient to prevent image spam .Hence , it is required to assemble image features like visual features and image meta - data in order to derive an effective spam detection system .", "label": "", "metadata": {}, "score": "49.00853"}
{"text": "The static component contains multiple knowledge concepts for a particular area of knowledge , and stores all senses for each word and concept .However , it does not contain concepts that are extremely volatile .Instead , the dynamic component contains words and concepts that are inferred to be related to the content of the static component .", "label": "", "metadata": {}, "score": "49.013268"}
{"text": "The static component contains multiple knowledge concepts for a particular area of knowledge , and stores all senses for each word and concept .However , it does not contain concepts that are extremely volatile .Instead , the dynamic component contains words and concepts that are inferred to be related to the content of the static component .", "label": "", "metadata": {}, "score": "49.013268"}
{"text": "Paper [ 11 ] gives an example of a ranking equation that can be used with information theoretic criteria .Information theory has to do with data compression and also loss of information through noise .The following is an example of the sort of equation that would be used to evaluate that .", "label": "", "metadata": {}, "score": "49.04429"}
{"text": "Given a protein pair ( P1,P2 ) , the domain interaction feature is calculated as follows , .d .S .e . t .d .S .e . t .s .c .o .r .", "label": "", "metadata": {}, "score": "49.136093"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 20 , wherein said ranking module determines similarity between said query and each of said documents returned from said data repository .", "label": "", "metadata": {}, "score": "49.175888"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 20 , wherein said ranking module determines similarity between said query and each of said documents returned from said data repository .", "label": "", "metadata": {}, "score": "49.175888"}
{"text": "On the other hand , comprehensibility results prove that GBAP is a competitive classifier in this sense , too .We consider these results promising , as they demonstrate that AP can be successfully employed to tackle classification problems , just as GP has demonstrated in previous research .", "label": "", "metadata": {}, "score": "49.188"}
{"text": "Those other concepts are the arguments of the predicate , and are generally nouns , because predicate relationships are usually between entities .The ontological parser 120 contains two significant functional components , namely , a sentence lexer 122 , a tool for transforming text strings into ontological entities and a parser 124 , a tool for analyzing syntactic relationships between entities .", "label": "", "metadata": {}, "score": "49.236748"}
{"text": "Those other concepts are the arguments of the predicate , and are generally nouns , because predicate relationships are usually between entities .The ontological parser 120 contains two significant functional components , namely , a sentence lexer 122 , a tool for transforming text strings into ontological entities and a parser 124 , a tool for analyzing syntactic relationships between entities .", "label": "", "metadata": {}, "score": "49.236748"}
{"text": "For example , web browser users can submit queries to the system via an HTML web site utilizing the Hyper Text Transfer Protocol ( HTTP ) .Application - level connections may use the concept based search engine through standards such as CORBA or Java RMI .", "label": "", "metadata": {}, "score": "49.323235"}
{"text": "For example , web browser users can submit queries to the system via an HTML web site utilizing the Hyper Text Transfer Protocol ( HTTP ) .Application - level connections may use the concept based search engine through standards such as CORBA or Java RMI .", "label": "", "metadata": {}, "score": "49.323235"}
{"text": "The data structure that represents the space of states is initialized just with the initial state and all possible transitions have the same quantity of pheromones .This data structure also contains attributes that take into account the effects of the evaporation and normalization processes over the environment .", "label": "", "metadata": {}, "score": "49.411522"}
{"text": "The original solutions that were included actually had an average difference of possibly around 2.27 , which is close to the random average value .The evolved solutions had an average difference of possibly 1.57 , which is a 30 % improvement on the random or single datasets value .", "label": "", "metadata": {}, "score": "49.48956"}
{"text": "In this case , the randomness applies to the evaluation process of the hyperheuristic itself .Their own XCS algorithm uses the problem state to determine what heuristic to apply at some stage of the problem solving process .It also however , chooses randomly which problem to solve at each step , and randomness is also used as part of the problem - solving process itself .", "label": "", "metadata": {}, "score": "49.504433"}
{"text": "Variable Selection .Before any entity can be analysed , it has to be determined what the most important features of that entity are .These features are then used to classify or evaluate the entity .This can be a difficult task because an entity could be composed of thousands of different features and so it is important to recognise the most important ones that make it different , or the same , as other entities .", "label": "", "metadata": {}, "score": "49.50666"}
{"text": "For example , the earliest generation of search engines , including Lycos , Altavista , and Webcrawler , as well as the most recent ones , such as Northern Light or FAST , are all based on keyword indexing and searching .", "label": "", "metadata": {}, "score": "49.617817"}
{"text": "For example , the earliest generation of search engines , including Lycos , Altavista , and Webcrawler , as well as the most recent ones , such as Northern Light or FAST , are all based on keyword indexing and searching .", "label": "", "metadata": {}, "score": "49.617817"}
{"text": "Performance comparison .We compared the performance of the proposed Active Feature Acquisition ( AFA ) heuristic with a system which randomly selects missing feature values for acquisition .In each iteration 500 missing values are acquired and a Decision Tree Classifier is retrained .", "label": "", "metadata": {}, "score": "49.62793"}
{"text": "For a given source sentence S , a maximum entropy ( ME ) classifier is applied to a large set of candidate target translations .A beam - search algorithm is used to abandon target sente ... \" .This paper extends previous work on extracting parallel sentence pairs from comparable data ( Munteanu and Marcu , 2005 ) .", "label": "", "metadata": {}, "score": "49.645348"}
{"text": "In this case , they apply each heuristic to a candidate solution to determine how it changes .If the solution changes positively , then the change is accepted .This is a perturbative approach , but includes both heuristic selection and heuristic creation or mutation .", "label": "", "metadata": {}, "score": "49.656303"}
{"text": "Table 4 is a sample Query Topic Example set 410 generated for the sample queries listed in Table 5 .Training processes for the query topic specific classifier are the same as training processes for document - domain - specific classifier described earlier .", "label": "", "metadata": {}, "score": "49.710075"}
{"text": "Table 4 is a sample Query Topic Example set 410 generated for the sample queries listed in Table 5 .Training processes for the query topic specific classifier are the same as training processes for document - domain - specific classifier described earlier .", "label": "", "metadata": {}, "score": "49.710075"}
{"text": "The purpose of simulated annealing is also to add a stochastic element , to make the heuristic more generally applicable .The stochastic element can prevent a search from getting trapped in a local minimum , a place that a particular heuristic would naturally evaluate to , based on its limited knowledge .", "label": "", "metadata": {}, "score": "49.72165"}
{"text": "Table IV shows average values for predictive accuracy with standard deviation .The best classification ac- curacies for each data set are highlighted in bold typeface .Analyzing the table , it is possible to realize that GBAP is competitive with respect to all the other algorithms considered , and also that it obtains the best results on 50 % of the data sets used in the experimentation .", "label": "", "metadata": {}, "score": "49.740074"}
{"text": "However , in some domains obtaining features may be resource - intensive because of which not all features may be available .An example is that of protein - protein interaction prediction , where not only are the labels ( ' interacting ' or ' non - interacting ' ) unavailable , but so are some of the features .", "label": "", "metadata": {}, "score": "49.74145"}
{"text": "The document clustering component 180 provides one final level of filtering accumulated documents against the user 's query .This ensures that users receive the optimal set of matching documents with minimal extraneous or irrelevant documents included .On occasion , the best - fit set of document matches for a particular query will contain an excessively large number of documents .", "label": "", "metadata": {}, "score": "49.810265"}
{"text": "The document clustering component 180 provides one final level of filtering accumulated documents against the user 's query .This ensures that users receive the optimal set of matching documents with minimal extraneous or irrelevant documents included .On occasion , the best - fit set of document matches for a particular query will contain an excessively large number of documents .", "label": "", "metadata": {}, "score": "49.810265"}
{"text": "If the decision is based on a signal strength from one place only , then the actual measurement of this has to be interpreted slightly more accurately and the neuron would need to do more .Although , more inputs to the neuron would also simply change this .", "label": "", "metadata": {}, "score": "49.831017"}
{"text": "Moreover , a combinationof these two heuristics can further increase performance .We compare our results with the results the creators of Otter obtained withthis renowned theorem prover and this way substantiate our achievements .Researchers initially have addressed the problem of spam detection as a text classification or categorization problem .", "label": "", "metadata": {}, "score": "49.868477"}
{"text": "16 is a flow diagram shows how to train a query topic specific classifier .A query topic example set is stored in the data repository 150 in step 850 .Next , distinct attributes and values are collected in step 855 .", "label": "", "metadata": {}, "score": "49.947372"}
{"text": "16 is a flow diagram shows how to train a query topic specific classifier .A query topic example set is stored in the data repository 150 in step 850 .Next , distinct attributes and values are collected in step 855 .", "label": "", "metadata": {}, "score": "49.947372"}
{"text": "Carrying out wet - lab experiments to determine all such missing features is infeasible as those experiments require human expertise , time , high - end equipment and other resources .It may however be possible to carry out a few experiments to determine some of the missing features , if not all .", "label": "", "metadata": {}, "score": "49.998497"}
{"text": "12 ) , serial configuration might be used before parallel configuration .People familiar with art would realize that there are many other possible configurations .Sub - Category Demographic Classification .A particular exemplary case of ethnicity category classification could be a four - class ethnicity classifier based on SVM classification .", "label": "", "metadata": {}, "score": "50.004063"}
{"text": "For e.g. , only Caucasian Female images are used for training , bootstrapping , and testing the Caucasian Female age classifier .Category Demographic Classification .In the current exemplary embodiment , only age , gender and ethnicity demographic categories were used .", "label": "", "metadata": {}, "score": "50.041607"}
{"text": "FIG .1 is a block diagram of the concept based search and retrieval system according to the present invention ; .FIG .2 is a block diagram of the query ontological parser according to the present invention ; .FIG .", "label": "", "metadata": {}, "score": "50.047874"}
{"text": "FIG .1 is a block diagram of the concept based search and retrieval system according to the present invention ; .FIG .2 is a block diagram of the query ontological parser according to the present invention ; .FIG .", "label": "", "metadata": {}, "score": "50.047874"}
{"text": "Machine Learning .View Article .Saar - Tsechansky M , Melville P , Provost F : Active feature - value acquisition .IROM-08 - 06 McCombs Research Paper Series .2009 , University of Texas at Austin .Druck G , Settles B , McCallum A : Active learning by labeling features .", "label": "", "metadata": {}, "score": "50.263554"}
{"text": "In the domain of Machine Learning , there exist some learning algorithms , which achieve interpretable results .One such algorithm is the Decision Tree family of learners .International Journal on Natural Language Computing ( IJNLC )Vol . 3 , No.3 , June 2014 133 A Decision Tree is defined as a finite tree structure where branches represent the tests , and the leaves denote the categories .", "label": "", "metadata": {}, "score": "50.265392"}
{"text": "In fact , it guarantees the closure property that must be fullfilled in any automatic programming system [ 10 ] , as any state and any feasible solution can only be reached from the initial state in a certain sequence of steps by applying the production rules available .", "label": "", "metadata": {}, "score": "50.296722"}
{"text": "Papers [ 12 , 13 ] discuss the difference between relevant and useful variables .In [ 12 ] they describe that at a conceptual level , one can divide the task of concept learning into two subtasks : deciding which features to use to describe the concept and deciding how to combine those features .", "label": "", "metadata": {}, "score": "50.297745"}
{"text": "Three classifiers namely , Maximum entropy , Na\u00efve Bayes classifiers and decision trees were used for classification .The advantage of decision tree technique was it required accessing only a subset of features for every testing image .The processing time at classification stage was reported to vary from 2.5 to 4.4 ms , based on the classifier being used .", "label": "", "metadata": {}, "score": "50.34307"}
{"text": "If several areas fire at the same time with parts related to the same problem , this would produce a stronger overall signal and could help to suggest what the correct interpretation is .This is especially useful if the search process is not particularly structured or constructive , that is without a clear search path , for example , when the duplication can help to confirm what the correct interpretation is .", "label": "", "metadata": {}, "score": "50.356026"}
{"text": "10.1002/pmic.200900259 .PubMed Central View Article PubMed .Melville P , Saar - Tsechansky M , Provost F , Mooney R : Active feature - value acquisition for classifier induction .Proceedings of the Fourth IEEE International Conference on Data Mining table of contents .", "label": "", "metadata": {}, "score": "50.435028"}
{"text": "As shown in step 502 , topic editor will classify each example document .If an example document belongs to the Finance domain , topic editor assigns value \" Yes \" to it ; if a example document irrelevant to the Finance domain , topic editor will assigns value \" No \" to it .", "label": "", "metadata": {}, "score": "50.477104"}
{"text": "As shown in step 502 , topic editor will classify each example document .If an example document belongs to the Finance domain , topic editor assigns value \" Yes \" to it ; if a example document irrelevant to the Finance domain , topic editor will assigns value \" No \" to it .", "label": "", "metadata": {}, "score": "50.477104"}
{"text": "A method for extracting demographic information using facial components comprising steps of ; . a ) detecting one or a plurality of face images from one or a plurality of input images , .b ) detecting facial components in the face images , .", "label": "", "metadata": {}, "score": "50.573826"}
{"text": "[ 12 ] P. Espejo , S. Ventura , and F. Herrera , \" A survey on the application of genetic programming to classification , \" Systems , Man , and Cybernetics , Part C : Applications and Reviews , IEEE Transactions on , vol .", "label": "", "metadata": {}, "score": "50.63183"}
{"text": "Bioinformatics .Navlakha S , Kingsford C : The power of protein interaction networks for associating genes with diseases .Bioinformatics .Mete M , Tang F , Xu X , Yuruk N : A structural approach for finding functional modules from large biological networks .", "label": "", "metadata": {}, "score": "50.64781"}
{"text": "1 , is a tool for probabilistically classifying documents and queries by the users .The Bayes classifier 130 is an implementation of the known na\u00efve Bayes classifier approach for classifying text , from which the system can build query - topic - specific and document - domain - specific classifiers .", "label": "", "metadata": {}, "score": "50.66499"}
{"text": "1 , is a tool for probabilistically classifying documents and queries by the users .The Bayes classifier 130 is an implementation of the known na\u00efve Bayes classifier approach for classifying text , from which the system can build query - topic - specific and document - domain - specific classifiers .", "label": "", "metadata": {}, "score": "50.66499"}
{"text": "[28 ] F. Otero , A. A. Freitas , and C. Johnson , \" cant - miner : An ant colony classification algorithm to cope with continuous attributes , \" LNCS , vol .5217 , pp .48 - 59 , 2008 .", "label": "", "metadata": {}, "score": "50.712208"}
{"text": "The default communication protocol inside of licas itself is an XML - RPC mechanism , but dynamic invocation of external Web Services is also possible .The main server package is now completely J2ME compatible , meaning that porting to a mobile device should be possible .", "label": "", "metadata": {}, "score": "50.745083"}
{"text": "Human faces provide us with a plethora of information that is valuable and necessary for social interaction .When we encounter a face , we can quickly and successfully decide whether it is one we know .For faces of people we know , we can easily retrieve semantic and identity information about the person .", "label": "", "metadata": {}, "score": "50.809013"}
{"text": "This type of classifier is very fast and very accurate in determining domain membership on a very large set of documents .The results of this training process are stored in the data repository 150 for use by the Bayes classifier 130 .", "label": "", "metadata": {}, "score": "50.861115"}
{"text": "This type of classifier is very fast and very accurate in determining domain membership on a very large set of documents .The results of this training process are stored in the data repository 150 for use by the Bayes classifier 130 .", "label": "", "metadata": {}, "score": "50.861115"}
{"text": "Full - text .In this paper an ant programming ( AP ) framework , capable of mining classification rules easily comprehensible by humans and , therefore , capable of supporting expert - domain decisions , is presented .The algorithm proposed , called GBAP ( Grammar Based Ant Programming ) , is the first AP algorithm developed for the extraction of classifica- tion rules , and it is guided by a context - free grammar that ensures the creation of new valid individuals .", "label": "", "metadata": {}, "score": "50.862526"}
{"text": "The alternative representation is matched against documents in a database similar to that of the systems described previously .However , the database does not contain a traditional inverted index , linking keywords to the documents that they appear in , but rather an annotated form of the same form as the query representation .", "label": "", "metadata": {}, "score": "50.87706"}
{"text": "The alternative representation is matched against documents in a database similar to that of the systems described previously .However , the database does not contain a traditional inverted index , linking keywords to the documents that they appear in , but rather an annotated form of the same form as the query representation .", "label": "", "metadata": {}, "score": "50.87706"}
{"text": "92 - 97 , 1995 , used Elastic Graph Matching on full face images to perform gender classification .They did not use components for classification purpose .Bebis et .al , \" Neural - Network - Based Gender Classification Using Genetic Search for Eigen - Feature Selection \" , IEEE World Congress on Computational Intelligence , 2002 , used Neural Networks , Genetic Algorithms and PCA to do gender classification .", "label": "", "metadata": {}, "score": "50.921402"}
{"text": "4 , pp .381 - 392 , 2007 .[56 ] D. H. Wolpert , \" The lack of a priori distinctions between learning algorithms , \" Neural Comput . , vol . 8 , no . 7 , pp .", "label": "", "metadata": {}, "score": "51.01351"}
{"text": "Once generalized predicates have been created by the query ontological parser 120 , a search for document predicates that match these generalized query predicates is performed .After all matches have been gathered , the links to documents pass through the same ranking and formatting components used in exact match mode .", "label": "", "metadata": {}, "score": "51.141445"}
{"text": "Once generalized predicates have been created by the query ontological parser 120 , a search for document predicates that match these generalized query predicates is performed .After all matches have been gathered , the links to documents pass through the same ranking and formatting components used in exact match mode .", "label": "", "metadata": {}, "score": "51.141445"}
{"text": "97 , no . 1 - 2 , pp .245 - 271 , 1997 .View at Google Scholar \u00b7 View at Scopus .J. J. Rocchio , \" Relevance feedback in information retrieval , \" in The SMART Retrieval System : Experiments in Automatic Document Processing , G. Salton , Ed . , pp .", "label": "", "metadata": {}, "score": "51.1698"}
{"text": "A predicate structure is a data type that includes a predicate and multiple additional concepts ; as a grouping of concepts , it is itself a concept .An ontology is a hierarchically organized complex data structure that provides a context for the lexical meaning of concepts .", "label": "", "metadata": {}, "score": "51.20799"}
{"text": "A predicate structure is a data type that includes a predicate and multiple additional concepts ; as a grouping of concepts , it is itself a concept .An ontology is a hierarchically organized complex data structure that provides a context for the lexical meaning of concepts .", "label": "", "metadata": {}, "score": "51.20799"}
{"text": "We investigate in how far interpolation mechanisms based on the nearest - neighbor rule ( NNR ) can support cancer research .The main objective is to usethe NNR to predict the likelihood of tumorigenesis based on given risk factors .By using a genetic algorithm to optimize the parameters of the nearest - neighbourprediction , the performance of this interpolation method can be improved sub - stantially .", "label": "", "metadata": {}, "score": "51.26082"}
{"text": "n . )P .No . i .n .P .w .i .No .In which w 1 , w 2 , . . ., w n are attributes represent the input document .Here are attributes defined at Table 2 .", "label": "", "metadata": {}, "score": "51.3235"}
{"text": "n . )P .No . i .n .P .w .i .No .In which w 1 , w 2 , . . ., w n are attributes represent the input document .Here are attributes defined at Table 2 .", "label": "", "metadata": {}, "score": "51.3235"}
{"text": "After being classified , the sentence then goes to the document ontological parser 140 , where it is transformed as discussed previously .Because of the length of the sentence , and the number of rules required to parse it successfully , the parse tree that would be generated from the example sentence is not shown .", "label": "", "metadata": {}, "score": "51.42091"}
{"text": "After being classified , the sentence then goes to the document ontological parser 140 , where it is transformed as discussed previously .Because of the length of the sentence , and the number of rules required to parse it successfully , the parse tree that would be generated from the example sentence is not shown .", "label": "", "metadata": {}, "score": "51.42091"}
{"text": "The states visited by each new ant are stored in the space of states .Then , the algorithm computes k fitness values per ant , k being the number of classes in the data set .Notice that at this point each ant encodes only the antecedent of a rule because the consequent has not been assigned yet .", "label": "", "metadata": {}, "score": "51.432953"}
{"text": "In this paper , an ant programming ( AP ) framework , which is capable of mining classification rules easily comprehensible by humans , and , therefore , capable of supporting expert - domain decisions , is presented .The algorithm proposed , called grammar based ant programming ( GBAP ) , is the first AP algorithm developed for the extraction of classification rules , and it is guided by a context - free grammar that ensures the creation of new valid individuals .", "label": "", "metadata": {}, "score": "51.464706"}
{"text": "A significant step of this method is the choice of similarity function between messages .The method frequently used to compute the similarity measure between messages is the \" cosine distance \" , where cosine is defined as the angle between the vectors representing the compared messages .", "label": "", "metadata": {}, "score": "51.545166"}
{"text": "Thus we often refer to the procedure as \" normal based feature selection \" .One speculates that since features with small . are not important for categorization they may also not be important for learning and , therefore , are good candidates for removal .", "label": "", "metadata": {}, "score": "51.55265"}
{"text": "In Section III , we describe the proposed algorithm .Section IV explains the experiments carried out , the data sets used and the algorithm set up .The results obtained are discussed in Section V. Finally , Section VI presents some concluding remarks .", "label": "", "metadata": {}, "score": "51.606796"}
{"text": "A heuristiclearned that way can then be profitably used to solve similar problems .Problems stemming from the study of logic calculi in connection with an infer - ence rule called \" condensed detachment \" are widely acknowledged as prominenttest sets for automated deduction systems and their search guiding heuristics .", "label": "", "metadata": {}, "score": "51.6402"}
{"text": "5 .First , the sentence receiver 310 obtains sentences consisting of ontological entities produced by the sentence lexer 122 .These sentences are parsed by the parser 124 , which is designed to use a context - free grammar , although other grammatical models may be used without departing from the scope and spirit of the invention .", "label": "", "metadata": {}, "score": "51.740185"}
{"text": "5 .First , the sentence receiver 310 obtains sentences consisting of ontological entities produced by the sentence lexer 122 .These sentences are parsed by the parser 124 , which is designed to use a context - free grammar , although other grammatical models may be used without departing from the scope and spirit of the invention .", "label": "", "metadata": {}, "score": "51.740185"}
{"text": "The feature matrix initially has missing values , the class label of each instance is already known .Missing features may be acquired with active feature acquisition procedure at a cost of Ci , j for feature Fi , j .qi , j refers to the query for value of Fi , j [ 16 ] .", "label": "", "metadata": {}, "score": "51.901665"}
{"text": "The unpredictability however means that it can be hit - and - miss .Their algorithm adopts a simulated annealing acceptance criterion to alleviate the shortcomings of hill - climbing or exhaustive search .Their algorithm also uses stochastic heuristic selection mechanisms instead of deterministic ones , which has been shown to be superior for some evolutionary optimisation problems [ 9 ] .", "label": "", "metadata": {}, "score": "51.914085"}
{"text": "The different modules can be arranged in parallel or in a hierarchical structure .For parallel structure the decision depends on combining the outputs of each module , usually given as continuous - valued scores .Modules when organized hierarchically use the simpler ones first .", "label": "", "metadata": {}, "score": "51.982925"}
{"text": "The positive ones are more likely to produce a positive evaluation and so are placed into a category of hill - climbing heuristics , to try to move directly to an optimal solution .The negative ones are placed into a category of mutational heuristics , which can then be changed to produce different ones .", "label": "", "metadata": {}, "score": "52.011093"}
{"text": "The authors combined this approach with particle swarm optimization , with AP responsible for evolving the architecture of flexible neural networks , and PSO responsible for optimiz- ing the parameters encoded in the neural tree .They applied developed flexible neural networks to a time - series prediction problem , showing the effectiveness of their algorithm .", "label": "", "metadata": {}, "score": "52.043472"}
{"text": "If any misclassification is found - either spam in the inbox or legitimate message in the quarantine - the errors may be reported to the filter to improve its performance .The filter may either work on the user 's system or on a server serving the same purpose for multiple users at a single time .", "label": "", "metadata": {}, "score": "52.052425"}
{"text": "In contrast , other expected utility - based methods for feature acquisition train a new classifier for each ' instance - feature - value ' triple .The results show that AFA achieves comparable F - score by acquiring only 40 % as much missing features as the random method .", "label": "", "metadata": {}, "score": "52.0545"}
{"text": "A beam - search algorithm is used to abandon target sentences as non - parallel early on during classification if they fall outside the beam .This way , our novel algorithm avoids any document - level prefiltering step .The algorithm increases the number of extracted parallel sentence pairs significantly , which leads to a BLEU improvement of about 1 % on our Spanish - English data . ... translation in the other sentence , otherwise it is labeled as non - parallel .", "label": "", "metadata": {}, "score": "52.17367"}
{"text": "A classifier training stage using the collected example data to train the classifier is shown in FIG .7 .The algorithm for training the Bayes Classifier is shown in FIG .8 .The learner component 132 sends a request to data repository 150 to get an example set 410 generated .", "label": "", "metadata": {}, "score": "52.17991"}
{"text": "A classifier training stage using the collected example data to train the classifier is shown in FIG .7 .The algorithm for training the Bayes Classifier is shown in FIG .8 .The learner component 132 sends a request to data repository 150 to get an example set 410 generated .", "label": "", "metadata": {}, "score": "52.17991"}
{"text": "The paper is structured as follows .The basics of spam message and spam filtering are mentioned in Section 2 .Section 3 emphasizes the prevalent spam filtering techniques .A comparison of existing image spam detection methods is focused in Section 4 .", "label": "", "metadata": {}, "score": "52.238113"}
{"text": "( 2007 ) [ 10 ] was to build a fast classifier [ 7 ] .In order to achieve this , the image processing operations which involved more time and effort was avoided .The proposed technique exploits a large set of features which are considered easy to compute : image metadata , and information like image height , width , aspect ratio , format extension ( e.g. , gif , jpg ) , and file size [ 7 ] .", "label": "", "metadata": {}, "score": "52.25925"}
{"text": "All collected words from an example document are treated as a set of attributes representing these example documents .All attributes are in lower case .A Finance Example set 410 is generated and stored into a data repository is in step 515 .", "label": "", "metadata": {}, "score": "52.335644"}
{"text": "All collected words from an example document are treated as a set of attributes representing these example documents .All attributes are in lower case .A Finance Example set 410 is generated and stored into a data repository is in step 515 .", "label": "", "metadata": {}, "score": "52.335644"}
{"text": "This vector is fed into a simple , two - layer self - organizing feature map , with small , randomly assigned adaptive weights allocated to each node in the feature map , and to each input connection from the input vectors to each node .", "label": "", "metadata": {}, "score": "52.358246"}
{"text": "This vector is fed into a simple , two - layer self - organizing feature map , with small , randomly assigned adaptive weights allocated to each node in the feature map , and to each input connection from the input vectors to each node .", "label": "", "metadata": {}, "score": "52.358246"}
{"text": "( Application ) 60/421,717 to Sharma describe another method for automatic age category classification based on Support Vector Machines ( SVM ) where they use full - face image for classification .Their system is not based on facial components for classification purposes .", "label": "", "metadata": {}, "score": "52.365532"}
{"text": "f .i .V . k . )A .F . )C .f .i . ) A(F ) is the accuracy of the original classifier .C(f i ) is the cost of acquiring the feature value .", "label": "", "metadata": {}, "score": "52.393127"}
{"text": "A method of performing concept - based searching of text documents as recited in .claim 1 , wherein said argument is a noun .A method of performing a concept - based searching of text documents comprising the steps of : . transforming a natural language query into predicate structures representing logical relationships between words in said natural language query ; . providing an ontology containing lexical semantic information about words ; . transforming said text documents into predicate structures ; . probabilistically classifying said document predicate structures and said query predicate structures ; . filtering said document predicate structures against said query predicate structures to produce a set of said document predicate structures matching said query predicate structures ; and . ranking said set of matching predicate structures .", "label": "", "metadata": {}, "score": "52.39524"}
{"text": "A method of performing concept - based searching of text documents as recited in .claim 1 , wherein said argument is a noun .A method of performing a concept - based searching of text documents comprising the steps of : . transforming a natural language query into predicate structures representing logical relationships between words in said natural language query ; . providing an ontology containing lexical semantic information about words ; . transforming said text documents into predicate structures ; . probabilistically classifying said document predicate structures and said query predicate structures ; . filtering said document predicate structures against said query predicate structures to produce a set of said document predicate structures matching said query predicate structures ; and . ranking said set of matching predicate structures .", "label": "", "metadata": {}, "score": "52.39524"}
{"text": "Therefore , \u0394\u03c1 is set to 0 for that case .Dataset and feature descriptors .In the domain of PPI prediction , there is no \" negative dataset \" available ; that is , there are no pairs that are known to be non - interacting .", "label": "", "metadata": {}, "score": "52.3974"}
{"text": "The authors declare that they have no competing interests .Authors ' contributions .MT proposed the heuristic for calculating the utility of acquiring a missing feature and carried out the bulk of the experiments with direction and supervision from MG .", "label": "", "metadata": {}, "score": "52.404396"}
{"text": "Ontological parsing is a grammatical analysis technique built on the proposition that the most useful information , which can be extracted from a sentence , is the set of concepts within it , as well as their formal relations to each other .", "label": "", "metadata": {}, "score": "52.45909"}
{"text": "Ontological parsing is a grammatical analysis technique built on the proposition that the most useful information , which can be extracted from a sentence , is the set of concepts within it , as well as their formal relations to each other .", "label": "", "metadata": {}, "score": "52.45909"}
{"text": "Retrieval is initiated by a user query submitted through the user interface 110 .Queries may come from any HTTP - compliant source , generally a web page .The user 's query is submitted in the form of a natural - language question .", "label": "", "metadata": {}, "score": "52.46187"}
{"text": "Retrieval is initiated by a user query submitted through the user interface 110 .Queries may come from any HTTP - compliant source , generally a web page .The user 's query is submitted in the form of a natural - language question .", "label": "", "metadata": {}, "score": "52.46187"}
{"text": "For the current problem only solution evaluations are matched , where to match any two solutions the algorithm must remove any rows that are in - between the two to be matched .The algorithm therefore also removes solutions as well as trying to keep other ones .", "label": "", "metadata": {}, "score": "52.587326"}
{"text": "P .c .j . )P .D . ) where c j is a possible class in the set of all possible classes C , D is the document to be classified , P ( c j D ) is the probability that document D belongs to class c j .", "label": "", "metadata": {}, "score": "52.66333"}
{"text": "P .c .j . )P .D . ) where c j is a possible class in the set of all possible classes C , D is the document to be classified , P ( c j D ) is the probability that document D belongs to class c j .", "label": "", "metadata": {}, "score": "52.66333"}
{"text": "Essentially , this necessi - tates the automation of the crucial step in the use of a deduction system , namelychoosing and configuring an appropriate search - guiding heuristic .Our experiments with a fully automated deductionsystem ' AutoCoDe ' have produced remarkable results .", "label": "", "metadata": {}, "score": "52.677914"}
{"text": "( Application ) US 20030110038A1 granted to Sharma et .al , describes a method for Multi - Modal Gender classification .Their method is based on performing gender classification using acoustic signals and face images of the user using statistical classification algorithms .", "label": "", "metadata": {}, "score": "52.73054"}
{"text": "Goldstein J , Mittal V , Carbonell J : Creating and evaluating multi - document sentence extract summaries .CIKM'00 : Ninth International Conference on Information Knowledge Management : 2000 .View Article .Madani O , Lizotte DJ , Greiner R : Budgeted learning of naive bayes classifiers .", "label": "", "metadata": {}, "score": "52.784313"}
{"text": "Any ontology 128 may be used , as may any part - of - speech tagging algorithm .Multiple sequences of ontological concepts may be produced by the sentence lexer 122 .Consequently , post - lexer 122 filters 123 are employed to prune out some of the sequences based on rules about sequences of syntactic tags .", "label": "", "metadata": {}, "score": "52.79187"}
{"text": "Any ontology 128 may be used , as may any part - of - speech tagging algorithm .Multiple sequences of ontological concepts may be produced by the sentence lexer 122 .Consequently , post - lexer 122 filters 123 are employed to prune out some of the sequences based on rules about sequences of syntactic tags .", "label": "", "metadata": {}, "score": "52.79187"}
{"text": "Unsupervised tasks include approaches that explore the data to find some intrinsic structures in them , so these tasks have a descriptive nature [ 3].\" [ Show abstract ] [ Hide abstract ] ABSTRACT : This paper proposes a novel grammar - guided genetic programming algorithm for subgroup discovery .", "label": "", "metadata": {}, "score": "52.936455"}
{"text": "Define set variables A and C ; set .Step 605 includes a process to calculate value probability P(\"Yes \" ) and value probability P(\"No \" ) .P(\"Yes \" ) represents the percentage of documents relevant to Finance domain that exist in the Finance Example Set , and P(\"No \" ) represents the percentage of documents irrelevant to the Finance that exist in the Finance Example Set .", "label": "", "metadata": {}, "score": "52.93843"}
{"text": "Define set variables A and C ; set .Step 605 includes a process to calculate value probability P(\"Yes \" ) and value probability P(\"No \" ) .P(\"Yes \" ) represents the percentage of documents relevant to Finance domain that exist in the Finance Example Set , and P(\"No \" ) represents the percentage of documents irrelevant to the Finance that exist in the Finance Example Set .", "label": "", "metadata": {}, "score": "52.93843"}
{"text": "Page 9 .These data sets are listed in Table II , where their particular characteristics are also described .Due to the fact that the data sets considered contained numerical attributes and missing values , two preprocessing actions were performed using Weka2 .", "label": "", "metadata": {}, "score": "53.049225"}
{"text": "It is a hybrid algorithm because it uses ACO to deal with nominal attributes and PSO to deal with numerical ones .There are different proposals using AP in the literature , which we now review , although their application is limited to problems such as symbolic regression , and no applications of AP to classification have been published so far .", "label": "", "metadata": {}, "score": "53.179268"}
{"text": "No .5,781,650 to De Lobo describes an automatic feature detection and age classification method for human face in images .Their automatic age categorization system is based on finding a face in an image and locating the facial features .Using these facial features , distances between them and by performing wrinkle analysis of the skin they categorize the age of the human face in the image .", "label": "", "metadata": {}, "score": "53.316727"}
{"text": "U.S. Pat .No .6,421,463 granted to Poggio et .al , describes a method for detecting human in an image using components .In their method is based on detecting the different human body components using wavelets in an image and classifying these components .", "label": "", "metadata": {}, "score": "53.414116"}
{"text": "Comparing the results achieved by [ Dredze et al .( 2007 ) , Fumera et al ( 2006)][10,12 ] the system was reported as recording an improvement above 6 % .Experiments performed on the Personal spam dataset , comparable results were achieved as [ Dredze et al .", "label": "", "metadata": {}, "score": "53.51378"}
{"text": "Experimental setup .The Gene Expression and Gene Neighborhood features in PPI prediction feature vectors have nearly 100 % coverage , and therefore do not depend on active feature acquisition .The Gene Ontology features ( biological process , cellular component and molecular function ) , domain and tissue features have a large number of missing values .", "label": "", "metadata": {}, "score": "53.517517"}
{"text": "The hyperheuristic framework is more likely to use genetic programming principles to mutate existing solutions to generate better ones .Hyperheuristics Related to the New Problem Solver Heuristic .This section looks at specific examples of heuristics that are directly related to the new hyperheuristic that is the core evaluator in the problem solver .", "label": "", "metadata": {}, "score": "53.563805"}
{"text": "13 is a flow diagram shows a Finance - domain - specific classifier 's training process .As shown in step 600 , Finance Example Set , which contains attributes and values of example documents , are retrieved from data repository .", "label": "", "metadata": {}, "score": "53.585537"}
{"text": "13 is a flow diagram shows a Finance - domain - specific classifier 's training process .As shown in step 600 , Finance Example Set , which contains attributes and values of example documents , are retrieved from data repository .", "label": "", "metadata": {}, "score": "53.585537"}
{"text": "Boryczka also presented extensions to these works with the aim of improving the evaluation performance .In [ 38 ] , the author improved the effectiveness and achieved more simplified solutions by eliminating introns , while in [ 39 ] the computational time necessary for the evaluation of transition rules was reduced .", "label": "", "metadata": {}, "score": "53.633965"}
{"text": "Table 3 contains all attributes collected from input document after those processes .The Finance Training Set , which represent the knowledge of this classifier , is retrieved from the data repository 150 in step 710 .P .Yes .D . )", "label": "", "metadata": {}, "score": "53.642075"}
{"text": "Table 3 contains all attributes collected from input document after those processes .The Finance Training Set , which represent the knowledge of this classifier , is retrieved from the data repository 150 in step 710 .P .Yes .D . )", "label": "", "metadata": {}, "score": "53.642075"}
{"text": "9 shows a detailed view Serial Configuration of classifiers for component information .It is used for Sub - Category Demographic Classification ( for e.g. , two or more sub - categories of Ethnicity ) .FIG .10 shows a detailed view of Parallel Configuration of classifiers for component information .", "label": "", "metadata": {}, "score": "53.69407"}
{"text": "EXPERIMENTATION In this section we will first present the data sets used in the experimental study , along with the preprocessing actions performed .Then , we explain the cross validation procedure employed .Finally , the parameter set - up for the different algo- rithms considered in the comparison is presented . A. Data Sets and Preprocessing The performance of GBAP was tested on 18 publicly available data sets , both artificial and real - world , selected from the machine learning repository of the University of California at Irvine ( UCI ) [ 52]1 .", "label": "", "metadata": {}, "score": "53.712234"}
{"text": "Feature extraction is a very important part of the classification system .Many different methods such as Principal Component Analysis ( PCA ) , Independent Component Analysis ( ICA ) , Non - Negative Matrix Factorization ( LNMF ) etc . could be used depending on which kind of classification paradigm is being used .", "label": "", "metadata": {}, "score": "53.71997"}
{"text": "Suppose the system is to use the Bayes classifier 130 to create a Finance - domain - specific classifier that can identify whether or not a given document belongs to Finance domain .The construction of Finance - domain - specific classifier includes two stages : example collection stage and classifier training stage .", "label": "", "metadata": {}, "score": "53.750526"}
{"text": "Suppose the system is to use the Bayes classifier 130 to create a Finance - domain - specific classifier that can identify whether or not a given document belongs to Finance domain .The construction of Finance - domain - specific classifier includes two stages : example collection stage and classifier training stage .", "label": "", "metadata": {}, "score": "53.750526"}
{"text": "They consist of several modules which analyze different characteristics of input emails , like address of the sender and the recipient , textual content , header format and mail attachments .The output of each module is combined to label an email as spam or legitimate .", "label": "", "metadata": {}, "score": "53.913963"}
{"text": "Any or all of the component information 203 , 204 , and 205 is used for used for classification purposes .The current embodiment uses , the PCA image of the components , its location and size , and distance between and from facial components for classification .", "label": "", "metadata": {}, "score": "53.939644"}
{"text": "The results show that our heuristic method for AFA creates an optimal training set with far less features acquired as compared to random acquisition .This shows the value of active feature acquisition to aid in protein - protein interaction prediction where feature acquisition is costly .", "label": "", "metadata": {}, "score": "54.07726"}
{"text": "Page 3 .In contrast , Ant - Miner+ , proposed by Martens et al .[ 27 ] , demonstrated superior accuracy results than the previous Ant - Miner versions .This algorithm defines the environment as a directed acyclic graph , which allows the selection of better transitions and the inclusion of interval rules .", "label": "", "metadata": {}, "score": "54.079086"}
{"text": "Given a protein pair , Gene Ontology ( GO ) information is usually encoded by measuring the semantic similarity between the GO terms of the proteins in the pair .But it is possible that a pair of GO terms ( function , processes or cellular component ) share low semantic similarity but they could be crucial for interaction between a protein pair .", "label": "", "metadata": {}, "score": "54.251137"}
{"text": "Since all classifiers are com- pared with respect to a control classifier , we can apply the Bonferroni - Dunn test [ 58 ] focusing on all possible pairwise comparisons involving the GBAP algorithm .Thus , the performance of GBAP is statistically better than those of the PSO / ACO2 , Ant - Miner+ , Ant - Miner .", "label": "", "metadata": {}, "score": "54.380276"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 20 , wherein said predicate structures for each of said documents forms at least one concept pattern vector for each of said documents .", "label": "", "metadata": {}, "score": "54.39165"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 20 , wherein said predicate structures for each of said documents forms at least one concept pattern vector for each of said documents .", "label": "", "metadata": {}, "score": "54.39165"}
{"text": "They did not apply their system or method for demographic classification .Moreover , their invention is based on wavelets transforms for classification .Furthermore , Poggio 's patent does not use or does not clarify the classifier fusion mechanism .US Pat No .", "label": "", "metadata": {}, "score": "54.394867"}
{"text": "( Application ) 60/436,933 to Sharma et .al , describes method for classifying human faces images according to ethnicity using SVM .Their system is based on full - face images and does not use facial components for ethnicity classification .", "label": "", "metadata": {}, "score": "54.442936"}
{"text": "F - score for Active Feature Acquisition .X - axis shows the number of missing features acquired .Y - axis shows the F - score for the classifier built at the corresponding number of missing features acquired .While the above comparison shows that the heuristic method is creating a training data effectively compared to random selection , it would be interesting to see whether this method performs comparably to computationally intensive AFA methods .", "label": "", "metadata": {}, "score": "54.465828"}
{"text": "The second approach explicitly models correlations by pairwise label interactions .However , the complexity remains exponential unless one assumes that label correlations are sparse .Furthermore , the learnt correlations reflect the training set biases .We take a middle approach that assumes labels are correlated but does not incorporate pairwise label terms in the prediction function .", "label": "", "metadata": {}, "score": "54.479393"}
{"text": "When that happens , the end user may optionally leave an e - mail address with the system .When new documents that match the query are located , the end user is notified via E - mail .This mode permits retraining the Bayes classifier 130 with better documents , or processing more documents with the query ontological parser 120 to produce a better data repository 150 .", "label": "", "metadata": {}, "score": "54.502167"}
{"text": "When that happens , the end user may optionally leave an e - mail address with the system .When new documents that match the query are located , the end user is notified via E - mail .This mode permits retraining the Bayes classifier 130 with better documents , or processing more documents with the query ontological parser 120 to produce a better data repository 150 .", "label": "", "metadata": {}, "score": "54.502167"}
{"text": "We would also thank the authors of Ant - Miner+ for kindly providing the source code of their algorithm .REFERENCES [ 1 ] J. Han and M. Kamber , Data Mining : Concepts and Techniques .Morgan Kauffman , 2006 .", "label": "", "metadata": {}, "score": "54.518105"}
{"text": "When a message is received it is sent to the spam filter .It is checked if the email contains any embedded image .The filter initially segments the image and extracts the text embedded in the image .Wu et al .", "label": "", "metadata": {}, "score": "54.554893"}
{"text": "The elimination of stop words will reduce the example set 410 size and save data repository space .For a query - topic - specific classifier the system will predefine a set of topics that the query will fill in , such as \" art \" , \" business \" , \" finance \" , \" health \" , \" science \" .", "label": "", "metadata": {}, "score": "54.659203"}
{"text": "The elimination of stop words will reduce the example set 410 size and save data repository space .For a query - topic - specific classifier the system will predefine a set of topics that the query will fill in , such as \" art \" , \" business \" , \" finance \" , \" health \" , \" science \" .", "label": "", "metadata": {}, "score": "54.659203"}
{"text": "Table VI shows all the possible hypotheses of comparison between the control algorithm and the others , ordered by their p value and associated with their level of significance \u03b1 .To contrast the results obtained by the Bonferroni - Dunn method , we applied the Holm test , which rejects those hypotheses that have a p value less or equal to 0.025 .", "label": "", "metadata": {}, "score": "54.68521"}
{"text": "These patents cover techniques for creating full - text databases of content , usually world - wide - web pages , and providing functionality to retrieve documents based on desired keywords .Full - text databases of documents are generally used to serve keyword - based search engines , where the user is presented with an interface such as a web page , and can submit query words to the search engine .", "label": "", "metadata": {}, "score": "54.721397"}
{"text": "These patents cover techniques for creating full - text databases of content , usually world - wide - web pages , and providing functionality to retrieve documents based on desired keywords .Full - text databases of documents are generally used to serve keyword - based search engines , where the user is presented with an interface such as a web page , and can submit query words to the search engine .", "label": "", "metadata": {}, "score": "54.721397"}
{"text": "Springer , .Page 15 .[42 ] N. Hoai and R. McKay , \" A framework for tree adjunct grammar guided genetic programming , \" in Proceedings of the Post - Graduate ADFA Conference on Computer Science ( PACCS'01 ) , 2001 , pp .", "label": "", "metadata": {}, "score": "54.7601"}
{"text": "FIG .4 is a block diagram of the sentence lexer according to one variation of the present invention ; .FIG .5 is a block diagram of the parser according to one variation of the present invention ; .FIG .", "label": "", "metadata": {}, "score": "54.771408"}
{"text": "FIG .4 is a block diagram of the sentence lexer according to one variation of the present invention ; .FIG .5 is a block diagram of the parser according to one variation of the present invention ; .FIG .", "label": "", "metadata": {}, "score": "54.771408"}
{"text": "2009 , 37 : D898 - 901 .10.1093/nar / gkn786 .PubMed Central View Article PubMed .Ng SK , Zhang Z , Tan SH , Lin K : Interdom : a database of putative interacting protein domains for validating predicted protein interactions and complexes .", "label": "", "metadata": {}, "score": "54.780132"}
{"text": "Concerning the design of any ant inspired algorithm , it is necessary to specify an environment where ants cooperate with each other .In GBAP , this environment is the search space comprising all possible expressions or programs that can be derived from the grammar in the number of derivations avail- able .", "label": "", "metadata": {}, "score": "54.831493"}
{"text": "The latter case has not been considered before and we show how the HMC and HSC approaches can be modified to support this setting .We compare the three approaches on 24 yeast data sets using as classification schemes MIPS 's FunCat ( tree structure ) and the Gene Ontology ( DAG structure ) .", "label": "", "metadata": {}, "score": "54.873455"}
{"text": "We use a synchronous context free grammar ( SCFG ) translation system ( Chiang , 2007 ) , a model which has y .. by Matthias B\u00fcchse , Jonathan May , Heiko Vogler - PRESENTATION AT 8TH INT .WORKSHOP FINITE - STATE METHODS AND NATURAL LANGUAGE PROCESSING , 2009 . \" ...", "label": "", "metadata": {}, "score": "54.874657"}
{"text": "784 - 787 , Dublin , Ireland , August 2009 .J. G. Mar\u00edn - Bl\u00e1zquez and S. Schulenburg , \" Multi - step environment learning classifier systems applied to hyper - heuristics , \" in Proceedings of the 8th Annual Genetic and Evolutionary Computation Conference , pp .", "label": "", "metadata": {}, "score": "54.897068"}
{"text": "Not all of these words or phrases would be included in the ontology 128 , and so the sentence lexer 122 would not be able to place them all in ontological context .However , the linguistic rules encoded in both the lexing and parsing stages still enable The concept based search and retrieval system 100 to recognize noun phrases such as \" Clinton administration \" and \" financial - services industry \" .", "label": "", "metadata": {}, "score": "54.931084"}
{"text": "Not all of these words or phrases would be included in the ontology 128 , and so the sentence lexer 122 would not be able to place them all in ontological context .However , the linguistic rules encoded in both the lexing and parsing stages still enable The concept based search and retrieval system 100 to recognize noun phrases such as \" Clinton administration \" and \" financial - services industry \" .", "label": "", "metadata": {}, "score": "54.931084"}
{"text": "FIG .15 is a flow diagram showing how to generate Query Topic Example set 410 .Topic editors create a set of example queries in step 800 , such as : .The topic editor assigns a value to each query based on his ( her ) own knowledge in step 805 .", "label": "", "metadata": {}, "score": "55.044685"}
{"text": "FIG .15 is a flow diagram showing how to generate Query Topic Example set 410 .Topic editors create a set of example queries in step 800 , such as : .The topic editor assigns a value to each query based on his ( her ) own knowledge in step 805 .", "label": "", "metadata": {}, "score": "55.044685"}
{"text": "5,974,455 .Various schemes have been proposed for ranking the results of such a search .For example , U.S. Pat .No .5,915,249 to Spencer sets forth a system and method for accelerated query evaluation of very large full text databases , and U.S. Pat .", "label": "", "metadata": {}, "score": "55.07133"}
{"text": "5,974,455 .Various schemes have been proposed for ranking the results of such a search .For example , U.S. Pat .No .5,915,249 to Spencer sets forth a system and method for accelerated query evaluation of very large full text databases , and U.S. Pat .", "label": "", "metadata": {}, "score": "55.07133"}
{"text": "Among them , we appreciate the hybrid particle swarm opti- mization ( PSO ) - ACO algorithm , PSO / ACO2 , developed by Holden et al .[ 33 ] , for the discovery of classification rules .PSO is another optimization technique positioned among SI , inspired by the social behavior of birds in flocks or fish in schools .", "label": "", "metadata": {}, "score": "55.149643"}
{"text": "It involves in embedding the spam message into images which are sent as email attachments .The aim is to surpass the spam filters whose analysis is based on only the emails ' textual content .Such spam emails may get misclassified by the filtering program , but the hidden message becomes visible to the recipients when opened by them .", "label": "", "metadata": {}, "score": "55.186043"}
{"text": "This can be observed in the behavior of the GP algorithm , because it nearly extracts one rule per class and , therefore , it obtains the best results in this respect .In addition , this number of rules may not be enough for obtaining accurate results in many data sets , as it can be deduced looking at the accuracy results obtained by GP algorithm in Section V - A. In contrast , by using the niching algorithm described in Section III - F , GBAP ensures the selection of the number of rules that are necessary to cover the examples of each class , also achieving very good classification results .", "label": "", "metadata": {}, "score": "55.197304"}
{"text": "In step 910 , the classifier accesses the query topic training set stored in the data repository 150 .The answer probability is calculated for each possible answer value , in step 920 .The query topic specific classifier returns a list of topic ranked in order of probability of correctness instead of a single \" TRUE \" or \" FALSE \" answer in step 925 .", "label": "", "metadata": {}, "score": "55.307816"}
{"text": "In step 910 , the classifier accesses the query topic training set stored in the data repository 150 .The answer probability is calculated for each possible answer value , in step 920 .The query topic specific classifier returns a list of topic ranked in order of probability of correctness instead of a single \" TRUE \" or \" FALSE \" answer in step 925 .", "label": "", "metadata": {}, "score": "55.307816"}
{"text": "The system will analyze the image content and classify the embedded image as spam or legitimate hence classify the email accordingly .International Journal on Natural Language Computing ( IJNLC ) Vol .However , as spammers ' continue to develop new techniques and the type of email content becomes more disparate , text - based anti - spam approaches alone are not sufficiently enough in preventing spam .", "label": "", "metadata": {}, "score": "55.32173"}
{"text": "Attribute extractor 400 extracts direct attributes \" current \" , \" situation \" , \" stock \" , and \" market \" from this query .It also can expand attribute \" stock \" to \" finance \" , \" banks \" , \" brokerages \" \" Wall Street , \" etc . by implementing a concept ontology that contains hierarchical concepts .", "label": "", "metadata": {}, "score": "55.33869"}
{"text": "Attribute extractor 400 extracts direct attributes \" current \" , \" situation \" , \" stock \" , and \" market \" from this query .It also can expand attribute \" stock \" to \" finance \" , \" banks \" , \" brokerages \" \" Wall Street , \" etc . by implementing a concept ontology that contains hierarchical concepts .", "label": "", "metadata": {}, "score": "55.33869"}
{"text": "In the second mode , the trained classifier 130 accepts a query and calculates the probability that the query belongs to the topic the classifier 130 is trained on .The resulting probabilities in either case determine the response from the reasoner 134 .", "label": "", "metadata": {}, "score": "55.339355"}
{"text": "In the second mode , the trained classifier 130 accepts a query and calculates the probability that the query belongs to the topic the classifier 130 is trained on .The resulting probabilities in either case determine the response from the reasoner 134 .", "label": "", "metadata": {}, "score": "55.339355"}
{"text": "It removes concepts from queries , which are not likely to be the actual concept the user intends .Pseudo - concepts are largely nouns , and can be captured by a stop word list .Pseudo - concepts include \" I \" , \" me \" , \" you \" , and in certain syntactic usages , \" information \" , \" news \" , and related words .", "label": "", "metadata": {}, "score": "55.355495"}
{"text": "It removes concepts from queries , which are not likely to be the actual concept the user intends .Pseudo - concepts are largely nouns , and can be captured by a stop word list .Pseudo - concepts include \" I \" , \" me \" , \" you \" , and in certain syntactic usages , \" information \" , \" news \" , and related words .", "label": "", "metadata": {}, "score": "55.355495"}
{"text": "Gene Expression features for PPI prediction problem are usually generated from a limited set of gene expression experiments .Qi et al .use 16 gene expression experiments [ 11 ] .However , in our work we use the several thousand gene expression experiments available in the Stanford Microarray Database ( SMD ) to compute this feature [ 22 ] .", "label": "", "metadata": {}, "score": "55.48069"}
{"text": "The system includes a chaos processor that receives the input discourse , and generates the grammatical structured output .Such grammatical structured output includes identifying the various parts of speech , and ascertaining how the words , clauses , and phrases in a sentence relate to one another .", "label": "", "metadata": {}, "score": "55.48816"}
{"text": "The system includes a chaos processor that receives the input discourse , and generates the grammatical structured output .Such grammatical structured output includes identifying the various parts of speech , and ascertaining how the words , clauses , and phrases in a sentence relate to one another .", "label": "", "metadata": {}, "score": "55.48816"}
{"text": "Determining PPIs by high - resolution experimental methods is very resource intensive .Computational methods are therefore necessary to complement the high - throughput methods to reconstruct the interactome expeditiously .Several computational systems have been developed for prediction of protein - protein interactions , particularly for yeast and human , using machine learning approaches [ 10 - 14 ] .", "label": "", "metadata": {}, "score": "55.522617"}
{"text": "The system engineering interface 112 of the user interface 110 allows engineers the ability to maintain , monitor and control system operations .There are two methods of monitoring of the system .The first method uses a graphical user interface ( GUI ) that displays current tasks in progress , user logs , and other types of statistical information .", "label": "", "metadata": {}, "score": "55.5779"}
{"text": "The system engineering interface 112 of the user interface 110 allows engineers the ability to maintain , monitor and control system operations .There are two methods of monitoring of the system .The first method uses a graphical user interface ( GUI ) that displays current tasks in progress , user logs , and other types of statistical information .", "label": "", "metadata": {}, "score": "55.5779"}
{"text": "It calculates the integral image rather than classifying on each component and the result is integrated over time .Furthermore , their system is based on wavelets to identify components .Moghaddam et . al . in \" Gender Classification with Support Vector Machines \" , IEEE International Conference on Automatic and Gesture Recognition , pp .", "label": "", "metadata": {}, "score": "55.58938"}
{"text": "The document predicate match mode is nearly identical to exact match mode , with only one difference .In this mode the query ontological parser 120 is allowed to create generalized predicates , based on the user 's original query .This entails the substitution of synonymous words for all concepts in the user 's query .", "label": "", "metadata": {}, "score": "55.61259"}
{"text": "The document predicate match mode is nearly identical to exact match mode , with only one difference .In this mode the query ontological parser 120 is allowed to create generalized predicates , based on the user 's original query .This entails the substitution of synonymous words for all concepts in the user 's query .", "label": "", "metadata": {}, "score": "55.61259"}
{"text": "Self - organizing feature maps are well - understood and computationally tractable systems for providing statistical and probabilistic modeling of large , complex sets of data with minimal computational overhead .In contrast to other probability distribution mapping techniques , the self - organizing feature map processes only a single input pattern at a time , with no need to retain large data sets in memory for global processing across the entire collection of data .", "label": "", "metadata": {}, "score": "55.617065"}
{"text": "Self - organizing feature maps are well - understood and computationally tractable systems for providing statistical and probabilistic modeling of large , complex sets of data with minimal computational overhead .In contrast to other probability distribution mapping techniques , the self - organizing feature map processes only a single input pattern at a time , with no need to retain large data sets in memory for global processing across the entire collection of data .", "label": "", "metadata": {}, "score": "55.617065"}
{"text": "The test data , while random , is not from a real application .So while this might not be able to prove a better approach , it shows that the process is constructive and is doing something intelligent .It is unsupervised and therefore all of the evaluations are taken from the information that is presented at the time .", "label": "", "metadata": {}, "score": "55.627426"}
{"text": "27 - 48 , 2004 .[ 55 ] S. Ventura , C. Romero , A. Zafra , J. A. Delgado , and C. Herv \u00b4 as , \" JCLEC : a java framework for evolutionary computation , \" Soft Comput . , vol .", "label": "", "metadata": {}, "score": "55.72367"}
{"text": "Then the feature value for a protein pair ( P1,P2 ) is proportional to , .G .O .S .e . t .G .O .S .e . t .n .G .O .", "label": "", "metadata": {}, "score": "55.74916"}
{"text": "In current embodiment , the gender classifiers are cascaded after ethnicity , with different gender classifier for each ethnicity .So , in the current implementation , there are four different two - class gender classifiers .The gender classifier is selected on the basis of the ethnicity classifier .", "label": "", "metadata": {}, "score": "55.770485"}
{"text": "Further we may be constrained by the amount of budget we can spend to learn the classifier .However performing a complete look - ahead has exponential time complexity .So highly simplified look - ahead procedures such as single feature look - ahead ( SFL ) [ 30 ] and randomized single feature look - ahead ( RSFL ) [ 31 ] have been proposed .", "label": "", "metadata": {}, "score": "55.774063"}
{"text": "Page 7 .IEEE TRANSACTIONS ON SYSTEMS , MAN , AND CYBERNETICS - PART B : CYBERNETICS7 the grammar .This cardinality table will contain as many entries as the maximum number of derivations available , where each entry maps the number of derivations to the number of solutions that can be reached .", "label": "", "metadata": {}, "score": "55.86006"}
{"text": "A method of performing concept - based searching of text documents as recited in .A method of performing concept - based searching of text documents as recited in . claim 5 , further comprising the step of clustering results of said search , said clustering step comprising the following steps of : . forming a concept pattern vector from said document predicate structures ; . providing a feature map that self - adaptively clusters said concept pattern vectors according to said concept patterns in said documents ; . producing a cluster model representing documents , identified in said concept - based searching , that reflects statistical distribution of said concept pattern vectors representing said documents ; and . providing at least one sample from said cluster model to focus search results .", "label": "", "metadata": {}, "score": "55.876152"}
{"text": "A method of performing concept - based searching of text documents as recited in .A method of performing concept - based searching of text documents as recited in . claim 5 , further comprising the step of clustering results of said search , said clustering step comprising the following steps of : . forming a concept pattern vector from said document predicate structures ; . providing a feature map that self - adaptively clusters said concept pattern vectors according to said concept patterns in said documents ; . producing a cluster model representing documents , identified in said concept - based searching , that reflects statistical distribution of said concept pattern vectors representing said documents ; and . providing at least one sample from said cluster model to focus search results .", "label": "", "metadata": {}, "score": "55.876152"}
{"text": "Suppose the system has defined a Topic Set containing finance , science , and business as three topics .The system uses the Bayes classifier 130 to construct a query topic specific classifier that can identify whether an input query belongs to one of these topics .", "label": "", "metadata": {}, "score": "55.895527"}
{"text": "Suppose the system has defined a Topic Set containing finance , science , and business as three topics .The system uses the Bayes classifier 130 to construct a query topic specific classifier that can identify whether an input query belongs to one of these topics .", "label": "", "metadata": {}, "score": "55.895527"}
{"text": "Index Terms - ant programming ( AP ) , grammar - based auto- matic programming , ant colony optimization ( ACO ) , classifica- tion , data mining ( DM ) I. INTRODUCTION D trivial and useful knowledge from data .The discovered knowl- edge should have good generalization performance , i.e. , it should accurately predict the values of some attributes or features of data that were not used during the run of the DM algorithm .", "label": "", "metadata": {}, "score": "55.91224"}
{"text": "The initial deterministic rule to be used in implementing pseudo - concept filter is that it should remove any instance of these verbs not preceded by a content - bearing noun ( i.e. , one not appearing in the list of pseudo - concepts or stop words ) .", "label": "", "metadata": {}, "score": "55.93015"}
{"text": "The initial deterministic rule to be used in implementing pseudo - concept filter is that it should remove any instance of these verbs not preceded by a content - bearing noun ( i.e. , one not appearing in the list of pseudo - concepts or stop words ) .", "label": "", "metadata": {}, "score": "55.93015"}
{"text": "[ 24 ] P. Jin , Y. Zhu , K. Hu , and S. Li , Classification Rule Mining Based on Ant Colony Optimization Algorithm .Springer , 2006 , vol .344 , pp .654 - 663 .[Online].", "label": "", "metadata": {}, "score": "55.973907"}
{"text": "IEEE TRANSACTIONS ON SYSTEMS , MAN , AND CYBERNETICS - PART B : CYBERNETICS2 of specific operators , the specification of the conditions that can appear in rule antecedents or how these conditions are connected [ 12].Moreover , our algorithm lacks the drawbacks of rule induction using sequential covering algorithms [ 13 ] , as Ant - Miner , because it does not rule out examples when building the classifier .", "label": "", "metadata": {}, "score": "55.990692"}
{"text": "Here , we focus on a different type of structure , namely output sparsity , which is not addressed in previous work .Moreover , our method is general enough to take advantage of structured notions of sp ... . by Grigorios Tsoumakas , Ioannis Katakis , Ioannis Vlahavas - In Data Mining and Knowledge Discovery Handbook , 2010 .", "label": "", "metadata": {}, "score": "56.007885"}
{"text": "In step 865 , for each distinct attribute in the query topic example set , the attribute value conditional probability is calculated .The query topic training set is then generated and stored in the data repository 150 in step 870 .", "label": "", "metadata": {}, "score": "56.02742"}
{"text": "In step 865 , for each distinct attribute in the query topic example set , the attribute value conditional probability is calculated .The query topic training set is then generated and stored in the data repository 150 in step 870 .", "label": "", "metadata": {}, "score": "56.02742"}
{"text": "137 - 145 , 2002 .[ 4 ] T.-M. Huang , V. Kecman , and I. Kopriva , \" Support vector machines in classification and regression - an introduction , \" in Kernel Based Algorithms for Mining Huge Data Sets : Supervised , Semi - supervised , and Unsupervised Learning ( Studies in Computational Intelligence ) .", "label": "", "metadata": {}, "score": "56.16082"}
{"text": "i .V .j . )P .y .L . m .C .p . )P .y .L . m .C .p .f .i .V .j . )If \u0394\u03c1 is less than 0 , it indicates that when f i is set to V j it concurs with the belief of C ( i.e. the estimated probability of ' p ' belonging to its correct class ( L m ) according to C increases ) .", "label": "", "metadata": {}, "score": "56.208572"}
{"text": "BACKGROUND OF THE INVENTION .Field of the Invention .This invention relates generally to image processing systems and more particularly to a system and method for automatic extraction of demographic information ( age , gender , or ethnicity ) from an image .", "label": "", "metadata": {}, "score": "56.21188"}
{"text": "When the query answer is \" no documents found , \" the system can assume that it failed to answer the question .Furthermore , when the system returns any document , the user has the opportunity to provide input as to the accuracy of the match between the documents provided and the intention behind the query of the user .", "label": "", "metadata": {}, "score": "56.268448"}
{"text": "When the query answer is \" no documents found , \" the system can assume that it failed to answer the question .Furthermore , when the system returns any document , the user has the opportunity to provide input as to the accuracy of the match between the documents provided and the intention behind the query of the user .", "label": "", "metadata": {}, "score": "56.268448"}
{"text": "[ 32 ] T. St\u00a8 utzle and H. H. Hoos , \" Max - min ant system , \" Future Generation Computer Systems , vol .16 , pp .889 - 914 , 2000 .[ 33 ] N. Holden and A. A. Freitas , \" A hybrid PSO / ACO algorithm for discovering classification rules in data mining , \" J. Artif .", "label": "", "metadata": {}, "score": "56.318474"}
{"text": "Internet users opt for spam filters that classify messages on the basis of analysis of the contents of the messages .The positive outcome of content - based filters has forced spammers to derive increasingly complex attacks which can surpass these filters and reach the users mailbox .", "label": "", "metadata": {}, "score": "56.35129"}
{"text": "Table 2 is a sample Finance Example Set which contains two documents , one belongs to Finance domain and the other irrelevant with Finance domain .After generating a Finance Example Set , the classifier 's construction goes to the next stage , classifier training stage .", "label": "", "metadata": {}, "score": "56.392822"}
{"text": "Table 2 is a sample Finance Example Set which contains two documents , one belongs to Finance domain and the other irrelevant with Finance domain .After generating a Finance Example Set , the classifier 's construction goes to the next stage , classifier training stage .", "label": "", "metadata": {}, "score": "56.392822"}
{"text": "claim 20 , wherein said Bayes classifier comprises a reasoner that determines a probability that a classified document matches said query .An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .", "label": "", "metadata": {}, "score": "56.40005"}
{"text": "claim 20 , wherein said Bayes classifier comprises a reasoner that determines a probability that a classified document matches said query .An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .", "label": "", "metadata": {}, "score": "56.40005"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 20 , wherein said document ontological parser comprises : . a sentence lexer that transforms said documents into multiple sequences of part - of - speech - tagged ontological concepts from said ontology ; . post - lexer filters that reduce the number of said multiple sequences produced by said sentence lexer , based on rules relating to sequences of syntactic tags ; . a parser that creates syntactic tree structures representing grammatical relations between said ontological concepts based on said syntactic tags ; and . post - parser filters that reduce the number of said parse trees based on rules relating to improbable syntactic structures , and rules concerning conflicting ontological specifications .", "label": "", "metadata": {}, "score": "56.403336"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 20 , wherein said document ontological parser comprises : . a sentence lexer that transforms said documents into multiple sequences of part - of - speech - tagged ontological concepts from said ontology ; . post - lexer filters that reduce the number of said multiple sequences produced by said sentence lexer , based on rules relating to sequences of syntactic tags ; . a parser that creates syntactic tree structures representing grammatical relations between said ontological concepts based on said syntactic tags ; and . post - parser filters that reduce the number of said parse trees based on rules relating to improbable syntactic structures , and rules concerning conflicting ontological specifications .", "label": "", "metadata": {}, "score": "56.403336"}
{"text": "A populated Finance Training Set represents the knowledge of the Finance - domain - specific classifier .Based on the probabilities data stored at Training Set , Finance - domain - specific classifier can determine if an input document belongs to Finance domain or not .", "label": "", "metadata": {}, "score": "56.438004"}
{"text": "A populated Finance Training Set represents the knowledge of the Finance - domain - specific classifier .Based on the probabilities data stored at Training Set , Finance - domain - specific classifier can determine if an input document belongs to Finance domain or not .", "label": "", "metadata": {}, "score": "56.438004"}
{"text": "According to Dahlgren et al , na\u00efve semantics is used at every structure building step to avoid combinatorial explosion .For example , the sentence \" face places with arms down \" has many available syntactic parses .The word \" face \" could be either a noun or a verb , as could the word places \" .", "label": "", "metadata": {}, "score": "56.445393"}
{"text": "According to Dahlgren et al , na\u00efve semantics is used at every structure building step to avoid combinatorial explosion .For example , the sentence \" face places with arms down \" has many available syntactic parses .The word \" face \" could be either a noun or a verb , as could the word places \" .", "label": "", "metadata": {}, "score": "56.445393"}
{"text": "After Topic editors ' classification , as shown in FIG .6 , the attribute extractor 400 will collect all attributes from input example documents 390 .An example set 410 is then generated based on the attributes and value of each Example documents .", "label": "", "metadata": {}, "score": "56.448048"}
{"text": "After Topic editors ' classification , as shown in FIG .6 , the attribute extractor 400 will collect all attributes from input example documents 390 .An example set 410 is then generated based on the attributes and value of each Example documents .", "label": "", "metadata": {}, "score": "56.448048"}
{"text": "In order to contrast the results obtained after the application of the Bonferroni - Dunn 's procedure , we can use the Holm test , which is more powerful than the first one and makes no additional assumptions about the hypotheses tested [ 58].", "label": "", "metadata": {}, "score": "56.47734"}
{"text": "In order to improve the accuracy of demographic sub - category classification ( such as male / female ) , the component demographic classifiers 800 , 801 , and 802 can be arranged in serial , parallel , or hybrid manner ( see .", "label": "", "metadata": {}, "score": "56.541927"}
{"text": "The node with the largest dot product is the node with a weight vector that most closely aligns in concept pattern space with the input vector .This node , plus those nodes in its immediate physical vicinity within the feature map , adjusts their weight vectors W via a simple learning algorithm : .", "label": "", "metadata": {}, "score": "56.546284"}
{"text": "The node with the largest dot product is the node with a weight vector that most closely aligns in concept pattern space with the input vector .This node , plus those nodes in its immediate physical vicinity within the feature map , adjusts their weight vectors W via a simple learning algorithm : .", "label": "", "metadata": {}, "score": "56.546284"}
{"text": "Online].Available : [ 15 ] M. Dorigo , V. Maniezzo , and A. Colorni , \" The ant system : Optimization by a colony of cooperating agents , \" IEEE Transactions on Systems , Man , and Cybernetics - Part B , vol .", "label": "", "metadata": {}, "score": "56.56623"}
{"text": "International Journal on Natural Language Computing ( IJNLC )Vol . 3 , No.3 , June 2014 136 Dredze et al ( 2007)[10 ] performed evaluation on three different sets of data .Results were measured using both accuracy and the spam F1 score .", "label": "", "metadata": {}, "score": "56.618088"}
{"text": "Once the k adjusted fitness values have been calculated , the consequent assigned to each ant corresponds to the one that reports the best adjusted fitness .To conclude , individuals that have an adjusted fitness greater than zero - and consequently cover at least one instance of the train set - are added to the classifier .", "label": "", "metadata": {}, "score": "56.6351"}
{"text": "Background of the Invention .The Internet , which was created to keep a small group of scientists informed , has now become so vast that it is no longer easy to find information .Even the simplest attempt to find information results in data overload .", "label": "", "metadata": {}, "score": "56.673935"}
{"text": "Background of the Invention .The Internet , which was created to keep a small group of scientists informed , has now become so vast that it is no longer easy to find information .Even the simplest attempt to find information results in data overload .", "label": "", "metadata": {}, "score": "56.673935"}
{"text": "The tissue feature score for a protein pair ( P1,P2 ) is computed as , .T .T . min .T .T . where , .T1 is the set of tissues P1 occurs in .T2 is the set of tissues P2 occurs in .", "label": "", "metadata": {}, "score": "56.679752"}
{"text": "The pseudo - concept filter operates only in the query ontological parser 120 .It removes verbs from queries , which are not likely to be the actual predicate of the query .Pseudo - predicate verbs include \" give \" , \" show \" , and \" find \" .", "label": "", "metadata": {}, "score": "56.684196"}
{"text": "The pseudo - concept filter operates only in the query ontological parser 120 .It removes verbs from queries , which are not likely to be the actual predicate of the query .Pseudo - predicate verbs include \" give \" , \" show \" , and \" find \" .", "label": "", "metadata": {}, "score": "56.684196"}
{"text": "The learning tree process uses a set of hand - classified documents to train the classifier 130 from an original na\u00efve state to one in which it can correctly classify new documents .The reasoner 134 answering process has two types of output , based on the input to the classifier 130 .", "label": "", "metadata": {}, "score": "56.75738"}
{"text": "The learning tree process uses a set of hand - classified documents to train the classifier 130 from an original na\u00efve state to one in which it can correctly classify new documents .The reasoner 134 answering process has two types of output , based on the input to the classifier 130 .", "label": "", "metadata": {}, "score": "56.75738"}
{"text": "Note that the number of arguments in the predicates do not match ; the document parses to cheer , which has more arguments than judge .The mismatch in the number of arguments would result in a lower score in the ranking and formatting component ; however , if not many documents match the query , it will still be prominently displayed as a match for the user 's question .", "label": "", "metadata": {}, "score": "56.836304"}
{"text": "Note that the number of arguments in the predicates do not match ; the document parses to cheer , which has more arguments than judge .The mismatch in the number of arguments would result in a lower score in the ranking and formatting component ; however , if not many documents match the query , it will still be prominently displayed as a match for the user 's question .", "label": "", "metadata": {}, "score": "56.836304"}
{"text": "Thus , we can arrange a trade- off between rule complexity and performance , reaching a compromise ( longer rules may report better rules as they can discover more complex relationships between attributes ) .As seen in Table VII , the GBAP algorithm is the third - best algorithm in obtaining a small number of conditions per rule , only beaten by GP and Ant - Miner .", "label": "", "metadata": {}, "score": "56.870117"}
{"text": "29 - 41 , 1996 .[ 16 ] D. Martens , B. Baesens , and T. Fawcett , \" Editorial survey : swarm intelligence for data mining , \" Mach .Learn . , vol .82 , pp . 1 - 42 , January 2011 .", "label": "", "metadata": {}, "score": "56.916527"}
{"text": "When the evolutionary process terminates , the classifier is set - up with the best individual found for each class .For each algorithm , excluding GBAP , its user - defined pa- rameters were set to the values reported by the authors in the aforementioned references .", "label": "", "metadata": {}, "score": "57.029205"}
{"text": "At this stage , the example sentence being tracked exists as a few lines of HTML text within a document downloaded by the concept based search and retrieval system 100 .The next stage of the concept - based search and retrieval system is the Bayes classifier 130 .", "label": "", "metadata": {}, "score": "57.0318"}
{"text": "At this stage , the example sentence being tracked exists as a few lines of HTML text within a document downloaded by the concept based search and retrieval system 100 .The next stage of the concept - based search and retrieval system is the Bayes classifier 130 .", "label": "", "metadata": {}, "score": "57.0318"}
{"text": "Figure 1 .A typical spam filter [ 5 ] 3.1 .Learning Algorithms The most important part in a spam classification system is the learning algorithm .[ 6 ] 3.1.1 .Probabilistic Approaches Probabilistic filters are the frequently used filters for spam classification because of its simplicity and the accuracy achieved .", "label": "", "metadata": {}, "score": "57.038963"}
{"text": "Unlike previous margin - based semisupervised algorithms , our sampling condition ... \" .We introduce a new algorithm for binary classification in the selective sampling protocol .Our algorithm uses Regularized Least Squares ( RLS ) as base classifier , and for this reason it can be efficiently run in any RKHS .", "label": "", "metadata": {}, "score": "57.128536"}
{"text": "302 - 311 , 2008 .[40 ] H. A. Abbass , X. Hoai , and R. I. Mckay , \" AntTAG : A new method to compose computer programs using colonies of ants , \" in In The IEEE Congress on Evolutionary Computation , 2002 , pp .", "label": "", "metadata": {}, "score": "57.161705"}
{"text": "Page 5 .Space of states at a depth of four derivations .The sample coloured path represents the antecedent found by a given ant .The grammar is shown in Figure 1 .Any production rule consists of a left hand side ( LHS ) and a right hand side ( RHS ) .", "label": "", "metadata": {}, "score": "57.195652"}
{"text": "Evaluating the impact of resolution it was found that at 400 \u00d7 400 , the system achieves an accuracy of more than 99.6 % .Higher accuracies were deemed impossible to implement considering human classification fallacy .[ 3 ] The results achieved by the Wang et al .", "label": "", "metadata": {}, "score": "57.231472"}
{"text": "This leads to an important extension since the Euclidean inner product can be replaces by any symmetric positive - definite kernel K(x , y ) .This use of kernel is equivalent to mapping the feature vectors to a high - dimensional space , thereby significantly increasing the discriminative power of the classifier .", "label": "", "metadata": {}, "score": "57.23427"}
{"text": "With regard to the standard deviation values , we can also observe that GBAP globally yields middling values in terms of stability .Though GBAP obtains the best average accuracy values , we performed the Friedman test with the aim of comparing the results obtained and analyzing if there are significant differences between the classifiers .", "label": "", "metadata": {}, "score": "57.243805"}
{"text": "10 describes how a query - topic - specific classifier determines input query 's topic .The input query is sent to attribute extractor 400 , which collects all attributes in the query .Reasoner 134 performs classification of query 's topic based on the knowledge stored at the training set 440 , inputs an attributes collection , and generates a list 450 of candidate topics ranked in order of probability of correctness .", "label": "", "metadata": {}, "score": "57.25307"}
{"text": "10 describes how a query - topic - specific classifier determines input query 's topic .The input query is sent to attribute extractor 400 , which collects all attributes in the query .Reasoner 134 performs classification of query 's topic based on the knowledge stored at the training set 440 , inputs an attributes collection , and generates a list 450 of candidate topics ranked in order of probability of correctness .", "label": "", "metadata": {}, "score": "57.25307"}
{"text": "The system can predefine a number n to indicate how many values will be returned .Then the first n topics will be returned as input query 's topic(s ) .For the above example , if the predefined value for n is one , only the first topic , finance , is returned as the input query 's topic .", "label": "", "metadata": {}, "score": "57.253143"}
{"text": "The system can predefine a number n to indicate how many values will be returned .Then the first n topics will be returned as input query 's topic(s ) .For the above example , if the predefined value for n is one , only the first topic , finance , is returned as the input query 's topic .", "label": "", "metadata": {}, "score": "57.253143"}
{"text": "The reasoner 134 performs classification based on the knowledge it learned and give back answer \" Yes \" or \" No \" to indicate the input document belongs to or not belongs to the specific domain .The other kind of Bayes classifier 120 is the query topic specific classifier , which is used to identify input query 's topic .", "label": "", "metadata": {}, "score": "57.332947"}
{"text": "The reasoner 134 performs classification based on the knowledge it learned and give back answer \" Yes \" or \" No \" to indicate the input document belongs to or not belongs to the specific domain .The other kind of Bayes classifier 120 is the query topic specific classifier , which is used to identify input query 's topic .", "label": "", "metadata": {}, "score": "57.332947"}
{"text": "claim 28 , wherein said Bayes classifier further comprises a learner that produces a set of trained document examples from data obtained from said data repository .An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .", "label": "", "metadata": {}, "score": "57.349068"}
{"text": "claim 28 , wherein said Bayes classifier further comprises a learner that produces a set of trained document examples from data obtained from said data repository .An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .", "label": "", "metadata": {}, "score": "57.349068"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . E. K. Burke , M. Hyde , G. Kendall , G. Ochoa , E. Ozcan , and R. Qu , \" A survey of hyper - heuristics , \" Computer Science Technical Report NOTTCS - TR - SUB-0906241418 - 2747 , University of Nottingham , 2009 , ( hhSurvey09 ) .", "label": "", "metadata": {}, "score": "57.44324"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 20 , further comprising a data repository storing said ontology , results from said Bayes classifier , and said predicate structures from said document ontological structure .", "label": "", "metadata": {}, "score": "57.44744"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 20 , further comprising a data repository storing said ontology , results from said Bayes classifier , and said predicate structures from said document ontological structure .", "label": "", "metadata": {}, "score": "57.44744"}
{"text": "The main characteristics of GBAP are depicted in the following subsections , presenting also a detailed pseudocode of the algorithm .Context - free grammar used in GBAP A. Environment and Rule Encoding GBAP prescribes a CFG for representing the antecedent of the rule encoded by each individual .", "label": "", "metadata": {}, "score": "57.506752"}
{"text": "To train the system further , engineers will be able to input queries using the same graphical user interface .The end user interface 114 provides a clear and simple graphical user interface that allows users to submit queries to the system .", "label": "", "metadata": {}, "score": "57.51069"}
{"text": "To train the system further , engineers will be able to input queries using the same graphical user interface .The end user interface 114 provides a clear and simple graphical user interface that allows users to submit queries to the system .", "label": "", "metadata": {}, "score": "57.51069"}
{"text": "The system alerts an engineer of particular events or irregularities in system operation that may require immediate attention .The engineers receive notification of these events via short messaging service to PCS wireless phones or e - mail to their desktops .", "label": "", "metadata": {}, "score": "57.52208"}
{"text": "The system alerts an engineer of particular events or irregularities in system operation that may require immediate attention .The engineers receive notification of these events via short messaging service to PCS wireless phones or e - mail to their desktops .", "label": "", "metadata": {}, "score": "57.52208"}
{"text": "Several anti - spam filtering solutions have been proposed till date .In general , these approaches treat the email spam filtering problem as a text classification or categorization problem , employing various machine learning techniques to solve the problem .Image spam is the most recent trap developed by spammers .", "label": "", "metadata": {}, "score": "57.54267"}
{"text": "Paper [ 17 ] also describes information gain .With this method , both class membership and the presence / absence of a particular term are seen as random variables , and one computes how much information about the class membership is gained by knowing the presence / absence .", "label": "", "metadata": {}, "score": "57.55631"}
{"text": "He has also been engaged in eleven research projects ( being the coordinator of two of them ) supported by the Spanish and Andalusian governments and the European Union , concerning several aspects of the area of evolutionary computation , machine learning , and data mining and its applications .", "label": "", "metadata": {}, "score": "57.568222"}
{"text": "References .Hamosh A , Scott AF , Amberger JS , Bocchini CA , McKusick VA : Online mendelian inheritance in man ( omim ) , a knowledgebase of human genes and genetic disorders .Nucleic Acids Res .2005 , D514-D517 .", "label": "", "metadata": {}, "score": "57.575462"}
{"text": "Online].Available : ftp://iridia.ulb.ac.be/pub/ mdorigo / tec . reps / TR.11-MetaHandBook.pdf [ 9 ] R. Parpinelli , A. A. Freitas , and H. S. Lopes , \" Data mining with an ant colony optimization algorithm , \" IEEE Trans on Evolutionary Computation , vol .", "label": "", "metadata": {}, "score": "57.648308"}
{"text": "F. Fitness Function and Consequent Assignment The fitness function that GBAP uses in the training stage to conduct the search process is the Laplace accuracy [ 50].This measure was selected because it suits well to multiclass classification since it takes into account the number of classes in the data set .", "label": "", "metadata": {}, "score": "57.65249"}
{"text": "View at Scopus .R. Bai , J. Blazewicz , E. K. Burke , G. Kendall , and B. McCollum , \" A simulated annealing hyper - heuristic methodology for flexible decision support , \" Tech .Rep. NOTTCS - TR-2007 - 8 , School of CSiT , University of Nottingham , 2007 .", "label": "", "metadata": {}, "score": "57.75908"}
{"text": "The processed image is fed to the component detectors 400 , 401 , and 402 to locate the components in a face image .There may be multitude of component detectors to detect the different components in the image .The component detection algorithm as implemented in Antonio Colmenarez , Brendan Frey , and Thomas S. Huang , \" Detection and Tracking of Faces and Facial Features \" , Proceedings on International Conference on Image Processing 1999 , ICIP 99 , Vol . 1 , pp .", "label": "", "metadata": {}, "score": "57.781075"}
{"text": "A proper noun is any capitalized Lexeme representing a noun concept .If a word appears at the beginning of a sentence , it is considered capitalized ( and therefore a proper noun ) if and only if it was not present in the lexicon .", "label": "", "metadata": {}, "score": "57.88889"}
{"text": "A proper noun is any capitalized Lexeme representing a noun concept .If a word appears at the beginning of a sentence , it is considered capitalized ( and therefore a proper noun ) if and only if it was not present in the lexicon .", "label": "", "metadata": {}, "score": "57.88889"}
{"text": "View at Google Scholar .View at Google Scholar .View at Scopus .K. Greer , \" Symbolic neural networks for clustering higher - level concepts , \" NAUN International Journal of Computers , vol .5 , no . 3 , pp .", "label": "", "metadata": {}, "score": "57.894295"}
{"text": "In this mode , topic editors provide training data in the form of specific documents known to belong to the selected topic or domain .These documents are used to train the Bayes classifier 130 .The classifier is able to determine membership criteria dynamically from the documents in the training set , after which the classifier is considered trained .", "label": "", "metadata": {}, "score": "58.08354"}
{"text": "In this mode , topic editors provide training data in the form of specific documents known to belong to the selected topic or domain .These documents are used to train the Bayes classifier 130 .The classifier is able to determine membership criteria dynamically from the documents in the training set , after which the classifier is considered trained .", "label": "", "metadata": {}, "score": "58.08354"}
{"text": "[ 31 ] K. M. Salama and A. M. Abdelbar , \" Extensions to the ant - miner classification rule discovery algorithm , \" in Swarm Intelligence - Proc .7th International Conference , ANTS 2010 , LNCS , vol .2010 , pp .", "label": "", "metadata": {}, "score": "58.09133"}
{"text": "5 ) .In an exemplary embodiment , image enhancement techniques 501 , such as histogram equalization and contrast stretching are performed .The processed image is fed to a face detection algorithm 301 .Face detection algorithm 301 detects the face and sends it to the face verification algorithm 302 , which verifies the hypotheses of a face in a scene .", "label": "", "metadata": {}, "score": "58.099945"}
{"text": "Rocchio Classifier .The Rocchio classifier [ 15 ] is a similarity - based linear classifier that considers both positive and negative input .Equation [ 16 ] can be described as given a training dataset .A classifier built using the Rocchio method rewards the closeness of a test document to the centroid of the positive training examples and its distance from the centroid of the negative training examples .", "label": "", "metadata": {}, "score": "58.183746"}
{"text": "Say if protein P1 does not have much variance , then for any protein P2 there will be little correlation between P1 and P2 .Domain interaction feature .The domain interaction information is obtained from the InterDom database [ 23 ] .", "label": "", "metadata": {}, "score": "58.238228"}
{"text": "Other evaluation equations were also tried , such as Euclidean , Jaccard , or similarity , see Section 3.1 , but the intersection of features proved to be a more suitable approach .Example Test Data .One example test was as follows : 30 datasets were created randomly .", "label": "", "metadata": {}, "score": "58.275856"}
{"text": "The cost for experimentally determining the interaction of the protein pairs might vary for different pairs depending upon the localization of the proteins and the experimental conditions which need to be created to verify the interaction .Similarly cost of obtaining the missing features might differ for the various feature types .", "label": "", "metadata": {}, "score": "58.282074"}
{"text": "The present system and method for concept - based searching is distinguishable from an ontology - based search system .A purely ontology - based search system would expand queries from particular words to include synonyms , instances , and parent concepts ( e.g. submarine is a synonym with U - boat , IBM is an instance of a company , and vehicle is a parent concept of automobile ) .", "label": "", "metadata": {}, "score": "58.33898"}
{"text": "The present system and method for concept - based searching is distinguishable from an ontology - based search system .A purely ontology - based search system would expand queries from particular words to include synonyms , instances , and parent concepts ( e.g. submarine is a synonym with U - boat , IBM is an instance of a company , and vehicle is a parent concept of automobile ) .", "label": "", "metadata": {}, "score": "58.33898"}
{"text": "Once connected , the end user interface 114 will register with the system to receive results for the user query .Once the query is processed , the end user interface 114 will format and present the results to the user in a logical manner .", "label": "", "metadata": {}, "score": "58.470375"}
{"text": "Once connected , the end user interface 114 will register with the system to receive results for the user query .Once the query is processed , the end user interface 114 will format and present the results to the user in a logical manner .", "label": "", "metadata": {}, "score": "58.470375"}
{"text": "wherein the hierarchical fusion classifiers process results from component demographic classifiers , . wherein the preprocessed component information from each component is preprocessed differently from each other to improve the accuracy of each component demographic classifier , . wherein the demographic information comprises age , gender , or ethnicity , . whereby said facial components are defined as artifacts that are individual parts of which a composite entity is made up , and . whereby the input images are acquired from an image sensing device or internet .", "label": "", "metadata": {}, "score": "58.493656"}
{"text": "Moreover , these artificially generated images are sent in batches .Thus images in a batch are similar and every message sent to different users are not the same .Analyzing the Image Spam Dataset designed by Dredze et al .( 2007)[10 ] it has been found that spam images contain pictures apart from embedded text .", "label": "", "metadata": {}, "score": "58.655403"}
{"text": "The main idea behind this project is to design a spam detection system .The system will be enabled to analyze the content of emails , in particular the artificially generated image sent as attachment in an email .The system will analyze the image content and classify the embedded image as spam or legitimate hence classify the email accordingly .", "label": "", "metadata": {}, "score": "58.76092"}
{"text": "Proc .17thInt .Conf .World Wide Web .ACM , pp .497 - 506 , 2008 [ 4 ] Blanzieri Enrico , Bryl Anton , \" A Survey Of Learning - Based Techniques Of Email Spam Filtering \" , Artificial Intelligence Review , Volume 29 , Issue 1 , Springer , pp 63 - 92 , 2008 .", "label": "", "metadata": {}, "score": "58.80434"}
{"text": "Finally , the majority class among the instances covered by the rule is assigned as the consequent .Since the publication of Ant - Miner , other research works have followed the research lines suggested in [ 9 ] , exploring the effects of several modifications .", "label": "", "metadata": {}, "score": "58.80799"}
{"text": "So , there are eight different five - class age classifiers .Each different five - class age is associated with each ethnicity and gender .The five - age age classifier is selected on the basis of the output of the gender and ethnicity classifiers .", "label": "", "metadata": {}, "score": "58.82563"}
{"text": "9617 , 2009 .[49 ] A. Geyer - Schulz , Fuzzy Rule - Based Expert Systems and Genetic Ma- chine Learning , ser .Studies in Fuzziness .1995 , vol .[50 ] P. Clark and R. Boswell , \" Rule induction with CN2 : Some recent improvements , \" in EWSL-91 .", "label": "", "metadata": {}, "score": "58.85313"}
{"text": "FIGS . 9 and 14 ) , the classifiers are organized in cascade method .Hence , Demographic Classifier N 802 , takes the output of previous classifiers to improve the accuracy and give Classifier Output 900 .In parallel configuration of classifiers ( see .", "label": "", "metadata": {}, "score": "58.968254"}
{"text": "A Bayes classifier 130 can only answer a question with a value that was present in the Example Set .Questions consist of a set of attributes , each of which is a word , token , or term .A classifier can only consider attributes that were present in its Example Set when answering a question .", "label": "", "metadata": {}, "score": "58.97303"}
{"text": "A Bayes classifier 130 can only answer a question with a value that was present in the Example Set .Questions consist of a set of attributes , each of which is a word , token , or term .A classifier can only consider attributes that were present in its Example Set when answering a question .", "label": "", "metadata": {}, "score": "58.97303"}
{"text": "[43 ] C. Keber and M. G. Schuster , \" Option valuation with generalized ant programming , \" in GECCO 2002 : Proceedings of the Genetic and Evolutionary Computation Conference , W. B. L. et al . , Ed .New York : Morgan Kaufmann Publishers , 9 - 13 Jul. 2002 , pp .", "label": "", "metadata": {}, "score": "59.003323"}
{"text": "IJCAI .Witten IH , Frank E : Data mining : practical machine learning tools and techniques .2005 , Amsterdam ; Boston , MA : Morgan Kaufman , 2 .Mohamed TP , Carbonell JG , Ganapathiraju MK : Active learning for human protein - protein interaction prediction .", "label": "", "metadata": {}, "score": "59.05237"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .I. Guyon and A. Elisseeff , \" An introduction to variable and feature selection , \" Journal of Machine Learning Research , vol .3 , pp .1157 - 1182 , 1993 .", "label": "", "metadata": {}, "score": "59.07728"}
{"text": "Publisher conditions are provided by RoMEO .Differing provisions from the publisher 's actual policy or licence agreement may be applicable . \"Consequently , previously learned rules directly influence the data of the other rules .Divide - and - conquer algorithms greedily find the split that best separates data in terms of some predefined impurity measure such as information gain , entropy , Gini index , etc . \" .", "label": "", "metadata": {}, "score": "59.111256"}
{"text": "More recently , Shirakawa et al .[46 ] proposed dynamic ant programming ( DAP ) .Its main difference with regards to ACP lies in the use of a dynamically changing pheromone table and a variable number of nodes , which leads to a more compact space of states .", "label": "", "metadata": {}, "score": "59.15451"}
{"text": "The niching algorithm takes care that it does not overlap with instances of another class .In addition , it is appropriate when removing redundant rules .Moreover , it lacks the drawbacks that are present in covering algorithms related to the discarding of instances .", "label": "", "metadata": {}, "score": "59.179688"}
{"text": "[46 ] S. Shirakawa , S. Ogino , and T. Nagao , \" Dynamic ant programming for automatic construction of programs , \" IEEJ Transactions on Electrical and Electronic Engineering ( TEEE ) , vol .3 , no .5 , pp .", "label": "", "metadata": {}, "score": "59.184895"}
{"text": "The features were just letters or letter combinations of the alphabet , where each dataset was assigned a random selection of these features .Each dataset therefore had a randomly selected subset of all of the features .Each feature was assigned a random score , but distributed around some mean value .", "label": "", "metadata": {}, "score": "59.210297"}
{"text": "Regardless of the method by which documents are acquired , they are then passed into the Bayes classifier 130 , which classifies the documents according to the set of available trained classifiers previously learned in the Bayes classifier 130 Training Mode .", "label": "", "metadata": {}, "score": "59.22338"}
{"text": "Regardless of the method by which documents are acquired , they are then passed into the Bayes classifier 130 , which classifies the documents according to the set of available trained classifiers previously learned in the Bayes classifier 130 Training Mode .", "label": "", "metadata": {}, "score": "59.22338"}
{"text": "Online].Evol .Syst . , 2002 , pp .180 - 184 .[ 18 ] - , \" Classification rule discovery with ant colony optimization , \" in IAT ' 03 : Proceedings of the IEEE / WIC International Conference on Intelligent Agent Technology .", "label": "", "metadata": {}, "score": "59.314228"}
{"text": "Based on the locus tag and the chromosome to which the genes are attached the distance score is computed between the genes .Tissue feature .The data for generating the tissue feature was obtained from Tissue - specific Gene Expression and Regulation ( TiGER ) database [ 24 ] .", "label": "", "metadata": {}, "score": "59.34021"}
{"text": "After the reasoner 134 accepts the input attributes , it sends a request to the data repository 150 to access correspond a training set 440 .The algorithm for calculating answer probability P(c j w i , w 2 , w n ) is described as follows and is shown in FIG .", "label": "", "metadata": {}, "score": "59.413395"}
{"text": "After the reasoner 134 accepts the input attributes , it sends a request to the data repository 150 to access correspond a training set 440 .The algorithm for calculating answer probability P(c j w i , w 2 , w n ) is described as follows and is shown in FIG .", "label": "", "metadata": {}, "score": "59.413395"}
{"text": "Finally , if the rule encoded by the ant has captured at least minCasesPerRule , the ant 's adjusted fitness value for this class is computed as described in Eq .14 , where idealTokens stands for the ideal number of tokens that the current ant could capture , i.e. , the number of tokens belonging to the computing class ( regardless of whether they have been previously captured by other ant or not ) .", "label": "", "metadata": {}, "score": "59.461273"}
{"text": "Vol . 3 , No.3 , June 2014 130 combat the text based anti - spam filters at the same time by using HTML formatting [ 3 ] .Understanding the increasing trend of multimedia enriched email messages , it is the need of time to use such information to defeat the spammers ' intention .", "label": "", "metadata": {}, "score": "59.564888"}
{"text": "Since proper nouns behave syntactically as regular nouns , there is no need to distinguish proper nouns and nouns already in the lexicon .The purpose of the proper noun filter is to ensure that sequences not already in the lexicon are treated as single words where appropriate .", "label": "", "metadata": {}, "score": "59.634884"}
{"text": "Since proper nouns behave syntactically as regular nouns , there is no need to distinguish proper nouns and nouns already in the lexicon .The purpose of the proper noun filter is to ensure that sequences not already in the lexicon are treated as single words where appropriate .", "label": "", "metadata": {}, "score": "59.634884"}
{"text": "14 shows an exemplary embodiment of the Serial Configuration for multiple Category Demographic Classifications ( for e.g. , two or more categories of age , gender , or ethnicity ) .FIG .15 shows an exemplary embodiment of the components used for Demographic Classification .", "label": "", "metadata": {}, "score": "59.74933"}
{"text": "In this invention , two classifier fusion methodologies are proposed .The first is Data Level Fusion 704 and the second is Hierarchical Fusion 803 demographic classifier .In case of Data Level Fusion 704 , the component information 203 , 204 , and 205 from every component may be preprocessed 700 , 701 , and 702 ( see .", "label": "", "metadata": {}, "score": "59.84465"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 20 , wherein said query predicate structure and said document predicate structures comprise a predicate and an argument , said predicate is one of a verb and a preposition , and said argument is any part of speech .", "label": "", "metadata": {}, "score": "59.84586"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 20 , wherein said query predicate structure and said document predicate structures comprise a predicate and an argument , said predicate is one of a verb and a preposition , and said argument is any part of speech .", "label": "", "metadata": {}, "score": "59.84586"}
{"text": "Attenberg J , Melville P , Provost F : A unified approach to active dual supervision .ECML PKDD 2010 , Proceedings of the European Conference on Machine Learning and Principles of Knowledge Discovery in Databases .Qi Y , Bar - Joseph Z , Klein - Seetharaman J : Evaluation of different biological data and computational classification methods for use in protein interaction prediction .", "label": "", "metadata": {}, "score": "59.860283"}
{"text": "If the neurons in the brain form in a purely mechanical way , without any real intelligence , then a more centralised and intelligent part that can interpret the firing neurons might be required .It is also known that the human brain does not store information only once , but duplicates it in different areas .", "label": "", "metadata": {}, "score": "59.93277"}
{"text": "App . , vol .2008 , pp .2:1 - 2:11 , January 2008 .[Online].[ 35 ] M. Boryczka and Z. J. Czech , \" Solving approximation problems by ant colony programming , \" in GECCO Late Breaking Papers , 2002 , pp .", "label": "", "metadata": {}, "score": "59.958397"}
{"text": "Vol . 3 , No.3 , June 2014 [ 8 ] Sakkis Georgios , Androutsopoulos Ion , Paliouras Georgios , Karkaletsis Vangelis , Spyropoulos Constantine D. , Stamatopoulos Panagiotis , \" Stacking classifiers for anti In Proc . 6th Conference on Empirical Methods 2001 .", "label": "", "metadata": {}, "score": "59.974083"}
{"text": "Each feature was assigned a random score taken from the distribution described in Table 1 .This description shows that there was a mean value of 10 that would be selected 40 % of the time .This is indicated by the 0.4 percentage value and the 1.0 distribution value in the centre of the script description .", "label": "", "metadata": {}, "score": "59.989487"}
{"text": "After the lexer 122 has checked the last word in a sentence against the contents of the ontology 128 , the sentence is passed to a series of lexer filters 125 .Filters 125 are modular plug - ins , which modify sentences based on knowledge about lexer word meanings .", "label": "", "metadata": {}, "score": "60.036293"}
{"text": "After the lexer 122 has checked the last word in a sentence against the contents of the ontology 128 , the sentence is passed to a series of lexer filters 125 .Filters 125 are modular plug - ins , which modify sentences based on knowledge about lexer word meanings .", "label": "", "metadata": {}, "score": "60.036293"}
{"text": "17 is a flow chart of a trained query topic classifier identification of an input query according to one variation of the present invention .DETAILED DESCRIPTION OF THE INVENTION .In the following detailed discussion of the present invention , numerous terms , specific to the subject matter of a system and method for concept - based searching , are used .", "label": "", "metadata": {}, "score": "60.114067"}
{"text": "17 is a flow chart of a trained query topic classifier identification of an input query according to one variation of the present invention .DETAILED DESCRIPTION OF THE INVENTION .In the following detailed discussion of the present invention , numerous terms , specific to the subject matter of a system and method for concept - based searching , are used .", "label": "", "metadata": {}, "score": "60.114067"}
{"text": "Technology stocks soared in heavy trading Wednesday , pushing the Nasdaq composite index to its 13th record of the year as money poured into the economy 's hottest chipmakers , telecommunications companies and biotechnology firms .The attribute extractor 400 collect attributes from this input documents in step 705 .", "label": "", "metadata": {}, "score": "60.216476"}
{"text": "Technology stocks soared in heavy trading Wednesday , pushing the Nasdaq composite index to its 13th record of the year as money poured into the economy 's hottest chipmakers , telecommunications companies and biotechnology firms .The attribute extractor 400 collect attributes from this input documents in step 705 .", "label": "", "metadata": {}, "score": "60.216476"}
{"text": "O .n .G .O .n .G .O . where , Set1 are the set of GO terms for P1 and Set2 are the terms for P2 .Three feature values , one each by using GO annotations for biological process , cellular component and molecular function are developed .", "label": "", "metadata": {}, "score": "60.284805"}
{"text": "For example , a query like \" What happened to stock market ? \" can be converted to a predicate structure containing concepts \" happened \" and \" stock market . \"With a concept ontology 128 that contains hierarchical concepts , \" happened \" may expand to include \" took place \" and \" occurred , \" while \" stock market \" may expand to include \" stock exchange , \" \" securities market , \" and \" Nasdaq .", "label": "", "metadata": {}, "score": "60.304077"}
{"text": "For example , a query like \" What happened to stock market ? \" can be converted to a predicate structure containing concepts \" happened \" and \" stock market . \"With a concept ontology 128 that contains hierarchical concepts , \" happened \" may expand to include \" took place \" and \" occurred , \" while \" stock market \" may expand to include \" stock exchange , \" \" securities market , \" and \" Nasdaq .", "label": "", "metadata": {}, "score": "60.304077"}
{"text": "[ 2 ] Radicati S , Khmartseva M , \" Email Statistics Report 2009 - 2013 \" , The Radicati Group , Inc , Palo Alto , CA , 2009 [ 3 ] Mehta , B. , Nangia , S. , Gupta , M. , Nejdl , W. , .", "label": "", "metadata": {}, "score": "60.392395"}
{"text": "16 shows the steps for training the classifiers .DETAILED DESCRIPTION OF THE INVENTION .The envisioned system and method for demographic classification using components is described in detail in the following paragraphs .The proposed invention detects the faces in the current scene in an image and determines the demographic information 102 of the people .", "label": "", "metadata": {}, "score": "60.549965"}
{"text": "The generation and distribution is justified from a spammer 's prospect as the effort and cost involved in sending a large number of emails is minimal and the probable return considering the large number of email users is huge .According to a survey the overall cost incurred in preventing spam in 2009 was estimated to be 130 billion U.S. dollars[1].", "label": "", "metadata": {}, "score": "60.5642"}
{"text": "Attribute extractor 400 includes processes to eliminate the stop words in the input documents and eliminate words case sensitivity problem .In general , all words in a document are converted to lower case before performing attribute collection .Stop words are those words that are judged to be so common in an information system that they have little information value .", "label": "", "metadata": {}, "score": "60.565914"}
{"text": "Attribute extractor 400 includes processes to eliminate the stop words in the input documents and eliminate words case sensitivity problem .In general , all words in a document are converted to lower case before performing attribute collection .Stop words are those words that are judged to be so common in an information system that they have little information value .", "label": "", "metadata": {}, "score": "60.565914"}
{"text": "V k ) .Let ( L 1 , L 2 , ...L N ) be the various possible labels for the instance .We assume that the instance under consideration is already labeled to be L m .The expected utility of acquiring f i is measured as follows , .", "label": "", "metadata": {}, "score": "60.76097"}
{"text": "The document clustering component 180 makes use of the results of the document ontological parser 140 .Each document stored in the Data repository 150 , and each document matched to a user query , must first be processed by the ontological parser 140 to determine that it is such a match .", "label": "", "metadata": {}, "score": "60.76419"}
{"text": "The document clustering component 180 makes use of the results of the document ontological parser 140 .Each document stored in the Data repository 150 , and each document matched to a user query , must first be processed by the ontological parser 140 to determine that it is such a match .", "label": "", "metadata": {}, "score": "60.76419"}
{"text": "FIG .6 shows an exemplary embodiment of component information .FIG .7 gives perspective into Data Level Fusion of component information .In this module , the component information from various components is concatenated together to form a single data vector .", "label": "", "metadata": {}, "score": "60.848553"}
{"text": "[ 9 ] , and it has become a bench- mark algorithm in this field .Since then , several extensions and modifications of this sequential covering algorithm have been presented .Another technique that has reported good results in classi- fication is genetic programming ( GP ) [ 10].", "label": "", "metadata": {}, "score": "60.956726"}
{"text": "As aforemen- tioned , when ants have been just created they only repre- sent the antecedent of a new rule .The consequent will be .Page 6 .IEEE TRANSACTIONS ON SYSTEMS , MAN , AND CYBERNETICS - PART B : CYBERNETICS6 assigned by following the niching approach described later in Section III - F. B. Algorithm The main steps of GBAP are detailed in the pseudocode of Algorithm 1 .", "label": "", "metadata": {}, "score": "60.978146"}
{"text": "Moreover , lower values for false - positive are considered more significant than high detection rates .Therefore , the one - class SVM classifier with 20 % outlier was chosen as the base classifier [ 9 ] .A comparison of a text - based and the proposed visual - based anti - spam filter revealed that a text - based Bayesian filter , trained using Ling - Spam dataset , identified only 47.73 % emails as spam .", "label": "", "metadata": {}, "score": "61.072327"}
{"text": "claim 20 , wherein said query ontological parser comprises : . a sentence lexer that transforms said natural language query into multiple sequences of part - of - speech - tagged ontological concepts from said ontology ; . post - lexer filters that reduce the number of said multiple sequences produced by said sentence lexer , based on rules relating to sequences of syntactic tags ; . a parser that creates syntactic tree structures representing grammatical relations between said ontological concepts based on said syntactic tags ; and . post - parser filters that reduce the number of said parse trees based on rules relating to improbable syntactic structures , and rules concerning conflicting ontological specifications .", "label": "", "metadata": {}, "score": "61.077625"}
{"text": "claim 20 , wherein said query ontological parser comprises : . a sentence lexer that transforms said natural language query into multiple sequences of part - of - speech - tagged ontological concepts from said ontology ; . post - lexer filters that reduce the number of said multiple sequences produced by said sentence lexer , based on rules relating to sequences of syntactic tags ; . a parser that creates syntactic tree structures representing grammatical relations between said ontological concepts based on said syntactic tags ; and . post - parser filters that reduce the number of said parse trees based on rules relating to improbable syntactic structures , and rules concerning conflicting ontological specifications .", "label": "", "metadata": {}, "score": "61.077625"}
{"text": "Consequently , this has greatly reduced the effectiveness of existing text - based anti - spam filters .As a matter of fact , legitimate message - senders have sought to enrich the messages by adding multimedia content like images .The spammers at the same time have started using images to hide the fraudulent messages and .", "label": "", "metadata": {}, "score": "61.1292"}
{"text": "IEEE Int .Conf .Image Process , Vol .III .pp .501 [ 10 ] Dredze , M. , Gevaryahu , R. , Elias Fourth Conf .Email Anti [11 ] Wang , Z. , Josephson , W. , Lv , Q. , Charikar , M. , Li , K. , \" Filtering image spam with near detection . \" , In : Proc .", "label": "", "metadata": {}, "score": "61.144585"}
{"text": "Once the pheromone trails in the environment have been reinforced and evaporated , a normalization process takes place , in order to bound the pheromone amount existing in each transition to the range [ \u03c4min , \u03c4max].Notice that it is quite complicated to store the environment 's pheromone values in a pheromone matrix .", "label": "", "metadata": {}, "score": "61.16578"}
{"text": "a pseudo - predicate filter that removes verbs from said queries .An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 31 , wherein said post - lexer filters comprise : . a stop word filter that removes words that serve as placeholders in English - language ; . an adjective filter that removes lexemes representing adjective concepts ; . a proper noun filter that groups proper nouns into single lexical nouns ; .", "label": "", "metadata": {}, "score": "61.189846"}
{"text": "a pseudo - predicate filter that removes verbs from said queries .An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 31 , wherein said post - lexer filters comprise : . a stop word filter that removes words that serve as placeholders in English - language ; . an adjective filter that removes lexemes representing adjective concepts ; . a proper noun filter that groups proper nouns into single lexical nouns ; .", "label": "", "metadata": {}, "score": "61.189846"}
{"text": "In this paper , we propose Two - Neighbor Orientation ( TNO ) model that jointly models the orientation decisions between anchors and two neighboring multi - unit chunks which may cross phrase or rule boundaries .We explicitly model the longest span of such chunks , referred to as Maximal Orientation Span , to serve as a global parameter that constrains underlying local decisions .", "label": "", "metadata": {}, "score": "61.200424"}
{"text": "d ) automatically generating component information from the facial component features and the facial components , and .e ) processing the component information using classifiers including data level fusion classifiers and hierarchical fusion classifiers for demographic information identification , . wherein the data level fusion classifiers concatenate preprocessed component information into a single vector , . wherein the hierarchical fusion classifiers process results from component demographic classifiers , . wherein the preprocessed component information from each component is preprocessed differently from each other to improve the accuracy of each component demographic classifier , . wherein the demographic information comprises age , gender , or ethnicity , . whereby said facial components are defined as artifacts that are individual parts of which a composite entity is made up , and . whereby the input images are acquired from an image sensing device or internet .", "label": "", "metadata": {}, "score": "61.39914"}
{"text": "As outlined in the following sections , the GBAP algorithm can not be fitted into a typical ACO system .Due to the bounding of the pheromone levels to within the interval [ \u03c4min , \u03c4max ] , and to the initialization of all edges to the maxi- mum pheromone amount allowed , the algorithm with which GBAP shares more characteristics may be the MMAS [ 32].", "label": "", "metadata": {}, "score": "61.418724"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 24 , wherein said Bayes classifier is query - topic specific so that words that form said query are used to determine a topic of said query .", "label": "", "metadata": {}, "score": "61.489197"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 24 , wherein said Bayes classifier is query - topic specific so that words that form said query are used to determine a topic of said query .", "label": "", "metadata": {}, "score": "61.489197"}
{"text": "Starting with the initial state of the environment , which is associated with the start symbol defined by the grammar , each ant tries to build a feasible solution to the problem .Any solution found takes the form of a path from the root node to a final state over the derivation tree , as shown in the sample coloured path in Figure 2 .", "label": "", "metadata": {}, "score": "61.490566"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in . claim 21 , wherein said Bayes classifier comprises a reasoner that determines a probability that a classified document matches said query .", "label": "", "metadata": {}, "score": "61.525852"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in . claim 21 , wherein said Bayes classifier comprises a reasoner that determines a probability that a classified document matches said query .", "label": "", "metadata": {}, "score": "61.525852"}
{"text": "Page 10 .cases per rule max .The minimum number of instances per rule Determines the amount of data used for reduced - error pruning .One fold is used for pruning , the rest for growing the rules Whether reduced - error pruning is used instead of C4.5 pruning Whether pruning is performed False confidenceFactor0.25 minNumObj numFolds 2 3 reducedErrorPruningFalse unprunedFalse where sensitivity and specificity are computed as indicated in Eq .", "label": "", "metadata": {}, "score": "61.527145"}
{"text": "It is therefore to be understood that all such variations , modifications and changes are believed to fall within the scope of the invention as defined in the appended claims .Dunja Mladinic , Turning Yahoo into an Automatic Web Page Classifier , ECAI 98:13European Conference on Artificial Intelligence , Brighton , UK , 8/23 to 8/28 , 1998 pp .", "label": "", "metadata": {}, "score": "61.56685"}
{"text": "It is therefore to be understood that all such variations , modifications and changes are believed to fall within the scope of the invention as defined in the appended claims .Dunja Mladinic , Turning Yahoo into an Automatic Web Page Classifier , ECAI 98:13European Conference on Artificial Intelligence , Brighton , UK , 8/23 to 8/28 , 1998 pp .", "label": "", "metadata": {}, "score": "61.56685"}
{"text": "427 - 430 , 2006 .[Online].[Online].[ 23 ] J. Smaldon and A. A. Freitas , \" A new version of the ant - miner algorithm discovering unordered rule sets , \" in GECCO , 2006 , pp .", "label": "", "metadata": {}, "score": "61.570152"}
{"text": "Thus , covering algorithms seek rules with good performance in the sub - data set .The pseudocode of the niching algorithm developed is shown in Procedure 3 .Notice that each existing instance in the training set is called a token : all ants will compete to capture the tokens , bearing in mind that a given token can be captured at most by one ant .", "label": "", "metadata": {}, "score": "61.6328"}
{"text": "29 ] C. Nalini and P. Balasubramanie , \" Discovering unordered rule sets for mixed variables using an ant - miner algorithm , \" Data Science Journal , vol .7 , pp .76 - 87 , May 2008 .Berlin , Heidelberg : Springer - Verlag , 2009 , pp .", "label": "", "metadata": {}, "score": "61.701004"}
{"text": "Zhang S , Ning X , Zhang X - S : Identification of functional modules in a ppi network by clique percolation clustering .Bioinformatics .Chin C - H , Chen S - H , Ho C - W , Ko M - T , Lin C - Y : A hub - attachment based method to detect functional modules from confidence - scored protein interactions and expression profiles .", "label": "", "metadata": {}, "score": "61.706154"}
{"text": "Kapoor A , Greiner R : Budgeted learning of bounded active classifiers .Proceedings of the ACM SIGKDD Workshop on Utility - Based Data Mining .Copyright .\u00a9 Thahir et al . ; licensee BioMed Central Ltd. 2012 .This article is published under license to BioMed Central Ltd.", "label": "", "metadata": {}, "score": "61.71408"}
{"text": "A document may be classified as belonging to multiple categories if the words within the document correspond to attributes of several classifiers .For example , a financial page would be classified as such by the occurrence of words like stock , bond , Federal Reserve , and interest rate .", "label": "", "metadata": {}, "score": "61.73854"}
{"text": "A document may be classified as belonging to multiple categories if the words within the document correspond to attributes of several classifiers .For example , a financial page would be classified as such by the occurrence of words like stock , bond , Federal Reserve , and interest rate .", "label": "", "metadata": {}, "score": "61.73854"}
{"text": "He received his Ph.D. in Computer Science from the University of Malaga , Spain , in 2007 .He has worked as an IT consultant for important business consulting and technology companies for several years .His current research in- terests include the use of bio - inspired algorithms for data mining , the industrial use of formal methods , open and distributed processing and model - driven software development and its applications .", "label": "", "metadata": {}, "score": "61.76432"}
{"text": "Nucleic Acids Res .2009 , D767 - 772 .37 Database .Venkatesan K , Rual JF , Vazquez A , Stelzl U , Lemmens I , Hirozane - Kishikawa T , Hao T , Zenkner M , Xin X , Goh KI , et al : An empirical framework for binary interactome mapping .", "label": "", "metadata": {}, "score": "61.767776"}
{"text": "claim 22 , wherein said post - lexer filters comprise : . a stop word filter that removes words that serve as placeholders in English - language ; . an adjective filter that removes lexemes representing adjective concepts ; . a proper noun filter that groups proper nouns into single lexical nouns ; .", "label": "", "metadata": {}, "score": "61.77499"}
{"text": "claim 22 , wherein said post - lexer filters comprise : . a stop word filter that removes words that serve as placeholders in English - language ; . an adjective filter that removes lexemes representing adjective concepts ; . a proper noun filter that groups proper nouns into single lexical nouns ; .", "label": "", "metadata": {}, "score": "61.77499"}
{"text": "15 is a flow chart of query topic example set generation according to one variation of the present invention ; .FIG .16 is a flow chart of query topic classification training according to one variation of the present invention ; and .", "label": "", "metadata": {}, "score": "61.782997"}
{"text": "15 is a flow chart of query topic example set generation according to one variation of the present invention ; .FIG .16 is a flow chart of query topic classification training according to one variation of the present invention ; and .", "label": "", "metadata": {}, "score": "61.782997"}
{"text": "For a given protein pair , this feature measures how close the genes ( encoding the proteins ) are to each other in the genome .The data for computing this feature is downloaded from ftp://\u200bftp .ncbi . nlm .nih .", "label": "", "metadata": {}, "score": "61.80331"}
{"text": "FIG .7 is a block diagram of the Bayes classifier training stage according to one variation of the present invention ; .FIG .8 is a diagram illustrating the Bayes training and classifier algorithms according to one variation of the present invention ; .", "label": "", "metadata": {}, "score": "61.957058"}
{"text": "FIG .7 is a block diagram of the Bayes classifier training stage according to one variation of the present invention ; .FIG .8 is a diagram illustrating the Bayes training and classifier algorithms according to one variation of the present invention ; .", "label": "", "metadata": {}, "score": "61.957058"}
{"text": "claim 7 , further comprising the step of collecting all attributes occurring in said document and determining if said document belongs to said specified domain .A method of performing concept - based searching of text documents as recited in .claim 6 , further comprising the steps of : . determining a topic of said query predicate structure ; . providing a set of trained document examples from said data repository ; . classifying said topic based on said trained set of document examples ; and . providing a list of possible topics ranked in order of probability of correctness .", "label": "", "metadata": {}, "score": "61.976486"}
{"text": "claim 7 , further comprising the step of collecting all attributes occurring in said document and determining if said document belongs to said specified domain .A method of performing concept - based searching of text documents as recited in .claim 6 , further comprising the steps of : . determining a topic of said query predicate structure ; . providing a set of trained document examples from said data repository ; . classifying said topic based on said trained set of document examples ; and . providing a list of possible topics ranked in order of probability of correctness .", "label": "", "metadata": {}, "score": "61.976486"}
{"text": "The color histogram filter achieved 100 % detection rates for 76 % categories , and more than 96.7 % for the remaining 4categories .The false positive rates of all categories ( except shift ) were 0.0006 % [ 11 ] .", "label": "", "metadata": {}, "score": "62.019005"}
{"text": "Ant - Miner chooses a new term for the current partial rule by applying the transition rule , and it only considers including terms that have not been previously chosen .An information theoretic measure in terms of entropy is used as the heuristic function .", "label": "", "metadata": {}, "score": "62.03933"}
{"text": "The complexity of MMAS - based algorithms is a complex research area , which has been widely studied and analyzed by Neumann et al .[47].On the other hand , regarding the AP algorithms reviewed in Section II - B , GBAP presents certain similarities with GAP [ 43 ] and EGAP [", "label": "", "metadata": {}, "score": "62.05307"}
{"text": "Learning - based filters possess the learning capability from spam and legitimate example messages which allows these filters to customize the spam detection .Learning - based filters also .International Journal on Natural Language Computing ( IJNLC )Vol . 3 , No.3 , June 2014 132 have the potential to learn and enhance the self- performance at real - time , as they can adapt themselves to the wide genre of spam and legitimate email a user receives .", "label": "", "metadata": {}, "score": "62.08029"}
{"text": "IEEE Int .Conf .Image Process , Vol .III .pp .501 - 504 . , 2005 .Proc .Fourth Conf .Email Anti - Spam ( CEAS ) , 2007 .Wang , Z. , Josephson , W. , Lv , Q. , Charikar , M. , Li , K. , \" Filtering image spam with near detection . \" , In : Proc .", "label": "", "metadata": {}, "score": "62.142426"}
{"text": "Constructing a complete human protein - protein interaction ( PPI ) network ( the ' interactome ' ) can accelerate discovery in biomedical sciences and is crucial to the study of disease mechanisms and drug discovery .Several network - based approaches have been devised to determine gene - disease associations and functional modules using the interactome , including neighborhood based approaches , clustering / graph partitioning based methods and random - walks [ 3 - 6 ] .", "label": "", "metadata": {}, "score": "62.177456"}
{"text": "The false positives are costlier than the false negatives .This ensures the classifier optimizing the cost .As spammers benefit depends on the number of spam messages read , they are forced to prepare very sophisticated techniques to breakthrough different filters equipped with different learned models .", "label": "", "metadata": {}, "score": "62.234978"}
{"text": "Simulation results show that our approach produces rulesets that are significantly better than those produced by the original Ripper . \"T HE aim of data mining ( DM ) is to extract non - trivial information and knowledge hidden in data .", "label": "", "metadata": {}, "score": "62.486732"}
{"text": "Dr. Ventura is a Member of the IEEE Computer , Computational Intelli- gence and Systems , Man and Cybernetics societies and the Association of Computing Machinery .Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .", "label": "", "metadata": {}, "score": "62.487396"}
{"text": "The orientation histogram filter also achieved 100 % detection rate for 4 categories , while the false positive rate was below 0.0007 % .[ 11 ] To understand the multiple spam filter aggregation three aggregation methods have been used : AND , OR and VOTE .", "label": "", "metadata": {}, "score": "62.56662"}
{"text": "Description .CROSS - REFERENCE TO RELATED APPLICATIONS .This application is entitled to the benefit of Provisional Patent Application Ser .No .60/514,094 , filed Oct. 24 , 2003 .FEDERALLY SPONSORED RESEARCH .Not Applicable .SEQUENCE LISTING OR PROGRAM .", "label": "", "metadata": {}, "score": "62.62791"}
{"text": "Figures .FIG .1 shows the general setup of the system .FIG .2 shows the overview block diagram of the invention .FIG .3 gives a perspective inside the Face Detection Module .The Face Detection Module receives a still image and localizes on the face region .", "label": "", "metadata": {}, "score": "62.75974"}
{"text": "A query - topic - specific Bayes classifier uses the words that make up a particular question as the features it uses to identify the topic of the question .The primary reason for using a Bayes classifier 130 is because it is a rapid , effective technique for reducing the number of documents to be searched in response to a query .", "label": "", "metadata": {}, "score": "62.76002"}
{"text": "A query - topic - specific Bayes classifier uses the words that make up a particular question as the features it uses to identify the topic of the question .The primary reason for using a Bayes classifier 130 is because it is a rapid , effective technique for reducing the number of documents to be searched in response to a query .", "label": "", "metadata": {}, "score": "62.76002"}
{"text": "claim 7 , wherein the method further comprises a step of performing fusion by concatenating the component information for extracting said demographic information .The method according to .claim 7 , wherein the method further comprises a step of passing component demographic classifier results to the hierarchical fusion classifiers , . wherein the hierarchical fusion classifiers are multi - level classifiers , . wherein component information from each component may be preprocessed differently , and .", "label": "", "metadata": {}, "score": "62.832195"}
{"text": "View at Google Scholar A concept - based indexing and search system indexes collections of documents with ontology - based predicate structures through automated and/or human - assisted methods .The system extracts the concepts behind user queries to return only those documents that match those concepts .", "label": "", "metadata": {}, "score": "62.842228"}
{"text": "Predicate structures are representations of logical relationships between the words in a sentence .Every predicate structure contains a predicate , which is either a verb or a preposition , and a set of arguments , which may be any part of speech .", "label": "", "metadata": {}, "score": "62.908386"}
{"text": "Predicate structures are representations of logical relationships between the words in a sentence .Every predicate structure contains a predicate , which is either a verb or a preposition , and a set of arguments , which may be any part of speech .", "label": "", "metadata": {}, "score": "62.908386"}
{"text": "Active learning methods optimize the interaction between a computational method and a human expert by preselecting the data that an expert is to devote time or resources on , so that the outcome contributes most beneficially to the computational algorithm .In molecular biology domain however , the reasons for active learning are atypical .", "label": "", "metadata": {}, "score": "62.93122"}
{"text": "More recently , ant colony optimization ( ACO ) [ 8 ] has successfully carried out the extraction of rule - based classifiers .ACO is a nature - inspired optimization metaheuristic based on the behavior and self - organizing capabilities of ant colonies in their search for food .", "label": "", "metadata": {}, "score": "63.154167"}
{"text": "4 gives a perspective inside the Component Detection Module .The Component Detection Module receives the face image .It detects and localizes on the various components in the face image .FIG .5 shows different steps in Preprocessing Module .", "label": "", "metadata": {}, "score": "63.293938"}
{"text": "We present a method for making use of past proof experience called flexiblere - enactment ( FR ) .FR is actually a search - guiding heuristic that uses past proofexperience to create a search bias .Experimental studiessubstantiate and illustrate this claim .", "label": "", "metadata": {}, "score": "63.304317"}
{"text": "In the current exemplary embodiment , the component detector 400 , 401 , and 402 returns the size and location of the components in the face image .Other embodiments of component detectors are also possible .Feature Extraction and Component Information .", "label": "", "metadata": {}, "score": "63.30636"}
{"text": "The system according to this invention , comprise of face detector module for identifying the faces within a digital image .The output of face detector module is fed to component detection module .The component detection module comprises of one or more component detectors to identify various components within the face image .", "label": "", "metadata": {}, "score": "63.350086"}
{"text": "In both cases the control algorithm found is GP , as it has the lowest ranking value .Before analyzing the results obtained , it is important to mention that all algorithms except GP extract rules in the same form , as a conjunction of conditions .", "label": "", "metadata": {}, "score": "63.37231"}
{"text": "In an attempt to defeat the anti - spam development technologies , spammers have recently adopted the image spam trick to make the scrutiny of emails ' body text inefficient .The main idea behind this project is to design a spam detection system .", "label": "", "metadata": {}, "score": "63.40464"}
{"text": "First , the algorithm initializes a new empty list to store the nodes visited by the new ant .Then , it creates a new node n that corresponds to the initial state of the environment and adds this node to the path list .", "label": "", "metadata": {}, "score": "63.41385"}
{"text": "17 is a flow diagram showing how a trained query topic specific classifier identifies the topic of an input query .The whole process is very similar to the operation of the document domain specific classifier .The trained query topic - specific classifier accepts an input query in step 900 .", "label": "", "metadata": {}, "score": "63.4337"}
{"text": "17 is a flow diagram showing how a trained query topic specific classifier identifies the topic of an input query .The whole process is very similar to the operation of the document domain specific classifier .The trained query topic - specific classifier accepts an input query in step 900 .", "label": "", "metadata": {}, "score": "63.4337"}
{"text": "M. Bader - El - Den and R. Poli , \" Generating SAT Local - Search Heuristics using a GP Hyper - Heuristic Framework , \" in Proceedings of the 8th International Conference on Artificial Evolution ( EA'07 ) , pp .", "label": "", "metadata": {}, "score": "63.704674"}
{"text": "Online].International Series in Operations Research and Management Science , F. Glover and G. Kochenberger , Eds .Kluwer Academic Publishers , 2002 , also available as technical report TR / IRIDIA/2000 - 32 , IRIDIA , Universit \u00b4 e Libre de Bruxelles .", "label": "", "metadata": {}, "score": "63.70822"}
{"text": "Euclidean Distance .This is a linear measurement that is one of the simpler classification metrics .It sums the difference between all attributes of two different input objects to determine how similar they are to each other .The equation can look like [ 14 ] : .", "label": "", "metadata": {}, "score": "63.71166"}
{"text": "121 - 144 , march 2010 .[ 13 ] J. F\u00a8 urnkranz , \" Separate - and - conquer rule learning , \" Artif .Intell .Nueva York , EUA : Oxford University , 1999 .27 , no . 2 , pp.129- 154 , 1999 .", "label": "", "metadata": {}, "score": "63.82573"}
{"text": "( 2008)[3 ] argued that spam images are artificially generated , and contain clearer and sharper objects than ham images ; thus , their color distribution should be less smooth .[ 9 ] Moreover , the researchers propounded that the low - level features helped the recipients to achieve the highest discerning capability .", "label": "", "metadata": {}, "score": "63.920815"}
{"text": "9 is a diagram illustrating the Bayes classifier document classification process according to one variation of the present invention ; .FIG .10 is a block diagram of the Bayes classifier query classification according to one variation of the present invention ; .", "label": "", "metadata": {}, "score": "63.969585"}
{"text": "9 is a diagram illustrating the Bayes classifier document classification process according to one variation of the present invention ; .FIG .10 is a block diagram of the Bayes classifier query classification according to one variation of the present invention ; .", "label": "", "metadata": {}, "score": "63.969585"}
{"text": "Each ant of the current generation is able to reinforce the pheromone amount in its path 's transitions only if the quality of the solution encoded by this ant is greater than a threshold value .Then , a delayed pheromone update over the path of this ant takes place .", "label": "", "metadata": {}, "score": "63.99079"}
{"text": "The metrics that we employ here are those that are commonly used in the domain of information retrieval : F - score .F - score is the harmonic mean of the precision and recall .Precision is measured as the percentage of true positives among all predicted interactions ; recall is the percentage of true positives among all real interactions .", "label": "", "metadata": {}, "score": "64.084435"}
{"text": "[Online].Studies in Computational Intelligence , C. Lim , L. Jain , and S. Dehuri , Eds ./ Heidelberg , 2009 , vol .248 , pp .91 - 120 .[Online].36 , pp .", "label": "", "metadata": {}, "score": "64.10306"}
{"text": "Thus , the first four parameters of GBAP are mandatory , and the other six parameters - enclosed into square brackets - are optional , having a default value .For GBAP , the configuration considered in Table III was adopted after carrying out a cross - validation procedure over three data sets ( primary - tumor , hepatitis and wine ) , using values from different ranks for each parameter , and then analyzing which specific set - up globally reported the best values .", "label": "", "metadata": {}, "score": "64.39702"}
{"text": "The component demographic classifiers 800 , 801 , and 802 can be arranged in serial , parallel , or hybrid manner ( see .FIGS .9 , 10 , 11 , and 12 ) .Moreover , the demographic classifiers can also be arranged in serial / parallel / hybrid organization to improve the accuracy .", "label": "", "metadata": {}, "score": "64.57566"}
{"text": "INTRODUCTION As the scope and use of Internet grows the type of information has been more multimedia enriched to attract larger number of users .Electronic mail is currently the most efficacious and sought - after mode of communication .However , like any other dynamic medium , it is prone to misusage .", "label": "", "metadata": {}, "score": "64.596375"}
{"text": "FIG .14 , the demographic categories are arranged in serial configuration .Age / Gender / Ethnicity Classifiers 1400 , 1401 , and 1402 are demographic category classifiers and can be age , gender , or ethnicity .In this configuration the result of the classifiers are dependent on the previous classifier results .", "label": "", "metadata": {}, "score": "64.61359"}
{"text": "Usually , spam filters are designed on the basis of machine learning classification techniques .Structure of a spam filter Incoming messages are handled by the filter one at a time and classified as legitimate or spam .Legitimate messages are destined to the recipient 's inbox which is read frequently .", "label": "", "metadata": {}, "score": "64.72335"}
{"text": "It also adds the newly visited state to the list path .It finishes when a final state is reached and , therefore , the ant has found a solution .Finally , a new ant is created from the list of visited states path .", "label": "", "metadata": {}, "score": "64.72395"}
{"text": "2007 , 8 ( Suppl 10 ) : S6 - 10.1186/1471 - 2105 - 8-S10-S6 .PubMed Central View Article PubMed .Scott MS , Barton GJ : Probabilistic prediction and ranking of human protein - protein interactions .", "label": "", "metadata": {}, "score": "64.92814"}
{"text": "Let N be the length of the vector .The Pearson Correlation Co - efficient is computed between these two vectors as follows , .PP .C . m .GE .m .GE .m .GE .m .", "label": "", "metadata": {}, "score": "64.983246"}
{"text": "GBAP also takes into account the complexity of the rules in the reinforcement , as seen in Section III - E. Finally , an example of a classifier obtained by GBAP on a training fold of the hepatitis data set is shown in Table VIII .", "label": "", "metadata": {}, "score": "65.050064"}
{"text": "1 , the document ontological parser 140 is used by the concept - based search and retrieval system to transform documents into predicate structures for storage in the data repository .The document ontological parser 140 is one of two versions of ontological parser 140 used by the concept based - search and retrieval system 100 .", "label": "", "metadata": {}, "score": "65.072784"}
{"text": "1 , the document ontological parser 140 is used by the concept - based search and retrieval system to transform documents into predicate structures for storage in the data repository .The document ontological parser 140 is one of two versions of ontological parser 140 used by the concept based - search and retrieval system 100 .", "label": "", "metadata": {}, "score": "65.072784"}
{"text": "Therefore , random pairs are usually treated as negative class instances in this domain .For our work , we created training and testing datasets of 10,000 protein pair instances each with 2,000 interacting pairs and 8,000 random pairs .AFA is carried out in batch mode , selecting 500 missing values in each batch .", "label": "", "metadata": {}, "score": "65.217514"}
{"text": "Patent granted to Player , US Pat No .( Application )US20020052881A1 , shows an example of use of demographic information for customizing computer games and advertising .They did not show any method or system for extracting demographic information from images or videos .", "label": "", "metadata": {}, "score": "65.22543"}
{"text": "Jaccard Coefficient .The Jaccard coefficient measures the similarity between datasets .It is a set theoretic measure and can be defined as the intersection of the datasets divided by the union of the datasets .For example , the Jaccard coefficient between .", "label": "", "metadata": {}, "score": "65.28848"}
{"text": "[19 ] Z. Wang and B. Feng , \" Classification rule mining with an improved ant colony algorithm , \" LNAI , vol .3339 , pp .357 - 367 , 2004 .[20 ] C. Chen , Y. Chen , and J. He , \" Neural network ensemble based ant colony classification rule mining , \" Innovative Computing , Information and Control , International Conference on , vol .", "label": "", "metadata": {}, "score": "65.43213"}
{"text": "Inferring informational goals and preferred level of detail of answers based on application employed by the user based at least on informational content being displayed to the user at the query is received .Methods and apparatus for extracting and correlating text information derived from comment and product databases for use in identifying product improvements based on comment and product database commonalities Tools . by Phil Blunsom , Trevor Cohn , Miles Osborne - In Proc . of the 46th Annual Conference of the Association for Computational Linguistics : Human Language Technologies ( ACL-08:HLT , 2008 . \" ...", "label": "", "metadata": {}, "score": "65.45996"}
{"text": "321 - 332 , 2002 .[ 10 ] J. R. Koza , Genetic programming : on the programming of computers by means of natural selection .Cambridge , MA : The MIT Press , 1992 .[11 ] O. Roux and C. Fonlupt , \" Ant programming : or how to use ants for automatic programming , \" in ANTS'2000 , M. Dorigo and E. Al , Eds . , 2000 , pp .", "label": "", "metadata": {}, "score": "65.4856"}
{"text": "The five operating modes of the System are : .Exact match ( end user mode , online mode ) .Document predicate match mode ( offline mode ) .Bayes training mode ( offline mode ) , .Document indexing mode ( offline mode ) , and .", "label": "", "metadata": {}, "score": "65.55855"}
{"text": "The five operating modes of the System are : .Exact match ( end user mode , online mode ) .Document predicate match mode ( offline mode ) .Bayes training mode ( offline mode ) , .Document indexing mode ( offline mode ) , and .", "label": "", "metadata": {}, "score": "65.55855"}
{"text": "claim 20 , further comprising a persistent agent maintaining at least one of said predicate structures extracted from said query , .An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .", "label": "", "metadata": {}, "score": "65.66906"}
{"text": "claim 20 , further comprising a persistent agent maintaining at least one of said predicate structures extracted from said query , .An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .", "label": "", "metadata": {}, "score": "65.66906"}
{"text": "5 for preprocessing .In the current exemplary embodiment , preprocessing module converts the color image to grayscale image , applies histogram equalization and brightness correction , performs rotation and translation and PCA data representation to the digital image .Components .", "label": "", "metadata": {}, "score": "65.68695"}
{"text": "An image spam contains text embedded in the image .Moreover spam image tend to have a rough distribution in the RGB / LAB color space [ 3 ] .Spammers ensure that each image spam is noisy and distinct .This is done by using various obscuring techniques like reposition various items , add noise arbitrarily , alter background or font colors and sizes , add indiscriminate patterns like lines or circles , borders , etc .", "label": "", "metadata": {}, "score": "65.72644"}
{"text": "Active feature acquisition ( AFA ) is a strategy to preselect such instance - feature combinations ( i.e. protein and experiment combinations ) for maximum utility .The goal of AFA is th e creation of optimal training set that would result in the best classifier , and not in determining the best classification model itself .", "label": "", "metadata": {}, "score": "65.727165"}
{"text": "[36 ] M. Boryczka , Z. J. Czech , and W. Wieczorek , \" Ant colony programming for approximation problems , \" in GECCO , 2003 , pp .142 - 143 .[ 37 ] J. Green , J. Whalley , and C. Johnson , \" Automatic programming with ant colony optimization , \" in Proceedings of the 2004 UK Workshop on Computational Intelligence , 2004 , pp .", "label": "", "metadata": {}, "score": "65.764755"}
{"text": "10.1002/prot.20865 .PubMed Central View Article PubMed .Hubble J , Demeter J , Jin H , Mao M , Nitzberg M , Reddy TB , Wymore F , Zachariah ZK , Sherlock G , Ball CA : Implementation of genepattern within the stanford microarray database .", "label": "", "metadata": {}, "score": "65.776596"}
{"text": "All these images were appropriately labeled with the demographic categories of the person(s ) in the image .These labels were used as ground truths to be used during the training of the classifiers .This data set was divided into three parts - the training 1600 , the bootstrapping 1602 , and the testing set 1605 , all of them mutually disjoint .", "label": "", "metadata": {}, "score": "65.7939"}
{"text": "For example , Liu et al .[17 ] presented Ant - Miner2 , where they applied a much simpler heuristic function , acting on the assumption that pheromone reinforcement has enough power to compensate possible errors induced by the use of this less effective heuristic measure .", "label": "", "metadata": {}, "score": "65.82004"}
{"text": "In fact , their algorithm starts by creating a random population of programs ( trees ) using the ramped half - and - half initialization method and storing a table of pheromones for each node of the tree .Each pheromone table holds the amount of pheromone associated with all possible elements ( also named terminals and functions , as GP does ) .", "label": "", "metadata": {}, "score": "65.865204"}
{"text": "In the current embodiment , an Adaboost face detector cascaded with Neural Network based face detector was used for faster detection of face .The output of the face detection module 201 is a rectangular window containing the face of the people in the image .", "label": "", "metadata": {}, "score": "66.07045"}
{"text": "Spammers attempt to decrease filtering effectiveness by deriving new spamming techniques .The reactivity of spammers asks for countermeasures from filter developers , which in the field of spam filtering may be termed as opposing reactivity .The advent of image spam can be considered as a part of the reactivity , and thus the image - based spam filtering as such can be considered an opposition to reactivity .", "label": "", "metadata": {}, "score": "66.120834"}
{"text": "These estimates are then used to encode the new features .From this data , pairs of GO terms ( GO1 , GO2 ) and the number of protein interactions in which each pair occurs n(GO1,GO2 ) are computed .Let 's say Protein A is associated with GO1 , GO2 and Protein B is associated with GO4 and Protein A and Protein B interact .", "label": "", "metadata": {}, "score": "66.22662"}
{"text": "Rule based learning algorithms involve conditional rules consisting of a logic condition as the premise and the consequent as class name .The premise is usually a Boolean expression assigning weights for words that appear in the document representation .For binary weights , conditions stand rather simplified for binary classification where rules contain premises , if certain combination of terms appears or not in the document .", "label": "", "metadata": {}, "score": "66.30467"}
{"text": "Production rules are expressed in prefix notation and should be always derived from the left .Hence each transition from a state i to another state j is triggered after applying a production rule to the first non- terminal symbol of the state i. This design decision was taken for performance reasons , in order to save on computation costs when gauging rule fitness .", "label": "", "metadata": {}, "score": "66.38175"}
{"text": "For intermediate transitions , the measure considered is re- lated to the cardinality of the production rules , and is referred to as Pcard .This component increases the likelihood that a given ant chooses transitions that lead to a greater number of candidate solutions .", "label": "", "metadata": {}, "score": "66.436195"}
{"text": "A populated training set 440 represents the knowledge of a Bayes classifier 130 .In a classifier reasoning stage , a trained Bayes classifier 130 performs question - answering functions based on the knowledge learned from classifier training process .In general , the system will accept an input text .", "label": "", "metadata": {}, "score": "66.656235"}
{"text": "A populated training set 440 represents the knowledge of a Bayes classifier 130 .In a classifier reasoning stage , a trained Bayes classifier 130 performs question - answering functions based on the knowledge learned from classifier training process .In general , the system will accept an input text .", "label": "", "metadata": {}, "score": "66.656235"}
{"text": "Banners detection was done considering the aspect ratio , height , and width .For graphics detection it was assumed that computer - generated graphics contain homogeneous background and less texture .A one - class classifier ( a SVM ) was proposed in this work , since a representative set of legitimate emails was unavailable .", "label": "", "metadata": {}, "score": "66.767456"}
{"text": "The attribute extractor 400 will collect all attributes from the sample queries , and generate Example set 410 .The value assign to each query example is the topic 's name .Besides including a filter stop words process , attribute extractor 410 , for the query - topic - specific classifier , includes a process to expand the attributes based on its meaning in the sample queries .", "label": "", "metadata": {}, "score": "66.77973"}
{"text": "The attribute extractor 400 will collect all attributes from the sample queries , and generate Example set 410 .The value assign to each query example is the topic 's name .Besides including a filter stop words process , attribute extractor 410 , for the query - topic - specific classifier , includes a process to expand the attributes based on its meaning in the sample queries .", "label": "", "metadata": {}, "score": "66.77973"}
{"text": "As it can be observed , GBAP ( 17 ) seems to have more parameters than the other ACO - based algorithms , and it may be a disadvantage for the final user .Nevertheless , the other ACO algorithms also have parameters that are hidden for the final user .", "label": "", "metadata": {}, "score": "66.8393"}
{"text": "It can be seen that the AFA system achieves the peak F - score after acquiring about 4,200 missing feature values ( indicated by red square marker on the figure ) .To achieve a similar F - score with a training data created with random - acquisition , almost 9,500 feature values had to be acquired .", "label": "", "metadata": {}, "score": "66.8816"}
{"text": "The data repository 150 manages data persistence and provides methods for data storage and retrieval .The data repository 150 hides the storage implementation details to the rest of the system by providing a general set of methods and interfaces for data access .", "label": "", "metadata": {}, "score": "67.134964"}
{"text": "The data repository 150 manages data persistence and provides methods for data storage and retrieval .The data repository 150 hides the storage implementation details to the rest of the system by providing a general set of methods and interfaces for data access .", "label": "", "metadata": {}, "score": "67.134964"}
{"text": "[57 ] D. H. Wolpert and W. G. Macready , \" No free lunch theorems for optimization , \" IEEE Transactions on Evolutionary Computation , vol .1 , no . 1 , pp .67 - 82 , April 1997 .", "label": "", "metadata": {}, "score": "67.22954"}
{"text": "In this mode , query ontological parser 120 parses the user 's query and produces a plurality of predicates , dependent upon the length of the user 's query and the number of entities it contains .The query ontological parser 120 does not perform any generalizations of the users query predicate(s ) in this mode .", "label": "", "metadata": {}, "score": "67.33295"}
{"text": "In this mode , query ontological parser 120 parses the user 's query and produces a plurality of predicates , dependent upon the length of the user 's query and the number of entities it contains .The query ontological parser 120 does not perform any generalizations of the users query predicate(s ) in this mode .", "label": "", "metadata": {}, "score": "67.33295"}
{"text": "[ 38 ] M. Boryczka , \" Eliminating introns in ant colony programming , \" Fun- dam .Inf . , vol .68 , no . 1 - 2 , pp . 1 - 19 , 2005 .[ 39 ] - , \" Ant colony programming with the candidate list , \" LNAI , vol .", "label": "", "metadata": {}, "score": "67.42325"}
{"text": "1 shows the overall system setup that provides the hardware and application context for the present invention .The hardware , for the current exemplary embodiment , comprise of an image - capturing device 100 which acquires the image of a user 103 standing in front of the system and a computing device 101 .", "label": "", "metadata": {}, "score": "67.54362"}
{"text": "claim 7 , wherein said demographic information comprises one or a plurality of demographic categories that further comprises two or more demographic sub - categories , . whereby the demographic categories include age , gender , or ethnicity , and whereby the demographic sub - categories include male , female for the gender demographic category .", "label": "", "metadata": {}, "score": "67.59161"}
{"text": "The higher is the pheromone level in a path , the higher is the probability that a given ant will follow this path .ACO algorithms were initially applied to combinatorial optimization problems [ 15 ] , finding optimal or near optimal solutions .", "label": "", "metadata": {}, "score": "67.6125"}
{"text": "E .f .i . ) k .K .P .f .i .V . k . )U .f .i .V . k . )U .f .i . )A .", "label": "", "metadata": {}, "score": "67.744675"}
{"text": "claim 7 , wherein the method further comprises a step of using one or a plurality of demographic classifiers , . wherein said demographic classifier comprises a combination of two or more steps of a ) data collection , . wherein the data is divided into three mutually disjoint parts , including training set , bootstrapping set , and testing set , .", "label": "", "metadata": {}, "score": "67.82564"}
{"text": "A method of performing concept - based searching of text documents as recited in .claim 1 , wherein said predicate is one of a verb and a preposition .A method of performing concept - based searching of text documents as recited in .", "label": "", "metadata": {}, "score": "67.8578"}
{"text": "P .w .W .n .c .j . )i .P .w .i .c .j . )The Bayes classifier 130 is a tool for answering question of rigid form based on a collection of example answers .", "label": "", "metadata": {}, "score": "67.933945"}
{"text": "P .w .W .n .c .j . )i .P .w .i .c .j . )The Bayes classifier 130 is a tool for answering question of rigid form based on a collection of example answers .", "label": "", "metadata": {}, "score": "67.933945"}
{"text": "method .Manuscript has been prepared by MT and MG with relevant contribution from TS .Authors ' Affiliations .Department of Biomedical Informatics , School of Medicine , University of Pittsburgh .Intelligent Systems Program , School of Arts and Sciences , University of Pittsburgh .", "label": "", "metadata": {}, "score": "67.99175"}
{"text": "The first algorithm that applied ACO to rule induction was Ant - Miner [ 9 ] , and it has become the most referred - to ACO algorithm in this field .It follows a separate- and - conquer approach where , starting from a training set and an empty set of rules , it finds new rules to be added to the set of discovered rules .", "label": "", "metadata": {}, "score": "67.999405"}
{"text": "5 ] Gordon V. Cormack , \" Email Spam Filtering :A Systematic Review \" , Foundations and TrendsR in Information Retrieval Vol . 1 , No . 4 335 - 455 , 2008 .[ 6 ] Sanz EP , Hidalgo Gomez JM , P\u00e9rez Cortizo JC . , \" Email Spam Filtering \" , Advances in Computers Volume 74 , Elsevier , Pages 45 - 114 , 2008 .", "label": "", "metadata": {}, "score": "68.139885"}
{"text": "Adjective filter checks each adjective for a noun following the adjective .The noun must follow either immediately after the adjective , or have only adjective and conjunction words appearing between the noun and the adjective .If no such noun is found , the adjective filter will veto the sentence .", "label": "", "metadata": {}, "score": "68.284485"}
{"text": "Adjective filter checks each adjective for a noun following the adjective .The noun must follow either immediately after the adjective , or have only adjective and conjunction words appearing between the noun and the adjective .If no such noun is found , the adjective filter will veto the sentence .", "label": "", "metadata": {}, "score": "68.284485"}
{"text": "Sebasti \u00b4 an Ventura was born in Cordoba , Spain , in 1966 .He received the B.Sc . and Ph.D. degrees from the University of Cordoba , in 1989 and 1996 , respectively .He is currently Associate Professor in the De- partment of Computer Science and Numerical Anal- ysis , the University of Cordoba , where he heads the Knowledge Discovery and Intelligent Systems Research Laboratory .", "label": "", "metadata": {}, "score": "68.33333"}
{"text": "227 - 239 , 2005 .[ 7 ] K. C. Tan , Q. Yu , C. M. Heng , and T. H. Lee , \" Evolutionary computing for knowledge discovery in medical diagnosis , \" Artificial Intelligencein Medicine , vol .", "label": "", "metadata": {}, "score": "68.358894"}
{"text": "presenting said matched predicate structures from said text documents .A method of performing concept - based searching of text documents as recited in .claim 1 , wherein said predicate is one of a verb and a preposition .A method of performing concept - based searching of text documents as recited in .", "label": "", "metadata": {}, "score": "68.47703"}
{"text": "2010 , 11 ( Suppl 1 ) : S57 - 10.1186/1471 - 2105 - 11-S1-S57 .PubMed Central View Article PubMed .Donmez P , Carbonell J : Proactive learning : cost - sensitive active learning with multiple imperfect oracles .", "label": "", "metadata": {}, "score": "68.50781"}
{"text": "9 , 10 , 11 , and 12 ) .Furthermore , the demographic category classifier ( such as age / ethnicity / gender ) can also be arranged in serial / parallel / hybrid manner ( see .FIGS .11 , 12 , 13 , and 14 ) to increase the demographic classification accuracy .", "label": "", "metadata": {}, "score": "68.66784"}
{"text": "As shown in FIG .2 , the query ontological parser 120 has five components , namely a sentence lexer 122 , post - lexer filters 123 , a parser 124 , post - parser filters 125 , and an ontology 128 .", "label": "", "metadata": {}, "score": "68.72837"}
{"text": "As shown in FIG .2 , the query ontological parser 120 has five components , namely a sentence lexer 122 , post - lexer filters 123 , a parser 124 , post - parser filters 125 , and an ontology 128 .", "label": "", "metadata": {}, "score": "68.72837"}
{"text": "FIG .5 shows an exemplary embodiment of preprocessing module .Preprocessing module is used for filtering the digital image to improve accuracy in image - processing operations 300 , 700 , 701 , and 702 .This module has Color Space Conversion 500 , Image Enhancement techniques 501 such as Color Histogram , Brightness Correction , Contrast Stretching , etc .", "label": "", "metadata": {}, "score": "68.73741"}
{"text": "This module also transforms the image by Data Representation 505 techniques such as PCA , ICA , LNMF , etc . to generate Output Processed Image 506 , which is used for face detection , component detection and classification .Image - processing operations 300 , 700 , 701 , and 702 might not use all the blocks in .", "label": "", "metadata": {}, "score": "68.91264"}
{"text": "[Online].New York , NY , USA : ACM , 2008 , pp . 111 - 118 .[45 ] - , \" The uphill battle of ant programming vs. genetic programming , \" in IJCCI , 2009 , pp .", "label": "", "metadata": {}, "score": "68.98647"}
{"text": "10.1093/nar / gkg079 .PubMed Central View Article PubMed .Liu X , Yu X , Zack DJ , Zhu H , Qian J : Tiger : a database for tissue - specific gene expression and regulation .BMC Bioinformatics .", "label": "", "metadata": {}, "score": "69.30408"}
{"text": "59 ] D. J. Sheskin , Handbook of Parametric and Nonparametric Statistical Procedures .Chapman & Hall / CRC , 2007 .Springer Berlin Heidelberg : Physica - Verlag , and S. Ventura,\"A niching Juan Luis Olmo was born in Cordoba , Spain , in 1984 .", "label": "", "metadata": {}, "score": "69.37569"}
{"text": "The Hierarchical Fusion 803 model uses the classifier results from component demographic classifiers 800 , 801 , and 802 for training , bootstrapping , and testing the Hierarchical Fusion 803 classifier ( see .FIG . 8 ) .The component information 203 , 204 , and 205 from each component may be preprocessed 701 , 701 , and 702 differently to improve the accuracy of each component demographic classifiers 800 , 801 , and 802 .", "label": "", "metadata": {}, "score": "69.60317"}
{"text": "When domain specific classifiers are retrained , the new training set data is stored in the data repository 150 in two ways : for retrieving ontology data , and for storing and retrieving predicate library structures .As training queries are processed , the query predicate libraries generated by the query ontological parser 120 and matching document predicate libraries from the document ontological parser 140 are stored together within the data repository 150 for later user query .", "label": "", "metadata": {}, "score": "69.64654"}
{"text": "When domain specific classifiers are retrained , the new training set data is stored in the data repository 150 in two ways : for retrieving ontology data , and for storing and retrieving predicate library structures .As training queries are processed , the query predicate libraries generated by the query ontological parser 120 and matching document predicate libraries from the document ontological parser 140 are stored together within the data repository 150 for later user query .", "label": "", "metadata": {}, "score": "69.64654"}
{"text": "CONCLUSION With the increasing importance of email and the incursions of Internet marketers , unsolicited commercial email ( also known as spam ) has become a major problem on the Internet .To detect image spam , computer vision and pattern recognition techniques are also required , and indeed several techniques have been recently proposed .", "label": "", "metadata": {}, "score": "69.656235"}
{"text": "Referring to FIG .3 , the Bayes classifier 130 has two main components , a learner 132 and a reasoner 134 .The learner 132 is responsible for training the classifier .Before the classifier 130 is trained , it is totally na\u00efve and can not properly classify text .", "label": "", "metadata": {}, "score": "69.695114"}
{"text": "Referring to FIG .3 , the Bayes classifier 130 has two main components , a learner 132 and a reasoner 134 .The learner 132 is responsible for training the classifier .Before the classifier 130 is trained , it is totally na\u00efve and can not properly classify text .", "label": "", "metadata": {}, "score": "69.695114"}
{"text": "Parse tree converter 315 receives the output of the parser 124 , and converts the parse trees into predicates .Following the Parse tree converter , Parser filters 125 operate on the predicates to remove erroneously generated predicates based on rules about the probability of syntactic analyses , as well as rules about the compatibility of concepts with each other .", "label": "", "metadata": {}, "score": "69.82683"}
{"text": "Parse tree converter 315 receives the output of the parser 124 , and converts the parse trees into predicates .Following the Parse tree converter , Parser filters 125 operate on the predicates to remove erroneously generated predicates based on rules about the probability of syntactic analyses , as well as rules about the compatibility of concepts with each other .", "label": "", "metadata": {}, "score": "69.82683"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 22 , wherein said parser comprises a parse tree converter for converting parse trees into predicate structures .An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .", "label": "", "metadata": {}, "score": "69.873924"}
{"text": "An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .claim 22 , wherein said parser comprises a parse tree converter for converting parse trees into predicate structures .An apparatus for use in an information retrieval system for retrieving information in response to a query as recited in .", "label": "", "metadata": {}, "score": "69.873924"}
{"text": "Declarations .Acknowledgements .This work has been funded in part by the BRAINS grant R01MH094564 awarded to MG by the National Institute of Mental Health of National Institutes of Health ( NIMH / NIH ) of USA .Authors would like to thank Dr. Jaime Carbonell for discussions that lead to the development of this approach .", "label": "", "metadata": {}, "score": "69.882645"}
{"text": "The transition rule will assign a probability to each available next state .The algorithm arranges that each possible transition can reach at least one final state or solution in the number of derivations that remain available at that point .If not , those transitions will be assigned a probability of zero and , therefore , the ant will never select such movements .", "label": "", "metadata": {}, "score": "69.88667"}
{"text": "Stop words are words that serve only as placeholders in English - language sentences .The stop word filter will contain a set of words accepted as stop words ; any lexeme whose text is in that set is considered to be a stop word .", "label": "", "metadata": {}, "score": "69.96858"}
{"text": "Stop words are words that serve only as placeholders in English - language sentences .The stop word filter will contain a set of words accepted as stop words ; any lexeme whose text is in that set is considered to be a stop word .", "label": "", "metadata": {}, "score": "69.96858"}
{"text": "Patent granted to Viola , US Pat No .( Application )US20020102024A1 , describes a method for object detection using integral image representation of the input image .The object detector uses cascade of homogenous classification functions or classifiers .Their invention defines a fast method for object detection using rectangular components defined by wavelets .", "label": "", "metadata": {}, "score": "70.00578"}
{"text": "Either side of the centre value are two sets with 0.175 percentages and then a distribution change of \u00b13.0 .The next distribution was 14 - 16 or 4 - 6 , selected 7.5 % of the time .Finally , the distribution of either the values 17 - 19 or 1 - 3 would be selected 5 % of the time .", "label": "", "metadata": {}, "score": "70.47269"}
{"text": "degree from the University Oberta of Catalonia , Barcelona , in 2007 , both in Computer Science .His research interests include the application of evolutionary computation and swarm intelligence to data mining .Juan Luis Olmo is a Member of the IEEE Computer , Computational Intelligence and Systems , Man and Cybernetics societies and the Association of Computing Machinery Special Interest Group on Genetic and Evolutionary Computation .", "label": "", "metadata": {}, "score": "70.50666"}
{"text": "In current embodiment , a PIII 864 Mhz , 512 MB RAM , 80 GB HDD was used as the computing device 101 and PYRO 1394 web cam by ADS technologies was used as image - capturing device 100 .In the current exemplary embodiment , the computer is fed with the digital image 200 of the scene .", "label": "", "metadata": {}, "score": "70.5161"}
{"text": "A method of cross validation could be used to get classifier 1601 .The different parameters that could be changed are the classification algorithm , kernels , and the kernel parameters .Once the best classifier is found from the cross validation method 1603 , the misclassified examples could be used in the bootstrapping 1602 process to further refine the classifier .", "label": "", "metadata": {}, "score": "70.518005"}
{"text": "We have compared GBAP with other representative rule- induction algorithms : three state - of - the - art algorithms ( Ant- Miner , Ant - Miner+ and PSO / ACO2 ) , a GP algorithm , and two .Page 14 .", "label": "", "metadata": {}, "score": "70.80315"}
{"text": "The Kullback - Leibler information divergence is a measure of the difference between two probability distributions .As described in Wikipedia : it can be used as a distance metric and measures the expected number of extra bits required to code samples from .", "label": "", "metadata": {}, "score": "71.136185"}
{"text": "WordNet \u2122 is used in the example embodiment discussed below ; however , any ontology 128 may be used .The sole function of the query ontological parser 120 is to use the five components to create predicate structures , which are then used as keys to search the data repository for documents which match the query of the user .", "label": "", "metadata": {}, "score": "71.223434"}
{"text": "WordNet \u2122 is used in the example embodiment discussed below ; however , any ontology 128 may be used .The sole function of the query ontological parser 120 is to use the five components to create predicate structures , which are then used as keys to search the data repository for documents which match the query of the user .", "label": "", "metadata": {}, "score": "71.223434"}
{"text": "The document ontological parser 140 employs the following filters : proper noun filter , adjective filter , adverb filter , modal verb filter , and stop word filter .The query ontological parser 120 makes use of all these filters , but adds a pseudo - concept filter .", "label": "", "metadata": {}, "score": "71.35226"}
{"text": "The document ontological parser 140 employs the following filters : proper noun filter , adjective filter , adverb filter , modal verb filter , and stop word filter .The query ontological parser 120 makes use of all these filters , but adds a pseudo - concept filter .", "label": "", "metadata": {}, "score": "71.35226"}
{"text": "13 is flow chart of an example of classification training flow according to one variation of the present invention ; .FIG .14 is a flow chart illustrating an example of the classification process according to one variation of the present invention ; .", "label": "", "metadata": {}, "score": "71.36223"}
{"text": "13 is flow chart of an example of classification training flow according to one variation of the present invention ; .FIG .14 is a flow chart illustrating an example of the classification process according to one variation of the present invention ; .", "label": "", "metadata": {}, "score": "71.36223"}
{"text": "d .D .D . where , .D1 is the set of domains in protein P1 .D2 is the set of domains in protein P2 .score(d1,d2 ) is the interaction score between the domains d1 and d2 .", "label": "", "metadata": {}, "score": "71.44966"}
{"text": "Furthermore , the component feature extractor 403 , 404 , and 405 may be used to locate other information within the feature like corner points , contours , gradient changes , etc .This representation of the image is finally fed to the classifier to extract the demographic information 102 .", "label": "", "metadata": {}, "score": "71.65075"}
{"text": "This classification algorithm can be substituted with existing classification algorithm or classification algorithm discovered in future .The current embodiment should not be treated as a restriction of the scope of this invention .Support Vector Machine .In the current exemplary embodiment , the classification technique used is the support vector machines ( SVM ) .", "label": "", "metadata": {}, "score": "71.65357"}
{"text": "Hence , the predictive accuracy obtained on a given data set is considered as the average accuracy over these ten folds , described as j ?In addition , to avoid any chance of obtaining biased results when evaluating the performance of stochastic algorithms , ten executions per fold were performed , using ten different seeds .", "label": "", "metadata": {}, "score": "71.82083"}
{"text": "Feature extraction increases accuracy by removing redundant or misleading information within the image .Moreover , it also improves the computational speed of the classifiers , which forms an important aspect for any real time system .FIG .6 shows an exemplary embodiment of the component information 203 , 204 , and 205 .", "label": "", "metadata": {}, "score": "71.90304"}
{"text": "The first rule is that any word relating to the user , or his current situation , such as \" I \" or \" me \" is always deleted .The second rule is that any of the \" information\"-type words is deleted when followed by a preposition .", "label": "", "metadata": {}, "score": "72.06596"}
{"text": "The first rule is that any word relating to the user , or his current situation , such as \" I \" or \" me \" is always deleted .The second rule is that any of the \" information\"-type words is deleted when followed by a preposition .", "label": "", "metadata": {}, "score": "72.06596"}
{"text": "Email Anti Spam ( CEAS ) , 2007 .Proc .The present invention includes a system and method for automatically extracting the demographic information from images .The present invention includes a system and method for automatically extracting the demographic information from images .", "label": "", "metadata": {}, "score": "73.06825"}
{"text": "Long distance reordering remains one of the greatest challenges in statistical machine translation research as the key contextual information may well be beyond the confine of translation units .In this paper , we propose Two - Neighbor Orientation ( TNO ) model that jointly models the orientation decisi ... \" .", "label": "", "metadata": {}, "score": "73.21614"}
{"text": "4 .A Document iterator 210 receives documents or text input 205 , and outputs individual sentences to the lexer 122 .As the lexer 122 receives each sentence , it passes each individual word to the ontology 128 .If the word exists within the ontology 128 , it is returned as an ontological entity ; if not , it is returned as a word tagged with default assumptions about its ontological status .", "label": "", "metadata": {}, "score": "73.39854"}
{"text": "4 .A Document iterator 210 receives documents or text input 205 , and outputs individual sentences to the lexer 122 .As the lexer 122 receives each sentence , it passes each individual word to the ontology 128 .If the word exists within the ontology 128 , it is returned as an ontological entity ; if not , it is returned as a word tagged with default assumptions about its ontological status .", "label": "", "metadata": {}, "score": "73.39854"}
{"text": "This new classifier 1604 is again tested with the bootstrapping images and the process is continued until the best classifier is obtained .Classifier Fusion .The component information 203 , 204 , and 205 is used for making the demographic classifiers .", "label": "", "metadata": {}, "score": "73.41417"}
{"text": "During document indexing mode each component 's function is examined by tracing the path of a complex , but typical , sentence from the Wall Street Journal as it passes through the concept based search and retrieval system 100 .Specifically , the first sentence from the lead story of the Money & Investing section of the Wall Street Journal Interactive Edition on Friday , Oct. 22 , 1999 is shown as follows : . \" Financial shares led a strong rally in the stock market Friday as investors cheered an agreement by lawmakers and the Clinton administration that removes a key obstacle to legislation that would overhaul the financial - services industry .", "label": "", "metadata": {}, "score": "73.42912"}
{"text": "During document indexing mode each component 's function is examined by tracing the path of a complex , but typical , sentence from the Wall Street Journal as it passes through the concept based search and retrieval system 100 .Specifically , the first sentence from the lead story of the Money & Investing section of the Wall Street Journal Interactive Edition on Friday , Oct. 22 , 1999 is shown as follows : . \" Financial shares led a strong rally in the stock market Friday as investors cheered an agreement by lawmakers and the Clinton administration that removes a key obstacle to legislation that would overhaul the financial - services industry .", "label": "", "metadata": {}, "score": "73.42912"}
{"text": "Finally , we present an empirical study demonstrating that the suggested changes lead to 10 - 30 % improvements in F1 scores versus an accepted competitive baseline , hierarchical SVMs . by Bharath Hariharan , Lihi Zelnik - manor , S. V. N. Vishwanathan , Manik Varma . \" ...", "label": "", "metadata": {}, "score": "73.754974"}
{"text": "Furthermore , the noun sense of \" face \" is eliminated by the fact that \" with arms down \" includes the concepts of position and body , and one sense of the verb \" face \" matches that conception .In addition to the na\u00efve semantic lexicon , a formal semantics module is incorporated , which permits sentences to be evaluated for truth conditions with respect to a model built by the coherence module .", "label": "", "metadata": {}, "score": "73.847595"}
{"text": "Furthermore , the noun sense of \" face \" is eliminated by the fact that \" with arms down \" includes the concepts of position and body , and one sense of the verb \" face \" matches that conception .In addition to the na\u00efve semantic lexicon , a formal semantics module is incorporated , which permits sentences to be evaluated for truth conditions with respect to a model built by the coherence module .", "label": "", "metadata": {}, "score": "73.847595"}
{"text": "Sinuhe is fast and memory efficient , and the BLEU scores obtained by it are only slightly inferior to those of Moses . ... nt reduction in the amount of training data ( 24 % in ( Blunsom et al . , 2008 ) ) .", "label": "", "metadata": {}, "score": "73.849464"}
{"text": "III .GBAP : GRAMMAR BASED ANT PROGRAMMING ALGORITHM In this section we describe the main features of Grammar Based Ant Programming ( GBAP ) algorithm .In short , GBAP is an automatic programming algorithm that uses ACO as its search technique and which is also guided by a context - free grammar .", "label": "", "metadata": {}, "score": "74.05182"}
{"text": "The algorithm is based on a simple theorem of probability known as Bayes ' theorem or Bayes ' formula .Mathematically , the formula is represented as .P .c .j .D . )P .D .c .", "label": "", "metadata": {}, "score": "74.175316"}
{"text": "The algorithm is based on a simple theorem of probability known as Bayes ' theorem or Bayes ' formula .Mathematically , the formula is represented as .P .c .j .D . )P .D .c .", "label": "", "metadata": {}, "score": "74.175316"}
{"text": "10.1038/nmeth.1280 .PubMed Central View Article PubMed .Qi Y , Klein - Seetharaman J , Bar - Joseph Z : Random forest similarity for protein - protein interaction prediction from multiple sources .Pac Symp Biocomput .Qi Y , Klein - Seetharaman J , Bar - Joseph Z : A mixture of feature experts approach for protein - protein interaction prediction .", "label": "", "metadata": {}, "score": "74.30921"}
{"text": "Mishra G , Suresh M , Kumaran K , Kannabiran N , Suresh S , Prasad T , Pandey A , Bala P , Shivakumar K , Anuradha N , et al : Human protein reference database--2006 Update .Nucleic Acids Res .", "label": "", "metadata": {}, "score": "74.33632"}
{"text": "In .FIG .13 , the demographic categories are arranged in parallel configuration .Age Classifier 1300 , Gender Classifier 1301 , and Ethnicity Classifier 1302 works independently and does not influence the Age Output 1303 , Gender Output 1304 , and Ethnicity Output 1305 .", "label": "", "metadata": {}, "score": "74.34476"}
{"text": "Note that 8 selected 3.5 times relates to doubling up on either 8 or 12 ( both sides ) , selected 1.75 times each , and so forth .The difference is being measured here and not the exact total .This gives a total average of .", "label": "", "metadata": {}, "score": "74.77371"}
{"text": "11 shows an exemplary embodiment of hybrid configuration where parallel configuration of a subset of component demographic classifiers 801 and 802 is used in conjunction with serial configuration of another subset of component demographic classifiers 804 and 805 .In another exemplary embodiment ( .", "label": "", "metadata": {}, "score": "74.9725"}
{"text": "7 ) differently to improve the overall accuracy of data level fusion 704 classifier .The preprocessed component information 203 , 204 , and 205 is concatenated into a single vector 703 .This vector is used for training , bootstrapping , and testing of Data Level Fusion 704 classifier .", "label": "", "metadata": {}, "score": "75.07896"}
{"text": "Modal verbs are verbs such as \" should \" , \" could \" , and \" would \" .Such verbs alter the conditions under which a sentence is true , but do not affect the meaning of the sentence .Since truth conditions do not need to be addressed by the ontological parser 120 or 140 , such words can be eliminated to reduce parsing complexity .", "label": "", "metadata": {}, "score": "75.50151"}
{"text": "Modal verbs are verbs such as \" should \" , \" could \" , and \" would \" .Such verbs alter the conditions under which a sentence is true , but do not affect the meaning of the sentence .Since truth conditions do not need to be addressed by the ontological parser 120 or 140 , such words can be eliminated to reduce parsing complexity .", "label": "", "metadata": {}, "score": "75.50151"}
{"text": "3.1.4 Support Vector Machines Support Vector Machines ( SVM ) is very popular in spam classification considering the accuracy with these algorithms .SVMs are defined as an algebraic formula generating maximum margin hyper - plane to separate training instances , with polynomial kernels .", "label": "", "metadata": {}, "score": "76.06096"}
{"text": "In the expression approach the system generates arithmetic expressions in prefix notation from the path followed by the ant in a graph .Green et al .[ 37 ] also presented an AP technique similar to the ACP expression approach .", "label": "", "metadata": {}, "score": "76.11278"}
{"text": "Following that , it would be passed to the lexer 122 , which would access the ontology 128 , and return the sequence : .The - det octopus - noun have - verb a - det heart - noun .Here , \" det \" stands for determiner , which is a word with a purely grammatical function , namely specifying a noun phrase .", "label": "", "metadata": {}, "score": "76.13273"}
{"text": "Following that , it would be passed to the lexer 122 , which would access the ontology 128 , and return the sequence : .The - det octopus - noun have - verb a - det heart - noun .Here , \" det \" stands for determiner , which is a word with a purely grammatical function , namely specifying a noun phrase .", "label": "", "metadata": {}, "score": "76.13273"}
{"text": "An image spam email can be defined as a HTML formatted document , which usually constitute non-suspicious text and an embedded image sent as an attachment .The message is conveyed by the embedded image and most email clients show the message with full totality .", "label": "", "metadata": {}, "score": "76.35327"}
{"text": "AutoCoDe outperforms Otter even when assuming veryfavorable conditions for Otter .In this report we present a case study of employing goal - oriented heuristics whenproving equational theorems with the ( unfailing ) Knut - Bendix completion proce - dure .The theorems are taken from the domain of lattice ordered groups .", "label": "", "metadata": {}, "score": "76.71869"}
{"text": "Spam messages are sent using bulk - mailers and address lists gathered from web pages and newsgroup annals .Radicati in the year 2009 estimated that 247 billion email messages were sent per day predicted to double by 2013 [ Radicati 2009 ] [ 1 , 2].", "label": "", "metadata": {}, "score": "76.88039"}
{"text": "PubMed Central View Article PubMed .Gomez SM , Rzhetsky A : Towards the prediction of complete protein -- protein interaction networks .Pac Symp Biocomput .Kim WK , Park J , Suh JK : Large scale statistical prediction of protein - protein interaction by potentially interacting domain ( PID ) pair .", "label": "", "metadata": {}, "score": "77.31174"}
{"text": "On NIST MT08 set , our most advanced model brings around +2.0 BLEU and-1.0 TER improvement .A Stochastic Hyperheuristic for Unsupervised Matching of Partial Information .Copyright \u00a9 2012 Kieran Greer .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "77.39661"}
{"text": "The reasoner 134 is the question - answering component of the Bayes classifier 130 .The reasoner 134 is responsible for determining the probability that each pre - classified document is the correct answer to a given question .The reasoner 134 makes a decision based on the knowledge acquired during the learning process .", "label": "", "metadata": {}, "score": "78.00238"}
{"text": "The reasoner 134 is the question - answering component of the Bayes classifier 130 .The reasoner 134 is responsible for determining the probability that each pre - classified document is the correct answer to a given question .The reasoner 134 makes a decision based on the knowledge acquired during the learning process .", "label": "", "metadata": {}, "score": "78.00238"}
{"text": "At a .Page 13 .To show the significant differences we applied the post - hoc Bonferroni - Dunn test .In turn , GBAP does not perform signifi- cantly worse than Ant - Miner , PSO / ACO2 and PART .", "label": "", "metadata": {}, "score": "78.532104"}
{"text": "These results are captured in Figure 3 , where one can also see that GBAP achieves competitive or even better accuracy results than PART and JRIP .In the first case , the Bonferroni - Dunn critical value is 1.8996 , so that GBAP is significantly more accurate than Ant - Miner+ , Ant - Miner and GP .", "label": "", "metadata": {}, "score": "78.56247"}
{"text": "The data repository 150 stores three different types of data : result data , Bayes data and ontology data .With regards to system initialization , the data repository 150 provides access to stored data for the Bayes classifier 130 and ontological parser 140 .", "label": "", "metadata": {}, "score": "78.90848"}
{"text": "The data repository 150 stores three different types of data : result data , Bayes data and ontology data .With regards to system initialization , the data repository 150 provides access to stored data for the Bayes classifier 130 and ontological parser 140 .", "label": "", "metadata": {}, "score": "78.90848"}
{"text": "Spam filters are a specialized technical fix against spam which helps end - users to keep their mailboxes clean .Spam filters can be operated on Internet Service Providers ( ISPs ) , email servers , or users ' email .International Journal on Natural Language Computing ( IJNLC )", "label": "", "metadata": {}, "score": "79.12024"}
{"text": "For PHam / PSpam , performance was found to improve to 98 % in accuracy .Naive Bayes performed with an accuracy of above 76 % , worse than Maximum Entropy while the decision tree showed an accuracy of 85 % for PHam / SpamArc .", "label": "", "metadata": {}, "score": "79.46595"}
{"text": "PubMed .Qi Y , Dhiman HK , Bhola N , Budyak I , Kar S , Man D , Dutta A , Tirupula K , Carr BI , Grandis J , et al : Systematic prediction of human membrane receptor interactions .", "label": "", "metadata": {}, "score": "79.62307"}
{"text": "The document ontological parser 140 contains the same components as the query ontological parser 120 ; however , the grammar for the document ontological parser 140 is written for declarative sentences , which are the type usually found in documents .The document ontological parser 140 receives documents and passes predicate libraries to the data repository 150 .", "label": "", "metadata": {}, "score": "79.99684"}
{"text": "The document ontological parser 140 contains the same components as the query ontological parser 120 ; however , the grammar for the document ontological parser 140 is written for declarative sentences , which are the type usually found in documents .The document ontological parser 140 receives documents and passes predicate libraries to the data repository 150 .", "label": "", "metadata": {}, "score": "79.99684"}
{"text": "IEEE TRANSACTIONS ON SYSTEMS , MAN , AND CYBERNETICS - PART B : CYBERNETICS4 Boryczka et al .[ 35 ] , [ 36 ] also applied AP to solve symbolic regression problems , calling their method ant colony program- ming ( ACP ) .", "label": "", "metadata": {}, "score": "80.13693"}
{"text": "The Wical system is further described in U.S. Pat .No . 5,940,821 .An example is given therein stating that a document about wine may include the words \" vineyards \" , \" Chardonnay \" , \" barrel fermented \" , and \" French oak \" , which are all words associated with wine .", "label": "", "metadata": {}, "score": "80.83589"}
{"text": "The Wical system is further described in U.S. Pat .No . 5,940,821 .An example is given therein stating that a document about wine may include the words \" vineyards \" , \" Chardonnay \" , \" barrel fermented \" , and \" French oak \" , which are all words associated with wine .", "label": "", "metadata": {}, "score": "80.83589"}
{"text": "Thus , when the sentence passes through the lexer filters 123 , the stop WordFilter removes \" a \" and \" the \" , leaving : . octopus - noun have - verb heart - noun .The sentence is then taken up by the sentence receiver 310 , which passes it to the parser 124 .", "label": "", "metadata": {}, "score": "80.83719"}
{"text": "Thus , when the sentence passes through the lexer filters 123 , the stop WordFilter removes \" a \" and \" the \" , leaving : . octopus - noun have - verb heart - noun .The sentence is then taken up by the sentence receiver 310 , which passes it to the parser 124 .", "label": "", "metadata": {}, "score": "80.83719"}
{"text": "A final state - represented in the figure with a double- border oval - only contains terminal symbols and , therefore represents the evaluatable expression of the antecedent of the rule encoded .Although final states encode an evaluatable antecedent , fulfilling the properties of an artificial ant [ 48 ] , ants have an internal memory to store the path in order to do an offline pheromone update .", "label": "", "metadata": {}, "score": "81.14521"}
{"text": "RELATED WORK In this section , we first present some related work on the application of ACO to classification .We then provide a review of the various AP algorithms published in the literature so far . A. Ant Colony Optimization ACO is an agent - based nature - inspired optimization meta- heuristic placed into swarm intelligence ( SI ) [ 14].", "label": "", "metadata": {}, "score": "82.49431"}
{"text": "[ 32 ] and uses a more accurate class - specific heuristic function .Another key difference of Ant - Miner+ lies in the value selected for the heuristic and the pheromone exponent parameters - \u03b1 and \u03b2 .In fact , it introduces a range for each parameter and lets the ants choose suitable values in an autonomous way .", "label": "", "metadata": {}, "score": "82.90138"}
{"text": "The operating modes represent the various ways in which the previously discussed components can interact .In Bayes training mode , shown in FIG .7 , the object is to train the Bayes classifier 130 to learn membership criteria for a specific topic .", "label": "", "metadata": {}, "score": "83.37944"}
{"text": "The operating modes represent the various ways in which the previously discussed components can interact .In Bayes training mode , shown in FIG .7 , the object is to train the Bayes classifier 130 to learn membership criteria for a specific topic .", "label": "", "metadata": {}, "score": "83.37944"}
{"text": "Therefore , there are significant differences between the algorithms .The subsequent application of the Bonferroni- Dunn test revealed that GBAP performs significantly better than Ant - Miner+ and PSO / ACO2 in this aspect .Another conclusion of this test is that GBAP is not significantly better than GP , Ant - Miner , JRIP and PART , neither significantly worse than these algorithms , which is more important .", "label": "", "metadata": {}, "score": "84.42154"}
{"text": "SPAM MESSAGE AND SPAM FILTERING The Spam Track at the Text Retrieval Conference ( TREC ) defines email spam as [ 5 ] : \" Unsolicited , unwanted email that was sent indiscriminately , directly or indirectly , by a sender having no current relationship with the recipient . \" Email spam , also known as unsolicited bulk Email ( UBE ) , junk mail , or unsolicited commercial email ( UCE ) , can thus be defined as the system of sending innumerable undesired email messages , featuring commercial content to an indiscriminate set of recipients .", "label": "", "metadata": {}, "score": "85.88042"}
{"text": "\" If the comparison and sorting algorithm does not find any documents with predicate structures indicating that Botswana has biological weapons in the data repository 150 , the answer returned may be : no documents found .However , the comparison and sorting algorithm may determine that some documents containing related information exist .", "label": "", "metadata": {}, "score": "86.790985"}
{"text": "\" If the comparison and sorting algorithm does not find any documents with predicate structures indicating that Botswana has biological weapons in the data repository 150 , the answer returned may be : no documents found .However , the comparison and sorting algorithm may determine that some documents containing related information exist .", "label": "", "metadata": {}, "score": "86.790985"}
{"text": "This increased the number of images in the Spam Archive dataset by a high value .Accuracy increased to 98 % on PHam / PSpam .Interestingly , accuracy on PHam / SpamArc increased to 97 % for the Maximum Entropy technique , reaching a level comparable to personal spam .", "label": "", "metadata": {}, "score": "87.08415"}
{"text": "Yes .w .w .w .n . )P .Yes .i .n .P .w .i .YES .P .No .D . )P .No . w .w .", "label": "", "metadata": {}, "score": "87.73036"}
{"text": "Yes .w .w .w .n . )P .Yes .i .n .P .w .i .YES .P .No .D . )P .No . w .w .", "label": "", "metadata": {}, "score": "87.73036"}
{"text": "\" What happened in the stock market Friday ?The query is received by the query ontological parser 120 , which converts it into one or more predicates depending on the search mode invoked .These predicates are then used to search the data repository 150 .", "label": "", "metadata": {}, "score": "88.17137"}
{"text": "\" What happened in the stock market Friday ?The query is received by the query ontological parser 120 , which converts it into one or more predicates depending on the search mode invoked .These predicates are then used to search the data repository 150 .", "label": "", "metadata": {}, "score": "88.17137"}
{"text": "Do \" only serves to fill a grammatical role within this type of question , and is thus removed , leaving : . octopus - noun have - verb heart - noun .This is identical to the sentence produced above , and results in the same parse tree , and the same predicate structure .", "label": "", "metadata": {}, "score": "90.43061"}
{"text": "Do \" only serves to fill a grammatical role within this type of question , and is thus removed , leaving : . octopus - noun have - verb heart - noun .This is identical to the sentence produced above , and results in the same parse tree , and the same predicate structure .", "label": "", "metadata": {}, "score": "90.43061"}
{"text": "FIG .4 shows an exemplary embodiment of the component detection module 202 .Component detection module 202 takes the face image 304 generated by face detection module 201 and performs more image - processing operations 300 for improved detection of components .", "label": "", "metadata": {}, "score": "93.12366"}
{"text": "15 where Left Eyebrow 1501 , Right Eyebrow 1502 , Left Eye 1503 , Right Eye 1506 , Nose 1505 , Mouth 1508 , Chin 1507 , Skin color information 1504 , and contour information 1500 of the face are used .", "label": "", "metadata": {}, "score": "94.00914"}
{"text": "11 .A parse tree converter 450 then converts this tree into a predicate , where octopus is the subject of have , and heart is the object .The predicate is : . have .This predicate is then passed through the parser filters 125 , where it successfully passes the parse probability and selectional feature compatibility tests .", "label": "", "metadata": {}, "score": "95.46414"}
{"text": "11 .A parse tree converter 450 then converts this tree into a predicate , where octopus is the subject of have , and heart is the object .The predicate is : . have .This predicate is then passed through the parser filters 125 , where it successfully passes the parse probability and selectional feature compatibility tests .", "label": "", "metadata": {}, "score": "95.46414"}
{"text": "Suppose that a user asks the question , \" Do octopuses have hearts ?The question will be read by the sentence lexer 122 , and a sentence made of ontological entities is produced .It reads : .Do - verb octopus - noun have - verb heart - noun .", "label": "", "metadata": {}, "score": "98.21022"}
{"text": "Suppose that a user asks the question , \" Do octopuses have hearts ?The question will be read by the sentence lexer 122 , and a sentence made of ontological entities is produced .It reads : .Do - verb octopus - noun have - verb heart - noun .", "label": "", "metadata": {}, "score": "98.21022"}
{"text": "All the modules are defined in more detail in the following paragraphs .In .FIG .3 , the face detection module 201 takes the input digital image 200 from the image - capturing device 100 and performs image - processing operations 300 ( see .", "label": "", "metadata": {}, "score": "99.45009"}
{"text": "Meghali Das M.TECH CSE ( AI )Don Bosco College of Engineering and Technology Guwahati , Assam 2 .Vijay Prasad Assistant Professor , Don Bosco College of Engineering and Technology , Guwahati , Assam .MTECH CSE ( AI ) International Journal on Natural Language Computing ( IJNLC )", "label": "", "metadata": {}, "score": "99.68542"}
{"text": "The example sentence is : .The octopus has a heart .First , the sentence lexer 122 would process this sentence .The first component of the sentence lexer 122 , the document iterator 210 , would extract this sentence from the document it was contained in .", "label": "", "metadata": {}, "score": "101.43866"}
{"text": "The example sentence is : .The octopus has a heart .First , the sentence lexer 122 would process this sentence .The first component of the sentence lexer 122 , the document iterator 210 , would extract this sentence from the document it was contained in .", "label": "", "metadata": {}, "score": "101.43866"}
{"text": "The component detection module 202 ( see .FIG .4 ) operates on the output of the face detection module 201 .The component detection module 202 detects the components in the face image 304 , extracts interesting features of each component , and generates the component information 203 , 204 , and 205 .", "label": "", "metadata": {}, "score": "104.63104"}
{"text": "As an example , the sentence \" the octopus has three hearts \" produces logical form triples \" have - Dsub - octopus \" , \" have - Dobj - heart \" , and \" heart - Ops - three \" .", "label": "", "metadata": {}, "score": "105.61893"}
{"text": "As an example , the sentence \" the octopus has three hearts \" produces logical form triples \" have - Dsub - octopus \" , \" have - Dobj - heart \" , and \" heart - Ops - three \" .", "label": "", "metadata": {}, "score": "105.61893"}
