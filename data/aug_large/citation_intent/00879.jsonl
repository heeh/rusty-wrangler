{"text": "This model is extended to a hierarchical clustering by Rosen - Zvi et al .( 2004 ) .Teh et al .( 2006 ) generalize further by presenting Hierarchical Dirichlet Processes , a probabilistic model which allows a group ( for us , a document ) to be drawn from an infinite mixture of latent topics , while still allowing these topics to be shared across documents .", "label": "", "metadata": {}, "score": "36.070045"}
{"text": "Cambridge , MA : MIT Press .Blei , D. M. , A. Y. Ng , et al .( 2003 ) .Latent Dirichlet Allocation .Journal of Machine Learning Research 3 : 993 - 1022 .Bloom , H .", "label": "", "metadata": {}, "score": "37.83271"}
{"text": "Bilingual latent semantic analysis Latent Dirichlet - tree allocation Cross - lingual language model adaptation Lexicon adaptation Topic distribution transfer Statistical machine translation .Share .References .Bellegarda JR ( 2000 ) Large vocabulary speech recognition with multispan statistical language models .", "label": "", "metadata": {}, "score": "38.63104"}
{"text": "( 1995 ) .Dumais ( 1993 ) and Dumais ( 1995 ) describe experiments on TREC benchmarks giving evidence that at least on some benchmarks , LSI can produce better precision and recall than standard vector - space retrieval .Sch\u00fctze and Silverstein ( 1997 ) evaluate LSI and truncated representations of centroids for efficient -means clustering ( Section 16.4 ) .", "label": "", "metadata": {}, "score": "39.333122"}
{"text": "Search - based structured prediction .Machine learn- trieval . ing , 75(3 ) , 297 - 325 .Rocchio , J. ( 1971 ) .Relevance feedback in informationDaum \u00b4 III , H. and Marcu , D. ( 2005 ) .", "label": "", "metadata": {}, "score": "39.86467"}
{"text": "our work we explicitly seek to use ( and learn ) inter- document similarity measures .Overall , our preferred version of Latent StructuredRanking that combines all these design decisions is There has been work on taking into account inter - given in Algorithm 1 . document similarities during ranking .", "label": "", "metadata": {}, "score": "41.280388"}
{"text": "Blei D , Ng A , Jordan M ( 2003 ) Latent Dirichlet allocation .J Mach Learn Res 3 : 1107 - 1135 CrossRef .Brown PF , Della Pietra SA , Della Pietra VJ , Mercer RL ( 1994 )", "label": "", "metadata": {}, "score": "41.807648"}
{"text": "In this paper a novel topic model is proposed , which enriches and extends the Latent Dirichlet Allocation ( LDA ) model by integrating such dependencies , encoded in a categorization of genes .The proposed topic model is used to derive a highly informative and discriminant representation for microarray experiments .", "label": "", "metadata": {}, "score": "43.04861"}
{"text": "Comput Linguist 19 : 263 - 311 .Darroch JN , Ratcliff D ( 1972 ) Generalized iterative scaling for log - linear models .Ann Math Stat 43 : 1470 - 1480 CrossRef .Deerwester SC , Dumais ST , Landauer TK , Furnas GW , Harshman RA ( 1990 ) Indexing by latent semantic analysis .", "label": "", "metadata": {}, "score": "43.169125"}
{"text": "The importance of syntactic parsing and inference in semantic role labeling .Comput .Linguist .Wang , X. , Brown , D.E. : The spatio - temporal generalized additive model for crim- inal incidents .ISI ( 2011 ) Abstract .", "label": "", "metadata": {}, "score": "43.74221"}
{"text": "Weiss , D. , Sapp , B. , and Taskar , B. ( 2010 ) . Sidestep-Large margin rank boundaries for ordinal regres- ping intractable inference with structured ensemble sion .Advances in Neural Information Process- 115 - 132 . ing Systems , 23 .", "label": "", "metadata": {}, "score": "44.3045"}
{"text": "Results are somewhat contradictory to Goldwater and Griffiths , possibly due to the combination of a simpler model and more training data .These three papers all deal with nonparametric models of syntax ( dependency or context - free grammars ) .", "label": "", "metadata": {}, "score": "44.66224"}
{"text": "Hofmann , T. : Unsupervised learning by probabilistic latent semantic analysis .Mach .Learn .42(1 - 2 ) , 177 - 196 ( 2001 ) MATH CrossRef .Jaakkola , T. , Haussler , D. : Exploiting generative models in discriminative classifiers .", "label": "", "metadata": {}, "score": "44.741943"}
{"text": "( 5)at inference time will improve the overall set of rankeditems .What is more , we would prefer model can be cast as a quadratic assignment prob - a model that places more weight on the top items in lem ( Lacoste - Julien et al . , 2006 ) .", "label": "", "metadata": {}, "score": "45.30825"}
{"text": "463 - 468 .Deerwester , S. et al .: Indexing by latent semantic analysis .J. Am .Soc .Inf .Sci .CrossRef .Dessus , P. : Simulating student comprehension with latent semantic analysis to deliver course readings from the Web , Cogn .", "label": "", "metadata": {}, "score": "45.38415"}
{"text": "Nathalie Camelin et al .Unsupervised concept annotation using latent Dirichlet allocation and segmental methods , In Proceedings of the EMNLP Workshop on Unsupervised Learning in NLP , 2011 .Avishay Livne et al .Networks and language in the 2010 election , In Proceedings of the 4th Annual Political Networks Conference , 2011 .", "label": "", "metadata": {}, "score": "45.669575"}
{"text": "Word alignment via quadratic assign - Bakir , G. H. , Hofmann , T. , Sch\u00a8lkopf , B. , Smola , o ment .In North American chapter of the Association A. J. , Taskar , B. , and Vishwanathan , S. V. N. for Computational Linguistics ( NAACL ) .", "label": "", "metadata": {}, "score": "46.327984"}
{"text": "References Hofmann , T. ( 1999 ) .Probabilistic latent semantic in- dexing .In SIGIR 1999 , pages 50 - 57 .Bai , B. , Weston , J. , Grangier , D. , Collobert , R. , Joachims , T. ( 2002 ) .", "label": "", "metadata": {}, "score": "46.772263"}
{"text": "Journal of Machine Learning Research , 3:993 - 1022 .( A shorter version appeared in NIPS 2002 ) .These three papers are about Latent Dirichlet Allocation ( a.k.a . topic models ) for learning semantic structure .The Psych Review paper provides a less technical introduction and considers LDA as a cognitive model .", "label": "", "metadata": {}, "score": "47.731415"}
{"text": "When the adapted language model and the adapted translation lexicon are applied simultaneously , the gain is additive .At the 95 % confidence interval of the unadapted baseline system , the gain in both scores is statistically significant using the medium - scale SMT system , while the gain in the NIST score is statistically significant using the GALE SMT system .", "label": "", "metadata": {}, "score": "47.952168"}
{"text": "Our approach is based on the auto- matic semantic analysis and understanding of natural language tweets , combined with dimensionality reduction via latent Dirichlet allocation and prediction via linear modeling .Evaluation results demonstrate the model 's ability to forecast hit - and - run crimes using only the information contained in the training set of tweets .", "label": "", "metadata": {}, "score": "48.129295"}
{"text": "Han Xiao and Thomas Stibor .Efficient Collapsed Gibbs Sampling for Latent Dirichlet Allocation , In Proceedings of the 2nd Asian Conference on Machine Learning ( ACML ) , 2010 , Tokyo .Sanae Fujita et al .MSS : Investigating the effectiveness of domain combinations and topic features for word sense disambiguation , In Proceedings of the 5th International Workshop on Semantic Evaluation , USA , 2010 .", "label": "", "metadata": {}, "score": "48.427322"}
{"text": "Bilingual LSA enables latent topic distributions to be efficiently transferred across languages by enforcing a one - to - one topic correspondence during training .Using the proposed bilingual LSA framework , model adaptation can be performed by , first , inferring the topic posterior distribution of the source text and then applying the inferred distribution to an n -gram language model of the target language and translation lexicon via marginal adaptation .", "label": "", "metadata": {}, "score": "48.687717"}
{"text": "Istvan Biro et al .Latent Dirichlet Allocation in Web Spam Filtering .In Proceedings of the Fourth International Workshop on Adversarial Information Retrieval on the Web , WWW2008 , April 2008 , Beijing , China .Dieu - Thu Le et al .", "label": "", "metadata": {}, "score": "48.791428"}
{"text": "a latent variable model that takes into account theFollowing ( Weston et al . , 2011 ) we employ a feature structure of the predicted ranked list of items givenrepresentation of the images which is an ensemble of the query .Thesee.g .", "label": "", "metadata": {}, "score": "48.830933"}
{"text": "In Grouping Multidimensional Data : Recent Advances In Clustering , ed . by Kogan , J. , Nicholas , C. , Teboulle , M. ( Springer , Berlin Heidelberg , New York 2005 ) pp .187 - 210 .Zesch , T. , M\u00fcller , C. , Gurevych , I. : Extracting lexical semantic knowledge from Wikipedia and Wiktionary .", "label": "", "metadata": {}, "score": "48.945747"}
{"text": "455 - 471 .Graesser , A. C. , et al .:Using latent semantic analysis to evaluate the contributions of students in autotutor .Interact .Learn .Environ . 8 , 129 - 147 ( 2000 ) CrossRef .", "label": "", "metadata": {}, "score": "49.118385"}
{"text": "Semantic Indexing ( SSI ) ( Bai et al . , 2009 ) .Empirical results on large involving thousands of possible labels , latent models scale image annotation and music recommen- have also proven to be very useful , e.g. the Wsabie dation tasks show improvements over existing model achieves state - of - the - art results on large - scale approaches . image ( Weston et al . , 2011 ) and music ( Weston et al .", "label": "", "metadata": {}, "score": "49.209854"}
{"text": "Laham , D. , Bennett , W. , Landauer , T. K. : An LSA - based software tool for matching jobs , people , and instruction , Interact .Learn .Environ . 8 , 171 - 185 ( 2000 ) CrossRef .", "label": "", "metadata": {}, "score": "49.605213"}
{"text": "The output from these systems forms the basis for event prediction , since it informs the model about current events , which ( we hypothesized ) might correlate with future criminal incidents .5 Event - based Topic Extraction via Latent Dirichlet Allocation After processing the tweets with the SRL systems , we have multiple events ei associ- ated with each day .", "label": "", "metadata": {}, "score": "49.94483"}
{"text": "Popular techniques in these studies include keyword volume analysis and sentiment analysis .These methods have proven useful for the tasks mentioned above ; however , a deeper semantic understanding of tweets is required to predict discrete criminal incidents , which are not mentioned ahead of time ( ruling out keyword volume and sentiment analysis ) .", "label": "", "metadata": {}, "score": "49.946148"}
{"text": "The first task of any such placement service is therefore to establish whether these similarities are present for a given learner .The technology with which this is done , latent semantic analysis , is presented here .The emphasis here is on the technical and computational aspects of data preparation and analysis .", "label": "", "metadata": {}, "score": "50.485268"}
{"text": "Strang ( 1986 ) provides an excellent introductory overview of matrix decompositions including the singular value decomposition .Theorem 18.3 is due to Eckart and Young ( 1936 ) .The connection between information retrieval and low - rank approximations of the term - document matrix was introduced in Deerwester et al .", "label": "", "metadata": {}, "score": "50.684452"}
{"text": "For a more in - depth treatment , see also Chapter 5 of my thesis ( above ) .This paper provides a direct comparison between Bayesian methods ( averaging over parameters and estimation using Gibbs sampling ) and standard methods ( estimating parameters directly using EM ) using the same underlying model ( a standard finite HMM ) .", "label": "", "metadata": {}, "score": "50.907375"}
{"text": "Watkins , 1999 ; Crammer and Singer , 2002 ) . org/ ) is a large scale image database to each other ( as they are trained independently ) .Theorganized according to WordNet ( Fellbaum , 1998 ) .multiclass ranking loss of Rank SVM performs muchWordNet is a graph of linguistic terms , where each better ( 5.35 % recall@1 ) but is still outperformed byconcept node consists of a word or word phrase , Wsabie ( 8.39 % recall@1 ) .", "label": "", "metadata": {}, "score": "51.229057"}
{"text": "LDA - based keyword selection in text categorization .In Proceedings of the 24th International Symposium on Computer and Information Sciences , 2009 .Yixun Liu et al .Modeling class cohesion as mixtures of latent topics , In Proceedings of the IEEE International Conference on Software Maintenance , 2009 .", "label": "", "metadata": {}, "score": "51.50153"}
{"text": "Doddington G ( 2002 )Automatic evaluation of MT quality using n - gram co - occurrence statistics .In : Proceedings of human language technology conference 2002 , San Diego , CA , pp 138 - 145 .Griffiths TL , Steyvers M , Blei DM , Tenenbaum JB ( 2004 )", "label": "", "metadata": {}, "score": "51.72126"}
{"text": "Quesada , J. : Creating your own LSA spaces .In Handbook of Latent Semantic Analysis , ed . by Landauer , T. et al .( Erlbaum , Mahwah 2007 ) pp .71 - 85 .Wild , F. , Stahl , C. , Stermsek , G. , Neumann , G. : Parameters driving effectiveness of automated essay scoring with LSA .", "label": "", "metadata": {}, "score": "51.776688"}
{"text": "We need a method for transforming the scores foraging the top ranked items to be a rather diverse set for single documents into scores for permutations .Sucha particular query , then a structured model can learn transformations have been studied in several previousto predict that instead .", "label": "", "metadata": {}, "score": "51.82106"}
{"text": "Diaz - Uriarte , R. , Alvarez de Andres , S. : Gene selection and classification of microarray data using random forest .BMC Bioinformatics 7(1 ) , 3 ( 2006 ) CrossRef .Frey , B. , Dueck , D. : Clustering by passing messages between data points .", "label": "", "metadata": {}, "score": "52.098778"}
{"text": ", trieval .Moreover , it would be interesting to explore1999 ) on the combined feature representation using using other algorithms as the \" base algorithm \" whichthe intersection kernel ( Barla et al . , 2003 ) to produce we add the structured predictions to .", "label": "", "metadata": {}, "score": "52.183765"}
{"text": "In Proceedings of the 30th Inter- national ACM SIGIR Conference on Research and Development in Information Retrieval , pages 271- 278 .Abstract .Topic models have recently shown to be really useful tools for the analysis of microarray experiments .In particular they have been successfully applied to gene clustering and , very recently , also to samples classification .", "label": "", "metadata": {}, "score": "52.223026"}
{"text": "487 - 493 ( 1999 ) .Jordan , M. , Ghahramani , Z. , Jaakkola , T. , Saul , L. : An introduction to variational methods for graphical models .Machine Learning 37(2 ) , 183 - 233 ( 1999 ) MATH CrossRef .", "label": "", "metadata": {}, "score": "52.31052"}
{"text": "The classical method Latent set of top predictions can be either too di- Semantic Indexing ( LSI ) ( Deerwester et al . , 1990 ) is verse ( contain results that contradict each an unsupervised approach that learns from documents other ) or are not diverse enough .", "label": "", "metadata": {}, "score": "52.509136"}
{"text": "We used state - of - the- art natural language processing ( NLP ) techniques to extract the semantic event content of the tweets .With the tweet information alone , our predictive model comfortably outperformed a uniform prediction baseline on held - out data .", "label": "", "metadata": {}, "score": "52.522923"}
{"text": "European Journal of Information Systems 21 , 1 ( Jan. 2012 ) , 70 - 86 .Graesser , A. C. , P. Wiemer - Hastings , K. Wiemer - Hastings , D. Harter & N. Person and the TRG , Using latent semantic analysis to evaluate the contributions of students in AutoTutor , Interactive Learning Environments , 8 ( 2000 ) 128 - 148 .", "label": "", "metadata": {}, "score": "52.754513"}
{"text": "Zhao B , Xing EP ( 2006 ) BiTAM : Bilingual topic admixture models for word alignment .In : Coling \u00b7 ACL 2006 , 21st international conference on computational linguistics and 44th annual meeting of the Association for Computational Linguistics , proceedings of the main conference poster sessions , Sydney , Australia , pp 969 - 976 .", "label": "", "metadata": {}, "score": "52.782963"}
{"text": "In Chap .11 we presented placement in the context of Accreditation of Prior Learning and showed that in the scenario we address we do not assume the availability of controlled vocabulary with which the contents of the learner portfolio or the learning material in the learning network is described .", "label": "", "metadata": {}, "score": "52.863712"}
{"text": "A key feature of LSI is its ability to extract the conceptual content of a body of text by establishing associations between those terms that occur in similar contexts . \"( Deerwester et al , 1988 cited by Wikipedia . \"", "label": "", "metadata": {}, "score": "52.95675"}
{"text": "Section 2 describesmake sure there is the right amount of consistency and our method , Latent Structured Ranking ( LaSR ) .Sec - diversity in the predictions . tion 3 discusses previous work and connects them toLet us suppose for a given query that some of the pre- our method .", "label": "", "metadata": {}, "score": "53.008972"}
{"text": "Bastian , M. , S. Heymann , et al .( 2009 ) .Gephi :An Open Source Software for Exploring and Manipulating Networks .Blei , D. M. , T. L. Griffiths , et al .( 2004 ) .", "label": "", "metadata": {}, "score": "53.137398"}
{"text": "We thus combined mul- problems often involve millions of examples or more , tiple feature representations which are the concatena- both in terms of the number of training pairs and thetion of various spatial ( Grauman and Darrell , 2007 ) number of items to be ranked .", "label": "", "metadata": {}, "score": "53.249794"}
{"text": "Web search clustering and labeling with hidden topics , ACM Transactions on Asian Language Information Processing ( ACM TALIP ) , Vol.8 , No.3 , 2009 .Chenghua Lin and Yulan He .Joint sentiment / topic model for sentiment analysis , In Proceeding of the 18th ACM Conference on Information and Knowledge Management ( ACM CIKM ) , 2009 .", "label": "", "metadata": {}, "score": "53.256367"}
{"text": "As latent parameters are being learnt for For the vanilla model we propose here , however , we caneach query type this is indeed possible .use a simple parameterization which allows for infer- ence by sorting .For any given permutation we assignIn this work we propose a latent modeling algorithm a score as follows : that attempts to do exactly what we describe above .", "label": "", "metadata": {}, "score": "53.578224"}
{"text": "The CMU statistical translation system .In : MT summit IX , proceedings of the ninth machine translation summit , New Orleans , pp 402 - 409 .Zhang Y , Vogel S ( 2004 )Measuring confidence intervals for the machine translation evaluation metrics .", "label": "", "metadata": {}, "score": "53.626453"}
{"text": "In Proceedings of the eighth ACM ( 2009 ) .Polynomial semantic indexing .In Advances SIGKDD , pages 133 - 142 .ACM . in Neural Information Processing Systems ( NIPS Lacoste - Julien , S. , Taskar , B. , Klein , D. , and Jordan , 2009 ) .", "label": "", "metadata": {}, "score": "53.827812"}
{"text": "[ 13 ] to analyze verb - based SRL structures and the system created by Gerber and Chai [ 8 ] to analyze noun - based SRL structures .In general , the SRL systems were well suited to the news tweets , since the systems were trained on news corpora .", "label": "", "metadata": {}, "score": "53.84677"}
{"text": "Improving question recommendation by exploiting information need , In Proceedings of the 49thAnnual Meeting of the Association for Computational Linguistics ( ACL ) , 2011 .Xin Zhao et al .Comparing Twitter and traditional media using topic models .In Proceedings of the 33rd European Conference on Information Retrieval ( ECIR ) , 2011 .", "label": "", "metadata": {}, "score": "53.862442"}
{"text": "Share .References .Ceri , S. , Matera , M. , Raffio , A. , Spoelstra , H. : Flexible processes in project - centred learning .In European Conference on Technology Enhanced Learning , ed by Duval , E. , Klamma , R. , Wolpers , M. Lecture Notes in Computer Science , vol .", "label": "", "metadata": {}, "score": "54.093353"}
{"text": "Stopwords and Stylometry : A Latent DirichletAllocation Approach , In Proceedings of the NIPS Workshop on Applications of Topic Models : Text and Beyond , Canada , 2009 .Kai Tian et al .Using Latent Dirichlet Allocation for automatic categorization of software , In Proceedings 6th IEEE Working Conference on Mining Software Repositories , Canada 2009 .", "label": "", "metadata": {}, "score": "54.438232"}
{"text": "Blei , D.M. , Ng , A.Y. , Jordan , M.I. : Latent dirichlet allocation .J. Mach .Learn .Res .Bollen , J. , Mao , H. , Zeng , X. : Twitter mood predicts the stock market .", "label": "", "metadata": {}, "score": "54.616943"}
{"text": "Note that if a global optimum is reached for each tThe method is as follows . have to compute d0 ( the ranking of items ) for eachtraining example for use in the next iteration .Note So far , the one thing we have failed to mention is reg - that using the sparse w of eq .", "label": "", "metadata": {}, "score": "54.66169"}
{"text": "Chainey , S. , Tompson , L. , Uhlig , S. : The utility of hotspot mapping for predicting spatial patterns of crime .Security Journal 21 , 428 ( 2008 ) 7 .Eck , J. , Chainey , S. , Cameron , J. , Leitner , M. , Wilson , R. : Mapping crime : Under- standing hot spots ( 2005 ) 8 .", "label": "", "metadata": {}, "score": "54.693756"}
{"text": "Introductions .Patterns in Unstructured Data , A Presentation to the Andrew W. Mellon Foundation by Clara Yu , John Cuadrado , Maciej Ceglowski , J. Scott Payne ( undated ) .A good introduction to LSI and its use in search engines .", "label": "", "metadata": {}, "score": "54.740055"}
{"text": "Scoring a single item as in equation ( 1 ) is not the endTraditional latent ranking models score the ith item goal of the tasks described above .The latent space the models described above is that scoring items indi - is n - dimensional , where n D , hence U and V are vidually as in eq .", "label": "", "metadata": {}, "score": "55.013336"}
{"text": "LSA as a theory of meaning .In Handbook of Latent Semantic Analysis , T. Landauer , D. McNamara , S. Dennis , and W. Kintsch , Eds .Lawrence Erlbaum Associates , Mahwah , NJ , 2007 , 3 - 32 .", "label": "", "metadata": {}, "score": "55.2143"}
{"text": "Learning topical transition probabilities in click through data with regression models , In Proceedings of 13th International Workshop on the Web and Databases ( WebDB ) , 2010 .Piotr Mirowski et al .Dynamic Auto - Encoders for Semantic Indexing , In Proceedings of the NIPS Workshop on Deep Learning and Unsupervised Feature Learning , 2010 .", "label": "", "metadata": {}, "score": "55.22602"}
{"text": "Iyer R , Ostendorf M ( 1996 )Modeling long distance dependence in language : topic mixtures vs. dynamic cache models .In : ICSLP 96 , fourth international conference on spoken language processing , Philadelphia , PA , pp 236 - 239 .", "label": "", "metadata": {}, "score": "55.413307"}
{"text": "A Comparative Analysis of Latent Variable Models for Web Page Classification .In Proceedings of the Latin American Web Conference , 2008 .Xuan - Hieu Phan et al .Learning to Classify Short and Sparse Text & Web with Hidden Topics from Large - scale Data Collections .", "label": "", "metadata": {}, "score": "55.453613"}
{"text": "We con- \u00aftop items .the same procedure used in several other works , e.g. ranking structure to make predictions dependent onWeston et al .( 2011 ) ; Bai et al .( 2009 ) .We can opti- the query and the other predicted items during infer - mize hyperparameters of the model such as C and the ence by encoding this in the model itself .", "label": "", "metadata": {}, "score": "55.612732"}
{"text": "( 2005 ) , Loughborough , UK : Loughborough University .Wolfe , M. B. W. , et al .: Learning from text : matching readers and texts by latent semantic analysis , Disc .Proc .25 , 309 - 336 ( 1998 ) CrossRef .", "label": "", "metadata": {}, "score": "55.677998"}
{"text": "The underlying idea is that the totality of information about all the word contexts in which a given word does and does not appear provides a set of mutual constraints that largely determines the similarity of meaning of words and set of words to each other .", "label": "", "metadata": {}, "score": "55.8367"}
{"text": "Support vector machines for multi - class pattern recognition .Weston , J. , Bengio , S. , and Usunier , N. ( 2011 ) .Large scale image annotation : Learning to rank with joint word - image embeddings .Weston , J. , Bengio , S. , and Hamel , P. ( 2012 ) .", "label": "", "metadata": {}, "score": "55.85848"}
{"text": "Thomas L. Griffiths , Michael Steyvers , David M. Blei , and Joshua B. Tenenbaum ( 2005 ) .Integrating topics and syntax .Advances in Neural Information Processing Systems 17 .David Blei , Andrew Ng , and Michael Jordan ( 2003 ) .", "label": "", "metadata": {}, "score": "55.911983"}
{"text": "The proposed framework also features rapid bootstrapping of LSA models for new languages based on a source LSA model of another language .Our approach is evaluated on the Chinese - English MT06 test set using the medium - scale SMT system and the GALE SMT system measured in BLEU and NIST scores .", "label": "", "metadata": {}, "score": "56.066963"}
{"text": "Hence , they ing error functions : can be calculated individually and , as before , can be sorted or the top k can be found , dependent m on the choice of w. If we use the sparse w of eq .", "label": "", "metadata": {}, "score": "56.138046"}
{"text": "In Journal of New Music Research .Xia , F. , Liu , T.-Y. , Wang , J. , Zhang , W. , and Li , H. ( 2008 ) .Listwise approach to learning to rank : the- ory and algorithm .", "label": "", "metadata": {}, "score": "56.32328"}
{"text": "The result is a distance matrix of dimension 3,592 x 3,592 .While measuring and tracking ' actual ' or ' true ' influence - conscious or unconscious - is impossible , it is possible to use the stylistic - thematic distance / similarity measurements as a proxy for influence .", "label": "", "metadata": {}, "score": "56.375427"}
{"text": "The structure of the ranked list ( i.e. considering the set of items returned as a whole ) is not taken into account .This can be a problem because the set of top predictions can be either too diverse ( contain results that contradict each other ) or are not diverse enough .", "label": "", "metadata": {}, "score": "56.398544"}
{"text": "Wiemer - Hastings , P. ; K. Wiemer - Hastings , A. Graesser & TRG ( 1999 ) .Improving an intelligent tutor 's comprehension of students with latent semantic analysis , In S. Lajoie & M. Vivet ( Eds . ) , Artificial intelligence in education , Amsterdam : IOS Press .", "label": "", "metadata": {}, "score": "56.418343"}
{"text": "Researches and papers using GibbsLDA++ for conducting experiments should include the following citation : .Xuan - Hieu Phan and Cam - Tu Nguyen .GibbsLDA++ : A C / C++ implementation of latent Dirichlet allocation ( LDA ) , 2007 .", "label": "", "metadata": {}, "score": "56.49776"}
{"text": "they will be presented to the user .We wish to optimize all the parameters of our model jointly for that goal .This method is analo- able option .However , during training we can not af- gous to inference by iterated conditional modes ford to perform full inference during each update step in graphical models ( Besag , 1986 ) .", "label": "", "metadata": {}, "score": "56.57914"}
{"text": "Bridging domains using World Wide Web knowledge for transfer learning , IEEE Transactions on Knowledge and Data Engineering ( IEEE TKDE ) , Vol.22 , No.6 , 2010 .Kerui Min et al .Decomposing background topics from keywords by principal component persuit , In Proceedings of the 19th ACM International Conference on Information and Knowledge Management ( ACM CIKM ) , 2010 .", "label": "", "metadata": {}, "score": "56.612095"}
{"text": "Note that these events are signaled by a noun and verb , respectively .Gildea and Jurafsky documented the seminal investigation into SRL [ 9 ] and the NLP community has had a sustained interest in the technique since then ( see [ 11 ] for a more recent survey and references ) .", "label": "", "metadata": {}, "score": "56.80761"}
{"text": "There are many ways in which this work can be extended .Regarding the GLM model , we used a simple stepwise selection method to choose features for prediction .A better alternative might be to apply the penalized GLM ( PGLM ) to select the most predictive features .", "label": "", "metadata": {}, "score": "56.923973"}
{"text": "The Journal of Machine Learning Raman , K. , Shivaswamy , P. , and Joachims , T. ( 2012 ) .Research , 2 , 265 - 292 .Learning to diversify from implicit feedback .InDaum \u00b4 , H. , Langford , J. , and Marcu , D. ( 2009 ) .", "label": "", "metadata": {}, "score": "56.98951"}
{"text": "TopicXP : Exploring Topics in Source Code using Latent Dirichlet Allocation , In Proceedings of the 26th IEEE International Conference on Software Maintenance , Romania , 2010 .Xin Jin et al .LDA - based related word detection in advertising , In Proceedings of the 2010 Seventh Web Information Systems and Applications Conference , 2010 .", "label": "", "metadata": {}, "score": "57.03969"}
{"text": "Proceedings of the 14th International Conference on Machine Learning ( ICML ' 97 ) , Nashville , Tennessee .Zhao , Y. , and J. Zobel ( 2005 ) .Effective and scalable authorship attribution using function words .Lecture Notes in Computer Science .", "label": "", "metadata": {}, "score": "57.09665"}
{"text": "From these , factor loadings can be produced for terms U\u03a3 and documents V\u03a3 .Steps in Latent Semantic Analysis .Figure redrawn from Evangelopoulos & Visinescu ( 2012 ) .3 Software .Free latent semantic analysis and easy to use software is difficult to find .", "label": "", "metadata": {}, "score": "57.250122"}
{"text": "Interact .Learn .Environ .15 , 191 - 200 ( 2007 ) CrossRef .Kalz , M. , Van Bruggen , J. , Rusman , E. , Giesbers , B. , Koper , R. ( submitted ) .Latent Semantic Analysis of Small - Scale Corpora for Placement in Learning Networks .", "label": "", "metadata": {}, "score": "57.26619"}
{"text": "Bell , R. , Koren , Y. , and Volinsky , C. ( 2009 ) .The Lee , D. and Seung , H. ( 2001 ) .negative matrix factorization .Advances in neuralBesag , J. ( 1986 ) .On the statistical analysis of dirty information processing systems , 13 . pictures .", "label": "", "metadata": {}, "score": "57.31505"}
{"text": "Examples of Gibbs sampling algorithms are described in chapters 4 and 5 . edu Abstract .Prior work on criminal incident prediction has relied primar- ily on the historical crime record and various geospatial and demographic information sources .Although promising , these models do not take into account the rich and rapidly expanding social media context that sur- rounds incidents of interest .", "label": "", "metadata": {}, "score": "57.508026"}
{"text": "We then extract events from the main textual content of each tweet using an NLP technique known as semantic role labeling ( SRL ) .Next , we apply latent Dirichlet allocation ( LDA ) to identify salient topics within the extracted events .", "label": "", "metadata": {}, "score": "57.631546"}
{"text": "Topic detection and organization of mobile text messages , In Proceedings of the 19th ACM international Conference on Information and Knowledge Management ( ACM CIKM ) , 2010 .Wayne Zhao et al .Context modeling for ranking and tagging bursty features in text streams , In Proceedings of the 19th ACM International Conference on Information and Knowledge Management ( ACM CIKM ) , 2010 .", "label": "", "metadata": {}, "score": "57.89814"}
{"text": ": Prediction of central nervous system embryonal tumour outcome based on gene expression .Nature 415(6870 ) , 436 - 442 ( 2002 ) CrossRef .Rogers , S. , Girolami , M. , Campbell , C. , Breitling , R. : The latent process decomposition of cdna microarray data sets .", "label": "", "metadata": {}, "score": "58.03991"}
{"text": "We should men- cosine similarity based on previously retrieved docu - tion that many other methods exist as well , in partic- ments .In a sense , LaSR is also a pseudo - relevanceular probabilistic methods like pLSA ( Hofmann , 1999 ) feedback technique , but where inter - document simi - and LDA ( Blei et al . , 2003 ) .", "label": "", "metadata": {}, "score": "58.05812"}
{"text": "Proc .25 , 259 - 284 ( 1998 ) CrossRef .Landauer , T. : LSA as a theory of meaning .In Handbook of Latent Semantic Analysis , ed . by Landauer , T. et al .( Erlbaum , Mahwah 2007 ) pp .", "label": "", "metadata": {}, "score": "58.09543"}
{"text": "Cross - lingual latent semantic analysis for LM .In : 2004 IEEE international conference on acoustics , speech , and signal processing , vol 1 .Montreal , Quebec , Canada , pp 257 - 260 .Kneser R , Peters J , Klakow D ( 1997 )", "label": "", "metadata": {}, "score": "58.1559"}
{"text": "Linguist .Mohler , G.O. , Short , M.B. , Brantingham , P.J. , Schoenberg , F.P. , Tita , G.E. : Self- exciting point process modeling of crime .Journal of the American Statistical As- sociation 106(493 ) , 100 - 108 ( March 2011 ) 13 .", "label": "", "metadata": {}, "score": "58.165276"}
{"text": "In : Saul LK , Weiss Y , Bottou L ( eds ) Advances in neural information processing systems 17 , Proceedings of the 2004 conference .MIT Press , Cambridge MA , pp 537 - 544 .Hofmann T ( 1999 )", "label": "", "metadata": {}, "score": "58.176735"}
{"text": "Michael Welch et al .Search Result Diversity for Information Queries .In Proceedings of The 20th International World Wide Web Conference ( WWW 2011 ) , Hyderabad , India .V. Suresh et al .A Non - syntactic Approach for Text SentimentClassi?cation with Stopwords , In Proceedings of The 20th International World Wide Web Conference ( WWW 2011 ) , Hyderabad , India .", "label": "", "metadata": {}, "score": "58.184433"}
{"text": "Investigating Unstructured Texts with Latent Semantic Analysis , in Lenz , Hans -J. ( ed ) .Advances in Data Analysis , Studies in Classification , Data Analysis , and Knowledge Organization , Advances in Data Analysis , Part V , 383 - 390 , DOI : 10.1007/978 - 3 - 540 - 70981 - 7_43", "label": "", "metadata": {}, "score": "58.405746"}
{"text": "The MIT Press .Histogram segmenting and labeling sequence data . Interna-Le , Q. and Smola , A. ( 2007 ) .Direct optimization of tional Conference on Image Processing ( ICIP ) , 3 , ranking measures .Technical report , National ICT III-513 - 16 vol.2 .", "label": "", "metadata": {}, "score": "58.68432"}
{"text": "Support vector machine learn- by latent semantic analysis .JASIS . ing for interdependent and structured output spaces .Deng , J. , Dong , W. , Socher , R. , Li , L.-J. , Li , K. , and In International Conference on Machine Learning Fei - Fei , L. ( 2009 ) .", "label": "", "metadata": {}, "score": "58.847515"}
{"text": "LSI ( referred to as LSA in more general settings ) has been applied to host of other problems in computer science ranging from memory modeling to computer vision .Hofmann ( 1999a ; b ) provides an initial probabilistic extension of the basic latent semantic indexing technique .", "label": "", "metadata": {}, "score": "58.93521"}
{"text": "User interest analysis with hidden topic in news recommendation system , In Proceedings of the International Conference on Asian Language Processing , 2010 .Scott Grant and James R. Cordy .Estimating the optimal number of latent concepts in source code analysis , In Proceedings of the 10th IEEE Working Conference on Source Code Analysis and Manipulation , 2010 .", "label": "", "metadata": {}, "score": "58.96326"}
{"text": "GibbsLDA++ is a C / C++ implementation of Latent Dirichlet Allocation ( LDA ) using Gibbs Sampling technique for parameter estimation and inference .It is very fast and is designed to analyze hidden / latent topic structures of large - scale datasets including large collections of text / Web documents .", "label": "", "metadata": {}, "score": "59.171265"}
{"text": "u methods for structured prediction .In Proceedings of Kernel principal component analysis .Advances in the 22nd international conference on Machine learn- kernel methods : support vector learning , pages 327- ing , pages 169 - 176 .ACM .Deerwester , S. , Dumais , S. T. , Furnas , G. W. , Lan- Tsochantaridis , I. , Hofmann , T. , Joachims , T. , and dauer , T. K. , and Harshman , R. ( 1990 ) .", "label": "", "metadata": {}, "score": "59.173832"}
{"text": "Inferring functional modules of protein families with probabilistic topic models , BMC Bioinformatics , 12:141 , 2011 .Lidong Bing and Wai Lam .Investigation of Web Query Refinement via Topic Analysis and Learning with Personalization , In Proceedings of the ACM SIGIR Workshop on Query Representation and Understanding , 2011 .", "label": "", "metadata": {}, "score": "59.270935"}
{"text": "A multi - view approach for term translation spotting .In Proceedings of the 12th International Conference on Computational Linguistics and Intelligent Text Processing ( CICLing 2011 ) , 2011 .Viet Cuong Nguyen et al .Improving Text Segmentation with Non - systematic Semantic Relation .", "label": "", "metadata": {}, "score": "59.28104"}
{"text": "performs SVD and NMF .ItMusicRecommendationDataset / lastfm-1K.html .We therefore report results for var-5th , 2009 ) for 992 users and 176,948 artists .Overall this gave5,408,975 training pairs , 500,000 validation pairs ( forhyperparameter tuning ) and 1,434,568 test pairs .", "label": "", "metadata": {}, "score": "59.312244"}
{"text": "PDF .McCarthy , Philip M. ; Adam M. Renner , Michael G. Duncan , Nicholas D. Duran , Erin J. Lightman , Danielle S. McNamara .Identifying topic sentencehood .Behavior Research Methods 40:3 , 647 - 664 .Penumatsa , Phanni ; Matthew Ventura , Arthur C. Graesser , Max Louwerse , Xiangen Hu , Zhiqiang Cai , And Donald R. Franceschetti ( 2006 ) .", "label": "", "metadata": {}, "score": "59.379528"}
{"text": "Our approach is based on the automatic semantic analysis and understanding of natural language Twitter posts , combined with dimensionality reduction via la- tent Dirichlet allocation and prediction via linear modeling .We tested our model on the task of predicting future hit - and - run crimes .", "label": "", "metadata": {}, "score": "59.687256"}
{"text": "Computational Statistics & Data Analysis 48(4 ) , 869 - 885 ( 2005 ) MATH MathSciNet CrossRef .Martins , A. , Smith , N. , Xing , E. , Aguiar , P. , Figueiredo , M. : Nonextensive information theoretic kernels on measures .", "label": "", "metadata": {}, "score": "59.70741"}
{"text": "Latent Semantic Analysis \" .Annual Review of Information Science and Technology 38 : 188 .Jurgens , David and Keith Stevens , ( 2010 ) .The S - Space Package : An Open Source Package for Word Space Models .", "label": "", "metadata": {}, "score": "59.755795"}
{"text": "We studied the hit - and - run incidents per day using traditional time series methods , but discovered no trend , seasonality , or autocorrelation .Thus , without any ad- ditional information , a baseline system would assign a uniform probability of incidents to all future days .", "label": "", "metadata": {}, "score": "59.759937"}
{"text": "Oxford : Blackwell .Martindale , C. , and D. McKenzie ( 1995 ) .On the Utility of Content Analysis in Author Attribution : The Federalist .Computers and the Humanities 29(4 ) : 259 - 270 .Team , R. D. C. ( 2011 ) .", "label": "", "metadata": {}, "score": "59.799164"}
{"text": "Duff , I. S. , Grimes , R. G. , Lewis , J. G. : User 's Guide for the Harwell - Boeing Sparse Matrix Collection ( Release I ) .Technical Report RAL 92 - 086 ( Rutherford Appleton Laboratory 1992 ) .", "label": "", "metadata": {}, "score": "59.88578"}
{"text": "In : Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology ( SAAIP 2011 ) .pp .2 - 10 .Asian Federation of Natural Language Processing , Chiang Mai , Thailand ( November 2011 ) 3 .Blei , D. , Carin , L. , Dunson , D. : Probabilistic topic models .", "label": "", "metadata": {}, "score": "59.95144"}
{"text": "Proceedings of World Conference on Educational Multimedia , Hypermedia and Telecommunications .AACE , Chesapeake , VA , 1999 , pp .939 - 944 .Giles , J. , Wo , L. , Berry , M. : GTP ( general text parser ) software for text mining .", "label": "", "metadata": {}, "score": "60.062473"}
{"text": "An Unsupervised Aspect - Sentiment Model for Online Reviews , In Proceedings of the 2010 Human Language Technologies and The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics ( HLT - NAACL ) , PA , USA , 2010 .", "label": "", "metadata": {}, "score": "60.33473"}
{"text": "Tam YC , Schultz T ( 2005 )Language model adaptation using variational Bayes inference .In : Proceedings of Interspeech'2005 - Eurospeech , 9th European conference on speech communication and technology , Lisbon , Portugal , pp 5 - 8 .", "label": "", "metadata": {}, "score": "60.50197"}
{"text": "MathSciNet .Masada , T. , Hamada , T. , Shibata , Y. , Oguri , K. : Bayesian multi - topic microarray analysis with hyperparameter reestimation .In : Proc .Int .Conf . on Advanced Data Mining and Applications ( 2009 ) .", "label": "", "metadata": {}, "score": "60.672516"}
{"text": "A solution to Plato 's problem : The Latent Semantic Analysis theory of the acquisition , induction , and representation of knowledge .Psychological Review , 104 , 211 - 240 .Landauer , T. K. ; P. W. Foltz & D. Laham , An introduction to latent semantic analysis , Discourse processes , 25 ( 1998 ) 259 - 284 .", "label": "", "metadata": {}, "score": "60.776497"}
{"text": "In methods like Conditional Random tured regression problem .Pre- setup .To the best of our knowledge , however , nonedicting ranked lists can also be seen in this framework .As we said 4 EXPERIMENTSbefore , due to the large number of items we are rank - ing many of those approaches are infeasible .", "label": "", "metadata": {}, "score": "60.981396"}
{"text": "( Latent Semantic Analysis , retrieved 12:59 , 12 March 2012 ( CET ) ) .SenseClusters by Ted Pedersen et al .This \" is a package of ( mostly )Perl programs that allows a user to cluster similar contexts together using unsupervised knowledge - lean methods .", "label": "", "metadata": {}, "score": "61.202305"}
{"text": "Word reordering in statistical machine translation with a POS - based distortion model .In : TMI 2007 , proceedings of the 11th international conference on theoretical and methodological issues in machine translation , Sk\u00f6vde , pp 171 - 180 .Stolcke A ( 2002 ) SRILM - an extensible language modeling toolkit .", "label": "", "metadata": {}, "score": "61.233833"}
{"text": "Detecting salient aspects in online reviews of health providers , In Proceedings of the AMIA Annual Symposium , 2010 .Georgiana Dinu and Mirella Lapata .Topic models for meaning similarity in context , In Proceedings of the 23rdInternational Conference on Computational Linguistics ( COLING ) , PA , USA , 2010 .", "label": "", "metadata": {}, "score": "61.26506"}
{"text": "A hybrid unsupervised image re - ranking approach with latent topic contents , In Proceedings of the ACM International Conference on Image and Video Retrieval ( ACM CIVR ) , 2010 .Trevor Fountain and Mirella Lapata .Meaning representation in natural language categorization , In Proceedings of the Annual Meeting of the Cognitive Science Society ( COGSCI ) , 2010 .", "label": "", "metadata": {}, "score": "61.42407"}
{"text": "A term - frequency matrix ( A ) must be created that includes the occurences of each term in each document .2 ) Singular Value Decomposition ( SVD ) : .Extract least - square principal components for two sets of variables : set of terms and set of documents .", "label": "", "metadata": {}, "score": "61.500343"}
{"text": "Unsupervised language model adaptation using latent semantic marginals .In : Interspeech 2006 - ICSLP , ninth international conference on spoken language processing , Pittsburgh , Pennsylvania , paper 1705-Thu1A2O.2 .Tam YC , Schultz T ( 2007 ) Correlated latent semantic model for unsupervised language model adaptation .", "label": "", "metadata": {}, "score": "61.66617"}
{"text": "Paulik M , F\u00fcgen C , Schaaf T , Schultz T , St\u00fcker S , Waibel A ( 2005 ) Document driven machine translation enhanced automatic speech recognition .In : Proceedings of Interspeech'2005 - Eurospeech , 9th European conference on speech communication and technology , Lisbon , Portugal , pp 2261 - 2264 .", "label": "", "metadata": {}, "score": "62.031075"}
{"text": "The descriptors are somewhat sparse , with The method we proposed is scalable to these tasks.about 50,000 non - zero weights per image .Some of the Future work could apply latent structured ranking toconstituent histograms are normalized and some are more applications , for example in text document re - not .", "label": "", "metadata": {}, "score": "62.269104"}
{"text": "2003 ; Blei , Griffiths et al .2004 ; Chang , Boyd - Graber et al .2009 ) .The thematic data includes information about the percentages of each theme / topic found in each text .4 I combine these two categories of data - stylistic and thematic - to create ' book signals ' composed of 592 unique feature measurements .", "label": "", "metadata": {}, "score": "62.313908"}
{"text": "Computational Lin- guistics 28 , 245 - 288 ( 2002 ) 10 .Tech . rep . , Project on Information Technology and Political Islam , University of Washington , Seattle ( January 2011 ) 11 .M'arquez , L. , Carreras , X. , Litkowski , K.C. , Stevenson , S. : Semantic role labeling : an introduction to the special issue .", "label": "", "metadata": {}, "score": "62.490562"}
{"text": "Given a querypredicted positions in the ranked list ) in order to op- ( seed ) artist , one has to recommend to the user othertimize the right metric , e.g. MAP or precision@k . artists that go well together with this artist if one wereIn that sense , methods like Wsabie which uses the listening to both in succession , which is the main stepWARP loss already use structure in the same way .", "label": "", "metadata": {}, "score": "62.56624"}
{"text": "Yue , Y. , Finley , T. , Radlinski , F. , and Joachims , T. ( 2007a ) .A support vector method for optimizing average precision .In SIGIR , pages 271 - 278 .Yue , Y. , Finley , T. , Radlinski , F. , and Joachims , T. ( 2007b ) .", "label": "", "metadata": {}, "score": "62.56761"}
{"text": "For this research , the topic model was set to extract 500 latent topics .Distance ' here is a measure of stylistic and thematic similarity .Distances were calculated using the default settings of the ' dist ( ) ' function in the R statistics package .", "label": "", "metadata": {}, "score": "63.022118"}
{"text": "Daniel K. Schneider 12:59 , 12 March 2012 ( CET ) . \"Latent Semantic Indexing ( LSI ) is an indexing and retrieval method that uses a mathematical technique called Singular value decomposition ( SVD ) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text .", "label": "", "metadata": {}, "score": "63.27407"}
{"text": "2 .ROC curves for predicting hit - and - run incidents tweets instead of event words only .The remaining experimental conditions were held constant , resulting in the ROC curve shown in Figure 2(b ) .5 Conclusions and Future Work This paper has presented a preliminary investigation into the use of social me- dia for criminal incident prediction .", "label": "", "metadata": {}, "score": "63.44358"}
{"text": "1 Introduction Traditional crime prediction systems ( e.g. , the one described by Wang and Brown [ 14 ] ) make extensive use of historical incident patterns as well as layers of in- formation provided by geographic information systems ( GISs ) and demographic information repositories .", "label": "", "metadata": {}, "score": "64.14224"}
{"text": "Geographic locations are characterized by a rich set of spatial and demographic features instead of the simple geographic coor- dinates used by KDE - based approaches .Example features include the distance to the nearest business and the number of divorced individuals in the region .", "label": "", "metadata": {}, "score": "64.202515"}
{"text": "In : UAI ' 99 , proceedings of the fifteenth conference on uncertainty in artificial intelligence , Stockholm , Sweden , pp 289 - 296 .Hsu B - J(P ) , Glass J ( 2006 ) Style & topic language model adaptation using HMM - LDA .", "label": "", "metadata": {}, "score": "64.38907"}
{"text": "Asur , S. , Huberman , B. : Predicting the future with social media .In : 2010 IEEE / WIC / ACM International Conference on Web Intelligence and Intelligent Agent Technology .pp .492 - 499 .IEEE ( 2010 ) 2 .", "label": "", "metadata": {}, "score": "64.868"}
{"text": "# i.e. , the vocabulary size .# i.e. , the Gibbs sampling iteration at which the model was saved .Each line is a document and each column is a topic . ..tassign : This file contains the topic assignments for words in training data .", "label": "", "metadata": {}, "score": "65.35882"}
{"text": "Information retrieval and search ( analyzing semantic / latent topic / concept structures of large text collection for a more intelligent information search ) .Document classification / clustering , document summarization , and text / web mining community in general .", "label": "", "metadata": {}, "score": "65.733604"}
{"text": "( 4 ) not take advantage of it .Another way to look at this is , precision@1 would be no better than usingAs we will see this also has some computational ad-the vanilla model of eq . vantages due to its sparsity , and will in fact be our The greedy procedure also permits beam searchmethod of choice in the algorithm we propose . variants .", "label": "", "metadata": {}, "score": "65.77706"}
{"text": "However , unlike that work , we do not or items ) and 5 million training pairs .The second is ause it to prune the set of items considered for ranking , task of large scale image annotation with over 15,000we use it to consider pairwise item similarities . labels and 7 million training examples .", "label": "", "metadata": {}, "score": "65.84985"}
{"text": "Julien et al . , 2006 ) .Solving even ( 3 ) this relaxed LP per query is computationally in - In addition to the parameters of eq .( 2 ) , we now intro- feasible for problems of this size .", "label": "", "metadata": {}, "score": "65.85338"}
{"text": "Overall process of criminal incident prediction using tweets generalized from one area of a city or country to another area .Furthermore , the feature - based representation permits the addition of information such as that extracted from social media services .", "label": "", "metadata": {}, "score": "65.901566"}
{"text": "Cross - cultural analysis of blogs and forums with mixed - collection topic models , In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , 2009 .Makoto P. Kato .Rhythmixearch : searching for unknown music by mixing known music , In Proceedings of the 10th International Society for Music Information Retrieval Conference , 2009 .", "label": "", "metadata": {}, "score": "65.98602"}
{"text": "Statistical Stylistics and Authorship Attribution : An Empirical Investigation .Literary and Linguistic Computing : Journal of the Association for Literary and Linguistic Computing 16(4 ) : 421 - 444 .Hoover , D. L. ( 2008 ) .Quantitative Analysis and Literary Studies .", "label": "", "metadata": {}, "score": "66.47331"}
{"text": "S S is a low technique is an attempt to overcome even linearrank matrix of item - item similarities where S is a n\u00d7D time inference for this problem.matrix , just like U and V , and must also be learnt bythe model using training data .", "label": "", "metadata": {}, "score": "66.6048"}
{"text": "Slightly more in - depth , covers the stick - breaking construction for the Dirichlet process ( which is not in my thesis ) as well as the Chinese restaurant process .These two papers apply the Dirichlet process and hierarchical Dirichlet process to word segmentation .", "label": "", "metadata": {}, "score": "66.7419"}
{"text": "To give uments or items D. where dand \" 60s folk \" in the same top k list .Let us begin by proposing methods for using the stan- dard latent model of eq .( 1 ) to score permutations .", "label": "", "metadata": {}, "score": "66.77861"}
{"text": "Literary and Linguistic Computing : Journal of the Association for Literary and Linguistic Computing 2 2(1 ) : 49 - 66 .Grieve , J. ( 2007 ) .Quantitative Authorship Attribution : An Evaluation of Techniques .Literary and Linguistic Computing : Journal of the Association for Literary and Linguistic Computing 22(3 ) : 251 - 270 .", "label": "", "metadata": {}, "score": "66.80075"}
{"text": "Semantic Vectors , retrieved 12:59 , 12 March 2012 ( CET ) ) .This not LSI / LSA , but similar if we understand right ... .Commercial software .SAS Text Miner .Quote : \" provides a rich suite of linguistic and analytical modeling tools for discovering and extracting knowledge from across text collections .", "label": "", "metadata": {}, "score": "66.959625"}
{"text": "In other words , it is a short or insufficient piece of information and requires additions .Draft .Contents .Latent Semantic Indexing ( LSI ) and Latent Semantic Analysis ( LSA refer to a family of text indexing and retrieval methods .", "label": "", "metadata": {}, "score": "67.029816"}
{"text": "Outputs .Outputs of Gibbs sampling estimation of GibbsLDA++ include the following files : . others . phi . theta . tassign . twords . in which : . : is the name of a LDA model corresponding to the time step it was saved on the hard disk .", "label": "", "metadata": {}, "score": "67.09155"}
{"text": "BMC Proceedings 2(suppl .4 ) , S7 ( 2008 ) CrossRef .About this Chapter .Title .Biologically - aware Latent Dirichlet Allocation ( BaLDA ) for the Classification of Expression Microarray This article or section is a stub .", "label": "", "metadata": {}, "score": "67.27042"}
{"text": "Springer , New York .Kim W , Khudanpur S ( 2003 )LM adaptation using cross - lingual information .In : 8th European conference on speech communication and technology ( Eurospeech 2003 - Interspeech 2003 ) , Geneva , Switzerland , pp 3129 - 3132 .", "label": "", "metadata": {}, "score": "67.55445"}
{"text": "applied the self - exciting point process model ( previously developed for earthquake prediction ) as a model of crime [ 12].This model , like ones based on KDE , relies on the prior occurrence of crimes in a particular area and thus can not generalize to previously unobserved areas .", "label": "", "metadata": {}, "score": "67.720375"}
{"text": "( introduction ) , retrieved 12:10 , 12 March 2012 ( CET ) .LSA package for R developed by Fridolin Wild .\" The basic idea of latent semantic analysis ( LSA ) is , that text do have a higher order ( latent semantic ) structure which , however , is obscured by word usage ( e.g. through the use of synonyms or polysemy ) .", "label": "", "metadata": {}, "score": "67.72624"}
{"text": "Distributional algorithms process text corpora and represent the semantic for words as high dimensional feature vectors .These approaches are known by many names , such as word spaces , semantic spaces , or distributed semantics and rest upon the Distributional Hypothesis : words that appear in similar contexts have similar meanings . \"", "label": "", "metadata": {}, "score": "67.99959"}
{"text": "Semantic Vectors can be used to find related terms and concepts to a target term . \" creates semantic WordSpace models from free natural language text .Such models are designed to represent words and documents in terms of underlying concepts .", "label": "", "metadata": {}, "score": "68.47591"}
{"text": "A teenth International Conference on Machine Learn- new baseline for image annotation .In European con- ing , volume 54 , page 48 . ference on Computer Vision ( ECCV ) .Blei , D. M. , Ng , A. , and Jordan , M. I. ( 2003 ) .", "label": "", "metadata": {}, "score": "68.49963"}
{"text": "Bioinformatics 21(5 ) , 631 - 643 ( 2005 ) CrossRef .Valafar , F. : Pattern recognition techniques in microarray data analysis : A survey .Annals of the New York Academy of Sciences 980 , 41 - 64 ( 2002 ) CrossRef .", "label": "", "metadata": {}, "score": "69.512566"}
{"text": "Even in the satellite community , sub clustering by gender is apparent .Weighted in - degree is a measure of influence coming into a node whereas weighted out - degree provides a measure of the influence a given node exerts on subsequent nodes .", "label": "", "metadata": {}, "score": "69.55145"}
{"text": "Crime hot - spots indicate spatial areas of relatively high threat accord- ing to some underlying model .A common model - one promoted by Eck et al .- relies on kernel density estimation ( KDE ) from the criminal history record of an area [ 7].", "label": "", "metadata": {}, "score": "69.772064"}
{"text": "Adding structure to LaSR again im - query and record the position of the item in the ranked proves the results in this case by boosting relativelylist .We then measure the recall at 5 , 10 , 30 and 50 .", "label": "", "metadata": {}, "score": "69.91951"}
{"text": "P2Prec : a P2P recommendation system for large - scale data sharing , Transactions on Large - Scale Data and Knowledge - Centered System III , 2011 .Hiroyuki Koga and Tadahiro Taniguchi .Developing a User Recommendation Engine on Twitter Using Estimated Latent Topics , In Proceedings of the Human Computer Interaction ( HCI ) , 2011 .", "label": "", "metadata": {}, "score": "70.02548"}
{"text": "The main idea here is to weight the pairwise viola- Algorithm 1 LaSR training algorithmtions depending on their position in the ranked list .Pick a random training pair ( q , d+ ) .We can optimize this function by SGD following the Compute f ( q , d+ ) .", "label": "", "metadata": {}, "score": "70.02784"}
{"text": "Analysis .Networks are constructed out of nodes ( books ) and edges ( distances ) .When plotted , nodes with less similarity ( i.e. larger distances between them ) will spread out further in the network .Figure 1 offers a simplified example of three imaginary books .", "label": "", "metadata": {}, "score": "70.14646"}
{"text": "A hidden topic - based framework toward building applications with short Web documents , IEEE Transactions on Knowledge and Data Engineering ( IEEE TKDE ) , Vol.23 , No.7 , 2011 .C. Lin et al .Weakly - supervised Joint Sentiment - Topic Detection from Text , IEEE Transactions on Knowledge and Data Engineering ( IEEE TKDE ) , to appear .", "label": "", "metadata": {}, "score": "70.47518"}
{"text": "Make sure to clearly label the dimensions of your matrix .Write down the matrices and and from these derive the rank 2 approximation .State succinctly what the entry in the matrix represents .State succinctly what the entry in the matrix represents , and why it differs from that in .", "label": "", "metadata": {}, "score": "70.53735"}
{"text": "We obtained these records from local law enforcement agencies , focusing on hit - and - run incidents during the same period covered by the Twitter data .In total , we collected records for 290 hit - and - run incidents ( 1.2 per day).5 3.2 Methods Semantic Role Labeling Our approach to Twitter - based crime prediction re- lies on a semantic understanding of tweets , one that goes beyond bag - of - words and sentiment representations .", "label": "", "metadata": {}, "score": "70.558525"}
{"text": "This is not simply a ' proxy ' of convenience .It is , in fact , an ideal proxy , especially so when we consider that even plagiarism ( the most obvious form of influence ) can be accidental .I 'm grateful to my colleague Elijah Meeks who sees the world through network analysis goggles and who aided me in visualizing and analyzing this data .", "label": "", "metadata": {}, "score": "70.603226"}
{"text": "Exploring English lexicon knowledge for Chinese sentiment analysis .In Proceedings of the CIPS - SIGHAN Joint Conference on Chinese Language Processing , 2010 , Beijing , China .Mingrong Liu et al .Predicting best answerers for new questions in community question answering , In Proceedings of the 11th international conference on Web - age information management , 2010 .", "label": "", "metadata": {}, "score": "70.92074"}
{"text": "( What is LSA ? , retrieved 12:10 , 12 March 2012 ( CET ) .In more practical terms : \" Latent semantic analysis automatically extracts the concepts contained in text documents .In simplified statistical terms , it factor analyzes the text to extract concepts and then clusters the documents into similar categories based on the factor scores .", "label": "", "metadata": {}, "score": "71.06997"}
{"text": "The outputs of GibbsLDA++ inference are almost the same as those of the estimation process except that the contents of those files are of the new data .For example , we want to estimate a LDA model for a collection of documents stored in file called models / casestudy / trndocs . dat and then use that model to do inference for new data stored in file models / casestudy / newdocs . dat .", "label": "", "metadata": {}, "score": "71.18869"}
{"text": "There have been several implementations of this model in C ( using Variational Methods ) , Java , and Matlab .We decided to release this implementation of LDA in C / C++ using Gibbs Sampling to provide an alternative to the topic - model community .", "label": "", "metadata": {}, "score": "71.38342"}
{"text": "Gensim - Topic Modelling for Humans , implemented in Python . \"Gensim aims at processing raw , unstructured digital texts ( \" plain text \" ) .The algorithms in gensim , such as Latent Semantic Analysis , Latent Dirichlet Allocation or Random Projections , discover semantic structure of documents , by examining word statistical co - occurrence patterns within a corpus of training documents .", "label": "", "metadata": {}, "score": "71.416046"}
{"text": "This is because LDA can be used to discover the underlying topic structures of any kind of discrete data .Therefore , GibbsLDA++ is not limited to text and natural language processing but can also be applied to other kinds of data like images and biological sequences .", "label": "", "metadata": {}, "score": "71.47379"}
{"text": "Och FJ ( 2003 )Minimum error rate training in statistical machine translation .In : ACL-03 , 41st annual meeting of the Association for Computational Linguistics , Sapporo , Japan , pp 160 - 167 .Papineni K , Roukos S , Ward T , Zhu W ( 2002 ) BLEU : a method for automatic evaluation of machine translation .", "label": "", "metadata": {}, "score": "71.47603"}
{"text": "We trained a GLM on these topics as described in Section 3.2 , using stepwise selection to identify the most informative features .Td , \u00b7 is the topic distribution on day d. As shown , the model emphasizes topics 1 , 4 , 6 , and 8 in the prediction of future hit - and - run incidents .", "label": "", "metadata": {}, "score": "71.64076"}
{"text": "We used the data before September 17 , 2011 to train the LDA and predictive models , setting k ( the number of latent topics ) to be 10 .Table 1 presents the top 10 words for each topic .The nature of these topics is subjective ; however , some structure is present .", "label": "", "metadata": {}, "score": "71.689545"}
{"text": "How come you know so much ?From practical problem to theory .In D. Hermann , C. McEvoy , M. Johnson , & P. Hertel ( Eds . ) , Basic and applied memory : Memory in context .Mahwah , NJ : Erlbaum , 105 - 126 .", "label": "", "metadata": {}, "score": "71.71553"}
{"text": "Figure 2(a ) shows the ROC curve of the prediction performance .The ideal ROC curve stretches toward the upper - left corner .A curve along the diagonal indicates no predictive power .The baseline system ROC curve lies on the diagonal , as it predicts hit - and - run incidents uniformly across all days .", "label": "", "metadata": {}, "score": "71.7587"}
{"text": "International Journal on Artificial Intelligence Tools 2006 15:05 , 767 - 777 DOI10.1142/S021821300600293X .Sidorova , A. , Evangelopoulos , N. , Valacich , J. , and Ramakrishnan , T. Uncovering the intellectual core of the information systems discipline .", "label": "", "metadata": {}, "score": "71.81232"}
{"text": "Aimed primarily at computational linguists , but should ( I hope ) be accessible to anyone who has a basic familiarity with generative probabilistic models .Chapters 2 and 3 cover many useful topics , including Bayesian integration in finite and infinite models ( i.e. , Dirichlet distribution , Dirichlet process , Chinese restaurant process ) and a brief introduction to sampling techniques ( Gibbs sampling and Metropolis - Hastings sampling ) .", "label": "", "metadata": {}, "score": "72.30153"}
{"text": "On iter- as otherwise training will be too slow .( 7 ) Joachims , 2002 ) .( ii )On subsequent itera- positive item .These costs are called pairwise viola- tions , we maximize the following scoring function : tions .", "label": "", "metadata": {}, "score": "72.53821"}
{"text": "The central hypothesis of this paper is that latent method without structure as well as other standardranking methods could be improved if one were to take baselines .We also provide some analysis of why weinto account the structure of the ranked list during in- think this is happening.ference .", "label": "", "metadata": {}, "score": "73.02828"}
{"text": "We also compare to two standard methods lan \" .For example , \" Sonic Youth \" which isSVD and our method , Latent Structured Ranking a poor match is demoted out of the top 20 .The sec-(LaSR ) in Table 1 .", "label": "", "metadata": {}, "score": "73.30701"}
{"text": "twords is specified in the command line .GibbsLDA++ also saves a file called wordmap.txt that contains the maps between words and word 's IDs ( integer ) .This is because GibbsLDA++ works directly with integer IDs of words / terms inside instead of text strings .", "label": "", "metadata": {}, "score": "73.96052"}
{"text": "Large - scale analysis of tweets might provide insights that are not apparent within a single feed .Acknowledgments We would like to thank the anonymous reviewers for their comments on a pre- vious version of this paper .The work presented in this paper was funded by United States Army Grant W911NF-10 - 2 - 0051 .", "label": "", "metadata": {}, "score": "73.96786"}
{"text": "Influence may even be ' oppositional ' as in the case of a writer who wishes to make his or her writing intentionally different from that of a predecessor .The aforementioned thinkers offer informed but anecdotal evidence in support of their claims of influence .", "label": "", "metadata": {}, "score": "74.63071"}
{"text": "In order to justify this added complexity , we re - trained the predictive LDA / GLM model on all words in the .7 False positive rate Averagetruepositiverate 0.0 0.2 0.4 0.6 0.8 1.0 0.00.20.40.60.81.0 ( a )Using events extracted from tweets False positive rate Averagetruepositiverate 0.0 0.2 0.4 0.6 0.8 1.0 0.00.20.40.60.81.0 ( b )", "label": "", "metadata": {}, "score": "75.10988"}
{"text": "Remember that time is not a feature in the similarity calculations .The arrangement of the nodes in a chronological fashion is a byproduct of the way in which the books signals change in a regular , chronological , manner .In the larger presentation of this work , I will offer an explanation for why the 499 books in this isolated cluster are split off from the main network .", "label": "", "metadata": {}, "score": "75.15398"}
{"text": "-dir : The directory contain the previously estimated model .-model : The name of the previously estimated model .See section \" Outputs \" to know how GibbsLDA++ saves outputs on hard disk .-niters : The number of Gibbs sampling iterations to continue estimating .", "label": "", "metadata": {}, "score": "75.27912"}
{"text": "See section \" Input data format \" for a description of input data format .Parameter estimation from a previously estimated model .Command line : .$ lda -estc -dir -model [ -niters ] [ -savestep ] [ -twords ] . in which ( parameters in [ ] are optional ) : .", "label": "", "metadata": {}, "score": "75.43183"}
{"text": "While it is not possible to show the details of the entire network here , it is possible to display several of the most obvious macro - structures .Figure 2 , for example , presents a zoomed out view of the network with book nodes colored according to dates of publication .", "label": "", "metadata": {}, "score": "75.49095"}
{"text": "The first cell contains a ' source ' book , the second cell a ' target ' book , and a third cell the measured distance between the two .After removing all of the records in which the target book was published before , or in the same year as , the source book , 8 the data was reduced from 12,902,464 records to 6,447,640 .", "label": "", "metadata": {}, "score": "75.57411"}
{"text": "BMC Bioinformatics 18(3 ) , 413 - 422 ( 2002 ) .Osareh , A. , Shadgar , B. : Classification and diagnostic prediction of cancers using gene microarray data analysis .J. of Applied Sciences 9(3 ) ( 2009 ) .", "label": "", "metadata": {}, "score": "76.90546"}
{"text": "-savestep : The step ( counted by the number of Gibbs sampling iterations ) at which the LDA model is saved to hard disk .The default value is 200 .-twords : The number of most likely words for each topic .", "label": "", "metadata": {}, "score": "77.146255"}
{"text": "-savestep : The step ( counted by the number of Gibbs sampling iterations ) at which the LDA model is saved to hard disk .The default value is 200 .-twords : The number of most likely words for each topic .", "label": "", "metadata": {}, "score": "77.146255"}
{"text": "archical Image Database .Computer Vision and Pattern Recognition .WordNet : An Electronic tion .In L. Bottou and M. Littman , editors , ICML , Lexical Database .MIT Press . pages 1057 - 1064 , Montreal .Omnipress .", "label": "", "metadata": {}, "score": "77.25197"}
{"text": "How- on iteration t , where Ut , Vt and St are separate matri - ever , for ( a variant of ) the iterative algorithm which ces for each iteration .This decouples the learning atwe described in the previous section the WARP ( or each iteration .", "label": "", "metadata": {}, "score": "77.41695"}
{"text": "Supposing that we are now at the home directory of GibbsLDA++ , We will execute the following command to estimate LDA model from scratch : .$ src / lda -est -alpha 0.5 -beta 0.1 -ntopics 100 -niters 1000 -savestep 100 -twords 20 -dfile models / casestudy / trndocs . dat .", "label": "", "metadata": {}, "score": "77.63305"}
{"text": "For outperforms Wsabie with a recall@1 of 9.45 % .many nouns , hundreds or even thousands of imagesare labeled .We can use this dataset to test image Some example annotations are given in Table 4 .LaSRannotation algorithms .We split the data into train seems to provide more consistent results than Wsabieand test and try to learn to predict the label ( an- on several queries ( with less bad predictions in the topnotation ) given the image .", "label": "", "metadata": {}, "score": "77.71523"}
{"text": "Input data format .Both data for training / estimating the model and new data ( i.e. , previously unseen data ) have the same format as follows : . [M ] .[ document 1 ] .[ document 2 ] .", "label": "", "metadata": {}, "score": "77.90481"}
{"text": "Data - driven approach for ontology learning , In Proceedings of the 6th International Conference on Electrical Engineering , Computing Science and Automatic Control , 2009 .Sao Carlos et al .Towards the automatic learning of ontologies , In Proceedings of the 7th Brazilian Symposium in Information and Human Language Technology , 2009 .", "label": "", "metadata": {}, "score": "78.41084"}
{"text": "In : Proceedings of Eurospeech ' 97 , 5th European conference on speech communication and technology , Rhodes , Greece , pp 1971 - 1974 .Mrva D , Woodland PC ( 2006 )Unsupervised language model adaptation for Mandarin broadcast conversation transcription .", "label": "", "metadata": {}, "score": "78.46703"}
{"text": "This is not intended to be a complete list , only a starting point .Note : This list has not been updated since 2008 , in part because the area has now expanded considerably , and keeping it up - to - date would be difficult .", "label": "", "metadata": {}, "score": "78.61815"}
{"text": "Honolulu , Hawaii , pp 41 - 44 .Tseng H , Chang P , Andrew G , Jurafsky D , Manning C ( 2005 )A conditional random field word segmenter .In : IJCNLP-05 , fourth SIGHAN workshop on Chinese language processing , Jeju Island , Korea , pp 168 - 171 .", "label": "", "metadata": {}, "score": "78.666176"}
{"text": "As a result of this similarity in ' signals , ' female - authored books cluster together on the south side of the main network , while male - authored books are drawn together in the north .12 These two ' views ' of the network allow us to begin imagining the larger macro - history of thematic - stylistic change and influence in the 19th - century novel .", "label": "", "metadata": {}, "score": "78.71348"}
{"text": "The authors found , among other things , evi- dence that social media activity of particular types preceded mass protests and other incidents .Whereas the study conducted by Howard et al . was retrospective , this pa- per presents a preliminary investigation of the predictive power of social media information , in particular information produced by the Twitter service .", "label": "", "metadata": {}, "score": "78.80415"}
{"text": "The Pyramid Volkovs , M. and Zemel , R. ( 2009 ) .In Proceedings tures .Journal of Machine Learning Research , 8 , of the 26th Annual International Conference on Ma- 725 - 760 . chine Learning , pages 1089 - 1096 .", "label": "", "metadata": {}, "score": "79.13164"}
{"text": "-ntopics : The number of topics .Its default value is 100 .This depends on the input dataset .See [ Griffiths04 ] and [ Blei03 ] for a more careful discussion of selecting the number of topics .-niters : The number of Gibbs sampling iterations .", "label": "", "metadata": {}, "score": "79.500015"}
{"text": "In the last 3 images neither method predicts the right label(armrest , night snake and heifer ) but LaSR seems slightly better ( e.g. more cat , snake and cow predictions ) .models trained with a ranking loss instead , which weTable 5 : Summary of Test Set Results on Im- refer to as Rank SVM , as it is an online version ofagenet .", "label": "", "metadata": {}, "score": "79.64153"}
{"text": "It is most useful when analyzing hundreds or thousands of documents , but can be applied to smaller numbers of short documents if they describe a small number of concepts . \"( University of Tennessee , OIT , retrieved 14 march 2012 .", "label": "", "metadata": {}, "score": "79.94742"}
{"text": "Each line after that is one document .[ document i ] is the i th document of the dataset that consists of a list of N i words / terms .N i ) are text strings and they are separated by the blank character .", "label": "", "metadata": {}, "score": "79.9534"}
{"text": "The Journal of Machine ( 2008 ) .Global ranking using continuous conditional Learning Research , 3 , 993 - 1022 .In Proceedings of the Twenty - SecondCrammer , K. and Singer , Y. ( 2002 ) .On the algo- Annual Conference on Neural Information Process- rithmic implementation of multiclass kernel - based ing Systems ( NIPS 2008 ) .", "label": "", "metadata": {}, "score": "80.4483"}
{"text": "Similarly , the model was saved at the 1200 th iteration is model-01200 .The model name of the last Gibbs sampling iteration is model - final . ..others: This file contains some parameters of LDA model , such as : . # i.e. , number of topics .", "label": "", "metadata": {}, "score": "81.09733"}
{"text": "New York : Oxford UP .Bloom , H .The anatomy of influence : literature as a way of life .New Haven , Conn. : Yale UP .Brik , O. M .Teaching Writers .Chang , J. , J. Boyd - Graber , et al .", "label": "", "metadata": {}, "score": "81.416504"}
{"text": "A C / C++ compiler and the STL library .The computational time of GibbsLDA++ much depends on the size of input data , the CPU speed , and the memory size .If your dataset is quite large ( e.g. , larger than 100,000 documents or so ) , it is better to train GibbsLDA++ on a minimum of 2GHz CPU , 1Gb RAM system .", "label": "", "metadata": {}, "score": "82.04714"}
{"text": "This reduces the dimensionality of docd and provides meaningful structured data for our predictive model , which is described next .Predictive Model docd contains the events that occurred on day d. Our goal is to use docd to make predictions about incidents in the future .", "label": "", "metadata": {}, "score": "82.29976"}
{"text": "The supported methods include the native SenseClusters techniques and Latent Semantic Analysis . \"( SenseClusters , retrieved 12:10 , 12 March 2012 ( CET ) .S - Space Package a Java package by Jurgens David and Keith Stevens . \"", "label": "", "metadata": {}, "score": "82.51961"}
{"text": "The default value of alpha is 50 / K ( K is the the number of topics ) .See [ Griffiths04 ] for a detailed discussion of choosing alpha and beta values .-beta : The value of beta , also the hyper - parameter of LDA .", "label": "", "metadata": {}, "score": "83.63034"}
{"text": "An essential part of this context is the stream of informa- tion created by users of services such as Facebook1 and Twitter2 .These services allow users to instantly create , disseminate , and consume information from any location with access to the Internet .", "label": "", "metadata": {}, "score": "83.72321"}
{"text": "on Comp .Biology and Bioinformatics 2(2 ) , 143 - 156 ( 2005 ) CrossRef .Dhanasekaran , S. , Barrette , T. , et al .: Delineation of prognostic biomarkers in prostate cancer .Nature 23412(6849 ) , 822 - 826 ( 2001 ) CrossRef .", "label": "", "metadata": {}, "score": "83.73404"}
{"text": "Google , Mountain View , USA .In particular , Singular Value Decomposition document or image retrieval and annotation .In the task of document retrieval , returned as a whole ) is not taken into ac- on the other hand , one is required to rank text docu- count .", "label": "", "metadata": {}, "score": "83.85779"}
{"text": "You should download version 0.2 that includes bug fix and code optimization , and thus faster than the version 0.1 .A Java implementation ( JGibbLDA ) is also available .You can download at its project page .Environments .Unix , Linux , Cygwin , and MinGW .", "label": "", "metadata": {}, "score": "83.964645"}
{"text": "$ src / lda -estc -dir models / casestudy/ -model model-01000 -niters 800 -savestep 100 -twords 30 .Now , look into the casestudy directory to see the outputs .$ src / lda -inf -dir models / casestudy/ -model model-01800 -niters 30 -twords 20 -dfile newdocs.dat .", "label": "", "metadata": {}, "score": "84.923225"}
{"text": "Assume you have a set of documents each of which is in either English or in Spanish .The collection is given in Figure 18.4 .Construct the appropriate term - document matrix to use for a collection consisting of these documents .", "label": "", "metadata": {}, "score": "85.742035"}
{"text": "Command line : .$ lda -inf -dir -model [ -niters ] [ -twords ] -dfile . in which ( parameters in [ ] are optional ) : . -inf : Do inference for previously unseen ( new ) data using a previously estimated LDA model .", "label": "", "metadata": {}, "score": "85.81769"}
{"text": "Vienna : Austria , R Foundation for Statistical Computing .Twain , M. , and A. B. Paine ( 1975 ) .Mark Twain 's letters .New York : AMS Press .Yang , Y. , and J. Pedersen ( 1997 ) .", "label": "", "metadata": {}, "score": "86.67871"}
{"text": "In : Proceedings of Human Language Technologies : The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics .pp .146 - 154 .Association for Computational Linguistics , Boulder , Col- orado ( June 2009 ) 9 .", "label": "", "metadata": {}, "score": "87.26524"}
{"text": "-model : The name of the previously estimated model .See section \" Outputs \" to know how GibbsLDA++ saves outputs on hard disk .-niters : The number of Gibbs sampling iterations for inference .The default value is 20 .", "label": "", "metadata": {}, "score": "87.567444"}
{"text": "The shading of nodes and edges according to publication date reveals the inherently chronological nature of stylistic and thematic change .The progressive darkening of the nodes from east to west allows us to see , at the macro - scale , how style and theme are changing and evolving over time . 10 Also seen in this image is a ' satellite ' of books in the northwest .", "label": "", "metadata": {}, "score": "87.89387"}
{"text": "If you set this parameter a value larger than zero , e.g. , 20 , GibbsLDA++ will print out the list of top 20 most likely words per each topic each time it save the model to hard disk according to the parameter savestep above .", "label": "", "metadata": {}, "score": "88.14891"}
{"text": "If you set this parameter a value larger than zero , e.g. , 20 , GibbsLDA++ will print out the list of top 20 most likely words per each topic each time it save the model to hard disk according to the parameter savestep above .", "label": "", "metadata": {}, "score": "88.14891"}
{"text": "The NIPS paper is just cool .A bunch of the papers mentioned above have descriptions of sampling algorithms and/or variational inference procedures for specific models .For more general information on these topics , consider reading some of the following : .", "label": "", "metadata": {}, "score": "88.67551"}
{"text": "The default value is zero .If you set this parameter a value larger than zero , e.g. , 20 , GibbsLDA++ will print out the list of top 20 most likely words per each topic after inference .-dfile : The file containing new data .", "label": "", "metadata": {}, "score": "89.08858"}
{"text": "Acknowledgements .Our code is based on the Java code of Gregor Heinrich and the theoretical description of Gibbs Sampling for LDA in [ Heinrich].I would like to thank Heinrich for sharing the code and a comprehensive technical report .", "label": "", "metadata": {}, "score": "89.507286"}
{"text": "The following sections describe these steps in detail .3.1 Data Collection The user base of Twitter comprises a vast community of news agencies , jour- nalists , and casual users who post tweets from their Internet - connected devices .4 Each tweet is restricted to 140 characters and can be observed by those who subscribe to the poster 's Twitter feed .", "label": "", "metadata": {}, "score": "89.9276"}
{"text": "For example , CBS194 in Charlottesville , Virginia published 3,659 tweets during the period of February 22 , 2011 through October 21 , 2011 ( approximately 15 per day ) .We collected these tweets using the public interface provided by Twitter .", "label": "", "metadata": {}, "score": "91.29962"}
{"text": "See the GNU General Public License for more details .You should have received a copy of the GNU General Public License along with GibbsLDA++ ; if not , write to the Free Software Foundation , Inc. , 59 Temple Place , Suite 330 , Boston , MA 02111 - 1307 USA .", "label": "", "metadata": {}, "score": "92.15988"}
{"text": "Recognizing surface Series B , 48 , 259 - 302 .using three - dimensional textons .Proc . of 7th Int'lBillsus , D. and Pazzani , M. ( 1998 ) .Learning collabo- Conf . on Computer Vision , Corfu , Greece .", "label": "", "metadata": {}, "score": "92.32776"}
{"text": "Command line : .$ lda -est [ -alpha ] [ -beta ] [ -ntopics ] [ -niters ] [ -savestep ] [ -twords ] -dfile . in which ( parameters in [ ] are optional ) : .-est : Estimate the LDA model from scratch .", "label": "", "metadata": {}, "score": "92.646576"}
{"text": "LREC'08 , Marrakech , Morocco , May 2008 Reading list on Bayesian modeling for language .People often ask me what they can read to learn more about recent Bayesian modeling techniques and their applications to language learning .Here is a list of the papers I have found to be most useful and relevant to my own research .", "label": "", "metadata": {}, "score": "92.845795"}
{"text": "For this , I employ the tools and techniques of stylometry , corpus linguistics , machine learning , and network analysis to measure influence in a corpus of late 18th- and 19th - century novels .Method .The 3,592 books in my corpus span from 1780 to 1900 and were written by authors from Britain , Ireland , and America ; the corpus is almost even in terms of gender representation .", "label": "", "metadata": {}, "score": "93.64871"}
{"text": "11 When the network is recolored according to gender ( figure 3 ) , a new axis can be seen splitting the network into northern and southern sectors along gender lines .Figure 3 : The 19 th -century novel network colored according to author - gender .", "label": "", "metadata": {}, "score": "94.342224"}
{"text": "Reading TeaLeaves : How Humans Interpret Topic Models Advances in Neural Information Processing Systems 22 .Eliot , T. S. ( 1920 ) .The sacred wood ; essays on poetry and criticism .London : Methuen .Garcia , M. , and C. Martin ( 2007 ) .", "label": "", "metadata": {}, "score": "95.2417"}
{"text": "The signals introduced by Austen and Scott position them at the beginning of a stylistic - thematic genealogy ; they are , in this sense , the literary equivalent of Homo erectus or , if you prefer , Adam and Eve .", "label": "", "metadata": {}, "score": "95.59464"}
{"text": "20 closed due to a wreck .( 2 ) Road closed at JPA and Shamrock due to tree falling over road .Intuitively , these tweets provide evidence of an increased hazard level along road- ways , which , in turn , might lead to an increased number of accidents or hit - and- run crimes .", "label": "", "metadata": {}, "score": "95.67926"}
{"text": "174 - 189 .Notes .Routinely attributed to Wilde , but of uncertain origin , Wilde probably ' borrowed ' this quip .An extreme case may be Fielding 's Shamela , which attempts to satirize Richardson 's Pamela .Features with a corpus mean less than 0.10 were excluded .", "label": "", "metadata": {}, "score": "96.4618"}
{"text": "HM - BiTAM : Bilingual topic exploration , word alignment , and translation .In : Twenty - second annual conference on neural information processing systems , Vancouver BC , Canada All ideas are second hand , consciously and unconsciously drawn from a million outside sources ' - Mark Twain ( 1903 ) .", "label": "", "metadata": {}, "score": "96.61913"}
{"text": "Our investigation did not attempt to acquire and digest all \" tweets \" ( short messages created by Twitter users ) ; rather , we pulled tweets from the Twitter feed of a news agency covering the area of Charlottesville , Virginia .", "label": "", "metadata": {}, "score": "97.01175"}
{"text": "We show top ranked results for a popular query , \" Bob Dylan \" ( folk rock music ) and a less popularquery \" Plaid \" ( electronic music ) .Total numbers of train and test pairs for given artist pairs are in squarebrackets , and totals for all artists shown are given in the last row .", "label": "", "metadata": {}, "score": "98.741714"}
{"text": "The elements of which the artwork is created are external to the author and independent of him ... ' - Osip Brik ( 1929 ) .Anxiety of Influence - Harold Bloom ( 1973 ) .Whether consciously influenced by a predecessor or not , it might be argued that every book is in some sense a necessary descendant of , or necessarily ' connected to , ' those before it .", "label": "", "metadata": {}, "score": "101.80908"}
{"text": "Lastly , the predictive model ( Equation 4 ) uses this distribution to predict the likelihood of an incident occurring on day d + 1 . 4 Evaluation and Results We evaluated our predictive model using Twitter data and actual hit - and - run incidents that occurred in Charlottesville , Virginia .", "label": "", "metadata": {}, "score": "103.7782"}
{"text": "$ gunzip GibbsLDA++ . tar.gz .$ tar -xf GibbsLDA++ . tar .Compile .Go to the home directory of GibbsLDA++ ( i.e. GibbsLDA++ directory ) , and type : .$ make clean .$ make all .After compiling GibbsLDA++ , we have an executable file \" lda \" in the GibbsLDA++/src directory .", "label": "", "metadata": {}, "score": "105.58872"}
{"text": "Harriet Beecher Stowe 's Uncle Tom 's Cabin , for example , clusters closer to the works of male authors , and Maria Edgeworth 's Belinda has a signal that does not become dominant for forty years after the date of Belinda 's publication .", "label": "", "metadata": {}, "score": "106.830215"}
{"text": "Other potential applications in biological data .Contact us : all comments , suggestions , and bug reports are highly appreciated .And if you have any further problems , please contact us : .Xuan - Hieu Phan ( pxhieu at gmail dot com ) , was at Tohoku University , Japan ( now at Vietnam National University , Hanoi ) Cam - Tu Nguyen ( ncamtu at gmail dot com ) , was at Vietnam National University , Hanoi ( now at Google Japan ) .", "label": "", "metadata": {}, "score": "116.23783"}
