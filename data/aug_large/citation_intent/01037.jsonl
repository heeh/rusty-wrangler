{"text": "The reader should understand that , under the probabilistic logic , the principle of entropy maximization is a fact and not a theory , conjecture or empirical finding .Thus , this principle provides a portion of the bedrock upon which a model may be founded .", "label": "", "metadata": {}, "score": "28.130325"}
{"text": "The entropy of the inference to the ways in which a state can occur is maximized , under constraints expressing the available information .The correct inference is the one that maximizes its own entropy .Thus , the principle of entropy maximization is a principle of reasoning .", "label": "", "metadata": {}, "score": "28.211143"}
{"text": "This solution , however , assumes that the experimental noise can be interpreted as \" hard \" limits and does not represent the fact that the experimental measurement is just an estimate of the underlying true value .As an alternative solution to this problem , Cavalli et al . propose a combination of the maximum entropy principle and Bayesian inference with a prior distribution that reflects the uncertainty of the measured quantity .", "label": "", "metadata": {}, "score": "28.428154"}
{"text": "This solution , however , assumes that the experimental noise can be interpreted as \" hard \" limits and does not represent the fact that the experimental measurement is just an estimate of the underlying true value .As an alternative solution to this problem , Cavalli et al . propose a combination of the maximum entropy principle and Bayesian inference with a prior distribution that reflects the uncertainty of the measured quantity .", "label": "", "metadata": {}, "score": "28.428154"}
{"text": "The principle of maximum entropy is useful explicitly only when applied to testable information .Testable information is a statement about a probability distribution whose truth or falsity is well - defined .For example , the statements .Entropy maximization with no testable information respects the universal \" constraint \" that the sum of the probabilities is one .", "label": "", "metadata": {}, "score": "29.09246"}
{"text": "With this brief introduction , we hope that we have conveyed the general applicability of the principle of maximum entropy .In particular , in combination with Bayesian inference , it is a powerful tool for consistent reasoning in the light of new data .", "label": "", "metadata": {}, "score": "29.198105"}
{"text": "With this brief introduction , we hope that we have conveyed the general applicability of the principle of maximum entropy .In particular , in combination with Bayesian inference , it is a powerful tool for consistent reasoning in the light of new data .", "label": "", "metadata": {}, "score": "29.198105"}
{"text": "Each set defines a different inference .Which inference is correct ?The model builder must decide !The principle of entropy maximization applies to the situation described .The correct inference to F ( W i given W i OR W j ) is the one which maximizes its own entropy , under constraints expressing the available information .", "label": "", "metadata": {}, "score": "30.372921"}
{"text": "As an alternative to the Bayesian pooling methods , this article introduces a decision rule based on the ' non - extensive entropy ' , which portraits the concept of generalized entropy as a quantitative criterion for measuring uncertainty in estimations .", "label": "", "metadata": {}, "score": "30.469936"}
{"text": "It is apt to classify maximum entropy expectation as a principle of reasoning because : a ) it is based upon the principle of entropy maximization and b ) the latter principle is a fact , under the probabilistic logic .In the nineteenth century , a group of logicians advocated a reform in the field of mathematical statistics .", "label": "", "metadata": {}, "score": "30.664764"}
{"text": "Each such inference assigns a number to the probability of each element of F ( W i given W i OR W j ) .Many inferences of the first and second kinds are possibilities .Which ones are correct ?The principle of entropy maximization applies to the situation .", "label": "", "metadata": {}, "score": "31.64099"}
{"text": "The maximum entropy principle makes explicit our freedom in using different forms of prior data .As a special case , a uniform prior probability density ( Laplace 's principle of indifference , sometimes called the principle of insufficient reason ) , may be adopted .", "label": "", "metadata": {}, "score": "31.825996"}
{"text": "This principle is entropy minimization .A derivation of the principle follows .If the observed state space of an inference contains several states , under the probabilistic logic the unique measure of this inference is its conditional entropy .The conditional entropy of an inference is the missing information in this inference , for a deductive conclusion .", "label": "", "metadata": {}, "score": "31.84082"}
{"text": "It means that thermodynamics systems need not be shown to be ergodic to justify treatment as a statistical ensemble .In ordinary language , the principle of maximum entropy can be said to express a claim of epistemic modesty , or of maximum ignorance .", "label": "", "metadata": {}, "score": "32.101562"}
{"text": "Alternatively , the principle is often invoked for model specification : in this case the observed data itself is assumed to be the testable information .Such models are widely used in natural language processing .An example of such a model is logistic regression , which corresponds to the maximum entropy classifier for independent observations .", "label": "", "metadata": {}, "score": "32.265568"}
{"text": "The correct inference is the one that maximizes its own entropy , under constraints expressing the available information .Designing an encoder in this manner eliminates logical error from the inference that made by this encoder .Shannon described a second principle of reasoning for the modern theory of communication .", "label": "", "metadata": {}, "score": "32.31271"}
{"text": "Next , through examples , it shows that maximizing entropy sometimes can stand in direct opposition to Bayesian updating based on reasonable prior beliefs .The paper concludes that if we take the Bayesian approach that probability is about reasonable belief based on all available information , then we can resolve the conflict between the maximum entropy approach and the Bayesian approach that is demonstrated in the examples .", "label": "", "metadata": {}, "score": "32.418587"}
{"text": "That is to say , when characterizing some unknown events with a statistical model , we should always choose the one that has Maximum Entropy .Maximum Entropy Modeling has been successfully applied to Computer Vision , Spatial Physics , Natural Language Processing and many other fields .", "label": "", "metadata": {}, "score": "32.667866"}
{"text": "The least informative distribution would occur when there is no reason to favor any one of the propositions over the others .In that case , the only reasonable probability distribution would be uniform , and then the information entropy would be equal to its maximum possible value , log m .", "label": "", "metadata": {}, "score": "32.731743"}
{"text": "A guide for authors and other relevant information for submission of manuscripts is available on the Instructions for Authors page .Entropy is an international peer - reviewed Open Access monthly journal published by MDPI .Abstract : The Principle of Maximum Entropy is often used to update probabilities due to evidence instead of performing Bayesian updating using Bayes ' Theorem , and its use often has efficacious results .", "label": "", "metadata": {}, "score": "33.384827"}
{"text": "Maximum entropy expectation solves the inverse problem .In setting up the inverse problem for solution , Christensen describes inferences by a carefully contrived strategy .This strategy is designed to render every issue of which of several inferences is correct decidable , under the principle of entropy maximization .", "label": "", "metadata": {}, "score": "34.220776"}
{"text": "The ' entropy ' that is maximized needs to be defined suitably for the problem at hand .If an inappropriate ' entropy ' is maximized , a wrong result is likely .In principle , maximum entropy thermodynamics does not refer narrowly and only to classical thermodynamic entropy .", "label": "", "metadata": {}, "score": "34.565647"}
{"text": "Furthermore , some numerical experiments indicate that the robust model in this paper can result in betterportfolio performance than a classical mean - variance model .Abstract : The maximum entropy method was originally proposed as a variational technique to determine probability densities from the knowledge of a few expected values .", "label": "", "metadata": {}, "score": "34.768486"}
{"text": "By choosing to use the distribution with the maximum entropy allowed by our information , the argument goes , we are choosing the most uninformative distribution possible .To choose a distribution with lower entropy would be to assume information we do not possess .", "label": "", "metadata": {}, "score": "34.81547"}
{"text": "This procedure is sometimes referred to as the principle of minimum discrimination information or minimum cross entropy , but can be seen as a natural extension of the maximum entropy approach .There is a substantial literature on the foundations of maximum entropy and why it is an appropriate framework for inference [ 1 ] , [ 14 ] - [ 16 ] .", "label": "", "metadata": {}, "score": "35.134186"}
{"text": "This procedure is sometimes referred to as the principle of minimum discrimination information or minimum cross entropy , but can be seen as a natural extension of the maximum entropy approach .There is a substantial literature on the foundations of maximum entropy and why it is an appropriate framework for inference [ 1 ] , [ 14 ] - [ 16 ] .", "label": "", "metadata": {}, "score": "35.134186"}
{"text": "Maximum entropy expectation assigns a number to Pr ( T l given U m ) over each value of the index l and the index m. The manner in which it computes each such number is the topic of the following derivation .", "label": "", "metadata": {}, "score": "35.519543"}
{"text": "Which inference is correct ?The principle of entropy maximization applies to the situation described .Under this principle , the correct inference maximizes its own entropy , under constraints expressing the available information .The information about the way in which the outcome will occur is nil , by the definition of a fair gambling device .", "label": "", "metadata": {}, "score": "36.411606"}
{"text": "Note that there is an important difference between adding a constraint on the second moment ( the variance ) and incorporating knowledge about the error of the first moment ( error of the mean ) .The former can easily be dealt with using the maximum entropy principle , while the latter is more problematic .", "label": "", "metadata": {}, "score": "36.553505"}
{"text": "Note that there is an important difference between adding a constraint on the second moment ( the variance ) and incorporating knowledge about the error of the first moment ( error of the mean ) .The former can easily be dealt with using the maximum entropy principle , while the latter is more problematic .", "label": "", "metadata": {}, "score": "36.553505"}
{"text": "The first is entropy minimization .The second is maximum entropy expectation .When the construction of a model is guided by entropy minimax , the elements of the observed state - space C are optimized abstractions .If knowledge is created by a scientific investigation , this is by the construction of a model .", "label": "", "metadata": {}, "score": "36.604843"}
{"text": "Maximum entropy approach .Given the possibility of both overfitting experimental data and underrestraining by unfavourable data - to - parameter ratios , it would be preferable to have a theoretically well - founded method for combining experiment and simulation .Incorporating experimental data into a simulation is essentially a matter of updating a probability distribution ( the original Boltzmann distribution defined by the force field ) in the light of new data .", "label": "", "metadata": {}, "score": "36.88436"}
{"text": "Maximum entropy approach .Given the possibility of both overfitting experimental data and underrestraining by unfavourable data - to - parameter ratios , it would be preferable to have a theoretically well - founded method for combining experiment and simulation .Incorporating experimental data into a simulation is essentially a matter of updating a probability distribution ( the original Boltzmann distribution defined by the force field ) in the light of new data .", "label": "", "metadata": {}, "score": "36.88436"}
{"text": "The model builder must decide !Under the principle of entropy maximization , the correct inference is the one that maximizes its own entropy , under constraints expressing the available information .What are the natures of the constraints ?In answering this question , Christensen makes a second application of the principle of entropy maximization .", "label": "", "metadata": {}, "score": "37.46263"}
{"text": "In the twentieth century , Shannon described a similar principle for the modern theory of communication .Subsequently , various theorists generalized the two principles to a principle of reasoning for models , in general .This principle is entropy maximization .", "label": "", "metadata": {}, "score": "37.587337"}
{"text": "Then the maximum entropy probability density function is . where A is a normalization constant .The invariant measure function is actually the prior density function encoding ' lack of relevant information ' .It can not be determined by the principle of maximum entropy , and must be determined by some other logical method , such as the principle of transformation groups or marginalization theory .", "label": "", "metadata": {}, "score": "37.98594"}
{"text": "Another way of stating this : Take precisely stated prior data or testable information about a probability distribution function .Consider the set of all trial probability distributions that would encode the prior data .Of those , the one with maximal information entropy is the proper distribution , according to this principle .", "label": "", "metadata": {}, "score": "38.026634"}
{"text": "They state that this method reproduces every aspect of orthodox Bayesian inference methods .In addition this new method opens the door to tackling problems that could not be addressed by either the maximal entropy principle or orthodox Bayesian methods individually .", "label": "", "metadata": {}, "score": "38.04757"}
{"text": "Higher values of will draw the mean value closer to the restraint , while increasing values of will increase the variance .Convergence can be assessed by simultaneously probing the violation of the expectation values relative to the restraints and the entropy of the distribution ( or the entropy corresponding to the restrained subspace ) .", "label": "", "metadata": {}, "score": "38.646713"}
{"text": "Higher values of will draw the mean value closer to the restraint , while increasing values of will increase the variance .Convergence can be assessed by simultaneously probing the violation of the expectation values relative to the restraints and the entropy of the distribution ( or the entropy corresponding to the restrained subspace ) .", "label": "", "metadata": {}, "score": "38.646713"}
{"text": "The other is the additional piece of evidence E 1 .Under constraints expressing the available information in E 1 , maximization of the entropy yields the probability distribution function Pr [ F ( W i given W i OR W j ) given E 1 ] .", "label": "", "metadata": {}, "score": "39.147552"}
{"text": "These arguments take the use of Bayesian probability as given , and are thus subject to the same postulates .Consider a discrete probability distribution among m mutually exclusive propositions .The most informative distribution would occur when one of the propositions was known to be true .", "label": "", "metadata": {}, "score": "39.18309"}
{"text": "The principle of maximum entropy is often used to obtain prior probability distributions for Bayesian inference .Jaynes was a strong advocate of this approach , claiming the maximum entropy distribution represented the least informative distribution .[ 3 ] A large amount of literature is now dedicated to the elicitation of maximum entropy priors and links with channel coding .", "label": "", "metadata": {}, "score": "39.264633"}
{"text": "Methodology : An alternative decision rule , based on the non - extensive entropy principle , is introduced , and a different Precautionary Principle characterization is applied .This approach values extreme negative results ( catastrophic events ) in a different way and predicts more plausible and mild events .", "label": "", "metadata": {}, "score": "39.640858"}
{"text": "The central idea is that among all the infinite number of distributions that are compatible with the data , one should select the distribution which maintains the largest degree of uncertainty about the variables of interest , thus ensuring that the data has been used as conservatively as possible .", "label": "", "metadata": {}, "score": "39.855064"}
{"text": "The central idea is that among all the infinite number of distributions that are compatible with the data , one should select the distribution which maintains the largest degree of uncertainty about the variables of interest , thus ensuring that the data has been used as conservatively as possible .", "label": "", "metadata": {}, "score": "39.855064"}
{"text": "Abstract : The maximum entropy method is a theoretically sound approach to construct an analytical form for the probability density function ( pdf ) given a sample of random events .In practice , numerical methods employed to determine the appropriate Lagrange multipliers associated with a set of moments are generally unstable in the presence of noise due to limited sampling .", "label": "", "metadata": {}, "score": "39.97888"}
{"text": "Unlike the Shannon entropy , the relative entropy H c has the advantage of remaining finite and well - defined for continuous x , and invariant under 1-to-1 coordinate transformations .The two expressions coincide for discrete probability distributions , if one can make the assumption that m ( x i ) is uniform - i.e. the principle of equal a - priori probability , which underlies statistical thermodynamics .", "label": "", "metadata": {}, "score": "40.04827"}
{"text": "In particular , they showed that the maximum entropy solution appears as a limit of the replica method when the harmonic potential enforcing the replica - averaged restraint becomes infinitely narrow .More precisely , the distribution of each replica in a replica - averaged ensemble simulation ( Eq . 1 ) will approach the maximum entropy distribution if both and .", "label": "", "metadata": {}, "score": "40.354263"}
{"text": "In particular , they showed that the maximum entropy solution appears as a limit of the replica method when the harmonic potential enforcing the replica - averaged restraint becomes infinitely narrow .More precisely , the distribution of each replica in a replica - averaged ensemble simulation ( Eq . 1 ) will approach the maximum entropy distribution if both and .", "label": "", "metadata": {}, "score": "40.354263"}
{"text": "[ 13 ] .Though the maximum entropy approach is based directly on informational entropy , it is applicable to physics only when there is a clear physical definition of entropy .There is no clear unique general physical definition of entropy for non - equilibrium systems , which are general physical systems considered during a process rather than thermodynamic systems in their own internal states of thermodynamic equibibrium .", "label": "", "metadata": {}, "score": "40.84034"}
{"text": "The model of maximum entropy distributions is characterized to be totally geodesic with respect to the linear connection associated with the divergence .A natural extension for the classical theory for the maximum likelihood method under the maximum entropy model in terms of the Boltzmann - Gibbs - Shannon entropy is given .", "label": "", "metadata": {}, "score": "41.076714"}
{"text": "The relationship between replica - based simulations and the maximum entropy formalism was clarified and mathematically proven in papers by Roux and Weare [ 10 ] and Cavalli et al .[ 11 ] , both of which demonstrated that a replica - based approach is equivalent to the maximum entropy solution .", "label": "", "metadata": {}, "score": "41.11186"}
{"text": "The relationship between replica - based simulations and the maximum entropy formalism was clarified and mathematically proven in papers by Roux and Weare [ 10 ] and Cavalli et al .[ 11 ] , both of which demonstrated that a replica - based approach is equivalent to the maximum entropy solution .", "label": "", "metadata": {}, "score": "41.11186"}
{"text": "This is the way the maximum entropy principle is most often used in statistical thermodynamics .Another possibility is to prescribe some symmetries of the probability distribution .The equivalence between conserved quantities and corresponding symmetry groups implies a similar equivalence for these two ways of specifying the testable information in the maximum entropy method .", "label": "", "metadata": {}, "score": "41.258377"}
{"text": "However , under the tradition , the application of it is illogical for violating the law of non - contradiction .Usually , a result from acting on this conclusion is for the model to fail from the resulting shrinkage .Either the principle of entropy maximization is empirically invalidated or the tradition is empirically invalidated .", "label": "", "metadata": {}, "score": "41.62901"}
{"text": "It is therefore as \" real \" as the other variables in the model description .If the model constraints in the probability assignment are a \" good \" description , containing all the information needed to predict reproducible experimental results , then that includes all of the results one could predict using the formulae involving entropy from classical thermodynamics .", "label": "", "metadata": {}, "score": "41.70917"}
{"text": "According to Attard , for physical problems analyzed by strongly non - equilibrium thermodynamics , several physically distinct kinds of entropy need to be considered , including what he calls second entropy .Attard writes : \" Maximizing the second entropy over the microstates in the given initial macrostate gives the most likely target macrostate .", "label": "", "metadata": {}, "score": "41.72986"}
{"text": "Each way defines a different inference .Which inference is correct ?The model builder must decide !The principle of entropy maximization does not apply to this situation , for its task is to assign numerical values to the probabilities of the states in an unobserved state - space .", "label": "", "metadata": {}, "score": "42.384506"}
{"text": "If and only if the observed state - space of an inference contains a single state then , under the probabilistic logic , the unique measure of this inference is its entropy .If and only if the states in the unobserved state - space of this inference are examples of ways , the entropy possesses a maximum .", "label": "", "metadata": {}, "score": "42.487644"}
{"text": "The results also show that that one can reach apparent convergence at lower values of the force constant , but that the resulting distribution in this case will not be the maximum entropy solution .For these and related problems , we also need better methods to check for convergence , both to study the effect of varying these restraint - parameters and to monitor and ensure sufficient sampling of the ensembles .", "label": "", "metadata": {}, "score": "42.725124"}
{"text": "The results also show that that one can reach apparent convergence at lower values of the force constant , but that the resulting distribution in this case will not be the maximum entropy solution .For these and related problems , we also need better methods to check for convergence , both to study the effect of varying these restraint - parameters and to monitor and ensure sufficient sampling of the ensembles .", "label": "", "metadata": {}, "score": "42.725124"}
{"text": "Each partition generates a different set of descriptions for the states in C .Each such set defines a different inference from C to O .Which of these inferences is correct ?The model builder must decide !The principle of entropy minimization applies to the situation described .", "label": "", "metadata": {}, "score": "42.82605"}
{"text": "He accepted that in a sense , a state of knowledge has a subjective aspect , simply because it refers to thought , which is a mental process .But he emphasized that the principle of maximum entropy refers only to thought which is rational and objective , independent of the personality of the thinker .", "label": "", "metadata": {}, "score": "42.82961"}
{"text": "There is therefore a crucial need of models allowing the prediction of this distribution .However , atomization processes are partially known and so far a universal model is not available .For almost thirty years , models based on the Maximum Entropy Formalism have been proposed to fulfill this task .", "label": "", "metadata": {}, "score": "43.047302"}
{"text": "For non - equilibrium scenarios , in an approximation that assumes local thermodynamic equilibrium , with the maximum entropy approach , the Onsager reciprocal relations and the Green - Kubo relations fall out directly .The approach also creates a theoretical framework for the study of some very special cases of far - from - equilibrium scenarios , making the derivation of the entropy production fluctuation theorem straightforward .", "label": "", "metadata": {}, "score": "43.407776"}
{"text": "The information entropy function is not assumed a priori , but rather is found in the course of the argument ; and the argument leads naturally to the procedure of maximizing the information entropy , rather than treating it in some other way .", "label": "", "metadata": {}, "score": "43.641945"}
{"text": "The thermodynamic entropy may go \" down \" as well as up .A more sophisticated analysis is given by the entropy Fluctuation Theorem , which can be established as a consequence of the time - dependent MaxEnt picture .As just indicated , the MaxEnt inference runs equally well in reverse .", "label": "", "metadata": {}, "score": "43.76448"}
{"text": "Another question is related to the steepness of the potential used to implement the restraint : how narrow should the potential be to mimic the appropriate -function that will ensure the maximum entropy correspondence ?Previous work has either found optimal values of the number of replicas by cross - validation , or simply chosen a sufficiently large to obtain convergence .", "label": "", "metadata": {}, "score": "43.85225"}
{"text": "Another question is related to the steepness of the potential used to implement the restraint : how narrow should the potential be to mimic the appropriate -function that will ensure the maximum entropy correspondence ?Previous work has either found optimal values of the number of replicas by cross - validation , or simply chosen a sufficiently large to obtain convergence .", "label": "", "metadata": {}, "score": "43.85225"}
{"text": "The probability distribution represents the excess of a randomness over the distribution and the H kl , which is the Kullback - Leibler distance , measures the maximum feasible divergence between the two probability distributions .It is worth observing that the measure of distance between distributions represents the constraint that has to be satisfied by the distribution H ( P ) , which is the optimal solution of the following Problem 1 .", "label": "", "metadata": {}, "score": "43.911423"}
{"text": "Maximize the knowledge .His second principle of reasoning constrains the process of maximization of the knowledge by the availability of information for this purpose .With the availability of no information , no knowledge is created .In practice , it is usually true that some but not perfect knowledge is created .", "label": "", "metadata": {}, "score": "44.212364"}
{"text": "Rather than actually carry out , and possibly have to repeat , the rather long random experiment , the protagonist decides to simply calculate and use the most probable result .The probability of any particular result is the multinomial distribution , .", "label": "", "metadata": {}, "score": "44.236935"}
{"text": "The number of maximum entropy applications in our field has grown steadily in recent years , in areas as diverse as sequence analysis , structural modelling , and neurobiology .In this Perspectives article , we give a broad introduction to the method , in an attempt to encourage its further adoption .", "label": "", "metadata": {}, "score": "44.283943"}
{"text": "The number of maximum entropy applications in our field has grown steadily in recent years , in areas as diverse as sequence analysis , structural modelling , and neurobiology .In this Perspectives article , we give a broad introduction to the method , in an attempt to encourage its further adoption .", "label": "", "metadata": {}, "score": "44.283943"}
{"text": "It can therefore also be used to predict a distribution for \" trajectories \" \u0393 \" over a period of time \" by maximising : .This \" information entropy \" does not necessarily have a simple correspondence with thermodynamic entropy .", "label": "", "metadata": {}, "score": "44.296104"}
{"text": "The inference assigns a numerical value to the probability of each state in the unobserved state - space .The numerical values that are assigned to the probabilities of the various states form a set .Sets of infinite number are possibilities for assignment .", "label": "", "metadata": {}, "score": "44.37303"}
{"text": "In fact , one of Jaynes ' great achievements was to demonstrate that many results in statistical mechanics could be derived by the simple application of this principle .Box 1 .A Primer to the Principle of Maximum Entropy ( Adapted from Ref .", "label": "", "metadata": {}, "score": "44.72323"}
{"text": "In fact , one of Jaynes ' great achievements was to demonstrate that many results in statistical mechanics could be derived by the simple application of this principle .Box 1 .A Primer to the Principle of Maximum Entropy ( Adapted from Ref .", "label": "", "metadata": {}, "score": "44.72323"}
{"text": "This degree of trust is currently not encoded in the force fields commonly employed in simulations .In principle , this information could be specified by providing distributions ( or at least variances ) for all estimated parameters in the force field , in the spirit of Bayesian inference , allowing the inference machinery to deduce or integrate out the relevant weights .", "label": "", "metadata": {}, "score": "44.749306"}
{"text": "This degree of trust is currently not encoded in the force fields commonly employed in simulations .In principle , this information could be specified by providing distributions ( or at least variances ) for all estimated parameters in the force field , in the spirit of Bayesian inference , allowing the inference machinery to deduce or integrate out the relevant weights .", "label": "", "metadata": {}, "score": "44.749306"}
{"text": "The nonparametric model , such as kernel density method , moving block bootstrapping method , or K - nearest neighbor resampling method , does not make assumptions about the probability distribution or dependence forms and provides an alternative for stochastic simulation [ Vogel and Shallcross , 1996 ; Sharma et al . , 1997 ; Prairie et al . , 2007 ; Nowak et al . , 2010 ] .", "label": "", "metadata": {}, "score": "44.802406"}
{"text": "The problem of maximum entropy in the context of noisy data has been addressed numerous times in other fields , leading to various forms of generalized maximum entropy procedures [ 46 ] , [ 47 ] and regularization approaches [ 48 ] , [ 49 ] .", "label": "", "metadata": {}, "score": "44.829643"}
{"text": "The problem of maximum entropy in the context of noisy data has been addressed numerous times in other fields , leading to various forms of generalized maximum entropy procedures [ 46 ] , [ 47 ] and regularization approaches [ 48 ] , [ 49 ] .", "label": "", "metadata": {}, "score": "44.829643"}
{"text": "The entropic index that represents the dependence degree among experts ' opinions is which is the usual concave and extensive Boltzman - Gibbs - Shannon entropy .13 This form of entropy was first introduced by Tsallis in 1988 , as a generalization of the standard entropy , and has been used in many applications , such as solar wind , high - energy physics and financial markets .", "label": "", "metadata": {}, "score": "44.835533"}
{"text": "All that remains for the protagonist to do is to maximize entropy under the constraints of her testable information .She has found that the maximum entropy distribution is the most probable of all \" fair \" random distributions , in the limit as the probability levels go from discrete to continuous .", "label": "", "metadata": {}, "score": "44.875835"}
{"text": "Under maximum entropy expectation , the situation is different .Thus , swapping in a new observed state space simply changes the expected value .It follows that , under maximum entropy expectation , patterns can be discovered , knowledge can be created and the principle of entropy minimization can be followed .", "label": "", "metadata": {}, "score": "45.03913"}
{"text": "The shrinkage can be eliminated .To accomplish this , the model builder eliminates the overestimation of the information about the probability of a state in T from knowing the state in U .This elimination is effected by conformity to the principle of entropy maximization .", "label": "", "metadata": {}, "score": "45.4099"}
{"text": "It follows that the degradation in the performance of this model that would result from these errors is eliminated .Thus , the model performs at the highest possible level .If the principles of reasoning are entropy minimax for the whole of logic , this logic must reduce to the deductive logic in the circumstance that every kind of missing information is reduced to nil .", "label": "", "metadata": {}, "score": "45.484985"}
{"text": "Among all possible models compatible with the new data , this will be the one that is the least biased .Or alternatively phrased , this will be the model that is as close as possible to the original distribution , while taking the new data into account .", "label": "", "metadata": {}, "score": "46.075943"}
{"text": "Among all possible models compatible with the new data , this will be the one that is the least biased .Or alternatively phrased , this will be the model that is as close as possible to the original distribution , while taking the new data into account .", "label": "", "metadata": {}, "score": "46.075943"}
{"text": "A result from satisfaction of this requirement is for the set of independent variables to take on a value for each of its variables in the period before an inference is made .In the example , the model has two independent variables .", "label": "", "metadata": {}, "score": "46.33066"}
{"text": "For instance , it is traditionally assumed that all our prior knowledge about the measured quantities can be expressed in terms of probability distributions .Often , however , we only obtain information about the average value of these quantities from experiments .", "label": "", "metadata": {}, "score": "46.467323"}
{"text": "For instance , it is traditionally assumed that all our prior knowledge about the measured quantities can be expressed in terms of probability distributions .Often , however , we only obtain information about the average value of these quantities from experiments .", "label": "", "metadata": {}, "score": "46.467323"}
{"text": "In computational biology , maximum entropy approaches are also becoming increasingly common .Examples include the formulation of models of collective neural stimuli [ 2 ] , reconstruction of protein signaling networks [ 3 ] , optimization of force fields for molecular simulation [ 4 ] , and modelling covariation among sites in protein sequences [ 5 ] , [ 6 ] .", "label": "", "metadata": {}, "score": "46.553307"}
{"text": "In computational biology , maximum entropy approaches are also becoming increasingly common .Examples include the formulation of models of collective neural stimuli [ 2 ] , reconstruction of protein signaling networks [ 3 ] , optimization of force fields for molecular simulation [ 4 ] , and modelling covariation among sites in protein sequences [ 5 ] , [ 6 ] .", "label": "", "metadata": {}, "score": "46.553307"}
{"text": "When implemented in this fashion , it is important to note that the simulations are not forced to agree perfectly with the experimental data .Instead , the level of agreement is now governed by the weight of the biasing energy term .", "label": "", "metadata": {}, "score": "46.661995"}
{"text": "When implemented in this fashion , it is important to note that the simulations are not forced to agree perfectly with the experimental data .Instead , the level of agreement is now governed by the weight of the biasing energy term .", "label": "", "metadata": {}, "score": "46.661995"}
{"text": "In particular , we discuss the complications that may arise when using the technique in practice , including the fact that all experiments contain various , sometimes unknown , sources of noise .Jaynes ' Principle of Maximum Entropy .Jaynes originally proposed the maximum entropy principle to establish a link between Shannon 's information theory [ 12 ] and statistical mechanics [ 1 ] .", "label": "", "metadata": {}, "score": "46.70691"}
{"text": "In particular , we discuss the complications that may arise when using the technique in practice , including the fact that all experiments contain various , sometimes unknown , sources of noise .Jaynes ' Principle of Maximum Entropy .Jaynes originally proposed the maximum entropy principle to establish a link between Shannon 's information theory [ 12 ] and statistical mechanics [ 1 ] .", "label": "", "metadata": {}, "score": "46.70691"}
{"text": "In the standard decision theory , Bayesian pooling methods , experts ' opinions and personal judges exist as methods for eliciting a consensus distribution .Nevertheless , the ambiguity attitude , that is , the attitude about the reliability of available information on the underlying uncertainty , emerges when individuals face vague and incomplete statistical data .", "label": "", "metadata": {}, "score": "46.73018"}
{"text": "This paper discusses some of these cases , and discusses how to identify some of the situations in which this principle should not be used .The paper starts by reviewing three approaches to probability , namely the classical approach , the limiting frequency approach , and the Bayesian approach .", "label": "", "metadata": {}, "score": "46.798935"}
{"text": "One approach that we foresee could be potentially useful in molecular simulation was proposed by Gull and Daniell in the context of image reconstruction [ 50 ] .The idea is to replace the many individual constraints with a single constraint on the statistic over all data , only matching them up to their experimental uncertainty : ( 7 )", "label": "", "metadata": {}, "score": "46.839275"}
{"text": "One approach that we foresee could be potentially useful in molecular simulation was proposed by Gull and Daniell in the context of image reconstruction [ 50 ] .The idea is to replace the many individual constraints with a single constraint on the statistic over all data , only matching them up to their experimental uncertainty : ( 7 )", "label": "", "metadata": {}, "score": "46.839275"}
{"text": "As Christensen has set up the problem , it responds to the principle of entropy maximization .Inferences of infinite number are possibilities .Each inference assigns a number to Pr [ ( W i given W i OR W j ) given E 2 ] and a different number to Pr [ ( W j given W i OR W j ) given E 2 ] .", "label": "", "metadata": {}, "score": "47.086662"}
{"text": "Such a tool allows us to refine the celebrated Lieb bound for Wehrl entropies and to discover thermodynamic - like relations that involve the degree of delocalization .Fisher - related thermal uncertainty relations are developed and the degree of purity of canonical distributions , regarded as mixed states , is connected to this Fisher measure as well .", "label": "", "metadata": {}, "score": "47.200684"}
{"text": "11 , 12 Crucially , because extreme events normally lay on the tail of the ordinary probability distributions , the non - extensive entropy principle considers the divergence between the two distributions before forecasting the pandemic events .Ambiguity attitude of the decision maker is represented through the non - extensive statistical mechanics , indeed a non - additive generalization of quantum information theory based on the non - extensive entropy , and the maximum entropy solution is defined .", "label": "", "metadata": {}, "score": "47.63457"}
{"text": "Math .Finance 2013 ) to find the maximum entropy density of an asset price to the relative entropy case .This is applied to study the impact of the choice of prior density in two market scenarios .In the first scenario , call option prices are prescribed at only a small number of strikes , and we see that the choice of prior , or indeed its omission , yields notably different densities .", "label": "", "metadata": {}, "score": "47.9011"}
{"text": "In his famous 1957 paper , Ed .T. Jaynes wrote : Information theory provides a constructive criterion for setting up probability distributions on the basis of partial knowledge , and leads to a type of statistical inference which is called the maximum entropy estimate .", "label": "", "metadata": {}, "score": "47.965973"}
{"text": "The distance between adjacent values is fixed at 1/ N and this distance is infinitesimal .We stipulate that F ( W i given W i OR W j ) is the unobserved state - space for an inference .The numerical values that are assigned to the probabilities of the elements of F ( W i given W i OR W j ) by this inference form a set .", "label": "", "metadata": {}, "score": "48.169693"}
{"text": "For our example , if we consider all possible outcomes of throws of a die , only a subset of these would be compatible with a given model .Maximizing the entropy ensures that this subset is as large as possible given the observed average value , not ruling out any more realizations than strictly necessary .", "label": "", "metadata": {}, "score": "48.17069"}
{"text": "For our example , if we consider all possible outcomes of throws of a die , only a subset of these would be compatible with a given model .Maximizing the entropy ensures that this subset is as large as possible given the observed average value , not ruling out any more realizations than strictly necessary .", "label": "", "metadata": {}, "score": "48.17069"}
{"text": "So long - term time averages and the ergodic hypothesis , despite the intense interest in them in the first part of the twentieth century , strictly speaking are not relevant to the probability assignment for the state one might find the system in .", "label": "", "metadata": {}, "score": "48.370186"}
{"text": "Thus , mathematics results from the conformity of its arguments to entropy minimax .This is the case .Perfect knowledge results from reduction of the logic to the deductive logic by the elimination of all missing information for a deductive conclusion .", "label": "", "metadata": {}, "score": "48.43267"}
{"text": "Then , the non - extensive entropy is defined as follows : .Definition 1 . is concave for ( and convex for ) ; hence , q - entropy maximizing distributions , given specific constraints , are uniquely defined for .", "label": "", "metadata": {}, "score": "48.503365"}
{"text": "[ 11 ] It means that there is thus clear evidence that some important physical information has been missed in the specification the problem .If it is correct that the dynamics \" are \" time - symmetric , it appears that we need to put in by hand a prior probability that initial configurations with a low thermodynamic entropy are more likely than initial configurations with a high thermodynamic entropy .", "label": "", "metadata": {}, "score": "49.119255"}
{"text": "v .c . u .v . )d .u . d .v .[ 9 ] With the moment constraints up to order m and pairwise product constraint in equation ( 4 ) , the maximum entropy copula density function can be obtained as [ Chui and Wu , 2009 ; Chu , 2011 ] .", "label": "", "metadata": {}, "score": "49.121803"}
{"text": "However it will no longer necessarily be a maximum entropy distribution for that new macroscopic description .On the other hand , the new thermodynamic entropy S Th ( 2 ) assuredly will measure the maximum entropy distribution , by construction .", "label": "", "metadata": {}, "score": "49.14788"}
{"text": "Under these principles , the construction of a model creates the maximum possible knowledge from fixed resources .The news of this advance has reached few of the people who need to know about it .On this Web site , the firm KnowledgeToTheMax offers a primer on the completed logic .", "label": "", "metadata": {}, "score": "49.27034"}
{"text": "But for a strongly non - equilibrium system , during a process , the state variables must include non - zero flux variables .Classical physical definitions of entropy do not cover this case , especially when the fluxes are large enough to destroy local thermodynamic equilibrium .", "label": "", "metadata": {}, "score": "49.370502"}
{"text": "One of the challenges associated with these hybrid energies is choosing such weights and other parameters for the biasing potential .Often these parameters are tuned manually .An alternative , Bayesian approach , called inferential structure determination , however , provides an elegant solution to this problem , by treating such unknown quantities as \" nuisance parameters \" and integrating them out [ 23 ] , [ 24 ] .", "label": "", "metadata": {}, "score": "49.56129"}
{"text": "One of the challenges associated with these hybrid energies is choosing such weights and other parameters for the biasing potential .Often these parameters are tuned manually .An alternative , Bayesian approach , called inferential structure determination , however , provides an elegant solution to this problem , by treating such unknown quantities as \" nuisance parameters \" and integrating them out [ 23 ] , [ 24 ] .", "label": "", "metadata": {}, "score": "49.56129"}
{"text": "It is an underdetermined problem , in the sense that there may be an infinite number of possible prior distributions that are compatible with this piece of data .A simple , but general solution to this type of problem was provided by Jaynes in 1957 , who proposed that among all the models fulfilling the constraints from the data , one should select the model containing the least amount of information [ 1 ] .", "label": "", "metadata": {}, "score": "49.563454"}
{"text": "It is an underdetermined problem , in the sense that there may be an infinite number of possible prior distributions that are compatible with this piece of data .A simple , but general solution to this type of problem was provided by Jaynes in 1957 , who proposed that among all the models fulfilling the constraints from the data , one should select the model containing the least amount of information [ 1 ] .", "label": "", "metadata": {}, "score": "49.563454"}
{"text": "Each description defines a different inference .The designer of the decoder must decide !The principle of entropy minimization applies to the situation described .That inference is correct which minimizes its own conditional entropy .Minimization of the conditional entropy through the design features of the decoder minimizes the deleterious effects of this noise .", "label": "", "metadata": {}, "score": "49.598915"}
{"text": "Nevertheless , because experts ' and scientists ' opinions were expressed as probability measures , densities , mass functions or odds , their probability distributions could have been used to form a ' consensus distribution ' , that is , a combination of all probability distributions .", "label": "", "metadata": {}, "score": "49.612198"}
{"text": "This result has immediate practical applications .Rather than determining Lagrange multipliers for all experimental observations , it is sufficient to conduct an ensemble - averaged simulation with -function constraints with a large number of replicas .In practice , -functions are difficult to work with and are often replaced with a steep potential , for instance a harmonic term .", "label": "", "metadata": {}, "score": "49.63765"}
{"text": "This result has immediate practical applications .Rather than determining Lagrange multipliers for all experimental observations , it is sufficient to conduct an ensemble - averaged simulation with -function constraints with a large number of replicas .In practice , -functions are difficult to work with and are often replaced with a steep potential , for instance a harmonic term .", "label": "", "metadata": {}, "score": "49.63765"}
{"text": "Special Issue \" Maximum Entropy \" .Abstract : This paper proposes a new method for estimating seismic wavelets .Suppose a seismic wavelet can be modeled by a formula with three free parameters ( scale , frequency and phase ) .", "label": "", "metadata": {}, "score": "49.64365"}
{"text": "In the search for an acceptable alternative , it may be noted that the function for which we require a measure , namely Pr [ F ( W i given W i OR W j ) given E 2 ] , is a set of pairs .", "label": "", "metadata": {}, "score": "49.726753"}
{"text": "The three new papers highlighted in this Perspectives article have provided substantial new insights to the field of molecular simulation under experimental restraints .Of particular interest is the result that the current common practice of replica - averaged simulations is tightly linked to the solution prescribed by the maximum entropy formalism .", "label": "", "metadata": {}, "score": "49.81126"}
{"text": "The three new papers highlighted in this Perspectives article have provided substantial new insights to the field of molecular simulation under experimental restraints .Of particular interest is the result that the current common practice of replica - averaged simulations is tightly linked to the solution prescribed by the maximum entropy formalism .", "label": "", "metadata": {}, "score": "49.81126"}
{"text": "Of course , in reality there is only one real state of the system .The entropy is not a direct function of that state .It is a function of the real state only through the ( subjectively chosen ) macroscopic model description .", "label": "", "metadata": {}, "score": "49.8706"}
{"text": "The unique measure was the missing information in this inference , for a deductive conclusion .This discovery yielded a pair of principles of reasoning .Inferences of infinite number were candidates for being made by a model .All but a few of these inferences were incorrect .", "label": "", "metadata": {}, "score": "49.912876"}
{"text": "Quite possibly , it arises as a reflection of the evident time - asymmetric evolution of the universe on a cosmological scale ( see arrow of time ) .Maximum Entropy thermodynamics has generally failed to be accepted by the majority of scientists , with mainstream thermodynamicists considering Jaynes ' work as an unfounded mathematical contrivance .", "label": "", "metadata": {}, "score": "49.936493"}
{"text": "We apply the methodology to a problem consisting of the determination of a probability density from a few values of its numerically - determined Laplace transform .This problem can be mapped onto a problem consisting of the determination of a probability density on [ 0 , 1 ] from the knowledge of a few of its fractional moments up to some measurement errors stemming from insufficient data .", "label": "", "metadata": {}, "score": "50.56357"}
{"text": "The probabilities are objective in the sense that , given these inputs , a uniquely defined probability distribution will result , the same for every rational investigator , independent of the subjectivity or arbitrary opinion of particular persons .The probabilities are epistemic in the sense that they are defined in terms of specified data and derived from those data by definite and objective rules of inference , the same for every rational investigator .", "label": "", "metadata": {}, "score": "50.76213"}
{"text": "It is also sometimes suggested that quantum measurement , especially in the decoherence interpretation , may give an apparently unexpected reduction in entropy per this argument , as it appears to involve macroscopic information becoming available which was previously inaccessible .( However , the entropy accounting of quantum measurement is tricky , because to get full decoherence one may be assuming an infinite environment , with an infinite entropy ) .", "label": "", "metadata": {}, "score": "50.980934"}
{"text": "The resulting expression , however , relies on the averages , which are not know a priori .A possible strategy would be to estimate and iteratively , by repeatedly estimating from a simulation , adjusting to match the calculated and expected value for , and then rerunning the simulation ( or reweighting the statistics from the previous one [ 8 ] ) .", "label": "", "metadata": {}, "score": "50.983925"}
{"text": "The resulting expression , however , relies on the averages , which are not know a priori .A possible strategy would be to estimate and iteratively , by repeatedly estimating from a simulation , adjusting to match the calculated and expected value for , and then rerunning the simulation ( or reweighting the statistics from the previous one [ 8 ] ) .", "label": "", "metadata": {}, "score": "50.983925"}
{"text": "The second of the constraints arises in the following way .Each such inference assigns a number to the probability of W i and a different number to the probability of W j .To continue the review , F ( W i given W i OR W j ) designates the unobserved state - space of a different kind of inference .", "label": "", "metadata": {}, "score": "51.028557"}
{"text": "Where do we stand on maximum entropy ?In : Levine R , Tribus M , editors .The Maximum Entropy Formalism .Cambridge , MA : MIT Press . pp . 1 - 104 .Lindorff - Larsen K , Maragakis P , Piana S , Eastwood MP , Dror RO , et al .", "label": "", "metadata": {}, "score": "51.05004"}
{"text": "Where do we stand on maximum entropy ?In : Levine R , Tribus M , editors .The Maximum Entropy Formalism .Cambridge , MA : MIT Press . pp . 1 - 104 .Lindorff - Larsen K , Maragakis P , Piana S , Eastwood MP , Dror RO , et al .", "label": "", "metadata": {}, "score": "51.05004"}
{"text": "This can not be guaranteed , a priori .For this reason MaxEnt proponents also call the method predictive statistical mechanics .The predictions can fail .But if they do , this is informative , because it signals the presence of new constraints needed to capture reproducible behaviour in the system , which had not been taken into account .", "label": "", "metadata": {}, "score": "51.062"}
{"text": "We then use the shadow values and nominal input prices to estimate crop - specific production functions using generalized maximum entropy ( GME ) to capture individual heterogeneity of the production environment while replicating observed inputs and outputs to production .The two - stage GME approach can be implemented with small data sets .", "label": "", "metadata": {}, "score": "51.125504"}
{"text": "Maximization of the entropy assigns equal numerical values to the probabilities of the various ways .The modern theory of heat , aka thermodynamics , arises from the principle of entropy maximization .The manner in which it arises is identical to the manner in which the theory of fair gambling devices arises , with the exception of the identities of the states in the unobserved state - space .", "label": "", "metadata": {}, "score": "51.239758"}
{"text": "Cavalli et al . provide a possible path in this direction , and in this paper , we have sketched out a few potential alternatives .From a theoretical viewpoint , it seems desirable to combine Bayesian inference , which provides a robust toolbox for dealing with noisy data , with the maximum entropy principle for deriving probability distributions in underdetermined systems .", "label": "", "metadata": {}, "score": "51.342384"}
{"text": "Cavalli et al . provide a possible path in this direction , and in this paper , we have sketched out a few potential alternatives .From a theoretical viewpoint , it seems desirable to combine Bayesian inference , which provides a robust toolbox for dealing with noisy data , with the maximum entropy principle for deriving probability distributions in underdetermined systems .", "label": "", "metadata": {}, "score": "51.342384"}
{"text": "Three recent papers [ 9 ] - [ 11 ] , have explored the assumptions underlying existing methods in the light of the maximum entropy principle , leading to suggestions for new avenues to optimally utilize the complementary information available from experiments and molecular simulations .", "label": "", "metadata": {}, "score": "51.34601"}
{"text": "Three recent papers [ 9 ] - [ 11 ] , have explored the assumptions underlying existing methods in the light of the maximum entropy principle , leading to suggestions for new avenues to optimally utilize the complementary information available from experiments and molecular simulations .", "label": "", "metadata": {}, "score": "51.34601"}
{"text": "A direct connection is thus made between the equilibrium thermodynamic entropy S Th , a state function of pressure , volume , temperature , etc . , and the information entropy for the predicted distribution with maximum uncertainty conditioned only on the expectation values of those variables : .", "label": "", "metadata": {}, "score": "51.510246"}
{"text": "Finally , this paper proposes a simple linear iterative method that generalizes the biproportional method to the data balancing problem with arbitrary data structure , uncertainty estimates and multiple data quality levels .Abstract : We show that a special entropic quantifier , called the statistical complexity , becomes maximal at the transition between super - Poisson and sub - Poisson regimes .", "label": "", "metadata": {}, "score": "51.85968"}
{"text": "These results show that the dependence structure of the monthly streamflow at each site and between different sites can be preserved relatively well .Figure 2 . Conclusions .[ 25 ] The maximum entropy copula method is proposed for the multisite monthly streamflow simulation and shown to be capable of modeling the rank correlation of monthly streamflows at different sites .", "label": "", "metadata": {}, "score": "51.886456"}
{"text": "When the force constant is determined from the experimental noise , this is no longer possible , suggesting that rather than the limit , an intermediate value of might be more appropriate in order to provide a balance between matching the mean and the variance .", "label": "", "metadata": {}, "score": "51.99321"}
{"text": "When the force constant is determined from the experimental noise , this is no longer possible , suggesting that rather than the limit , an intermediate value of might be more appropriate in order to provide a balance between matching the mean and the variance .", "label": "", "metadata": {}, "score": "51.99321"}
{"text": "The existence and uniqueness of the measure of an inference signified that the identity of the correct inference could be established by optimization .Shannon described a pair of applications for the idea of optimization ; these applications were in the design of equipment for the telecommunications industry .", "label": "", "metadata": {}, "score": "52.062325"}
{"text": "Remaining challenges .The replica - averaged approach described in the previous section is a remarkably elegant , easily implementable technique that provides the least - biased distribution consistent with any observed expectation values over the data .From our perspective , it represents a significant step forward in our understanding of how experimental data should be used in molecular simulations .", "label": "", "metadata": {}, "score": "52.272972"}
{"text": "Remaining challenges .The replica - averaged approach described in the previous section is a remarkably elegant , easily implementable technique that provides the least - biased distribution consistent with any observed expectation values over the data .From our perspective , it represents a significant step forward in our understanding of how experimental data should be used in molecular simulations .", "label": "", "metadata": {}, "score": "52.272972"}
{"text": "Background paper .Atlanta , GA : CDC , 1999 .The strong version of the Precautionary Principle would suggest using this prediction for vaccination campaigns .On the contrary , the non - extensive maximum entropy principle predicts a lower attack rate , which induces a 20 % saving in public funding for vaccines doses .", "label": "", "metadata": {}, "score": "52.31064"}
{"text": "For a copula density function c ( u , v ) , the entropy can be expressed as .W .c . u .v . ) log .c . u .v . )d .u . d .", "label": "", "metadata": {}, "score": "52.330315"}
{"text": "In this article , we provide an overview of the current strategies and point out where and how the method of maximum entropy has been introduced in this area .Its applicability in various disciplines has been abundantly demonstrated .We give several examples of applications of maximum entropy in different stages of drug discovery .", "label": "", "metadata": {}, "score": "52.65593"}
{"text": "Crucially , , the solution of this constrained maximum entropy problem , is ' the \" Renyi \" entropy of distribution with index minus a linear function of the constrained ' .Definition 3 .The Renyi entropy is with a nd it is concave only for .", "label": "", "metadata": {}, "score": "52.752777"}
{"text": "When this happens , the result is the same as when a dishonest research worker fabricates empirical data .A consequence is for the model to fail in service from making false assertions .It arises in the following manner .Suppose a model makes an inference from an observed state - space containing a single state to the unobserved state - space that participates with the observed state - space in making an inference .", "label": "", "metadata": {}, "score": "52.910336"}
{"text": "This model is formulated by a Gibbs distribution , under the MaxEnt framework , that can be sampled to generate plausible scenes .Once an And - Or graph is sampled from the ensemble , the hierarchical constraints are employed to sample the Or - nodes ( style variations ) and the contextual constraints are subsequently used to enforce the corresponding relations that must be satisfied by the And - nodes .", "label": "", "metadata": {}, "score": "52.95475"}
{"text": "Three very recent papers have explored this problem using the maximum entropy approach , providing both new theoretical and practical insights to the problem .We highlight each of these contributions in turn and conclude with a discussion on remaining challenges .", "label": "", "metadata": {}, "score": "52.99862"}
{"text": "Three very recent papers have explored this problem using the maximum entropy approach , providing both new theoretical and practical insights to the problem .We highlight each of these contributions in turn and conclude with a discussion on remaining challenges .", "label": "", "metadata": {}, "score": "52.99862"}
{"text": "Prior information is now considered to be given by calibrated Heston , Sch\u00f6bel - Zhu or Variance Gamma models .We find that the resulting digital option prices are essentially the same as those given by the ( non - relative ) Buchen - Kelly density itself .", "label": "", "metadata": {}, "score": "53.025814"}
{"text": "First , because it allows to include convex constraints in a natural way , and second , because it allows to incorporate and to estimate ( additive ) measurement errors from the data .Here we shall see both methods in action in a specific example .", "label": "", "metadata": {}, "score": "53.074715"}
{"text": "The second term acts to enforce that the simulation is in agreement with the experiments , but penalizing the entire ensemble only when the ensemble averaged quantities , deviate from experiment .For linearly averaged quantities , .In this way , the calculated quantities in individual conformation ( ) may differ from experiment as long as their ensemble average , , matches the experiment within a scale that is implicitly determined by the force constant , .", "label": "", "metadata": {}, "score": "53.152405"}
{"text": "The second term acts to enforce that the simulation is in agreement with the experiments , but penalizing the entire ensemble only when the ensemble averaged quantities , deviate from experiment .For linearly averaged quantities , .In this way , the calculated quantities in individual conformation ( ) may differ from experiment as long as their ensemble average , , matches the experiment within a scale that is implicitly determined by the force constant , .", "label": "", "metadata": {}, "score": "53.152405"}
{"text": "Abstract : We propose a continuous maximum entropy method to investigate the robustoptimal portfolio selection problem for the market with transaction costs and dividends .This robust model aims to maximize the worst - case portfolio return in the case that allof asset returns lie within some prescribed intervals .", "label": "", "metadata": {}, "score": "53.27661"}
{"text": "One writer even goes so far as to label Jaynes ' approach as \" ultrasubjectivist \" , [ 9 ] and to mention \" the panic that the term subjectivism created amongst physicists \" .[ 10 ] .The probabilities represent both the degree of knowledge and lack of information in the data and the model used in the analyst 's macroscopic description of the system , and also what those data say about the nature of the underlying reality .", "label": "", "metadata": {}, "score": "53.31823"}
{"text": "Abstract : We discuss a special class of generalized divergence measures by the use of generator functions .Any divergence measure in the class is separated into the difference between cross and diagonal entropy .The diagonal entropy measure in the class associates with a model of maximum entropy distributions ; the divergence measure leads to statistical estimation via minimization , for arbitrarily giving a statistical model .", "label": "", "metadata": {}, "score": "53.707825"}
{"text": "We will highlight the most important ones here .Ensuring convergence .There are some challenges involved in determining optimal values for the number of replicas and the force constant .Ideally , should be chosen as large as possible , but as illustrated by Figure 2 , this will impose a requirement for a larger number of replicas as well .", "label": "", "metadata": {}, "score": "53.831226"}
{"text": "We will highlight the most important ones here .Ensuring convergence .There are some challenges involved in determining optimal values for the number of replicas and the force constant .Ideally , should be chosen as large as possible , but as illustrated by Figure 2 , this will impose a requirement for a larger number of replicas as well .", "label": "", "metadata": {}, "score": "53.831226"}
{"text": "For compactness , boldface is used to denote a sets of replicas or restraints ( e.g. , ) .Assuming independence between the restraints , we have : ( 4 ) Assuming flat priors , we have , and assuming independent Gaussian distributions on the latter , ( 5 ) where again is the calculated ensemble averaged quantity of data .", "label": "", "metadata": {}, "score": "53.855347"}
{"text": "For compactness , boldface is used to denote a sets of replicas or restraints ( e.g. , ) .Assuming independence between the restraints , we have : ( 4 ) Assuming flat priors , we have , and assuming independent Gaussian distributions on the latter , ( 5 ) where again is the calculated ensemble averaged quantity of data .", "label": "", "metadata": {}, "score": "53.855347"}
{"text": "Rather than maximizing W directly , the protagonist could equivalently maximize any monotonic increasing function of W .She decides to maximize .At this point , in order to simplify the expression , the protagonist takes the limit as , i.e. as the probability levels go from grainy discrete values to smooth continuous values .", "label": "", "metadata": {}, "score": "54.019863"}
{"text": "How does one find the most uniform model subject to a set of constraints ?The maximum entropy method answers both questions , modelling available information and assuming nothing about what is unknown .Therefore , given a collection of influenza events , such as historical estimates of pandemic influenza attack rates 15 - 19 and the seasonal attack rate , choose a model that is consistent with all these previous observable events , but otherwise be as uniform as possible .", "label": "", "metadata": {}, "score": "54.05092"}
{"text": "[ 11 ] The joint distribution in the higher dimension is of particular interest when the multivariate dependence structure has to be modeled .In this case , a multivariate entropy in equation ( 2 ) can be defined and then copula density function with the maximum entropy can be derived straightforward .", "label": "", "metadata": {}, "score": "54.15921"}
{"text": "In the deductive logic , every proposition was true in either 0 % or 100 % of the instances in which this proposition was asserted .In reality , though , a proposition might be true in a proportion of instances in which it was asserted lying between 0 % and 100 % .", "label": "", "metadata": {}, "score": "54.1661"}
{"text": "One critique of the method relates to the ratio of the number of free parameters ( atomic coordinates ) to the number of experimental data points .In \" normal \" ( non - ensemble ) structure determination , there are typically fewer experimental data than atomic positions to be determined ; the problem is underdetermined and additional ( prior ) information , e.g. , from a force field , is needed to determine structures .", "label": "", "metadata": {}, "score": "54.333008"}
{"text": "One critique of the method relates to the ratio of the number of free parameters ( atomic coordinates ) to the number of experimental data points .In \" normal \" ( non - ensemble ) structure determination , there are typically fewer experimental data than atomic positions to be determined ; the problem is underdetermined and additional ( prior ) information , e.g. , from a force field , is needed to determine structures .", "label": "", "metadata": {}, "score": "54.333008"}
{"text": "Now , let it be stipulated that the bases for inferences of the two kinds are entirely empirical .In fact , under the stated circumstances , Pr [ F ( W i given W i OR W j ) given E 2 ] is a constant .", "label": "", "metadata": {}, "score": "54.341454"}
{"text": "Thus , it must be the tradition that is empirically invalidated .Acting on the conclusion that the tradition is empirically invalidated , Christensen defines E 1 and E 2 outside the tradition .In particular : .The evidence E 1 pushes the entropy downward .", "label": "", "metadata": {}, "score": "54.376457"}
{"text": "Minimization of the conditional entropy is the optimization that determines the descriptions .Minimization of the conditional entropy uniquely determines the correct inference .Thus , minimization of the conditional entropy is a principle of reasoning .The unobserved state - space is the alphabet of the un - encoded message .", "label": "", "metadata": {}, "score": "54.387245"}
{"text": "This expression now only includes , the experimentally determined quantity that is an estimate of the true , underlying value .The equation above , derived by Cavalli et al . is quite striking , in the sense that it corresponds exactly to the form used in classic ensemble simulations ( Eq . 1 ) , except that the force constant that can normally be tuned freely is now determined uniquely by the uncertainty in the observed experimental values .", "label": "", "metadata": {}, "score": "54.481583"}
{"text": "This expression now only includes , the experimentally determined quantity that is an estimate of the true , underlying value .The equation above , derived by Cavalli et al . is quite striking , in the sense that it corresponds exactly to the form used in classic ensemble simulations ( Eq . 1 ) , except that the force constant that can normally be tuned freely is now determined uniquely by the uncertainty in the observed experimental values .", "label": "", "metadata": {}, "score": "54.481583"}
{"text": "We assume this information has the form of m constraints on the expectations of the functions f k ; that is , we require our probability distribution to satisfy .where m ( x ) , which Jaynes called the \" invariant measure \" , is proportional to the limiting density of discrete points .", "label": "", "metadata": {}, "score": "54.522892"}
{"text": "We envisage that new theoretical developments , such as the link between ensemble simulations and maximum entropy solutions , can be directly applicable in other fields .Similarly , new methods for deriving modified models in the context of noisy data should have broad applicability .", "label": "", "metadata": {}, "score": "54.670403"}
{"text": "We envisage that new theoretical developments , such as the link between ensemble simulations and maximum entropy solutions , can be directly applicable in other fields .Similarly , new methods for deriving modified models in the context of noisy data should have broad applicability .", "label": "", "metadata": {}, "score": "54.670403"}
{"text": "It demands as given some partly specified model and some specified data related to the model .It selects a preferred probability distribution to represent the model .The given data state \" testable information \" [ 3 ] [ 4 ] about the probability distribution , for example particular expectation values , but are not in themselves sufficient to uniquely determine it .", "label": "", "metadata": {}, "score": "54.743332"}
{"text": "At an abstract level , this result simply means that some of the information we originally had about the system has become \" no longer useful \" at a macroscopic level .At the level of the 6 N -dimensional probability distribution , this result represents coarse graining -i.e . , information loss by smoothing out very fine - scale detail .", "label": "", "metadata": {}, "score": "55.175285"}
{"text": "It is the absence of the evidence E 2 that causes the model to fail , under the tradition .A procedure has been described for determination of the function Pr [ F ( W i given W i OR W j ) given E 2 ] .", "label": "", "metadata": {}, "score": "55.222336"}
{"text": "For sufficiently large values of the harmonic term mimics a -function and when is increased for such values of the distribution converges towards the maximum entropy solution without explicitly determining any Lagrange multipliers .In this example , we only have experimental data regarding the y - dimension of the distribution ( target value indicated by dotted line ) .", "label": "", "metadata": {}, "score": "55.258587"}
{"text": "For sufficiently large values of the harmonic term mimics a -function and when is increased for such values of the distribution converges towards the maximum entropy solution without explicitly determining any Lagrange multipliers .In this example , we only have experimental data regarding the y - dimension of the distribution ( target value indicated by dotted line ) .", "label": "", "metadata": {}, "score": "55.258587"}
{"text": "However the Second Law argument above also runs in reverse : given macroscopic information at time t 2 , we should expect it too to become less useful .The two procedures are time - symmetric .But now the information will become less and less useful at earlier and earlier times .", "label": "", "metadata": {}, "score": "55.408783"}
{"text": "If it is inconsistent , she will reject it and try again .If it is consistent , her assessment will be . where p i is the probability of the i th proposition , while n i is the number of quanta that were assigned to the i th proposition ( i.e. the number of balls that ended up in bucket i ) .", "label": "", "metadata": {}, "score": "55.430946"}
{"text": "However , this reform could not have been more damaging to the advancement of science for , under frequentism , patterns could not be discovered and knowledge could not be created .Frequentism is the idea that the constant numerical value of the limiting relative frequency of a state is assigned to the probability of this state .", "label": "", "metadata": {}, "score": "55.451714"}
{"text": "However , the ability of the commonly used parametric copulas to model dependences in higher dimensions is rather restricted [ Kao and Govindaraju , 2008 ; Chui and Wu , 2009 ] .In this study , we propose the maximum entropy copula for multisite monthly streamflow simulation in which the rank correlation in higher dimensions among monthly streamflows at different sites can be modeled .", "label": "", "metadata": {}, "score": "55.580414"}
{"text": "In the amalgamated model , the mechanistic model plays two roles .First , certain of its independent variables may provide independent variables for the empirical model .Second , the inferences that are made to the outcomes of events by the mechanistic model may serve as a constraint on entropy maximization .", "label": "", "metadata": {}, "score": "55.586792"}
{"text": "The concept of Maximum Entropy can be traced back along multiple threads to Biblical times .However , not until the late of 21st century has computer become powerful enough to handle complex problems with statistical modeling technique like Maxent .Maximum Entropy was first introduced to NLP area by Berger , et al ( 1996 ) and Della Pietra , et al .", "label": "", "metadata": {}, "score": "55.62699"}
{"text": "A model is a procedure for making inferences .Each time an inference is made , there are possibilities a , b for being made .The model builder must decide !Logic is the science of the principles that discriminate the one correct inference from the many incorrect ones .", "label": "", "metadata": {}, "score": "55.665543"}
{"text": "doi : 10.1529/biophysj.107.108241 .Cavalli A , Camilloni C , Vendruscolo M ( 2013 ) Molecular dynamics simulations with replica averaged structural restraints generate structural ensembles according to the maximum entropy principle .J Chem Phys 138 : 094112 . doi : 10.1063/1.4793625 .", "label": "", "metadata": {}, "score": "55.894375"}
{"text": "doi : 10.1529/biophysj.107.108241 .Cavalli A , Camilloni C , Vendruscolo M ( 2013 ) Molecular dynamics simulations with replica averaged structural restraints generate structural ensembles according to the maximum entropy principle .J Chem Phys 138 : 094112 . doi : 10.1063/1.4793625 .", "label": "", "metadata": {}, "score": "55.894375"}
{"text": "We shall see that OME is actually a particular instance of MEM , when the reference measure is a Poisson Measure .Abstract : A generalized maximum entropy estimator is developed for the linear simultaneous equations model .Monte Carlo sampling experiments are used to evaluate the estimator 's performance in small and medium sized samples , suggesting contexts in which the current generalized maximum entropy estimator is superior in mean square error to two and three stage least squares .", "label": "", "metadata": {}, "score": "55.924866"}
{"text": "It has also implicitly assumed that the uncertainty predicted at time t 1 for the variables at time t 2 will be much smaller than the measurement error .But if the measurements do meaningfully update our knowledge of the system , our uncertainty as to its state is reduced , giving a new S I ( 2 ) which is less than S I ( 1 ) .", "label": "", "metadata": {}, "score": "55.976517"}
{"text": "Bayesian inference is commonly put forward as an answer to this question .It provides a simple recipe for how to produce a new model ( posterior ) by modifying an existing model ( prior ) after observing a new set of data .", "label": "", "metadata": {}, "score": "55.976746"}
{"text": "Bayesian inference is commonly put forward as an answer to this question .It provides a simple recipe for how to produce a new model ( posterior ) by modifying an existing model ( prior ) after observing a new set of data .", "label": "", "metadata": {}, "score": "55.976746"}
{"text": "As an example , Box 1 contains a primer of the basic maximum entropy procedure on the simple problem of inferring the probability of the different outcomes of a ( possibly biased ) die , given only information about the average observed after a large number of throws .", "label": "", "metadata": {}, "score": "55.987583"}
{"text": "As an example , Box 1 contains a primer of the basic maximum entropy procedure on the simple problem of inferring the probability of the different outcomes of a ( possibly biased ) die , given only information about the average observed after a large number of throws .", "label": "", "metadata": {}, "score": "55.987583"}
{"text": "In the construction of a model , though , the builder often encounters situations in which these sets are not crisply defined .In these situations , a similar logic applies but with set theory replaced by fuzzy set theory and the various measures by their fuzzy equivalents .", "label": "", "metadata": {}, "score": "56.05114"}
{"text": "In general , the solution to this type of optimization problem takes the form : ( 9 ) where runs over the number of constraints , and Z is the partition function , which ensures proper normalization .Notice how the value produces the uniform distribution as we expect , while higher or lower values produce gradually more skewed distributions .", "label": "", "metadata": {}, "score": "56.26377"}
{"text": "In general , the solution to this type of optimization problem takes the form : ( 9 ) where runs over the number of constraints , and Z is the partition function , which ensures proper normalization .Notice how the value produces the uniform distribution as we expect , while higher or lower values produce gradually more skewed distributions .", "label": "", "metadata": {}, "score": "56.26377"}
{"text": "The top - left plot is the unperturbed potential , while the top - right plot shows the maximum entropy solution with a numerically optimized Lagrange multiplier .The plots in the matrix show the behavior of different combinations of the force constant of the harmonic potential and the number of replicas used in the simulation .", "label": "", "metadata": {}, "score": "56.297424"}
{"text": "The top - left plot is the unperturbed potential , while the top - right plot shows the maximum entropy solution with a numerically optimized Lagrange multiplier .The plots in the matrix show the behavior of different combinations of the force constant of the harmonic potential and the number of replicas used in the simulation .", "label": "", "metadata": {}, "score": "56.297424"}
{"text": "When MD or MC methods are used to sample protein conformations they typically give rise to an ensemble of conformations that are distributed according the celebrated Boltzmann distribution , , that relates the probability of observing a given conformation to the energy of that conformation .", "label": "", "metadata": {}, "score": "56.39292"}
{"text": "When MD or MC methods are used to sample protein conformations they typically give rise to an ensemble of conformations that are distributed according the celebrated Boltzmann distribution , , that relates the probability of observing a given conformation to the energy of that conformation .", "label": "", "metadata": {}, "score": "56.39292"}
{"text": "We use the least squares cross validation to derive the optimal weights .MonteCarlo simulations demonstrate that the proposedW - GME estimator is comparable to and often outperforms the conventional GME estimator , which places equal weights on the entropies of coefficient and disturbance distributions .", "label": "", "metadata": {}, "score": "56.577187"}
{"text": "The paper shows that conventional data balancing methods , such as generalized least squares , weighted least squares and biproportional methods are particular cases of the general method described here .As a consequence , it is possible to determine the underlying assumptions and range of application of each traditional method .", "label": "", "metadata": {}, "score": "56.766953"}
{"text": "Four iterative parameter estimation algorithms are compared on several NLP tasks .L - BFGS is observed to be the most effective parameter estimation method for Maximum Entropy model , much better than IIS and GIS .( Wallach 02 ) reported similar results on parameter estimation of Conditional Random Fields .", "label": "", "metadata": {}, "score": "56.87166"}
{"text": "The effect can also be understood in the detailed analysis by Roux and Weare of a 1D harmonic potential with a harmonic restraint .In particular , their calculations show that when the number of replicas is increased for a fixed force constant , the mean of the restrained ensemble converges to that of the prior reference distribution while the variance increases to its correct value .", "label": "", "metadata": {}, "score": "57.255383"}
{"text": "The effect can also be understood in the detailed analysis by Roux and Weare of a 1D harmonic potential with a harmonic restraint .In particular , their calculations show that when the number of replicas is increased for a fixed force constant , the mean of the restrained ensemble converges to that of the prior reference distribution while the variance increases to its correct value .", "label": "", "metadata": {}, "score": "57.255383"}
{"text": "Under a precept of measure theory , the measure of an empty set is nil .The union of several sets is the set of all elements that belong to at least one set .Probability is an example of a measure .", "label": "", "metadata": {}, "score": "57.35643"}
{"text": "Suitable marginal distributions , such as kernel density , can be selected to model the properties of streamflow of each month , such as skewness and bimodal properties , which have been well documented [ Sharma et al . , 1997 ; Prairie et al . , 2007 ; Salas and Lee , 2010 ; Hao and Singh , 2012 ] .", "label": "", "metadata": {}, "score": "57.39489"}
{"text": "Equivalently , it means that the probability distribution for the whole system , in 6N - dimensional phase space , becomes increasingly irregular , spreading out into long thin fingers rather than the initial tightly defined volume of possibilities .Classical thermodynamics is built on the assumption that entropy is a state function of the macroscopic variables -i.e . , that none of the history of the system matters , so that it can all be ignored .", "label": "", "metadata": {}, "score": "57.57945"}
{"text": "o an inference to an unobserved state - space assigns a numerical value to the probability of each of the states in this state - space and , .o the observed state - space that participates with the unobserved state - space in making the inference contains a single state and , .", "label": "", "metadata": {}, "score": "57.640915"}
{"text": "\" There are significant challenges associated with estimating and sampling from such models , but recent work provides hope for the eventual feasibility of such an approach .First , advances in techniques for force field optimization [ 8 ] , [ 52 ] allow for a Bayesian approach to integrate experimental data and , e.g. , quantum - level data , bringing us closer to the ability to probe the uncertainties associated with individual parameters .", "label": "", "metadata": {}, "score": "57.651142"}
{"text": "\" There are significant challenges associated with estimating and sampling from such models , but recent work provides hope for the eventual feasibility of such an approach .First , advances in techniques for force field optimization [ 8 ] , [ 52 ] allow for a Bayesian approach to integrate experimental data and , e.g. , quantum - level data , bringing us closer to the ability to probe the uncertainties associated with individual parameters .", "label": "", "metadata": {}, "score": "57.651142"}
{"text": "Thus the straight rule was invalided as a general guide to model building .Under the probabilistic logic , the shrinkage has a cause .This cause is overestimation of the information one gets about the probability of a state in T , from knowing the state in U .", "label": "", "metadata": {}, "score": "57.925667"}
{"text": "[ .r . m .r .u .r .r . m .v .r . ) m .u .v . ) . ]d .u . d .v ( 6 ) .[ 10 ] The dependence structure in terms of the Spearman rank correlation can be modeled through the joint probability density function in equation ( 5 ) .", "label": "", "metadata": {}, "score": "58.244396"}
{"text": "It remains to be seen whether this poses a significant problem for the application of this method in practice .Estimating Lagrange multipliers .Despite the convenience of the replica - averaged method , it remains unclear whether this method is always preferable to an approach that estimates the Lagrange multipliers explicitly .", "label": "", "metadata": {}, "score": "58.40325"}
{"text": "It remains to be seen whether this poses a significant problem for the application of this method in practice .Estimating Lagrange multipliers .Despite the convenience of the replica - averaged method , it remains unclear whether this method is always preferable to an approach that estimates the Lagrange multipliers explicitly .", "label": "", "metadata": {}, "score": "58.40325"}
{"text": "The designer of the decoder must decide !Each state in the unobserved state - space of the inference is an example of a way .The observed state - space that participates with the unobserved state - space in making the inference contains a single state ; this state is abstracted from the ways in the unobserved state - space .", "label": "", "metadata": {}, "score": "58.494522"}
{"text": "Finally , we study variance swaps and derive a simple formula relating the fair variance swap rate to entropy .Then we show , again , that the prior loses its influence on the fair variance swap rate as the number of strikes increases .", "label": "", "metadata": {}, "score": "58.58725"}
{"text": "While this sounds like a trivial principle , it is actually violated by many existing methods .Conceptually , the maximum entropy procedure is simple , and we proceed exactly as we did for the die example .Technical issues , however , seem to have hindered a practically useful implementation of the method .", "label": "", "metadata": {}, "score": "58.833954"}
{"text": "While this sounds like a trivial principle , it is actually violated by many existing methods .Conceptually , the maximum entropy procedure is simple , and we proceed exactly as we did for the die example .Technical issues , however , seem to have hindered a practically useful implementation of the method .", "label": "", "metadata": {}, "score": "58.833954"}
{"text": "Under the precept of additivity , .Thus , the set being measured by Sh ( . )Though Shannon did not realize it , the existence of the unique measure of an inference signified that the problem of induction could be solved by optimization .", "label": "", "metadata": {}, "score": "59.25285"}
{"text": "Roux and Weare point out that even when successfully finding all Lagrange multipliers , one still has to run an entire simulation .Similar problems seem to assert themselves for the replica - case , where production runs can only be conducted once convergence in entropy has been ensured .", "label": "", "metadata": {}, "score": "59.580727"}
{"text": "Roux and Weare point out that even when successfully finding all Lagrange multipliers , one still has to run an entire simulation .Similar problems seem to assert themselves for the replica - case , where production runs can only be conducted once convergence in entropy has been ensured .", "label": "", "metadata": {}, "score": "59.580727"}
{"text": "Solving this problem made the principles of reasoning known and available for construction of a model .The ideas that were to foster a solution were those of measure , inferences , optimization and missing information .In the optimization of an inference , that possibility would be identified as correct whose measure was minimal or maximal .", "label": "", "metadata": {}, "score": "59.69407"}
{"text": "This law can not be derived .Over the years in which the problem of induction remained unsolved , the major barrier to solution was to satisfy the law of non - contradiction .In every instance in which a heuristic identifies the one correct inference , at least one different heuristic identifies a different inference as the one correct inference .", "label": "", "metadata": {}, "score": "59.69536"}
{"text": "As such , the system - specific force field correction introduced by the restraints , when applied appropriately , may be viewed as a natural extension of the Boltzmann ensemble when one is provided with additional information beyond the energy .In addition to the theoretical developments highlighted in this article , an important area for future studies is how best to implement them in practice .", "label": "", "metadata": {}, "score": "59.7251"}
{"text": "As such , the system - specific force field correction introduced by the restraints , when applied appropriately , may be viewed as a natural extension of the Boltzmann ensemble when one is provided with additional information beyond the energy .In addition to the theoretical developments highlighted in this article , an important area for future studies is how best to implement them in practice .", "label": "", "metadata": {}, "score": "59.7251"}
{"text": "The matrix shows various combinations of force constant ( ) and number of replicas ( ) when enforcing the restraint through a harmonic potential .In these calculations , corresponds to the standard method for structure calculation , and corresponds to ensemble refinement .", "label": "", "metadata": {}, "score": "59.817795"}
{"text": "The matrix shows various combinations of force constant ( ) and number of replicas ( ) when enforcing the restraint through a harmonic potential .In these calculations , corresponds to the standard method for structure calculation , and corresponds to ensemble refinement .", "label": "", "metadata": {}, "score": "59.817795"}
{"text": "According to one , frequently employed heuristic , the correct inference was the one of greatest beauty .The first principle of reasoning was the law of non - contradiction .In employing heuristics , scientists violated this law .A result was for models to be highly susceptible to making logical errors .", "label": "", "metadata": {}, "score": "59.885715"}
{"text": "We have some testable information I about a quantity x which takes values in some interval of the real numbers ( all integrals below are over this interval ) .We assume this information has the form of m constraints on the expectations of the functions f k , i.e. we require our probability density function to satisfy .", "label": "", "metadata": {}, "score": "59.93126"}
{"text": "In establishing the identity of this sum , it is convenient to employ the substitution in which .With this substitution , the measure g ( . ) of the union of the pairs in the collection of measurable sets is .", "label": "", "metadata": {}, "score": "60.34075"}
{"text": "The most common technique is to combine a physical force field , with an experimentally derived \" biasing potential , \" : .The function acts to bias simulations to provide structures that are compatible with experiments and typically takes the form of a harmonic potential that penalizes protein structures that are not in agreement with experiments : .", "label": "", "metadata": {}, "score": "60.340992"}
{"text": "The most common technique is to combine a physical force field , with an experimentally derived \" biasing potential , \" : .The function acts to bias simulations to provide structures that are compatible with experiments and typically takes the form of a harmonic potential that penalizes protein structures that are not in agreement with experiments : .", "label": "", "metadata": {}, "score": "60.340992"}
{"text": "Alternatively , the maximum entropy rule suggests using the experts ' prediction of the pandemic ( Q ) and the seasonal influenza attack rate ( P ) for obtaining an alternative attack rate scenario indeed the distribution .The influenza attack rate variable is broadly summarized in five levels as follows : .", "label": "", "metadata": {}, "score": "60.67607"}
{"text": "We stipulate that the collection of sets that are measurable by g ( . ) contains the set of these pairs and that the elements of this set are non - overlapping .By a property of the Dirac delta function , it must be true that the measure g ( . )", "label": "", "metadata": {}, "score": "60.701538"}
{"text": "Although this superficially sounds reasonable - indeed the idea of the biasing potential is to bring the conformations to be in agreement with experiments - it brings with it some additional consequences .The basic problem arises because the experimental data , , are typically averaged over a very large number of molecules as well as averaged over timescales that are long compared to those typical of macromolecular fluctuations .", "label": "", "metadata": {}, "score": "60.750504"}
{"text": "Although this superficially sounds reasonable - indeed the idea of the biasing potential is to bring the conformations to be in agreement with experiments - it brings with it some additional consequences .The basic problem arises because the experimental data , , are typically averaged over a very large number of molecules as well as averaged over timescales that are long compared to those typical of macromolecular fluctuations .", "label": "", "metadata": {}, "score": "60.750504"}
{"text": "The MaxEnt inference would predict that the most probable origin of a currently low - entropy state would be as a spontaneous fluctuation from an earlier high entropy state .But this conflicts with what we know to have happened , namely that entropy has been increasing steadily , even back in the past .", "label": "", "metadata": {}, "score": "60.86812"}
{"text": "An interesting feature of the method is its potential to incorporate errors in the data .Here , we examine two possible ways of doing that .The two approaches have different intuitive interpretations , and one of them allows for error estimation .", "label": "", "metadata": {}, "score": "60.937717"}
{"text": "In order to be as fair as possible , each throw is to be independent of any other , and every bucket is to be the same size . )Once the experiment is done , she will check if the probability assignment thus obtained is consistent with her information .", "label": "", "metadata": {}, "score": "60.9832"}
{"text": "14 ] It follows that the maximum entropy approach will not be applicable to non - equilibrium systems until there is found a clear physical definition of entropy .This is related to the fact that heat may be transferred from a hotter to a colder physical system even when local thermodynamic equilibrium does not prevail , so that neither system has a temperature .", "label": "", "metadata": {}, "score": "60.986305"}
{"text": "H . a .b . a .b .f .x .y . ) ln .f .x .y . )d .x .d .y ( 1 ) .Maximum Entropy Copula .[ 7 ] The maximum entropy copula has been developed based on the entropy theory [ Chui and Wu , 2009 ; Chu , 2011 ] .", "label": "", "metadata": {}, "score": "60.99482"}
{"text": "She has some testable information , but is not sure how to go about including this information in her probability assessment .She therefore conceives of the following random experiment .She will distribute N quanta of probability ( each worth 1/ N ) at random among the m possibilities .", "label": "", "metadata": {}, "score": "61.025085"}
{"text": "Perfect ignorance results from failure to discover patterns .No observational data conflict with the thesis that the principles of reasoning are entropy minimax .The quantity of observational data that bear on this issue is great .They are : .", "label": "", "metadata": {}, "score": "61.048424"}
{"text": "It uses an objective function that is the sum of the entropies for coefficient distributions and disturbance distributions .This method can be generalized to the weighted GME ( W - GME ) , where different weights are assigned to the two entropies in the objective function .", "label": "", "metadata": {}, "score": "61.120087"}
{"text": "The propositions that are referenced by the probabilistic logic are examples of states .That a proposition is a state signifies that this proposition can be validated or invalidated by observation .A proposition that is a state is validated each time the associated body is observed and found to be in the state that is claimed for it ; otherwise , it is invalidated .", "label": "", "metadata": {}, "score": "61.218006"}
{"text": "By this way , we can represent HOS as a polynomial function of second - order statistics to improve the anti - noise performance and accuracy .In addition , the proposed method can work well for short time series .Abstract : The existence of noise has great influence on the real features of observed time series , thus noise reduction in time series data is a necessary and significant task in many practical applications .", "label": "", "metadata": {}, "score": "62.08031"}
{"text": "Analysis results of both several different synthetic series and typical observed time series data have verified the performance of the new method .A comprehensive discussion of the results indicates that compared with traditional wavelet de - noising methods , the new proposed method is more effective and universal .", "label": "", "metadata": {}, "score": "62.126133"}
{"text": "Parameter Estimation . , 2 m+ 1 ) in equation ( 5 ) have to be estimated .It has been shown that these Lagrange multipliers can be solved by finding the minimum of a convex function \u0393 expressed as [ Kapur , 1989 ] .", "label": "", "metadata": {}, "score": "62.248665"}
{"text": "It assumes in particular that the initial macroscopic description contains all of the information relevant to predicting the later macroscopic state .This may not be the case , for example if the initial description fails to reflect some aspect of the preparation of the system which later becomes relevant .", "label": "", "metadata": {}, "score": "62.343925"}
{"text": "The count of the elements that are observed to be in state T l AND U m is another example of a frequency ; let this frequency be designated by x .Let V designate a statistical sample .To answer this question , one needs a solution to the inverse problem .", "label": "", "metadata": {}, "score": "62.65046"}
{"text": "Monte Carlo experiments are also used to provide evidence on the power and size of test statistics .An empirical application is included to demonstrate the practical implementation of the estimator .Abstract : We use the principle of maximum entropy to propose a parsimonious model for the generation of simulated rainfall during the wettest three - month season at a typical location on the east coast of Australia .", "label": "", "metadata": {}, "score": "62.684376"}
{"text": "Replica - averaged simulations have a substantial track record and have in many cases been shown to improve the quality of structural ensembles - e.g . , measured through cross - validation with unrelated experimental data - and to provide new biological insights .", "label": "", "metadata": {}, "score": "62.685623"}
{"text": "Replica - averaged simulations have a substantial track record and have in many cases been shown to improve the quality of structural ensembles - e.g . , measured through cross - validation with unrelated experimental data - and to provide new biological insights .", "label": "", "metadata": {}, "score": "62.685623"}
{"text": "Methodology .Entropy Concepts .[5 ] Let the joint probability density function ( PDF ) of two random variable X and Y on the interval [ a 1 , b 1 ] .\u00d7 [ a 2 , b 2 ] be f ( x , y ) .", "label": "", "metadata": {}, "score": "62.811592"}
{"text": "These distributions satisfy properties in Definition 2 and are used in finding the distribution as the solution of the following Problem 1 .Definition 2 .Let P and Q be two probability distributions , such that is absolutely continuous with respect to .", "label": "", "metadata": {}, "score": "62.930992"}
{"text": "In building models , KnowledgeToTheMax operates under a technology sharing agreement with the developer of entropy minimax pattern discovery , Ronald Christensen .In some cases , the scientific community possesses a degree of mechanistic understanding of the phenomenon being modeled .", "label": "", "metadata": {}, "score": "63.048786"}
{"text": "Later , Rosenfeld and his group proposed a Whole Sentence Exponential Model that overcome the computation bottleneck of conditional ME model .You can find more on my SLM page .This dissertation discusses the application of maxent model to various Natural Language Dis - ambiguity tasks in detail .", "label": "", "metadata": {}, "score": "63.066246"}
{"text": "One of the main practical issues is that one needs to numerically determine the optimal values for the Lagrange multiplier corresponding to each constraint .Since experimental data will easily provide hundreds of these constraints , this optimization is a formidable task .", "label": "", "metadata": {}, "score": "63.24357"}
{"text": "One of the main practical issues is that one needs to numerically determine the optimal values for the Lagrange multiplier corresponding to each constraint .Since experimental data will easily provide hundreds of these constraints , this optimization is a formidable task .", "label": "", "metadata": {}, "score": "63.24357"}
{"text": "Given the limited accuracy of force fields , macromolecular simulations sometimes produce results that are at not in complete and quantitative accordance with experiments .A common solution to this problem is to explicitly ensure agreement between the two by perturbing the potential energy function towards the experimental data .", "label": "", "metadata": {}, "score": "63.276016"}
{"text": "Given the limited accuracy of force fields , macromolecular simulations sometimes produce results that are at not in complete and quantitative accordance with experiments .A common solution to this problem is to explicitly ensure agreement between the two by perturbing the potential energy function towards the experimental data .", "label": "", "metadata": {}, "score": "63.276016"}
{"text": "Let C designate the observed state - space that participates with O in making an inference .If the construction of a model is to create knowledge , this model must be built upon one or more independent variables .Each such variable is a measured variable or is computed from one or more measured variables .", "label": "", "metadata": {}, "score": "63.315464"}
{"text": "doi : 10.1007/s10858 - 007 - 9150 - 1 .Olsson S , Boomsma W , Frellsen J , Bottaro S , Harder T , et al .( 2011 ) Generative probabilistic models extend the scope of inferential structure determination .", "label": "", "metadata": {}, "score": "63.359028"}
{"text": "doi : 10.1007/s10858 - 007 - 9150 - 1 .Olsson S , Boomsma W , Frellsen J , Bottaro S , Harder T , et al .( 2011 ) Generative probabilistic models extend the scope of inferential structure determination .", "label": "", "metadata": {}, "score": "63.359028"}
{"text": "Prior to the year 1948 , model builders lacked an alternative to the method of heuristics .In that year , the idea of optimizing inferences was published by Claude Shannon .Under optimization , the correct inference was the one whose unique measure was minimal or maximal .", "label": "", "metadata": {}, "score": "63.404594"}
{"text": "The single state in X was abstracted from the states in Y .Shannon worked in the field of communications engineering .Communications firms , such as telephone companies , understood that their role was to move information .That they did not know precluded optimization of their operations .", "label": "", "metadata": {}, "score": "63.540306"}
{"text": "Although efficient algorithms exist for improving molecular force fields based on experimental data [ 8 ] , a common approach is to introduce a system - specific modification to the energy function , and thereby modify the structural ensemble to become in agreement with the experimental data .", "label": "", "metadata": {}, "score": "64.06227"}
{"text": "Although efficient algorithms exist for improving molecular force fields based on experimental data [ 8 ] , a common approach is to introduce a system - specific modification to the energy function , and thereby modify the structural ensemble to become in agreement with the experimental data .", "label": "", "metadata": {}, "score": "64.06227"}
{"text": "By this strategy , Christensen solved the inverse problem .In keeping track of the ideas , it helps to reference them by symbols .Toward this end , let T designate an unobserved state - space and let U designate the observed state - space that participates with T in making an inference .", "label": "", "metadata": {}, "score": "64.103424"}
{"text": "Since our goal is to address policy questions , we emphasize the model 's ability to reproduce characteristics of the existing production system and predict outcomes of policy changes at a disaggregate level .Measurement of distributional impacts of policy changes requires use of farm - level models estimated across a wide spectrum of sizes and types , which is often difficult with traditional econometric methods due to data limitations .", "label": "", "metadata": {}, "score": "64.49907"}
{"text": "The relevancy , hierarchical and contextual constraints are extracted from a set of training scenes and utilized to generate plausible synthetic scenes that in turn satisfy these constraints .After applying the proposed framework , scenes that are plausible representations of the training examples are automatically generated .", "label": "", "metadata": {}, "score": "64.62075"}
{"text": "These advancements would strengthen the utility of Maxent for wildlife research and management .Abstract : The high pay packages of U.S. CEOs have raised serious concerns about what would constitute a fair pay .Since the present economic models do not adequately address this fundamental question , we propose a new theory based on statistical mechanics and information theory .", "label": "", "metadata": {}, "score": "64.673676"}
{"text": "This is an extension of two papers , [ 10 ] and [ 4 ] , which proposed the estimation of parameters where only spatial constraints were taken into account .The extension we propose allows one to properly handle memory effects in spike statistics , for large - sized neural networks .", "label": "", "metadata": {}, "score": "64.69133"}
{"text": "Error degrades the performance of a model .Conversely , an absence of error boosts the performance of a model to the maximum possible level .In some cases , the degree of boost is found to be of an astounding order of magnitude .", "label": "", "metadata": {}, "score": "64.69161"}
{"text": "These assignments had to be made in order for the knowledge to be computed and maximized .The major barrier to solving the inverse problem was the question of how to avoid violation of the law of non - contradiction .In response , Christensen developed a strategy that answered this question .", "label": "", "metadata": {}, "score": "64.72075"}
{"text": "Abstract : There are two entropy - based methods to deal with linear inverse problems , which we shall call the ordinary method of maximum entropy ( OME ) and the method of maximum entropy in the mean ( MEM ) .", "label": "", "metadata": {}, "score": "64.85233"}
{"text": "H c is the negative of the Kullback - Leibler divergence , or discrimination information , of m ( x ) from p ( x ) , where m ( x ) is a prior invariant measure for the variable(s ) .", "label": "", "metadata": {}, "score": "65.01593"}
{"text": "Nevertheless , we assume that the experts ' distribution is concentrated between levels M and Hi .The underlying assumption is that the experts ' distribution is mainly concentrated on level Hi , but few experts are willing to assign a lower level of attack rate ( M ) ( see figure 2 for a graphical description ) .", "label": "", "metadata": {}, "score": "65.22721"}
{"text": "The non - extensive maximum entropy principle , which incorporates vague and incomplete information available to decision makers , produces a more coherent forecast of possible influenza pandemic and a conservative spending in public funding .Introduction .On 14 June 2009 , the Director - General of the World Health Organization ( WHO ) declared a global pandemic of A / H1N1/Cal influenza and suggested the application of the WHO Interim Program ( 2007 ) to mitigate the pandemic emergency .", "label": "", "metadata": {}, "score": "65.534515"}
{"text": "One approach to explore this problem is first to use synthetic data that have themselves been generated from simulations and compare the restrained ensemble with the ensemble used to generate the data [ 37 ] , [ 38 ] .With real - world experimental data , a suitable value of can be determined by cross - validating with independent data not used in the structure determination [ 39 ] .", "label": "", "metadata": {}, "score": "65.541336"}
{"text": "One approach to explore this problem is first to use synthetic data that have themselves been generated from simulations and compare the restrained ensemble with the ensemble used to generate the data [ 37 ] , [ 38 ] .With real - world experimental data , a suitable value of can be determined by cross - validating with independent data not used in the structure determination [ 39 ] .", "label": "", "metadata": {}, "score": "65.541336"}
{"text": "With the availability of these means , the derivation can be completed .Our strategy is to discovery a measure of Pr [ F ( W i given W i OR W j ) given E 2 ] with the properties that are required of the number which is assigned to Pr ( W i given W i OR W j ) .", "label": "", "metadata": {}, "score": "65.54421"}
{"text": "To ensure the integration of the copula density function over all the space equates one , g 1 ( u , v ) can be specified as 1 .To model the dependence structure , the function g ( u , v ) can be specified in the form that is related to an association measure such that the expectation E ( g ( u , v ) ) becomes some linear form of rank correlation .", "label": "", "metadata": {}, "score": "65.548546"}
{"text": "Thus , we envisage that in future applications it might be possible to integrate out not only experimental noise and \" nuisance parameters , \" but potentially also the uncertainty associated with the parameterization of a force field .We note that distributed computing platforms may be particularly well suited to sample from such models as one might need to perform multiple , independent simulations that differ only slightly in the force field used .", "label": "", "metadata": {}, "score": "65.726364"}
{"text": "Thus , we envisage that in future applications it might be possible to integrate out not only experimental noise and \" nuisance parameters , \" but potentially also the uncertainty associated with the parameterization of a force field .We note that distributed computing platforms may be particularly well suited to sample from such models as one might need to perform multiple , independent simulations that differ only slightly in the force field used .", "label": "", "metadata": {}, "score": "65.726364"}
{"text": "Parametric disaggregation method is another type of parametric methods for multisite streamflow simulation that generally consists of two steps .It first generates aggregated streamflow ( e.g. , annual flow ) and then disaggregates or divides it into lower - level variables ( e.g. , monthly flow ) [ Valencia and Schaake , 1973 ; Stedinger and Vogel , 1984 ; Koutsoyiannis and Manetas , 1996 ] .", "label": "", "metadata": {}, "score": "65.772064"}
{"text": "One must then consider whether this gives further information which is still relevant at the time of measurement .The question of how ' rapidly mixing ' different properties of the system are then becomes very much of interest .Information about some degrees of freedom of the combined system may become unusable very quickly ; information about other properties of the system may go on being relevant for a considerable time .", "label": "", "metadata": {}, "score": "65.846634"}
{"text": "The key elements for the maximum entropy decision are as follows : .Solving Problem 1 numerically , 21 we get the distribution for the pandemic influenza attack rate .This distribution is largely flat , with heavier tails than the seasonal influenza distribution .", "label": "", "metadata": {}, "score": "65.89749"}
{"text": "^ Lieb , E.H. , Yngvason , J. ( 2003 ) .The entropy of classical thermodynamics , Chapter 8 of Greven , A. , Keller , G. , Warnecke ( editors ) ( 2003 ) .Entropy , Princeton University Press , Princeton NJ , ISBN 0 - 691 - 11338 - 6 , page 190 .", "label": "", "metadata": {}, "score": "65.98007"}
{"text": "o the theory of fair gambling devices , .o the modern theory of heat aka thermodynamics and , .o the modern theory of communication .A study ( Christensen , 1986a ) compares the performances of models built by entropy minimax pattern discovery to the performances of models built under the method of heuristics .", "label": "", "metadata": {}, "score": "66.29223"}
{"text": "Abstract : In this paper we present a simple model to describe a rather general system in a stationary non - equilibrium state , which is an open system traversed by a stationary flux .The probabilistic description is provided by a non - homogeneous Markov chain , which is not assumed on the basis of a model of the microscopic interactions but rather derived from the knowledge of the macroscopic fluxes traversing the system through a maximum entropy rate principle .", "label": "", "metadata": {}, "score": "66.32593"}
{"text": "In Liber de Ludo Aleae , Cardano supplied a principle of reasoning whose scope was limited to models of games of chance .Under this principle , equal numerical values were assigned to the probabilities of the ways in which an outcome could occur in a game of chance , provided that this game was fair .", "label": "", "metadata": {}, "score": "66.622025"}
{"text": "The effect is to maximize the missing information about the encoded message at the encoder of this message and minimize the missing information about the un - encoded message at the decoder of the same message .By 1963 , the problem of induction remained unsolved .", "label": "", "metadata": {}, "score": "67.13283"}
{"text": "In the example provided above , the states male and female are examples of ways .The state male OR female is not a way , for it is abstracted from the two other states .If an inference were to be optimized , it had to possess a unique measure .", "label": "", "metadata": {}, "score": "67.247574"}
{"text": "i . g .i ( 7 ) .[ 13 ] These parameters can be estimated using the Newton Raphson iteration method [ Wu , 2003 ; Hao and Singh , 2011 ] .However , a high - dimensional integration is involved in the parameter estimation for the multisite simulation to obtain the value of \u03bb 0 in equation ( 6 ) , which makes it even more complicated than the single - site streamflow simulation . , 1991 ] .", "label": "", "metadata": {}, "score": "67.65584"}
{"text": "Whether this approximation in practice proves more efficient than finding local - optima in the full restraint Lagrange problem remains to be seen .One direction that is worth pursuing further in this respect is to develop a replica analogy to the approach , alleviating the need for the numerical determination of the Lagrange multiplier .", "label": "", "metadata": {}, "score": "67.67729"}
{"text": "Whether this approximation in practice proves more efficient than finding local - optima in the full restraint Lagrange problem remains to be seen .One direction that is worth pursuing further in this respect is to develop a replica analogy to the approach , alleviating the need for the numerical determination of the Lagrange multiplier .", "label": "", "metadata": {}, "score": "67.67729"}
{"text": "v . ) exp .[ .r . m .r .u .r .r . m .v .r . ) m .u .v . ) . ]Parameter \u03bb 0 can be expressed as a function of other parameters as .", "label": "", "metadata": {}, "score": "67.75798"}
{"text": "With this information , the first constraint in modelling H is and we can search a suitable model that obeys this constraint .Infinite combinations of events are possible .However , further information may be available , for example , that levels VL and L appear 30 % of the time .", "label": "", "metadata": {}, "score": "68.076065"}
{"text": "Recent studies indicate Maxent is relatively insensitive to spatial errors associated with location data , requires few locations to construct useful models , and performs better than other presence - only modeling approaches .Further advances are needed to better define model thresholds , to test model significance , and to address model selection .", "label": "", "metadata": {}, "score": "68.12762"}
{"text": "In doing so , it generated a logical theory of knowledge that was the only such theory .This line of thinking yielded a pair of principles of reasoning .To keep unambiguous track of these ideas , it is necessary to employ mathematical symbols in referencing some of them .", "label": "", "metadata": {}, "score": "68.21887"}
{"text": "Combining Experiments and Simulations Using the Maximum Entropy Principle .PLoS Comput Biol 10(2 ) : e1003406 .doi:10.1371/journal.pcbi.1003406 .Editor : Michael Levitt , Stanford University , United States of America .Published : February 20 , 2014 .", "label": "", "metadata": {}, "score": "68.22481"}
{"text": "Combining Experiments and Simulations Using the Maximum Entropy Principle .PLoS Comput Biol 10(2 ) : e1003406 .doi:10.1371/journal.pcbi.1003406 .Editor : Michael Levitt , Stanford University , United States of America .Published : February 20 , 2014 .", "label": "", "metadata": {}, "score": "68.22481"}
{"text": "Decades of research have gone into the development and fine - tuning of these force fields , and they have proven useful in a multitude of applications [ 7 ] .Figure 1 Despite their success , it is , however , still a common scenario that the results obtained through simulations do not quantitatively match those obtained from experiments .", "label": "", "metadata": {}, "score": "68.24628"}
{"text": "Decades of research have gone into the development and fine - tuning of these force fields , and they have proven useful in a multitude of applications [ 7 ] .Figure 1 Despite their success , it is , however , still a common scenario that the results obtained through simulations do not quantitatively match those obtained from experiments .", "label": "", "metadata": {}, "score": "68.24628"}
{"text": "This result only reflects assumptions used in the numerical example , and more skewed distribution and average pandemic influenza attack rate can be found varying the distribution and uncertainty assumptions ( e.g. the experts ' attack rate , the uncertainty factor , etc . ) .", "label": "", "metadata": {}, "score": "68.4025"}
{"text": "In 3 trials , the relative frequency will be 0 OR 1/3 OR 2/3 OR 1 .In N trials , the relative frequency will be 0 OR 1/ N OR 2/ N OR 3/ N OR 1 .Note that the relative frequency will surely be one of the elements in the sequence of numbers 0 , 1/ N , 2/ N , 3/ N , , 1 .", "label": "", "metadata": {}, "score": "68.426834"}
{"text": "The previous framework can be applied once a decision maker faces a set of probability distributions describing the possible attack rate for an infectious disease .In the case of epidemic and pandemic flu , data are generally aggregated for different age classes , and discrete probability distributions are considered for the expected attack rate .", "label": "", "metadata": {}, "score": "68.437164"}
{"text": "Failure to accurately predict them is a good indicator that relevant macroscopically determinable physics may be missing from the model .According to Liouville 's theorem for Hamiltonian dynamics , the hyper - volume of a cloud of points in phase space remains constant as the system evolves .", "label": "", "metadata": {}, "score": "68.49996"}
{"text": "Another must read paper on maxent .It deals with a more general frame work : Random Fields and proposes an Improved Iterative Scaling algorithm for estimating parameters of Random Fields .This paper gives theoretical background to Random Fields ( and hence Maxent model ) .", "label": "", "metadata": {}, "score": "68.75515"}
{"text": "The extension of logic makes it possible , for the first time , to eliminate logical error from a model .Most models in use today , in fields of endeavor that include medicine , engineering , law , business and government , are guilty of this kind of error .", "label": "", "metadata": {}, "score": "68.78088"}
{"text": "As we have here hinted , the problem of uncertainties in the data appears to be related to the problem of determining the relative weight between force field and restraint - potential .A relevant question in this context is whether such a weight can be meaningfully defined and assigned without considering the inherent accuracy of the force field itself .", "label": "", "metadata": {}, "score": "68.87387"}
{"text": "As we have here hinted , the problem of uncertainties in the data appears to be related to the problem of determining the relative weight between force field and restraint - potential .A relevant question in this context is whether such a weight can be meaningfully defined and assigned without considering the inherent accuracy of the force field itself .", "label": "", "metadata": {}, "score": "68.87387"}
{"text": "To our knowledge , this method has not yet been applied to molecular simulation , and the practical applicability of the approach therefore remains to be established .Finally , we note that an alternative approach has very recently been suggested to derive structural ensembles from noisy , ensemble - averaged experimental data [ 51 ] .", "label": "", "metadata": {}, "score": "68.983795"}
{"text": "To our knowledge , this method has not yet been applied to molecular simulation , and the practical applicability of the approach therefore remains to be established .Finally , we note that an alternative approach has very recently been suggested to derive structural ensembles from noisy , ensemble - averaged experimental data [ 51 ] .", "label": "", "metadata": {}, "score": "68.983795"}
{"text": "The monthly streamflows at different sites are then generated by sampling from the conditional distribution .A case study for the generation of monthly streamflow at three sites in the Colorado River basin illustrates the application of the proposed method .Simulated streamflow from the maximum entropy copula is in satisfactory agreement with observed streamflow .", "label": "", "metadata": {}, "score": "69.1167"}
{"text": "The adhesive layer between the skin and core is modeled using linear springs , the rigidities of which are reduced in debonded sectors .The algorithm is validated using experimental data of an aluminum honeycomb panel under different damage scenarios .Abstract : We study the problem of finding probability densities that match given European call option prices .", "label": "", "metadata": {}, "score": "69.29776"}
{"text": "Well , it 's time to have a look at this one .Edwin Thompson Jaynes presented some insightful results of maximum entropy principle in this 1957 paper published in Physics Reviews .This is also his first paper in information theory .", "label": "", "metadata": {}, "score": "70.049866"}
{"text": "The degree of degradation could be and often was great .People died and suffered other unpleasant consequences from the errors .In 1948 , the mathematician and communications engineer Claude Shannon opened up a path out of this quagmire .Shannon identified a measure which , it could be shown , was the unique measure of an inference .", "label": "", "metadata": {}, "score": "70.0684"}
{"text": "Simulating replicas .One intuitive strategy to overcome this problem is to simultaneously simulate several replicas of the system and apply restraints on the average of the back - calculated experimental values , rather than on the individual structures [ 25 ] .", "label": "", "metadata": {}, "score": "70.14161"}
{"text": "Simulating replicas .One intuitive strategy to overcome this problem is to simultaneously simulate several replicas of the system and apply restraints on the average of the back - calculated experimental values , rather than on the individual structures [ 25 ] .", "label": "", "metadata": {}, "score": "70.14161"}
{"text": "The estimates show considerable distributional differences resulting from policies that change water subsidies in the region or shift price supports to direct payments .Abstract : This paper addresses the problem of balancing statistical economic data , when data structure is arbitrary and both uncertainty estimates and a ranking of data quality are available .", "label": "", "metadata": {}, "score": "70.195526"}
{"text": "Experiment results prove that Hierarchical Geometry Verification based on Maximum Entropy Saliency can not only improve retrieval accuracy , but also reduce the time consumption of the full retrieval .Abstract : Drug discovery applies multidisciplinary approaches either experimentally , computationally or both ways to identify lead compounds to treat various diseases .", "label": "", "metadata": {}, "score": "70.43364"}
{"text": "Astronomical and Astrophysical Transactions , V.1 , issue 4 , p. 313 - 320 . \"A Maximum Entropy Model Applied to Spatial and Temporal Correlations from Cortical Networks in Vitro \" .Journal of Neuroscience 28 ( 2 ) : 505 - 518 .", "label": "", "metadata": {}, "score": "70.69826"}
{"text": "Non - Equilibrium Thermodynamics and Statistical Mechanics : Foundations and Applications , Oxford University Press , Oxford UK , ISBN 978 - 0 - 19 - 966276 - 0 , p. 161 .Grandy , W. T. , 1987 .Foundations of Statistical Mechanics .", "label": "", "metadata": {}, "score": "70.84922"}
{"text": "Abstract : In this paper we present a stochastic route choice model for transit networks that explicitly addresses route correlation due to overlapping alternatives .The model is based on a multi - objective mathematical programming problem , the optimality conditions of which generate an extension to the Multinomial Logit models .", "label": "", "metadata": {}, "score": "71.30255"}
{"text": "An unconventional adaptive simulated annealing technique , called funnel diffusion , determines expansion coefficients for Chebyshev polynomials in the exponential function .Abstract : We review here the difference between quantum statistical treatments and semiclassical ones , using as the main concomitant tool a semiclassical , shift - invariant Fisher information measure built up with Husimi distributions .", "label": "", "metadata": {}, "score": "71.379906"}
{"text": "The dot between the parentheses symbolizes that element in the collection of measurable sets which is measured by Pr ( . )The collection of sets which were measurable by Sh ( . ) included an unobserved state - space plus the observed state - space which participated with this unobserved state - space in making an inference .", "label": "", "metadata": {}, "score": "71.51281"}
{"text": "Sometimes they pay with their lives .The firm KnowledgeToTheMax fills a gap in which very few research workers are equipped to build a logically sound , optimally effective model .The firm offers services that include conduct of tutorials , consultation on curriculum reform in education and construction of models .", "label": "", "metadata": {}, "score": "71.58179"}
{"text": "This prediction is in agreement with observed data for the bottom 90%-95 % of the working population .The theory estimates that the top 35 U.S. CEOs were overpaid by about 129 times their ideal salaries in 2008 .We also provide an insight of entropy as a measure of fairness , which is maximized at equilibrium , in an economic system .", "label": "", "metadata": {}, "score": "71.751495"}
{"text": "[ 8 ] The constraints can be expressed as .c . u .v . ) g .i . u .v . )d .u . d .v .g .i .i .n ( 3 ) .", "label": "", "metadata": {}, "score": "72.14114"}
{"text": "o this principle has been known since Aristotle described it 23 centuries ago .For the deductive logic , the principle of reasoning dictates the conformity of arguments to the form called modus ponens or the form called modus tollens .To be useful to us , a model must describe the unobserved ones .", "label": "", "metadata": {}, "score": "72.31517"}
{"text": "Major premise : A implies B .Minor premise : A .Conclusion : B .Modus tollens states : .Major premise : A implies B .Minor premise : NOT B .Conclusion : NOT A .Modus ponens and modus tollens express the one - to - one relationship between patterns and outcomes , under entropy minimax , when the missing information for a deductive conclusion is reduced to nil .", "label": "", "metadata": {}, "score": "72.355576"}
{"text": "The independent variable space of a model may be divided into parts .Each element of C is a tuple or is abstracted from the tuples in a part of this partition .In practice , there are a great many possible partitions of the independent variable space .", "label": "", "metadata": {}, "score": "72.50466"}
{"text": "Let this set be designated by F ( W i given W i OR W j ) .F ( W i given W i OR W j ) is a variable whose true but thus far undetermined value is Fr ( W i given W i OR W j ) .", "label": "", "metadata": {}, "score": "72.54276"}
{"text": "If the identity of g ( . ) is determined , then the required means are available for the assignment of a number to Pr ( W i given W i OR W j ) .What is the identity of the measure g ( . )", "label": "", "metadata": {}, "score": "72.791824"}
{"text": "One of these outcomes was a hit in a time at bat in the game of baseball .The other outcome was not a hit .Each condition was the identity of the major league player who was the batter .The results of the test were published in the periodical Scientific American ( Efron and Bradley , 1977 ) .", "label": "", "metadata": {}, "score": "73.01903"}
{"text": "The proposed methodology can also be applied to similar topics , such as rainfall simulation and geostatistical interpolation .The potential drawbacks would be that the marginal properties of the copula are approximated numerically and the sum of tributary flows adding up to the downstream flow can not be ensured with the current framework .", "label": "", "metadata": {}, "score": "73.022934"}
{"text": "Equation ( 3 ) imposes the first of two constraints on the form of the measure g ( . )On the assumption that the function Pr [ F ( W i given W i OR W j ) given E 2 ] has a single maximum , a form for g ( . ) that is consistent with this constraint is that g ( . ) is the value of F ( W i given W i OR W j ) at this maximum .", "label": "", "metadata": {}, "score": "73.182655"}
{"text": "The incorrect inferences degraded the performance of the model .The magnitude of the degradation could be and often was great .Over the period of 27 years that ended in 1975 , it became possible to eliminate the incorrect inferences by optimization of inferences .", "label": "", "metadata": {}, "score": "73.32687"}
{"text": "The following argument is the result of a suggestion made by Graham Wallis to E. T. Jaynes in 1962 .[ 8 ] It is essentially the same mathematical argument used for the Maxwell - Boltzmann statistics in statistical mechanics , although the conceptual emphasis is quite different .", "label": "", "metadata": {}, "score": "73.55861"}
{"text": "Comparison with other machine learning technique ( Naive Bayes , Transform Based Learning , Decision Tree etc . ) was given .Ratnaparkhi also had a short introduction paper on ME .Abney applies Improved Iterative Scaling algorithm to parameters estimation of Attribute - Value grammars , which can not be corrected calculated by ERF method ( though it works on PCFG ) .", "label": "", "metadata": {}, "score": "74.19319"}
{"text": "The observed state - space contains a single state , which is abstracted from the ways in the unobserved state - space .The numerical values which are assigned to the probabilities of the various ways form a set .Sets of numerical values of infinite number are possibilities .", "label": "", "metadata": {}, "score": "74.43233"}
{"text": "Let E 2 designate the evidence that is available for the assignment of a numerical value to Pr ( W i given W i OR W j ) .Let Pr [ ( W i given W i OR W j ) given E 2 ] designate this value .", "label": "", "metadata": {}, "score": "74.5509"}
{"text": "This can not be done , for to do so would be to change the value from 0.6931 to some other value but this value is fixed under the defining precept of frequentism .To generalize from this example , pattern discovery can not take place under frequentism nor can knowledge be created because frequentism implies the states in observed state - spaces to be of fixed description .", "label": "", "metadata": {}, "score": "74.58567"}
{"text": "KnowledgeToTheMax offers its assistance to the scientific , educational and business communities in filling this gap .Prior to the year 1975 , science was undermined by the existence of unresolved foundational issues .Among these were : .o The origins of patterns , .", "label": "", "metadata": {}, "score": "74.60595"}
{"text": "With this Perspectives article , we will highlight the approach in some detail , hopefully communicating the elegance of the procedure and encouraging further work in this direction .As a concrete example , we will focus our attention on a recent application in the field of structural biology , namely , the problem of conducting molecular simulations under restraints from experimental data .", "label": "", "metadata": {}, "score": "74.66997"}
{"text": "With this Perspectives article , we will highlight the approach in some detail , hopefully communicating the elegance of the procedure and encouraging further work in this direction .As a concrete example , we will focus our attention on a recent application in the field of structural biology , namely , the problem of conducting molecular simulations under restraints from experimental data .", "label": "", "metadata": {}, "score": "74.66997"}
{"text": "Since then , Maximum Entropy technique ( and the more general framework Random Fields ) has enjoyed intensive research in NLP community .YASMET --Yet Another Simple Maximum Entropy Toolkit with Feature Selection .YASMET(2 ) --Yet Another Small MaxEnt Toolkit .", "label": "", "metadata": {}, "score": "74.933205"}
{"text": "The phase of the wavelet is estimated by constant - phase rotation to the seismic signal , while the other two parameters are obtained by the Higher - order Statistics ( HOS ) ( fourth - order cumulant ) matching method .", "label": "", "metadata": {}, "score": "75.003815"}
{"text": "The reduction to the deductive logic occurs in the following manner .Associated with the deductive logic is a single principle of reasoning .This principle states that an argument is correct if and only if it matches the abstract argument called modus ponens or the abstract argument called modus tollens .", "label": "", "metadata": {}, "score": "75.282974"}
{"text": "T takes on the values of O and C .If T takes on the value of O then U takes on the value of C .If T takes on the value of C then U contains a single state and this state is abstracted from the states in C .", "label": "", "metadata": {}, "score": "75.28645"}
{"text": "That few of us are aware of the principles of reasoning or how they operate is a barrier to eradication of the incorrect inferences that plague us .To gain this awareness , one must delve into the details of logic .", "label": "", "metadata": {}, "score": "75.29659"}
{"text": "17 ] ) .Jaynes ' die problem .A die has been tossed many times , and we are provided with the information that the average outcome was some value , rather than the 3.5 that one would expect from a fair die .", "label": "", "metadata": {}, "score": "75.39648"}
{"text": "17 ] ) .Jaynes ' die problem .A die has been tossed many times , and we are provided with the information that the average outcome was some value , rather than the 3.5 that one would expect from a fair die .", "label": "", "metadata": {}, "score": "75.39648"}
{"text": "doi : 10.1016/j.jmr.2011.08.039 .Figures .Abstract .A key component of computational biology is to compare the results of computer modelling with experimental measurements .Despite substantial progress in the models and algorithms used in many areas of computational biology , such comparisons sometimes reveal that the computations are not in quantitative agreement with experimental data .", "label": "", "metadata": {}, "score": "75.84761"}
{"text": "Alternatively , view our Knowledge Base articles for additional help .Your feedback is important to us , so please let us know if you have comments or ideas for improvement .Introduction .[ 2 ] For multisite streamflow simulation in a river basin , it is desired that statistical properties of streamflow at individual sites and dependence structure among different sites are preserved .", "label": "", "metadata": {}, "score": "75.850174"}
{"text": "In the construction of a model , a key idea is that of abstraction .A model is abstracted ( removed ) from some of the details of the real world .How to abstract his / her model from the details is one of the problems faced by the builder of a model .", "label": "", "metadata": {}, "score": "76.0679"}
{"text": "Thus , it is an example of a maximum likelihood estimator .The straight rule is illogical , for it violates the principle of entropy maximization .This deficiency is most apparent in the circumstance that n is small .Is it logical to conclude that all swans are white on the basis of a sighting of a single white swan ?", "label": "", "metadata": {}, "score": "76.180824"}
{"text": "However , as time evolves , that initial information we had becomes less directly accessible .Instead of being easily summarisable in the macroscopic description of the system , it increasingly relates to very subtle correlations between the positions and momenta of individual molecules .", "label": "", "metadata": {}, "score": "76.18699"}
{"text": "The situation in which logic has been completed but neither the scientific nor academic community has come to grips with this advance leaves a great deal of work to be done and very few people or organizations with the ability to do this work .", "label": "", "metadata": {}, "score": "76.18843"}
{"text": "A bibliography is available by clicking here .The literature is large and not completely user friendly .Proofs of some theorems are sketchy or absent .Hence , it would be far more cost effective to engage a tutor than to attempt to climb the learning curve unaided .", "label": "", "metadata": {}, "score": "76.28064"}
{"text": "Which candidate was correct ?The model builder had to decide !However , logic was incomplete .Aristotle had described the principle of reasoning for the deductive branch of logic but , in building a model , the builder had to employ the inductive branch of logic .", "label": "", "metadata": {}, "score": "76.44469"}
{"text": "Jaynes stated Bayes ' theorem was a way to calculate a probability , while maximum entropy was a way to assign a prior probability distribution .[ 9 ] .Jaynes , E. T. , 1986 ( new version online 1996 ) , ' Monkeys , kangaroos and ' , in Maximum - Entropy and Bayesian Methods in Applied Statistics , J. H. Justice ( ed . ) , Cambridge University Press , Cambridge , p. 26 .", "label": "", "metadata": {}, "score": "76.6399"}
{"text": "Jaynes explicitly rejected the criticism of some writers that , just because one can say that thought has a subjective aspect , thought is automatically non - objective .He explicitly rejected subjectivity as a basis for scientific reasoning , the epistemology of science ; he required that scientific reasoning have a fully and strictly objective basis .", "label": "", "metadata": {}, "score": "76.81198"}
{"text": "In an advance of breathtaking importance , logic has been completed .The completion was effected by extending logic from its roots in the deductive logic through the inductive logic .In the extension of logic , the principles of reasoning were discovered .", "label": "", "metadata": {}, "score": "77.047646"}
{"text": "Introduction .Picture this scenario : you have spent years developing an elaborate model for a particular scientific phenomenon .Now , new experimental data have been measured for the same phenomenon , and the data disagree with your model .How do you proceed ?", "label": "", "metadata": {}, "score": "77.10516"}
{"text": "Introduction .Picture this scenario : you have spent years developing an elaborate model for a particular scientific phenomenon .Now , new experimental data have been measured for the same phenomenon , and the data disagree with your model .How do you proceed ?", "label": "", "metadata": {}, "score": "77.10516"}
{"text": "[ 12 ] .The theory has also been criticized in the grounds of internal consistency .For instance , Radu Balescu provides a concise but strong criticism of the MaxEnt School and of Jaynes ' work .Balescu states how Jaynes ' and coworkers theory is based on a non - transitive evolution law that produces ambiguous results .", "label": "", "metadata": {}, "score": "77.25523"}
{"text": "Burling FT , Weis WI , Flaherty KM , Brunger AT ( 1996 ) Direct observation of protein salvation and discrete disorder with experimental crystallographic phases .Science 271 : 72 - 77 .doi : 10.1126/science.271.5245.72 .J Biomol NMR 15 : 315 - 330 .", "label": "", "metadata": {}, "score": "77.28374"}
{"text": "Burling FT , Weis WI , Flaherty KM , Brunger AT ( 1996 ) Direct observation of protein salvation and discrete disorder with experimental crystallographic phases .Science 271 : 72 - 77 .doi : 10.1126/science.271.5245.72 .J Biomol NMR 15 : 315 - 330 .", "label": "", "metadata": {}, "score": "77.28374"}
{"text": "The primer can be speed - read in about half an hour , probably without attaining full understanding of the mathematical details .More thorough study of this topic , preferably with the help of a competent tutor , is advised for scientists , philosophers , educators , intellectuals , professionals , business leaders and political leaders , among others .", "label": "", "metadata": {}, "score": "77.69978"}
{"text": "As such , they may in particular benefit from improved force fields , and we expect that as force fields continue to improve it should become possible to study more complex systems with less experimental information .Importantly , a consistent theoretical framework should allow us to transition smoothly between traditional , mostly data - driven methods for structure determination and molecular simulations in the absence of any experimental data .", "label": "", "metadata": {}, "score": "78.189644"}
{"text": "As such , they may in particular benefit from improved force fields , and we expect that as force fields continue to improve it should become possible to study more complex systems with less experimental information .Importantly , a consistent theoretical framework should allow us to transition smoothly between traditional , mostly data - driven methods for structure determination and molecular simulations in the absence of any experimental data .", "label": "", "metadata": {}, "score": "78.189644"}
{"text": "We argue that the A / H1N1/Cal pandemic could have been managed with a less conservative rule .This article suggests that the application of the full conservative notion or strong version of the PP induces over - reaction .", "label": "", "metadata": {}, "score": "78.46784"}
{"text": "This was to revolutionize the communications industry .HDTV was to become one of the fruits from this revolution .Inexplicably , research workers failed to seize the same opportunity .We employ these inferences in making decisions on issues of importance to us .", "label": "", "metadata": {}, "score": "78.689926"}
{"text": "Scatterplots of the observed ( closed circle ) and simulated ( plus symbol ) monthly streamflow ( marginal ) for March and April at different sites .[ 24 ] Boxplots were used to display the observed and simulated statistics , and the performance was judged to be good when a statistic fell within the boxplot [ Nowak et al . , 2010 ; Salas and Lee , 2010 ] .", "label": "", "metadata": {}, "score": "78.71064"}
{"text": "In certain cases , the degree of outperformance was very great .o whether a gasoline storage tank will be found to be leaking a carcinogen into an aquifer or an explosive into adjacent basements , if dug up and tested and , .", "label": "", "metadata": {}, "score": "79.40526"}
{"text": "The previous sections assumed that the experimentally observed values were obtained with perfect accuracy .In any real - world scenario there will , however , be some level of noise or uncertainty associated with such experimental data .As an example , consider the case of the die in Box 1 : the experiment from which the averages are observed will always consist of a finite number of tosses , and the average is therefore only determined within some uncertainty .", "label": "", "metadata": {}, "score": "80.07764"}
{"text": "The previous sections assumed that the experimentally observed values were obtained with perfect accuracy .In any real - world scenario there will , however , be some level of noise or uncertainty associated with such experimental data .As an example , consider the case of the die in Box 1 : the experiment from which the averages are observed will always consist of a finite number of tosses , and the average is therefore only determined within some uncertainty .", "label": "", "metadata": {}, "score": "80.07764"}
{"text": "A broad range of physical models can be studied within this approach .We use one - dimensional classical spin systems to illustrate the theoretical ideas .The examples studied in this paper are : the Ising model , the Potts model and the Blume - Emery - Griffiths model .", "label": "", "metadata": {}, "score": "80.167336"}
{"text": "Whole Sentence Language Model ) with sampling based training .Now seems to be part of scipy .Stanford Classifer is another open source implementation of Maximum Entropy Model in java , suitable for NLP tagging and parsing tasks .NLTK includes a maxent classifier written entirely in Python .", "label": "", "metadata": {}, "score": "80.17624"}
{"text": "[ 15 ] The simulation methodology to generate the monthly streamflow ( marginal ) at each site can be summarized as follows : . [ 16 ] ( 1 ) Initialize monthly streamflow at sites 1 , 2 , and 3 of the first month , i.e. , u 1 , v 1 , and w 1 , by assigning random values from historical records .", "label": "", "metadata": {}, "score": "80.19058"}
{"text": "In each trial of this experiment , we observe whether the state is W i , given that the state is W i OR W j .In 1 trial of this experiment , it is a fact that the relative frequency of W i given W i OR W j will be 0 OR 1 .", "label": "", "metadata": {}, "score": "80.493866"}
{"text": "Richter B , Gsponer J , V\u00e1rnai P , Salvatella X , Vendruscolo M ( 2007 )The MUMO ( minimal underrestraining minimal over - restraining ) method for the determination of native state ensembles of proteins .J Biomol NMR 37 : 117 - 135 .", "label": "", "metadata": {}, "score": "80.57455"}
{"text": "Richter B , Gsponer J , V\u00e1rnai P , Salvatella X , Vendruscolo M ( 2007 )The MUMO ( minimal underrestraining minimal over - restraining ) method for the determination of native state ensembles of proteins .J Biomol NMR 37 : 117 - 135 .", "label": "", "metadata": {}, "score": "80.57455"}
{"text": "Decisions that have been supported by models built by entropy minimax pattern discovery include : .o the course of treatment for disorders of the cervical spine , .o which factors , in addition to .PSA , improve the reliability of prostate cancer diagnosis , .", "label": "", "metadata": {}, "score": "81.05784"}
{"text": "Applying the strong version of the PP , the government should use the most extreme prediction and buy doses of vaccine for 15 % of children population , which , at a cost of \u20ac 21 per dose , implies a spending of about \u20ac 3 millions .", "label": "", "metadata": {}, "score": "81.17546"}
{"text": "From Figure 2 , it can be seen that for most months , the median of simulated statistics is within the boxplot .Box plots of the spatial dependence of the observed and simulated monthly streamflow of the same month between different sites are shown in Figure 2 ( right column ) .", "label": "", "metadata": {}, "score": "81.19496"}
{"text": "Methods in Protein Design , Academic Press , Volume 523 of Methods in Enzymology .pp .109 - 143 .Best RB , Hummer G ( 2009 ) Optimized molecular dynamics force fields applied to the helix - coil transition of polypeptides .", "label": "", "metadata": {}, "score": "81.23108"}
{"text": "Methods in Protein Design , Academic Press , Volume 523 of Methods in Enzymology .pp .109 - 143 .Best RB , Hummer G ( 2009 ) Optimized molecular dynamics force fields applied to the helix - coil transition of polypeptides .", "label": "", "metadata": {}, "score": "81.23108"}
{"text": "Systematic validation of protein force fields against experimental data .PLOS One 7 : e32131 doi:10.1371/journal.pone.0032131 .Leaver - Fay A , O'Meara MJ , Tyka M , Jacak R , Song Y , et al .. ( 2013 ) Chapter six - scientific benchmarks for guiding macromolecular energy function improvement .", "label": "", "metadata": {}, "score": "81.66149"}
{"text": "Systematic validation of protein force fields against experimental data .PLOS One 7 : e32131 doi:10.1371/journal.pone.0032131 .Leaver - Fay A , O'Meara MJ , Tyka M , Jacak R , Song Y , et al .. ( 2013 ) Chapter six - scientific benchmarks for guiding macromolecular energy function improvement .", "label": "", "metadata": {}, "score": "81.66149"}
{"text": "Res ., 44 , W02415 , doi : 10.1029/2007WR006261 .Sharma , A. , and R. O'Neill ( 2002 ) , A nonparametric approach for representing interannual dependence in monthly streamflow sequences , Water Resour .Res . , 38 ( 7 ) , 1100 , doi : 10.1029/2001WR000953 .", "label": "", "metadata": {}, "score": "81.74716"}
{"text": "Christensen completed it .Using his idea , Christensen explained the origins of patterns , described the nature of knowledge and enunciated the principles of reasoning .In the construction of a model , one of two principles of reasoning was to maximize the knowledge .", "label": "", "metadata": {}, "score": "82.8338"}
{"text": "An word morphology application for English was developed . longer version .This paper applies ME technique to statistical language modeling task .More specifically , it builds a conditional Maximum Entropy model that incorporates traditional N - gram , distant N - gram and trigger pair features .", "label": "", "metadata": {}, "score": "83.06615"}
{"text": "Many otherwise well informed people believe the problem remains unsolved .In many ways , our society is organized as if this belief were true .For example , while it is impermissible to publish an illogical deductive argument in a mathematical journal , it is permissible to publish an illogical inductive argument in a scientific journal .", "label": "", "metadata": {}, "score": "83.38859"}
{"text": "Therefore , calling H the model for the pandemic influenza attack rate , we need to assign a level of severity to the next influenza wave H(p ) to find the less concentrate or most ' uniform ' decision model .The parameter p is the level of severity .", "label": "", "metadata": {}, "score": "83.440445"}
{"text": "Patterns originated in the construction of models under the principles of reasoning .Often , they performed much better .Today , there is an anomaly in which , with near universality , communications engineers build their models by optimization while , with near universality , research workers build their models by the method of heuristics .", "label": "", "metadata": {}, "score": "83.611206"}
{"text": "[21 ] We illustrate the derivation of the joint probability density function for monthly streamflow at site 1 and 2 as an example .Denote the marginal probabilities of monthly streamflow for the month s at sites 1 and 2 as U s and V s .", "label": "", "metadata": {}, "score": "83.66131"}
{"text": "We acknowledge that the vaccination choice depends on more factors than presently described ( e.g. political decisions and budget constraints ) , but the core of the article is only about decision principles in pandemic prevention .In the puzzling and ambiguous scenario of the pandemic influenza , the WHO and Health Ministers decided to contain the A / H1N1/Cal influenza by adopting the strong version of the Precautionary Principle ( PP ) , which dictates ' better safe than sorry ' .", "label": "", "metadata": {}, "score": "84.08429"}
{"text": "o consultancy on curriculum reform in education , .o management of theoretical aspects of scientific studies and , .o construction of ultra - optimized , logical , maximally effective models .From 1975 to 1982 Oldberg managed the theoretical side of the research program of the electric utilities of the U.S. on the performance of materials in the cores of their nuclear reactors .", "label": "", "metadata": {}, "score": "84.32178"}
{"text": "One bit of information is gained when an erasure is replaced by a binary digit .The information about the winner is the number of binary digits .The missing information about the winner is the number of erasures .The missing information about the winner , also measured in bits , is the number of erasures .", "label": "", "metadata": {}, "score": "85.17795"}
{"text": "Dordrecht : D. Reidel .Vol . 1 : ISBN 90 - 277 - 2489-X .Vol . 2 : ISBN 90 - 277 - 2649 - 3 .Extensive archive of further papers by E.T. Jaynes on probability and physics .", "label": "", "metadata": {}, "score": "85.223465"}
{"text": "s .u . s .v .s .v .s .v .s . )[ 23 ] One hundred sequences of monthly streamflow ( marginal ) with the same length as the historical record ( 98 years ) were generated for each site with the simulation methodology .", "label": "", "metadata": {}, "score": "85.38185"}
{"text": "Macromolecular Structure Determination .Molecular simulations typically utilize either molecular dynamics ( MD ) or Monte Carlo ( MC ) methods to sample conformations according to an energy function , .Here , represents the structure of a molecule and possibly also solvent molecules and other co - factors , and represents a mathematical function that relates the structure to the \" energy \" of the system .", "label": "", "metadata": {}, "score": "85.66853"}
{"text": "Macromolecular Structure Determination .Molecular simulations typically utilize either molecular dynamics ( MD ) or Monte Carlo ( MC ) methods to sample conformations according to an energy function , .Here , represents the structure of a molecule and possibly also solvent molecules and other co - factors , and represents a mathematical function that relates the structure to the \" energy \" of the system .", "label": "", "metadata": {}, "score": "85.66853"}
{"text": "Suitable for text categorization and related NLP tasks .Here is another small maxent package in C++ with a BSD - like license , written by Dekang Lin .A must read paper on applying maxent technique to Natural Language Processing .", "label": "", "metadata": {}, "score": "86.13521"}
{"text": "The tags added to the feature descriptors are used to compute the saliency matching score , and the scores are regarded as the weight information in the geometry verification step .Second we define a spatial pattern as a triangle composed of three matched features and evaluate the similarity between every two spatial patterns .", "label": "", "metadata": {}, "score": "86.600105"}
{"text": "The insensitivity eliminates the violation of the law of non - contradiction .However , there is an unsavory side effect .The story of what it is that is unsavory tells best by way of an example .In the example , c is 0.6931 , W i is rain given cloudy and W j is no rain given cloudy .", "label": "", "metadata": {}, "score": "86.70043"}
{"text": "In view of the potential for confusion , it would be wise and cost - effective for the student to engage a competent tutor .For those who wish to attempt to learn of the details without a tutor , the following self - guided tutorial is provided .", "label": "", "metadata": {}, "score": "86.9977"}
{"text": "This approach has , for instance , been used to study the structural dynamics of folded proteins [ 31 ] - [ 33 ] , unfolded proteins [ 34 ] , membrane proteins [ 35 ] , and intrinsically disordered proteins [ 36 ] .", "label": "", "metadata": {}, "score": "87.638565"}
{"text": "This approach has , for instance , been used to study the structural dynamics of folded proteins [ 31 ] - [ 33 ] , unfolded proteins [ 34 ] , membrane proteins [ 35 ] , and intrinsically disordered proteins [ 36 ] .", "label": "", "metadata": {}, "score": "87.638565"}
{"text": "19 ] ( 4 ) Repeat step ( 3 ) to generate a sequence of monthly streamflows u 4 , ... , u t , v 4 , ... , v t and w 4 , ... , w t up to time t .", "label": "", "metadata": {}, "score": "87.729294"}
{"text": "Figures .Abstract .A key component of computational biology is to compare the results of computer modelling with experimental measurements .Despite substantial progress in the models and algorithms used in many areas of computational biology , such comparisons sometimes reveal that the computations are not in quantitative agreement with experimental data .", "label": "", "metadata": {}, "score": "88.0238"}
{"text": "The spread pattern of simulated streamflow pairs generally matched that of observed streamflow pairs of the 2 months well .As an example , the monthly streamflow of March and April for site 3 shows a strong dependence ( Spearman correlation : 0.83 ) and most of the streamflow pairs spread along the diagonal .", "label": "", "metadata": {}, "score": "88.02492"}
{"text": "Claude Elwood Shannon 's influential 1948 paper that laid the foundation of information theory and changed the whole world since then .I see no reason who has read the above papers does not want to read this one .Information Theory and Statistical Mechanics ( Jaynes , E. T. , 1957 )", "label": "", "metadata": {}, "score": "88.18227"}
{"text": "This article presents a new supervised learning algorithm to identify debonded regions in aluminum honeycomb panels .The algorithm uses a linear approximation method handled by a statistical inference model based on the maximum - entropy principle .The merits of this new approach are twofold : training is avoided and data is processed in a period of time that is comparable to the one of neural networks .", "label": "", "metadata": {}, "score": "88.25184"}
{"text": "doi : 10.1126/science.1157092 .Roux B , Islam SM ( 2013 ) Restrained - ensemble molecular dynamics simulations based on distance histograms from double electron - electron resonance spectroscopy .J Phys Chem B 117 : 4733 - 4739 .", "label": "", "metadata": {}, "score": "88.35362"}
{"text": "doi : 10.1126/science.1157092 .Roux B , Islam SM ( 2013 ) Restrained - ensemble molecular dynamics simulations based on distance histograms from double electron - electron resonance spectroscopy .J Phys Chem B 117 : 4733 - 4739 .", "label": "", "metadata": {}, "score": "88.35362"}
{"text": "( 2011 ) Direct - coupling analysis of residue coevolution captures native contacts across many protein families .Proc Natl Acad Sci U S A 108 : E1293-E1301 .doi : 10.1073/pnas.1111471108 .Klepeis JL , Lindorff - Larsen K , Dror RO , Shaw DE ( 2009 )", "label": "", "metadata": {}, "score": "88.67205"}
{"text": "( 2011 ) Direct - coupling analysis of residue coevolution captures native contacts across many protein families .Proc Natl Acad Sci U S A 108 : E1293-E1301 .doi : 10.1073/pnas.1111471108 .Klepeis JL , Lindorff - Larsen K , Dror RO , Shaw DE ( 2009 )", "label": "", "metadata": {}, "score": "88.67205"}
{"text": "doi : 10.1021/jp901540 t .Tyka MD , Jung K , Baker D ( 2012 )Efficient sampling of protein conformational space using fast loop building and batch minimization on highly parallel computers .J Comput Chem 33 : 2483 - 2491 .", "label": "", "metadata": {}, "score": "88.77924"}
{"text": "doi : 10.1021/jp901540 t .Tyka MD , Jung K , Baker D ( 2012 )Efficient sampling of protein conformational space using fast loop building and batch minimization on highly parallel computers .J Comput Chem 33 : 2483 - 2491 .", "label": "", "metadata": {}, "score": "88.77924"}
{"text": "Traditional structure determination methods .Despite recent substantial developments in the accuracy of molecular energy functions [ 18 ] - [ 20 ] it is still not possible routinely and consistently to use molecular simulations to predict or refine the structure of proteins [ 21 ] , [ 22 ] .", "label": "", "metadata": {}, "score": "88.99477"}
{"text": "Traditional structure determination methods .Despite recent substantial developments in the accuracy of molecular energy functions [ 18 ] - [ 20 ] it is still not possible routinely and consistently to use molecular simulations to predict or refine the structure of proteins [ 21 ] , [ 22 ] .", "label": "", "metadata": {}, "score": "88.99477"}
{"text": "Structure determination by NMR : The modeling of NMR parameters as ensemble averages .In : Hoch JC , Poulsen FM , Redfield C , editors .Computational aspects of the Study of Biological Macromolecules by Nuclear Magnetic Resonance Spectroscopy .New York : Plenum Press . pp .", "label": "", "metadata": {}, "score": "89.01511"}
{"text": "Structure determination by NMR : The modeling of NMR parameters as ensemble averages .In : Hoch JC , Poulsen FM , Redfield C , editors .Computational aspects of the Study of Biological Macromolecules by Nuclear Magnetic Resonance Spectroscopy .New York : Plenum Press . pp .", "label": "", "metadata": {}, "score": "89.01511"}
{"text": "PMID 18184793 .Open access article containing pointers to various papers and software implementations of Maximum Entropy Model on the net .Abstract .Background : During the global pandemic of A / H1N1/California/07/2009 ( A / H1N1/Cal ) influenza , many governments signed contracts with vaccine producers for a universal influenza immunization program and bought hundreds of millions of vaccines doses .", "label": "", "metadata": {}, "score": "89.32989"}
{"text": "Dedmon MM , Lindorff - Larsen K , Christodoulou J , Vendruscolo M , Dobson CM ( 2005 ) Mapping long - range interactions in \u03b1 - synuclein using spin - label NMR and ensemble molecular dynamics simulations .J Am Chem Soc 127 : 476 - 477 .", "label": "", "metadata": {}, "score": "89.39607"}
{"text": "Dedmon MM , Lindorff - Larsen K , Christodoulou J , Vendruscolo M , Dobson CM ( 2005 ) Mapping long - range interactions in \u03b1 - synuclein using spin - label NMR and ensemble molecular dynamics simulations .J Am Chem Soc 127 : 476 - 477 .", "label": "", "metadata": {}, "score": "89.39607"}
{"text": "For planned papers , a title and short abstract ( about 100 words ) can be sent to the Editorial Office for announcement on this website .Submitted manuscripts should not have been published previously , nor be under consideration for publication elsewhere ( except conference proceedings papers ) .", "label": "", "metadata": {}, "score": "89.51311"}
{"text": "o whether to restart a nuclear reactor containing parts that might fail in service , .o whether to suspend licensing of nuclear reactors , .o the level of water that should be kept behind a dam , in light of the long range forecast for precipitation , .", "label": "", "metadata": {}, "score": "89.88768"}
{"text": "Lindorff - Larsen K , Kristjansdottir S , Teilum K , Fieber W , Dobson CM , et al .( 2004 ) Determination of an ensemble of structures representing the denatured state of the bovine acyl - coenzyme A binding protein .", "label": "", "metadata": {}, "score": "90.22768"}
{"text": "Lindorff - Larsen K , Kristjansdottir S , Teilum K , Fieber W , Dobson CM , et al .( 2004 ) Determination of an ensemble of structures representing the denatured state of the bovine acyl - coenzyme A binding protein .", "label": "", "metadata": {}, "score": "90.22768"}
{"text": "E.T. Jaynes - Papers on probability , statistics and statistical physics .Dordrecht , Netherlands : D. Reidel .ISBN 90 - 277 - 1448 - 7 ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "90.61195"}
{"text": "In fact , different Health Ministers assumed the occurrence of the worst possible scenario and undervalued the possibility of mild or weak pandemic wave .This over - pessimistic view resulted in billions of euros / dollars allocated to vaccines stockpiling .", "label": "", "metadata": {}, "score": "90.64085"}
{"text": "[ 1 ] Synthetic streamflows at different sites in a river basin are needed for planning , operation , and management of water resources projects .Modeling the temporal and spatial dependence structure of monthly streamflow at different sites is generally required .", "label": "", "metadata": {}, "score": "91.840576"}
{"text": "However , millions of short - running antiviral doses and a large number of pandemic vaccine doses remained on the shelves , as millions of people refused vaccination ( e.g. only 60 million Americans had been vaccinated ) .These undesired outcomes induced some critical questions on the role of the WHO in declaring the pandemic alert , and the function of pharmaceutical industry in managing such emergencies .", "label": "", "metadata": {}, "score": "92.34244"}
{"text": "The factor of 12 to 36 improvement had been effected through the use of a method of model building that was new to meteorology .How could a mere switch in the method of its construction effect such an enormous improvement in the performance of a model ?", "label": "", "metadata": {}, "score": "92.35336"}
{"text": "A similar analysis for Sydney is also described .", "label": "", "metadata": {}, "score": "92.52045"}
{"text": "Kim Y , Prestegard J ( 1989 )A dynamic model for the structure of acyl carrier protein in solution .Biochemistry 28 : 8792 - 8797 .doi : 10.1021/bi00448a017 .Kuriyan J , \u00d6sapay K , Burley SK , Br\u00fcnger AT , Hendrickson WA , et al .", "label": "", "metadata": {}, "score": "92.58316"}
{"text": "Kim Y , Prestegard J ( 1989 )A dynamic model for the structure of acyl carrier protein in solution .Biochemistry 28 : 8792 - 8797 .doi : 10.1021/bi00448a017 .Kuriyan J , \u00d6sapay K , Burley SK , Br\u00fcnger AT , Hendrickson WA , et al .", "label": "", "metadata": {}, "score": "92.58316"}
{"text": "Raval A , Piana S , Eastwood MP , Dror RO , Shaw DE ( 2012 ) Refinement of protein structure homology models via long , all - atom molecular dynamics simulations .Proteins 80 : 2071 - 2079 .doi : 10.1002/prot.24098 .", "label": "", "metadata": {}, "score": "92.59235"}
{"text": "Raval A , Piana S , Eastwood MP , Dror RO , Shaw DE ( 2012 ) Refinement of protein structure homology models via long , all - atom molecular dynamics simulations .Proteins 80 : 2071 - 2079 .doi : 10.1002/prot.24098 .", "label": "", "metadata": {}, "score": "92.59235"}
{"text": "You need GCC 2.9x to compile the source .link2 .MEGA Model Optimization Package .A recently appeared ME implementation by Hal Daum\u00e9 III .The software features CG and LM - BFGS Optimization and is written in OCaml .Although I no longer use OCaml , I 'd say that 's a great language , and is worth learning .", "label": "", "metadata": {}, "score": "93.680534"}
{"text": "Curr Opin Struct Biol 19 : 120 - 127 .doi : 10.1016/j.sbi.2009.03.004 .Norgaard AB , Ferkinghoff - Borg J , Lindorff - Larsen K ( 2008 )Experimental parameterization of an energy function for the simulation of unfolded proteins .", "label": "", "metadata": {}, "score": "93.87861"}
{"text": "Curr Opin Struct Biol 19 : 120 - 127 .doi : 10.1016/j.sbi.2009.03.004 .Norgaard AB , Ferkinghoff - Borg J , Lindorff - Larsen K ( 2008 )Experimental parameterization of an energy function for the simulation of unfolded proteins .", "label": "", "metadata": {}, "score": "93.87861"}
{"text": "In this application the experts ' influenza pandemic attack rate on population is drawn from studies of Metzler et al .15 , 16 and the ordinary seasonal attack rate is obtained from the annual Italian ILI morbidity and severity data .", "label": "", "metadata": {}, "score": "93.99413"}
{"text": "The missing information has a precise mathematical formula that you can look up on the Web .The story is about a race among 8 equally matched horses .With the winner unknown , the identity of the winner is conveyed by the three bit binary number _ _ _ .", "label": "", "metadata": {}, "score": "94.072754"}
{"text": "To demonstrate the application of this principle , a simplified example based on Italian data on influenza - like illnesses ( ILI ) among children for the period 2003 - 10 is presented .Method : non - extensive entropy maximization .", "label": "", "metadata": {}, "score": "94.90553"}
{"text": "Proteins 10 : 340 - 358 .doi : 10.1002/prot.340100407 .Lange OF , Lakomek NA , Far\u00e8s C , Schr\u00f6der GF , Walter KF , et al .( 2008 )Recognition dynamics up to microseconds revealed from an rdc - derived ubiquitin ensemble in solution .", "label": "", "metadata": {}, "score": "95.04288"}
{"text": "Proteins 10 : 340 - 358 .doi : 10.1002/prot.340100407 .Lange OF , Lakomek NA , Far\u00e8s C , Schr\u00f6der GF , Walter KF , et al .( 2008 )Recognition dynamics up to microseconds revealed from an rdc - derived ubiquitin ensemble in solution .", "label": "", "metadata": {}, "score": "95.04288"}
{"text": "The scatterplots of the rank of observed monthly streamflow and one sequence of simulated streamflow pairs from the copula at different sites for the same month of March are also shown in Figure 1 ( bottom ) .The simulated Spearman correlations are 0.59 , 0.59 , and 0.58 , which are relatively close to the observed Spearman correlation ( i.e. , 0.65 , 0.68 , and 0.67 ) .", "label": "", "metadata": {}, "score": "95.64245"}
{"text": "Furthermore , using a Tsallis distribution in decision making for the pandemic influenza , we take explicitly into account uncertainty and acknowledge that the distribution for decision makers ' choice is broad as in figure 2 .In conclusion , using this alternative decision rule , the decision makers could rationally decide to buy vaccines doses for 12 % of the children population for preventing pandemic influenza .", "label": "", "metadata": {}, "score": "98.14424"}
{"text": "This is an open - access article distributed under the terms of the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original author and source are credited .The funders had no role in the preparation of the manuscript .", "label": "", "metadata": {}, "score": "98.189514"}
{"text": "This is an open - access article distributed under the terms of the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original author and source are credited .The funders had no role in the preparation of the manuscript .", "label": "", "metadata": {}, "score": "98.189514"}
{"text": "Modeling the Economic Impact of Pandemic Influenza in the United States : Implications for Setting Priorities for Intervention .Background paper .Atlanta , GA : CDC , 1999 .Our site uses cookies to improve your experience .You can find out more about our use of cookies in About Cookies , including instructions on how to turn off cookies if you wish to do so .", "label": "", "metadata": {}, "score": "98.24688"}
{"text": "M ( 51 - 100/1000 people ) .Hi ( 101 - 200/1000 people ) .VHi ( 201 - 350/1000 people ) .Therefore , counting the proportion of times that each age class registers an attack rate in one of the five levels in the ordinary influenza season , we get the severity of influenza distributions as in figure 1 .", "label": "", "metadata": {}, "score": "98.26755"}
{"text": "Lapedes AS , Giraud BG , Liu L , Stormo GD ( 1999 ) Correlated mutations in models of protein sequences : phylogenetic and structural effects .Lect Notes Monogr Ser 33 : 236 - 256 .doi : 10.1214/lnms/1215455556 .", "label": "", "metadata": {}, "score": "98.40773"}
{"text": "Lapedes AS , Giraud BG , Liu L , Stormo GD ( 1999 ) Correlated mutations in models of protein sequences : phylogenetic and structural effects .Lect Notes Monogr Ser 33 : 236 - 256 .doi : 10.1214/lnms/1215455556 .", "label": "", "metadata": {}, "score": "98.40773"}
{"text": "A simplified application is presented using seasonal data of morbidity and severity among Italian children influenza - like illness for the period 2003 - 10 .Principal Findings : Established literature results predict an average attack rate of not less than 15 % for the next pandemic influenza [ Meltzer M , Cox N , Fukuda K. The economic impact of pandemic influenza in the United States : implications for setting priorities for interventions .", "label": "", "metadata": {}, "score": "98.70288"}
{"text": "Problem 1 is formalized focusing on the Children group distribution , which predicts that level VL occurs in 80 % of cases and L in 20 % .On average , seasonal attack rate is 10/1000 .For the distribution Q ( x ) of Problem 1 , we assume that experts ' forecast for the next influenza pandemic reflects findings in Meltez et al .", "label": "", "metadata": {}, "score": "99.02706"}
{"text": "Wilson 8 offered a different view and interpreted the difference between predicted and observed effect of the pandemic A / H1N1/Cal as a problem of ' how ... deaths are estimated , counted and compared ' ( p. 7 ) .", "label": "", "metadata": {}, "score": "99.58554"}
{"text": "At the start of this period , centuries of research had extended the span of time over which the weather could be forecasted , with statistical significance , to no more than 1 month .At this point , it would be instructive and motivating for the reader to learn of the features of this model .", "label": "", "metadata": {}, "score": "100.696396"}
{"text": "In science , a model is invalidated if a single one of its propositions is invalidated .A state in an unobserved state - space may be conditional upon on a state in an observed state - space .For example , the state rain may be conditional upon the state cloudy .", "label": "", "metadata": {}, "score": "100.8032"}
{"text": "doi : 10.1016/j.jmr.2011.08.039 .all Addendum Article Book Review Case Report Comment Commentary Communication Concept Paper Conference Report Correction Creative Data Descriptor Discussion Editorial Erratum Essay Interesting Images Letter New Book Received Obituary Opinion Project Report Reply Retraction Review Short Note Technical Note .", "label": "", "metadata": {}, "score": "102.11068"}
{"text": "Special Issue Information .Submission .Once you are registered , click here to go to the submission form .Manuscripts can be submitted until the deadline .Papers will be published continuously ( as soon as accepted ) and will be listed together on the special issue website .", "label": "", "metadata": {}, "score": "102.45601"}
{"text": "Abstract : Honeycomb sandwich structures are used in a wide variety of applications .Nevertheless , due to manufacturing defects or impact loads , these structures can be subject to imperfect bonding or debonding between the skin and the honeycomb core .", "label": "", "metadata": {}, "score": "102.53961"}
{"text": "In the ordinary season , the period 2004 - 05 presented , on average , the highest attack rate for all age classes , except for the Young group ( 5 - 14 years ) , for which the worst period was 2009 - 10 , with an attack rate of almost 10 % .", "label": "", "metadata": {}, "score": "103.263145"}
{"text": "Notice : Wiley Online Library will be unavailable on Saturday 27th February from 09:00 - 14:00 GMT / 04:00 - 09:00 EST / 17:00 - 22:00 SGT for essential maintenance .Apologies for the inconvenience .Space Sciences and Space Physics .", "label": "", "metadata": {}, "score": "104.42303"}
{"text": "The A / H1N1/Cal influenza pandemic shed light on the need for a rational decision rule to assist policy makers and planners with effective health system responses to epidemics .We introduce a decision rule capable of taking explicitly into account the uncertainty about the pandemic infection of A / H1N1/Cal .", "label": "", "metadata": {}, "score": "104.469124"}
{"text": "Thus , we avoid the need for a posteriori adjustment of simulated monthly totals in order to correctly simulate the observed seasonal statistics .Detailed results are presented for the modelling and simulation of seasonal rainfall in the town of Kempsey on the mid - north coast of New South Wales .", "label": "", "metadata": {}, "score": "106.344955"}
{"text": "Similarly , in the ' non - ordinary influenza season ' the influenza attack rate is lower than in any other ordinary season .Contrasting the ordinary and swine flu seasonal attack rates , we find some statistically significant differences as shown in the last row of table 1 .", "label": "", "metadata": {}, "score": "107.09245"}
{"text": "Oldberg has held positions in research , management and engineering with the Lawrence Livermore National Laboratory , General Electric Company , Electric Power Research Institute , Alltel Healthcare Information Systems and Picturetel Corporation .Oldberg holds the B.M.E. degree in mechanical engineering from Cornell University , the M.S.E. degree in mechanical engineering from the University of Michigan and the M.S.E.E. degree in electrical engineering from Santa Clara University .", "label": "", "metadata": {}, "score": "108.629364"}
{"text": "Nonetheless , prior to 1957 , statisticians were firm believers in the straight rule .It is biased in the direction of presuming extremely more information than is possessed by the model builder about the colors of the unobserved swans .The straight rule may be tested for its conformity to reality .", "label": "", "metadata": {}, "score": "108.97529"}
{"text": "The justification for this approach may have been the combination of the constantly evolving nature of influenza viruses and the possible shortage of vaccine supply due to constrained production capacity .The containment strategy ended in February 2010 reporting roughly 18,500 laboratory - confirmed deaths for pandemic influenza A / H1N1/Cal from 213 countries .", "label": "", "metadata": {}, "score": "110.0591"}
{"text": "We estimated the new model on the Santiago ( Chile ) Metro network and compared the results with other route choice models that can be found in the literature .The new model has better explanatory and predictive power that many other alternative models , correctly capturing the correlation factor .", "label": "", "metadata": {}, "score": "111.69014"}
{"text": "This ' post - pandemic ' estimate suggests very mild effects .However , at the beginning of 2009 , the Italian Health Minister could not foresee the impact of swine flu , but had to decide which quantity of vaccines to buy .", "label": "", "metadata": {}, "score": "113.09271"}
{"text": "The pandemic virus of A / H1N1/Cal was first recognized in North America as a reasserting of the influenza A / H1N1 sub - type and then confirmed in Australia and New Zealand in May 2009 .This information and the influenza distribution observed in one hemisphere could have been used as a proxy in the maximum entropy setting for predicting the attack rate in other hemispheres .", "label": "", "metadata": {}, "score": "113.22768"}
{"text": "v .s .v .s . ) exp .i .i . u . s .i .i .i .v .s .i .i .i .v .s .i . u . s .", "label": "", "metadata": {}, "score": "113.88739"}
{"text": "The ordinary attack rates of influenza come from the Italian annual ILI morbidity and severity data , provided by the surveillance system , which collects epidemiological and virological data from national networks .For the year 2009 , data are also available for the Weeks 17 - 42 , defined as the ' non - ordinary influenza season ' .", "label": "", "metadata": {}, "score": "115.3556"}
{"text": "o whether to submit a request for approval of a diagnostic technique for breast cancer to the U.S. Food and Drug Administration , FDA , .o whether to submit a request for approval of a diagnostic technique for cervical cancer to the FDA , .", "label": "", "metadata": {}, "score": "117.51781"}
{"text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "129.9229"}
