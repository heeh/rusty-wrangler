{"text": "We investigate how to best train a parser on the French Treebank ( Abeill\u00e9 et al . , 2003 ) , viewing the task as a trade - off between generalizability and interpretability .We compare , for French , a supervised lexicalized parsing algorithm with a semi - supervised unlexicalized algorithm ( Petrov et al . , 2006 ) along the lines of ( Crabb\u00e9 and Candito , 2008 ) .", "label": "", "metadata": {}, "score": "40.867615"}
{"text": "We investigate how to best train a parser on the French Treebank ( Abeill\u00e9 et al . , 2003 ) , viewing the task as a trade - off between generalizability and interpretability .We compare , for French , a supervised lexicalized parsing algorithm with a semi - supervised unlexicalized algorithm ( Petrov et al . , 2006 ) along the lines of ( Crabb\u00e9 and Candito , 2008 ) .", "label": "", "metadata": {}, "score": "40.867615"}
{"text": "We present a syntax - based language model for use in noisy - channel machine translation .In particular , a language model based upon that described in ( Cha01 ) is combined with the syntax based translation - model described in ( YK01 ) .", "label": "", "metadata": {}, "score": "43.76279"}
{"text": "We apply the new transition - based parser on typologically different languages such as English , Chinese , Czech , and German and report competitive labeled and unlabeled attachment scores . ... restricted to projective dependency trees and used pseudo - projective parsing ( Kahane et al .", "label": "", "metadata": {}, "score": "43.818295"}
{"text": "Intl .Assoc . for Machine Translation , 2003 . \" ...We present a syntax - based language model for use in noisy - channel machine translation .In particular , a language model based upon that described in ( Cha01 ) is combined with the syntax based translation - model described in ( YK01 ) .", "label": "", "metadata": {}, "score": "45.67492"}
{"text": "We compare various PCFG and history - based parsers ( based on Collins , 1999 ; Charniak , 2000 ; Bikel , 2002 ) to find a baseline parsing system that fits best into our automatic dependency structure annotation technique .This combined system of syntactic parser and dependency structure annotation is compared to two hand - crafted , deep constraint - based parsers ( Carroll and Briscoe 2002 ; Riezler et al .", "label": "", "metadata": {}, "score": "45.956154"}
{"text": "We investigate how to best train a parser on the French Treebank ( Abeill\u00e9 et al . , 2003 ) , viewing the task as a trade - off between generalizability and interpretability .We compare , for French , a supervised lexicalized parsing algorithm w ... \" .", "label": "", "metadata": {}, "score": "46.607224"}
{"text": "We investigate how to best train a parser on the French Treebank ( Abeill\u00e9 et al . , 2003 ) , viewing the task as a trade - off between generalizability and interpretability .We compare , for French , a supervised lexicalized parsing algorithm w ... \" .", "label": "", "metadata": {}, "score": "46.607224"}
{"text": "In particular , we show that the reranking parser described in Charniak and Johnson ( 2005 ) improves performance of the parser on Brown to 85.2 % .Furthermore , use of the self - training techniques described in ( Mc - Closky et al . , 2006 ) raise this to 87.8 % ( an error reduction of 28 % ) again without any use of labeled Brown data .", "label": "", "metadata": {}, "score": "47.341774"}
{"text": "In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .", "label": "", "metadata": {}, "score": "47.549225"}
{"text": "Finally , we present multilingual experiments which show that parsing with hierarchical state - splitting is fast and accurate in multiple languages and domains , even without any language - specific tuning . ... g ( Matsuzaki et al . , 2005 ; Petrov et al . , 2006 ) .", "label": "", "metadata": {}, "score": "47.803658"}
{"text": "We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .", "label": "", "metadata": {}, "score": "48.687202"}
{"text": "We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .", "label": "", "metadata": {}, "score": "48.687202"}
{"text": "This paper aims to provide some understanding and solid baseline numbers for the ... \" .Previous work on German parsing has provided confusing and conflicting results concerning the difficulty of the task and whether techniques that are useful for English , such as lexicalization , are effective for German .", "label": "", "metadata": {}, "score": "50.08528"}
{"text": "This paper aims to provide some understanding and solid baseline numbers for the ... \" .Previous work on German parsing has provided confusing and conflicting results concerning the difficulty of the task and whether techniques that are useful for English , such as lexicalization , are effective for German .", "label": "", "metadata": {}, "score": "50.08528"}
{"text": "An experimental evaluation shows that the incorporation of a grammar - based generator into an SMT framework provides improved grammaticality while achieving state - of - the - art quality on in - coverage examples , suggesting a possible hybrid framework .", "label": "", "metadata": {}, "score": "50.525047"}
{"text": "We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .", "label": "", "metadata": {}, "score": "51.282196"}
{"text": "We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .", "label": "", "metadata": {}, "score": "51.282196"}
{"text": "The system consists of two components : an unlabeled dependency parser using Gibbs sampling which can incorporate sentence - level ( global ) features as well as token - leve ... \" .In this paper , we describe a two - stage multilingual dependency parser used for the multilingual track of the CoNLL 2007 shared task .", "label": "", "metadata": {}, "score": "51.377747"}
{"text": "We could also introduce new variables , e.g. , nonterminal refinements ( Matsuzaki et al . , 2005 ) , or secondary links Mij ( not constrai ... . by Jin - dong Kim , Tomoko Ohta , Sampo Pyysalo , Yoshinobu Kano - In Proceedings of Natural Language Processing in Biomedicine ( BioNLP )", "label": "", "metadata": {}, "score": "51.476482"}
{"text": "We provide experimental evaluations on the Penn Treebank . ... , or build a single tree by means of shift - reduce parsing actions ( Yamada & Matsumoto , 2003 ) .These parsers process the sentence sequentially , hence their efficiency makes them suitable for processing large amounts of text , as required , for example , in information retrieval applications .", "label": "", "metadata": {}, "score": "52.031578"}
{"text": "We generalize the evaluation to other word - types , and show that the performance can be increased to 18 % relative by preserving part - of - speech equivalencies during translation .We further differentiate ourselves from previous work by conducting a second evaluation which examines the accuracy of translating all word types , rather than just nouns .", "label": "", "metadata": {}, "score": "52.875496"}
{"text": "This paper presents novel improvements to the induction of translation lexicons from monolingual corpora using multilingual dependency parses .We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative ... \" .", "label": "", "metadata": {}, "score": "53.50414"}
{"text": "In contrast , we introduce a largely automated method for capturing more information from human post - editors , so that corrections may be performed automatically to translation grammar rules and lexical entries .This paper introduces a general framework for incorporating a refinement module to rule - based transfer MT systems .", "label": "", "metadata": {}, "score": "53.522583"}
{"text": "While prior feature - based dynamic programming parsers have restricted training and evaluation to artificially short sentences , we present the first general , featurerich discriminative parser , based on a conditional random field model , which has been successfully scaled to the full WSJ parsing data .", "label": "", "metadata": {}, "score": "53.663322"}
{"text": "We depend on a source - language dependency parser and a word - aligned parallel corpus .The only targe ... \" .done while at Microsoft Research We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .", "label": "", "metadata": {}, "score": "54.38208"}
{"text": "While the synchronised derivations allow different structures to be built for the semantic non - planar graphs and syntactic dependency trees , useful statistical dependencies between these structures are modeled using latent variables .The resulting synchronous parser achieves competitive performance on the CoNLL-2008 shared task , achieving relative error reduction of 12 % in semantic F score over previously proposed synchronous models that can not process non - planarity online . ... ivre and Nilsson , 2005].", "label": "", "metadata": {}, "score": "54.829613"}
{"text": "..METU - Sabanc\u0131 treebank ( Atalay et al . , 2003 ; Oflazer et al . , 2003 ) from the CoNLL shared task in 2006 .Whenever using CoNLL shared task data , we used the first 80 % of the data d .. \" ...", "label": "", "metadata": {}, "score": "55.349228"}
{"text": "Dependency parsing is a central NLP task .In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .", "label": "", "metadata": {}, "score": "55.37844"}
{"text": "We present an evaluation measure that takes into account the possibility of incompatible token segmentation between the gold standard and the parsed data .Results indicate that ( a ) MST - parser performs better on Hebrew data than Malt - Parser , and ( b ) both parsers do not make good use of morphological information when parsing Hebrew . ... s on Hebrew dependency parsing .", "label": "", "metadata": {}, "score": "55.38196"}
{"text": "In particular we note the effects of two comparatively recent techniques for parser improvement .Then a reranking phase uses more detailed features , features which would ( mostly ) be ... . \" ...We formulate dependency parsing as a graphical model with the novel ingredient of global constraints .", "label": "", "metadata": {}, "score": "56.053596"}
{"text": "This system 's ability to acquire its primary translation knowledge automatically by parsing a bilingual corpus of hundreds of thousands of sentence pairs and aligning resulting logical f ... \" .We describe MSR - MT , a large - scale hybrid machine translation system under development for several language pairs .", "label": "", "metadata": {}, "score": "56.117214"}
{"text": "A number of previous efforts have tackled this tradeoff by starting with a commitment to linguistically motivated analyses and then finding appropriate ways to soften that commitment .We present an approach that explores the tradeoff from the other direction , starting with a context - free translation model learned directly from aligned parallel text , and then adding soft constituent - level constraints based on parses of the source language .", "label": "", "metadata": {}, "score": "56.12661"}
{"text": "A number of previous efforts have tackled this tradeoff by starting with a commitment to linguistically motivated analyses and then finding appropriate ways to soften that commitment .We present an approach that explores the tradeoff from the other direction , starting with a context - free translation model learned directly from aligned parallel text , and then adding soft constituent - level constraints based on parses of the source language .", "label": "", "metadata": {}, "score": "56.12661"}
{"text": "We evaluate two decoding approaches , one inspired by dynamic programming and the . ... m combining the power of statistical learning and modeling with the insight of linguistic analysis has recently been the subject of much research .However it did not incorporate t .. by Stephen D. Richardson , William B. Dolan , Arul Menezes , Jessie Pinkham - In Proceedings of the 2001 MT , 2001 . \" ...", "label": "", "metadata": {}, "score": "56.52256"}
{"text": "To determine why , we analyzed the time usage of a dependency parser .We illustrate that the mapping of the features onto thei ... \" .In addition to a high accuracy , short parsing and training times are the most important properties of a parser .", "label": "", "metadata": {}, "score": "56.695957"}
{"text": "This paper presents a comparative study of probabilistic treebank parsing of German , using the Negra and T\u00fcBa - D / Z treebanks .Experiments with the Stanford parser , which uses a factored PCFG and dependency model , show that , contrary to previous claims for other parsers , lexicalization of PCFG models ... \" .", "label": "", "metadata": {}, "score": "56.98591"}
{"text": "This paper presents a comparative study of probabilistic treebank parsing of German , using the Negra and T\u00fcBa - D / Z treebanks .Experiments with the Stanford parser , which uses a factored PCFG and dependency model , show that , contrary to previous claims for other parsers , lexicalization of PCFG models ... \" .", "label": "", "metadata": {}, "score": "56.98591"}
{"text": "We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative improvement over the baseline approach that uses a fixed context window of adjacent words .", "label": "", "metadata": {}, "score": "57.211708"}
{"text": "A second group of papers does parsing by a sequence of independent , discriminative decisions , either greedily or with use of a small beam ( Ratnaparkhi , 1997 ; Henderson , 2004 ) .This paper extends th ... does n't break the sense of the sentence and it is still valid .", "label": "", "metadata": {}, "score": "57.395348"}
{"text": "Our approach involves building a probabilistic context - free grammar for each author and using this grammar as a language model for classification .We evaluate the performance of our method on a wide range of datasets to demonstrate its efficacy . ... 000 ; Holmes and Forsyth , 1995 ; Joachims , 1998 ; Mosteller and Wallace , 1984 ) .", "label": "", "metadata": {}, "score": "57.564472"}
{"text": "Our approach involves building a probabilistic context - free grammar for each author and using this grammar as a language model for classification .We evaluate the performance of our method on a wide range of datasets to demonstrate its efficacy . ... 000 ; Holmes and Forsyth , 1995 ; Joachims , 1998 ; Mosteller and Wallace , 1984 ) .", "label": "", "metadata": {}, "score": "57.564472"}
{"text": ".. ch automatically aligns translationally equivalent tree fragments in a fast and consistent fashion , and which requires little or no knowledge of the language pair .We conduct a number of experiments on the English - French section of the Xerox HomeCentre corpus .", "label": "", "metadata": {}, "score": "57.626625"}
{"text": "We present a supervised method for training a sentence level confidence measure on translation output using a humanannotated corpus .We evaluate a variety of machine learning methods .The resultant measure , while trained on a very small dataset , correlates well with human judgments , and proves to be ... \" .", "label": "", "metadata": {}, "score": "57.84828"}
{"text": "( 2003 ) who show that parsing - based language modeling ca ... .by Stephen D. Richardson , William B. Dolan , Arul Menezes , Monica Corston - oliver - In Proceedings of the ACL 2001 Workshop on Data - Driven Methods in Machine Translation , 2001 . \" ...", "label": "", "metadata": {}, "score": "58.103325"}
{"text": "Empirically , optimal k - best lists can be extracted significantly faster than with other approaches , over a range of grammar types . \" ...We present a novel approach to grammatical error correction based on Alternating Structure Optimization .As part of our work , we introduce the NUS Corpus of Learner English ( NUCLE ) , a fully annotated one million words corpus of learner English available for research purposes .", "label": "", "metadata": {}, "score": "58.399426"}
{"text": "Empirically , optimal k - best lists can be extracted significantly faster than with other approaches , over a range of grammar types . \" ...We present a novel approach to grammatical error correction based on Alternating Structure Optimization .As part of our work , we introduce the NUS Corpus of Learner English ( NUCLE ) , a fully annotated one million words corpus of learner English available for research purposes .", "label": "", "metadata": {}, "score": "58.399426"}
{"text": "We hope that this method may find wider acceptance and be useful in establishing a generally applicable framework for evaluation in natural language parsing .We employ this method in an evaluation of NLPWin ( Heidorn , 2000 ) , a parser developed at Microsoft Research without reference to the Penn Treebank , and , for comparison , the well - known statistical Treebank parser of Charniak ( 2000 ) .", "label": "", "metadata": {}, "score": "58.680313"}
{"text": "In this paper we adopt a simplified version of this approach , where we introduce a single new action .Although the resulting parser is not powerful enough to parse all non - planar structures , this s .. \" ...In addition to a high accuracy , short parsing and training times are the most important properties of a parser .", "label": "", "metadata": {}, "score": "59.383877"}
{"text": "We apply this idea to dependency and constituent parsing , generating results that surpass state - of - theart ... \" .We present a novel parser combination scheme that works by reparsing input sentences once they have already been parsed by several different parsers .", "label": "", "metadata": {}, "score": "59.426685"}
{"text": "Lexicalized parsing focuses on identifying dependencies .w.o .GFs with GFs T\u00fcBa - D / Z 2611 2610 2197 Tiger 2535 2534 1592 T ..Existing k - best extraction methods can efficiently search for top derivations , but only after an exhaustive 1-best pass .", "label": "", "metadata": {}, "score": "60.163074"}
{"text": "Lexicalized parsing focuses on identifying dependencies .w.o .GFs with GFs T\u00fcBa - D / Z 2611 2610 2197 Tiger 2535 2534 1592 T ..Existing k - best extraction methods can efficiently search for top derivations , but only after an exhaustive 1-best pass .", "label": "", "metadata": {}, "score": "60.163074"}
{"text": "First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar without a treebank .In our experiments , hierarchical pruning greatly accelerates parsing with no loss in empirical accuracy .", "label": "", "metadata": {}, "score": "60.23255"}
{"text": "Such worries have merit .The standard \" Charniak parser \" checks in at a labeled precisionrecall f - measure of 89.7 % on the Penn WSJ test set , but only 82.9 % on the test set from the Brown treebank corpus .", "label": "", "metadata": {}, "score": "60.693245"}
{"text": "pp .81 - 124 .Abstract .In this article , we revisit the experiments in Preiss ( 2003 ) and Kaplan et al .( 2004 ) , this time using the sophisticated automatic LFG f - structure annotation methodologies of Cahill et al .", "label": "", "metadata": {}, "score": "60.79604"}
{"text": "We evaluate using dependency - based gold standards ( DCU 105 , PARC 700 , CBS 500 and dependencies for WSJ Section 22 ) and use the Approximate Randomization Test ( Noreen 1989 ) to test the statistical significance of the results .", "label": "", "metadata": {}, "score": "60.94876"}
{"text": "Experimental results show that the global features are useful in all the languages . ... mines unlabeled dependency structures only , and we attach dependency relation labels using Support Vector Machines afterwards . \" ...We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .", "label": "", "metadata": {}, "score": "60.95388"}
{"text": "We present an approach to statistical machine translation that combines ideas from phrase - based SMT and traditional grammar - based MT .Our system incorporates the concept of multi - word translation units into transfer of dependency structure snippets , and models and trains statistical components according to stateof - the - art SMT systems .", "label": "", "metadata": {}, "score": "62.04241"}
{"text": "We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .We apply the framework to word segmentation , joint segmentation and POStagging , dependency parsing , and phrase - structure parsing .", "label": "", "metadata": {}, "score": "62.11515"}
{"text": "At a high level , MSR - MT is a syntactically - informed example based system , trained on domain specific translation resources from parallel sentence aligned bilingual c .. \" ...We present an approach to statistical machine translation that combines ideas from phrase - based SMT and traditional grammar - based MT .", "label": "", "metadata": {}, "score": "62.428913"}
{"text": "Trained on aligned English - Spanish technical prose , a blind evaluation shows that MSR - MT 's integration of rule - based parsers , example based processing , and statistical techniques ... \" .We describe MSR - MT , a large - scale example - based machine translation system under development for several language pairs .", "label": "", "metadata": {}, "score": "62.551926"}
{"text": "This method requires a source - language dependency parser , target language word segmentation and an unsupervised word alignment component .We align a parallel corpus , project the source dependency parse onto the target sentence , extract dependency treelet translation pairs , and train a tree - based ordering model .", "label": "", "metadata": {}, "score": "62.55504"}
{"text": "Specifically , we develop three infinite tree models , each of which enforces different independence assumptions , and for each model we define a simple direct assignment sampling inference procedure . ... ch of the left and right .As is standard , we used WSJ sections 2 - 21 for training , section 22 for development , and section 23 for testing .", "label": "", "metadata": {}, "score": "62.842407"}
{"text": "Specifically , we develop three infinite tree models , each of which enforces different independence assumptions , and for each model we define a simple direct assignment sampling inference procedure . ... ch of the left and right .As is standard , we used WSJ sections 2 - 21 for training , section 22 for development , and section 23 for testing .", "label": "", "metadata": {}, "score": "62.842407"}
{"text": "We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .This method requires a source - language dependency parser , target language word segmentation and an unsupervised word alignment compo ... \" .", "label": "", "metadata": {}, "score": "62.94288"}
{"text": "Tools . \" ...In adding syntax to statistical MT , there is a tradeoff between taking advantage of linguistic analysis , versus allowing the model to exploit linguistically unmotivated mappings learned from parallel training data .A number of previous efforts have tackled this tradeoff by starting with a commitment ... \" .", "label": "", "metadata": {}, "score": "63.031837"}
{"text": "We focus on one of the simplest and most efficient architectures , based on a deterministic shift - reduce algorithm , trained with the perceptron .By adopting second - order feature maps , the primal form of the perce ... \" .", "label": "", "metadata": {}, "score": "63.06103"}
{"text": "To process non - planarity online , the semantic transition - based parser u ... \" .This paper investigates a generative history - based parsing model that synchronises the derivation of non - planar graphs representing semantic dependencies with the derivation of dependency trees representing syntactic structures .", "label": "", "metadata": {}, "score": "63.094593"}
{"text": "Adapting WSJ - trained parsers to the British national corpus using in - domain self - training .Foster , Jennifer and Wagner , Joachim and Seddah , Djam\u00e9 and van Genabith , Josef ( 2007 ) Adapting WSJ - trained parsers to the British national corpus using in - domain self - training .", "label": "", "metadata": {}, "score": "63.309013"}
{"text": "On WSJ15 , we attain a state - of - the - art F - score of 90.9 % , a 14 % relative reduction in error over previous models , while being two orders of magnitude faster .On sentences of length 40 , our system achieves an F - score of 89.0 % , a 36 % relative reduction in error over a generative baseline . ...", "label": "", "metadata": {}, "score": "63.45745"}
{"text": "The reported experiments Eric Ringger , Robert C. Moore , Eugene Charniak , Lucy Vanderwende , and Hisami Suzuki May 2004 .Abstract .This paper describes a method for conducting evaluations of Treebank and non - Treebank parsers alike against the English language U. Penn Treebank ( Marcus et al . , 1993 ) using a metric that focuses on the accuracy of relatively non - controversial aspects of parse structure .", "label": "", "metadata": {}, "score": "63.545322"}
{"text": "The reported experiments Tools . \" ...In adding syntax to statistical MT , there is a tradeoff between taking advantage of linguistic analysis , versus allowing the model to exploit linguistically unmotivated mappings learned from parallel training data .A number of previous efforts have tackled this tradeoff by starting with a commitment ... \" .", "label": "", "metadata": {}, "score": "63.627697"}
{"text": "This has lead to a higher accuracy .We could further increase the parsing and training speed with a parallel feature extraction and a parallel parsing algorithm .We are convinced that the Hash Kernel and the parallelization can be applied successful to other NLP applications as well such as transition based dependency parsers , phrase structrue parsers , and machine translation . by Massimiliano Ciaramita - Proc . of the 12th International Workshop on Parsing Technologies ( IWPT , 2007 . \" ...", "label": "", "metadata": {}, "score": "63.770164"}
{"text": "Finally , we try to draw general conclusions about multi - lingual parsing : What makes a particular language , treebank or annotation scheme easier or harder to parse and which phenomena are challenging for any dependency parser ?Acknowledgement Many thanks to Amit Dubey and Yuval Krymolowski , the other two organizers of the shared task , for discussions , converting treebanks , writing software and helping with the papers . \" ...", "label": "", "metadata": {}, "score": "63.834312"}
{"text": "The results show that all three systems achieve competitive performance , with a best labeled attachment score over 88 % .All three parsers benefit from the use of automatically derived lemmas , while morphological features seem to be less important .", "label": "", "metadata": {}, "score": "64.528"}
{"text": "We consider generative and discriminative models for dependency grammar induction that use word - level alignments and a source language parser ( English ) to constrain the space of possible target trees .Unlike previous approaches , our framework does not require full projected parses , allowing partial , approximate transfer through linear expectation constraints on the space of distributions over trees .", "label": "", "metadata": {}, "score": "64.80553"}
{"text": "We evaluate our approach on Bulgarian and Spanish CoNLL shared task data and show that we consistently outperform unsupervised methods and can outperform supervised learning for limited training data . ... ibution over possible target parses to approximately respect projected dependencies and other rules which we describe below .", "label": "", "metadata": {}, "score": "64.8914"}
{"text": "The wide availability of parallel text and accurate parsers in English has opened up the possibility of grammar induction through partial transfer across bitext .We consider generative and di ... \" .Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .", "label": "", "metadata": {}, "score": "65.15816"}
{"text": "Abstract .We introduce a set of 1,000 gold standard parse trees for the British National Corpus ( BNC ) and perform a series of self - training experiments with Charniak and Johnson 's reranking parser and BNC sentences .We show that retraining this parser with a combination of one million BNC parse trees ( produced by the same parser ) and the original WSJ training data yields improvements of 0.4 % on WSJ Section 23 and 1.7 % on the new BNC gold standard set .", "label": "", "metadata": {}, "score": "65.692245"}
{"text": "Wide - coverage deep statistical parsing using automatic dependency structure annotation .Cahill , Aoife and Burke , Michael and O'Donovan , Ruth and Riezler , Stefan and van Genabith , Josef and Way , Andy ( 2008 )Wide - coverage deep statistical parsing using automatic dependency structure annotation .", "label": "", "metadata": {}, "score": "65.7116"}
{"text": "The results show a significant improvement in precision for both topic relevance and opinion relevance . ...Results We performed a few experiments using the TREC 2006 Blog topics n .. \" ...Transition - based dependency parsers are often forced to make attachment decisions at a point when only partial information about the relevant graph configuration is available .", "label": "", "metadata": {}, "score": "65.994354"}
{"text": "This robustness led to the third best overall average labeled attachment score in the task , despite using no discriminative methods .We also demonstrate that the parser is quite fast , and can provide even faster parsing times without much loss of accuracy . \" ...", "label": "", "metadata": {}, "score": "66.199234"}
{"text": "The system participated in the closed challenge ranking third in the complete problem evaluation with the following scores : 82.06 labeled macro F1 for the overall task , 86.6 labeled attachment for syntactic dependencies , and 77.5 labeled F1 for semantic dependencies .", "label": "", "metadata": {}, "score": "66.28655"}
{"text": "This naive grammar ... . \" ...We present several improvements to unlexicalized parsing with hierarchically state - split PCFGs .First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar wi ... \" .", "label": "", "metadata": {}, "score": "66.651886"}
{"text": "The tree with the maximal probability is outputted .The experiments are carried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser . ... arried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser .", "label": "", "metadata": {}, "score": "67.33583"}
{"text": "Stamatatos et al .( 1999 ) and Luyckx and Daelemans ( 2008 ) use a combination of word - level statistics and part - of - speech counts or n - grams .Baayen ... .by Anna N. Rafferty , Christopher D. Manning - In ACL WorkShop on Parsing German , 2008 . \" ...", "label": "", "metadata": {}, "score": "67.644516"}
{"text": "Stamatatos et al .( 1999 ) and Luyckx and Daelemans ( 2008 ) use a combination of word - level statistics and part - of - speech counts or n - grams .Baayen ... .by Anna N. Rafferty , Christopher D. Manning - In ACL WorkShop on Parsing German , 2008 . \" ...", "label": "", "metadata": {}, "score": "67.644516"}
{"text": "So basically , I 'm talking about parts of the sentence , which make the information more specific , but removing them does n't break the whole sentence .Is there any NLP library in which identifying such parts is available ? 2 Answers 2 .", "label": "", "metadata": {}, "score": "67.87553"}
{"text": "To get a feel for the typical case , we used off - the - shelf parsers ( McDonald et al . , 2005 ) for E .. by Ivan Titov , James Henderson - IN PROCEEDINGS OF CONLL-2007 SHARED TASK .", "label": "", "metadata": {}, "score": "68.15263"}
{"text": "Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation .On the other hand , our grammars are much more compact and substantially more accurate than previous work on automatic annotation .Despite its simplicity , our best grammar achieves an F1 of 90.2 % on the Penn Treebank , higher than fully lexicalized systems . ... reebank , higher than fully lexicalized systems .", "label": "", "metadata": {}, "score": "68.43887"}
{"text": "Comput .Linguist . , 2010 . \" ...Information - extraction ( IE ) systems seek to distill semantic relations from naturallanguage text , but most systems use supervised learning of relation - specific examples and are thus limited by the availability of training data .", "label": "", "metadata": {}, "score": "68.60719"}
{"text": "We focus on one of the simplest and most efficient architectures , based on a deterministic shift - reduce algorithm , trained with the perceptron .By adopting second - order feature maps , the primal form of the perceptron produces models with comparable accuracy to more complex architectures , with no need for approximations .", "label": "", "metadata": {}, "score": "68.69516"}
{"text": "To determine why , we analyzed the time usage of a dependency parser .We illustrate that the mapping of the features onto their weights in the support vector machine is the major factor in time complexity .To resolve this problem , we implemented the passive - aggressive perceptron algorithm as a Hash Kernel .", "label": "", "metadata": {}, "score": "69.026054"}
{"text": "However , parsing accuracies for Arabic usually lag behind non - semitic languages .Moreover , whil ...", "label": "", "metadata": {}, "score": "69.07859"}
{"text": "most languages are projective .In Figure 8 An example Chinese dependency tree .Although non - projec ... . \" ...Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .", "label": "", "metadata": {}, "score": "69.130905"}
{"text": "This paper presents WOE , an open IE system which improves dramatically on TextRunner 's precision and recall .The key to WOE 's performance is a novel form of self - supervised learning for open extractors - using heuristic matches between Wikipedia infobox attribute values and corresponding sentences to construct training data .", "label": "", "metadata": {}, "score": "69.201096"}
{"text": "Their symbolic component is amenable to inspection by humans , while their probabilistic component helps resolve ambiguity .They also permit the use of well - understood , generalpurpose learn ... \" .Probabilistic grammars offer great flexibility in modeling discrete sequential data like natural language text .", "label": "", "metadata": {}, "score": "69.510826"}
{"text": "We evaluate a variety of machine learning methods .The resultant measure , while trained on a very small dataset , correlates well with human judgments , and proves to be effective on one task based evaluation .Although the experiments have only been run on one MT system , we believe the nature of the features gathered are general enough that the approach will also work well on other systems .", "label": "", "metadata": {}, "score": "69.934784"}
{"text": "The beam - search decoder only requires the syntactic processing task to be broken into a sequence of decisions , such that , at each stage in the process , the decoder is able to consider the top - n candidates and generate all possibilities for the next stage .", "label": "", "metadata": {}, "score": "70.26459"}
{"text": "Transition - based dependency parsers are often forced to make attachment decisions at a point when only partial information about the relevant graph configuration is available .In this paper , we describe a model that takes into account complete structures as they become available to rescore the elements of a beam , combining the advantages of transition - based and graph - based approaches .", "label": "", "metadata": {}, "score": "70.73982"}
{"text": "The translations were sorted into four groups : good / bad syntax crossed with good / bad meaning .The number of translations that did not preserve meaning , but at least had good grammar , also increased , though to less avail . by Declan Groves , Mary Hearne , Andy Way - In Proceedings of the 20th International Conference on Computational Linguistics ( COLING )", "label": "", "metadata": {}, "score": "70.82826"}
{"text": "non - parallel , multilingual corpus . 1 Introduction Probabilistic grammars have become an important tool in natural language processing .An attractive property of probabilistic grammars is that the ... . by Fei Wu , Daniel S. Weld - in Proc . 48th Annu .", "label": "", "metadata": {}, "score": "71.00225"}
{"text": "Since data is processed as soon as it becomes available , processing delay is minimized improving data throughput .The processing modules can be written in C++ or in Python and can be combined using few lines of Python scripts to produce full NLP applications .", "label": "", "metadata": {}, "score": "71.29715"}
{"text": "The paper presents the design and implementation of the BioNLP'09 Shared Task , and reports the final results with analysis .The shared task consists of three sub - tasks , each of which addresses bio - molecular event extraction at a different level of specificity .", "label": "", "metadata": {}, "score": "71.31459"}
{"text": "The paper presents the design and implementation of the BioNLP'09 Shared Task , and reports the final results with analysis .The shared task consists of three sub - tasks , each of which addresses bio - molecular event extraction at a different level of specificity .", "label": "", "metadata": {}, "score": "71.31459"}
{"text": "We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .Starting with a simple Xbar grammar , we learn a new grammar whose nonterminals are subsymbols of the original nonterminals .", "label": "", "metadata": {}, "score": "71.37692"}
{"text": "We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .Starting with a simple Xbar grammar , we learn a new grammar whose nonterminals are subsymbols of the original nonterminals .", "label": "", "metadata": {}, "score": "71.37692"}
{"text": "Discriminative feature - based methods are widely used in natural language processing , but sentence parsing is still dominated by generative methods .While prior feature - based dynamic programming parsers have restricted training and evaluation to artificially short sentences , we present the first gene ... \" .", "label": "", "metadata": {}, "score": "71.39501"}
{"text": "The tenth CoNLL ( CoNLL - X ) saw a shared task on Multilingual Dependency Parsing .In this paper , we describe how treebanks for 13 languages were converted into the same dependency format and how parsing performance was measured .", "label": "", "metadata": {}, "score": "71.82025"}
{"text": "In this paper , we present a novel approach for authorship attribution , the task of identifying the author of a document , using probabilistic context - free grammars .Our approach involves building a probabilistic context - free grammar for each author and using this grammar as a language model for class ... \" .", "label": "", "metadata": {}, "score": "71.8824"}
{"text": "In this paper , we present a novel approach for authorship attribution , the task of identifying the author of a document , using probabilistic context - free grammars .Our approach involves building a probabilistic context - free grammar for each author and using this grammar as a language model for class ... \" .", "label": "", "metadata": {}, "score": "71.8824"}
{"text": "In this work , we present 1 . an effective method for pruning in split PCFGs 2 . a comparison of objective functions for infe ... . \" ...The l - bfgs limited - memory quasi - Newton method is the algorithm of choice for optimizing the parameters of large - scale log - linear models with L2 regularization , but it can not be used for an L1-regularized loss due to its non - differentiability whenever some parameter is zero .", "label": "", "metadata": {}, "score": "72.16674"}
{"text": "This simple framework performs surprisingly well , giving accuracy results competitive with the state - of - the - art on all the tasks we consider .The computational simplicity of the decoder and training algorithm leads to significantly higher test speeds and lower training times than their main alternatives , including log - linear and large - margin training algorithms and dynamic - programming for decoding .", "label": "", "metadata": {}, "score": "72.27875"}
{"text": "We discuss how the general framework is applied to each of the problems studied in this article , making comparisons with alternative learning and decoding algorithms .We also show how the comparability of candidates considered by the beam is an important factor in the performance .", "label": "", "metadata": {}, "score": "72.39065"}
{"text": "The most common strategy uses the swap transition ( Nivre , 2009 ; Nivre et al . , 2009 ) , an alternative solution uses two planes and a switch transition to switch between the two planes ( G .. \" ... Abstract .", "label": "", "metadata": {}, "score": "72.43391"}
{"text": "OpenNLP may do some of this for you .Phrase chunking and parsing should help you with this .However , this is not a particularly simple problem , and algorithms will tend to get confused as sentence structure becomes more complex and ambiguous .", "label": "", "metadata": {}, "score": "72.61083"}
{"text": "We present a novel approach to grammatical error correction based on Alternating Structure Optimization .As part of our work , we introduce the NUS Corpus of Learner English ( NUCLE ) , a fully annotated one million words corpus of learner English available for research purposes .", "label": "", "metadata": {}, "score": "72.63652"}
{"text": "We present a novel approach to grammatical error correction based on Alternating Structure Optimization .As part of our work , we introduce the NUS Corpus of Learner English ( NUCLE ) , a fully annotated one million words corpus of learner English available for research purposes .", "label": "", "metadata": {}, "score": "72.63652"}
{"text": "Each year the Conference on Computational Natural Language Learning ( CoNLL ) 1 features a shared task , in which participants train and test their systems on exactly the same data sets , in order to better compare systems .The tenth CoNLL ( CoNLL - X ) saw a shared task on Multilingual Dependency Parsing .", "label": "", "metadata": {}, "score": "72.95055"}
{"text": "We explored a single stage approach to opinion mining , retrieving opinionated documents ranked with a special ranking function which exploits an index enriched with opinion tags .A set of subjective words are used as tags for identifying opinionated sentences .", "label": "", "metadata": {}, "score": "73.25369"}
{"text": "However , data acquisition constitutes a serious bottleneck as DOT requires parsed sentences aligned at both sentential and sub - structural levels .Manual substructural alignment is time - consuming , error - prone and requires considerable knowledge of both source and target languages and how they are related .", "label": "", "metadata": {}, "score": "73.63261"}
{"text": "Our experiments show that our approach outperforms two baselines trained on non - learner text and learner text , respectively .Our approach also outperforms two commercial grammar checking software packages . \" ...We investigate whether wording , stylistic choices , and online behavior can be used to predict the age category of blog authors .", "label": "", "metadata": {}, "score": "73.791306"}
{"text": "Our experiments show that our approach outperforms two baselines trained on non - learner text and learner text , respectively .Our approach also outperforms two commercial grammar checking software packages . \" ...We investigate whether wording , stylistic choices , and online behavior can be used to predict the age category of blog authors .", "label": "", "metadata": {}, "score": "73.791306"}
{"text": "WOE can operate in two modes : when restricted to POS tag features , it runs as quickly as TextRunner , but when set to use dependency - parse features its precision and recall rise even higher . ... h recall .", "label": "", "metadata": {}, "score": "74.91307"}
{"text": "Data - Oriented Translation ( DOT ) , based on DataOriented Parsing ( DOP ) , is a language - independent MT engine which exploits parsed , aligned bitexts to produce very high quality translations .However , data acquisition constitutes a serious bottleneck as DOT requires parsed sentences aligned at both ... \" .", "label": "", "metadata": {}, "score": "74.93366"}
{"text": "Even with second - order features or latent variables , which would make exact parsing considerably slower or NP - hard , BP needs only O(n3 ) time with a small constant factor .Furthermore , such features significantly improve parse accuracy over exact first - order methods .", "label": "", "metadata": {}, "score": "74.972565"}
{"text": "The Stanford and Berkeley parsers are probably the easiest to install and use .As seen in Cer et al .2010 , the most accurate parsers are Berkeley and Charniak .The Bikel parser is slower and less accurate than the others .", "label": "", "metadata": {}, "score": "74.99622"}
{"text": "Shay , 2009 . \" ...We present a family of priors over probabilistic grammar weights , called the shared logistic normal distribution .This family extends the partitioned logistic normal distribution , enabling factored covariance between the probabilities of different derivation events in the probabilistic grammar , prov ... \" .", "label": "", "metadata": {}, "score": "75.0195"}
{"text": "-Lone Coder Dec 20 ' 11 at 19:21 .Hi @dmcer , does the conclusion in the paper , particularly that Charniak 's parser performs better than Stanford 's parser , and that Charniak 's is more recommended to be used for Stanford dependencies still remains ? -", "label": "", "metadata": {}, "score": "75.043045"}
{"text": "These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation .Therefore , the standard evaluation does not provide a true indication of algorithm quality .We present a new measure , Neutral Edge Direction ( NED ) , and show that it greatly reduces this undesired phenomenon .", "label": "", "metadata": {}, "score": "75.40622"}
{"text": "A Tanl pipeline can be processed in parallel on a cluster of computers by means of a modified version of Hadoop streaming .We present the architecture , its modules and some sample applications . ... trees .The module takes as input a stream of vectors of tokens , and produces a stream of sentences .", "label": "", "metadata": {}, "score": "75.57933"}
{"text": "Yet , various grammar parameters are expected to be correlated because the elements in language they represent share linguistic properties .In this paper , we suggest an alternative to the Dirichlet prior , a family of logistic normal distributions .We derive an inference algorithm for this family of distributions and experiment with the task of dependency grammar induction , demonstrating performance improvements with our priors on a set of six treebanks in different natural languages .", "label": "", "metadata": {}, "score": "75.70847"}
{"text": "There 's an online demo for the Stanford parser here .I used the demo to produce the parse given above of your example sentence .A Note About Deletion .Within each constituent , there will be a head word .", "label": "", "metadata": {}, "score": "75.85216"}
{"text": "This has led to concer ... \" .Statistical parsers trained and tested on the Penn Wall Street Journal ( WSJ ) treebank have shown vast improvements over the last 10 years .Much of this improvement , however , is based upon an ever - increasing number of features to be trained on ( typically ) the WSJ treebank data .", "label": "", "metadata": {}, "score": "75.92087"}
{"text": "Based on this i ... \" .Abstract .This paper explores the idea that non - projective dependency parsing can be conceived as the outcome of two interleaved processes , one that sorts the words of a sentence into a canonical order , and one that performs strictly projective dependency parsing on the sorted input .", "label": "", "metadata": {}, "score": "76.08568"}
{"text": "Experiments with the Stanford parser , which uses a factored PCFG and dependency model , show that , contrary to previous claims for other parsers , lexicalization of PCFG models boosts parsing performance for both treebanks .The experiments also show that there is a big difference in parsing performance , when trained on the Negra and on the T\u00fcBa - D / Z treebanks .", "label": "", "metadata": {}, "score": "76.872696"}
{"text": "Experiments with the Stanford parser , which uses a factored PCFG and dependency model , show that , contrary to previous claims for other parsers , lexicalization of PCFG models boosts parsing performance for both treebanks .The experiments also show that there is a big difference in parsing performance , when trained on the Negra and on the T\u00fcBa - D / Z treebanks .", "label": "", "metadata": {}, "score": "76.872696"}
{"text": "The only target language resource assumed is a word breaker .These are used to produce treelet ( \" phrase \" ) translation pairs as well as several models , including a channel model , an order model , and a target language model .", "label": "", "metadata": {}, "score": "77.02488"}
{"text": "Information - extraction ( IE ) systems seek to distill semantic relations from naturallanguage text , but most systems use supervised learning of relation - specific examples and are thus limited by the availability of training data .Open IE systems such as TextRunner , on the other hand , aim to handle the unbounded number of relations found on the Web .", "label": "", "metadata": {}, "score": "77.199295"}
{"text": "We present an algorithm Orthant - Wise Limited - memory Quasi - Newton ( owlqn ) , based on l - bfgs , that can efficiently optimize the L1-regularized log - likelihood of log - linear models with millions of parameters .", "label": "", "metadata": {}, "score": "77.30773"}
{"text": "Classifier ... \" .This paper describes the DeSRL system , a joined effort of Yahoo !Research Barcelona and Universit\u00e0 di Pisa for the CoNLL-2008 Shared Task ( Surdeanu et al . , 2008 ) .The system is characterized by an efficient pipeline of linear complexity components , each carrying out a different sub - task .", "label": "", "metadata": {}, "score": "78.04288"}
{"text": "Figure 1 summarizes the system architecture .We detail the parsing All authors contributed equally to this work . ...The parser processes input tokens advancing on the input from left to right with Shift actions and accumulates processed tokens on a stack with ... . \" ...", "label": "", "metadata": {}, "score": "78.076126"}
{"text": "Abstract .Most current Machine Translation ( MT ) systems do not improve with feedback from post - editors beyond the addition of corrected translations to parallel training data ( for statistical and example - base MT ) or to a memory database .", "label": "", "metadata": {}, "score": "78.668"}
{"text": "Abstract .Most current Machine Translation ( MT ) systems do not improve with feedback from post - editors beyond the addition of corrected translations to parallel training data ( for statistical and example - base MT ) or to a memory database .", "label": "", "metadata": {}, "score": "78.668"}
{"text": "We decompose the problem into three subtasks : parsing , predicate identification and classification ( PIC ) , and argument identification and classification ( AIC ) .We address each of these subtasks with separate components without backward feedback between sub - tasks .", "label": "", "metadata": {}, "score": "79.014915"}
{"text": "..But first of all , we need to define the notion of a dependency graph a little more precisely . \" ...This paper describes the DeSRL system , a joined effort of Yahoo !Research Barcelona and Universit\u00e0 di Pisa for the CoNLL-2008 Shared Task ( Surdeanu et al . , 2008 ) .", "label": "", "metadata": {}, "score": "80.68477"}
{"text": "Trained on English and Spanish technical prose , a blind evaluation shows that MSR - MT 's integration of rule - based parsers , example based processing , and statistical techniques produces translations whose quality exceeds that of uncustomized commercial MT systems in this domain . by Ariadna Font Llitj\u00f3s , Jaime G Carbonell , Alon Lavie - Machine Translation .", "label": "", "metadata": {}, "score": "80.78438"}
{"text": "We examine the performance of three techniques on three treebanks ( Negra , Tiger , and T\u00fcBa - D / Z ) : ( i ) Markovization , ( ii ) lexicalization , and ( iii ) state splitting .We additionally explore parsing with the inclusion of grammatical function information .", "label": "", "metadata": {}, "score": "81.0412"}
{"text": "We examine the performance of three techniques on three treebanks ( Negra , Tiger , and T\u00fcBa - D / Z ) : ( i ) Markovization , ( ii ) lexicalization , and ( iii ) state splitting .We additionally explore parsing with the inclusion of grammatical function information .", "label": "", "metadata": {}, "score": "81.0412"}
{"text": "The l - bfgs limited - memory quasi - Newton method is the algorithm of choice for optimizing the parameters of large - scale log - linear models with L2 regularization , but it can not be used for an L1-regularized loss due to its non - differentiability whenever some parameter is zero .", "label": "", "metadata": {}, "score": "81.30285"}
{"text": "This family extends the partitioned logistic normal distribution , enabling factored covariance between the probabilities of different derivation events in the probabilistic grammar , providing a new way to encode prior knowledge about an unknown grammar .We describe a variational EM algorithm for learning a probabilistic grammar based on this family of priors .", "label": "", "metadata": {}, "score": "81.5885"}
{"text": "To globally model parsing actions of all steps that are taken on the inpu ... \" .Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .They only determine parsing actions stepwisely by a trained classifier .", "label": "", "metadata": {}, "score": "82.264755"}
{"text": "We also present a proof that owl - qn is guaranteed to converge to a globally optimal parameter vector . \" ...Statistical parsers trained and tested on the Penn Wall Street Journal ( WSJ ) treebank have shown vast improvements over the last 10 years .", "label": "", "metadata": {}, "score": "82.26827"}
{"text": "Within a sentence , they have a nested hierarchical structure .For instance , the first example sentence you gave could be analyzed as : .( S ( PP ( IN On ) ( NP ( NNP March ) ( CD 1 ) ) ) ( NP ( PRP he ) ) ( VP ( VBD was ) ( VP ( VBN born ) ) ) ) .", "label": "", "metadata": {}, "score": "82.948975"}
{"text": "This comparison at least suggests that German is not harder to parse than its West - Germanic neighbor language English . ... ing an appropriate parsing model for German .Section 3 introduces the Negra and T\u00fcBa - D / Z treebanks and 2 German is not the first language for which this question has been raised .", "label": "", "metadata": {}, "score": "83.5068"}
{"text": "This comparison at least suggests that German is not harder to parse than its West - Germanic neighbor language English . ... ing an appropriate parsing model for German .Section 3 introduces the Negra and T\u00fcBa - D / Z treebanks and 2 German is not the first language for which this question has been raised .", "label": "", "metadata": {}, "score": "83.5068"}
{"text": "In fact , when linguistics are trying to discover a language 's grammar , they do it in part by looking at movement .As in your example , this is where a group of words can be moved to a different position in a sentence while still preserving the meaning of the sentence .", "label": "", "metadata": {}, "score": "83.57649"}
{"text": "Tanl pipelines are data driven , i.e. each stage pulls data from the preceding stage and transforms them for use by the next stage .Since data is processed as s ... \" .Tanl ( Natural Language Text Analytics ) is a suite of tools for text analytics based on the software architecture paradigm of data pipelines .", "label": "", "metadata": {}, "score": "83.81708"}
{"text": "We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .", "label": "", "metadata": {}, "score": "84.103806"}
{"text": "We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .", "label": "", "metadata": {}, "score": "84.103806"}
{"text": "In indexing the collection , we recovered the relevant content from the blog permalink pages , exploiting HTML metadata about the generator and heuristics to remove irrelevant parts from the body .The index also contains information about the occurrence of opinionated words , extracted from an analysis of WordNet glosses .", "label": "", "metadata": {}, "score": "85.45415"}
{"text": "The Stanford Parser is used to derive dependencies from CJ50 and gold parse trees .Figure 8 shows the detailed P / R curves .We can see that although today ... .by Jenny Rose Finkel , Alex Kleeman , Christopher D. Manning - In Proc .", "label": "", "metadata": {}, "score": "85.66341"}
{"text": "As a parsing algorithm , BP is both asymptotically and empirically efficient .E ... \" .We formulate dependency parsing as a graphical model with the novel ingredient of global constraints .We show how to apply loopy belief propagation ( BP ) , a simple and effective tool for approximate learning and inference .", "label": "", "metadata": {}, "score": "86.21447"}
{"text": "They also permit the use of well - understood , generalpurpose learning algorithms .There has been an increased interest in using probabilistic grammars in the Bayesian setting .To date , most of the literature has focused on using a Dirichlet prior .", "label": "", "metadata": {}, "score": "86.35924"}
{"text": "The prepositional phrase can be further decomposed into a unit consisting of the single word ' On ' followed by a noun phrase .Phrase Structure Parsers .To find constituents automatically , you will probably want to use a phrase structure parser .", "label": "", "metadata": {}, "score": "86.854385"}
{"text": "Historically , unsupervised learning techniques have lacked a principled technique for selecting the number of unseen components .Research into non - parametric priors , such as the Dirichlet process , has enabled instead the use of infinite models , in which the number of hidden categories is not fixed , ... \" .", "label": "", "metadata": {}, "score": "86.88312"}
{"text": "Historically , unsupervised learning techniques have lacked a principled technique for selecting the number of unseen components .Research into non - parametric priors , such as the Dirichlet process , has enabled instead the use of infinite models , in which the number of hidden categories is not fixed , ... \" .", "label": "", "metadata": {}, "score": "86.88312"}
{"text": "Research into non - parametric priors , such as the Dirichlet process , has enabled instead the use of infinite models , in which the number of hidden categories is not fixed , but can grow with the amount of training data .", "label": "", "metadata": {}, "score": "87.211105"}
{"text": "Research into non - parametric priors , such as the Dirichlet process , has enabled instead the use of infinite models , in which the number of hidden categories is not fixed , but can grow with the amount of training data .", "label": "", "metadata": {}, "score": "87.211105"}
{"text": "We also show that internet writing characteristics are important features for age prediction , but that lexical content is also needed to produce significantly more accurate results .Our best results allow for 81.57 % accuracy . by Marie C , Beno\u00eet Crabb\u00e9 , Djam\u00e9 Seddah , Universit\u00e9 Paris , Universit\u00e9 Paris . \" ...", "label": "", "metadata": {}, "score": "87.58549"}
{"text": "We also show that internet writing characteristics are important features for age prediction , but that lexical content is also needed to produce significantly more accurate results .Our best results allow for 81.57 % accuracy . by Marie C , Beno\u00eet Crabb\u00e9 , Djam\u00e9 Seddah , Universit\u00e9 Paris , Universit\u00e9 Paris . \" ...", "label": "", "metadata": {}, "score": "87.58549"}
{"text": "For instance , 14.4 % of section 23 is tagged differently by ( 1 ) and ( 2 ) 8 .5 The Neutral Edge Direction ( NED ) Me ... . by Shay B. Cohen , Noah A. Smith , Alex Clark , Dorota Glowacka , Colin De La Higuera , Mark Johnson , John Shawe - taylor . \" ...", "label": "", "metadata": {}, "score": "88.45868"}
{"text": "Printed / Distributed with the permission of ELRA .This paper was published within the proceedings of the LREC'2004 Conference .\u00a9 2004 ELRA - European Language Resources Association .All rights reserved .Tools . by Kuzman Ganchev , Jennifer Gillenwater , Ben Taskar - In ACL - IJCNLP , 2009 . \" ...", "label": "", "metadata": {}, "score": "89.09173"}
{"text": "The shared task was run over 12 weeks , drawing initial interest from 42 teams .Of these teams , 24 submitted final results .The evaluation results are encouraging , indicating that state - of - the - art performance is approaching a practically applicable level and revealing some remaining challenges . ... parsers . \" ...", "label": "", "metadata": {}, "score": "90.64045"}
{"text": "( NP ( DT The ) ( JJ big ) ( JJ blue ) ( NN ball ) ) .The head word here is the noun ball , and it is modified by the adjectives big and blue .If this noun phrase was embedded in a sentence , you could delete those modifiers and still have something that was consistent with , but less specific than , the meaning of the original sentence .", "label": "", "metadata": {}, "score": "90.94662"}
{"text": "Through experimentation with a range of y ... \" .We investigate whether wording , stylistic choices , and online behavior can be used to predict the age category of blog authors .Our hypothesis is that significant changes in writing style distinguish pre - social media bloggers from post - social media bloggers .", "label": "", "metadata": {}, "score": "94.462555"}
{"text": "Through experimentation with a range of y ... \" .We investigate whether wording , stylistic choices , and online behavior can be used to predict the age category of blog authors .Our hypothesis is that significant changes in writing style distinguish pre - social media bloggers from post - social media bloggers .", "label": "", "metadata": {}, "score": "94.462555"}
{"text": "Intent mining is a special kind of document analysis whose goal is to assess the attitude of the document author with respect to a given subject .Opinion mining is a kind of intent mining where the attitude is a positive or negative opinion .", "label": "", "metadata": {}, "score": "99.3992"}
{"text": "Intent mining is a special kind of document analysis whose goal is to assess the attitude of the document author with respect to a given subject .Opinion mining is a kind of intent mining where the attitude is a positive or negative opinion .", "label": "", "metadata": {}, "score": "99.3992"}
{"text": "Within verb phrases and complete clauses , things get more tricky since deleting material that servers as an argument to the verb can completely change the interpretation a sentence .For example , deleting the book from He sold Jim the book results in He sold Jim .", "label": "", "metadata": {}, "score": "121.004524"}
