{"text": "Previous work by Lin and Hovy [ 9 ] has shown that a recall - based automatic metric for evaluating summaries outperforms the BLEU metric on that task .We describe the metrics used in our evaluation in Section 2 .We also discuss certain characteristics of the BLEU and NIST metrics that may account for the advantage of metrics based on unigram recall .", "label": "", "metadata": {}, "score": "33.859795"}
{"text": "A remaining disadvantage , however , is the high model complexity .This paper describes a word alignment training procedure for statistical machine translation that uses a simple and clear statistical model , different from the IBM models .The main idea of the algorithm is to generate a symmetric and monotonic alignment between the target sentence and a permutation graph representing different reorderings of the words in the source sentence .", "label": "", "metadata": {}, "score": "36.226494"}
{"text": "Conf . on Language Resources and Evaluation , LREC'06 , 2006 . \" ...The IBM Models ( Brown et al . , 1993 ) enjoy great popularity in the machine translation community because they offer high quality word alignments and a free implementation is available with the GIZA + + Toolkit ( Och and Ney , 2003 ) .", "label": "", "metadata": {}, "score": "37.637165"}
{"text": "The IBM Models ( Brown et al . , 1993 ) enjoy great popularity in the machine translation community because they offer high quality word alignments and a free implementation is available with the GIZA + + Toolkit ( Och and Ney , 2003 ) .", "label": "", "metadata": {}, "score": "38.71901"}
{"text": "While this may seem unexpected , since BLEU and NIST focus on n - gram precision and disregard recall , our experiments show that correlation with human judgments is highest when almost all of the weight is assigned to recall .We also show that stemming is significantly beneficial not just to simpler unigram precision and recall based metrics , but also to BLEU and NIST . 1 Introduction Automatic Metrics for machine translation ( MT ) evaluation have been receiv- ing significant attention in the past two years , since IBM 's BLEU metric was proposed and made available [ 1].", "label": "", "metadata": {}, "score": "41.368942"}
{"text": "For instance , this problem was the focus as a shared task at a recent data driven machine translation workshop .See also the systematic comparison by Och and Ney ( Computational Linguistics , 2003 ) .At this point , the most common tool to establish a word alignment is to use the toolkit GIZA++ .", "label": "", "metadata": {}, "score": "44.16131"}
{"text": "Our findings are also consistent with the curves presented by [ 33 ] , although their results are limited to a much lower data set size ( less than . sentences ) and presented on a linear scale .Incidentally , that paper also presents a recent attempt into using active learning for improving MT and meets the challenge of \" diminishing returns ' ' identified in the learning curves : a constant performance improvement requires increasing amounts of data .", "label": "", "metadata": {}, "score": "44.569084"}
{"text": "Methods for Learning Phrase Translations .Marcu and Wong .First , the exception : Marcu and Wong ( EMNLP , 2002 ) proposed to establish phrase correspondences directly in a parallel corpus .To learn such correspondences , they introduced a phrase - based joint probability model that simultaneously generates both the source and target sentences in a parallel corpus .", "label": "", "metadata": {}, "score": "45.84084"}
{"text": "Work related to our learning curve experiments can also be found in [ 10 ] .It is important to remark that while there are many discussions about automatic evaluation of SMT systems , this work does not consider them .We work within the well - defined setting where a loss function has been agreed upon , that can measure the similarity between two sentences , and a paired training set has been provided .", "label": "", "metadata": {}, "score": "46.153282"}
{"text": "Our method is related to work by Ueffing ( 2002 ) for generating n - best lists for IBM Model 4 .Learning to Translate : A Statistical and Computational Analysis .Received 15 July 2011 ; Accepted 30 January 2012 .", "label": "", "metadata": {}, "score": "46.403633"}
{"text": "Phrase - based MT can be traced back to Och 's alignment template model , which can be re - framed as a phrase translation system .Other researchers used augmented their systems with phrase translation , such as Yamada , who use phrase translation in a syntax - based model .", "label": "", "metadata": {}, "score": "46.72692"}
{"text": "Results show how the ngram - based approach outperforms the phrase - based approach by achieving similar accuracy scores in less computational time and with less memory needs .nce reordered .This procedure poses additional difficulties when applied to the ngram - based approach , because the characteristics of the ngram - based translation model . by Josep M. Crego , Adri\u00e0 De Gispert , Jos\u00e9 B. Mari\u00f1o - in Proc .", "label": "", "metadata": {}, "score": "46.801723"}
{"text": "Our first concerns were to distinguish between approximation and estimation error : the performance limitations due to the use of a limited language model versus those due to the need to estimate the parameters of that model from a finite sample .", "label": "", "metadata": {}, "score": "47.09601"}
{"text": "No exact numbers of tagging performance can be provided on these data sets since the data is not internally annotated with gene mentions .The above approach was taken by Morgan et al .[5 ] for the fly organism and their system achieved very promising results : 88 % precision and 61 % recall .", "label": "", "metadata": {}, "score": "47.334778"}
{"text": "This yields an efficient algorithm for obtaining the exact solution of each line search in Powell 's method and therefore provides a way to iteratively optimize the log - linear weights . using MERT .A number of alternatives have been proposed , such as on - line discriminative training [ 19 , 20 ] .", "label": "", "metadata": {}, "score": "47.634506"}
{"text": "We present first experimental results on single objects and on artificially generated scenes .Although the computational complexity of the approach is high , the additional effort seems justified and there is potential for reduction of complexity .Discussions .IBM 's software group is getting ready to release a Java development tool that claims it will ease the process of building custom business applications .", "label": "", "metadata": {}, "score": "47.712456"}
{"text": "While this does not allow us to simultaneously match different portions of the translation with different references , it supports the use of recall as a component in scoring each possible match .In the second case , we stem both translation and references prior to matching and then require identity on stems .", "label": "", "metadata": {}, "score": "48.208405"}
{"text": "See also the description by Zens ( 2002 ) .The alternative phrase - based methods differ in the way the phrase translation table is created , which we discuss in detail below .Model .The figure below illustrates the process of phrase - based translation .", "label": "", "metadata": {}, "score": "48.232513"}
{"text": "Some will be quick to point out that maximizing , for example , BLEU may neither be necessary for , nor guarantee good translation performance .Although we acknowledge that automatic MT metrics may not tell the whole story as far as translation quality is concerned , our systematic study aims at characterizing the behaviour of SMT systems that are built by maximizing such metrics .", "label": "", "metadata": {}, "score": "48.268154"}
{"text": "The approach takes into account the interdependence of several operations including recognition and transformation of the objects and segme ... \" .In this paper , we present a statistical framework for the recognition of multiple objects in an image , which is a generalization of the Bayesian decision rule .", "label": "", "metadata": {}, "score": "48.485252"}
{"text": "The approach takes into account the interdependence of several operations including recognition and transformation of the objects and segme ... \" .In this paper , we present a statistical framework for the recognition of multiple objects in an image , which is a generalization of the Bayesian decision rule .", "label": "", "metadata": {}, "score": "48.485252"}
{"text": "Although many language pairs would yield different translation performance , in this paper , we are not interested in the translation performance per se : we focus our attention on analyzing the SMT system as a learning system .Since our goal was to obtain high - accuracy learning curves , that can be trusted both for comparing different system settings and to extrapolate performance under unseen conditions , we conducted a large - scale series of tests , to reduce uncertainty in the estimations and to obtain the strongest possible signals .", "label": "", "metadata": {}, "score": "48.639797"}
{"text": "Proceedings of Sixth Conference on Natural Language Learning 2002 .Sha F , Pereira F : Shallow parsing with conditional random fields .Proceedings of HLT - NAACL 2003 , 213 - 220 .Tsuruoka Y , Tsujii J : Boosting Precision and Recall of Dictionary - Based Protein Name Recognition .", "label": "", "metadata": {}, "score": "48.857536"}
{"text": "We therefore reach the conclusion that estimating entries in the phrase translation tables is the dominant factor in determining performance .What controls the creation of phrase - translation tables ?This is mostly limited by Zipf 's law , since the probability of encountering phrases that have not been seen in the training set does not vanish even after observing very large corpora .", "label": "", "metadata": {}, "score": "49.120213"}
{"text": "The Significance of Recall in Automatic Metrics for MT Evaluation .DOI : 10.1007/978 - 3 - 540 - 30194 - 3_16 Conference : Machine Translation : From Real Users to Research , 6th Conference of the Association for Machine Translation in the Americas , AMTA 2004 , Washington , DC , USA , September 28-October 2 , 2004 , Proceedings .", "label": "", "metadata": {}, "score": "49.156036"}
{"text": "We also introduce a simple but effective heuristic method for speeding up the algorithms used to determine the model parameters .Note e.g. that the maximum likelihood estimation of class specific diagonal covariance matrices already imposes problems for the USPS data as in some of the classes some of the dimensions have zero ... . by", "label": "", "metadata": {}, "score": "49.511036"}
{"text": "We also introduce a simple but effective heuristic method for speeding up the algorithms used to determine the model parameters .Note e.g. that the maximum likelihood estimation of class specific diagonal covariance matrices already imposes problems for the USPS data as in some of the classes some of the dimensions have zero ... . by", "label": "", "metadata": {}, "score": "49.511036"}
{"text": "To further restrict the genes considered , a second stage of the pattern matching system produces , for each document , a set of candidate genes .Now , only genes that are present in the candidate list for a document and are also associated with an informative synonym in that document will be added to the document 's final list .", "label": "", "metadata": {}, "score": "49.572346"}
{"text": "[ 4 ] Background .Background .Statistical Machine Translation as a research area started in the late 1980s with the Candide project at IBM .IBM 's original approach maps individual words to words and allows for deletion and insertion of words .", "label": "", "metadata": {}, "score": "49.807465"}
{"text": "We swap them and we use the mod - ied source training corpora to realign and to build the nal translation system .We have evaluated our reordering ap - proach both in alignment and translation quality .In addition , we have used two state - of - the - art SMT systems : a Phrased - based and an Ngram - based .", "label": "", "metadata": {}, "score": "49.91458"}
{"text": "The first is primarily based on standard pattern matching and information extraction techniques .The second and more novel solution uses a statistical classifier to recognize valid gene matches from a list of known gene synonyms .Results .We compare the results of the two systems , analyze their merits and argue that the classification based system is preferable for many reasons including performance , simplicity and robustness .", "label": "", "metadata": {}, "score": "49.995636"}
{"text": "In any case , the addition of massive amounts of data from the same distribution will result in small improvements in the performance .The small error bars that we have obtained also allow us to regard the stability of the SMT when trained on the same training set size .", "label": "", "metadata": {}, "score": "50.001957"}
{"text": "There is some effort in building syntax - based models that either use real syntax trees generated by syntactic parsers , or tree transfer methods motivated by syntactic reordering patterns .The phrase - based statistical machine translation model we present here was defined by Koehn et al .", "label": "", "metadata": {}, "score": "50.142975"}
{"text": "Since the entire phrase translation table may be too big to fit into memory , we can restrict ourselves to these translation options to overcome such computational concerns .We may even generate a phrase translation table on demand that only includes valid translation options for a given input text .", "label": "", "metadata": {}, "score": "50.171402"}
{"text": "We show that signican tly better correlations can be achieved by placing more weight on recall than on precision .While this may seem unexpected , since BLEU and NIST focus on n - gram precision and disregard recall , our experiments show that correlation with human judgments is highest when almost all of the weight is assigned to recall .", "label": "", "metadata": {}, "score": "50.39324"}
{"text": "If we intersect the two alignments , we get a high - precision alignment of high - confidence alignment points .If we take the union of the two alignments , we get a high - recall alignment with additional alignment points .", "label": "", "metadata": {}, "score": "50.47586"}
{"text": "The training data is noisy , but experiments run by Morgan et al .show the trained tagger to perform at a reasonable level .Another seemingly straightforward approach is to treat the problem as multi - class document classification .Here , each normalized gene form is a possible class and the goal is to label each document with a set of classes ( genes ) .", "label": "", "metadata": {}, "score": "50.5235"}
{"text": "We also believe that in this particular situation , the presence of the error bars may help to better understand the stability of the system .Using the framework described above , four different settings have been set to produce learning curves , see Table 3 .", "label": "", "metadata": {}, "score": "50.54463"}
{"text": "Full - text preview . cmu.edu Abstract .Recent research has shown that a balanced harmonic mean ( F1 measure ) of unigram precision and recall outperforms the widely used BLEU and NIST metrics for Machine Translation evaluation in terms of correlation with human judgments of translation quality .", "label": "", "metadata": {}, "score": "50.724277"}
{"text": "Note that this approach is consistent with the approach taken by Marcu and Wong themselves , who use conditional models during decoding .Och and Ney .Och and Ney ( Computational Linguistics , 2003 ) propose a heuristic approach to refine the alignments obtained from GIZA++ .", "label": "", "metadata": {}, "score": "50.95527"}
{"text": "The second concern was to distinguish between the role of the numerical and lexical parts in the language and translation models .Various perturbation experiments show that the accuracy in estimating the numerical parameters is not a crucial aspect of performance , while the estimation of the lexical parts of the tables is a major factor in determining performance .", "label": "", "metadata": {}, "score": "51.123856"}
{"text": "The difficulty with such an approach is that the matching algorithm would be potentially less efficient , with a naive O ( n 2 ) implementation being totally impractical for this task .However , approximate string matching techniques as developed in computational biology might be useful here .", "label": "", "metadata": {}, "score": "51.25329"}
{"text": "Currently our matching criteria extracts as low as 79 % of all good matches , which bounds the recall of the system .We are experimenting with different string distance metrics proposed by Cohen et al .[ 7 ] to try and raise the number of good matches returned .", "label": "", "metadata": {}, "score": "51.26689"}
{"text": "Then , additional features are used to rescore these translations .An n - best list is one way to represent multiple candidate translations .Such a set of possible translations can also be represented by word graphs ( Ueffing et al . , EMNLP 2002 ) or forest structures over parse trees ( Langkilde , EACL 2002 ) .", "label": "", "metadata": {}, "score": "51.33615"}
{"text": "The main concern is the exponential explosion from the 2 n f possible configurations of foreign words covered by a hypothesis .Note this causes the problem of machine translation to become NP - complete ( Knight , Computational Linguistics , 1999 ) and thus dramatically harder than , for instance , speech recognition .", "label": "", "metadata": {}, "score": "51.38868"}
{"text": "In practice this trade - off is easily observed , by noticing how the training error can be driven to zero by using a rich hypothesis class , which typically results into overfitting and increased test error .In the context of statistical machine translation ( SMT ) , where large bilingual corpora are used to train adaptive software to translate text , this task is further complicated by the peculiar distribution underlying the data , where the probability of encountering new words or expressions never vanishes .", "label": "", "metadata": {}, "score": "51.42823"}
{"text": "In this paper , we present a comparison between the widely used BLEU and NIST metrics , and a set of easily computable metrics based on unigram precision and recall .Using several empirical evaluation methods that have been proposed .Page 2 . in the recent literature as concrete means to assess the level of correlation of au- tomatic metrics and human judgments , we show that higher correlations can be obtained with fairly simple and straightforward metrics .", "label": "", "metadata": {}, "score": "51.544544"}
{"text": "We could base the judgment of what inferior hypotheses are on the cost of each hypothesis so far .However , this is generally a very bad criterion , since it biases the search to first translating the easy part of the sentence .", "label": "", "metadata": {}, "score": "51.566055"}
{"text": "Any way to enforce linguistic constraints might result in a reduced need for data , and ultimately in more complete models , given the same corpus [ 34 ] .Neither approach would change the statistical nature of the system , but they would help it bypass the phrase acquisition bottleneck .", "label": "", "metadata": {}, "score": "51.740356"}
{"text": "This is useful because the language model feature typically favours shorter sentences ( because each additional trigram can only lower the language model probability ) .This is a simple , yet effective feature .The process of training a machine translation system involves estimating the various parameters of the model : the log - linear parameters . as well as the parameters internal to the feature functions , such as the phrase translation probabilities and language model n -gram and backoff probabilities .", "label": "", "metadata": {}, "score": "51.741066"}
{"text": "Afterwards , we classify these pairs into groups , following recursively a co - occurrence block criterion , in order to infer reorderings .Inside the same group , we allow new internal combination in or - der to generalize the reorder to unseen pairs of blocks .", "label": "", "metadata": {}, "score": "51.824104"}
{"text": "It is important to notice , however , that introducing a more aggressive type of noise ( Figure 7(b ) ) that essentially replaces entire parameters with random values does lead to a more significant decline in performance .This was obtained by swapping random entries , and so after 100 percent of swaps essentially every entry is a random number ( because the locations to swap are chosen with replacement ) .", "label": "", "metadata": {}, "score": "51.901787"}
{"text": "The complexity of the system is also a problem .Data is transformed in many stages : stemming , creating the informative synonym list , creating the neighbor list and finally matching the synonyms to the text .As with all pipelined systems , this may lead to cascading errors in which an error early in the pipeline will cause errors to be made at later stages .", "label": "", "metadata": {}, "score": "51.922142"}
{"text": "Unfortunately , current estimation procedures are unable to reach such high - performing regions of the parameter space .This was also noted by a recent paper by Wisniewski et al . who note that \" the current bottleneck of translation performances is not the representation power of the [ phrase - based translation systems ] but rather in their scoring functions '' [ 38 ] .", "label": "", "metadata": {}, "score": "51.944054"}
{"text": "Core Algorithm .The phrase - based decoder we developed employs a beam search algorithm , similar to the one used by Jelinek ( book \" Statistical Methods for Speech Recognition \" , 1998 ) for speech recognition .The English output sentence is generated left to right in form of hypotheses .", "label": "", "metadata": {}, "score": "51.955597"}
{"text": "This unrealistic case is not affected by the Zipf 's law , because almost all the words necessary to translate the training material have , by definition , already been observed .The model is therefore able to match long phrases when producing the \" test on training set ' ' translations .", "label": "", "metadata": {}, "score": "52.07914"}
{"text": "We investigate the learning - theoretic implications of this setting , including the interplay between approximation error and estimation error , model selection , and accuracy in parameters estimation .We do not address more general themes about the opportunity for SMT to be evaluated by automatic metrics .", "label": "", "metadata": {}, "score": "52.08055"}
{"text": "It 's helpful to have a single number to easily compare performance .Precision and recall and the F1 statistic can help when trying to classify very skewed classes , where one class is rare in the data .Simply taking a percentage of correct classifications can be misleading , since always guessing the more common class means you 'll almost always be right .", "label": "", "metadata": {}, "score": "52.205612"}
{"text": "The unfolding technique produces a different bilingual n - gram language model with reordered source words .Figure 1 : ... .Therefore , all models are combined in search and a single best hypothesis is output .4.2.4 Optimisation procedure Minimum - error training states that we can directly train our models according the an errorminimisation function on a certain development data , as discussed in \u00a7 2.4.1 .", "label": "", "metadata": {}, "score": "52.259975"}
{"text": "The decoder implements a beam search and is roughly similar to work by Tillmann ( PhD , 2001 ) and Och ( PhD , 2002 ) .In fact , by reframing Och 's alignment template model as a phrase translation model , the decoder is also suitable for his model , as well as other recently proposed phrase models .", "label": "", "metadata": {}, "score": "52.380905"}
{"text": "When extracting longer phrases , we expect training set performance to be higher , but test performance to drop ( overfitting ) .Optimizing test performance requires the right trade - off .In this section , we analyze how the phrase length can affect the performance in terms of BLEU score .", "label": "", "metadata": {}, "score": "52.439575"}
{"text": "The first uses an HMM gene tagger to find mentions of genes in text .The second step looks for matches of each mention to a known synonym while carefully filtering those matches on highly ambiguous or unreliable synonyms .The primary reason that this approach worked for Morgan et al . is that they were able to create a training set specific to fly for identifying gene mentions .", "label": "", "metadata": {}, "score": "52.542145"}
{"text": "As this is an enormous search space , it is no wonder that both algorithmic and statistical challenges are encountered when training these systems .From a statistical learning point of view , this raises interesting questions : How much of the overall error of the translation system is due to representation limitations , and how much to the difficulty of extracting suitable Translation and Language model tables from a finite sample ?", "label": "", "metadata": {}, "score": "52.722847"}
{"text": "Clearly , all measures correlate strongly with each other , such that the choice of the performance measure is fairly arbitrary , as long as one is consistent .For this reason , we have chosen to use BLEU throughout this paper as it is the most widely used automatic score in machine translation .", "label": "", "metadata": {}, "score": "52.852768"}
{"text": "Recall that for excluding hypotheses from the beam we do not only have to consider the cost so far , but also an estimate of the future cost .While it is possible to calculate the cheapest possible future cost for each hypothesis , this is computationally so expensive that it would defeat the purpose of the beam search .", "label": "", "metadata": {}, "score": "52.87481"}
{"text": "One of our key findings is that the current performance of phrase - based statistical machine translation systems is not limited by the representation power of the hypothesis class , but rather by model estimation from data .In other words , we demonstrate that parameter choices exist that can deliver significantly higher performance , but that inferring them from finite samples is the problem .", "label": "", "metadata": {}, "score": "52.899216"}
{"text": "Similarily there is JSR 207 called \" Process Definition for Java \" ( PD4J ) which defines a standard for a Java based process definition language and there is a long list of other Portal standards as well ( JSR 94 , 127 , 168 etc . ) .", "label": "", "metadata": {}, "score": "53.20736"}
{"text": "263 - 311 , 1994 .View at Google Scholar .P. Koehn , F. J. Och , and D. Marcu , \" Statistical phrase - based translation , \" in Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology , pp .", "label": "", "metadata": {}, "score": "53.21507"}
{"text": "The high performance observed in the train - on - test conditions shows that there exists at least one choice of tunable parameters with which the phrase - based translation system can deliver much higher performance .This is useful to bound the space of \" possible performances , ' ' although in ideal situations .", "label": "", "metadata": {}, "score": "53.444916"}
{"text": "Recently , research in the field of content - based image retrieval has attracted a lot of attention .Nevertheless , most existing methods can not be easily applied to medical image databases , as global image descriptions based on color , texture , or shape do not supply sufficient semantics for medical applications .", "label": "", "metadata": {}, "score": "53.447956"}
{"text": "R. Zens , F.-J. Och , and H. Ney , \" Phrase - based statistical machine translation , \" in Proceedings of the 25th Annual German Conference on AI ( KI ' 02 ) , pp .18 - 32 , Springer , London , UK , 2002 .", "label": "", "metadata": {}, "score": "53.4888"}
{"text": "Consider a system in which every time a synonym had a text based match with a document the system also labeled that document with that synonyms normal form .The inspiration for our second model comes from the observation that this kind of liberal pattern matching can achieve a very high recall ( 91 % , 79 % and 90 % for fly , mouse and yeast on the development data ) .", "label": "", "metadata": {}, "score": "53.706577"}
{"text": "Higher values of \u03b4 result in higher precision at the expense of recall and lower values of \u03b4 result in higher recall at the expense of precision .Table 2 .Performance of pattern matching system on development data .Precision and recall numbers for pattern matching system using : A ) Simple direct matching of synonyms to text .", "label": "", "metadata": {}, "score": "53.8293"}
{"text": "In other words , the essential limiting factor for phrase - based SMT systems seems to be the Zipf law found in natural language .Our large - scale analysis also suggests that the current bottleneck of the phrase - based SMT approach is the lack of sufficient data , not the function class used for the representation of translation systems .", "label": "", "metadata": {}, "score": "53.895317"}
{"text": "Work on this problem has been done by Yu and Agichtein [ 15 ] .However , the results of their system are below 50 % F1 measure and may not yet be usable in practical applications such as gene normalization .", "label": "", "metadata": {}, "score": "54.019756"}
{"text": "However , preliminary experiments on the development data suggested that additional context had a negligible effect on accuracy and only served to increase the time it took to train the model .Another potential improvement would be to relax the criteria when extracting matches .", "label": "", "metadata": {}, "score": "54.19729"}
{"text": "When people start learning J2SE , J2EE getting past the semantics of coding and concepts the enormous amount of add - on's / frameworks / patterns / os projects is out of control .I just read through an Accenture J2EE architecture that nearly relies upon all open source products .", "label": "", "metadata": {}, "score": "54.241142"}
{"text": "If the future cost estimates are inadequate , we may prune out hypotheses on the path to the best scoring translation .Using best - first search and an admissible heuristic allows pruning that is risk - free .In practice , however , this type of pruning does not sufficiently reduce the search space .", "label": "", "metadata": {}, "score": "54.336014"}
{"text": "Nevertheless , most existing methods can not be easily applied to medical image databases , as global image descriptions based on color , texture , or shape do not supply sufficient semantics for medical ap ... \" .Recently , research in the field of content - based image retrieval has attracted a lot of attention .", "label": "", "metadata": {}, "score": "54.465645"}
{"text": "Several other automatic metrics for MT evaluation have been proposed since the early 1990s .The utility and attractiveness of automatic metrics for MT evaluation has been widely recognized by the MT community .Evaluating an MT system using such automatic metrics is much faster , easier and cheaper compared to human evaluations , which require trained bilingual evaluators .", "label": "", "metadata": {}, "score": "54.495384"}
{"text": "Differing provisions from the publisher 's actual policy or licence agreement may be applicable .\" Their experiment also revealed that the enhancement of both BLEU and NIST is correlated to human evaluation .To overcome the weaknesses of the above mentioned metrics , a new metric was proposed by Lavie et al .", "label": "", "metadata": {}, "score": "54.64193"}
{"text": "\" Ideally we would like to be able to build a portal on one portal server and move it to another .Or build a generic business process on one process engine and move it to another .\" This is possible today .", "label": "", "metadata": {}, "score": "54.76609"}
{"text": "Sometimes its easier to just redo parts from scratch .One of the great promises of OO is reusability , but these kind of tools tend to shoot it right out of the water .Any \" productivity \" gains are quickly eaten up by costs in subsequent projects for further development and new functionality , debugging for trivial bugs and just plain - old change - requests that ALWAYS will turn up during a project if the customer cares the least bit .", "label": "", "metadata": {}, "score": "54.79727"}
{"text": "At this point , most competitive statistical machine translation systems use phrase translation , such as the CMU , IBM , ISI , and Google systems , to name just a few .Phrase - based systems came out ahead at a recent international machine translation competition ( DARPA TIDES Machine Translation Evaluation 2003 - 2006 on Chinese - English and Arabic - English ) .", "label": "", "metadata": {}, "score": "54.902046"}
{"text": "[ 1 ] In particular , the value of the coefficient of determination will shrink relative to the original training data .In order to avoid overfitting , it is necessary to use additional techniques ( e.g. cross - validation , regularization , early stopping , pruning , Bayesian priors on parameters or model comparison ) , that can indicate when further training is not resulting in better generalization .", "label": "", "metadata": {}, "score": "54.93283"}
{"text": "Small test set sizes produce a big variance in BLEU score .When increasing the test set size , the error bars tend to reduce .using two different test sets of the same size depend on the test set choice and not on different techniques .", "label": "", "metadata": {}, "score": "54.938038"}
{"text": "Presentation at DARPA / TIDES 2003 MT Workshop .NIST , Gathersberg , MD .July 2003 .Bo Pang , Kevin Knight and Daniel Marcu .Syntax - based Alignment of Multiple Translations : Extracting Paraphrases and Generating New Sentences .", "label": "", "metadata": {}, "score": "55.00548"}
{"text": "Sure enough you can generate XMI but to get that exported and imported in another tool with all information , annotation , implementation and layout preserved : Good Luck .Now that is what I call vendor lock in .Porting a million lines of code is probably a lot easier than porting a thousand diagrams .", "label": "", "metadata": {}, "score": "55.050915"}
{"text": "It requires other IDE like WSAD for debugging purpose .I believe it is good for developing considerably a small project with a team of maximum 3 or 4 people and with core JSP / Servlets .Any custom libraries / frameworks if used in the development will be difficult to maintain .", "label": "", "metadata": {}, "score": "55.08525"}
{"text": "F. J. Och and H. Weber , \" Improving statistical natural language translation with categories and rules , \" in Proceedings of the 17th International Conference on Computational Linguistics , vol .2 , pp .985 - 989 , Stroudsburg , Pa , USA , 1998 .", "label": "", "metadata": {}, "score": "55.115997"}
{"text": "Statistics on the phrase pair are accumulated over the entire corpus .In our experiments below , we rely on word - to - word IBM models [ 2 ] for alignment .Although more elaborate techniques have appeared more recently [ 13 , 14 ] , their impact on the resulting machine translation quality is still unclear [ 15 ] .", "label": "", "metadata": {}, "score": "55.28781"}
{"text": "One way to achieve this could be to either introduce an oracle to which the system can ask for annotation when needed or a process that uses linguistic knowledge to create new table entries based on existing table entries and some grammatical rules .", "label": "", "metadata": {}, "score": "55.40767"}
{"text": "IBM 's proposed approach to development using this tool resembles an MDA - based one - they call it \" architected RAD , \" or architected rapid application development .In some respects , IBM seems to be positioning it as IBM J2EE For Dummies .", "label": "", "metadata": {}, "score": "55.426598"}
{"text": "However , the difference in word order between two languages is one of the most important sources of errors in SMT .In this paper , we show that SMT can take advantatge of in - ductive learning in order to solve reorder - ing problems .", "label": "", "metadata": {}, "score": "55.525818"}
{"text": "f . )No smoothing is performed , although lexical weighting addresses the problem of sparse data .For more details , see our paper on phrase - based translation ( Koehn at al , HLT - NAACL 2003 ) .Tillmann .", "label": "", "metadata": {}, "score": "55.599167"}
{"text": "The extended graph is traversed in decoding when a fullyinformed decision can be taken ( no preprocessing decision about reordering is taken ) .We also show how the N - gram translation model can be successfully used as reordering model when estimated with reordered source words ( to harmonize the source and target word order ) .", "label": "", "metadata": {}, "score": "55.61028"}
{"text": "Development and test sets are fixed .One instance of the SMT system has been run for each of all possible combinations of the language and translation training data sizes .BLEU score value has been associated to each pair : language and translation set size .", "label": "", "metadata": {}, "score": "55.655952"}
{"text": "The performance of the classifier is evaluated using a set of 1617 radiographs from daily routine , where the error rate of 8.0 % in this six - class problem is an excellent result , taking into account the difficulty of the task .", "label": "", "metadata": {}, "score": "55.702045"}
{"text": "Traditional approaches to machine translation ( MT ) [ 1 ] relied to a large extent on linguistic analysis .The ( relatively ) recent development of statistical approaches [ 2 ] and especially phrase - based machine translation , or PBMT [ 3 , 4 ] , has put the focus on the intensive use of large parallel corpora .", "label": "", "metadata": {}, "score": "55.743073"}
{"text": "This does not mean that a pattern matching approach is useless , our first system relies heavily on standard techniques .However , we do not assume that every synonym in the list reliably labels documents with their normalized gene mentions .", "label": "", "metadata": {}, "score": "55.752106"}
{"text": "The two systems we present here primarily focus on the second problem : identifying the unique gene that has been mentioned .This includes identifying whether some mention is erroneous .In general the systems treat the given synonym lists as complete , with some tolerance for punctuation and orthographic differences .", "label": "", "metadata": {}, "score": "55.83667"}
{"text": "Zhang et al .( 2003 ) proposes a phrase alignment method that is based on word alignments and tries to find a unique segmentation of the sentence pair , as it is done by Marcu and Wong directly .This enables them to estimate joint probability distributions , which can be marginalized into conditional probability distributions .", "label": "", "metadata": {}, "score": "55.83711"}
{"text": "We only add new alignment points that exist in the union of two word alignments .We also always require that a new alignment point connects at least one previously unaligned word .First , we expand to only directly adjacent alignment points .", "label": "", "metadata": {}, "score": "55.974617"}
{"text": "The study has been carried out on two different translation tasks ( in terms of translation difficulty and amount of available training data ) , and allowing for distortion ( reordering ) in the decoding process .Thus it extends a previous work were both approaches were compared under monotone conditions .", "label": "", "metadata": {}, "score": "56.067383"}
{"text": "Use a learning algorithm with many parameters and many features - low bias .Get a very large training set .Tools . by Josep M. Crego , Marta R. Costa - juss\u00e0 , Jos\u00e9 B. Mari\u00f1o , Jos\u00e9 A. R. Fonollosa - In Proceedings of the International Workshop on Spoken Language Technology ( IWSLT'05 , 2005 . \" ...", "label": "", "metadata": {}, "score": "56.068726"}
{"text": "The first statistical models were word based [ 2 , 11 ] , combining a Markovian language model with a generative word - to - word translation model , in a noisy channel model inspired by speech recognition research .Current state - of - the - art SMT uses phrase - based models , which generalized and superseded word - based models .", "label": "", "metadata": {}, "score": "56.21624"}
{"text": "Comparing Tables 3 and 4 , we see that maximum entropy classification does just as well or better than the pattern matching system .A primary advantage of maximum entropy classification over pattern matching is that the system is uniform across organisms , hence the method is more likely to perform well when extended to different organisms .", "label": "", "metadata": {}, "score": "56.22435"}
{"text": "On the other hand , a classifier based on local representations admits the distortion of parts of the image . ... by Daniel Keysers , Franz Josef Och , Hermann Ney , Supervisor Prof , Dr. -ing H. Ney - Proc .", "label": "", "metadata": {}, "score": "56.421177"}
{"text": "On the other hand , a classifier based on local representations admits the distortion of parts of the image . ... by Daniel Keysers , Franz Josef Och , Hermann Ney , Supervisor Prof , Dr. -ing H. Ney - Proc .", "label": "", "metadata": {}, "score": "56.421177"}
{"text": "Porting a million lines of code is probably a lot easier than porting a thousand diagrams .Of course diagrams and processes are great and much needed ( BTW , I still think conceptually , OPEN was far ahead of RUP but had much worse marketing , and maybe , tool support ) .", "label": "", "metadata": {}, "score": "56.50685"}
{"text": "First , we use chunks to refine the set of word alignments typically used as a starting point in SMT systems .Second , we extend an N - grambased SMT system with chunk tags to better account for long - distance reorderings .", "label": "", "metadata": {}, "score": "56.543396"}
{"text": "First , we use chunks to refine the set of word alignments typically used as a starting point in SMT systems .Second , we extend an N - grambased SMT system with chunk tags to better account for long - distance reorderings .", "label": "", "metadata": {}, "score": "56.543396"}
{"text": "This is done iteratively until no alignment point can be added anymore .In a final step , we add non - adjacent alignment points , with otherwise the same requirements .We collect all aligned phrase pairs that are consistent with the word alignment : The words in a legal phrase pair are only aligned to each other , and not to words outside .", "label": "", "metadata": {}, "score": "56.771797"}
{"text": "This could greatly improve performance , particularly for synonym matches not seen in training .If the system matches have a feature indicating that a synonym is trustworthy it could provide evidence to classify the match as valid .Currently , the model 's features are based primarily on textual matching and contain no domain specific information .", "label": "", "metadata": {}, "score": "56.789024"}
{"text": "This setting has been applied to Europarl and Giga corpus datasets using Moses as SMT system . vary across the datasets and correspond to an increase of 1.3 to 1.5 BLEU point for the LM and 1.8 to 1.9 for the TM , for each doubling of the data .", "label": "", "metadata": {}, "score": "56.866077"}
{"text": "Error analysis .To improve performance of a machine learning algorithm , one helpful step is to manually examine the cases your algorithm gets wrong .Look for systematic trends in the errors .What features would have helped correctly classify these cases ?", "label": "", "metadata": {}, "score": "56.87056"}
{"text": "The search will prefer to start the sentence with the easy part and discount alternatives too early .So , our measure for pruning out hypotheses in our beam search does not only include the cost so far , but also an estimate of the future cost .", "label": "", "metadata": {}, "score": "56.882057"}
{"text": "Tools . by Daniel Keysers , J\u00f6rg Dahmen , Hermann Ney , Berthold B. Wein , Thomas M. Lehmann , 2003 . \" ...Recently , research in the field of content - based image retrieval has attracted a lot of attention .", "label": "", "metadata": {}, "score": "57.005722"}
{"text": "We will later analyze the contribution of each component to the overall score .The typical processing pipeline is as follows .Given a parallel training corpus , long sentences are filtered out , and the remaining material is lowercased and tokenized .", "label": "", "metadata": {}, "score": "57.011833"}
{"text": "Although the rate of improvement may depend on both the data and the estimation method , it is unlikely that the general shape of the learning curve will change without major changes in the modeling and inference phases .Possible research directions that address this issue include the integration of linguistic rules or the development of active learning procedures .", "label": "", "metadata": {}, "score": "57.048836"}
{"text": "We present an extensive experimental study of Phrase - based Statistical Machine Translation , from the point of view of its learning capabilities .Very accurate Learning Curves are obtained , using high - performance computing , and extrapolations of the projected performance of the system under different conditions are provided .", "label": "", "metadata": {}, "score": "57.08201"}
{"text": "They contain different modules to preprocess data and train the language models and the translation models .These models can be tuned using minimum error rate training [ 17 ] .Both use standard external tools for training the language model , such as SRILM [ 23 ] , and Moses also uses GIZA++ [ 24 ] for word alignments .", "label": "", "metadata": {}, "score": "57.105133"}
{"text": "Actually , these tools do n't even support the UML standard very well .I have used UML successfully as a simple design notation , but neither it nor any UML tool out there has actually helped me design better software .", "label": "", "metadata": {}, "score": "57.12133"}
{"text": "It is extremely non - reusable and is on a larger scale full of design - flaws .Ever tried to build new functionality and expand a system that is hardcoded for a particular implementation and full of the simplest design - flaws ?", "label": "", "metadata": {}, "score": "57.157856"}
{"text": "Using long phrases will help when the system has to translate sequences of words that match what was encountered in the training corpus , but this becomes increasingly unlikely as the phrases become longer .On the other hand , short sentences are more often reused , but may also be more ambiguous and lead to errors more often .", "label": "", "metadata": {}, "score": "57.222496"}
{"text": "One way to combat this problem is to use a simpler model .This is valid , but might be limiting .Another option is regularization , which penalizes large parameter values .This prioritizes solutions fitting the training data reasonably well without curving around wildly .", "label": "", "metadata": {}, "score": "57.352966"}
{"text": "Does the performance improve with more data because certain parameters are estimated better , or just because the lists are growing ?In the second case , it is likely that more sophisticated statistical algorithms to improve the estimation of probabilities will have limited impact .", "label": "", "metadata": {}, "score": "57.55191"}
{"text": "This is due to a match extraction error that was discovered and resolved after the official results were submitted .A quick glance at the results show that maximum entropy classification does as well or better than pattern matching for all organisms without the need for organism specific optimizations .", "label": "", "metadata": {}, "score": "57.620747"}
{"text": "Computing products , ratios , differences or logarithms may be informative .Creativity comes in here , but remember to test the effectiveness of your new features on the cross - validation set .Features are on different scales may benefit from feature scaling .", "label": "", "metadata": {}, "score": "57.645702"}
{"text": ".. ...[ 8].which is independent of the tangent vectors and can therefore be neglected in the following maximum likelihood estimation .3.2 Estima ... . \" ...Statistical classification using tangent vectors and classification based on local features are two successful methods for various image recognition problems .", "label": "", "metadata": {}, "score": "57.714058"}
{"text": "Our results suggest that performance , as measured by BLEU , increases by a constant factor for each doubling of the data .Although that factor varies depending on corpus and language pair , this result seems consistent over all experimental conditions we tried .", "label": "", "metadata": {}, "score": "57.781258"}
{"text": "When describing the phrase - based translation model so far , we did not discuss how to obtain the model parameters , especially the phrase probability translation table that maps foreign phrases to English phrases .Most recently published methods on extracting a phrase translation table from a parallel corpus start with a word alignment .", "label": "", "metadata": {}, "score": "57.920734"}
{"text": "This paper addresses the problem of reordering in statistical machine translation ( SMT ) .We describe an elegant and efficient approach to couple reordering ( word order monotonization ) and decoding , which does not need for any additional model .", "label": "", "metadata": {}, "score": "57.957855"}
{"text": "This paper addresses the problem of reordering in statistical machine translation ( SMT ) .We describe an elegant and efficient approach to couple reordering ( word order monotonization ) and decoding , which does not need for any additional model .", "label": "", "metadata": {}, "score": "57.957855"}
{"text": "The openness of Java is great but were making it too difficult ourselves , everyday it 's a new tool to make this or that better .I ca n't recall how much time I wasted trying to determine a decent mvc framework and then it 's what persistence framework should I use and will it integrate ?", "label": "", "metadata": {}, "score": "58.035496"}
{"text": "Results on Chinese - to - English and Arabic - to - English tracks using supplied data are reported . ... rdered search , which is guided by the N - gram model of the unfolded tuples and the additional feature models .", "label": "", "metadata": {}, "score": "58.052963"}
{"text": "Also note that if the foreign words not covered so far are two ( or more ) disconnected sequences of foreign words , the combined cost is simply the product of the costs for each contiguous sequence .Since there are only n(n+1)/2 contiguous sequences for n words , the future cost estimates for these sequences can be easily precomputed and cached for each input sentence .", "label": "", "metadata": {}, "score": "58.109627"}
{"text": "What is the best function class to map Spanish documents into English documents ?This is a question of linguistic nature and has been the subject of a long debate .With the growing availability of bilingual parallel corpora , the 1990 s saw the development of statistical machine translation ( SMT ) models .", "label": "", "metadata": {}, "score": "58.233112"}
{"text": "TMs were limited to a phrase length of 7 words , and LMs were limited to 3 .Hardware .All the experiments have been run on high - performance clusters of machines .Additional information : ClearSpeed accelerator boards on the thick nodes ; SilverStorm Infiniband high - speed connectivity throughout for parallel code message passing ; General Parallel File System ( GPFS ) providing data access from all the nodes with a total of 11 terabytes of storage .", "label": "", "metadata": {}, "score": "58.237835"}
{"text": "Yet for real sound UML you have to go with Rational , STP ( whoever owns this now ) or maybe TogetherSoft ( now Borland , I believe ) .Sure enough you can generate XMI but to get that exported and imported in another tool with all information , annotation , implementation and layout preserved : Good Luck .", "label": "", "metadata": {}, "score": "58.587242"}
{"text": "The statistical classifier for the anatomic region is based on Gaussian kernel densities within a probabilistic framework for multiobject recognition .Special emphasis is placed on invariance , employing a probabilistic model of variability based on tangent distance and an image distortion model .", "label": "", "metadata": {}, "score": "58.6295"}
{"text": "The concept of METEOR is rather different from that of the above metrics in that all the other metrics relied on unigram precision ( the two SL and TL identical word strings ) only , while METEOR gives more weight to unigram precision and unigram recall .", "label": "", "metadata": {}, "score": "58.65546"}
{"text": "XMI has been a complete failure from a portability perspective .Trying to take an XMI file from one UML tool to another almost always fails .In fact , some tools ( I wo n't mention any names ) ca n't even import what they exported !", "label": "", "metadata": {}, "score": "58.660507"}
{"text": "New Orleans , LA .Sept. 2003 .pp .240 - 247 .I. Dan Melamed , R. Green and J. Turian .Precision and Recall of Machine Translation .In Proceedings of HLT - NAACL 2003 .Edmonton , Canada .", "label": "", "metadata": {}, "score": "58.77211"}
{"text": "The training part is used to obtain the language model and phrase tables .The development set is used to estimate the log - linear weights . using MERT , and the test set is set aside during the estimation process in order to provide an unbiased estimate of the translation performance .", "label": "", "metadata": {}, "score": "58.810204"}
{"text": "Our experiments and their results are described in section 4 .Future directions and extensions of this work are discussed in section 5 . 2 Evaluation Metrics The metrics used in our evaluations , in addition to BLEU and NIST , are based on explicit word - to - word matches between the translation being evaluated and each of one or more reference translations .", "label": "", "metadata": {}, "score": "58.87189"}
{"text": "The most obvious of which is to include more expert knowledge into the model .Maximum entropy models are widely used since they easily allow for the integration of such expert knowledge through the definition of new features .For extracting gene mentions from text , these features generally take the form of lexical resources and indicative regular expressions [ 2 ] .", "label": "", "metadata": {}, "score": "59.10798"}
{"text": "Background .Recently , researchers have begun to apply machine - learning - based information extraction techniques to biomedical text , most notably to identify gene and chemical compound mentions [ 1 - 3 ] .A related problem is gene normalization , which involves annotating a document ( or abstract ) with the list of identifiers for genes mentioned in the document .", "label": "", "metadata": {}, "score": "59.146683"}
{"text": "295 - 302 , Philadelphia , Pa , USA , 2001 .R. C. Moore , W.-T. Yih , and A. Bode , \" Improved discriminative bilingual word alignment , \" in Proceedings of the 21stInternational Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics ( ACL ' 06 ) , pp .", "label": "", "metadata": {}, "score": "59.16716"}
{"text": "The first system presented relies on a series of pattern matching techniques to find and filter synonym string matches .The second system extracts all possible synonym matches and uses a binary classifier to determine which are valid .Initial directions .", "label": "", "metadata": {}, "score": "59.30154"}
{"text": "In Section 3.4 , we report the correlation coefficient between all the measures .Each correlation coefficient is computed using the results of the 160 experiments described above .Acknowledgments .This work is supported by the EU IST Project SMART ( FP6 - 033917 ) .", "label": "", "metadata": {}, "score": "59.41044"}
{"text": "Authors ' Affiliations .Department of Computer and Information Science , University of Pennsylvania , Levine Hall .References .Kazama J , Makino T , Ohta Y , Tsujii J : Tuning Support Vector Machines for Biomedical Named Entity Recognition .", "label": "", "metadata": {}, "score": "59.545074"}
{"text": "They are automatically filled during the training phase , when a bilingual corpus is used to identify both phrases and their probabilities .Since future translations are produced by maximizing a scoring function estimating translation quality , using the content of the two tables , we see that the contents of the translation and language models tables correspond to the tunable parameters of the learning system .", "label": "", "metadata": {}, "score": "59.575123"}
{"text": "We then introduce the concept of comparable states that allow us to define a beam of good hypotheses and prune out hypotheses that fall out of this beam .In a later section , we will describe how to generate an ( approximate ) n - best list .", "label": "", "metadata": {}, "score": "59.60369"}
{"text": "This is because the rate of improvement of translation performance is at best logarithmic with the training set size .We estimate that bridging the gap between training and test error would require about .paired bilingual sentences , which is larger than the current estimated size of the web .", "label": "", "metadata": {}, "score": "59.72735"}
{"text": "Most commercial systems use transfer rules and a rich translation lexicon .Machine translation research was focused on transfer - based systems in the 1980s and on knowledge based systems that use an interlingua representation as an intermediate step between input and output in the 1990s .", "label": "", "metadata": {}, "score": "59.843185"}
{"text": "On the other hand , optimization is really expensive in terms of computational cost .In Figure 9 , it increases roughly linearly with the development set size .It is nice to note how the computational time is strongly related to the number of optimization steps in Figure 10 . A.2 .", "label": "", "metadata": {}, "score": "59.85188"}
{"text": "McDonald R , Pereira F : Identifying gene mentions in text using conditional random fields .BMC Bioinformatics 2005 , 6 ( Suppl 1 ) : S6 .View Article PubMed .Narayanaswamy M , Ravikumar KE , Vijay - Shanker K : A Biological Named Entity Recognizer .", "label": "", "metadata": {}, "score": "59.920204"}
{"text": "The other aspect is the diversity of the frameworks .We recently had a look at the open source Workflow engines / frameworks and believe me , there is a lot of them out there !So , which one is going to become a standard ( if any ) ?", "label": "", "metadata": {}, "score": "60.058933"}
{"text": "In Figure 8 , BLEU score as function of the development size is reported .The optimization procedure increases the quality of the translations .This improvement does not seem to be significant after a certain size of the development set .", "label": "", "metadata": {}, "score": "60.18091"}
{"text": "F. J. Och , \" Minimum error rate training in statistical machine translation , \" in Proceedings of the 41st Annual Meeting on Association for Computational Linguistics , pp .160 - 167 , Sapporo , Japan , 2003 .W. H. Press , S. A. Teukolsky , W. T. Vetterling , and B. P. Flannery , Numerical Recipes in C++ , Cambridge University Press , Cambridge , Mass , USA , 2002 . A. Arun and P. Koehn , \" Online learning methods for discriminative training of phrase based statistical machine translation , \" in Proceedings of 11th the Machine Translation Summit , Copenhagen , Denmark , 2007 .", "label": "", "metadata": {}, "score": "60.256786"}
{"text": "Table 5 : Performance obtained training the regressor on 80 % of the data and testing on 20 % .This process has been iterated 1,000 times .Experiments have been performed independently on the Europarl and Giga corpus dataset .Role of Phrase Length in the Translation Table ( Model Selection ) .", "label": "", "metadata": {}, "score": "60.26139"}
{"text": "In this process of overfitting , the performance on the training examples still increases while the performance on unseen data becomes worse .As a simple example , consider a database of retail purchases that includes the item bought , the purchaser , and the date and time of purchase .", "label": "", "metadata": {}, "score": "60.45349"}
{"text": "Almost nobody learns all of J2EE 's content .A development team would usually have presentation layer developers ( JSP , servlet , Web framework ) , middleware people ( EJBs , JMS , etc . ) , etc .Even in J2SE there are packages that one does n't use all the time .", "label": "", "metadata": {}, "score": "60.471687"}
{"text": "While we refer to \" words swap ' ' when , given two entries of the translation model , we swap the target language phrases .Three different sets of experiments have been run applying \" numerical swap ' ' only to the language model , \" numerical swap ' ' only to the translation model and \" words swap ' ' only to the translation model .", "label": "", "metadata": {}, "score": "60.677177"}
{"text": "( ii ) Unlearning by Randomization of Parameters .The second kind of noise that we add to the model is based on a swap of a particular quantity inside two entries of language or translation model .This is meant to test how robust the system is to perturbations of the all - important associations between phrases / numbers and to the associations between source / target phrases .", "label": "", "metadata": {}, "score": "60.71304"}
{"text": "Data .We used three different sentence - aligned corpora , covering different language pairs and sizes : ( 1 ) Europarl Release v3 Spanish - English [ 7 ] , ( 2 ) UN Chinese - English corpus provided by the Linguistic Data Consortium , ( 3 ) Giga corpus French - English [ 8 ] .", "label": "", "metadata": {}, "score": "60.72104"}
{"text": "Currently there are no clear standards on asynchrony , state management etc , hence you have JSR 181 .BEA is driving JSR 181 through the standardization process .JSR 181 , defines how to use simple Java classes with declarative annotations to build powerful enterprise - class Web services , was unanimously approved by the Java executive committee in April 2002 , with the JSR 181 expert group working on developing a standard specification since that time .", "label": "", "metadata": {}, "score": "60.8423"}
{"text": "Gathering data might be expensive .Another option is artificial data synthesis , either creating new examples out of whole cloth or by transforming existing examples .In text recognition , a library of digital fonts might be used to generate examples , or existing examples might be warped or reflected .", "label": "", "metadata": {}, "score": "60.945168"}
{"text": "Role of Training Set Size on Performance on New Sentences .In this section , we analyze how training set size affects the performance by creating learning curves ( BLEU score versus training set size ) .The general framework for this set of experiments consists of creating subsets of the complete corpus by subsampling from a uniform distribution without replacement .", "label": "", "metadata": {}, "score": "61.088203"}
{"text": "We present first experimental results on single objects and on artificially generated scenes .Although the computational complexity of the approach is high , the additional effort seems justified and there is potential for reduction of complexity .Tools . by Daniel Keysers , J\u00f6rg Dahmen , Hermann Ney , Berthold B. Wein , Thomas M. Lehmann , 2003 . \" ...", "label": "", "metadata": {}, "score": "61.38232"}
{"text": "That is followed by de- scriptino of m - bleu and m - ter , enhanced ver- sions of two other widely used metrics bleu and ter , which extend the exact word match- ing used in these metrics with the flexible matching based on stemming and Wordnet in Meteor .", "label": "", "metadata": {}, "score": "61.42623"}
{"text": "However , it is much harder to detect and score global properties over such data structures .Additional Arcs in the Search Graph .Recall the process of state expansions .The generated hypotheses and the expansions that link them form a graph .", "label": "", "metadata": {}, "score": "61.463493"}
{"text": "A human error analysis indicates that long - distance reorderings are captured effectively . by Sujan Kumar Saha , Partha Sarathi Ghosh , Sudeshna Sarkar , Pabitra Mitra . \" ...Abstract - Named entities are perhaps the most important indexing element in text for most of the information extraction and mining tasks .", "label": "", "metadata": {}, "score": "61.556793"}
{"text": "Briefly , the system performs a log - linear combination of a translation model and additional feature functions .The translation model is estimated as an N - gram of bilingual units called tuples , and the feature functions include a target language model , a word penalty , and lexical features , depending on the language pair and task .", "label": "", "metadata": {}, "score": "61.56784"}
{"text": "In both approaches , the translation process is based on bilingual units related by word - to - word alignments ( pairs of source and target words ) , while the main di ... \" .This work summarizes a comparison between two approaches to Statistical Machine Translation ( SMT ) , namely Ngram - based and Phrase - based SMT .", "label": "", "metadata": {}, "score": "61.59002"}
{"text": "In an age where the creation of intelligent behaviour is increasingly data driven , this is a question of great importance to all of artificial intelligence .In phrase - based approaches to statistical machine translation , translations are generated in response to some input source text .", "label": "", "metadata": {}, "score": "61.604797"}
{"text": "Role of Test Set Size on Measuring Performance .BLEU score , the metric used in this work to evaluate the quality of the translation , is test set dependent .It means that different test sets regardless of the dimension can produce variation in the value of the BLEU score .", "label": "", "metadata": {}, "score": "61.61884"}
{"text": "Figure 3 : Chinese - English learning curve obtained using UN corpus and Portage .In all the figures , the curves are increasing linearly or slightly more slowly than that , suggesting a learning curve that is \" at best ' ' logarithmically increasing with the training set size .", "label": "", "metadata": {}, "score": "61.630177"}
{"text": "386 - 393 .Chin - Yew Lin and Eduard Hovy .Automatic Evaluation of Summaries Using N - gram Co - occurrence Statistics .In Proceedings of HLT - NAACL 2003 .Edmonton , Canada .May 2003 .pp .", "label": "", "metadata": {}, "score": "61.791054"}
{"text": "If the gene mention and a synonym have a Jaro - Winkler similarity [ 7 ] greater than 0.85 , then the gene that synonym is associated with is added to the candidate list for that document .This two - stage pattern matching system compensates for the fact that the given synonym list contains large amounts of ambiguity , but does nothing to reduce the number of gene mentions that a naive pattern matching approach misses due to the incompleteness of the synonym lists .", "label": "", "metadata": {}, "score": "61.936707"}
{"text": "The figure below gives pseudo - code for the algorithm we used for our beam search .For each number of foreign words covered , a hypothesis stack in created .The initial hypothesis is placed in the stack for hypotheses with no foreign words covered .", "label": "", "metadata": {}, "score": "62.026234"}
{"text": "The distortion feature controls the reordering between phrases .Note that only very short - range reordering may be handled within phrases .Long - range reordering must be handled by target phrase permutations .This feature allows to regulate the amount of reordering depending on , for example , the language pair .", "label": "", "metadata": {}, "score": "62.041027"}
{"text": "However , just as it is possible to use the training data to determine which synonyms are useful , it is also possible to use the training data to determine which matches are correct .We present here a model that , given a set of synonym matches , distinguishes correct from incorrect ones .", "label": "", "metadata": {}, "score": "62.062134"}
{"text": "This phrase - based machine translation approach relies on a specific representation of the translation process , such as the choice of contiguous word sequences ( phrases ) as basic units in the language and translation models .How far can this representation take us towards the target of improving translation quality ?", "label": "", "metadata": {}, "score": "62.14103"}
{"text": "In each case , we count the number of phrases of each length that were actually used to produce the translation .The right panel of Figure 5 reports these distribution .It shows that , while the models use a fair amount of longer phrases to translate the training material , these longer phrases are essentially never used for translating the test set : 98 % of the phrases are 5-grams or shorter .", "label": "", "metadata": {}, "score": "62.148872"}
{"text": "Average .and error on the Europarl and Giga corpus datasets are shown in Table 5 .The proposed model is able to approximate well enough the BLEU score using Moses as translation system and in - domain test sets .According to this setting and assuming that we are in the standard case where .", "label": "", "metadata": {}, "score": "62.158806"}
{"text": "35 - 43 , Columbus , Ohio , USA , 2008 . Y. Al - Onaizan , J. Curin , M. Jahr , et al . , \" Statistical machine translation : final report , \" Tech .Rep. , Johns Hopkins University , Summer Workshop on Language Engineering , Center for Speech and Language Processing , Baltimore , Md , USA , 1999 .", "label": "", "metadata": {}, "score": "62.231277"}
{"text": "[ 8].which is independent of the tangent vectors and can therefore be neglected in the following maximum likelihood estimation .3.2 Estima ... . \" ...Statistical classification using tangent vectors and classification based on local features are two successful methods for various image recognition problems .", "label": "", "metadata": {}, "score": "62.295288"}
{"text": "868 - 876 , 2007 .J. Blatz , E. Fitzgerald , G. Foster , et al . , \" Confidence estimation for machine translation , \" in Proceedings of the 20th international Conference on Computational Linguistics ( COLING ' 04 ) , vol .", "label": "", "metadata": {}, "score": "62.326088"}
{"text": "The log - linear parameters are then estimated by minimum error rate training ( MERT ) .The weights .is the set of sentence pairs over which MERT is performed .Solving ( 3 ) is difficult because the decoding necessary to produce the hypothesis translation is expensive .", "label": "", "metadata": {}, "score": "62.335457"}
{"text": "Estimating a machine translation system is therefore similar to learning the mapping between the source / input and the target / output , a problem which has been extensively studied in statistics and in machine learning .This justifies our view of a typical phrase - based machine translation model as a learning system and motivates our analysis of the performance on that system .", "label": "", "metadata": {}, "score": "62.408142"}
{"text": "The evaluation of a machine translation system is a lively and hotly debated topic in this field .Ideally , human beings can evaluate the quality of a translated sentence .However , this is unfeasible for rapid development of automatically trained systems with multiple parameter tuning , as human evaluation is expensive , slow , and sometimes inconsistent and subjective .", "label": "", "metadata": {}, "score": "62.419888"}
{"text": "2142 - 2147 , Genova , Italy , 2006 .N. Draper and H. Smith , Applied Regression Analysis , John Wiley & Sons , New York , NY , USA , 1981 .F. J. Och , \" Statistical machine translation : foundations and recent advances , \" in Proceedings of the Tutorial at MT Summit , 2005 .", "label": "", "metadata": {}, "score": "62.49595"}
{"text": "I think that the main reason why the companies have Software / Technical Architects .Keeping up with the new technologies / tools is a part of the job .One either has to have good learning skills or good delegation skills :-) .", "label": "", "metadata": {}, "score": "62.500847"}
{"text": "How can you even think about comparing the tool with a properatory WLS application builder called workshop ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?I think you know UML is kind of universal language for communicating and visualizing the design ideas in best way .", "label": "", "metadata": {}, "score": "62.52357"}
{"text": "In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics ( ACL ) , pages 311 - 318 , Philadelphia , PA , July .Doddington , George .Automatic Evaluation of Machine Translation Quality Using N - gram Co - Occurrence Statistics .", "label": "", "metadata": {}, "score": "62.617767"}
{"text": "So if we remove an n -gram , chances are that other similar ( longer or shorter ) n -grams are present and can take over .In this way , it is not possible to directly compare the unlearning curve for the n -grams part with that for the numeric part of the tables .", "label": "", "metadata": {}, "score": "62.627502"}
{"text": "Understanding the most important reasons for failure of a PBSMT system is a fundamental task .In [ 39 ] , a classification of different types of error has been proposed .In this section , we focus our attention on a particular type of error : unknown words .", "label": "", "metadata": {}, "score": "62.63018"}
{"text": "The unfolding technique produces a different bilingual N - gram language model with reordered source words .Usually , ... .by Josep M. Crego , Nizar Habash - In Proceedings of the Third Workshop on Statistical Machine Translation , 2008 . \" ...", "label": "", "metadata": {}, "score": "62.828938"}
{"text": "In our implementation , we store the information about hypotheses , hypothesis transitions , and additional arcs in a file that can be processed by the finite state toolkit Carmel , which we use to mine the n - best lists .", "label": "", "metadata": {}, "score": "62.86108"}
{"text": "P. Koehn , \" Statistical significance tests for machine translation evaluation , \" in Proceedings of the Conference on Empirical Methods in Natural Language Processing , pp .388 - 395 , Barcelona , Spain , 2004 . A. Stolcke , \" Srilm - an extensible language modeling toolkit , \" in Proceedings of the International Conference on Spoken Language Processing , Denver , Colo , USA , 2002 .", "label": "", "metadata": {}, "score": "62.898888"}
{"text": "To classify a new abstract , the system first extracts all the synonym matches that occur within it .For each positive match , the normal form causing the match is added to the documents normalized gene list .Results of the trained models on evaluation data are shown in Table 4 .", "label": "", "metadata": {}, "score": "62.94593"}
{"text": "The recommended approach .Quickly testing ideas empirically and optimizing developer time is the approach embodied in these steps : .First , implement a simple quick and dirty algorithm , plot learning curves , and perform error analysis .Create a list of potential ideas to try to improve performance .", "label": "", "metadata": {}, "score": "62.956635"}
{"text": "In each case , we found the same overall behaviour , of a logarithmic growth in performance with training set size .The question becomes as follows : on which aspect of these systems should we act to achieve better performance ?", "label": "", "metadata": {}, "score": "62.96396"}
{"text": "As before , each informative synonym is compared to each document .If the synonym matches and the corresponding gene is in the candidate list for that document , then the gene is added to that document 's final gene list .", "label": "", "metadata": {}, "score": "63.005306"}
{"text": "Note that the inferior hypothesis can be part of the path to the second best translation .This is important for generating n - best lists .Beam Search .While the recombination of hypotheses as described above reduces the size of the search space , this is not enough for all but the shortest sentences .", "label": "", "metadata": {}, "score": "63.088768"}
{"text": "Relative Importance of TM and LM .In the previous section , experiments have been run using the same training set size for language and translation models .In general , there is a large difference in terms of cost of retrieving training data for language and translation models ; the former can be trained using monolingual data , while the second needs bilingual texts .", "label": "", "metadata": {}, "score": "63.1379"}
{"text": "Variance is the opposite problem , having lots of parameters , which carries a risk of overfitting .If we are overfitting , the algorithm fits the training set well , but has high cross - validation and testing error .If we see low training set error , with cross - validation error trending downward , then the gap between them might be narrowed by training on more data .", "label": "", "metadata": {}, "score": "63.204147"}
{"text": "Training the translation models requires several steps such as aligning words , computing the lexical translation , extracting and scoring the phrases , and creating the reordering model .When the models have been created , the development set is used to run the minimum error rate training ( MERT ) algorithm [ 17 ] to optimize their weights .", "label": "", "metadata": {}, "score": "63.268196"}
{"text": "BLEU and NIST are based on averaging n -gram precisions , combined with a length penalty which penalizes short translations containing only sure words .These metrics differ on the way the precisions are combined and on the length penalty .Meteor evaluates a translation by computing a score based on the word alignment between the translation and a given reference translation .", "label": "", "metadata": {}, "score": "63.30265"}
{"text": "It may be hard to pick the best of the frameworks for each layer .I am student of IT and developing a website using jsp builder i am using RUP model for development but can not find any particular software .", "label": "", "metadata": {}, "score": "63.317406"}
{"text": "tried by MERT , new hypothesis translations are added to the list .As the number of hypotheses produced by the decoder is finite , this is guaranteed to converge , and in practice , it does fairly quickly .An additional difficulty is that the landscape of the cost , for example , BLEU , is piecewise constant and highly irregular .", "label": "", "metadata": {}, "score": "63.38646"}
{"text": "Both of these ideas of course are being pursued at the moment .It is of course important to remark that these limitations only refer to the current systems , where language is modelled as a Markov chain , and by entirely changing language model , different limitations could be found .", "label": "", "metadata": {}, "score": "63.38891"}
{"text": "Affiliated with .Abstract .Background .Document gene normalization is the problem of creating a list of unique identifiers for genes that are mentioned within a document .Automating this process has many potential applications in both information extraction and database curation systems .", "label": "", "metadata": {}, "score": "63.396236"}
{"text": "To create training data for the classifier , we matched every synonym to each training document using a loose matching criterion ( punctuation and numbers were ignored ) .We then extracted , for each match , the text that matched ( adding back the removed characters ) , some context of the match , the normal form causing the match , as well as the number of other genes which matched that specific piece of text .", "label": "", "metadata": {}, "score": "63.40214"}
{"text": "In ( a ) , \" words swap TM ' ' has been obtained by swapping the target phrases inside the TM .In ( b ) , two unlearning curves have been compared . \"Numerical swap LM ' ' has been obtained applying numerical swaps only to the LM and \" numerical swap TM ' ' applying numerical swaps only to the LM .", "label": "", "metadata": {}, "score": "63.481457"}
{"text": "A number of sentences were used as a testing dataset to evaluate both engines .Human translations by three bilingual speakers were used as a gold standard .A simple evaluation metric was proposed to calculate the translation accuracy of verb - noun collocations .", "label": "", "metadata": {}, "score": "63.50436"}
{"text": "Short Papers : pp .61 - 63 .Joseph P. Turian , Luke Shen and I. Dan Melamed .Evaluation of Machine Translation and its Evaluation .In Proceedings of MT Summit IX .New Orleans , LA .Sept. 2003 .", "label": "", "metadata": {}, "score": "63.57164"}
{"text": "San Diego , CA . pp .128 - 132 .K.-Y. Su , M.-W. Wu , and J.-S. Chang .A New Quantitative Quality Measure for Machine Translation Systems .In Proceedings of the fifteenth International Conference on Computational Linguistics ( COLING-92 ) .", "label": "", "metadata": {}, "score": "63.641594"}
{"text": "In fact , a common belief in SMT is that learning curves follow logarithmic laws ; to analyze this in our experiments , we show all the learning curves in the linear log scale , where we can study if the curve has a linear behaviour .", "label": "", "metadata": {}, "score": "63.681377"}
{"text": "The gentle decline in performance seems to suggest that fine tuning of parameters is not what controls the performance here , and that perhaps advanced statistical estimation or more observations of the same n -grams would not lead to much better performance .", "label": "", "metadata": {}, "score": "63.716858"}
{"text": "Feature selection and treatment .Are the given features sufficiently informative to make predictions ?Asking whether a human expert can confidently predict the output given the input features will give a good indication .At times , it may be necessary to derive new features .", "label": "", "metadata": {}, "score": "63.72015"}
{"text": "For all hand - tuned parameters there is the danger of overfitting to the development data .By examining Tables 2 and 3 , it appears that this may not be a problem for this set of data .In particular , the F1 score for the mouse organism is actually better on evaluation then on development , and for both fly and mouse the recall on the evaluation set is higher than the recall on the development set .", "label": "", "metadata": {}, "score": "63.755066"}
{"text": "What I find interesting about this \" Universal Language \" is that there is almost no way to produce production quality UML without using specific and expensive Tools .Sure you can use Tools like ArgoUML , Visio , Violet etc . to produce Something - That - Is - Quite - Like - UML .", "label": "", "metadata": {}, "score": "63.880997"}
{"text": "In Proceedings of the Second International Conference on Language Resources and Evaluation ( LREC-2000 ) .Athens , Greece .pp .39 - 45 .Gregor Leusch , Nicola Ueffing and Herman Ney .String - to - String Distance Measure with Applications to Machine Translation Evaluation .", "label": "", "metadata": {}, "score": "64.0173"}
{"text": "We have isolated 4,000 pairs of sentences from the Europarl training set , and we have selected from the remaining part 629,957 pairs .A Moses model is trained using this set .Using the 4,000 sentences pairs , we have created 10 random subsets for each of the 16 chosen sizes , where each size can contain a number of pairs from 250 to 4,000 by a step of 250 pairs .", "label": "", "metadata": {}, "score": "64.11841"}
{"text": "The key is dividing data into training , cross - validation and test sets .The test set is used only to evaluate performance , not to train parameters or select a model representation .The rationale for this is that training set error is not a good predictor of how well your hypothesis will generalize to new examples .", "label": "", "metadata": {}, "score": "64.1254"}
{"text": "( 2003 ) reviews these two methods and shows that the combining phrase tables generated by different methods improves results .Decoder .This section describes the Moses decoder from a more theoretical perspective .The decoder was originally developed for the phrase model proposed by Marcu and Wong .", "label": "", "metadata": {}, "score": "64.18265"}
{"text": "If we would do this , the search graph would only contain one path for each hypothesis in the last hypothesis stack ( which contains hypotheses that cover all foreign words ) .If we store information that there are multiple ways to reach a hypothesis , the number of possible paths also multiplies along the path when we traverse backward through the graph .", "label": "", "metadata": {}, "score": "64.4467"}
{"text": "C. van Rijsbergen .Information Retrieval .Butterworths .London , England .2nd Edition .Deborah Coughlin .Correlating Automated and Human Assessments of Machine Translation Quality .In Proceedings of MT Summit IX .New Orleans , LA .Sept. 2003 .", "label": "", "metadata": {}, "score": "64.464066"}
{"text": "For each subset , a new instance of the PBSMT system has been created , for a total of 100 models .Each model has been tested on the test set and on a subset of 2,000 pairs the training set .", "label": "", "metadata": {}, "score": "64.47165"}
{"text": "Pattern matching .Given a synonym list that is both unambiguous and exhaustive , creating a normalized gene list would be trivial .We could simply match every occurrence of a synonym in the text , and based on those matches label the document with the corresponding normalized mentions .", "label": "", "metadata": {}, "score": "64.488106"}
{"text": "The primary limitation of the pattern matching and maximum entropy classification models are their reliance on the gene synonym list to find potential matches .For the three organisms under consideration here , it is possible to attain a maximum recall of 91 % , 79 % and 90 % for fly , mouse and yeast using the their synonym lists to match the text .", "label": "", "metadata": {}, "score": "64.53645"}
{"text": "View Article .Yu H , Agichtein E : Extracting synonymous gene and protein terms from biological literature .Bioinformatics 2003 , 19 ( ISMB supplement ) : 340 - 349 .View Article .Copyright .\u00a9 Crim et al 2005 .", "label": "", "metadata": {}, "score": "64.576935"}
{"text": "Results are presented regarding translation accuracy and computational efficiency , showing significant improvements in translation quality for both translation directions at a very low computational cost .Index Terms - statistical machine translation , reordering , N - gram translation model 1 . .", "label": "", "metadata": {}, "score": "64.6268"}
{"text": "However , the mapping between words is stored in a very redundant way within the TM , and this depends on the way the translation table is created , based on sentence alignments .Once an alignment has been found between two sentences , essentially every n -gram ( for every value of n ) is a candidate for insertion in the translation table .", "label": "", "metadata": {}, "score": "64.690216"}
{"text": "In the end , the best hypothesis of the ones that cover all foreign words is the final state of the best translation .We can read off the English words of the translation by following the back links in each hypothesis .", "label": "", "metadata": {}, "score": "64.691696"}
{"text": "Tuning the trade off between bias vs variance .The steps we take to improve performance depend on whether our algorithm is suffering from bias or variance .A learning curve is a diagnostic that can tell which of these situations we 're in , by plotting training error and validation error as a function of training set size .", "label": "", "metadata": {}, "score": "64.774284"}
{"text": "We can see that kGMM , with less components number , has obviously much better performance than traditional GMM with or without LDA .Although , the result by kGMM is not ... . by Daniel Keysers , J\u00f6rg Dahmen , Hermann Ney , Mark Oliver G\u00fcld - IN INFORMATIKTAGE 2001 DER GESELLSCHAFT F\u00dcR INFORMATIK , KONRADIN VERLAG , 2001 . \" ...", "label": "", "metadata": {}, "score": "64.82155"}
{"text": "We can see that kGMM , with less components number , has obviously much better performance than traditional GMM with or without LDA .Although , the result by kGMM is not ... . by Daniel Keysers , J\u00f6rg Dahmen , Hermann Ney , Mark Oliver G\u00fcld - IN INFORMATIKTAGE 2001 DER GESELLSCHAFT F\u00dcR INFORMATIK , KONRADIN VERLAG , 2001 . \" ...", "label": "", "metadata": {}, "score": "64.82155"}
{"text": "The problem is determining which part to ignore .A learning algorithm that can reduce the chance of fitting noise is called robust .Overfitting is also a problem in regression .In the extreme case , if there are p variables in a linear regression with p data points , the fitted line will go exactly through every point .", "label": "", "metadata": {}, "score": "64.86932"}
{"text": "Tangent vectors can be used to obtain global inva ... \" .Statistical classification using tangent vectors and classification based on local features are two successful methods for various image recognition problems .These two approaches tolerate global and local transformations of the images , respectively .", "label": "", "metadata": {}, "score": "64.87837"}
{"text": "Tangent vectors can be used to obtain global inva ... \" .Statistical classification using tangent vectors and classification based on local features are two successful methods for various image recognition problems .These two approaches tolerate global and local transformations of the images , respectively .", "label": "", "metadata": {}, "score": "64.87837"}
{"text": "For each model , we count the unknown words .Figure 11 shows unknown words as function of the training model .It is clear that small training sets are able to cover a small part of the word space .When increasing the dimension of the training set , the number of unknown words decreases .", "label": "", "metadata": {}, "score": "64.910614"}
{"text": "Berger AL , Della Pietra SA , Della Pietra VJ : A maximum entropy approach to natural language processing .Computational Linguistics 1996 ., 22 ( 1 ) : .Chen SF , Rosenfeld R : A Gaussian prior for smoothing maximum entropy models .", "label": "", "metadata": {}, "score": "64.924484"}
{"text": "The error due to each stage is estimated by substituting labeled data for that stage , revealing how well the whole pipeline would perform if that stage had no error .Stepping through the stages , we note the potential for improvement at each one .", "label": "", "metadata": {}, "score": "64.99196"}
{"text": "The tool , called IBM Rational Rapid Developer , is expected to be unveiled .because I am sick of the term MDA .Because with MDA ( as I have seen it , as Booch etc . talked about it ) the model does not ever drive the architecture - it 's the platform and the artefacts predefined for the platform that drive the architecture .", "label": "", "metadata": {}, "score": "65.167496"}
{"text": "However , the difference in word order between two languages is one of t ... \" .Statistical Machine Translation ( SMT ) is based on alignment models which learn from bilingual corpora the word corre - spondences between source and target lan - guage .", "label": "", "metadata": {}, "score": "65.19388"}
{"text": "Authors in [ 30 ] reported \" almost linear \" improvements in BLEU score by doubling the training set size .In the presentation [ 32 ] , the claim is that BLEU increases with each doubling of the training set size , by 0.5 and 2.5 BLEU points for the language and translation models , respectively , in the context of Arabic - English translation .", "label": "", "metadata": {}, "score": "65.29649"}
{"text": "We also provide insight into the way statistical machine translation learns from data , including the respective influence of translation and language models , the impact of phrase length on performance , and various unlearning and perturbation analyses .Our results support and illustrate the fact that performance improves by a constant amount for each doubling of the data , across different language pairs , and different systems .", "label": "", "metadata": {}, "score": "65.30047"}
{"text": "In this paper , we show how this principle is related to the discriminative training of Gaussian mixture densities using the maximum mutual information criterion .This leads to a relaxation of the constraints on the covariance matrices to be positive ( semi-)definite . .", "label": "", "metadata": {}, "score": "65.34209"}
{"text": "Only words that did not occur in a stop - list of common English words were included in this calculation .The gene lists for the neighbouring documents are merged to create the final candidate list .For mouse - related documents , the system first tags the document using a gene tagger [ 2 ] .", "label": "", "metadata": {}, "score": "65.443115"}
{"text": "This has considerable speed advantages over computing future cost on the fly .N - Best Lists Generation .Usually , we expect the decoder to give us the best translation for a given input according to the model .But for some applications , we might also be interested in the second best translation , third best translation , and so on .", "label": "", "metadata": {}, "score": "65.57038"}
{"text": "He starts with phrase alignments based on the intersection of the two GIZA++ alignments and uses points of the union to expand these .See his presentation for details .Venugopal , Zhang , and Vogel .Venugopal et al .( ACL 2003 ) allows also for the collection of phrase pairs that are violated by the word alignment .", "label": "", "metadata": {}, "score": "65.66135"}
{"text": "See the figure below for some examples what this means .All alignment points for words that are part of the phrase pair have to be in the phrase alignment box .It is fine to have unaligned words in a phrase alignment , even at the boundary .", "label": "", "metadata": {}, "score": "65.76986"}
{"text": "Multi - class document classification is typically done for tens and in rare instances hundreds of classes .However , as stated earlier , each organism has thousands of genes and in some cases tens of thousands .This poses substantial computational issues .", "label": "", "metadata": {}, "score": "65.8062"}
{"text": "For the second set of experiments , data has been randomly sampled in training and test sets one thousand times .Training set has been used to estimate the alphas and the residual , and test set to predict the BLEU score values .", "label": "", "metadata": {}, "score": "65.883835"}
{"text": "Model Perturbation : Analysis and Unlearning Curves .Much research has focused on devising improved principles for the statistical estimation of the parameters in language and translation models .The introduction of discriminative graphical models has marked a departure from traditional maximum likelihood estimation principles , and various approaches have been proposed .", "label": "", "metadata": {}, "score": "65.89386"}
{"text": "This problem may be exacerbated for other organisms that do not have synonym lists that have been as well curated as the ones for fly , mouse and yeast .A simple mechanism to increase the recall for synonym matching is to relax the matching criteria further using some sort of edit distance or string similarity metric [ 7 ] .", "label": "", "metadata": {}, "score": "65.96798"}
{"text": "Replacements are not allowed .These choices also depend on the high computational cost of the tuning algorithm .For each size , ten random sets have been selected .For each set , an instance of the system has been run .", "label": "", "metadata": {}, "score": "65.982285"}
{"text": "Google in [ 30 ] has shown that performance improves logarithmically in the linear scale with the number of tokens in the language model training set when this quantity is huge ( from billions to trillions of tokens ) .In this section , we are interested to understand whether there is a trade - off between the training data size used to build language and translation models and how performances are affected by their differences .", "label": "", "metadata": {}, "score": "66.00183"}
{"text": "Tables 3 and 4 outline the results for both the pattern matching and the maximum entropy classification systems .The results are comparable for mouse and yeast , however , the classification system outperforms the pattern matching system for fly - related documents .", "label": "", "metadata": {}, "score": "66.01812"}
{"text": "Are both unaligned ?What is the lexical probability for the potential point ?Och and Ney ( Computational Linguistics , 2003 ) are ambigous in their description about which alignment points are added in their refined method .We reimplemented their method for Moses , so we will describe this interpretation here .", "label": "", "metadata": {}, "score": "66.086296"}
{"text": "I\u00b4m inclined to agree with the previous speakers about not wanting \" J2EE for Dummies \" .There are a few aspects that would speak for it , such as lack of skilled developers for some project ( resourcing ) etc , but having previously seen the results of \" point - and - click \" code I\u00b4d rather see the project take 7 months instead of 6 .", "label": "", "metadata": {}, "score": "66.0977"}
{"text": "cost from the previous to higher - cost hypothesis .The figure below gives an example for the generation of such an arc : in this case , the hypotheses 2 and 4 are equivalent in respect to the heuristic search , as detailed above .", "label": "", "metadata": {}, "score": "66.10104"}
{"text": "The impressive capability of current machine translation systems is not only a testament to an incredibly productive and creative research community , but can also be seen as a paradigm for other artificial intelligence tasks .Data - driven approaches to all main areas of AI currently deliver the state - of - the - art performance , from summarization to speech recognition to machine vision to information retrieval .", "label": "", "metadata": {}, "score": "66.139755"}
{"text": "At a maximum , the points of the union of the two alignments are considered .To illustrate this , see the figure below .The intersection points are black , the additional points in the union are shaded grey .Och and Ney explore the space between intersection and union with expansion heuristics that start with the intersection and add additional alignment points .", "label": "", "metadata": {}, "score": "66.25026"}
{"text": "For our model , x is a binary vector containing predicates on the matched text , its context , the normal form causing the match and the number of other genes matching the text .Each feature function f i ( y , x ) maps an input vector and class to a binary variable , for instance : .", "label": "", "metadata": {}, "score": "66.44304"}
{"text": "Within the first step of processing , images are classified according to image modality , body orientation , anatomic region , and biological system .The statistical classifier for the anatomic region is based on Gaussian kernel densities within a probabilistic framework for multiobject recognition .", "label": "", "metadata": {}, "score": "66.48613"}
{"text": "Or build a generic business process on one process engine and move it to another .This is typical behavior where companies will innovate and then push those innovations towards standards eventually competing on implementation as is somewhat the case with app servers today .", "label": "", "metadata": {}, "score": "66.48881"}
{"text": "We approximate the cost for a path through translation options by the product of the cost for each option .To illustrate this concept , refer to the figure below .The translation options cover different consecutive foreign words and carry an estimated cost c ij .", "label": "", "metadata": {}, "score": "66.6095"}
{"text": "the last two English words generated ( needed for computing future language model costs ) .the end of the last foreign phrase covered ( needed for computing future distortion costs ) .the last added English phrase ( needed for reading the translation from a path of hypotheses ) .", "label": "", "metadata": {}, "score": "66.62488"}
{"text": "We extract two words before and after the match .In the first example , the normalized form causing the match is FBgn0001308 , it was the only gene matching that piece of text and it constituted an actual match .Note that the third match , Utrabithorax , is negative because it is actually a match for the gene FBgn0003944 , which shares the synonym Utrabithorax with FBgn0013100 .", "label": "", "metadata": {}, "score": "66.671875"}
{"text": "We conclude with background on n - best list generation .Translation Options .Given an input string of words , a number of phrase translations could be applied .We call each such applicable phrase translation a translation option .This is illustrated in the figure below , where a number of phrase translations for the Spanish input sentence Maria no daba uma bofetada a la bruja verde are given .", "label": "", "metadata": {}, "score": "66.72836"}
{"text": "A briefly discussion about the presence of unknown words when we test on a subset of the training set is given by Section 4.3 .Figure 11 : Number of unknown words translating training and test sets versus training set size .", "label": "", "metadata": {}, "score": "66.78861"}
{"text": "Eric Schurr , a marketing VP from IBM said , that \" it is aimed at developers without Java expertise and is not specifically intended for skilled J2EE developers , which are the target customers for WebSphere Studio .\" Is this IBM trying to come up with its own BEA WebLogic Workshop ?", "label": "", "metadata": {}, "score": "66.91518"}
{"text": "Note that these are not phrases in the linguistic sense , but simply subsequences of words .For a sentence .referred to as a phrase table .Part of the overall MT training process is to estimate this table and the associated probabilities .", "label": "", "metadata": {}, "score": "67.072815"}
{"text": "W. Locke and A. Booth , Machine Translation of Languages , MIT Press , Cambridge , Mass , USA , 1955 .P. F. Brown , S. D. Pietra , V. J. D. Pietra , and R. L. Mercer , \" The mathematic of statistical machine translation : parameter estimation , \" Computational Linguistics , vol .", "label": "", "metadata": {}, "score": "67.20016"}
{"text": "Understanding how sophisticated behaviour can be learnt from data is hence not just a concern for machine learning , or to individual applied communities , such as statistical machine translation , but rather a general concern for modern artificial intelligence .The analysis of learning curves and the identification of the various limitations to performance are a crucial part of the machine learning method , and one where statistics and algorithms interact closely .", "label": "", "metadata": {}, "score": "67.23461"}
{"text": "We used the MALLET [ 9 ] implementation of maximum entropy models [ 10 ] for our classifiers .Maximum entropy classifiers model the conditional probability of a class given an input vector with the log - linear form : . where y is a class ( in our case yes or no ) , x is an input vector and Z ( x ) is a normalizing term .", "label": "", "metadata": {}, "score": "67.2612"}
{"text": "Bias .A high bias model has few parameters and may result in underfitting .Essentially we 're trying to fit an overly simplistic hypothesis , for example linear where we should be looking for a higher order polynomial .In a high bias situation , training and cross - validation error are both high and more training data is unlikely to help much .", "label": "", "metadata": {}, "score": "67.28019"}
{"text": "We describe the details of our future cost estimation in the next section .Given the cost so far and the future cost estimation , we can prune out hypotheses that fall outside the beam .The beam size can be defined by threshold and histogram pruning .", "label": "", "metadata": {}, "score": "67.306305"}
{"text": "The first unlearning curve ( Figure 6 ) , obtained by adding to each parameter a random number ( sampled from within a range ) proportional to its size , is meant to test the role of detailed tuning of parameters .", "label": "", "metadata": {}, "score": "67.335815"}
{"text": "In the framework of the phrase - based model , not only may single words be translated individually , but also consecutive sequences of words as a phrase .Each such translation operation carries a translation cost , language model costs , and a distortion cost .", "label": "", "metadata": {}, "score": "67.3496"}
{"text": "Each phrase is translated into an English phrase , and English phrases in the output may be reordered .In this section , we will define the phrase - based machine translation model formally .The phrase translation model is based on the noisy channel model .", "label": "", "metadata": {}, "score": "67.471"}
{"text": "L. Specia , M. Turchi , Z. Wang , J. Shawe - Taylor , and C. Saunders , \" Improving the confidence of machine translation quality estimates , \" in Proceedings of 12th the Machine Translation Summit , 2009 . D. Vilar , J. Xu , L. F. D'Haro , and H. Ney , \" Error analysis of statistical machine translation output , \" in Proceedings of the 5th International Conference on Language Resources and Evaluation ( LREC ' 06 ) , Genova , Italy , 2006 .", "label": "", "metadata": {}, "score": "67.70909"}
{"text": "C ) Same as B , except restrict that a synonym must be in a documents candidate list for match to be valid .D ) Same as C , except matches are run with all tokens stemmed .Numbers are reported for both fly and mouse .", "label": "", "metadata": {}, "score": "67.785736"}
{"text": "These experiments suggest that the phrase length has a limited impact on actual test performance .Going to larger n- grams seems to bring little benefit in terms of performance as the model continues to prefer short phrases during the decoding phase .", "label": "", "metadata": {}, "score": "67.84326"}
{"text": "Compared with most classical kernel methods , the proposed method can solve problems in probabilistic framework .Moreover , it can tackle nonlinear problems better than the traditional GMM .To avoid great computational cost problem existing in most kernel methods upon large scale data set , we also employ a Monte Carlo sampling technique to speed up kernel GMM so that it is more practical and efficient .", "label": "", "metadata": {}, "score": "68.069016"}
{"text": "Compared with most classical kernel methods , the proposed method can solve problems in probabilistic framework .Moreover , it can tackle nonlinear problems better than the traditional GMM .To avoid great computational cost problem existing in most kernel methods upon large scale data set , we also employ a Monte Carlo sampling technique to speed up kernel GMM so that it is more practical and efficient .", "label": "", "metadata": {}, "score": "68.069016"}
{"text": "The principle of maximum entropy is a powerful framework that can be used to estimate class posterior probabilities for pattern recognition tasks .In this paper , we show how this principle is related to the discriminative training of Gaussian mixture densities using the maximum mutual information cr ... \" .", "label": "", "metadata": {}, "score": "68.09226"}
{"text": "How much space for improvement is there , given new data or new statistical estimation methods or given different models with different complexities ?Before we present experimental results that address these questions , we will describe the setup that was used to obtain these results .", "label": "", "metadata": {}, "score": "68.11296"}
{"text": "Figure 5 shows that the number of phrases peaks around 4-grams and 5-grams , then steadily decreases .This means that the phrase extraction algorithm finds it more and more difficult to extract longer phrases .We investigate this further by plotting the distribution of phrases actually used while translating .", "label": "", "metadata": {}, "score": "68.17592"}
{"text": "For each subset , a new instance of the PBSMT system has been created , for a total of 200 models .Two hundred experiments have then been run on an independent test set ( of 2,000 sentences , also not included in any other phase of the experiment ) .", "label": "", "metadata": {}, "score": "68.186905"}
{"text": "Among possible methods , two stand out as particularly promising .The first is to generate phrase pairs by using grammatical or various linguistic rules ( e.g. , turning existing entries into new entries , by applying various forms of inflection ) .", "label": "", "metadata": {}, "score": "68.23987"}
{"text": "Performance of an SMT system is a function of the dimension of the training data that can be logarithmic as seen in the previous section .We have modelled this relation in the following way : . of the data as increasing set size .", "label": "", "metadata": {}, "score": "68.25463"}
{"text": "Conclusion .Data - driven solutions to classic AI problems are now commonplace , ranging from computer vision to information retrieval tasks , and machine translation is one of the main successes of this approach .The idea of putting learning systems at the centre of all AI methodologies introduces however the need to understand the properties and limitations of these learning components .", "label": "", "metadata": {}, "score": "68.35514"}
{"text": "\" Test on training set ' ' is a test set selected by the training set for each training set size and no optimization phase .In the \" test on test set ' ' learning curve , there seems to be no significant advantage to using phrases longer than 4 words .", "label": "", "metadata": {}, "score": "68.35695"}
{"text": "The noised probability is obtained as ., ten experiments have been run .In this case , we randomly select two fixed training set sizes equal to 62,995 and 629,957 pairs of sentences form the Europarl corpora and use Moses as translation system .", "label": "", "metadata": {}, "score": "68.39255"}
{"text": "63 - 70 .Bradley Efron and Robert Tibshirani .Bootstrap Methods for Standard Er- rors , Confidence Intervals , and Other Measures of Statistical Accuracy .Statistical Science , 1(1 ) .pp .54 - 77 .George Doddington .", "label": "", "metadata": {}, "score": "68.492004"}
{"text": "Below are some examples of such matches : . of drosophila Kinesin heavy chain attached to , FBgn0001308 , 1 , Y . was analyzed in trajectories with , FBgn0001250 , 5 , N . homeotic gene Ultrabithorax ( ubx , FBgn0013100 , 7 , N .", "label": "", "metadata": {}, "score": "68.50346"}
{"text": "Principle component analysis ( PCA ) can help by reducing dimensionality of high - dimensional features .Collapsing highly correlated features can help learning algorithms run faster .Often , incorrectly implemented machine learning algorithms can appear to work , producing no obvious error , but simply converging slower or with more error than a correct implementation .", "label": "", "metadata": {}, "score": "68.638916"}
{"text": "It has been distinguished between truly unknown words ( or stems ) and unseen forms of known stems .The unknown words are the direct effect of Zipf 's law in a language , as new words can come , but the training set is not flexible enough to cover them .", "label": "", "metadata": {}, "score": "68.70113"}
{"text": "This learning curve reports BLEU score versus the percentage of perturbation applied .These results have been obtained using a fixed training set size equal to 62,995 and 629,957 pairs of sentences and Moses as translation system .Figure 7 : Unlearning curves .", "label": "", "metadata": {}, "score": "68.759186"}
{"text": "1 I is translated into an English phrase .e . i .The English phrases may be reordered .Phrase translation is modeled by a probability distribution \u03c6 ( .f .e . i ) .Recall that due to the Bayes rule , the translation direction is inverted from a modeling standpoint .", "label": "", "metadata": {}, "score": "69.0966"}
{"text": "Compare ... \" .Abstract .In this paper , we present a kernel trick embedded Gaussian Mixture Model ( GMM ) , called kernel GMM .The basic idea is to embed kernel trick into EM algorithm and deduce a parameter estimation algorithm for GMM in feature space .", "label": "", "metadata": {}, "score": "69.21498"}
{"text": "Compare ... \" .Abstract .In this paper , we present a kernel trick embedded Gaussian Mixture Model ( GMM ) , called kernel GMM .The basic idea is to embed kernel trick into EM algorithm and deduce a parameter estimation algorithm for GMM in feature space .", "label": "", "metadata": {}, "score": "69.21498"}
{"text": "Gazetteer lists are often used for the developme ... \" .Abstract - Named entities are perhaps the most important indexing element in text for most of the information extraction and mining tasks .Construction of a Named Entity Recognition ( NER ) system becomes challenging if proper resources are not available .", "label": "", "metadata": {}, "score": "69.23729"}
{"text": "This paper provides a description of TALP - Ngram , the tuple - based statistical machine translation system developed at the TALP Research Center of the UPC ( Universitat Polit\u00e8cnica de Catalunya ) .Briefly , the system performs a log - linear combination of a translation model and additional feature functio ... \" .", "label": "", "metadata": {}, "score": "69.24437"}
{"text": "The underlying log - linear model may be interpreted as a maximum entropy model : . is linear in the log domain , which motivates the description of this framework as \" log - linear model ' ' [ 3 , 4 , 12 ] .", "label": "", "metadata": {}, "score": "69.391846"}
{"text": "Shortcomings of pattern matching .It is rather surprising how well pattern matching can do if used with some care .However , there is something unsettling about this approach .First , several parameters need to be adjusted on the development data .", "label": "", "metadata": {}, "score": "69.64412"}
{"text": "If it is not , it has to solve a frequent / common problem in a very elegant way , something like the Struts does to become the de facto standard .The other aspect is the diversity of the frameworks .", "label": "", "metadata": {}, "score": "69.649376"}
{"text": "Recombining hypothesis is a risk - free way to reduce the search space .Two hypotheses can be recombined if they agree in .the foreign words covered so far .If there are two paths that lead to two hypotheses that agree in these properties , we keep only the cheaper hypothesis , e.g. , the one with the least cost so far .", "label": "", "metadata": {}, "score": "69.71269"}
{"text": "Results on two translation directions are reported , namely from Arabic and Chinese into English , thoroughly explaining all language - related preprocessing and translation schemes .nce , we allow the source words to be reordered before extracting translation units from training sentence pairs by following the word - to - word alignments .", "label": "", "metadata": {}, "score": "69.746124"}
{"text": "Generally , a learning algorithm is said to overfit relative to a simpler one if it is more accurate in fitting known data ( hindsight ) but less accurate in predicting new data ( foresight ) .One can intuitively understand overfitting from the fact that information from all past experience can be divided into two groups : information that is relevant for the future and irrelevant information ( \" noise \" ) .", "label": "", "metadata": {}, "score": "69.94313"}
{"text": "However , most experiments suggest that performance does not change dramatically with different values for the prior .The prior exists primarily to keep weights as close to zero as possible and in all our experiments setting the prior to 1.0 was satisfactory to prevent overfitting .", "label": "", "metadata": {}, "score": "69.97483"}
{"text": "An automatic score measures the quality of machine - translated sentences by comparing them to a set of human translations , called reference sentences .The score needs to be able to discriminate good translations from bad ones , whilst considering aspects such as adequacy and fluency .", "label": "", "metadata": {}, "score": "70.06595"}
{"text": "Only 22 % , 13 % and 47 % of all fly , mouse and yeast genes were ever seen in the training data .This would make it impossible to gather the enough statistics to make accurate predictions .Implementation .", "label": "", "metadata": {}, "score": "70.1156"}
{"text": "This study and its results may help to shed some light on the problem and to develop new methods to improve Arabic verb noun collocability in the output translation of current machine translation engines .\" ORdering ) is an automatic evaluation metric for the machine translation output .", "label": "", "metadata": {}, "score": "70.13762"}
{"text": "The principle of maximum entropy is a powerful framework that can be used to estimate class posterior probabilities for pattern recognition tasks .In this paper , we show how this principle is related to the discriminative training of Gaussian mixture densities using the maximum mutual information criterion .", "label": "", "metadata": {}, "score": "70.17933"}
{"text": "In many resource - poor languages gazetteer lists of proper size are not available , but sometimes relevant lists are available in English .Proper transliteration makes the English lists useful in the NER tasks for such languages .In this paper , we have described a Maximum Entropy based NER system for Hindi .", "label": "", "metadata": {}, "score": "70.231125"}
{"text": "We begin the search in an initial state where no foreign input words are translated and no English output words have been generated .New states are created by extending the English output with a phrasal translation of that covers some of the foreign input words not yet translated .", "label": "", "metadata": {}, "score": "70.2435"}
{"text": "The search for the optimal translation in ( 2 ) is also referred to as decoding as , in the original analogy of the noisy channel , it corresponds to retrieving the clean message ., we usually assume that the feature functions decompose linearly across basic constituents of the sentences .", "label": "", "metadata": {}, "score": "70.44842"}
{"text": "The set of experiments in Figure 7(a ) is harder to explain without discussing the inner workings of the translation model and Moses .Here , we swapped n -grams in the translation table , essentially breaking the connection between words and their translation .", "label": "", "metadata": {}, "score": "70.45867"}
{"text": "[5 ] provide a good introduction to the problem space and present a two staged system that identifies mentions and then labels each mention with a normal form .The focus of their work is on the fly organism .Gene normalization is both easier and harder than identifying gene mentions .", "label": "", "metadata": {}, "score": "70.485245"}
{"text": "In this paper , we present a kernel trick embedded Gaussian Mixture Model ( GMM ) , called kernel GMM .The basic idea is to embed kernel trick into EM algorithm and deduce a parameter estimation algorithm for GMM in feature space .", "label": "", "metadata": {}, "score": "70.53865"}
{"text": "In this paper , we present a kernel trick embedded Gaussian Mixture Model ( GMM ) , called kernel GMM .The basic idea is to embed kernel trick into EM algorithm and deduce a parameter estimation algorithm for GMM in feature space .", "label": "", "metadata": {}, "score": "70.53865"}
{"text": "Similarily an application that uses the process management engine or message broker would require that an implementation of the process management engine and message broker also be present on the other app servers .You simply ca nt take any Portal project ( whether it 's IBM or BEA ) and port it to whichever app server you want .", "label": "", "metadata": {}, "score": "70.632805"}
{"text": "A.1 .Effect of Data Size in Optimization Set .In this section , we study the role of the optimization / development set with regard to the quality of translation .In particular , we analyze how different sizes of the development set affect the performance and the computational cost of the optimization phase .", "label": "", "metadata": {}, "score": "70.68694"}
{"text": "Note that we use the informal concept cost analogous to probability : A high cost is a low probability .Each search state ( hypothesis ) is represented by .a back link to the best previous state ( needed for finding the best translation of the sentence by back - tracking through the search states ) .", "label": "", "metadata": {}, "score": "70.851395"}
{"text": "The language pairs cover European as well as non - European languages , and the sizes range from 1.2 M to 22.5 M sentence pairs .We expect that translation between European languages will be easier than from Chinese to English ; however , we are not so much interested in the actual translation performance as in the way this performance evolves with increasing data and under a number of conditions .", "label": "", "metadata": {}, "score": "70.85164"}
{"text": "A Gaussian prior over weights , with variance tuned to 1.0 on the development data , reduces the danger of overfitting the model to the training data [ 11 ] .The log - likelihood function is concave allowing optimal parameter values to be found by numerical optimization methods .", "label": "", "metadata": {}, "score": "70.865295"}
{"text": "Often , a learning algorithm may fit the training data very well , but perform poorly on new examples .This failure to generalize is called overfitting .The classic example is fitting a high degree polynomial , which can lead to a very curvy line that closely fits a large number of data points .", "label": "", "metadata": {}, "score": "70.89702"}
{"text": "The test set is used to evaluate the quality of models on the data .All experiments using Moses have been run using the default parameter configuration .The training , development , and test set sentences are tokenized and lowercased .", "label": "", "metadata": {}, "score": "71.12059"}
{"text": "Overfitting .Noisy ( roughly linear ) data is fitted to both linear and polynomial functions .Although the polynomial function is a perfect fit , and the linear function misses most of the data points , the linear version can be expected to generalize better .", "label": "", "metadata": {}, "score": "71.13529"}
{"text": "The file system is Ibrix and provides data access from all nodes , with a total of 17 TB of storage .Experiments using Portage are distributed over several CPUs , the total number of which depends on the various stages in the estimation process .", "label": "", "metadata": {}, "score": "71.19523"}
{"text": "One , containing 1,159,914 pairs of sentences , has been used to train the model .This step has been done only once , and all the experiments use the same translation , language , and reordering models .The second set has 100,000 pairs of sentences , and it is used to randomly select the development sets .", "label": "", "metadata": {}, "score": "71.24698"}
{"text": "To be consistent and to avoid anomalies due to overfitting or particular data combinations , each set of pairs of sentences has been randomly sampled .The number of pairs is fixed , and a program selects them randomly from the whole original training , development , or test set using a uniform distribution .", "label": "", "metadata": {}, "score": "71.25446"}
{"text": "The parameters of the model are the feature weights \u03bb i .Ideally one would like the weights of features that tend to be on for correct classifications to be strongly positive , the weights of features that tend on for incorrect classifications to be strongly negative , and the weights of uninformative features to be zero .", "label": "", "metadata": {}, "score": "71.39084"}
{"text": "The name \" model - DRIVING architecture \" would be more accurate .\" Gee , the term drives me mad .\" The industry 's gone through a variety of alternative names for things like MDA , including \" model - integrated computing \" , \" executable models \" , \" model translation \" , \" model compilation \" , \" generative programming \" , and \" recursive design \" .", "label": "", "metadata": {}, "score": "71.74593"}
{"text": "S tag sequence 2 .Figure 2 shows an example of tuple extraction following regular and unfold techniques .Fig .2 .Unfold vs. regular tuple extraction .The N - gram translation model estimated with unfolded units does no ... .", "label": "", "metadata": {}, "score": "71.78"}
{"text": "That 's what I 'm trying to compile and summarize here .Most of Ng 's advice centers around the idea of making decisions in an empirical way , fitting to a data - driven discipline , rather than relying on gut feeling .", "label": "", "metadata": {}, "score": "71.81888"}
{"text": "Their price is also too much and they are selling the product on Weblogic brand name .Once again by just following the market share options , some vendor like BEA fooled around your company management .A right engineer who know the power of Java can easilly build a good web frame work within six months and take to production .", "label": "", "metadata": {}, "score": "71.84214"}
{"text": "The concept of overfitting is important in machine learning .Usually a learning algorithm is trained using some set of training examples ; i.e. , exemplary situations for which the desired output is known .The learner is assumed to reach a state where it will also be able to predict the correct output for other examples , thus generalizing to situations not presented during training ( based on its inductive bias ) .", "label": "", "metadata": {}, "score": "71.8613"}
{"text": "The principle ... \" .The principle of maximum entropy is a powerful framework that can be used to estimate class posterior probabilities for pattern recognition tasks .It is a conceptually simple and easily extensible model that allows to estimate a large number of free parameters reliably .", "label": "", "metadata": {}, "score": "72.03377"}
{"text": "The principle ... \" .The principle of maximum entropy is a powerful framework that can be used to estimate class posterior probabilities for pattern recognition tasks .It is a conceptually simple and easily extensible model that allows to estimate a large number of free parameters reliably .", "label": "", "metadata": {}, "score": "72.03377"}
{"text": "METEOR scores machine translation hypotheses by aligning them to one or more reference translations . \" \" meteor , initially proposed and released in 2004 ( Lavie et al ., 2004 ) was explicitly designed to improve correlation with human judgments of MT quality at the segment level .", "label": "", "metadata": {}, "score": "72.088554"}
{"text": "These sites come from the Canadian government , the European Union , the United Nations , and other international organizations .In addition to covering a wide range of themes , they also contain documents with different styles and genres .We estimate that the rate of misaligned sentence pairs was around 13 % .", "label": "", "metadata": {}, "score": "72.08974"}
{"text": "On the other hand , gene normalization is harder than identifying mentions in that it requires the actual gene to be detected and associated with the organism - specific unique gene identifier .The three organisms under consideration , yeast , fly , mouse , have from thousands to tens of thousands of genes .", "label": "", "metadata": {}, "score": "72.168884"}
{"text": "I actually asked for RUP rational unified process which will help me in building website related to my project , if u know any thing about it then plz reply .RUP is like other developing models such as RAD ( rapid applicatipn develpoment ) .", "label": "", "metadata": {}, "score": "72.21555"}
{"text": "The computed posterior probabilities are furthermore used in the subsequent steps of the retrieval process . by Daniel Keysers , Franz Josef Och , Hermann Ney - In Pattern Recognition , 24th DAGM Symposium , 2002 . \" ...The principle of maximum entropy is a powerful framework that can be used to estimate class posterior probabilities for pattern recognition tasks .", "label": "", "metadata": {}, "score": "72.26903"}
{"text": "Translation of training sentences allows us to estimate the training error .The learning curves in Figure 4 illustrate how the performance is affected by the phrase length .The \" test on test set ' ' curve is less influenced by the phrase length than the \" test on training set ' ' curve .", "label": "", "metadata": {}, "score": "72.315765"}
{"text": "They also provided extensive synonym lists based on resources from the associated model organism databases .Suppressor of Hairless , br7 , C : Group C , RBP JKappa , lethal 7 in the black - reduced region .The problem of gene normalization is relatively new and unexplored .", "label": "", "metadata": {}, "score": "72.5065"}
{"text": "( i ) Unlearning by Adding Noise .A percentage of noise has been added to each probability , . , in the Language model , including conditional probability , and translation model , bidirectional phrase translation probabilities and lexicalized weighting .", "label": "", "metadata": {}, "score": "72.522385"}
{"text": "pp .433- 439 . Y. Akiba , K. Imamura , and E. Sumita .Using Multiple Edit Distances to Automatically Rank Machine Translation Output .In Proceedings of MT Summit VIII .Santiago de Compostela , Spain .pp .15 - 20 . S. Niessen , F. J. Och , G. Leusch , and H. Ney .", "label": "", "metadata": {}, "score": "72.58336"}
{"text": "Google scored a verb - noun collocation value of 0.75 ( 3 % higher than Bing ) with a trend estimation ranging between 0.63 and 0.85 .The results also showed that , in most cases , the Arabic translation output of both engines produced a one verb synonym which did not collocate with the different nouns in the testing data sentences .", "label": "", "metadata": {}, "score": "72.779205"}
{"text": "This can either represent the effect of insufficient statistics in estimating them , or the use of imperfect parameter estimation biases .These parameters are probabilities , phrases , and associations between source / target phrases contained inside translation and language model tables .", "label": "", "metadata": {}, "score": "72.80205"}
{"text": "Particularly , neighbor lists are generated differently for each organism or not at all in the case of yeast .One could easily argue that the method will not generalize well to other organisms .What we really desire is one uniform approach , for all organisms , in which every parameter is automatically set during the training phase .", "label": "", "metadata": {}, "score": "72.87299"}
{"text": "The first is finding those mentions that do not occur as a known synonym in a curated list .The second problem is to determine which unique gene each identified mention refers to .This is correlated with the precision of the system in that some identified mentions may not actually be genes , or might be genes for other organisms or might be ambiguous amongst many genes .", "label": "", "metadata": {}, "score": "72.99922"}
{"text": "Given all these choices how is someone supposed to figure out all of this when you could just buy a solution .Sometimes buying is just much simpler but also because some research analyst has indicated this is more cost effective .", "label": "", "metadata": {}, "score": "73.05533"}
{"text": "Each derived hypothesis is placed in a stack based on the number of foreign words it covers . initialize hypothesisStack[0 .We proceed through these hypothesis stacks , going through each hypothesis in the stack , deriving new hypotheses for this hypothesis and placing them into the appropriate stack ( see figure below for an illustration ) .", "label": "", "metadata": {}, "score": "73.123085"}
{"text": "The possibility of overfitting exists because the criterion used for training the model is not the same as the criterion used to judge the efficacy of a model .In particular , a model is typically trained by maximizing its performance on some set of training data .", "label": "", "metadata": {}, "score": "73.177345"}
{"text": "138 - 145 , Morgan Kaufmann Publishers , San Francisco , Calif , USA , 2002 .S. Banerjee and A. Lavie , \" Meteor : an automatic metric for mt evaluation with improved correlation with human judgments , \" in Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics , Ann Arbor , Mich , USA , 2005 .", "label": "", "metadata": {}, "score": "73.72092"}
{"text": "I do n't know about the rest of you , but I do n't want dummies working on a J2EE project with me .I do n't want some chucklehead who can point and click generating code .I will never get the rationale behind making these sorts of \" click Next 7 times and you have a functional application \" IDEs .", "label": "", "metadata": {}, "score": "73.81508"}
{"text": "Rational even before merging with IBM was in market with tools developed based on universal standards of UML language .In any work place Rational tools never stopped the developers or architects using any vendors application servers or database or operating system .", "label": "", "metadata": {}, "score": "73.84906"}
{"text": "This is a simple means to optimize performance .Usually , this factor is larger than 1 , biasing toward longer output .In summary , the best English output sentence e best given a foreign input sentence f according to our model is .", "label": "", "metadata": {}, "score": "73.86592"}
{"text": "Richer hypothesis classes can fit the training data more accurately but generalize less well than poorer classes , a phenomenon known as overfitting .The choice of the appropriate expressive power , within a parametrized class of models , is called model selection and is one of the most crucial steps in the design of learning systems .", "label": "", "metadata": {}, "score": "74.07959"}
{"text": "e . f . ) , which reflects the probability that phrases .e . and .f . are translation equivalents ; ( ii ) and a joint distribution d(i , j ) , which reflects the probability that a phrase at position i is translated into a phrase at position j .", "label": "", "metadata": {}, "score": "74.242584"}
{"text": "We have undertaken a large scale experimental and theoretical investigation of these questions .We use this data to inform a discussion about learning curves .We have also investigated the model - selection properties of n -gram size , where the n -grams are the phrases used as building blocks in the translation process .", "label": "", "metadata": {}, "score": "74.2682"}
{"text": "During decoding , the foreign input sentence f is segmented into a sequence of I phrases .f .1 I .We assume a uniform probability distribution over all possible segmentations .Each foreign phrase .f .i in .", "label": "", "metadata": {}, "score": "74.34755"}
{"text": "The graph of the hypothesis space can be also be viewed as a probabilistic finite state automaton .The hypotheses are states , and the records of back - links and the additionally stored arcs are state transitions .The added probability scores when expanding a hypothesis are the costs of the state transitions .", "label": "", "metadata": {}, "score": "74.45238"}
{"text": "This is reflected in the two main components of the typical SMT model : the language model and the translation model .The language model is typically built using a table of n -grams , with associated probabilities , which is sufficient to define a Markov chain .", "label": "", "metadata": {}, "score": "74.467735"}
{"text": "This is an active area of research in machine translation [ 35 - 37 ] .The results of the perturbation analysis in Section 5 suggest that the limiting factor in the translation tables is not in the numeric part of the model - the parameters being estimated - but in the phrases contained in it , the entries of the phrase table .", "label": "", "metadata": {}, "score": "74.62521"}
{"text": ", 2004 ; Banerjee and Lavie , 2005 ; Lavie and Agarwal , 2007 ) have described the details underlying the metric and have extensively compared its performance with Bleu and several other MT evaluation metrics .\" [ Show abstract ] [ Hide abstract ] ABSTRACT : We describe our submission to the NIST Met- rics for Machine Translation Challenge consist- ing of 4 metrics - two versions of meteor , m - bleu and m - ter .", "label": "", "metadata": {}, "score": "74.67144"}
{"text": "This allows a quicker lookup than consulting the whole phrase translation table during decoding .The translation options are stored with the information .first foreign word covered .last foreign word covered .English phrase translation .phrase translation probability .", "label": "", "metadata": {}, "score": "74.896515"}
{"text": "Both learning curves show a big improvement when moving from the word - to - word translation ( phrase length equal to one ) to the phrase - based model ( higher phrase lengths ) .Figure 4 : BLEU versus n -gram length .", "label": "", "metadata": {}, "score": "74.93742"}
{"text": "But very few attempts were made to develop transliteration systems for Indian languages to English or other languages .We can mention a transliteration system for ... . \" ... Statistical Machine Translation ( SMT ) is based on alignment models which learn from bilingual corpora the word corre - spondences between source and target lan - guage .", "label": "", "metadata": {}, "score": "75.1971"}
{"text": "For each percentage value , ten experiments have been run .All the perturbations have been applied on a model trained with 629,957 pairs of sentences randomly selected form the Europal data using Moses as translation system .The unlearning curves are shown in Figure 7 .", "label": "", "metadata": {}, "score": "75.36667"}
{"text": "A synonym , s , for a gene , g , is considered informative if and only if for the training set D : .The left - hand - side fraction is the conditional probability of g labeling a document , given that there was a match of s in the document .", "label": "", "metadata": {}, "score": "75.609436"}
{"text": "Software .Several software packages are available for training PBSMT systems .In this work , we use both Moses [ 5 ] and Portage [ 6 ] .Moses is a complete open - source phrase - based translation toolkit for academic purposes , while Portage is a similar package available to partners of the National Research Council Canada .", "label": "", "metadata": {}, "score": "75.69521"}
{"text": "Model representation .The representation of the hypothesis , the function h , defines the space of solutions that your algorithm can find .The example used in the class was modeling house price as a function of size .The model tells you what parameters your algorithm needs to learn .", "label": "", "metadata": {}, "score": "76.01619"}
{"text": "But since we want to keep the information about the path leading from hypothesis 3 to 2 , we store a record of this arc .The arc also contains the cost added from hypothesis 3 to 4 .Note that the cost from hypothesis 1 to hypothesis 2 does not have to be stored , since it can be recomputed from the hypothesis data structures .", "label": "", "metadata": {}, "score": "76.6332"}
{"text": "We have incorporated some gazetteer lists in the system to increase the performance of the system .These lists are collected from the web and are in English .To make these English lists useful in the Hindi NER task , we have proposed a two - phase transliteration methodology .", "label": "", "metadata": {}, "score": "76.777054"}
{"text": "The language model cost is usually calculated by a trigram language model .However , we do not know the preceding English words for a translation operation .Therefore , we approximate this cost by computing the language model score for the generated English words alone .", "label": "", "metadata": {}, "score": "76.86521"}
{"text": "Paths join when hypotheses are recombined .Usually , when we recombine hypotheses , we simply discard the worse hypothesis , since it can not possibly be part of the best path through the search graph ( in other words , part of the best translation ) .", "label": "", "metadata": {}, "score": "76.935936"}
{"text": "It seems that stuff like this , and the BEA Workshop is solely geared towards selling the server to managers who have no other basis for comparison . \"Hey , if my idiot programmers can deploy a J2EE app without knowing J2EE , that sounds great ! \"", "label": "", "metadata": {}, "score": "77.41031"}
{"text": "Who would get abord a plan piloted by someone using \" Teach yourself Airline Piloting in 24 hours \" . :-)You write your application ( Sorry !The wizard writes it ) in 2 weeks instead of 4 however you loose 4 weeks to solve a trivial problem that would take a few hours to solve if you knew the code ...", "label": "", "metadata": {}, "score": "77.63163"}
{"text": "We have created 10 random subsets of the complete Europarl corpus containing 629,957 pairs of sentences .For each subset , ten PBMT systems have been estimated .Each instance of Moses has been trained using a different maximum phrase length , from 1 to 10 .", "label": "", "metadata": {}, "score": "77.95047"}
{"text": "Each entry in the list represents a specific gene and contains both a unique identifier for that gene , called here a normal form , and a set of different ways in which the gene has been or may be mentioned .", "label": "", "metadata": {}, "score": "77.95114"}
{"text": "Fine , click away code towards a solution and I 'm sure most will work .The issue with this audience ( serverside ) is that most are craftmans at hand and just plain prefer perfection .That 's a pretty small audience , it 's like being a mechanic for an indy car , sure you could fix my nova but let me make a few professional enhancements and this thing will be ready for the track .", "label": "", "metadata": {}, "score": "78.19617"}
{"text": "If two words are generated , we take the unigram probability of the first word and the bigram probability of the second word , and so on .For a sequence of foreign words multiple overlapping translation options exist .We just described how we calculate the cost for each translation option .", "label": "", "metadata": {}, "score": "78.38097"}
{"text": "In statistics and machine learning , overfitting occurs when a statistical model describes random error or noise instead of the underlying relationship .Overfitting generally occurs when a model is excessively complex , such as having too many parameters relative to the number of observations .", "label": "", "metadata": {}, "score": "78.39122"}
{"text": "There are a number of Portal , Web Services , BPM Frameworks / Products out in the market place that allow you to deploy to a number of different Vendor 's App servers .That is true however when you think that IBM+BEA+SUN have 70 % of the market , a standard not supported by those companies does n't have an automatic big acceptance .", "label": "", "metadata": {}, "score": "78.54244"}
{"text": "Given the first expanded hypothesis we generate a new hypothesis by translating no with did not .Now the first two foreign words Maria and no are marked as being covered .Following the back pointers of the hypotheses we can read of the ( partial ) translations of the sentence .", "label": "", "metadata": {}, "score": "79.31389"}
{"text": "The proposed transliteration based gazetteer preparation methodology is also applicable for other languages .Apart from Hindi , we have applied the transliteration approach in Bengali NER task and also achieved performance improvement .Index Terms - Gazetteer list preparation , named entity recognition , natural language processing , transliteration .", "label": "", "metadata": {}, "score": "79.416534"}
{"text": "Overfitting / overtraining in supervised learning ( e.g. , neural network ) .Training error is shown in blue , validation error in red , both as a function of the number of training cycles .If the validation error increases(positive slope ) while the training error steadily decreases(negative slope ) then a situation of overfitting may have occurred .", "label": "", "metadata": {}, "score": "79.41962"}
{"text": "This paper describes TALPtuples , the 2007 N - gram - based statistical machine translation system developed at the TALP Research Center of the UPC ( Universitat Polite\u0300cnica de Catalunya ) in Barcelona .Emphasis is put on improvements and extensions of the system of previous years .", "label": "", "metadata": {}, "score": "79.45441"}
{"text": "This paper describes TALPtuples , the 2007 N - gram - based statistical machine translation system developed at the TALP Research Center of the UPC ( Universitat Polite\u0300cnica de Catalunya ) in Barcelona .Emphasis is put on improvements and extensions of the system of previous years .", "label": "", "metadata": {}, "score": "79.45441"}
{"text": "Overfitting occurs when a model begins to \" memorize \" training data rather than \" learning \" to generalize from trend .The potential for overfitting depends not only on the number of parameters and data but also the conformability of the model structure with the data shape , and the magnitude of model error compared to the expected level of noise or error in the data .", "label": "", "metadata": {}, "score": "79.689354"}
{"text": "Thus , the pattern matching system includes a third , and final stage .In it , all punctuation is removed and each token is stemmed with the Porter stemmer [ 8 ] in both the documents and the synonym lists .", "label": "", "metadata": {}, "score": "79.85867"}
{"text": "Our experiments showed that for mouse , the gene tagger used [ 2 ] performed reasonably well on the development data .However , for fly and yeast , the tagger 's performance was less than useful .This is most likely a result of the fact that the tagger training data did not contain enough examples for those organisms .", "label": "", "metadata": {}, "score": "79.86777"}
{"text": "There are n't any good design tools out there IMHO .The whiteboard is still my best friend .Best regards , Bill Willis Director of PatternsCentral \" Where Patterns and People Meet \" .I feel RAD is good for small applications which has perfect design right from the start of the project .", "label": "", "metadata": {}, "score": "80.08804"}
{"text": "They serve to illustrate the effectiveness of stemming in MT evaluation .Page 10 .Acknowledgments This research was funded in part by NSF grant number IIS-0121631 .References 1 .Papineni , Kishore , Salim Roukos , Todd Ward , and Wei - Jing Zhu .", "label": "", "metadata": {}, "score": "80.19156"}
{"text": "You could able to verify this concept easily with an application developed with products such as BEA WorkShop BEA Process Integrator BEA Jam for Mainframe BEA Portal etc .A simple Web Application built on workshop consisting of struts / jsp 's etc . may be ported to another app server , the issue is that when you get into frameworks such as Portal and Process Management , there are no mature standards out there .", "label": "", "metadata": {}, "score": "80.35512"}
{"text": "Although it is widely used , it is still hard to say that Struts is the de - facto standard because there are tens of other frameworks and some of them do a very good job .But when your company blindly go and buy a framework from company like BEA ( BEA portal or integration or jam ) cuz of they have 70 % market share today .", "label": "", "metadata": {}, "score": "80.802155"}
{"text": "BTW : Business requirements .Another term that drives me mad .Picked up a JDO book yesterday ( not bad a book by the first look of it ) .Of course the author stresses that the programmer can concentrate on the business requirements rather than coding persistence .", "label": "", "metadata": {}, "score": "81.44382"}
{"text": "So , which one is going to become a standard ( if any ) ?Apache Struts is ( again ) a good example .Although it is widely used , it is still hard to say that Struts is the de - facto standard because there are tens of other frameworks and some of them do a very good job .", "label": "", "metadata": {}, "score": "81.47072"}
{"text": "I never ever go to deploy that into another application servers from vendors other than BEA .I understand that is something called proprietary approach to design and development of an application .Since BEA doing business in Java language which is default made for build one and deploy anywhere concept , people may think BEA is not into a vendor specific business .", "label": "", "metadata": {}, "score": "81.901886"}
{"text": "The reason for this is that most researchers refer to yeast genes using a standard nomenclature , where each gene is usually mentioned in one of a few known and unambiguous forms .Table 2 shows the performance for the different stages of the system for the fly and mouse organisms .", "label": "", "metadata": {}, "score": "82.381485"}
{"text": "In which alignment does the potential alignment point exist ?Foreign - English or English - foreign ?Does the potential point neighbor already established points ?Does neighboring mean directly adjacent ( block - distance ) , or also diagonally adjacent ?", "label": "", "metadata": {}, "score": "82.38432"}
{"text": "However , these models have some serious draw - backs .Most importantly , they only allow at most one English word to be aligned with each foreign word .To resolve this , some transformations are applied .First , the parallel corpus is aligned bidirectionally , e.g. , Spanish to English and English to Spanish .", "label": "", "metadata": {}, "score": "82.56024"}
{"text": "Final states in the search are hypotheses that cover all foreign words .Among these the hypothesis with the lowest cost ( highest probability ) is selected as best translation .The algorithm described so far can be used for exhaustively searching through all possible translations .", "label": "", "metadata": {}, "score": "82.82919"}
{"text": "It will be difficult to use the tool in this case .The tool in my aspect looks more like ASERA ( can be said as Very much simplified and eased form of ASERA ) but it will be very difficult to port the applications which is build on custom frameworks .", "label": "", "metadata": {}, "score": "83.72014"}
{"text": "TechTarget provides technology professionals with the information they need to perform their jobs - from developing strategy , to making cost - effective purchase decisions and managing their organizations technology projects - with its network of technology - specific websites , events and online magazines .", "label": "", "metadata": {}, "score": "84.75869"}
{"text": "185 - 188 , Prague , Czech Republic , 2007 .P. Koehn , \" Europarl : a parallel corpus for statistical machine translation , \" in Proceedings of the 10 th Machine Translation Summit , pp .79 - 86 , Phuket , Thailand , 2005 .", "label": "", "metadata": {}, "score": "85.028305"}
{"text": "JDO 's pretty cool , though :-) . \" because I am sick of the term MDA .Because with MDA ( as I have seen it , as Booch etc . talked about it ) the model does not ever drive the architecture - it 's the platform and the artefacts predefined for the platform that drive the architecture .", "label": "", "metadata": {}, "score": "85.08152"}
{"text": "Note : Did nt say great though .This depends a lot on the person , some might be great in that time , others might not be that even after 5 years , its all down to their will to learn new skills and put their \" ego \" aside .", "label": "", "metadata": {}, "score": "85.86473"}
{"text": "The two effects interact with richer classes being better approximators of the target behaviour but requiring more training data to reliably identify the best hypothesis .The resulting trade - off , equally well known in statistics and in machine learning , can be expressed in terms of bias versus variance , capacity control , or model selection .", "label": "", "metadata": {}, "score": "87.571335"}
{"text": "However , there are many difficulties with such an approach .The primary problem is that mentions may be ambiguous .For instance , the gene mention alcohol dehydrogenease is a valid synonym for 111 different fly genes .Simply matching alcohol dehydrogenease to all 111 genes would lead to a steep decline in precision ( since the mention is most likely referring to only one specific gene ) .", "label": "", "metadata": {}, "score": "88.829704"}
{"text": "As previously mentioned , many synonyms are ambiguous , either occurring with multiple genes or in contexts where no gene mentions are present .For instance , blink , with and weak are all listed in the fly synonym list .Matches to these common English words will most likely not constitute actual gene mentions .", "label": "", "metadata": {}, "score": "89.88466"}
{"text": "The result was that the number of total synonyms was reduced from 99501 to 4029 for fly , 130548 to 2898 for mouse and 14756 to 2307 for yeast .This reduction is substantial , since , as Table 2 indicates , it resulted in an absolute increase in f - measure of 50 % for fly and 27 % for mouse .", "label": "", "metadata": {}, "score": "90.49063"}
{"text": "Acknowledgements .The authors would like to thank Seth Kulick , Mark Liberman , Mark Mandel , Andy Schein , Scott Winters and Pete White for useful discussions and guidance .We are also very appreciative of Andrew McCallum for making an early version of MALLET available to us .", "label": "", "metadata": {}, "score": "92.90028"}
{"text": "However , in practice , gene mentions vary widely and evolve over time .Table 1 contains a few entries of the synonym list for the fly organism .To facilitate gene normalization research , the organizers of BioCreative [ 4 ] have made available a number of abstract / normalized - list pairs for three different organisms : fly , mouse and yeast .", "label": "", "metadata": {}, "score": "93.53679"}
{"text": "The Europarl corpus contains material extracted from the proceedings of the European parliament , and the UN data contains material from the United Nations .Both therefore cover a wide range of themes , but are fairly homogeneous in terms of style and genre .", "label": "", "metadata": {}, "score": "93.91849"}
{"text": "Edmonton , Canada .May 2003 .pp .102 - 109 .Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .", "label": "", "metadata": {}, "score": "93.92837"}
{"text": "Starting from the initial hypothesis , the first expansion is the foreign word Maria , which is translated as Mary .The foreign word is marked as translated ( marked by an asterisk ) .We may also expand the initial hypothesis by translating the foreign word bruja as witch .", "label": "", "metadata": {}, "score": "111.61456"}
{"text": "Copyright \u00a9 2012 Marco Turchi et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "122.67746"}
