{"text": "The resulting grammars are extremely compact com- pared to other high - performance parsers , yet the parser gives the best published accuracies on several languages , as well as the best generative parsing numbers in English .In addi- tion , we give an associated coarse - to - fine inference scheme which vastly improves inference time with no loss in test set accuracy .", "label": "", "metadata": {}, "score": "28.06926"}
{"text": "However , it seems reasonable to expect that the usefulness of the models trained using LinkSet would be limited by its ability to assign meaningful correspondences between the English and foreign versions of a training sentence .Inducing a Monolingual Parser through Bilingual Parsing .", "label": "", "metadata": {}, "score": "29.012913"}
{"text": "Here is a concise summary of the conclusions detailed in the chapters above : .A statistical model of the relationship between the syntactic structures of two different languages can be effectively learned from a bilingual corpus by an unsupervised learning technique , even when syntactic annotations are available for only one of the languages .", "label": "", "metadata": {}, "score": "29.931618"}
{"text": "To test this ability to quickly build a working parser for a foreign language , we used two bilingual corpora ( French -- English and Chinese -- English ) to automatically build monolingual parsers for French and Chinese .We then tested these parsers by parsing test sets in each language , and comparing the structures assigned by the new parsers against hand - bracketings of the same test sentences .", "label": "", "metadata": {}, "score": "30.34694"}
{"text": "However , current tree - based systems suffer from a major drawback : they only use the 1-best pa ... \" .Among syntax - based translation models , the tree - based approach , which takes as input a parse tree of the source sentence , is a promising direction being faster and simpler than its string - based counterpart .", "label": "", "metadata": {}, "score": "30.805706"}
{"text": "However , current tree - based systems suffer from a major drawback : they only use the 1-best pa ... \" .Among syntax - based translation models , the tree - based approach , which takes as input a parse tree of the source sentence , is a promising direction being faster and simpler than its string - based counterpart .", "label": "", "metadata": {}, "score": "30.805706"}
{"text": "A new method of inducing a parser for a foreign language given a bilingual corpus and an English parser , implemented as a combination of the Lynx and LinkSet parsers .A new method of incorporating syntactic structure into a statistical translation model , demonstrated by reranking decoder outputs using the Lynx and LinkSet parsers .", "label": "", "metadata": {}, "score": "30.852905"}
{"text": "Bilingual Parsing .When given a bilingual corpus where a parser is already available for the opposite language ( such as English ) , this could be done in principle by word - aligning the corpus and ' ' copying ' ' the structure across the alignments .", "label": "", "metadata": {}, "score": "31.028624"}
{"text": "While previous work has focused primarily on English , we extend these results to other languages along two dimensions .First , we show th ... \" .It has been established that incorporating word cluster features derived from large unlabeled corpora can significantly improve prediction of linguistic structure .", "label": "", "metadata": {}, "score": "32.656403"}
{"text": "Combining multiple grammars that were self - trained on disjoint sets of unlabeled data results in a final test accuracy of 92.5\\% on the WSJ test set and 89.6\\% on our Broadcast News test set .This work shows how to improve state - of - the - art monolingual natural language processing models using unannotated bilingual text .", "label": "", "metadata": {}, "score": "32.821236"}
{"text": "The ontology - based parser incorporates both a system and method for converting natural - language text into predicate - argument format that can be easily used by a variety of applications , including search engines , summarization applications , categorization applications , and word processors .", "label": "", "metadata": {}, "score": "33.110516"}
{"text": "However , our case study suggests that for any particular language pair , progress could quickly be made from a quick and dirty induced parser to a higher - quality parser through focused incremental improvements such as the one we have demonstrated .", "label": "", "metadata": {}, "score": "33.22947"}
{"text": "In principle , these models of English sentence structure and of foreign sentence structure given English sentence structure can be composed to generate a model of foreign sentence structure Pr(F ) , which can then be used to parse foreign sentences monolingually .", "label": "", "metadata": {}, "score": "33.50135"}
{"text": "No .4,887,212 to Zamora et al . discloses a parser for syntactic analysis of text using a fast and compact technique .After part - of - speech tagging and disambiguation , syntactic analysis occurs in four steps .The grammar of Zamora et al . operates by making multiple passes to guess at noun phrases and verb phrases and then attempts to reconcile the results .", "label": "", "metadata": {}, "score": "33.679985"}
{"text": "To parse a sentence is to resolve it into its component parts and describe its grammatical structure .Applications that benefit from syntactic parsing include corpus analysis , question answering , natural - language command execution , rule - based automatic translation , and summarization .", "label": "", "metadata": {}, "score": "33.885136"}
{"text": "Integrating syntax structure into the statistical models used for automatic translation can increase the quality of translated output .The use of syntax - based models significantly improves the overall ranking of hypotheses according to the standard NIST evaluation of each hypothesis .", "label": "", "metadata": {}, "score": "34.247505"}
{"text": "Our method does not assume any knowledge about the target language ( in particular no tagging dictionary is assumed ) , making it applicable to a wide array of resource - poor languages .We use graph - based label propagation for cross - lingual knowledge transfer and use the projected labels as features in an unsupervised model ( Berg - Kirkpatrick et al .", "label": "", "metadata": {}, "score": "34.51855"}
{"text": "While many translation systems use phrase - to - phrase alignment , these approaches typically deal only with contiguous phrases .As our experiment shows , a simple extension to the LinkSet model can enable it to handle discontiguous phrases .( While a relatively straightforward extension of the LinkSet model , it is still significant enough a change to be implemented with a quick fix to the existing code base ; hence the narrowly focused experiment . )", "label": "", "metadata": {}, "score": "34.58361"}
{"text": "In an ordinary syntactic parser , the input is a string , and the grammar ranges over strings .This paper explores generalizations of ordinary parsing algorithms that allow the input to consist of string tuples and/or the grammar to range over string tuples .", "label": "", "metadata": {}, "score": "34.59933"}
{"text": "In an ordinary syntactic parser , the input is a string , and the grammar ranges over strings .This paper explores generalizations of ordinary parsing algorithms that allow the input to consist of string tuples and/or the grammar to range over string tuples .", "label": "", "metadata": {}, "score": "34.59933"}
{"text": "In an ordinary syntactic parser , the input is a string , and the grammar ranges over strings .This paper explores generalizations of ordinary parsing algorithms that allow the input to consist of string tuples and/or the grammar to range over string tuples .", "label": "", "metadata": {}, "score": "34.59933"}
{"text": "In an ordinary syntactic parser , the input is a string , and the grammar ranges over strings .This paper explores generalizations of ordinary parsing algorithms that allow the input to consist of string tuples and/or the grammar to range over string tuples .", "label": "", "metadata": {}, "score": "34.59933"}
{"text": "An ontology - based parser incorporates both a system and method for converting natural - language text into predicate - argument format that can be easily used by a variety of applications , including search engines , summarization applications , categorization applications , and word processors .", "label": "", "metadata": {}, "score": "34.70736"}
{"text": "Training this model with a bilingual corpus , we will test its ability to align sentences by comparing the most probable alignments according to the model , as compared to human - annotated alignments .Finally , we will use these models together in two different ways .", "label": "", "metadata": {}, "score": "34.973846"}
{"text": "Such corpora are not usually available anyway , especially if the two languages must be annotated using the same formalism .Solving these would allow us to build both a parser for the foreign language and a statistical translation system between that language and English that takes into account the syntactic structure of each sentence .", "label": "", "metadata": {}, "score": "35.190193"}
{"text": "Unlike existing preordering models , we train feature - rich discriminative classifiers that directly predict the target - side word order .Our approach combines the strengths of lexical reordering and syntactic preordering models by performing long - distance reorderings using the structure of the parse tree , while utilizing a discriminative model with a rich set of features , including lexical features .", "label": "", "metadata": {}, "score": "35.209625"}
{"text": "We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .", "label": "", "metadata": {}, "score": "35.262043"}
{"text": "We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .", "label": "", "metadata": {}, "score": "35.262043"}
{"text": "We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .", "label": "", "metadata": {}, "score": "35.262043"}
{"text": "We compare the performance of three statistical parsing architectures on the problem of deriving typed dependency structures for French .The architectures are based on PCFGs with latent variables , graph - based dependency parsing and transition - based dependency parsing , respectively .", "label": "", "metadata": {}, "score": "35.262043"}
{"text": "( Others have induced more basic text analysis tools . )No knowledge was used except for the sentence - alignment of the corpus and the original English parser ; given these resources , the building of a foreign - language parser was completely unsupervised .", "label": "", "metadata": {}, "score": "35.292446"}
{"text": "Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .The wide availability of parallel text and accurate parsers in English has opened up the possibility of grammar induction through partial transfer across bitext .", "label": "", "metadata": {}, "score": "35.314796"}
{"text": "Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .The wide availability of parallel text and accurate parsers in English has opened up the possibility of grammar induction through partial transfer across bitext .", "label": "", "metadata": {}, "score": "35.314796"}
{"text": "has a complicated analysis , and can not afford semantic status to each word relative to all the other words within the dictionary .The Kucera et al . system uses three parsing stages , each of which needs more than one pass through the sentence to complete its analysis .", "label": "", "metadata": {}, "score": "35.448814"}
{"text": "In our experiments on Chineseto - English translation , this MaxEnt - based reordering model obtains significant improvements in BLEU score on the NIST MT-05 and IWSLT-04 tasks . ... the reorderings of phrases , but also integrates some phrasal generalizations into the global model .", "label": "", "metadata": {}, "score": "35.47152"}
{"text": "In our experiments on Chineseto - English translation , this MaxEnt - based reordering model obtains significant improvements in BLEU score on the NIST MT-05 and IWSLT-04 tasks . ... the reorderings of phrases , but also integrates some phrasal generalizations into the global model .", "label": "", "metadata": {}, "score": "35.47152"}
{"text": "Starting with a simple Xbar grammar , we learn a new grammar whose nonterminals are subsymbols of the original nonterminals .In co ... \" .We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .", "label": "", "metadata": {}, "score": "35.58824"}
{"text": "This paper presents novel improvements to the induction of translation lexicons from monolingual corpora using multilingual dependency parses .We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative ... \" .", "label": "", "metadata": {}, "score": "35.69427"}
{"text": "This paper presents novel improvements to the induction of translation lexicons from monolingual corpora using multilingual dependency parses .We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative ... \" .", "label": "", "metadata": {}, "score": "35.69427"}
{"text": "We will test this new parser by comparing its accuracy in bracketing unseen foreign sentences with respect to human - annotated bracketings .Second , we will enhance an automatic translation system by using these structured models to reevaluate the hypotheses it generates , comparing the resulting translations against the original system 's output using standard evaluation metrics such as the BLEU and NIST scores .", "label": "", "metadata": {}, "score": "35.798058"}
{"text": "The system consists of two components : an unlabeled dependency parser using Gibbs sampling which can incorporate sentence - level ( global ) features as well as token - leve ... \" .In this paper , we describe a two - stage multilingual dependency parser used for the multilingual track of the CoNLL 2007 shared task .", "label": "", "metadata": {}, "score": "35.816277"}
{"text": "The system consists of two components : an unlabeled dependency parser using Gibbs sampling which can incorporate sentence - level ( global ) features as well as token - leve ... \" .In this paper , we describe a two - stage multilingual dependency parser used for the multilingual track of the CoNLL 2007 shared task .", "label": "", "metadata": {}, "score": "35.816277"}
{"text": "The exact definition of this specialized grammar is conceptualized as a series of transformations applied to the English structure to arrive at the foreign structure .These transformations constrain the range of structures considered possible for the foreign sentence .Then word - to - word translation probabilities to generate the actual foreign sentence from the transformed English one assign a probability to each possible structure , allowing the most probable to be selected .", "label": "", "metadata": {}, "score": "35.862144"}
{"text": "All applications making use of the fact that the output of the ontology - based parser is an ontological entity may realize enormous speed benefits from the parameterized ontology that the parser utilizes .The present system imposes a logical structure on text , and a semantic representation is the form used for storage .", "label": "", "metadata": {}, "score": "35.875313"}
{"text": "First , we automatically induce a parser for a foreign language across a bilingual corpus .Then we improve the output of an automatic translation system by incorporating syntactic structure into its translation and language models .Thesis Statement .My thesis statement has 4 parts : .", "label": "", "metadata": {}, "score": "36.199356"}
{"text": "Finally , we present multilingual experiments which show that parsing with hierarchical state - splitting is fast and accurate in multiple languages and domains , even without any language - specific tuning . ... g ( Matsuzaki et al . , 2005 ; Petrov et al . , 2006 ) .", "label": "", "metadata": {}, "score": "36.276882"}
{"text": "A third advantage of this technique is its versatility .Training data for a statistical parser could come not only from a single existing parser , but from various sources , if desired .For example , a few hand - coded examples could be added to introduce a new grammatical construct not found in the original parser , or the output of two or three parsers with different strengths and weaknesses could be combined to produce a new parser that combines their strengths .", "label": "", "metadata": {}, "score": "36.388824"}
{"text": "We apply this idea to dependency and constituent parsing , generating results that surpass state - of - theart ... \" .We present a novel parser combination scheme that works by reparsing input sentences once they have already been parsed by several different parsers .", "label": "", "metadata": {}, "score": "36.416862"}
{"text": "Specifically , we extend the method recently proposed by T\u00e4ckstr\u00f6m et al .( 2012 ) , which is based on cross - lingual word cluster features .First , we show that by using multiple source languages , combined with sel ... \" .", "label": "", "metadata": {}, "score": "36.493244"}
{"text": "Despite its simplicity , a product of eight automatically learned grammars improves parsing accuracy from 90.2 % to 91.8 % on English , and from 80.3 % to 84.5 % on German .Pruning can massively accelerate the computation of feature expectations in large models .", "label": "", "metadata": {}, "score": "36.599358"}
{"text": "This paper describes the application of discriminative reranking techniques to the problem of machine translation .For each sentence in the source language , we obtain from a baseline statistical machine translation system , a ranked nbest list of candidate translations in the target language .", "label": "", "metadata": {}, "score": "36.732243"}
{"text": "This paper describes the application of discriminative reranking techniques to the problem of machine translation .For each sentence in the source language , we obtain from a baseline statistical machine translation system , a ranked nbest list of candidate translations in the target language .", "label": "", "metadata": {}, "score": "36.732243"}
{"text": "We generalize the evaluation to other word - types , and show that the performance can be increased to 18 % relative by preserving part - of - speech equivalencies during translation .We further differentiate ourselves from previous work by conducting a second evaluation which examines the accuracy of translating all word types , rather than just nouns .", "label": "", "metadata": {}, "score": "36.754097"}
{"text": "We generalize the evaluation to other word - types , and show that the performance can be increased to 18 % relative by preserving part - of - speech equivalencies during translation .We further differentiate ourselves from previous work by conducting a second evaluation which examines the accuracy of translating all word types , rather than just nouns .", "label": "", "metadata": {}, "score": "36.754097"}
{"text": "( Alshawi et al . , 2000 ) represents each production in parallel dependency trees as a finite - state tr ... . \" ...This paper describes the application of discriminative reranking techniques to the problem of machine translation .For each sentence in the source language , we obtain from a baseline statistical machine translation system , a ranked nbest list of candidate translations in the target language .", "label": "", "metadata": {}, "score": "36.764694"}
{"text": "( Alshawi et al . , 2000 ) represents each production in parallel dependency trees as a finite - state tr ... . \" ...This paper describes the application of discriminative reranking techniques to the problem of machine translation .For each sentence in the source language , we obtain from a baseline statistical machine translation system , a ranked nbest list of candidate translations in the target language .", "label": "", "metadata": {}, "score": "36.764694"}
{"text": "The design of the ontology - based parser is based on the premise that predicate structures represent a convenient approach to searching through text .Predicate structures constitute the most compact possible representation for the relations between grammatical entities .Most of the information required to construct predicates does not need to be stored , and once the predicates have been derived from a document , the predicates may be stored as literal text strings , to be used in the same way .", "label": "", "metadata": {}, "score": "36.794147"}
{"text": "We consider generative and di ... \" .Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .The wide availability of parallel text and accurate parsers in English has opened up the possibility of grammar induction through partial transfer across bitext .", "label": "", "metadata": {}, "score": "36.816193"}
{"text": "A statistical model of the relationship between the syntactic structures of two different languages can be effectively learned from a bilingual corpus by an unsupervised learning technique , even when syntactic annotations are available for only one of the languages .Using a bilingual corpus and an existing parser in one language , a new parser can be automatically induced for the other language , without the aid of a language expert .", "label": "", "metadata": {}, "score": "36.94451"}
{"text": "Additionally , semantic feature compatibility checking is not possible with Jensen 's system .U.S. Pat .No .5,721,938 to Stuckey discloses a parsing technique , which organizes natural language into symbolic complexes , which treat all words as either nouns or verbs .", "label": "", "metadata": {}, "score": "37.001022"}
{"text": "Unlike previous work on projecting syntactic resources , we show that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers .The projected parsers from our system result in state - of - the - art performance when compared to previously studied unsupervised and projected parsing systems across eight different languages .", "label": "", "metadata": {}, "score": "37.021706"}
{"text": "The method first searches for hierarchical alignments of the training examples guided by correlation statistics , and then constructs the transitions of head transducers that are consistent with these alignments .Experimental results are given for applying the training method to translation from English to Spanish and Japanese . by Haitao Mi , Liang Huang , Qun Liu - In Proceedings of ACL-08 : HLT , 2008 . \" ...", "label": "", "metadata": {}, "score": "37.15751"}
{"text": "The method first searches for hierarchical alignments of the training examples guided by correlation statistics , and then constructs the transitions of head transducers that are consistent with these alignments .Experimental results are given for applying the training method to translation from English to Spanish and Japanese . by Haitao Mi , Liang Huang , Qun Liu - In Proceedings of ACL-08 : HLT , 2008 . \" ...", "label": "", "metadata": {}, "score": "37.15751"}
{"text": "Specifically , we extend the method recently proposed by T\u00e4ckstr\u00f6m et al .( 2012 ) , which is based on cross - lingual word cluster features .First , we show that by using multiple source languages , combined with self - training for target language adaptation , we can achieve significant improvements compared to using only single source direct transfer .", "label": "", "metadata": {}, "score": "37.15972"}
{"text": "Using statistical machine translation techniques , a semantic parser based on a synchronous context - free grammar augmented with \u03bb - operators is learned given a set of training sentences and their correct logical forms .The resulting parser is shown to be the best - performing system so far in a database query domain . \" ...", "label": "", "metadata": {}, "score": "37.211872"}
{"text": "Using statistical machine translation techniques , a semantic parser based on a synchronous context - free grammar augmented with \u03bb - operators is learned given a set of training sentences and their correct logical forms .The resulting parser is shown to be the best - performing system so far in a database query domain . \" ...", "label": "", "metadata": {}, "score": "37.211872"}
{"text": "In co ... \" .We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .Starting with a simple Xbar grammar , we learn a new grammar whose nonterminals are subsymbols of the original nonterminals .", "label": "", "metadata": {}, "score": "37.319786"}
{"text": "We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .Starting with a simple Xbar grammar , we learn a new grammar whose nonterminals are subsymbols of the original nonterminals .", "label": "", "metadata": {}, "score": "37.55079"}
{"text": "This is identical to the sentence produced above , and results in the same parse tree , and the same predicate structure .Thus , when the ontological parser in this example embodiment receives this question , it generates a predicate identical to that from a declarative sentence , and they can be matched .", "label": "", "metadata": {}, "score": "37.619442"}
{"text": "Until now , however , such conversion schemes have been created manually ... \" .We present an automatic method for mapping language - specific part - of - speech tags to a set of universal tags .This unified representation plays a crucial role in cross - lingual syntactic transfer of multilingual dependency parsers .", "label": "", "metadata": {}, "score": "37.7439"}
{"text": "Combine the new scores with those from the translation system .Rank the hypothesis list by the interpolated scores .The top - ranked candidate is now output as the English translation of the foreign sentence .To test this idea , we trained the Lynx and LinkSet parsers using a Chinese -- English corpus , and used an existing statistical translation system to generate 100-best lists of English translations for another corpus of Chinese sentences , for each of which four reference translations were available .", "label": "", "metadata": {}, "score": "37.752117"}
{"text": "In our method the first , monolingual view consists of supervised predictors learned separately for each language .The second , bilingual view consists of log - linear predictors learned over both languages on bilingual text .Our training procedure estimates the parameters of the bilingual model using the output of the monolingual model , and we show how to combine the two models to account for dependence between views .", "label": "", "metadata": {}, "score": "37.912735"}
{"text": "The parser converts the sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the sentence , and then applies rules to it that bind arguments into predicates .Ontological parsing is a grammatical analysis technique built on the proposition that the most useful information that can be extracted from a sentence is the set of concepts within it , as well as their formal relations to each other .", "label": "", "metadata": {}, "score": "38.079613"}
{"text": "As long as grammatical roles can be identified , the present system and method can be easily adapted to any language .For example , certain case - marked languages , such as Japanese or German , can be parsed through a grammar which simply records the grammatical relationships encoded by particular markers , and the resulting output is still compatible with the parsing results achieved for other languages .", "label": "", "metadata": {}, "score": "38.257767"}
{"text": "The data is transformed using a syntactic parser and ontology .The ontology is used as a lexical resource .The output that results is also an ontological entity with a structure that matches the organization of concepts in natural language .", "label": "", "metadata": {}, "score": "38.261864"}
{"text": "The data is transformed using a syntactic parser and ontology .The ontology is used as a lexical resource .The output that results is also an ontological entity with a structure that matches the organization of concepts in natural language .", "label": "", "metadata": {}, "score": "38.261864"}
{"text": "We consider the problem of using a bilingual dictionary to transfer lexico - syntactic information from a resource - rich source language to a resource - poor target language .In contrast to past work that used bitexts to transfer analyses of specific sentences at the token level , we instead use features to transfer the behavior of words at a type level .", "label": "", "metadata": {}, "score": "38.324528"}
{"text": "Therefore reordering can be modelled as a problem ofsclassification with ... . \" ...This paper presents the first empirical results to our knowledge on learning synchronous grammars that generate logical forms .Using statistical machine translation techniques , a semantic parser based on a synchronous context - free grammar augmented with \u03bb - operators is learned given a set of training ... \" .", "label": "", "metadata": {}, "score": "38.34384"}
{"text": "Therefore reordering can be modelled as a problem ofsclassification with ... . \" ...This paper presents the first empirical results to our knowledge on learning synchronous grammars that generate logical forms .Using statistical machine translation techniques , a semantic parser based on a synchronous context - free grammar augmented with \u03bb - operators is learned given a set of training ... \" .", "label": "", "metadata": {}, "score": "38.34384"}
{"text": "The ontology - based parser is designed around the idea that predicate structures represent a convenient approach to searching through text .Predicate structures constitute the most compact possible representation for the relations between grammatical entities .Most of the information required to construct predicates does not need to be stored , and once the predicates have been derived from a document , the predicates may be stored as literal text strings , to be used in the same way .", "label": "", "metadata": {}, "score": "38.41979"}
{"text": "This limits the versatility of the techniques .U.S. Pat .No .4,864,502 to Kucera et al . discloses a device that tags and parses natural - language sentences , and provides interactive facilities for grammar correction by an end user .", "label": "", "metadata": {}, "score": "38.454136"}
{"text": "We highlight the use of this resource via two experiments , including one that reports competitive accuracies for unsupervised grammar induction without gold standard part - of - speech tags .We present an online learning algorithm for training structured prediction models with extrinsic loss functions .", "label": "", "metadata": {}, "score": "38.45586"}
{"text": "For example , noun phrases might be split into subcategories for subjects and objects , singular and plural , and so on .This splitting process admits an efficient incremental inference scheme which reduces parsing times by orders of magnitude .Furthermore , it produces the best parsing accuracies across an array of languages , in a fully language - general fashion .", "label": "", "metadata": {}, "score": "38.49192"}
{"text": "In order to build a statistical translation system that accurately models the hierarchical structure of natural language , it would be very useful to be able to train a model of a structured foreign sentence given a structured English sentence .This would require designing a model capable of capturing the relevant features of the relationship between structures in two languages .", "label": "", "metadata": {}, "score": "38.638905"}
{"text": "Our central hypothesis is that a valid mapping yields POS annotations with coherent linguistic properties which are consistent across source and target languages .We encode this intuition in an objective function that captures a range of distributional and typological characteristics of the derived mapping .", "label": "", "metadata": {}, "score": "38.666374"}
{"text": "We present experiments with sequence models on part - of - speech tagging and named entity recognition tasks , and with syntactic parsers on dependency parsing and machine translation reordering tasks .Low - latency solutions for syntactic parsing are needed if parsing is to become an integral part of user - facing natural language applications .", "label": "", "metadata": {}, "score": "38.84916"}
{"text": "The overview above serves as an outline of this thesis .We will first introduce a model of English sentence structure , along with a method for using it to parse English sentences .Using training data derived from an existing parser , we will train the model , and then test this new statistical parser by comparing its ability to bracket sentence constituents with that of the other parser , as measured against human - annotated bracketings .", "label": "", "metadata": {}, "score": "38.856716"}
{"text": "We show that the automatically induced latent variable grammars of Petrov et al .2006 vary widely in their underlying representations , depending on their EM initialization point .We use this to our advantage , combining multiple automatically learned grammars into an unweighted product model , which gives significantly improved performance over state - of - the - art individual grammars .", "label": "", "metadata": {}, "score": "38.87307"}
{"text": "Unlike previous work , our final model does not require any additional resources at run - time .Compared to a state - of - the - art approach , we achieve more than 20 % relative error reduction .Additionally , we annotate a corpus of search queries with part - of - speech tags , providing a resource for future work on syntactic query analysis .", "label": "", "metadata": {}, "score": "38.910248"}
{"text": "Our results demonstrate that automatically induced mappings rival the quality of their manually designed counterparts when evaluated in the context of multilingual parsing . ...2005 ; Burkett and Klein , 2008 ) .These approaches assume access to a common input representation in the form of universal tags , which enables the model to connect patterns observed in the source language to th ... . \" ...", "label": "", "metadata": {}, "score": "39.022697"}
{"text": "However , the intended output of the parser is the set of predicate structures that it builds for each sentence , and so the preferred parse tree receiver is a software module called a parse tree converter , which extracts predicate structures from the parse trees .", "label": "", "metadata": {}, "score": "39.214954"}
{"text": "We provide experimental results on the NIST 2003 Chinese - English large data track evaluation .We also provide theoretical analysis of our algorithms and experiments that verify that our algorithms provide state - of - theart performance in machine translation . ... ectively .", "label": "", "metadata": {}, "score": "39.421646"}
{"text": "We provide experimental results on the NIST 2003 Chinese - English large data track evaluation .We also provide theoretical analysis of our algorithms and experiments that verify that our algorithms provide state - of - theart performance in machine translation . ... ectively .", "label": "", "metadata": {}, "score": "39.421646"}
{"text": "With this combined model , the best translation of a foreign sentence f can in principle be found .In practice , the sum over all English structures and over all foreign structures consistent with the given foreign sentence is infeasible to calculate .", "label": "", "metadata": {}, "score": "39.4657"}
{"text": "We present several improvements to unlexicalized parsing with hierarchically state - split PCFGs .First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar without a treebank .", "label": "", "metadata": {}, "score": "39.468346"}
{"text": "However , it can be approximated .Once we build a model of foreign structure , we can parse foreign sentences the same way we do English : .Following the noisy - channel interpretation of statistical translation that has become standard , we pretend that the foreign sentence f is a transformed version of some ' ' original ' ' English sentence e .", "label": "", "metadata": {}, "score": "39.704952"}
{"text": "The second method is to perform research from the ground up in defining an ontology , assigning elements on an as - needed basis .Since minimal representation size is a main goal of parameterizing the ontology , one would want to eliminate many of the redundancies found in general - purpose ontologies such as WordNet .", "label": "", "metadata": {}, "score": "39.788017"}
{"text": "The parser of the Stuckey system is only suitable for grammar - checking applications .U.S. Pat .No .5,960,384 to Brash discloses a parsing method and apparatus for symbolic expressions of thought such as English - language sentences .The parser of the Brash system assumes a strict compositional semantics , where a sentence 's interpretation is the sum of the lexical meanings of nearby constituents .", "label": "", "metadata": {}, "score": "39.79044"}
{"text": "Integrating syntax structure into the statistical models used for automatic translation can increase the quality of translated output .Overview .This section gives a high - level theoretical overview of the models developed throughout this thesis .Beginning with the structural model of English sentences used in the Lynx parser we then introduce the model of the relationship between English and a foreign language used in the LinkSet bilingual parser .", "label": "", "metadata": {}, "score": "39.872627"}
{"text": "In all four cases , the LinkSet bilingual parser was able to align the words of bilingual sentence pairs significantly better than a baseline technique which took the most probable alignment according to the word - translation model without any structural information .", "label": "", "metadata": {}, "score": "39.883614"}
{"text": "They also have the advantage of being easier to build and to customize , because they do not require the work of a language expert to carefully design a grammar and patiently encode a dictionary .Instead , given an appropriate framework , all but the most basic grammar rules can be learned automatically from data , resulting in a huge savings in time and effort , especially if an existing parsing system is being ported to a new language or domain .", "label": "", "metadata": {}, "score": "39.954056"}
{"text": "We present several models to this end ; in particular a partially observed conditional random field model , where coupled token and type constraints provide a partial signal for training .Averaged across eight previously studied Indo - European languages , our model achieves a 25 % relative error reduction over the prior state of the art .", "label": "", "metadata": {}, "score": "39.98664"}
{"text": "Thus a rule - based parser can be parlayed into a new parser with all the advantages of a statistical technique , without the need for a language expert .However , this technique has several advantages .Statistical parsing is more robust than rule - based methods , and can respond to difficult inputs with graceful degradation rather than sudden failure .", "label": "", "metadata": {}, "score": "40.078796"}
{"text": "In addition , our discriminative approach integrally admits features beyond local tree configurations .We present a multi - scale training method along with an efficient CKY - style dynamic program .On a variety of domains and languages , this method produces the best published parsing accuracies with the smallest reported grammars .", "label": "", "metadata": {}, "score": "40.111374"}
{"text": "The model is formally a latent variable CRF grammar over trees , learned by iteratively splitting grammar productions ( not categories ) .Different regions of the grammar are refined to different degrees , yielding grammars which are three orders of magnitude smaller than the single - scale baseline and 20 times smaller than the split - and - merge grammars of Petrov et al .", "label": "", "metadata": {}, "score": "40.11666"}
{"text": "First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar without a treebank .In our experiments , hierarchical pruning greatly accelerates parsing with no loss in empirical accuracy .", "label": "", "metadata": {}, "score": "40.150406"}
{"text": "First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar without a treebank .In our experiments , hierarchical pruning greatly accelerates parsing with no loss in empirical accuracy .", "label": "", "metadata": {}, "score": "40.150406"}
{"text": "No .5,386,406 to Hedin et al . discloses a system for converting natural - language expressions into a language - independent conceptual schema .The output of the Hedin et al . system is not suitable for use in a wide variety of applications ( e.g. machine translation , document summarization , categorization ) .", "label": "", "metadata": {}, "score": "40.20725"}
{"text": "The system and method of the present invention isolates predicate - argument relationships into a consistent format regardless of text types .The predicate - argument relationships can be used in search , grammar - checking , summarization , and categorization applications , among others .", "label": "", "metadata": {}, "score": "40.229877"}
{"text": "We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .We apply the framework to word segmentation , joint segmentation and POStagging , dependency parsing , and phrase - structure parsing .", "label": "", "metadata": {}, "score": "40.33755"}
{"text": "We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .We apply the framework to word segmentation , joint segmentation and POStagging , dependency parsing , and phrase - structure parsing .", "label": "", "metadata": {}, "score": "40.33755"}
{"text": "We could also introduce new variables , e.g. , nonterminal refinements ( Matsuzaki et al . , 2005 ) , or secondary links Mij ( not constrai ... . by Jin - dong Kim , Tomoko Ohta , Sampo Pyysalo , Yoshinobu Kano - In Proceedings of Natural Language Processing in Biomedicine ( BioNLP )", "label": "", "metadata": {}, "score": "40.580223"}
{"text": "For each sentence , sorting the 100 translation hypotheses by score yields a hypothesis ranking .We ranked the hypotheses according to the original decoder score , the Lynx score , the LinkSet score , and by combinations of these scores .", "label": "", "metadata": {}, "score": "40.66324"}
{"text": "We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .", "label": "", "metadata": {}, "score": "40.726547"}
{"text": "We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .", "label": "", "metadata": {}, "score": "40.726547"}
{"text": "We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .", "label": "", "metadata": {}, "score": "40.726547"}
{"text": "We describe a newly available Hebrew Dependency Treebank , which is extracted from the Hebrew ( constituency ) Treebank .We establish some baseline unlabeled dependency parsing performance on Hebrew , based on two state - of - the - art parsers , MST - parser and MaltParser .", "label": "", "metadata": {}, "score": "40.726547"}
{"text": "The main point of this work has been the integration of syntactic structure into the statistical models used in translation --- both monolingual language models and models of translation from one language to another .Through the development of the Lynx and LinkSet models and parsers , we have taken a big step in that direction , and shown that adding models of syntactic structure can improve the output of a state - of - the - art statistical translation system .", "label": "", "metadata": {}, "score": "40.729633"}
{"text": "In particular , it allows one to efficiently learn a model which discriminates among the entire space of parse trees , as opposed to reranking the top few candidates .Our models can condition on arbitrary features of input sentences , thus incorporating an important kind of lexical information without the added algorithmic complexity of modeling headedness .", "label": "", "metadata": {}, "score": "40.74598"}
{"text": "We learn the neural network representation using a gold corpus augmented by a large number of automatically parsed sentences .Given this fixed network representation , we learn a final layer using the structured perceptron with beam - search decoding .On the Penn Treebank , our parser reaches 94.26 % unlabeled and 92.41 % labeled attachment accuracy , which to our knowledge is the best accuracy on Stanford Dependencies to date .", "label": "", "metadata": {}, "score": "40.762146"}
{"text": "In order to capture inherent relations occurring in corpus texts that can be critical in real - world applications , many NP relations are included in the set of grammatical relations used .We provide a comparison of our system with Minipar and the Link parser .", "label": "", "metadata": {}, "score": "40.786057"}
{"text": "When applying the same method to direct transfer of named - entity recognizers , we observe relative improvements of up to 26 % . ... rget languages in which no or few such resources are available ( Hwa et al . , 2005 ) .", "label": "", "metadata": {}, "score": "40.81356"}
{"text": "Nonetheless , the resulting grammars encode many linguistically interpretable patterns and give the best published parsing accuracies on three German treebanks .We demonstrate that log - linear grammars with latent variables can be practically trained using discriminative methods .Central to efficient discriminative training is a hierarchical pruning procedure which allows feature expectations to be efficiently approximated in a gradient - based procedure .", "label": "", "metadata": {}, "score": "40.888832"}
{"text": "This paper shows how finite approximations of long distance dependency ( LDD ) resolution can be obtained automatically for wide - coverage , robust , probabilistic Lexical - Functional Grammar ( LFG ) resources acquired from treebanks .We extract LFG subcategorisation frames and paths linking LDD reentrancies from f - structures generated automatically for the Penn - II treebank trees and use them in an LDD resolution algorithm to parse new text .", "label": "", "metadata": {}, "score": "40.9292"}
{"text": "Our best results show a 26-fold speedup compared to a sequential C implementation .We present a simple method for transferring dependency parsers from source languages with labeled training data to target languages without labeled training data .We first demonstrate that delexicalized parsers can be directly transferred between languages , producing significantly higher accuracies than unsupervised parsers .", "label": "", "metadata": {}, "score": "40.97616"}
{"text": "Unlike previous approaches , our framework does not require full projected parses , allowing partial , approximate transfer through linear expectation constraints on the space of distributions over trees .We consider several types of constraints that range from generic dependency conservation to language - specific annotation rules for auxiliary verb analysis .", "label": "", "metadata": {}, "score": "41.045498"}
{"text": "Unlike previous approaches , our framework does not require full projected parses , allowing partial , approximate transfer through linear expectation constraints on the space of distributions over trees .We consider several types of constraints that range from generic dependency conservation to language - specific annotation rules for auxiliary verb analysis .", "label": "", "metadata": {}, "score": "41.045498"}
{"text": "In these cases , correct analysis may require lexical and distributional knowledge not found in hand - crafted grammar rules .Instead of attempting to encode this knowledge manually , which would be far too difficult , researchers have turned to corpus - based statistical techniques , in which lexical and distributional knowledge is gathered from large corpora of real human - generated sentences .", "label": "", "metadata": {}, "score": "41.12932"}
{"text": "We propose a novel reordering model for phrase - based statistical machine translation ( SMT ) that uses a maximum entropy ( MaxEnt ) model to predicate reorderings of neighbor blocks ( phrase pairs ) .The model provides content - dependent , hierarchical phrasal reordering with generalization based on features automatically learned from a real - world bitext .", "label": "", "metadata": {}, "score": "41.2371"}
{"text": "We propose a novel reordering model for phrase - based statistical machine translation ( SMT ) that uses a maximum entropy ( MaxEnt ) model to predicate reorderings of neighbor blocks ( phrase pairs ) .The model provides content - dependent , hierarchical phrasal reordering with generalization based on features automatically learned from a real - world bitext .", "label": "", "metadata": {}, "score": "41.2371"}
{"text": "To train this transformation model , an EM approach can be used , updating the likelihood of each transformation according to the probability of each sentence structure that uses it .In addition to improving the quality of foreign structures inferred , this transformational model can then be used in a translation system .", "label": "", "metadata": {}, "score": "41.45358"}
{"text": "The modular design of the ontological parser permits the use of any part - of - speech - tagged ontology , with only minimal rewriting of the lexer and parser to accommodate format - specific issues .However , maximum benefits are recognized through the use of a parameterized ontology , an innovation heretofore unavailable in any parser or information retrieval system .", "label": "", "metadata": {}, "score": "41.49318"}
{"text": "Comput .Linguist . , 2010 . \" ...Information - extraction ( IE ) systems seek to distill semantic relations from naturallanguage text , but most systems use supervised learning of relation - specific examples and are thus limited by the availability of training data .", "label": "", "metadata": {}, "score": "41.52894"}
{"text": "In contrast with previous work , we are able to split various terminals to different degrees , as appropriate to the actual complexity in the data .Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation .", "label": "", "metadata": {}, "score": "41.598824"}
{"text": "The previous techniques of natural language processing are often limited to the performance of a particular purpose and can not be used for other purposes .Conventional parsing techniques may be designed to function as part of a grammar checking system , but can not function as part of a search engine , summarization application , or categorization application .", "label": "", "metadata": {}, "score": "41.72255"}
{"text": "Typically , the training data must consist of real sentences annotated with structural information of the kind the parser will eventually generate .Unfortunately , annotating these sentences can require a huge amount of work by language experts , comparable to that required to develop a rule - based grammar .", "label": "", "metadata": {}, "score": "41.73301"}
{"text": "Given this grammar , an LALR parser generator would fail to produce a parser because of a shift / reduce conflict .The modified LALR parser generator algorithm that the ontological parser of the present invention uses must be aware of the possibility of more than one possible course of action , and should recursively try both actions .", "label": "", "metadata": {}, "score": "41.74161"}
{"text": "This ' universal ' treebank is made freely available in order to facilitate research on multilingual dependency parsing .We consider the construction of part - of - speech taggers for resource - poor languages .Recently , manually constructed tag dictionaries from Wiktionary and dictionaries projected via bitext have been used as type constraints to overcome the scarcity of annotated data in this setting .", "label": "", "metadata": {}, "score": "41.777782"}
{"text": "Being largely languageuniversal , the selection component is learned in a supervised fashion from all the training languages .In contrast , the ordering decisions are only influenced by languages with similar properties .We systematically model this cross - lingual sharing using typological features .", "label": "", "metadata": {}, "score": "41.892143"}
{"text": "The advantages of the present system are the provision of a semantic representation of comparable utility with significantly reduced processing requirements , and no need to train the system to produce semantic representations of text content .The system and method for ontological parsing of natural language according to the present invention has a far simpler analysis process than conventional parsing techniques , and utilizes a dictionary containing tags with syntactic information .", "label": "", "metadata": {}, "score": "41.93541"}
{"text": "We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative improvement over the baseline approach that uses a fixed context window of adjacent words .", "label": "", "metadata": {}, "score": "42.015614"}
{"text": "We introduce a dependency - based context model that incorporates long - range dependencies , variable context sizes , and reordering .It provides a 16 % relative improvement over the baseline approach that uses a fixed context window of adjacent words .", "label": "", "metadata": {}, "score": "42.015614"}
{"text": "Begin with a foreign sentence needing translation into English .Get an N - best list from some other translation system .Rescore each translation hypothesis as follows : .Parse the candidate using the Lynx parser , obtaining the most probable structure and its probability .", "label": "", "metadata": {}, "score": "42.037987"}
{"text": "The ontology - based parser contains functional components for receiving documents in a plurality of formats , tokenizing them into instances of concepts from an ontology , and assembling the resulting concepts into predicates .The ontological parser has two major functional elements , a sentence lexer and a parser .", "label": "", "metadata": {}, "score": "42.22775"}
{"text": "Previous sentence segmentation systems have typically been very local , using low - level prosodic and lexical features to independently decide whether or not to segment at each word boundary position .In this work , we leverage global syntactic information from a syn- tactic parser , which is better able to capture long distance depen- dencies .", "label": "", "metadata": {}, "score": "42.25249"}
{"text": "Mare\u010dek and Zabokrtsk\u00b4y , 2011 , inter alia ) . \" ...We present a novel algorithm for multilingual dependency parsing that uses annotations from a diverse set of source languages to parse a new unannotated language .Our motivation is to broaden the advantages of multilingual learning to languages that exhibit significant differences from existing reso ... \" .", "label": "", "metadata": {}, "score": "42.35321"}
{"text": "Experimental results show that the global features are useful in all the languages . ... mines unlabeled dependency structures only , and we attach dependency relation labels using Support Vector Machines afterwards . \" ...We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .", "label": "", "metadata": {}, "score": "42.39543"}
{"text": "Experimental results show that the global features are useful in all the languages . ... mines unlabeled dependency structures only , and we attach dependency relation labels using Support Vector Machines afterwards . \" ...We study a range of syntactic processing tasks using a general statistical framework that consists of a global linear model , trained by the generalized perceptron together with a generic beamsearch decoder .", "label": "", "metadata": {}, "score": "42.39543"}
{"text": "Wu ( 1997 ) introduced constraints on alignments using a probabilistic synchronous context - free grammar restricted to Chomskynormal form .Yamada and Knight ( 2001 ) used a statistical parser trained using a Treebank in the source language to produce parse trees ... . \" ...", "label": "", "metadata": {}, "score": "42.44885"}
{"text": "Wu ( 1997 ) introduced constraints on alignments using a probabilistic synchronous context - free grammar restricted to Chomskynormal form .Yamada and Knight ( 2001 ) used a statistical parser trained using a Treebank in the source language to produce parse trees ... . \" ...", "label": "", "metadata": {}, "score": "42.44885"}
{"text": "The annotations are produced automatically with statistical models that are specifically adapted to historical text .The corpus will facilitate the study of linguistic trends , especially those related to the evolution of syntax .Syntactic analysis of search queries is important for a variety of information- retrieval tasks ; however , the lack of annotated data makes training query analysis models difficult .", "label": "", "metadata": {}, "score": "42.46129"}
{"text": "The parser converts the sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the sentence , and then applies rules to it that bind arguments into predicates .A system for ontological parsing that converts natural - language text into predicate - argument format comprising : . a sentence lexer for converting a natural language sentence into a sequence of ontological entities that are tagged with part - of - speech information ; and .", "label": "", "metadata": {}, "score": "42.661213"}
{"text": "In this thesis we incorporated linguistic knowledge into statistical models of language structure and of the relationship between different languages ' structures .The linguistic knowledge appears in the guise of model structure and of the selection and dependencies of model parameters .", "label": "", "metadata": {}, "score": "42.663036"}
{"text": "No .5,146,496 to Jensen discloses a technique for identifying predicate - argument relationships in natural language text .The Jensen system must create intermediate feature structures to store semantic roles , which are then used to fill in predicates whose deep structures have missing arguments .", "label": "", "metadata": {}, "score": "42.70294"}
{"text": "system checks only for syntactic correctness .U.S. Pat .No .4,914,590 to Loatman et al . discloses a natural language understanding system .The goal of the Loatman et al . system is to provide a formal representation of the context of a sentence , not merely the sentence itself .", "label": "", "metadata": {}, "score": "42.705116"}
{"text": "Secondly , the use of real sentences in training actually adds information to the system , enabling to make use of lexical and distributional knowledge ignored by the original rule - based system , which is especially useful in ambiguous cases .", "label": "", "metadata": {}, "score": "42.71193"}
{"text": "While these universal parsers currently constitute the highest - performing methods for languages without treebanks , they are inherently limited by operating at the coarse POS level , as lexical featu ... . \" ...We present an automatic method for mapping language - specific part - of - speech tags to a set of universal tags .", "label": "", "metadata": {}, "score": "42.736206"}
{"text": "ON LANGUAGE RESOURCES AND EVALUATION ( LREC , 2006 . \" ...This paper describes a system for extracting typed dependency parses of English sentences from phrase structure parses .In order to capture inherent relations occurring in corpus texts that can be critical in real - world applications , many NP relations are included in the set of grammatical relations ... \" .", "label": "", "metadata": {}, "score": "42.751015"}
{"text": "In addition , the ontology - based parser is designed to permit the use of arithmetic operations instead of string operations in text - processing programs , which employ the ontology - based parser .The output predicate structures contain numeric tags that represent the location of each concept within the ontology .", "label": "", "metadata": {}, "score": "42.813705"}
{"text": "In addition , the ontology - based parser is designed to permit the use of arithmetic operations instead of string operations in text - processing programs , which employ the ontology - based parser .The output predicate structures contain numeric tags that represent the location of each concept within the ontology .", "label": "", "metadata": {}, "score": "42.813705"}
{"text": "The sentence receiver is a software abstraction that may be realized through any number of techniques .The parser 230 takes a sequence of instances from an ontology , in the form of a sentence , and converts them into a collection of parse trees .", "label": "", "metadata": {}, "score": "42.889988"}
{"text": "The following is an example of a sentence and demonstrates both how it is parsed as a sentence within a document , and how a question to an information retrieval system would produce matching predicates to retrieve the document containing this sentence .", "label": "", "metadata": {}, "score": "42.893562"}
{"text": "Because it is expensive to annotate examples by hand , we used an existing parser to analyze sentences collected from news articles , and used its output as training data .Although this automatically - generated training set has significantly more errors than one would expect from a hand - labeled training set , the Lynx parser is able to score as well as the Link parser at constituent bracketing .", "label": "", "metadata": {}, "score": "43.02115"}
{"text": "This improvement was limited by the small space available for improvement of a state - of - the - art statistical translation system through reranking of translation hypotheses .These are the main contributions of this thesis : .A new technique for training a statistical link grammar parser from examples , implemented as the Lynx parser .", "label": "", "metadata": {}, "score": "43.091026"}
{"text": "In other cases , syntactic ambiguity will result in multiple possible parses .The parser should not generate any output trees for a sentence that does not reduce according to the rules ; rather it should generate a tree for every possible parse of an ambiguous sentence .", "label": "", "metadata": {}, "score": "43.104942"}
{"text": "Similarly , for information retrieval purposes , an embodiment of the ontological parser optimized for queries may make use of all these filters , but add a pseudo - predicate filter and a pseudo - concept filter .The stop word filter removes stop words from sentences .", "label": "", "metadata": {}, "score": "43.125603"}
{"text": "Starting from a mono - phone model , we learn increasingly refined models that capture phone internal structures , as well as context - dependent variations in an automatic way .Our approaches reduces error rates compared to other baseline approaches , while streamlining the learning procedure .", "label": "", "metadata": {}, "score": "43.267982"}
{"text": "non - parallel , multilingual corpus . 1 Introduction Probabilistic grammars have become an important tool in natural language processing .An attractive property of probabilistic grammars is that the ... . by Fei Wu , Daniel S. Weld - in Proc . 48th Annu .", "label": "", "metadata": {}, "score": "43.368835"}
{"text": "If the word exists within the ontology 140 , it is returned as an ontological entity ; if not , it is returned as a word tagged with default assumptions about its ontological status .In one embodiment , words are automatically assumed to be nouns ; however , the words may be other parts of speech .", "label": "", "metadata": {}, "score": "43.43509"}
{"text": "First , we show that these results hold true for a number of languages across families .Second , and more interestingly , we provide an algorithm for inducing cross - lingual clusters and we show that features derived from these clusters significantly improve the accuracy of cross - lingual structure prediction .", "label": "", "metadata": {}, "score": "43.45284"}
{"text": "Thus when confronted with a sentence that would be considered ungrammatical by a more rigid grammar , a stochastic syntax model simply assigns a lower score , nevertheless selecting the structure most probable under the circumstances .This generalization yields a great increase in robustness , allowing performance to degrade gracefully on more difficult sentences .", "label": "", "metadata": {}, "score": "43.552853"}
{"text": "However , the models used in most statistical translation systems are much too simple to capture to syntactic structure of each sentence , often resulting in output that is ungrammatical or has the wrong meaning .Because important information is carried not only in the choice of words , but in their grammatical relationships , it is necessary to incorporate syntactic structure into translation models in order to meaning to be conveyed accurately and grammatically .", "label": "", "metadata": {}, "score": "43.60283"}
{"text": "We build on three intuitions that are explicit in phrase - structure grammars but only implicit in standard dependency ... \" .We present a new family of models for unsupervised parsing , Dependency and Boundary models , that use cues at constituent boundaries to inform head - outward dependency tree generation .", "label": "", "metadata": {}, "score": "43.611935"}
{"text": "Tokuume et al . , U.S. Pat .No .5,101,349 , discloses a natural language processing system that makes provisions for validating grammar from the standpoint of syntactic well - formedness , but does not provide facilities for validating the semantic well - formedness of feature structures .", "label": "", "metadata": {}, "score": "43.654835"}
{"text": "Synchronous dependency insertion grammars are a version of synchronous grammars defined on dependency trees .We first introduce our approach to inducing such a grammar from parallel corpora .Second , we describe the graphical model for the machine translation task , which can also be viewed as a stochastic tree - to - tree transducer .", "label": "", "metadata": {}, "score": "43.72779"}
{"text": "Synchronous dependency insertion grammars are a version of synchronous grammars defined on dependency trees .We first introduce our approach to inducing such a grammar from parallel corpora .Second , we describe the graphical model for the machine translation task , which can also be viewed as a stochastic tree - to - tree transducer .", "label": "", "metadata": {}, "score": "43.72779"}
{"text": "It turns out that these generalized parsers can do most of the work required to train and apply a syntax - aware statistical machine translation system . \" ...We propose a novel reordering model for phrase - based statistical machine translation ( SMT ) that uses a maximum entropy ( MaxEnt ) model to predicate reorderings of neighbor blocks ( phrase pairs ) .", "label": "", "metadata": {}, "score": "43.745502"}
{"text": "It turns out that these generalized parsers can do most of the work required to train and apply a syntax - aware statistical machine translation system . \" ...We propose a novel reordering model for phrase - based statistical machine translation ( SMT ) that uses a maximum entropy ( MaxEnt ) model to predicate reorderings of neighbor blocks ( phrase pairs ) .", "label": "", "metadata": {}, "score": "43.745502"}
{"text": "A mixture grammar fit with the EM algorithm shows improvement over a single PCFG , both in parsing accuracy and in test data likelihood .We argue that this improvement comes from the learning of specialized grammars that capture non - local correlations .", "label": "", "metadata": {}, "score": "43.797863"}
{"text": "We extend and improve upon recent work in structured training for neural network transition - based dependency parsing .We do this by experimenting with novel features , additional transition systems and by testing on a wider array of languages .In particular , we introduce set - valued features to encode the predicted morphological properties and part - of - speech confusion sets of the words being parsed .", "label": "", "metadata": {}, "score": "43.883667"}
{"text": "Using Bayes ' rule , we can turn this around and factor out the Pr ( f ) that would appear in the denominator , since it does not depend on e .So far we have described translation of sentence strings , ignoring syntactic structure .", "label": "", "metadata": {}, "score": "43.95797"}
{"text": "1 Introduction This article presents CYK+ , a bottom - up parsing algorithm for stochastic context - free grammars that is able : 1 . to deal multiple interpretations of sentences containing compound words ; 2 . to extract N - most probable parses in O(n 3 ) and compute at the same time all possible parses of any portion of the input sequence with their p ..", "label": "", "metadata": {}, "score": "43.95816"}
{"text": "1 Introduction This article presents CYK+ , a bottom - up parsing algorithm for stochastic context - free grammars that is able : 1 . to deal multiple interpretations of sentences containing compound words ; 2 . to extract N - most probable parses in O(n 3 ) and compute at the same time all possible parses of any portion of the input sequence with their p ..", "label": "", "metadata": {}, "score": "43.95816"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 20 , wherein said parser filters remove parse trees that violate one of statistical and ontological criteria for well - formedness .", "label": "", "metadata": {}, "score": "44.0341"}
{"text": "In the original formulation , the LinkSet model was unable to account for this phrase properly , because of its one - to - one alignment model .While the LinkSet model can , through the use of null links , deal reasonably well with contiguous multi - word phrases aligned to single words in the other language , a non - contiguous phrase presented a problem .", "label": "", "metadata": {}, "score": "44.092697"}
{"text": "In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .", "label": "", "metadata": {}, "score": "44.100357"}
{"text": "In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .", "label": "", "metadata": {}, "score": "44.100357"}
{"text": "..METU - Sabanc\u0131 treebank ( Atalay et al . , 2003 ; Oflazer et al . , 2003 ) from the CoNLL shared task in 2006 .Whenever using CoNLL shared task data , we used the first 80 % of the data d .. \" ...", "label": "", "metadata": {}, "score": "44.209183"}
{"text": "..METU - Sabanc\u0131 treebank ( Atalay et al . , 2003 ; Oflazer et al . , 2003 ) from the CoNLL shared task in 2006 .Whenever using CoNLL shared task data , we used the first 80 % of the data d .. \" ...", "label": "", "metadata": {}, "score": "44.209183"}
{"text": "We present a nonparametric Bayesian model of tree structures based on the hierarchical Dirichlet process ( HDP ) .Our HDP - PCFG model allows the complexity of the grammar to grow as more training data is available .In addition to presenting a fully Bayesian model for the PCFG , we also develop an efficient variational inference procedure .", "label": "", "metadata": {}, "score": "44.213875"}
{"text": "These grammar rules , called productions , specify language that the target parser is supposed to recognize .Each production indicates that a specific combination of input symbols , called terminals , and assembled groups of terminals , called non - terminals , can be assembled into a new non - terminal .", "label": "", "metadata": {}, "score": "44.33385"}
{"text": "On a large - scale Chinese - English translation task , we obtain statistically significant improvements of +1.5 Bleu and +1.1 Bleu , respectively .We analyze the impact of the new features and the performance of the learning algorithm .The baseline model includes 12 features whose weights are optimized using MERT .", "label": "", "metadata": {}, "score": "44.400185"}
{"text": "On a large - scale Chinese - English translation task , we obtain statistically significant improvements of +1.5 Bleu and +1.1 Bleu , respectively .We analyze the impact of the new features and the performance of the learning algorithm .The baseline model includes 12 features whose weights are optimized using MERT .", "label": "", "metadata": {}, "score": "44.400185"}
{"text": "We present methods to control the lexicon size when learning a Combinatory Categorial Grammar semantic parser .Existing methods incrementally expand the lexicon by greedily adding entries , considering a single training datapoint at a time .We propose using corpus - level statistics for lexicon learning decisions .", "label": "", "metadata": {}, "score": "44.44475"}
{"text": "A rough - grain approximation of expectation maximization training does not improve the model .However , a more fine - grained EM approach might work much better .The induced parser can be incrementally improved through cleaning of the translation lexicon and adjustment of the model to handle common structures missed during the original training .", "label": "", "metadata": {}, "score": "44.450695"}
{"text": "Their symbolic component is amenable to inspection by humans , while their probabilistic component helps resolve ambiguity .They also permit the use of well - understood , generalpurpose learn ... \" .Probabilistic grammars offer great flexibility in modeling discrete sequential data like natural language text .", "label": "", "metadata": {}, "score": "44.492554"}
{"text": "Their symbolic component is amenable to inspection by humans , while their probabilistic component helps resolve ambiguity .They also permit the use of well - understood , generalpurpose learn ... \" .Probabilistic grammars offer great flexibility in modeling discrete sequential data like natural language text .", "label": "", "metadata": {}, "score": "44.492554"}
{"text": "SUMMARY OF THE INVENTION .The foregoing and other deficiencies are addressed by the present invention , which is directed to an ontology - based parser for natural language processing .More particularly , the present invention relates to a system that provides a simple knowledge - base - style representation format for the manipulation of natural - language documents .", "label": "", "metadata": {}, "score": "44.542747"}
{"text": "We also show that our techniques can be applied to full - scale parsing applications by demonstrating its effectiveness in learning state - split grammars .Treebank parsing can be seen as the search for an optimally refined grammar consistent with a coarse training treebank .", "label": "", "metadata": {}, "score": "44.574795"}
{"text": "Many probabilistic models for natural language are now written in terms of hierarchical tree structure .Tree - based modeling still lacks many of the standard tools taken for granted in ( finite - state ) string - based modeling .The theory of tree transducer automata provides a possible framework to ... \" .", "label": "", "metadata": {}, "score": "44.70548"}
{"text": "We describe experiments on learning latent variable grammars for various German treebanks , using a language - agnostic statistical approach .In our method , a minimal initial grammar is hierarchically refined using an adaptive split - and - merge EM procedure , giving compact , accurate grammars .", "label": "", "metadata": {}, "score": "44.730507"}
{"text": "Specifically , an ini- tial hypothesis lattice is constrcuted using local features .Candidate sentences are then assigned syntactic language model scores .These global syntactic scores are combined with local low - level scores in a log - linear model .", "label": "", "metadata": {}, "score": "44.74904"}
{"text": "In the predicate representation scheme of the present invention , there are only a few distinct frames for predicate structures , as many as needed to cover the different numbers of arguments taken by different verbs .Predicates may be enhanced with selectional restriction information , which can be coded automatically for entire semantic classes of words , rather than on an individual basis , because of the ontological scheme .", "label": "", "metadata": {}, "score": "44.80948"}
{"text": "In particular we note the effects of two comparatively recent techniques for parser improvement .Then a reranking phase uses more detailed features , features which would ( mostly ) be ... . \" ...We formulate dependency parsing as a graphical model with the novel ingredient of global constraints .", "label": "", "metadata": {}, "score": "44.898518"}
{"text": "Second , we compare various inference procedures for state - split PCFGs from the standpoint of risk minimization , paying particular attention to their practical tradeoffs .Finally , we present multilingual experiments which show that parsing with hierarchical state - splitting is fast and accurate in multiple languages and domains , even without any language - specific tuning . .", "label": "", "metadata": {}, "score": "44.98601"}
{"text": "Finally , we conduct a multi - lingual evaluation that demonstrates the robustness of the overall structured neural approach , as well as the benefits of the extensions proposed in this work .Our research further demonstrates the breadth of the applicability of neural network methods to dependency parsing , as well as the ease with which new features can be added to neural parsing models .", "label": "", "metadata": {}, "score": "45.144634"}
{"text": "Finally , we present multilingual experiments which show that parsing with hierarchical state - splitting is fast and accurate in multiple languages and domains , even without any language - specific tuning .This work describes systems for detecting semantic categories present in news video .", "label": "", "metadata": {}, "score": "45.150185"}
{"text": "In order to economically test the efficacy of the syntax - based Lynx and LinkSet models in a translation system , we use the models to assign scores to the translation hypotheses generated by a state - of - the - art statistical translation system .", "label": "", "metadata": {}, "score": "45.15393"}
{"text": "These transducers are strictly more expressive than the special case of standard leftto - right finite - state transducers .Dependency transduction models are then defined as collections of weighted head transducers that are applied hierarchically .A dynamic programming search algorithm is described for finding the optimal transduction of an input string with respect to a dependency transduction model .", "label": "", "metadata": {}, "score": "45.189625"}
{"text": "These transducers are strictly more expressive than the special case of standard leftto - right finite - state transducers .Dependency transduction models are then defined as collections of weighted head transducers that are applied hierarchically .A dynamic programming search algorithm is described for finding the optimal transduction of an input string with respect to a dependency transduction model .", "label": "", "metadata": {}, "score": "45.189625"}
{"text": "However , parsing accuracies for Arabic usually lag behind non - semitic languages .Moreover , whil ...Tools . by Kuzman Ganchev , Jennifer Gillenwater , Ben Taskar - In ACL - IJCNLP , 2009 . \" ...Broad - coverage annotated treebanks necessary to train parsers do not exist for many resource - poor languages .", "label": "", "metadata": {}, "score": "45.204838"}
{"text": "1 is a block diagram of the sentence lexer according to the present invention ; .FIG .2 is a block diagram of the parser according to the present invention ; .FIG .3 is a diagram showing two complete parse trees produced according to the present invention ; .", "label": "", "metadata": {}, "score": "45.22504"}
{"text": "Yet , various grammar parameters are expected to be correlated because the elements in language they represent share linguistic properties .In this paper , we suggest an alternative to the Dirichlet prior , a family of logistic normal distributions .We derive an inference algorithm for this family of distributions and experiment with the task of dependency grammar induction , demonstrating performance improvements with our priors on a set of six treebanks in different natural languages .", "label": "", "metadata": {}, "score": "45.242374"}
{"text": "Yet , various grammar parameters are expected to be correlated because the elements in language they represent share linguistic properties .In this paper , we suggest an alternative to the Dirichlet prior , a family of logistic normal distributions .We derive an inference algorithm for this family of distributions and experiment with the task of dependency grammar induction , demonstrating performance improvements with our priors on a set of six treebanks in different natural languages .", "label": "", "metadata": {}, "score": "45.242374"}
{"text": "For example , in a search engine application , it may be useful to check whether or not a particular noun can serve as an argument of a predicate .The features of the noun should be more specific than the features of the argument position it is attached to .", "label": "", "metadata": {}, "score": "45.304703"}
{"text": "The largest improvement is achieved on the non Indo - European languages yielding a gain of 14.4 % . ... parser trained using parallel data .The underlying parsing model is the dependency model with valance ( DMV ) ( Klein and Manning , 2004 ) .", "label": "", "metadata": {}, "score": "45.472122"}
{"text": "This naive grammar ... . \" ...We present several improvements to unlexicalized parsing with hierarchically state - split PCFGs .First , we present a novel coarse - to - fine method in which a grammar 's own hierarchical projections are used for incremental pruning , including a method for efficiently computing projections of a grammar wi ... \" .", "label": "", "metadata": {}, "score": "45.53457"}
{"text": "While this training is a fully automated process , given a human - generated but unannotated text corpus ( a plentiful resource ) , it is a semi - supervised learning process because the explicit grammar knowledge exercised by the Link parser acts as a kind of supervisor .", "label": "", "metadata": {}, "score": "45.698925"}
{"text": "Those other concepts are the arguments of the predicate , and are generally nouns , because predicate relationships are usually between entities .As stated previously , the ontological parser has two major components , a sentence lexer 100 and a parser 200 .", "label": "", "metadata": {}, "score": "45.729733"}
{"text": "One of the reasons the Lynx parser is able to do so well is that it gains the benefit of the grammatical and distributional knowledge implicit in the sentences used for training , even though the analysis of these sentences by the Link parser is fallible .", "label": "", "metadata": {}, "score": "45.75545"}
{"text": "In addition to the tagset , we develop a mapping from 25 different treebank tagsets to this universal set .As a result , when combined with the original treebank data , this universal tagset and mapping produce a dataset consisting of common parts - of - speech for 22 different languages . \" ...", "label": "", "metadata": {}, "score": "45.823875"}
{"text": "The Lynx parser uses a generative model Pr(E ) of a structured English sentence E , a syntactic tree structure including words and labels .Parsing a given English sentence string e is the same as finding the most likely tree that yields the same surface string .", "label": "", "metadata": {}, "score": "45.828392"}
{"text": "However , appropriate probabilities for each rule can only be determined by experimentation .In the initial version , probabilities will be assigned by linguistic intuition ; as iterations of the design progress , probabilities will be determined through experimentation .Since sentence probabilities are generally very small numbers , the parse probability filter should pass any parse tree with a probability of at least 30 % of the highest probability parse .", "label": "", "metadata": {}, "score": "45.83582"}
{"text": "Such a representation scheme gives each node in the tree a unique identifier that completely determines the relative place of that node in the tree structure .It also provides a simple way to compare relative positions of two discovered node instances .", "label": "", "metadata": {}, "score": "45.842247"}
{"text": "Dependency parsing is a central NLP task .In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .", "label": "", "metadata": {}, "score": "45.87739"}
{"text": "Dependency parsing is a central NLP task .In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations .We show that for three leading unsupervised parsers ( Klein and Manning , 2004 ; Cohen and Smith , 2009 ; Spitkovsky et al .", "label": "", "metadata": {}, "score": "45.87739"}
{"text": "Because each refinement introduces only limited complexity , both learning and inference can be done in an incremental fashion .In this dissertation , we describe several coarse - to - fine systems .In the domain of syntactic parsing , complexity is in the grammar .", "label": "", "metadata": {}, "score": "45.94612"}
{"text": "The ontological parser is designed to be modular , so that improvements and language - specific changes can be made to individual components without reengineering the other components .The components are discussed in detail below .The ontological parser has two major functional elements , a sentence lexer and a parser .", "label": "", "metadata": {}, "score": "45.95476"}
{"text": "Monolingual Probabilistic Parsing .The results are shown in this table , which shows the number and percentage of sentences for which the method in each column beats the method in each row .The Lynx parser analyzes sentences for syntactic structure by finding the most probable structure consistent with the given text , according to a statistical model of structured sentences .", "label": "", "metadata": {}, "score": "46.09667"}
{"text": "Instead the system and method of the present invention incorporates a sophisticated syntactic analysis component , which allows facts about parts - of - speech to determine the correct syntactic analysis .Additionally , by incorporating ontologies as the basis for the lexical resource , the present invention permits the output of the parser to be easily modified by other applications .", "label": "", "metadata": {}, "score": "46.25467"}
{"text": "To manage this complexity , we translate into target language clusterings of increasing vocabulary size .This approach gives dramatic speed - ups while additionally increasing final translation quality .The intersection of tree transducer - based translation models with n - gram language models results in huge dynamic programs for machine translation decoding .", "label": "", "metadata": {}, "score": "46.49183"}
{"text": "While prior feature - based dynamic programming parsers have restricted training and evaluation to artificially short sentences , we present the first general , featurerich discriminative parser , based on a conditional random field model , which has been successfully scaled to the full WSJ parsing data .", "label": "", "metadata": {}, "score": "46.614048"}
{"text": "Often numerous passes through the input sentence(s ) are required to fully parse the input , thereby adding to the time required to parse the input .Often the previous techniques do not have very robust feature checking capabilities .In particular , the techniques do not check for both syntactic and semantic compatibility .", "label": "", "metadata": {}, "score": "46.61782"}
{"text": "( 2014 ) presented a task - agnostic method for learning to map input sequences to output sequences that achieved strong results on a large scale machine translation problem .In this work , we show that precisely the same sequence - to - sequence method achieves results that are close to state - of - the - art on syntactic constituency parsing , whilst making almost no assumptions about the structure of the problem .", "label": "", "metadata": {}, "score": "46.763035"}
{"text": "In some sense it could be considered a relief , considering the huge computational cost involved .However , perhaps a better EM technique would yield improvement , since our EM training was a fairly crude approximation of the ideal parameter estimation method , with sentence - level rather than feature - level granularity .", "label": "", "metadata": {}, "score": "46.922573"}
{"text": "However , parsing accuracies for Arabic usually lag behind non - semitic languages .Moreover , whil ...Syntactic parsing is a fundamental problem in computational linguistics and natural language processing .Traditional approaches to parsing are highly complex and problem specific .", "label": "", "metadata": {}, "score": "47.05023"}
{"text": "The tree with the maximal probability is outputted .The experiments are carried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser . ... arried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser .", "label": "", "metadata": {}, "score": "47.07322"}
{"text": "The tree with the maximal probability is outputted .The experiments are carried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser . ... arried on 10 languages , and the results show that our probabilistic parsing action models outperform the original deterministic dependency parser .", "label": "", "metadata": {}, "score": "47.07322"}
{"text": "most languages are projective .In Figure 8 An example Chinese dependency tree .Although non - projec ... . \" ...Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .", "label": "", "metadata": {}, "score": "47.091908"}
{"text": "most languages are projective .In Figure 8 An example Chinese dependency tree .Although non - projec ... . \" ...Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .", "label": "", "metadata": {}, "score": "47.091908"}
{"text": "In order to enable computers to handle the complexities of natural language , and of many other phenomena as well , we need the combined power of theoretical knowledge and real - world statistics .Creating tools to bring these together should pay off not only in natural language processing , but in a variety of fields .", "label": "", "metadata": {}, "score": "47.176678"}
{"text": "In contrast to annotation projection approaches ( Yarowsky et al . , 2001 ; Hwa et al . , 2005 ; Ganchev et al ., 2009 ; Spreyer and Kuhn , 2009 ) , delexicalized transfer methods do not rely on ... . \" ...", "label": "", "metadata": {}, "score": "47.187035"}
{"text": "Our experiments have shown that scores assigned by the Lynx and LinkSet parsers to translation decoder output can produce a significant improvement in the ranking of the hypotheses over the decoder 's original ranking .However , when only the number - one hypothesis is taken into account , no significant gains were made in the end - to - end performance of the translation system .", "label": "", "metadata": {}, "score": "47.199936"}
{"text": "The Brash system makes no provisions for the possibility that immediate relationships are not in fact the correct expression of sentence - level concepts , because it assumes that syntactic constituency is always defined by immediate relationships .The Brash system does not incorporate ontologies as the basis for its lexical resource , and therefore does not permit the output of the parser to be easily modified by other applications .", "label": "", "metadata": {}, "score": "47.216774"}
{"text": "In particular , we demonstrated in Petrov et al .( 2006 ) that a hierarchically split PCFG could exceed the accuracy of lexic ... . by Ben Taskar , Dan Klein , Michael Collins , Daphne Koller , Christopher Manning - In Proceedings of EMNLP , 2004 . \" ...", "label": "", "metadata": {}, "score": "47.21918"}
{"text": "Finally , we show that we can significantly improve target language performance , even after annotating up to 64,000 tokens in the target language , by simply concatenating source and target language annotations .Here we perform a set of experiments where we investigate the potential of multi - source transfer for NER , in German ( DE ) , English ( EN ) , Spanish ( ES ) and Dutch ( NL ) , using cro ... . \" ...", "label": "", "metadata": {}, "score": "47.409073"}
{"text": "We evaluate the outputs of our MT system using the NIST and Bleu automatic MT evaluation software .The result shows that our system outperforms the baseline system based on the IBM models in both translation speed and quality . ... guages or loose translations in real corpora , pose a major challenge to syntax - based statistical MT .", "label": "", "metadata": {}, "score": "47.442276"}
{"text": "We evaluate the outputs of our MT system using the NIST and Bleu automatic MT evaluation software .The result shows that our system outperforms the baseline system based on the IBM models in both translation speed and quality . ... guages or loose translations in real corpora , pose a major challenge to syntax - based statistical MT .", "label": "", "metadata": {}, "score": "47.442276"}
{"text": "Our motivation is to broaden the advantages of multilingual learning to languages that exhibit significant differences from existing resource - rich languages .The algorithm learns which aspects of the source languages are relevant for the target language and ties model parameters accordingly .", "label": "", "metadata": {}, "score": "47.497368"}
{"text": "Latent variable grammars take an observed ( coarse ) treebank and induce more fine - grained grammar categories , that are better suited for modeling the syntax of natural languages .Estimation can be done in a generative or a discriminative framework , and results in the best published parsing accuracies over a wide range of syntactically divergent languages and domains .", "label": "", "metadata": {}, "score": "47.512146"}
{"text": "The system and method of the present invention also provides a robust feature - checking system that accounts for semantic compatibility as well as syntactic compatibility .The ontology of the present invention converts all inflected words to their canonical forms .", "label": "", "metadata": {}, "score": "47.54164"}
{"text": "First , a new statistical parser is presented .This parser , titled Lynx , is trained from sentences annotated automatically by another parser , and achieves results comparable to the original parser .Second , a statistical model of the relationship between the syntactic structure of two languages is presented , along with an unsupervised training algorithm , titled LinkSet .", "label": "", "metadata": {}, "score": "47.62582"}
{"text": "In this sample embodiment , this predicate is then passed through the parser filters , where it successfully passes the parse probability and selectional feature compatibility tests .In the foregoing example , \" have \" is a verb unlikely to have any selectional restrictions on arguments .", "label": "", "metadata": {}, "score": "47.741608"}
{"text": "All applications making use of the fact that the output of the ontology - based parser is an ontological entity may realize enormous speed benefits from the parameterized ontology that the parser utilizes .Background of the Invention .Numerous techniques have been developed to process natural language input .", "label": "", "metadata": {}, "score": "48.043266"}
{"text": "The pseudo - concept filter operates in one embodiment , a query ontological parser .It removes concepts from queries , which are not likely to be the actual concept the user intends .Pseudo - concepts are largely nouns , and can be captured by a stop word list .", "label": "", "metadata": {}, "score": "48.376118"}
{"text": "This distinction may have some psychological validity , but it is not computationally attractive to maintain this distinction in separate array elements .A compromise approach is to attempt to make judgments about redundancy , and write software to merge branches as specified by the judgments of a knowledge engineer .", "label": "", "metadata": {}, "score": "48.38521"}
{"text": "Despite its simplicity , our best grammar achieves an F1 of 90.2 % on the Penn Treebank , higher than fully lexicalized systems . ...e into smaller steps ) .In this paper , we investigate the learning of a grammar consistent with a treebank at the level of evaluation symbols ... . by Michele Banko , Michael J Cafarella , Stephen Soderland , Matt Broadhead , Oren Etzioni - IN IJCAI , 2007 . \" ...", "label": "", "metadata": {}, "score": "48.389145"}
{"text": "We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task .For languages from different families the improvements often exceed 2 BLEU .Many of these gains are also significant in human evaluations .We present a new collection of treebanks with homogeneous syntactic dependency annotation for six languages : German , English , Swedish , Spanish , French and Korean .", "label": "", "metadata": {}, "score": "48.42269"}
{"text": "During the sentence lexer stage , words are labeled with information from the ontology , including these numerical codes .The argument position for each predicate structure may be tagged with codes from any level of the ontology .The parser will only output predicate structures where the noun inherits at least those features specified by the code .", "label": "", "metadata": {}, "score": "48.474033"}
{"text": "The parser is a tool for analyzing syntactic relationships between entities .Referring to .FIG .1 , the sentence lexer 100 is shown .Document iterator 120 receives documents or text input 110 , and outputs individual sentences to the lexer 130 .", "label": "", "metadata": {}, "score": "48.52687"}
{"text": "Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation .On the other hand , our grammars are much more compact and substantially more accurate than previous work on automatic annotation .Despite its simplicity , our best grammar achieves an F1 of 90.2 % on the Penn Treebank , higher than fully lexicalized systems . ... reebank , higher than fully lexicalized systems .", "label": "", "metadata": {}, "score": "48.58124"}
{"text": "This model is an extension of PCFG in which non - terminal symbols are augmented with latent variables .Finegrained CFG rules are automatically induced from a parsed corpus by training a PCFG - LA model using an EM - algorithm .", "label": "", "metadata": {}, "score": "48.63731"}
{"text": "Our methods result in state - of - the - art performance on the task of executing sequences of natural language instructions , achieving up to 25 % error reduction , with lexicons that are up to 70 % smaller and are qualitatively less noisy .", "label": "", "metadata": {}, "score": "49.130627"}
{"text": "Our generative self - trained grammars reach F scores of 91.6 on the WSJ test set and surpass even discriminative reranking systems without self - training .Additionally , we show that multiple self - trained grammars can be combined in a product model to achieve even higher accuracy .", "label": "", "metadata": {}, "score": "49.20234"}
{"text": "Adverbs detail the meaning of the verbs they accompany , but do not change them .Since the meaning of the sentence remains the same , adverbs can be removed to simplify parsing .The pseudo - predicate filter operates in one embodiment , as a query ontological parser .", "label": "", "metadata": {}, "score": "49.209526"}
{"text": "Unfortunately , parsing is a hard problem , and constructing a new parsing system that works reasonably well typically requires a large effort by language experts , either in designing a grammar or in annotating training data .However , by training the Lynx parser ) using data annotated automatically by the LinkSet bilingual parser , a quick - and - dirty parser can be constructed with minimal effort and without much need for language expertise .", "label": "", "metadata": {}, "score": "49.309135"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 3 , wherein said numbers can be subtracted to determine if features are in agreement , wherein a non - negative number indicates agreement .", "label": "", "metadata": {}, "score": "49.396385"}
{"text": "Tree - based modeling still lacks many of the standard tools taken for granted in ( finite - state ) string - based modeling .The theory of tree transducer automata provides a possible framework to draw on , as it has been worked out in an extensive literature .", "label": "", "metadata": {}, "score": "49.47341"}
{"text": "In the rule - based Link parser , any constructions not anticipated by the designers of the grammar can only be covered through null links .There is a sharp dividing line between what is considered grammatical and what is not , which can cause sentences with a missing word to be analyzed strangely or not at all .", "label": "", "metadata": {}, "score": "49.56098"}
{"text": "Since ancient times , the ability to translate from one language to another has been valued .Automatic translation is now a reality , though for open - domain translation , automated systems can not yet come anywhere near a bilingual human in quality .", "label": "", "metadata": {}, "score": "49.69145"}
{"text": "Incorporating additional features would increase the runtime additively rather than multiplicatively . ... , 2007)-but our footnote 11 suggests that BP might incorporate a language model rapidly .Finally , we can take advantage of improvements to BP proposed in the context of other applications .", "label": "", "metadata": {}, "score": "49.766922"}
{"text": "Incorporating additional features would increase the runtime additively rather than multiplicatively . ... , 2007)-but our footnote 11 suggests that BP might incorporate a language model rapidly .Finally , we can take advantage of improvements to BP proposed in the context of other applications .", "label": "", "metadata": {}, "score": "49.766922"}
{"text": "We propose a forest - based approach that translates a packed forest of exponentially many parses , which encodes many more alternatives than standard n - best lists .Large - scale experiments show an absolute improvement of 1.7 BLEU points over the 1-best baseline .", "label": "", "metadata": {}, "score": "49.887413"}
{"text": "We propose a forest - based approach that translates a packed forest of exponentially many parses , which encodes many more alternatives than standard n - best lists .Large - scale experiments show an absolute improvement of 1.7 BLEU points over the 1-best baseline .", "label": "", "metadata": {}, "score": "49.887413"}
{"text": "Similarly , the filter would need to check twice to determine that \" car \" is in agreement with \" transportation , \" and once for \" vehicle . \"In contrast , a parameterized ontology assigns numbers to these concepts , such that each level is a larger number than the previous level .", "label": "", "metadata": {}, "score": "50.218605"}
{"text": "Expectation maximization training improves the model .Careful model design is important in order to avoid the complementary hazards of computational complexity and data sparsity .Using a bilingual corpus and an existing parser in one language , a new parser can be automatically induced for the other language , without the aid of a language expert .", "label": "", "metadata": {}, "score": "50.37355"}
{"text": "However , we were able to address this problem fairly easily by narrowing the overly broad word - translation model for those specific words and by allowing some English words to effectively align to more than one foreign word .The problem of discontiguous many - to - one alignment is quite general and may be at the root of many misaligned phrases .", "label": "", "metadata": {}, "score": "50.47399"}
{"text": "a parse tree converter that receives the output of said parser component and converts said parse trees into predicates .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 19 , wherein said parser component further comprises : . parser filters operating on said predicates to remove erroneous predicates .", "label": "", "metadata": {}, "score": "50.523506"}
{"text": "Unfortunately the sentence in Figure 1(b ) is highly unusual in its amount of dependency conservation .To get a feel for the typical case , we used off - the - shelf parsers ( McDonald et al . , 2005 ) for E .. by Ivan Titov , James Henderson - IN PROCEEDINGS OF CONLL-2007 SHARED TASK .", "label": "", "metadata": {}, "score": "50.574097"}
{"text": "Unfortunately the sentence in Figure 1(b ) is highly unusual in its amount of dependency conservation .To get a feel for the typical case , we used off - the - shelf parsers ( McDonald et al . , 2005 ) for E .. by Ivan Titov , James Henderson - IN PROCEEDINGS OF CONLL-2007 SHARED TASK .", "label": "", "metadata": {}, "score": "50.574097"}
{"text": "On full - scale treebank parsing experiments , the discriminative latent models outperform both the comparable generative latent models as well as the discriminative non - latent baselines .We present a maximally streamlined approach to learning HMM - based acoustic models for automatic speech recognition .", "label": "", "metadata": {}, "score": "50.598343"}
{"text": "Top - left : Cross - lingual ( EN - ES ) word clustering model .Top - right : Samples of some of the induced cro ... . \" ...We present LLCCM , a log - linear variant of the constituent context model ( CCM ) of grammar induction .", "label": "", "metadata": {}, "score": "50.607765"}
{"text": "Discriminative feature - based methods are widely used in natural language processing , but sentence parsing is still dominated by generative methods .While prior feature - based dynamic programming parsers have restricted training and evaluation to artificially short sentences , we present the first gene ... \" .", "label": "", "metadata": {}, "score": "50.67505"}
{"text": "Meanwhile , the LinkSet score is able to bring a small improvement when added to the decoder score , but not as much as the Lynx score .For long sentences , especially those 80 words and longer , the lines converge .", "label": "", "metadata": {}, "score": "50.73262"}
{"text": "Across eight European languages , our approach results in an average absolute improvement of 10.4 % over a state - of - the - art baseline , and 16.7 % over vanilla hidden Markov models induced with the Expectation Maximization algorithm .", "label": "", "metadata": {}, "score": "50.732788"}
{"text": "With 100 K unlabeled and 2 K labeled questions , uptraining is able to improve parsing accuracy to 84 % , closing the gap between in - domain and out - of - domain performance .We study self - training with products of latent variable grammars in this paper .", "label": "", "metadata": {}, "score": "50.851627"}
{"text": "A second group of papers does parsing by a sequence of independent , discriminative decisions , either greedily or with use of a small beam ( Ratnaparkhi , 1997 ; Henderson , 2004 ) .This paper extends th ... \" ...", "label": "", "metadata": {}, "score": "50.878174"}
{"text": "Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation .On the other hand , our grammars are much more compact and substantially more accurate than previous work on automatic annotation .Despite its simplicity , our best grammar achieves an F1 of 89.9 % on the Penn Treebank , higher than most fully lexicalized systems .", "label": "", "metadata": {}, "score": "50.896904"}
{"text": "In the Penn Treebank , transitions between upper- and lowercase tokens tend to align with the boundaries of base ( English ) noun phrases .Such signals can be used as partial bracketing constraints to train a grammar inducer : in our experiments , directed dependency accuracy increased by 2.2 % ( average over 14 languages having case information ) .", "label": "", "metadata": {}, "score": "50.981438"}
{"text": "The above data structure naturally lends itself to one particular algorithm for comparing the identity or subsumption of ontological features .The algorithm relies on the implementation of the tree by associating with each node in the tree an integer value that represents the position of that node within the hierarchical structure .", "label": "", "metadata": {}, "score": "50.99141"}
{"text": "The result is that the time complexity of structure - comparison algorithms attains the polynomial order of the number of features ( or nodes ) being compared .This fact makes the use of ontologies inefficient for high - performance computing applications , such as searching terabyte - sized databases with wide - ranging conceptual content .", "label": "", "metadata": {}, "score": "51.068962"}
{"text": "Second , how can we efficiently infer optimal structures within them ?Hierarchical coarse - to - fine methods address both questions .Coarse - to - fine approaches exploit a sequence of models which introduce complexity gradually .At the top of the sequence is a trivial model in which learning and inference are both cheap .", "label": "", "metadata": {}, "score": "51.23311"}
{"text": "Instead , they must traverse the list of links and compare structures on a node - by - node basis to guarantee identity .Complicating this procedure is the fact that concepts may be cross - linked across multiple branches of a tree , sharing multiple structures .", "label": "", "metadata": {}, "score": "51.27504"}
{"text": "The LALR parser is widely used and is better known as the approach used by parser generators such as yacc and bison .While the description is a preferred embodiment , it will be understood that any implementation of a context - free grammar within a similar architecture , including such variants as an LALR-2 parser ( which looks ahead by two words ) , are within the scope of the present invention .", "label": "", "metadata": {}, "score": "51.31669"}
{"text": "State - of - the - art natural language processing models are anything but compact .Syntactic parsers have huge grammars , machine translation systems have huge transfer tables , and so on across a range of tasks .With such complexity come two challenges .", "label": "", "metadata": {}, "score": "51.370075"}
{"text": "The system of the present invention maintains arguments as variables during the parsing process , and automatically fills in long - distance dependencies as part of the parsing process .No post - parsing analysis is needed to obtain this benefit , and the parsing time is not impacted by the maintenance of these variables , thus resulting in faster parsing execution .", "label": "", "metadata": {}, "score": "51.479095"}
{"text": "If a model will not work well , we would want to discover that fact before investing months of effort in building a new translation decoder .If a reranking experiment shows that a new model has good potential , the effort of building a decoder that can take advantage of its strengths may then be justified .", "label": "", "metadata": {}, "score": "51.493492"}
{"text": "Consequently , a parser that handles both of these conditions is needed .The parser 230 must pursue all possible parse trees , in effect branching and pursuing more than one path at every ambiguity .The standard LALR parser is a finite state machine designed to build a parse tree from the set of grammar rules ( called productions ) one input symbol at a time .", "label": "", "metadata": {}, "score": "51.9823"}
{"text": "Tools . by Slav Petrov , Leon Barrett , Romain Thibaux , Dan Klein - In ACL ' 06 , 2006 . \" ...We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank .", "label": "", "metadata": {}, "score": "51.994476"}
{"text": "This paper defines a generative probabilistic model of parse trees , which we call PCFG - LA .This model is an extension of PCFG in which non - terminal symbols are augmented with latent variables .Finegrained CFG rules are automatically induced from a parsed corpus by training a PCFG - LA model using an E ... \" .", "label": "", "metadata": {}, "score": "52.02277"}
{"text": "This has led to concer ... \" .Statistical parsers trained and tested on the Penn Wall Street Journal ( WSJ ) treebank have shown vast improvements over the last 10 years .Much of this improvement , however , is based upon an ever - increasing number of features to be trained on ( typically ) the WSJ treebank data .", "label": "", "metadata": {}, "score": "52.065544"}
{"text": "This manual labor scales linearly with the number of target relations .This paper introduces Open IE ( OIE ) , a new extraction paradigm where the system makes a single data - driven pass over its corpus and extracts a large set of relational tuples without requiring any human input .", "label": "", "metadata": {}, "score": "52.207253"}
{"text": ".. ations are used to define grammatical roles .The original treebanks , in particular the Penn Treebank , were for English , and provided only phrase structure trees , and hence this is the native ou ... . by Slav Petrov , Leon Barrett , Romain Thibaux , Dan Klein - In ACL ' 06 , 2006 . \" ...", "label": "", "metadata": {}, "score": "52.235626"}
{"text": "This paper investigates the role of resource allocation as a source of processing difficulty in human sentence comprehension .The paper proposes a simple informationtheoretic characterization of processing difficulty as the work incurred by resource reallocation during parallel , incremental , probabi ... \" .", "label": "", "metadata": {}, "score": "52.260685"}
{"text": "We apply our method to train parsers that excel when used as part of a reordering component in a statistical machine translation system .We use a corpus of weakly - labeled reference reorderings to guide parser training .Our best parsers contribute significant improvements in subjective translation quality while their intrinsic attachment scores typically regress .", "label": "", "metadata": {}, "score": "52.28632"}
{"text": "However , it is clear from the tree above that not all differences are equally meaningful .In order for the magnitude of the difference to be relevant , it must first be the case that one of the concepts inherits all the properties of the others .", "label": "", "metadata": {}, "score": "52.451447"}
{"text": "Such worries have merit .The standard \" Charniak parser \" checks in at a labeled precisionrecall f - measure of 89.7 % on the Penn WSJ test set , but only 82.9 % on the test set from the Brown treebank corpus .", "label": "", "metadata": {}, "score": "52.577682"}
{"text": "Shifting to a new domain requires the user to name the target relations and to ma ... \" .Traditionally , Information Extraction ( IE ) has focused on satisfying precise , narrow , pre - specified requests from small homogeneous corpora ( e.g. , extract the location and time of seminars from a set of announcements ) .", "label": "", "metadata": {}, "score": "52.628494"}
{"text": "This shows that the Lynx parser compares favorably with an established parser , which is good .However , this result is made more meaningful by the observation that the Link parser is the source of all the training data for the Lynx parser .", "label": "", "metadata": {}, "score": "52.72149"}
{"text": "The present invention relates to an ontological parser for natural language processing .More particularly , the present invention relates to a system and method for ontological parsing of natural language that provides a simple knowledge - base - style representation format for the manipulation of natural - language documents .", "label": "", "metadata": {}, "score": "52.74395"}
{"text": "Admittedly , the Lynx parser does not score better than its source of training data , only about the same .However , on 30 % of the sentences evaluated , the Lynx parser scores better than the Link parser , showing that it actually does have a significant improvement in the ability to parse some sentences , offset by inferior performance on some other sentences .", "label": "", "metadata": {}, "score": "53.015766"}
{"text": "The beam - search decoder only requires the syntactic processing task to be broken into a sequence of decisions , such that , at each stage in the process , the decoder is able to consider the top - n candidates and generate all possibilities for the next stage .", "label": "", "metadata": {}, "score": "53.111454"}
{"text": "The beam - search decoder only requires the syntactic processing task to be broken into a sequence of decisions , such that , at each stage in the process , the decoder is able to consider the top - n candidates and generate all possibilities for the next stage .", "label": "", "metadata": {}, "score": "53.111454"}
{"text": "The figure above shows the average distance between the rankings of various systems and the NIST - score ranking , grouped by sentence length .The sentences were grouped by length into bins of width five .Six different system combinations were compared : the original decoder score , the Lynx score , both of these together , and each of these three with the LinkSet score .", "label": "", "metadata": {}, "score": "53.159058"}
{"text": "Across various hierarchical encoding schemes and for multiple language pairs , we show speed - ups of up to 50 times over single - pass decoding while improving BLEU score .Moreover , our entire decoding cascade for trigram language models is faster than the corresponding bigram pass alone of a bigram - to - trigram decoder .", "label": "", "metadata": {}, "score": "53.214035"}
{"text": "Our approach , which implicitly incorporates knowledge into the design of an over - arching statistical model , is in many ways more elegant because it has a simple probabilistic interpretation and is very flexible in its ability to be trained on new data without special programming .", "label": "", "metadata": {}, "score": "53.26259"}
{"text": "The difference is simply a digit - by - digit comparison that starts with the most significant bit and continues until the first decimal digit difference is located .Importantly , though , the differences due to inheritance along incompatible sub - trees do not correspond to elements of natural - language meaning .", "label": "", "metadata": {}, "score": "53.28517"}
{"text": "Any remaining minor node may be deleted .The remaining minor nodes are repartitioned into left and right sets .On either side , a new minor node may be inserted .Inserted nodes correspond to null links .The probability of a foreign sentence tree given an English sentence tree is the product over all nodes in the English tree of the probabilities of applying these transformations in a way that results in the foreign sentence tree .", "label": "", "metadata": {}, "score": "53.448723"}
{"text": "An alternate way of combining knowledge with statistical modeling is to incorporate plenty of small statistical models into what is structurally a knowledge - based system , which could also be pictured as a rule - based system in which statistical models govern the application of each rule .", "label": "", "metadata": {}, "score": "53.47354"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 1 , wherein said sentence lexer comprises : . a document iterator that receives text input and outputs individual sentences ; . a lexer that receives said individual sentences from said document iterator and outputs individual words ; and . an ontology that receives said individual words from said lexer and returns ontological entities or words tagged with default assumptions about an ontological status of said individual words to said lexer .", "label": "", "metadata": {}, "score": "53.577904"}
{"text": "The parse probability filter vetoes parse trees that fall below a minimum probability for valid semantic interpretation .The parse probability filter will calculate the probability of a sentence parse by taking the product of the probabilities of the syntactic rules used to generate a given parse tree .", "label": "", "metadata": {}, "score": "53.62249"}
{"text": "However , these rules are often too rigid to accommodate real - world utterances , which often bend the rules of ' ' correct ' ' grammar in creative ways , or include minor errors , but are still easily comprehensible by human listeners .", "label": "", "metadata": {}, "score": "53.730873"}
{"text": "Information - extraction ( IE ) systems seek to distill semantic relations from naturallanguage text , but most systems use supervised learning of relation - specific examples and are thus limited by the availability of training data .Open IE systems such as TextRunner , on the other hand , aim to handle the unbounded number of relations found on the Web .", "label": "", "metadata": {}, "score": "53.827595"}
{"text": "Predicate structures are representations of logical relationships between the words in a sentence .Every predicate structure contains a predicate , which is either a verb or a preposition , and a set of arguments , which may be any part of speech .", "label": "", "metadata": {}, "score": "53.952957"}
{"text": "Primary acoustic , speech , and vision systems were trained to discriminate instances of the categories .Higher - level systems exploited correlations among the categories , incorporated sequential context , and combined the joint evidence from the three information sources .", "label": "", "metadata": {}, "score": "53.963818"}
{"text": "Standard inference can be used at test time .Our approach is able to scale to very large problems and yields significantly improved target domain accuracy .It is well known that parsing accuracies drop significantly on out - of - domain data .", "label": "", "metadata": {}, "score": "53.996395"}
{"text": "The paper defines weighted head transducers , finite - state machines that perform middle - out string transduction .These transducers are strictly more expressive than the special case of standard leftto - right finite - state transducers .Dependency transduction models are then defined as collections of wei ... \" .", "label": "", "metadata": {}, "score": "54.027496"}
{"text": "The paper defines weighted head transducers , finite - state machines that perform middle - out string transduction .These transducers are strictly more expressive than the special case of standard leftto - right finite - state transducers .Dependency transduction models are then defined as collections of wei ... \" .", "label": "", "metadata": {}, "score": "54.027496"}
{"text": "We first show how recent insights on selective parameter sharing , based on typological and language - family fe ... \" .We study multi - source transfer parsing for resource - poor target languages ; specifically methods for target language adaptation of delexicalized discriminative graph - based dependency parsers .", "label": "", "metadata": {}, "score": "54.111607"}
{"text": "The best accuracies were in the 80 - 84\\% range for F1 and LAS ; even part - of - speech accuracies were just above 90\\% .Coarse - to - fine inference has been shown to be a robust approximate method for improving the efficiency of structured prediction models while preserving their accuracy .", "label": "", "metadata": {}, "score": "54.12126"}
{"text": "This simple framework performs surprisingly well , giving accuracy results competitive with the state - of - the - art on all the tasks we consider .The computational simplicity of the decoder and training algorithm leads to significantly higher test speeds and lower training times than their main alternatives , including log - linear and large - margin training algorithms and dynamic - programming for decoding .", "label": "", "metadata": {}, "score": "54.21823"}
{"text": "This simple framework performs surprisingly well , giving accuracy results competitive with the state - of - the - art on all the tasks we consider .The computational simplicity of the decoder and training algorithm leads to significantly higher test speeds and lower training times than their main alternatives , including log - linear and large - margin training algorithms and dynamic - programming for decoding .", "label": "", "metadata": {}, "score": "54.21823"}
{"text": "7 is another example parse tree incorporating real words according to the present invention .DETAILED DESCRIPTION OF THE INVENTION .In the following detailed discussion of the present invention , numerous terms , specific to the subject matter of a system and method for concept - based searching , are used .", "label": "", "metadata": {}, "score": "54.364338"}
{"text": "The term concept as used herein means an abstract formal representation of meaning , which corresponds to multiple generic or specific words in multiple languages .Concepts may represent the meanings of individual words or phrases , or the meanings of entire sentences .", "label": "", "metadata": {}, "score": "54.483433"}
{"text": "Knowledge bases contain instances of real data , which represent a location somewhere within the ontology .Validating the equivalence of an instance with a concept in an ontology entails comparing the features of an instance with the features of a concept .", "label": "", "metadata": {}, "score": "54.491806"}
{"text": "Participants were to build a single parsing system that is robust to domain changes and can handle noisy text that is commonly encountered on the web .There was a constituency and a dependency parsing track and 11 sites submitted a total of 20 systems .", "label": "", "metadata": {}, "score": "54.558365"}
{"text": "A discriminative reranker requires a source of candidate parses for each sentence .This paper describes a simple yet novel method for constructing sets of 50-best parses based on a co ... \" .Discriminative reranking is one method for constructing high - performance statistical parsers ( Collins , 2000 ) .", "label": "", "metadata": {}, "score": "54.565178"}
{"text": "Parse tree converter 240 receives the output of the parser 230 , and converts the parse trees into predicates .Following the Parse tree converter , parser filters 250 operate or the predicates to remove erroneously generated predicates based on rules about the probability of syntactic analyses , as well as rules about the compatibility of concepts with each other .", "label": "", "metadata": {}, "score": "54.653072"}
{"text": "To facilitate future research in unsupervised induction of syntactic structure and to standardize best - practices , we propose a tagset that consists of twelve universal part - of - speech categories .In addition to the tagset , we develop a mapping from 25 different treebank tagsets to this universal set .", "label": "", "metadata": {}, "score": "54.662933"}
{"text": "To facilitate future research in unsupervised induction of syntactic structure and to standardize best - practices , we propose a tagset that consists of twelve universal part - of - speech categories .In addition to the tagset , we develop a mapping from 25 different treebank tagsets to this universal set .", "label": "", "metadata": {}, "score": "54.662933"}
{"text": "In this paper , we present a syntax - based statistical machine translation system based on a probabilistic synchronous dependency insertion grammar .Synchronous dependency insertion grammars are a ... \" .Syntax - based statistical machine translation ( MT ) aims at applying statistical models to structured data .", "label": "", "metadata": {}, "score": "54.736168"}
{"text": "In this paper , we present a syntax - based statistical machine translation system based on a probabilistic synchronous dependency insertion grammar .Synchronous dependency insertion grammars are a ... \" .Syntax - based statistical machine translation ( MT ) aims at applying statistical models to structured data .", "label": "", "metadata": {}, "score": "54.736168"}
{"text": "We discuss how the general framework is applied to each of the problems studied in this article , making comparisons with alternative learning and decoding algorithms .We also show how the comparability of candidates considered by the beam is an important factor in the performance .", "label": "", "metadata": {}, "score": "54.818363"}
{"text": "We discuss how the general framework is applied to each of the problems studied in this article , making comparisons with alternative learning and decoding algorithms .We also show how the comparability of candidates considered by the beam is an important factor in the performance .", "label": "", "metadata": {}, "score": "54.818363"}
{"text": "Our formulation uses a factorization analogous to the standard dynamic programs for parsing .In particular , it allows one to efficiently learn a model which discriminates ... \" .We present a novel discriminative approach to parsing inspired by the large - margin criterion underlying support vector machines .", "label": "", "metadata": {}, "score": "54.830276"}
{"text": "We report statistics on TEXTRUNNER 's 11,000,000 highest probability tuples , and show that they contain over 1,000,000 concrete facts and over 6,500,000 more abstract assertions . \" ...We present several improvements to unlexicalized parsing with hierarchically state - split PCFGs .", "label": "", "metadata": {}, "score": "54.86762"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 6 , wherein a first digit difference between two nodes provides a measure of the degree of ontological proximity of two concepts .", "label": "", "metadata": {}, "score": "55.023468"}
{"text": "In the Penn Treebank , transitions between upper- and lowercase tokens tend to align with the boundaries of base ( English ) noun phrases .Such signals can be used as partial bracketing constraints to train a grammar inducer : in ou ... \" .", "label": "", "metadata": {}, "score": "55.029816"}
{"text": "This paper describes a simple yet novel method for constructing sets of 50-best parses based on a coarse - to - fine generative parser ( Charniak , 2000 ) .This method generates 50-best lists that are of substantially higher quality than previously obtainable . by Marie - Catherine de Marneffe , Bill MacCartney , Christopher D. Manning - IN PROC .", "label": "", "metadata": {}, "score": "55.186356"}
{"text": "This robustness led to the third best overall average labeled attachment score in the task , despite using no discriminative methods .We also demonstrate that the parser is quite fast , and can provide even faster parsing times without much loss of accuracy . \" ...", "label": "", "metadata": {}, "score": "55.253723"}
{"text": "This robustness led to the third best overall average labeled attachment score in the task , despite using no discriminative methods .We also demonstrate that the parser is quite fast , and can provide even faster parsing times without much loss of accuracy . \" ...", "label": "", "metadata": {}, "score": "55.253723"}
{"text": "We then show how the parser can be relexicalized and adapted using unlabeled target language data and a learning method that can incorporate diverse knowledge sources through ambiguous labelings .In the latter scenario , we exploit two sources of knowledge : arc marginals derived from the base parser in a self - training algorithm , and arc predictions from multiple transfer parsers in an ensemble - training algorithm .", "label": "", "metadata": {}, "score": "55.33828"}
{"text": "On WSJ15 , we attain a state - of - the - art F - score of 90.9 % , a 14 % relative reduction in error over previous models , while being two orders of magnitude faster .On sentences of length 40 , our system achieves an F - score of 89.0 % , a 36 % relative reduction in error over a generative baseline . ...", "label": "", "metadata": {}, "score": "55.341644"}
{"text": "Our first- , second- , and third - order models achieve accuracies comparable to those of their unpruned counterparts , while exploring only a fraction of the search space .We observe speed - ups of up to two orders of magnitude compared to exhaustive search .", "label": "", "metadata": {}, "score": "55.390823"}
{"text": "A side benefit from this algorithm is that it provides an intuitive , natural ranking algorithm .Larger values from the subtraction operation mean further distance apart in the tree , so even when two concepts are in the same branch , the representation provides a convenient metric of conceptual distance .", "label": "", "metadata": {}, "score": "55.395935"}
{"text": "These trees are implemented via a variety of techniques , which are generally equivalent to doubly - linked lists .Doubly - linked lists must be created with head and tail nodes , which terminate the list and are designed to keep traversals of the list in bounds .", "label": "", "metadata": {}, "score": "55.497078"}
{"text": "For example , another possible encoding of the ontology tree might involve a 40-digit decimal number .In such a case , 4 digits could be assigned to each node of the tree , implying that the tree could have up to 10 levels of depth .", "label": "", "metadata": {}, "score": "55.59729"}
{"text": "Despite the much simplified training process , our acoustic model achieves state - of - the - art results on phone classification ( where it outperforms almost all other methods ) and competitive performance on phone recognition ( where it outperforms standard CD triphone / subphone / GMM approaches ) .", "label": "", "metadata": {}, "score": "55.613827"}
{"text": "The algorithm uses a similarity graph to encourage similar n - grams to have similar POS tags .We demonstrate the efficacy of our approach on a domain adaptation task , where we assume that we have access to large amounts of unlabeled data from the target domain , but no additional labeled data .", "label": "", "metadata": {}, "score": "55.633076"}
{"text": "Shay , 2009 . \" ...We present a family of priors over probabilistic grammar weights , called the shared logistic normal distribution .This family extends the partitioned logistic normal distribution , enabling factored covariance between the probabilities of different derivation events in the probabilistic grammar , prov ... \" .", "label": "", "metadata": {}, "score": "55.91826"}
{"text": "This structure guarantees that an arbitrary number of nodes may be inserted into the list without losing track of the locations of existing nodes , as well as enabling the list to be searched from either the top or bottom .However , the great flexibility of tree data structures , which may encompass trees of arbitrary depth , also imposes a significant cost in computability .", "label": "", "metadata": {}, "score": "55.92595"}
{"text": "While this would probably increase computational and memory requirements , a cleverly integrated system could probably accomplish this kind of training without massively increasing the ( already quite high ) processing burden for training .Such a system would probably give better results ; whether they would be significantly better is hard to say without having time to actually do the experiment .", "label": "", "metadata": {}, "score": "55.99066"}
{"text": "This method allows various models to be compared on the translation task without requiring a whole new translation system to be built each time .Thus , a reranking approach will tend to underestimate the potential of a new model because its range of outputs is artificially constrained .", "label": "", "metadata": {}, "score": "56.01046"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said noun filter groups proper nouns into single lexical nouns .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "56.031967"}
{"text": "FIG .3 , for the input string ' ab . 'An example of a context - free grammar that would be used in implementing the parser is as follows : .The modified LALR parser generator , grammar , and modified LALR parsing engine discussed previously should generate a non - deterministic recursive parser .", "label": "", "metadata": {}, "score": "56.058075"}
{"text": "The paper presents the design and implementation of the BioNLP'09 Shared Task , and reports the final results with analysis .The shared task consists of three sub - tasks , each of which addresses bio - molecular event extraction at a different level of specificity .", "label": "", "metadata": {}, "score": "56.36374"}
{"text": "The paper presents the design and implementation of the BioNLP'09 Shared Task , and reports the final results with analysis .The shared task consists of three sub - tasks , each of which addresses bio - molecular event extraction at a different level of specificity .", "label": "", "metadata": {}, "score": "56.36374"}
{"text": "On sentences of up to length 40 , LLCCM outperforms CCM by 13.9 % bracketing F1 and outperforms a right - branchin ... \" .We present LLCCM , a log - linear variant of the constituent context model ( CCM ) of grammar induction .", "label": "", "metadata": {}, "score": "56.46125"}
{"text": "We can then subtract numbers to see if the features are in agreement , and a non - negative result suffices to prove this .Since 1 is nonnegative , we know that the features are in agreement .If concepts are identical , they will subtract to zero , which is equivalent to passing the filter by having two identical strings .", "label": "", "metadata": {}, "score": "56.46942"}
{"text": "It would certainly be possible to compute these dynamically , since any tree - search algorithm must keep track of which branches it traverses in trying to locate a particular node .However , as the search backtracks and corrects its path a fair number of adjustments and recalculations of the current node value would likely result .", "label": "", "metadata": {}, "score": "56.501083"}
{"text": "We show how to apply loopy belief propagation ( BP ) , a simple and effective tool for approximate learning and inference .As a parsing algorithm , BP is both asymptotically and empirically efficient .E ... \" .We formulate dependency parsing as a graphical model with the novel ingredient of global constraints .", "label": "", "metadata": {}, "score": "56.550625"}
{"text": "We show how to apply loopy belief propagation ( BP ) , a simple and effective tool for approximate learning and inference .As a parsing algorithm , BP is both asymptotically and empirically efficient .E ... \" .We formulate dependency parsing as a graphical model with the novel ingredient of global constraints .", "label": "", "metadata": {}, "score": "56.550625"}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the step of vetoing parse trees that fall below a minimum probability for semantic interpretation .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "56.676563"}
{"text": "We use the Margin Infused Relaxed Algorithm of Crammer et al . to add a large number of new features to two machine translation systems : the Hiero hierarchical phrasebased translation system and our syntax - based translation system .On a large - scale Chinese - English translation task , we obtain statisti ... \" .", "label": "", "metadata": {}, "score": "56.692947"}
{"text": "We use the Margin Infused Relaxed Algorithm of Crammer et al . to add a large number of new features to two machine translation systems : the Hiero hierarchical phrasebased translation system and our syntax - based translation system .On a large - scale Chinese - English translation task , we obtain statisti ... \" .", "label": "", "metadata": {}, "score": "56.692947"}
{"text": "Each score is the F 1 combination of precision and recall , and the improvement is the margin by which Lynx does better than the baseline .Unsurprisingly , the English version of the parser is most able to exceed the performance of its baseline .", "label": "", "metadata": {}, "score": "56.84071"}
{"text": "For example , in an information retrieval application , it is capable of pulling out stopwords and unintended query words ( as in the pseudo - concept and pseudo - predicate filters ) .In the embodiment discussed above , the grammar violation checking of the system and method of the present invention filters both by the probability of a syntactically successful parse and the compatibility of the lexical semantics of words in the ontology .", "label": "", "metadata": {}, "score": "57.00494"}
{"text": "Still another object of the present invention is to provide a system and method for parsing natural language input that transforms data using a syntactic parser and ontology , where the ontology is used as a lexical resource .Yet another object of the present invention is to provide a system and method for parsing natural language input that provides ontological entities as output that are predicate - argument structures .", "label": "", "metadata": {}, "score": "57.01715"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said pseudo - concept filter removes concepts from queries .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "57.08591"}
{"text": "The results show that all three systems achieve competitive performance , with a best labeled attachment score over 88 % .All three parsers benefit from the use of automatically derived lemmas , while morphological features seem to be less important .", "label": "", "metadata": {}, "score": "57.183502"}
{"text": "The results show that all three systems achieve competitive performance , with a best labeled attachment score over 88 % .All three parsers benefit from the use of automatically derived lemmas , while morphological features seem to be less important .", "label": "", "metadata": {}, "score": "57.183502"}
{"text": "The modal verb filter will contain a set of modal verbs similar to the stop word list contained in stop word filter .Any Lexeme whose text is in that set and whose concept is a verb is identified as a modal verb , and will be removed .", "label": "", "metadata": {}, "score": "57.25741"}
{"text": "To globally model parsing actions of all steps that are taken on the inpu ... \" .Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .They only determine parsing actions stepwisely by a trained classifier .", "label": "", "metadata": {}, "score": "57.272667"}
{"text": "To globally model parsing actions of all steps that are taken on the inpu ... \" .Deterministic dependency parsers use parsing actions to construct dependencies .These parsers do not compute the probability of the whole dependency tree .They only determine parsing actions stepwisely by a trained classifier .", "label": "", "metadata": {}, "score": "57.272667"}
{"text": "A key to intelligent design is leaving room for expansion .As long as the maximum depth of trees is not reached , adding additional levels is transparent .The trade - off in a parameterized ontology is selecting the size of a data structure so that it is no larger than it needs to be , but with adequate room for correcting mistakes or expanding coverage later on .", "label": "", "metadata": {}, "score": "57.274887"}
{"text": "If the ontological tree structure is carefully crafted , proximity within the tree should , in some measure , correspond to ontological proximity .Therefore , detecting the first digit difference , as above , gives a reasonable measure of the degree of ontological proximity of the two concepts .", "label": "", "metadata": {}, "score": "57.371384"}
{"text": "This paper presents WOE , an open IE system which improves dramatically on TextRunner 's precision and recall .The key to WOE 's performance is a novel form of self - supervised learning for open extractors - using heuristic matches between Wikipedia infobox attribute values and corresponding sentences to construct training data .", "label": "", "metadata": {}, "score": "57.45691"}
{"text": "The stop word filter will contain a set of words accepted as stop words ; any lexeme whose text is in that set is considered to be a stop word .An adjective filter serves to remove lexemes representing adjective concepts from sentences .", "label": "", "metadata": {}, "score": "57.481884"}
{"text": "We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .", "label": "", "metadata": {}, "score": "57.769318"}
{"text": "We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .", "label": "", "metadata": {}, "score": "57.769318"}
{"text": "We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .", "label": "", "metadata": {}, "score": "57.769318"}
{"text": "We use a generative history - based model to predict the most likely derivation of a dependency parse .Our probabilistic model is based on Incremental Sigmoid Belief Networks , a recently proposed class of latent variable models for structure prediction .", "label": "", "metadata": {}, "score": "57.769318"}
{"text": "Languages such as Japanese or Russian , which permit free ordering of words , but mark intended usage by morphological changes , would be difficult to parse using the Brash system .The patent to Hemphill et al .( U.S. Pat .", "label": "", "metadata": {}, "score": "57.94802"}
{"text": "It should be readily apparent that the ordering of elements of the code can be arbitrary , but must be used consistently in order to compare features .There are two ways to construct a parameterized ontology .The first method is to simply freeze an existing ontology , write a program to find the maximum tree depths and number of branches , and then write another program to recode the pointer information into array elements and depths .", "label": "", "metadata": {}, "score": "58.12992"}
{"text": "The decision - making process occurs at intermediate parsing stages , and parse probabilities are considered before all parse paths have been pursued .Intermediate parse probability calculations have to be stored , and the system has to check for intermediate feature clashes .", "label": "", "metadata": {}, "score": "58.47621"}
{"text": "Statistical methods are effective for many natural language processing tasks , including automatic translation and parsing .This thesis brings these two applications together in two ways , using translation to aid parser construction and using parsing to improve translation quality .", "label": "", "metadata": {}, "score": "58.80301"}
{"text": "To evaluate the system - generated rankings , we measured the rank - order distance between each system 's ranking for each sentence and the corresponding rankings given by BLEU score and by NIST score .We used the Kendall rank correlation ( \u03c4 ) as a measure of agreement between rankings ; this distance is the number of adjacent pairs that must be swapped in order to bring the rankings into agreement .", "label": "", "metadata": {}, "score": "58.893944"}
{"text": "In particular , we show that the reranking parser described in Charniak and Johnson ( 2005 ) improves performance of the parser on Brown to 85.2 % .Furthermore , use of the self - training techniques described in ( Mc - Closky et al . , 2006 ) raise this to 87.8 % ( an error reduction of 28 % ) again without any use of labeled Brown data .", "label": "", "metadata": {}, "score": "58.978096"}
{"text": "Having described several embodiments of the concept - based indexing and search system in accordance with the present invention , it is believed that other modifications , variations and changes will be suggested to those skilled in the art in view of the description set forth above .", "label": "", "metadata": {}, "score": "59.064293"}
{"text": "This operation may be accomplished in several ways : .If the ontology used by the parser only contains string labels for the nodes in a tree structure , the tree leading to the restriction must be established as a sub - tree of the selectional features of the argument .", "label": "", "metadata": {}, "score": "59.32534"}
{"text": "Since the parser is both probabilistic and operating on multiple streams of possible ontological entities , it is necessary to prune out spurious parse trees generated by the parser 230 .Parser filters 250 are designed to prune out spurious parse trees generated by the parser 230 , by removing trees that violate either statistical or ontological criteria for well - formed - ness .", "label": "", "metadata": {}, "score": "59.366753"}
{"text": "A predicate structure is a data type that includes a predicate and multiple additional concepts ; as a grouping of concepts , it is itself a concept .An ontology is a hierarchically organized complex data structure that provides a context for the lexical meaning of concepts .", "label": "", "metadata": {}, "score": "59.405666"}
{"text": "We present an evaluation measure that takes into account the possibility of incompatible token segmentation between the gold standard and the parsed data .Results indicate that ( a ) MST - parser performs better on Hebrew data than Malt - Parser , and ( b ) both parsers do not make good use of morphological information when parsing Hebrew . ... s on Hebrew dependency parsing .", "label": "", "metadata": {}, "score": "59.47174"}
{"text": "We present an evaluation measure that takes into account the possibility of incompatible token segmentation between the gold standard and the parsed data .Results indicate that ( a ) MST - parser performs better on Hebrew data than Malt - Parser , and ( b ) both parsers do not make good use of morphological information when parsing Hebrew . ... s on Hebrew dependency parsing .", "label": "", "metadata": {}, "score": "59.47174"}
{"text": "A proper noun is any word or phrase representing a non - generic noun concept .Although a number of proper nouns are already present in the lexicon , they are already properly treated as regular lexical items .Since proper nouns behave syntactically as regular nouns , there is no need to distinguish proper nouns and nouns already in the lexicon .", "label": "", "metadata": {}, "score": "59.52178"}
{"text": "They also permit the use of well - understood , generalpurpose learning algorithms .There has been an increased interest in using probabilistic grammars in the Bayesian setting .To date , most of the literature has focused on using a Dirichlet prior .", "label": "", "metadata": {}, "score": "59.64746"}
{"text": "They also permit the use of well - understood , generalpurpose learning algorithms .There has been an increased interest in using probabilistic grammars in the Bayesian setting .To date , most of the literature has focused on using a Dirichlet prior .", "label": "", "metadata": {}, "score": "59.64746"}
{"text": "On sentences of up to length 40 , LLCCM outperforms CCM by 13.9 % bracketing F1 and outperforms a right - branching baseline in regimes where CCM does not . ... ependency grammar induction .Nevertheless , simplistic dependency models like the DMV do not contain information present in a cons ... . \" ...", "label": "", "metadata": {}, "score": "59.77819"}
{"text": "As a parsing algorithm , BP is both asymptotically and empirically efficient .Even with second - order features or latent variables , which would make exact parsing considerably slower or NP - hard , BP needs only O(n3 ) time with a small constant factor .", "label": "", "metadata": {}, "score": "59.830772"}
{"text": "As a parsing algorithm , BP is both asymptotically and empirically efficient .Even with second - order features or latent variables , which would make exact parsing considerably slower or NP - hard , BP needs only O(n3 ) time with a small constant factor .", "label": "", "metadata": {}, "score": "59.830772"}
{"text": "( ii ) Punctuation at sentence boundaries further helps distinguish full sentences from fragments like headlines and titles , allowing us to model grammatical differences between complete and incomplete sentences .( iii ) Sentence - internal punctuation boundaries help with longer - distance dependencies , since punctuation correlates with constituent edges .", "label": "", "metadata": {}, "score": "59.87815"}
{"text": ".. by Aoife Cahill , Michael Burke , Josef Van Genabith , Andy Way - In Proceedings of the 42nd Meeting of the ACL , 2004 . \" ...This paper shows how finite approximations of long distance dependency ( LDD ) resolution can be obtained automatically for wide - coverage , robust , probabilistic Lexical - Functional Grammar ( LFG ) resources acquired from treebanks .", "label": "", "metadata": {}, "score": "59.88462"}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the step of vetoing parse trees having conflicts between selectional features of concepts serving as arguments to a second concept and restrictions of said second concept .", "label": "", "metadata": {}, "score": "59.973335"}
{"text": "Since algorithm design and implementation are distinct and separable issues , an embodiment of a parameterized ontology 's data structures has not yet been discussed .The following is a suggested implementation .The proposed data structure includes an integer value , where each digit of the integer corresponds to a specific branch taken at the corresponding level in the tree .", "label": "", "metadata": {}, "score": "60.12947"}
{"text": "This proposal subsumes and clarifies findings that high - constraint contexts can facilitate lexical processing , and connects these findings to well - known models of parallel constraint - based comprehension .In addition , the theory leads to a number of specific predictions about the role of expectation in syntactic comprehension , including the reversal of locality - based difficulty patterns in syntactically constrained contexts , and conditions under which increased ambiguity facilitates processing .", "label": "", "metadata": {}, "score": "60.276817"}
{"text": "The French version , on the other hand , is almost the reverse of the Chinese : While failing to improve very much over its baseline , it does quite well overall , with high precision and recall .The French baseline scores higher than the English baseline , perhaps because the French sentences are more consistently right - branching than English or Chinese , or perhaps because the hand - annotator favored right - branching interpretations of the sentences .", "label": "", "metadata": {}, "score": "60.299232"}
{"text": "This representation also provides optimized execution of the difference comparison , since using hexadecimals instead of decimals optimizes the logical digit - by - digit comparison to a computer - efficient byte - by - byte comparison .It should also be noted that the above examples of decimal , hexadecimal , or multi - digit hexadecimal are typical parameter choices for the node encoding included in the present invention .", "label": "", "metadata": {}, "score": "60.348866"}
{"text": "\" It is worth noting that once the first digit difference is detected , there is no further need to compute remaining digits .They diverge at level 3 , the third digit in the representation , and thereafter lie along completely different sub - trees that do not intersect .", "label": "", "metadata": {}, "score": "60.440315"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said adverb filter removes lexemes containing adverb concepts from said individual sentences .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "60.5802"}
{"text": "A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 39 , wherein a most significant digit difference between two nodes provides a measure of the degree of ontological proximity of two concepts .", "label": "", "metadata": {}, "score": "60.682842"}
{"text": "The new Viewer adds three features for more powerful search : wildcards , morphological inflections , and capitalization .These additions allow the discovery of patterns that were previously difficult to find and further facilitate the study of linguistic trends in printed text .", "label": "", "metadata": {}, "score": "60.776794"}
{"text": "As a parsing algorithm , BP is both asymptotically and empirically efficient .E ... \" .We formulate dependency parsing as a graphical model with the novel ingredient of global constraints .We show how to apply loopy belief propagation ( BP ) , a simple and effective tool for approximate learning and inference .", "label": "", "metadata": {}, "score": "60.86683"}
{"text": "We also present a proof that owl - qn is guaranteed to converge to a globally optimal parameter vector . \" ...Statistical parsers trained and tested on the Penn Wall Street Journal ( WSJ ) treebank have shown vast improvements over the last 10 years .", "label": "", "metadata": {}, "score": "60.967484"}
{"text": "Dunja Mladinic , Turning Yahoo into an Automatic Web Page Classifier , ECAI 98:13th European Conference on Artificial Intelligence , Brighton , UK , Aug. 23 to Aug. 28 , 1998 , pp .473 - 474 , John Wiley & Sons , Ltd. .", "label": "", "metadata": {}, "score": "60.997276"}
{"text": "The configuration of the parser 200 is shown in FIG .2 .First , the sentence receiver 220 obtains sentences 210 consisting of ontological entities produced by the sentence lexer 100 .These sentences are parsed by the parser 230 , which is designed to use a context - free grammar , although other grammatical models may be used without departing from the scope and spirit of the invention .", "label": "", "metadata": {}, "score": "61.00674"}
{"text": "We report on experiments over a 9,000,000 Web page corpus that compare TEXTRUNNER with KNOWITALL , a state - of - the - art Web IE system .TEXTRUNNER achieves an error reduction of 33 % on a comparable set of extractions .", "label": "", "metadata": {}, "score": "61.0551"}
{"text": "We present a new edition of the Google Books Ngram Corpus , which describes how often words and phrases were used over a period of five centuries , in eight languages ; it reflects 6 % of all books ever published .", "label": "", "metadata": {}, "score": "61.242104"}
{"text": "claim 6 , wherein said predicates and arguments are represented by encodings comprising at least one digit separated into multiple groups to provide multiple ontological levels and a branching factor at each node .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 2 , further comprising lexer filters for modifying said individual sentences based on word meanings .", "label": "", "metadata": {}, "score": "61.52023"}
{"text": "The noun must follow either immediately after the adjective , or have only adjective and conjunction words appearing between the noun and the adjective .If no such noun or conjunction is found , the adjective filter will veto the sentence .", "label": "", "metadata": {}, "score": "61.584435"}
{"text": "If a noun is found and it satisfies the restrictions of the adjective , the adjective filter will apply the selectional features of the adjective to the noun by adding all of the adjective 's selectional features to the noun 's set of selectional features .", "label": "", "metadata": {}, "score": "61.61747"}
{"text": "Another object of the present invention is to provide a system and method for parsing natural language input that realizes enormous speed benefits from the parameterized ontology that the parser utilizes .BRIEF DESCRIPTION OF THE DRAWINGS .These and other attributes of the present invention will be described with respect to the following drawings in which : .", "label": "", "metadata": {}, "score": "62.059868"}
{"text": "We present a novel approach which employs a randomized sequence of pruning masks .Formally , we apply auxiliary variable MCMC sampling to generate this sequence of masks , thereby gaining theoretical guarantees about convergence .Because each mask is generally able to skip large portions of an underlying dynamic program , our approach is particularly compelling for high - degree algorithms .", "label": "", "metadata": {}, "score": "62.216637"}
{"text": "At every cycle , a new character is read from the input stream and the character and current state are used to look up , in the action table , which action to perform .The actions are in one of the following forms : .", "label": "", "metadata": {}, "score": "62.33008"}
{"text": "claim 23 , wherein said parse probability filter vetoes parse trees that fall below a minimum probability for semantic interpretation .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 1 , wherein said system is modular to permit the use of any part - of - speech - tagged ontology .", "label": "", "metadata": {}, "score": "62.463943"}
{"text": "claim 28 , wherein the step of parsing comprises the step of looking ahead one word , scanning input from left - to - right , and constructing said parse tree .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "62.82064"}
{"text": "The Stanford Parser is used to derive dependencies from CJ50 and gold parse trees .Figure 8 shows the detailed P / R curves .We can see that although today ... .by Jenny Rose Finkel , Alex Kleeman , Christopher D. Manning - In Proc .", "label": "", "metadata": {}, "score": "62.838165"}
{"text": "Crucially , a limitation of this assumption is that substantially more effort must be applied in crafting the ontology , since re - indexing large volumes of text becomes extraordinarily expensive as the text grows .The designers of a parameterized ontology must be certain that their coverage is adequate before making a decision to freeze the structure .", "label": "", "metadata": {}, "score": "62.840492"}
{"text": "claim 38 , further comprising the step of representing said parse trees by modified hexadecimal numbers that have an octet of hexadecimal pairs to provide eight ontological levels and a branching factor at each node of 256 .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "63.260303"}
{"text": "Two rules are included in this example of a pseudo - concept filter implementation .The first rule is that any word relating to the user , or his current situation , such as \" I \" or \" me \" is always deleted .", "label": "", "metadata": {}, "score": "63.45691"}
{"text": "Consequently , ten is too small to constrain the branching factor for each level .The use of a hexadecimal representation would improve this some by increasing the branching factor to 16 .Thus , using a 16-digit ( i.e. , a 64-bit ) hexadecimal number gives 16 branches at each node for 16 levels : 16 16 possible concepts .", "label": "", "metadata": {}, "score": "63.496265"}
{"text": "Pseudo - predicate verbs include \" give \" , \" show \" , and \" find \" .Not all instances of these verbs are pseudo - predicates ; however , the first instance of them in a query often is .", "label": "", "metadata": {}, "score": "63.67785"}
{"text": "A 10-digit decimal number allows 10 10 , or 10 billion possible concepts to be stored in the tree .That is a sufficient number of total concepts , but the branching factor is too small .There can be a maximum of ten possible branches out of each node to the next level .", "label": "", "metadata": {}, "score": "63.83106"}
{"text": "Lexer filters 150 are modular plug - ins , which modify sentences based on knowledge about word meanings .The preferred embodiment contains several filters 150 , although more may be developed , and existing filters may be removed from future versions , without altering the scope of the invention .", "label": "", "metadata": {}, "score": "64.16728"}
{"text": "Even with second - order features or latent variables , which would make exact parsing considerably slower or NP - hard , BP needs only O(n3 ) time with a small constant factor .Furthermore , such features significantly improve parse accuracy over exact first - order methods .", "label": "", "metadata": {}, "score": "64.6545"}
{"text": "claim 30 , further comprising the step of assigning numbers to said concepts .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in . claim 34 , further comprising the step of subtracting said numbers to determine if features are in agreement , wherein a negative number indicates feature incompatibility .", "label": "", "metadata": {}, "score": "64.98131"}
{"text": "Meanwhile , Graphics Processor Units ( GPUs ) have become widely available , offering the opportunity to alleviate this bottleneck by exploiting the fine - grained data parallelism found in the CKY algorithm .In this paper , we explore the design space of parallelizing the dynamic programming computations carried out by the CKY algorithm .", "label": "", "metadata": {}, "score": "65.07944"}
{"text": "Consider a sample path through an ontology : .In this example , if the argument position of a predicate must be an example of transportation , then any of the three more - specific words will be an acceptable argument for the predicate .", "label": "", "metadata": {}, "score": "65.36102"}
{"text": "The path starts at the root node ( Level 1 ) and takes the 2nd branch to level 2 , then takes the 3rd branch from that node to get to level 3 .The final \" 0 \" is a terminator , indicating that this particular node of the tree is not at the lowest possible level of the tree ; it does not necessarily indicate that no nodes branch from this level .", "label": "", "metadata": {}, "score": "66.07802"}
{"text": "This family extends the partitioned logistic normal distribution , enabling factored covariance between the probabilities of different derivation events in the probabilistic grammar , providing a new way to encode prior knowledge about an unknown grammar .We describe a variational EM algorithm for learning a probabilistic grammar based on this family of priors .", "label": "", "metadata": {}, "score": "66.083466"}
{"text": "In this work , we present 1 . an effective method for pruning in split PCFGs 2 . a comparison of objective functions for infe ... . \" ...The l - bfgs limited - memory quasi - Newton method is the algorithm of choice for optimizing the parameters of large - scale log - linear models with L2 regularization , but it can not be used for an L1-regularized loss due to its non - differentiability whenever some parameter is zero .", "label": "", "metadata": {}, "score": "66.12119"}
{"text": "claim 28 , further comprising the step of modifying said natural language sentence based on word meanings .A method of ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 28 , further comprising the steps of : . receiving sentences including ontological entities ; . parsing said sentences including ontological entities into parse trees representing concepts in the corresponding sentence including ontological entities ; and . converting said parse trees into predicates .", "label": "", "metadata": {}, "score": "66.289696"}
{"text": "A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 11 , wherein said stop word filter removes stop words from said individual sentences .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "66.68036"}
{"text": "WOE can operate in two modes : when restricted to POS tag features , it runs as quickly as TextRunner , but when set to use dependency - parse features its precision and recall rise even higher . ... h recall .", "label": "", "metadata": {}, "score": "66.76074"}
{"text": "This assumption is that the number of branches in an ontological hierarchy , and their depth , can be determined by designing it to fixed parameters at the time of creation , and by selecting maximum values for the branches and the depths .", "label": "", "metadata": {}, "score": "66.96767"}
{"text": "claim 3 , wherein said numbers can be subtracted to determine if features are in agreement , wherein a negative number indicates feature incompatibility .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .", "label": "", "metadata": {}, "score": "67.24582"}
{"text": "2009 ) , which are likely sensitive to the proverbial \" bum steer \" from unrepresentative short fragments , pace Tu and Honavar ( 2011 ) . \" ...We consider the problem of using a bilingual dictionary to transfer lexico - syntactic information from a resource - rich source language to a resource - poor target language .", "label": "", "metadata": {}, "score": "67.26961"}
{"text": "4 is an example parse tree according to the present invention ; .FIG .5 is another example parse tree according to the present invention ; .FIG .6 is another example parse tree according to the present invention ; and .", "label": "", "metadata": {}, "score": "67.46177"}
{"text": "claim 6 , wherein said parse trees is represented by modified hexadecimal digits that have an octet of hexadecimal pairs to provide eight ontological levels and a branching factor at each node of 256 .A method of ontological parsing that converts natural - language text into predicate - argument format comprising the steps of : . converting a natural language sentence into a sequence of ontological entities that are tagged with part - of - speech information ; and . converting said sequence of ontological entities into predicate structures using a two - stage process that analyzes the grammatical structure of the natural language sentence and binds arguments into predicates .", "label": "", "metadata": {}, "score": "67.74814"}
{"text": "We show that dependency parsers have more difficulty parsing questions than constituency parsers .In particular , deterministic shift - reduce dependency parsers , which are of highest interest for practical applications because of their linear running time , drop to 60 % labeled accuracy on a question test set .", "label": "", "metadata": {}, "score": "67.84114"}
{"text": "For example , consider a tree shown in FIG .7 .It is clear that in some cases , it is useful to know the distance between words , but that it is not equally useful in all cases .However , since neither of these terms shares any properties beyond \" organic \" with \" amino acid , \" it is not helpful to know the distance between \" bread \" and \" amino acid , \" even though they are only one level apart .", "label": "", "metadata": {}, "score": "67.963936"}
{"text": "The modal verb filter removes modal verbs from sentence objects .Modal verbs are verbs such as \" should \" , \" could \" , and \" would \" .Such verbs alter the conditions under which a sentence is true , but do not affect the basic meaning of the sentence .", "label": "", "metadata": {}, "score": "68.10135"}
{"text": "If a highly accurate selector could be trained to choose which parser has a better analysis of each sentence , a gain of almost 5 percentage points is possible .Why is the Lynx parser able to score better than its source of training data on so many sentences ?", "label": "", "metadata": {}, "score": "68.330215"}
{"text": "Similar features will have similar paths through the tree .Referring to .FIG .5 , an example is illustrated .Node A is represented with the decimal number \" 1212 . \"Node B is represented with the decimal number \" 1220 .", "label": "", "metadata": {}, "score": "68.49788"}
{"text": "Thus , for example , the node to Node A 's immediate left , is represented by \" 1211 .\" When the difference comparison is made , it works out to be \" 0001 , \" which implies a correspondingly close ontological relationship between the two concepts .", "label": "", "metadata": {}, "score": "69.40614"}
{"text": "4 .Each arrowhead in .FIG .4 represents a concept node .The deeper into the tree ( i.e. , the higher the numbered level of the concept node ) , the more specific the concept is .Consider one path through FIG .", "label": "", "metadata": {}, "score": "69.62988"}
{"text": "Reduce actions cause the parser to finish the current production and replace the assembled symbols with the symbol that replaces them ; .Accepts cause the parser to finish assembling a complete parse tree and halt ; .Errors cause the parser to give up because no grammar rule is available to reconcile what has already been parsed with what remains in the input stream .", "label": "", "metadata": {}, "score": "69.828186"}
{"text": "The penalty for a recognition failure is often small : if two con- figurations are confused , they are often similar to each other , and the illusion works well enough , for instance , to drive a graphics animation of the moving hand .", "label": "", "metadata": {}, "score": "70.20111"}
{"text": "We present an algorithm Orthant - Wise Limited - memory Quasi - Newton ( owlqn ) , based on l - bfgs , that can efficiently optimize the L1-regularized log - likelihood of log - linear models with millions of parameters .", "label": "", "metadata": {}, "score": "70.61397"}
{"text": "Despite such an improvement over a decimal representation , the branching factor of only 16 is still unacceptably small .A solution to this is to use a modified hexadecimal representation .Since it is unlikely that a reasonable , specialized ontology will need more than eight levels of general concept representation , a 16-digit hexadecimal number can be interpreted slightly differently , as an octet of hexadecimal pairs : .", "label": "", "metadata": {}, "score": "71.26596"}
{"text": "Behavior Control : Finally we show how all these elements can be incorporated into a goal keeping robot .We develop simple behaviors that can be used in a layered architecture and enable the robot to block most balls that are being shot at the goal .", "label": "", "metadata": {}, "score": "71.875"}
{"text": "Ball Tracking :The reliable tracking of the ball is vital in robot soccer .Therefore a Kalman - filter based system for estimating the ball position and velocity in the presence of occlusions is developped . -Sensor Fusion : The robot perceives its environment through several independent sensors ( camera , odometer , etc . ) , which have different delays .", "label": "", "metadata": {}, "score": "72.20299"}
{"text": "Similar to the lexer filters 150 , the parser filters 250 may be chained together to form a list of filters to be applied to each candidate parse tree .Each parser filter 250 will keep track of the filter that should be applied immediately before it , and will submit candidate parse trees to that filter before performing a filtering function .", "label": "", "metadata": {}, "score": "72.66968"}
{"text": "This would add 8 bytes of total storage to each node in the tree .For a 10,000-concept tree , this is only 80 KB .For a 100,000-concept tree , it is 800 KB .And for a 1,000,000-concept tree , it is 8 MB .", "label": "", "metadata": {}, "score": "73.186676"}
{"text": "The standard LALR parser generator algorithm fails when the grammar does not provide the parser generator enough information to decide whether the correction to perform given a certain current state and input symbol is to shift or to reduce .The generator algorithm also fails when the grammar does not provide the parser generator enough information to decide which of two or more rules should be reduced .", "label": "", "metadata": {}, "score": "73.41667"}
{"text": "These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation .Therefore , the standard evaluation does not provide a true indication of algorithm quality .We present a new measure , Neutral Edge Direction ( NED ) , and show that it greatly reduces this undesired phenomenon .", "label": "", "metadata": {}, "score": "73.9274"}
{"text": "These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation .Therefore , the standard evaluation does not provide a true indication of algorithm quality .We present a new measure , Neutral Edge Direction ( NED ) , and show that it greatly reduces this undesired phenomenon .", "label": "", "metadata": {}, "score": "73.9274"}
{"text": "A predicate structure built from \" eat \" might thus require that the object of the predicate have a code beginning with \" 112 .\" As can be seen from the tree shown , it is clear that all the foods listed inherit the \" 112 \" prefix .", "label": "", "metadata": {}, "score": "75.26828"}
{"text": "The l - bfgs limited - memory quasi - Newton method is the algorithm of choice for optimizing the parameters of large - scale log - linear models with L2 regularization , but it can not be used for an L1-regularized loss due to its non - differentiability whenever some parameter is zero .", "label": "", "metadata": {}, "score": "75.58403"}
{"text": "Additional trials , in which varying weights were used for each system , gave almost identical results .All of these best combinations include the Lynx score .This chart shows that among these systems , the Lynx score is the best approximation of the ranking given by the NIST scores , and that no combination of systems significantly outperforms the unadorned Lynx score .", "label": "", "metadata": {}, "score": "76.61471"}
{"text": "The shared task was run over 12 weeks , drawing initial interest from 42 teams .Of these teams , 24 submitted final results .The evaluation results are encouraging , indicating that state - of - the - art performance is approaching a practically applicable level and revealing some remaining challenges . ... parsers . \" ...", "label": "", "metadata": {}, "score": "76.79924"}
{"text": "claim 22 , wherein said parser filters include a selectional restriction filter and a parse probability filter .A system for ontological parsing that converts natural - language text into predicate - argument format as recited in .claim 23 , wherein said selectional restriction filter vetoes parse trees having conflicts between selectional features of concepts serving as arguments to a second concept and restrictions of said second concept .", "label": "", "metadata": {}, "score": "78.02905"}
{"text": "Following that , it would be passed to the lexer 120 , which would access the ontology 140 , and return the sequence : .The - det octopus - noun have - verb a - det heart - noun .Here , det stands for determiner , which is a word with a purely grammatical function , namely specifying a noun phrase .", "label": "", "metadata": {}, "score": "78.91411"}
{"text": "Computers fail to track these in fast video , but sleight of hand fools humans as well : what happens too quickly we just can not see .We show a 3D tracker for these types of motions that relies on the recognition of familiar configurations in 2D images ( classification ) , and fills the gaps in - between ( interpolation ) .", "label": "", "metadata": {}, "score": "79.84376"}
{"text": "A minor node is selected ( from among those listed at the current major node ) to head the current major node .The selected node may be replaced with one of its descendants .( This is called head - deletion . )", "label": "", "metadata": {}, "score": "82.24786"}
{"text": "Description .Applicants hereby incorporate by reference co - pending application Ser .No .09/627,295 filed in the U.S. Patent and Trademark Office on Jul. 27 , 2000 , entitled \" Concept - Based Search and Retrieval System . \" BACKGROUND OF THE INVENTION .", "label": "", "metadata": {}, "score": "83.927986"}
{"text": "A selectional restriction filter vetoes any parse tree where there are conflicts between the selectional features of the concepts serving as arguments to another concept and the restrictions of that concept .Selectional restrictions are imposed on the argument positions of predicate structures .", "label": "", "metadata": {}, "score": "86.36383"}
{"text": "For instance , 14.4 % of section 23 is tagged differently by ( 1 ) and ( 2 ) 8 .5 The Neutral Edge Direction ( NED ) Me ... . by Shay B. Cohen , Noah A. Smith , Alex Clark , Dorota Glowacka , Colin De La Higuera , Mark Johnson , John Shawe - taylor . \" ...", "label": "", "metadata": {}, "score": "87.9989"}
{"text": "For instance , 14.4 % of section 23 is tagged differently by ( 1 ) and ( 2 ) 8 .5 The Neutral Edge Direction ( NED ) Me ... . by Shay B. Cohen , Noah A. Smith , Alex Clark , Dorota Glowacka , Colin De La Higuera , Mark Johnson , John Shawe - taylor . \" ...", "label": "", "metadata": {}, "score": "87.9989"}
{"text": "This Master 's thesis describes parts of the control software used by the soccer robots of the Free University of Berlin , the so called FU - Fighters .The FU - Fighters compete in the Middle Sized League of RoboCup and reached the semi - finals during the 2004 RoboCup World Cup in Lisbon , Portugal .", "label": "", "metadata": {}, "score": "89.51317"}
{"text": "Suppose that a user of a search engine which makes use of this parser asks the question : .Do octopuses have hearts ?The sentence lexer 100 will read the question , and a sentence made of ontological entities is produced .", "label": "", "metadata": {}, "score": "95.19176"}
{"text": "In the parser 220 , the tree shown in .FIG .6 is produced .The parse tree converter 230 then converts this tree into a predicate , where octopus is the subject of have , and heart is the object .", "label": "", "metadata": {}, "score": "95.86819"}
{"text": "Thus , when the sentence passes through the lexer filters 150 as discussed in the previous example embodiment , the stop word filter removes \" a \" and \" the , \" leaving : . octopus - noun have - verb heart - noun .", "label": "", "metadata": {}, "score": "96.405685"}
{"text": "Do - verb octopus - noun have - verb heart - noun .In the preferred embodiment 's lexer filters , the pseudo predicate filter removes the first verb \" do , \" because it is not the main verb of the sentence . \"", "label": "", "metadata": {}, "score": "97.075775"}
{"text": "The example sentence is : .The octopus has a heart .First , the sentence lexer 100 would process this sentence .The first component of the sentence lexer 100 , the document iterator 110 , would extract this sentence from the document it was contained in .", "label": "", "metadata": {}, "score": "104.872665"}
