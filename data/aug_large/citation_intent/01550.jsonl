{"text": "Yet , several problems are widely acknowledged with this approach .First , other link types than hyperonymy can usefully be exploited to establish semantic similarity .Yet other scholars have attempted to widen the range of relationships on the basis of which semantic similarity can be computed ; see , among others , [ Nir93b ] who also use morphological information and antonyms .", "label": "", "metadata": {}, "score": "23.00255"}
{"text": "Accurately representing synonymy using distributional similarity requires large volumes of data to reliably represent infrequent words .However , the na\u00efve nearestneighbour approach to comparing context vectors extracted from large corpora scales poorly ( O(n 2 ) in the vocabulary size ) .", "label": "", "metadata": {}, "score": "27.889053"}
{"text": "Accurately representing synonymy using distributional similarity requires large volumes of data to reliably represent infrequent words .However , the na\u00efve nearestneighbour approach to comparing context vectors extracted from large corpora scales poorly ( O(n 2 ) in the vocabulary size ) .", "label": "", "metadata": {}, "score": "27.889053"}
{"text": "Although many types of relation exist , the only distinction that typically is drawn is a broad one between semantic similarity and associative relatedne ... . \" ...A central concern of psycholinguistic research is explaining the relative ease or difficulty involved in processing words .", "label": "", "metadata": {}, "score": "28.21686"}
{"text": "Our analysis revealed that a major reason for the rather loose semantic similarity obtained by distributional similarity methods is insufficient quality of the word feature vectors , caused by deficient feature weighting .This observation led to the definition of a bootstrapping scheme which yields improved feature weights , and hence higher quality feature vectors .", "label": "", "metadata": {}, "score": "28.670933"}
{"text": "In Rada et al .[Rad89 ] and Lee et al .[ Lee93 ] , the assessment of semantic similarity is done with respect to hyperonymy ( IS - A ) links .Under this approach , semantic similarity is evaluated in terms of the distance between the nodes corresponding to the items being compared in a taxonomy : the shorter the path from one node to another , the more similar they are .", "label": "", "metadata": {}, "score": "28.67246"}
{"text": "Furthermore , the combination of the two methods provides the best accuracy . ... hem , is related to the restriction of combinations of these entities relative to other entities .Similarity means that words with similar meaning tend to appear in similar contexts .", "label": "", "metadata": {}, "score": "30.752861"}
{"text": "Typically , semantic similarity is computed either on the basis of taxonomical relationships such as hyperonymy and synonymy or through distributional evidence .The former approach presupposes prior availability of independent hierarchically structured sources of lexico - semantic information such as WordNet [ Mil90a ] .", "label": "", "metadata": {}, "score": "31.116291"}
{"text": "As we saw above , two words can be considered to be semantically related if they typically co - occur within the same context .In the section on distributionally - based semantic similarity , we showed that word co - occurrence patterns are instrumental for identifying clusterings of semantically similar words .", "label": "", "metadata": {}, "score": "31.80453"}
{"text": "The notion of taxonomy - based semantic similarity crucially hinges on words ' membership of more general semantic classes .By contrast , distributionally - based semantic similarity rests on the assumption that words entering into the same syntagmatic relation with other words can be seen as semantically similar , although in this case the similarity may be grounded on some covert properties orthogonal to their general semantic superclass .", "label": "", "metadata": {}, "score": "32.288918"}
{"text": "We argue that groups of unannotated texts with overlapping and non - contradictory semantics represent a valuable source of information for learning semantic representations .A simple and efficient inference method recursively induces joint semantic representations for each group and discovers correspondence between lexical entries and latent semantic concepts .", "label": "", "metadata": {}, "score": "32.29405"}
{"text": "The knowledge sources used for computing relatedness can be as different as dictionaries , ontologies or large corpora .According to Budanitsky and Hirst ( 2006 ) , there are three prevalent approaches ... . \" ...We argue that groups of unannotated texts with overlapping and non - contradictory semantics represent a valuable source of information for learning semantic representations .", "label": "", "metadata": {}, "score": "32.320946"}
{"text": "Collected patterns were successfully used for different disambiguation purposes .For instance , [ Hin93 ] show how structural ambiguities such as prepositional phrase attachment can be resolved on the basis of the relative strength of association of words , estimated on the basis of distribution in an automatically parsed corpus .", "label": "", "metadata": {}, "score": "33.230064"}
{"text": "By contrast , syntagmatic aspects of lexical meaning form a less prominent topic of lexical semantics which in the literature is generally referred to as co - occurrence restrictions .Nowadays , a new trend in the lexical semantics literature is emerging which questions the watertight classification of meanings presupposed by traditional approaches to lexical semantics .", "label": "", "metadata": {}, "score": "33.681"}
{"text": "Evaluating semantic relatedness measures is usually performed by comparison with human judgments .Previous test datasets had been created analytically and were limited in size .We propose a corpus - based system for automatic ... \" .Semantic relatedness is a special form of linguistic distance between words .", "label": "", "metadata": {}, "score": "34.22249"}
{"text": "The triples are automatically extracted from a shallow - parsed corpus .Accordingly two target words are taken to be semantically close if they occur as modifiers of the same headword .The authors , unfortunately , do not use this technique to construct word classes .", "label": "", "metadata": {}, "score": "35.614914"}
{"text": "Such an approach , combining a taxonomic structure with empirical probability estimates , provides a way of tailoring a static knowledge structure such as a semantic taxonomy onto specific texts .The thrust of distributionally - based semantic similarity rests on the idea that the semantic content of a target word T can to a large extent be characterised in terms of ( a description of ) how T accompanies with other words in a corpus .", "label": "", "metadata": {}, "score": "35.82793"}
{"text": "\" ...Traditionally , vector - based semantic space models use word co - occurrence counts from large corpora to represent lexical meaning .In this article we present a novel framework for constructing semantic spaces that takes syntactic relations into account .", "label": "", "metadata": {}, "score": "36.743214"}
{"text": "Fortunately , statistical corpus analysis is an obvious area of overlap for IR and FLP .Hearst ( 1992 ) shows how a pattern like \" Xs and other Ys \" can be used to construct more fluid , context - specific taxonomies than th ... . \" ...", "label": "", "metadata": {}, "score": "36.831867"}
{"text": "We claim that such simple distributional statistics can form the basis of a parsimonious model of lexical processing effort . \" ...Traditional vector - based models use word co - occurrence counts from large corpora to represent lexical meaning .In this paper we present a novel approach for constructing semantic spaces that takes syntactic relations into account .", "label": "", "metadata": {}, "score": "37.001698"}
{"text": "This paper considers how fluent language users are rational in their language processing , their unconscious language representation systems optimally prepared for comprehension and production , how language learners are intuitive statisticians , and how acquisition can be understood as contingency learning .", "label": "", "metadata": {}, "score": "37.45092"}
{"text": "We label the semantic relations between categories using methods based on connectivity in the network and lexicosyntactic matching .As a result we are able to derive a large scale taxonomy containing a large amount of subsumption , i.e ... \" .", "label": "", "metadata": {}, "score": "37.573936"}
{"text": "DLSIUAES .RTE5 .FIRST USE : Similarity between lemmata , computed by WordNet - based metrics .SECOND USE : antonymy relations between verbs .THIRD USE : synonymy / identity between verb lemmata in T and H. FOURTH USE ( WordNet+Framenet ) : WordNet synonym and hyponym relations from T 's frame elements to H 's frame elements .", "label": "", "metadata": {}, "score": "37.778416"}
{"text": "DLSIUAES .RTE5 .FIRST USE : Similarity between lemmata , computed by WordNet - based metrics .SECOND USE : antonymy relations between verbs .THIRD USE : synonymy / identity between verb lemmata in T and H. FOURTH USE ( WordNet+Framenet ) : WordNet synonym and hyponym relations from T 's frame elements to H 's frame elements .", "label": "", "metadata": {}, "score": "37.778416"}
{"text": "DLSIUAES .RTE5 .FIRST USE : Similarity between lemmata , computed by WordNet - based metrics .SECOND USE : antonymy relations between verbs .THIRD USE : synonymy / identity between verb lemmata in T and H. FOURTH USE ( WordNet+Framenet ) : WordNet synonym and hyponym relations from T 's frame elements to H 's frame elements .", "label": "", "metadata": {}, "score": "37.778416"}
{"text": "DLSIUAES .RTE5 .FIRST USE : Similarity between lemmata , computed by WordNet - based metrics .SECOND USE : antonymy relations between verbs .THIRD USE : synonymy / identity between verb lemmata in T and H. FOURTH USE ( WordNet+Framenet ) : WordNet synonym and hyponym relations from T 's frame elements to H 's frame elements .", "label": "", "metadata": {}, "score": "37.778416"}
{"text": "DLSIUAES .RTE5 .FIRST USE : Similarity between lemmata , computed by WordNet - based metrics .SECOND USE : antonymy relations between verbs .THIRD USE : synonymy / identity between verb lemmata in T and H. FOURTH USE ( WordNet+Framenet ) : WordNet synonym and hyponym relations from T 's frame elements to H 's frame elements .", "label": "", "metadata": {}, "score": "37.778416"}
{"text": "DLSIUAES .RTE5 .FIRST USE : Similarity between lemmata , computed by WordNet - based metrics .SECOND USE : antonymy relations between verbs .THIRD USE : synonymy / identity between verb lemmata in T and H. FOURTH USE ( WordNet+Framenet ) : WordNet synonym and hyponym relations from T 's frame elements to H 's frame elements .", "label": "", "metadata": {}, "score": "37.778416"}
{"text": "DLSIUAES .RTE5 .FIRST USE : Similarity between lemmata , computed by WordNet - based metrics .SECOND USE : antonymy relations between verbs .THIRD USE : synonymy / identity between verb lemmata in T and H. FOURTH USE ( WordNet+Framenet ) : WordNet synonym and hyponym relations from T 's frame elements to H 's frame elements .", "label": "", "metadata": {}, "score": "37.778416"}
{"text": "During the calculation of the similarity measures we treat words from T and H that are synonyms according to WordNet as identical .Ablation test performed .Negative impact of the resource : -2 % accuracy on two - way , -2.67 % on three - way task .", "label": "", "metadata": {}, "score": "37.965565"}
{"text": "Improved feature weighting also allows massive feature reduction , which indicates that the most characteristic features .The rationale behind this inference is that if two words are distributionally similar then the occurrence of one word in some contexts indicates that the other word is also likely to occur in such ... . \" ...", "label": "", "metadata": {}, "score": "38.10986"}
{"text": "Agirre and Rigau [ Agi96 ] propose a semantic similarity measure which , besides the length of the path , is sensitive to .the depth of the nodes in the hierarchy ( deeper nodes are ranked closer ) , and .", "label": "", "metadata": {}, "score": "38.211483"}
{"text": "Distributional information ( information abou ... \" .A central concern of psycholinguistic research is explaining the relative ease or difficulty involved in processing words .In this thesis , we explore the connection between lexical processing effort and measurable properties of the linguistic environment .", "label": "", "metadata": {}, "score": "38.36327"}
{"text": "Unlike all approaches considered so far , whereby word clusters are defined once and for all by averaging out counts for words in context , semantic proportional analogy varies depending on the context .Thus , the same word T selects a different closest analogue depending whether T is considered in the company of the object O i or the object O j .", "label": "", "metadata": {}, "score": "38.36518"}
{"text": "The method was motivated by attempts to utilize distributional similarity for identifying the concrete semantic relationship of lexical entailment .Our analys ... \" .This article presents a novel bootstrapping approach for improving the quality of feature vector weighting in distributional word similarity .", "label": "", "metadata": {}, "score": "38.383545"}
{"text": "Hereafter we will refer to type 1 . similarity as ' ' semantic similarity ' ' tout court while referring to type 2 . similarity more loosely as ' ' semantic relatedness ' ' .As we will see , the two aspects are obviously interconnected ( and in fact they are often not kept apart in the literature ) although we find it useful for classificatory purposes to maintain the distinction .", "label": "", "metadata": {}, "score": "38.740845"}
{"text": "UB.dmirg .RTE5 .When using WordNet , we assume that a term is semantically interchangeable with its exact occurrence , its synonyms , and its hypernyms .In extracting hypernyms , we exclude the hypernyms that are more distant than two links to the original terms in WordNet synsets .", "label": "", "metadata": {}, "score": "39.040253"}
{"text": "UB.dmirg .RTE5 .When using WordNet , we assume that a term is semantically interchangeable with its exact occurrence , its synonyms , and its hypernyms .In extracting hypernyms , we exclude the hypernyms that are more distant than two links to the original terms in WordNet synsets .", "label": "", "metadata": {}, "score": "39.040253"}
{"text": "UB.dmirg .RTE5 .When using WordNet , we assume that a term is semantically interchangeable with its exact occurrence , its synonyms , and its hypernyms .In extracting hypernyms , we exclude the hypernyms that are more distant than two links to the original terms in WordNet synsets .", "label": "", "metadata": {}, "score": "39.040253"}
{"text": "UB.dmirg .RTE5 .When using WordNet , we assume that a term is semantically interchangeable with its exact occurrence , its synonyms , and its hypernyms .In extracting hypernyms , we exclude the hypernyms that are more distant than two links to the original terms in WordNet synsets .", "label": "", "metadata": {}, "score": "39.040253"}
{"text": "UB.dmirg .RTE5 .When using WordNet , we assume that a term is semantically interchangeable with its exact occurrence , its synonyms , and its hypernyms .In extracting hypernyms , we exclude the hypernyms that are more distant than two links to the original terms in WordNet synsets .", "label": "", "metadata": {}, "score": "39.04026"}
{"text": "In real taxonomies , it has been noted that the ' ' distance ' ' covered by individual taxonomic links is variable , due to the fact that , for instance , certain sub - taxonomies are much denser than others .", "label": "", "metadata": {}, "score": "39.051033"}
{"text": "NLP methods and applications need to take account not only of \" classical \" lexical rela - tions , as found in WordNet , but the less - structural , more context - dependent \" non - classical \" relations that readers intuit in text .", "label": "", "metadata": {}, "score": "39.569584"}
{"text": "Distributionally - based semantic similarity is computed on both terms of these relations .Thus , verbs are taken to be semantically similar if they share some words serving as direct object or subject .By the same token , nouns are semantically similar if they serve as subject and/or object for a shared subset of verbs .", "label": "", "metadata": {}, "score": "39.78801"}
{"text": "SECOND USE : contradiction detection based on antonymy relation .FIRST USE : .Ablation test performed .Positive impact of the resource : +3.17 % accuracy on two - way , +4 % on three - way task .During the calculation of the similarity measures we treat words from T and H that are synonyms according to WordNet as identical .", "label": "", "metadata": {}, "score": "40.09011"}
{"text": "We label the semantic relations between categories using methods based on connectivity in the network and lexicosyntactic matching .As a result we are able to derive a large scale taxonomy containing a large amount of subsumption , i.e. isa , relations .", "label": "", "metadata": {}, "score": "40.437786"}
{"text": "The quantification of lexical semantic relatedness has many applications in NLP , and many different measures have been proposed .We evaluate five of these measures , all of which use WordNet as their central resource , by comparing their performance in detecting and correcting real - word spelling error ... \" .", "label": "", "metadata": {}, "score": "40.457394"}
{"text": "A reader 's perception of even an \" objective \" text is to some degree subjective .We present the results of a pilot study in which we looked at the degree of subjectivity in readers ' per - ceptions of lexical semantic relations , which are the building blocks of the lexical chains used in many applications in nat - ural language processing .", "label": "", "metadata": {}, "score": "40.855713"}
{"text": "Sense relations are of two fundamental types : paradigmatic and syntagmatic .Paradigmatic relations such as synonymy , hyperonymy / hyponymy , antonymy or meronymy occupy focal positions in discussions of lexical semantics ( see , for instance , [ Cru86 ] ) .", "label": "", "metadata": {}, "score": "41.61682"}
{"text": "This similarity measure is referred to as ' ' conceptual density ' ' measure .Resnik [ Res95 ] defines a taxonomic similarity measure which dispenses with the path length approach and is based on the notion of information content .Under his view , semantic similarity between two words is represented by the entropy value of the most informative concept subsuming the two in a semantic taxonomy , the WordNet lexical database ( see \u00a7 3.4.2 ) in the case at hand .", "label": "", "metadata": {}, "score": "41.69218"}
{"text": "These processing effects are crucial in the interpretation of meaning - it is thus that an i .. by Jane Morris , Graeme Hirst - AAAI Spring Symposium on Exploring Affect and Attitude in Text , 2004 . \" ...A reader 's perception of even an \" objective \" text is to some degree subjective .", "label": "", "metadata": {}, "score": "41.862328"}
{"text": "These include words which have the same orthography and part of speech as the synonyms defining the concept as well as the concept 's superordinates .Each time a word W p is encountered in K , the count of each concepts c p subsuming W p ( in any of its senses ) is increased by one : .", "label": "", "metadata": {}, "score": "42.089317"}
{"text": "Traditionally , vector - based semantic space models use word co - occurrence counts from large corpora to represent lexical meaning .In this article we present a novel framework for constructing semantic spaces that takes syntactic relations into account .We introduce a formalization for this class of models , which allows linguistic knowledge to guide the construction process .", "label": "", "metadata": {}, "score": "42.18164"}
{"text": "We evaluate five of these measures , all of which use WordNet as their central resource , by comparing their performance in detecting and correcting real - word spelling errors .An information - content - based measure proposed by Jiang and Conrath is found superior to those proposed by Hirst and St - Onge , Leacock and Chodorow , Lin , and Resnik .", "label": "", "metadata": {}, "score": "42.747635"}
{"text": "In the literature , various scholars have suggested that ambiguity resolution ( e.g. prepositional phrase attachment ) is strongly influenced by the lexical content of specific words ( [ For82 , Mar80 ] to mention only a few ) .Yet , for this assumption to be assessed in practice , the necessary information about lexical associations was to be acquired .", "label": "", "metadata": {}, "score": "42.851387"}
{"text": ".. large corpora , e.g. , distributional similarity ( Church & Hanks , 1 We use Sans Serif for words and queries , CAPITALS for Wikipedia pages and SMALL CAPS for Wikipedia categories .Such unlabeled relations between words proved to be as useful for disambiguating syntactic and semantic analyses as the manually assembled knowle ... . by Simone Paolo Ponzetto , Michael Strube - JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH , 2007 . \" ... Wikipedia provides a semantic network for computing semantic relatedness in a more structured fashion than a search engine and with more coverage than WordNet .", "label": "", "metadata": {}, "score": "43.3311"}
{"text": "Approaches differ in terms of i ) how the notion of distribution is formally characterised and ii ) what distance metric is adopted to assess the proximity of two distributions .In the work reported by [ Bro91 ] , each target word T i is characterised by the words that immediately follow it in a text .", "label": "", "metadata": {}, "score": "43.71679"}
{"text": "Used in combination with VerbOcean .SECOND USE : Synonymy , hyponymy and hypernymy for nouns and adjectives .Used in combination with eXtended WordNet relations .FIRST USE : Ablation test performed ( Wordnet + VerbOcean ) .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .", "label": "", "metadata": {}, "score": "44.025337"}
{"text": "Category coordinates primed only when they were normatively associated , instrument relations primed both with and without association , and script relations primed in neither condition .The semantic priming paradigm introduced by Meyer and Schvaneveldt ( 1971 ) is one of the most widely used in psychological studies of memory and language .", "label": "", "metadata": {}, "score": "44.41078"}
{"text": "Previous test datasets had been created analytically and were limited in size .We propose a corpus - based system for automatically creating test datasets .1 Experiments with human subjects show that the resulting datasets cover all degrees of relatedness .", "label": "", "metadata": {}, "score": "44.437675"}
{"text": ".. cus .Some researchers have always included some non - classical relations , such as Evens et al .( 1983 ) , Chaffin and Herrmann ( 1984 ) , and researchers in Library and Information Science .However , as stated ... . ... diom activate other words in the idiom , then we expect significant priming in both conditions .", "label": "", "metadata": {}, "score": "44.58816"}
{"text": "Used in combination with VerbOcean .SECOND USE : Synonymy , hyponymy and hypernymy .Used in combination with eXtended WordNet relations .FIRST USE : Ablation test performed ( Wordnet + VerbOcean ) .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .", "label": "", "metadata": {}, "score": "44.704952"}
{"text": "In order to broaden the domain of the antonymy relation , we consider a combination of synonyms and antonyms .Used in combination with VerbOcean .SECOND USE : Synonymy , hyponymy and hypernymy .Used in combination with eXtended WordNet relations .", "label": "", "metadata": {}, "score": "44.75659"}
{"text": "This idea is realized via a bootstrapping step applied to an initial standard approximation of the similarity space .The superior performance of the bootstrapping method was assessed in two different experiments , one based on direct human gold - standard annotation and the other based on an automatically created disambiguation dataset .", "label": "", "metadata": {}, "score": "44.91021"}
{"text": "Negative impact of the resource : -2 % accuracy on two - way , -2.67 % on three - way task .BIU .Synonyms , hyponyms ( 2 levels away from the original term ) , the hyponym_instance relation and derivations .", "label": "", "metadata": {}, "score": "45.214066"}
{"text": "Negative impact of the resource : -2 % accuracy on two - way , -2.67 % on three - way task .BIU .Synonyms , hyponyms ( 2 levels away from the original term ) , the hyponym_instance relation and derivations .", "label": "", "metadata": {}, "score": "45.214066"}
{"text": "Negative impact of the resource : -2 % accuracy on two - way , -2.67 % on three - way task .BIU .Synonyms , hyponyms ( 2 levels away from the original term ) , the hyponym_instance relation and derivations .", "label": "", "metadata": {}, "score": "45.214066"}
{"text": "Negative impact of the resource : -2 % accuracy on two - way , -2.67 % on three - way task .BIU .Synonyms , hyponyms ( 2 levels away from the original term ) , the hyponym_instance relation and derivations .", "label": "", "metadata": {}, "score": "45.214066"}
{"text": "Negative impact of the resource : -2 % accuracy on two - way , -2.67 % on three - way task .BIU .Synonyms , hyponyms ( 2 levels away from the original term ) , the hyponym_instance relation and derivations .", "label": "", "metadata": {}, "score": "45.214066"}
{"text": "The first for Wordnet alone , the second for both WordNet and Framenet .Null impact of the resource(s ) on two - way task for both ablations .Contents .During the calculation of the similarity measures we treat words from T and H that are synonyms according to WordNet as identical .", "label": "", "metadata": {}, "score": "45.664032"}
{"text": "The first for Wordnet alone , the second for both WordNet and Framenet .Null impact of the resource(s ) on two - way task for both ablations .Contents .During the calculation of the similarity measures we treat words from T and H that are synonyms according to WordNet as identical .", "label": "", "metadata": {}, "score": "45.664032"}
{"text": "SECOND USE : Synonymy , hyponymy and hypernymy .Used in combination with eXtended WordNet relations .SECOND USE : Synonymy , hyponymy and hypernymy .Used in combination with eXtended WordNet relations .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .", "label": "", "metadata": {}, "score": "46.714554"}
{"text": "Ablation test performed .Negative impact of the resource : -2 % accuracy on two - way , -2.67 % on three - way task .BIU .Synonyms , hyponyms ( 2 levels away from the original term ) , the hyponym_instance relation and derivations .", "label": "", "metadata": {}, "score": "46.776947"}
{"text": "Used in combination with VerbOcean .In order to broaden the domain of the antonymy relation , we consider a combination of synonyms and antonyms .Used in combination with VerbOcean .SECOND USE : Synonymy , hyponymy and hypernymy .Used in combination with eXtended WordNet relations .", "label": "", "metadata": {}, "score": "47.12082"}
{"text": "Used in combination with VerbOcean .In order to broaden the domain of the antonymy relation , we consider a combination of synonyms and antonyms .Used in combination with VerbOcean .SECOND USE : Synonymy , hyponymy and hypernymy .Used in combination with eXtended WordNet relations .", "label": "", "metadata": {}, "score": "47.12082"}
{"text": "In all cases , our framework obtains results that are comparable or superior to the state of the art . 1 . by Helen E. Moss , Ruth K. Ostrin , Lorraine K. Tyler , William D. Marslen - wilson - Journal of Experimental Psychology : Learning , Memory , and Cognition , 1995 . \" ...", "label": "", "metadata": {}, "score": "47.16593"}
{"text": "The context considered may be a small or large window around the word , or an entire document ; or it may be a syntactic relationship .For example , Weeds ( 2003 ; Weeds and Weir , 2005 ) ( se ... . by Simone Paolo Ponzetto , Michael Strube - In Proceedings of AAAI , 2007 . \" ...", "label": "", "metadata": {}, "score": "47.187145"}
{"text": "We demonstrate the effectiveness of these kernels by presenting state - of - the - art results on datasets for three semantic classification : compound noun interpretation , identification of semantic relations between nominals and semantic classification of verbs .Finally , we consider explanations for the impressive performance of distributional kernels and sketch some promising generalisations . by Maayan Zhitomirsky - geffet , Ido Dagan - Computational Linguistics , 2009 . \" ...", "label": "", "metadata": {}, "score": "47.29227"}
{"text": "The authors probed for activation of information about a word 's category membership by using prime - target pairs that were members of ... \" .The types of semantic information that are automatically retrieved from the mental lexicon on hearing a word were investigated in 3 semantic priming experiments .", "label": "", "metadata": {}, "score": "48.156433"}
{"text": "In contrast , natural language generation systems normally produce uniform texts .In this paper we apply distributional similarity measures to help verb choice in a natural language generation system which tries to generate text similar to individual author .By using a distributional similarity ( DS ) measure on corpora collected from a recipe domain , we get the most likely verbs for individual authors .", "label": "", "metadata": {}, "score": "48.59581"}
{"text": "In a paired and a single - word presentation version of an auditory lexicaldecision priming task , the authors found significant priming for category and functionally related targets , both with and without an additional associative relation .In all cases there was a significant associative boost .", "label": "", "metadata": {}, "score": "48.61381"}
{"text": "for nouns and adjectives .Used in combination with eXtended WordNet relations .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .", "label": "", "metadata": {}, "score": "48.65097"}
{"text": "for nouns and adjectives .Used in combination with eXtended WordNet relations .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .", "label": "", "metadata": {}, "score": "48.65097"}
{"text": "Significant variations exist between authors .In contrast , natural language generation systems normally produce uniform texts .In this paper we apply distributional similarity measures to help verb choice in a natura ... \" .Human text is characterised by the individual lexical choices of a specific author .", "label": "", "metadata": {}, "score": "49.048492"}
{"text": "RTE5 .Use of many WordNet relations ( such as synonymy , hypernymy , hyponymy , meronymy , holonymy etc . ) to compute the relatedness between words with the same part of speech in T and H. .No ablation test performed .", "label": "", "metadata": {}, "score": "49.23085"}
{"text": "RTE5 .Use of many WordNet relations ( such as synonymy , hypernymy , hyponymy , meronymy , holonymy etc . ) to compute the relatedness between words with the same part of speech in T and H. .No ablation test performed .", "label": "", "metadata": {}, "score": "49.23085"}
{"text": "RTE5 .Use of many WordNet relations ( such as synonymy , hypernymy , hyponymy , meronymy , holonymy etc . ) to compute the relatedness between words with the same part of speech in T and H. .No ablation test performed .", "label": "", "metadata": {}, "score": "49.23085"}
{"text": "RTE5 .Use of many WordNet relations ( such as synonymy , hypernymy , hyponymy , meronymy , holonymy etc . ) to compute the relatedness between words with the same part of speech in T and H. .No ablation test performed .", "label": "", "metadata": {}, "score": "49.23085"}
{"text": "RTE5 .Use of many WordNet relations ( such as synonymy , hypernymy , hyponymy , meronymy , holonymy etc . ) to compute the relatedness between words with the same part of speech in T and H. .No ablation test performed .", "label": "", "metadata": {}, "score": "49.23085"}
{"text": "RTE5 .Use of many WordNet relations ( such as synonymy , hypernymy , hyponymy , meronymy , holonymy etc . ) to compute the relatedness between words with the same part of speech in T and H. .No ablation test performed .", "label": "", "metadata": {}, "score": "49.23085"}
{"text": "RTE5 .Use of many WordNet relations ( such as synonymy , hypernymy , hyponymy , meronymy , holonymy etc . ) to compute the relatedness between words with the same part of speech in T and H. .No ablation test performed .", "label": "", "metadata": {}, "score": "49.23085"}
{"text": "IR views language as an open - ended set of mostly stable signs with which texts can be indexed and retrieved , focusing more on a text 's potential relevance ... \" .Information retrieval ( IR ) and figurative language processing ( FLP ) could scarcely be more different in their treatment of language and meaning .", "label": "", "metadata": {}, "score": "49.307106"}
{"text": "Synonyms , hyponyms ( 2 levels away from the original term ) , the hyponym_instance relation and derivations .Ablation test performed .Positive impact of the resource : +2.5 % accuracy on two - way task .Boeing .The system makes uses of Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H. .", "label": "", "metadata": {}, "score": "49.748573"}
{"text": "The vector associated with a target noun n k to characterise its sense contains the ( conditional ) distribution of verbs for which it serves as direct object in a corpus .The metric used in this study is relative entropy and the representation of the resulting classes is a tree structure of groups .", "label": "", "metadata": {}, "score": "49.794907"}
{"text": "The idea at the basis of their clustering method is to find groups in which the loss of average mutual information is small .In general , the loss is smaller when the members of the group have similar vectors .In related work , words are not clustered in terms of frequency counts for the word immediately following T , but rather by looking at a text window of about one thousand words surrounding T. The problem with this and similar approaches is that they are considerably greedy without being completely reliable .", "label": "", "metadata": {}, "score": "49.90605"}
{"text": "We have ... .by Jane Morris , Graeme Hirst - Workshop on Computational Lexical Semantics , In Proc .Human Language Technology Conference of the NAACL , 2004 . \" ...NLP methods and applications need to take account not only of \" classical \" lexical rela - tions , as found in WordNet , but the less - structural , more context - dependent \" non - classical \" relations that readers intuit in text .", "label": "", "metadata": {}, "score": "50.38734"}
{"text": "Rhodes .RTE5 .Lexicon based match : we chose a very simple metric : matching between words in T and H based on a path of distance at most 2 in the WordNet graph , using any links ( hyponymy , hypernymy , meronymy , pertainymy , etc . ) .", "label": "", "metadata": {}, "score": "50.77146"}
{"text": "This is because priming performance reflects automatic or implicit access to semantic information , unlike most other tests of semantic knowledge , which rely on explicit , voluntary access .Second , we can investigate the detailed pattern of loss and preservation of different types of semantic infomation , by charting the priming effects for different kinds of words , and different kinds of semantic relations between primes and targets .", "label": "", "metadata": {}, "score": "50.866226"}
{"text": "The relationships themselves are analyzed , and consequences for NLP are discussed .A notable exception to this trend is in library and information science ( LIS ) , and is likely a pragmatic reflection of the fact that it is a field with a large user base that demanded this type of ... . ...", "label": "", "metadata": {}, "score": "51.013443"}
{"text": "Impact of the resource on two - way task : +1.33%/-0.33 % accuracy respectively on run1 and run2 .QUANTA .RTE5 .Several relations from wordnet , such as synonyms , hyponym , hypernym et al . .Ablation test performed .", "label": "", "metadata": {}, "score": "51.264584"}
{"text": "Impact of the resource on two - way task : +1.33%/-0.33 % accuracy respectively on run1 and run2 .QUANTA .RTE5 .Several relations from wordnet , such as synonyms , hyponym , hypernym et al . .Ablation test performed .", "label": "", "metadata": {}, "score": "51.264584"}
{"text": "Impact of the resource on two - way task : +1.33%/-0.33 % accuracy respectively on run1 and run2 .QUANTA .RTE5 .Several relations from wordnet , such as synonyms , hyponym , hypernym et al . .Ablation test performed .", "label": "", "metadata": {}, "score": "51.264584"}
{"text": "Impact of the resource on two - way task : +1.33%/-0.33 % accuracy respectively on run1 and run2 .QUANTA .RTE5 .Several relations from wordnet , such as synonyms , hyponym , hypernym et al . .Ablation test performed .", "label": "", "metadata": {}, "score": "51.264584"}
{"text": "Impact of the resource on two - way task : +1.33%/-0.33 % accuracy respectively on run1 and run2 .QUANTA .RTE5 .Several relations from wordnet , such as synonyms , hyponym , hypernym et al . .Ablation test performed .", "label": "", "metadata": {}, "score": "51.264584"}
{"text": "Impact of the resource on two - way task : +1.33%/-0.33 % accuracy respectively on run1 and run2 .QUANTA .RTE5 .Several relations from wordnet , such as synonyms , hyponym , hypernym et al . .Ablation test performed .", "label": "", "metadata": {}, "score": "51.264584"}
{"text": "Impact of the resource on two - way task : +1.33%/-0.33 % accuracy respectively on run1 and run2 .QUANTA .RTE5 .Several relations from wordnet , such as synonyms , hyponym , hypernym et al . .Ablation test performed .", "label": "", "metadata": {}, "score": "51.264584"}
{"text": "RTE5 .FIRST USE : Antonymy relation to detect contradiction .In order to broaden the domain of the antonymy relation , we consider a combination of synonyms and antonyms .Used in combination with VerbOcean .SECOND USE : Synonymy , hyponymy and hypernymy for nouns and adjectives .", "label": "", "metadata": {}, "score": "51.296875"}
{"text": "RTE5 .FIRST USE : Antonymy relation to detect contradiction .In order to broaden the domain of the antonymy relation , we consider a combination of synonyms and antonyms .Used in combination with VerbOcean .SECOND USE : Synonymy , hyponymy and hypernymy for nouns and adjectives .", "label": "", "metadata": {}, "score": "51.296875"}
{"text": "RTE5 .FIRST USE : Antonymy relation to detect contradiction .In order to broaden the domain of the antonymy relation , we consider a combination of synonyms and antonyms .Used in combination with VerbOcean .SECOND USE : Synonymy , hyponymy and hypernymy for nouns and adjectives .", "label": "", "metadata": {}, "score": "51.296875"}
{"text": "RTE5 .FIRST USE : Antonymy relation to detect contradiction .In order to broaden the domain of the antonymy relation , we consider a combination of synonyms and antonyms .Used in combination with VerbOcean .SECOND USE : Synonymy , hyponymy and hypernymy for nouns and adjectives .", "label": "", "metadata": {}, "score": "51.296875"}
{"text": "RTE5 .FIRST USE : Antonymy relation to detect contradiction .In order to broaden the domain of the antonymy relation , we consider a combination of synonyms and antonyms .Used in combination with VerbOcean .SECOND USE : Synonymy , hyponymy and hypernymy for nouns and adjectives .", "label": "", "metadata": {}, "score": "51.296883"}
{"text": "Traditional vector - based models use word co - occurrence counts from large corpora to represent lexical meaning .In this paper we present a novel approach for constructing semantic spaces that takes syntactic relations into account .We introduce a formalisation for this class of models and evaluate their adequacy on two modelling tasks : semantic priming and automatic discrimination of lexical relations . \" ...", "label": "", "metadata": {}, "score": "52.038803"}
{"text": "We bring these two methods together by introducing distributional kernels that compare co - occurrence probability distributions .We demonstrate the effectiveness of ... \" .Distributional measures of lexical similarity and kernel methods for classification are well - known tools in Natural Language Processing .", "label": "", "metadata": {}, "score": "52.198"}
{"text": "FIRST USE : .Lexicon based match : we chose a very simple metric : matching between words in T and H based on a path of distance at most 2 in the WordNet graph , using any links ( hyponymy , hypernymy , meronymy , pertainymy , etc . ) .", "label": "", "metadata": {}, "score": "52.696228"}
{"text": "Positive impact of the resource : +2.5 % accuracy on two - way task .Boeing .The system makes uses of Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H. .", "label": "", "metadata": {}, "score": "52.980522"}
{"text": "Positive impact of the resource : +2.5 % accuracy on two - way task .Boeing .The system makes uses of Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H. .", "label": "", "metadata": {}, "score": "52.980522"}
{"text": "Positive impact of the resource : +2.5 % accuracy on two - way task .Boeing .The system makes uses of Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H. .", "label": "", "metadata": {}, "score": "52.980522"}
{"text": "Positive impact of the resource : +2.5 % accuracy on two - way task .Boeing .The system makes uses of Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H. .", "label": "", "metadata": {}, "score": "52.980522"}
{"text": "Positive impact of the resource : +2.5 % accuracy on two - way task .Boeing .The system makes uses of Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H. .", "label": "", "metadata": {}, "score": "52.980522"}
{"text": "Positive impact of the resource : +2.5 % accuracy on two - way task .Boeing .The system makes uses of Wordnet synonyms , hypernyms relationships between ( senses of ) words , \" similar \" ( SIM ) , \" pertains \" ( PER ) , and \" derivational \" ( DER ) links to recognize equivalence between T and H. .", "label": "", "metadata": {}, "score": "52.980522"}
{"text": "Exi ... \" .Wikipedia provides a semantic network for computing semantic relatedness in a more structured fashion than a search engine and with more coverage than WordNet .We present experiments on using Wikipedia for computing semantic relatedness and compare it to WordNet on various benchmarking datasets .", "label": "", "metadata": {}, "score": "53.110027"}
{"text": "Participants are recommended to add further information .FbkIrst .RTE4 .Lexical similarity .No precise evaluation of the resource has been carried out .In our second run we used a combined system ( EDITSneg + EDITSallbutneg ) , and we had an improvement of 0.6 % in accuracy with respect to the first run in which only EDITSneg was used .", "label": "", "metadata": {}, "score": "53.63266"}
{"text": "Participants are recommended to add further information .FbkIrst .RTE4 .Lexical similarity .No precise evaluation of the resource has been carried out .In our second run we used a combined system ( EDITSneg + EDITSallbutneg ) , and we had an improvement of 0.6 % in accuracy with respect to the first run in which only EDITSneg was used .", "label": "", "metadata": {}, "score": "53.63266"}
{"text": "Participants are recommended to add further information .FbkIrst .RTE4 .Lexical similarity .No precise evaluation of the resource has been carried out .In our second run we used a combined system ( EDITSneg + EDITSallbutneg ) , and we had an improvement of 0.6 % in accuracy with respect to the first run in which only EDITSneg was used .", "label": "", "metadata": {}, "score": "53.63266"}
{"text": "RTE4 .Synonyms , hyponyms ( 2 levels away from the original term ) , the hyponym_instance relation and derivations .Also used as part of our novel lexical - syntactic resource . 0.8 % improvement in ablation test on RTE-4 .", "label": "", "metadata": {}, "score": "53.68255"}
{"text": "RTE4 .Synonyms , hyponyms ( 2 levels away from the original term ) , the hyponym_instance relation and derivations .Also used as part of our novel lexical - syntactic resource . 0.8 % improvement in ablation test on RTE-4 .", "label": "", "metadata": {}, "score": "53.68255"}
{"text": "We also address the question whether and how Wikipedia can be integrated into NLP applications as a knowledge base .Including Wikipedia improves the performance of a machine learning based coreference resolution system , indicating that it represents a valuable resource for NLP applications .", "label": "", "metadata": {}, "score": "53.924747"}
{"text": "Rhodes .RTE5 .FIRST USE : Lexicon based match : we chose a very simple metric : matching between words in T and H based on a path of distance at most 2 in the WordNet graph , using any links ( hyponymy , hypernymy , meronymy , pertainymy , etc . ) .", "label": "", "metadata": {}, "score": "54.26465"}
{"text": "Rhodes .RTE5 .FIRST USE : Lexicon based match : we chose a very simple metric : matching between words in T and H based on a path of distance at most 2 in the WordNet graph , using any links ( hyponymy , hypernymy , meronymy , pertainymy , etc . ) .", "label": "", "metadata": {}, "score": "54.26465"}
{"text": "Rhodes .RTE5 .FIRST USE : Lexicon based match : we chose a very simple metric : matching between words in T and H based on a path of distance at most 2 in the WordNet graph , using any links ( hyponymy , hypernymy , meronymy , pertainymy , etc . ) .", "label": "", "metadata": {}, "score": "54.26465"}
{"text": "Rhodes .RTE5 .FIRST USE : Lexicon based match : we chose a very simple metric : matching between words in T and H based on a path of distance at most 2 in the WordNet graph , using any links ( hyponymy , hypernymy , meronymy , pertainymy , etc . ) .", "label": "", "metadata": {}, "score": "54.26465"}
{"text": "Positive impact of the resource : +4 % accuracy on two - way , +5.67 % on three - way task .DFKI .RTE5 .FIRST USE : Argument alignment between T and H. SECOND USE : used to change all the nominal predicates into verbs , to calculate relatedness between T and H ( using VerbOcean ) .", "label": "", "metadata": {}, "score": "54.843224"}
{"text": "Positive impact of the resource : +4 % accuracy on two - way , +5.67 % on three - way task .DFKI .RTE5 .FIRST USE : Argument alignment between T and H. SECOND USE : used to change all the nominal predicates into verbs , to calculate relatedness between T and H ( using VerbOcean ) .", "label": "", "metadata": {}, "score": "54.843224"}
{"text": "Positive impact of the resource : +4 % accuracy on two - way , +5.67 % on three - way task .DFKI .RTE5 .FIRST USE : Argument alignment between T and H. SECOND USE : used to change all the nominal predicates into verbs , to calculate relatedness between T and H ( using VerbOcean ) .", "label": "", "metadata": {}, "score": "54.843224"}
{"text": "Positive impact of the resource : +4 % accuracy on two - way , +5.67 % on three - way task .DFKI .RTE5 .FIRST USE : Argument alignment between T and H. SECOND USE : used to change all the nominal predicates into verbs , to calculate relatedness between T and H ( using VerbOcean ) .", "label": "", "metadata": {}, "score": "54.843224"}
{"text": "Positive impact of the resource : +4 % accuracy on two - way , +5.67 % on three - way task .DFKI .RTE5 .FIRST USE : Argument alignment between T and H. SECOND USE : used to change all the nominal predicates into verbs , to calculate relatedness between T and H ( using VerbOcean ) .", "label": "", "metadata": {}, "score": "54.843224"}
{"text": "Positive impact of the resource : +4 % accuracy on two - way , +5.67 % on three - way task .DFKI .RTE5 .FIRST USE : Argument alignment between T and H. SECOND USE : used to change all the nominal predicates into verbs , to calculate relatedness between T and H ( using VerbOcean ) .", "label": "", "metadata": {}, "score": "54.843224"}
{"text": "Positive impact of the resource : +4 % accuracy on two - way , +5.67 % on three - way task .DFKI .RTE5 .FIRST USE : Argument alignment between T and H. SECOND USE : used to change all the nominal predicates into verbs , to calculate relatedness between T and H ( using VerbOcean ) .", "label": "", "metadata": {}, "score": "54.843224"}
{"text": "FIRST USE : Ablation test performed .Positive impact of the resource : +3.17 % accuracy on two - way , +4 % on three - way task .SECOND USE : no abletion test performed .Sagan .RTE5 .Used to obtain two features ( string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps of the system .", "label": "", "metadata": {}, "score": "55.907257"}
{"text": "Positive impact of the resource : +3.17 % accuracy on two - way , +4 % on three - way task .Sagan .RTE5 .Used to obtain two features ( string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps of the system .", "label": "", "metadata": {}, "score": "55.953503"}
{"text": "Null / negative ( -0.87 % ) impact of the resource respectively on two - way and three - way task .Siel_09 .RTE5 .Similarity between nouns using WN tool .Ablation test performed .Impact of the resource : +0.34 % accuracy on two - way , -0.17 % on three - way task .", "label": "", "metadata": {}, "score": "56.273476"}
{"text": "Null / negative ( -0.87 % ) impact of the resource respectively on two - way and three - way task .Siel_09 .RTE5 .Similarity between nouns using WN tool .Ablation test performed .Impact of the resource : +0.34 % accuracy on two - way , -0.17 % on three - way task .", "label": "", "metadata": {}, "score": "56.273483"}
{"text": "Null / negative ( -0.87 % ) impact of the resource respectively on two - way and three - way task .Siel_09 .RTE5 .Similarity between nouns using WN tool .Ablation test performed .Impact of the resource : +0.34 % accuracy on two - way , -0.17 % on three - way task .", "label": "", "metadata": {}, "score": "56.273483"}
{"text": "Null / negative ( -0.87 % ) impact of the resource respectively on two - way and three - way task .Siel_09 .RTE5 .Similarity between nouns using WN tool .Ablation test performed .Impact of the resource : +0.34 % accuracy on two - way , -0.17 % on three - way task .", "label": "", "metadata": {}, "score": "56.273483"}
{"text": "Null / negative ( -0.87 % ) impact of the resource respectively on two - way and three - way task .Siel_09 .RTE5 .Similarity between nouns using WN tool .Ablation test performed .Impact of the resource : +0.34 % accuracy on two - way , -0.17 % on three - way task .", "label": "", "metadata": {}, "score": "56.273483"}
{"text": "We then describe two recent studies in which we have employed semantic priming tasks , along with other more traditional methods , to investigate specific questions about the semantic memory deficits of three patients . ... ng .SEMANTIC MEMORY AND PRIMING 365 Although we have argued against this particular version of the automaticity hypothesis ( Tyler , Ostrin , Cooke , & Moss , 1995 ) , it highlights the point that an absence ...", "label": "", "metadata": {}, "score": "56.46238"}
{"text": "Potential contribution is higher since this resource partially overlaps with the novel lexical - syntactic rule base .Boeing . RTE4 .Semantic relation between words .No formal evaluation .Plays a role in most entailments found .Cambridge .RTE4 .", "label": "", "metadata": {}, "score": "56.88683"}
{"text": "Potential contribution is higher since this resource partially overlaps with the novel lexical - syntactic rule base .Boeing . RTE4 .Semantic relation between words .No formal evaluation .Plays a role in most entailments found .Cambridge .RTE4 .", "label": "", "metadata": {}, "score": "56.88683"}
{"text": "Potential contribution is higher since this resource partially overlaps with the novel lexical - syntactic rule base .Boeing . RTE4 .Semantic relation between words .No formal evaluation .Plays a role in most entailments found .Cambridge .RTE4 .", "label": "", "metadata": {}, "score": "56.88683"}
{"text": "FIRST USE : Ablation test performed .Positive impact of the resource : +3.17 % accuracy on two - way , +4 % on three - way task .SECOND USE : no ablation test performed .Sagan .RTE5 .Used to obtain two features ( string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps of the system .", "label": "", "metadata": {}, "score": "57.554047"}
{"text": "FIRST USE : Ablation test performed .Positive impact of the resource : +3.17 % accuracy on two - way , +4 % on three - way task .SECOND USE : no ablation test performed .Sagan .RTE5 .Used to obtain two features ( string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps of the system .", "label": "", "metadata": {}, "score": "57.554047"}
{"text": "FIRST USE : Ablation test performed .Positive impact of the resource : +3.17 % accuracy on two - way , +4 % on three - way task .SECOND USE : no ablation test performed .Sagan .RTE5 .Used to obtain two features ( string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps of the system .", "label": "", "metadata": {}, "score": "57.554047"}
{"text": "Sagan .RTE5 .Used to obtain two features ( string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps of the system .Ablation test performed .Null / negative ( -0.87 % ) impact of the resource respectively on two - way and three - way task .", "label": "", "metadata": {}, "score": "57.582798"}
{"text": "Sagan .RTE5 .Used to obtain two features ( string similarity based on Levenshtein distance and semantic similarity ) in the training and testing steps of the system .Ablation test performed .Null / negative ( -0.87 % ) impact of the resource respectively on two - way and three - way task .", "label": "", "metadata": {}, "score": "57.582798"}
{"text": "Participants are recommended to add further information .UPC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .AUEB .RTE3 .Synonymy resolution .Replacing the words of H with their synonyms in T : on RTE3 data sets 2 % improvement Word clustering is a technique for partitioning sets of words into subsets of semantically similar words and is increasingly becoming a major technique used in a number of NLP tasks ranging from word sense or structural disambiguation to information retrieval and filtering .", "label": "", "metadata": {}, "score": "57.603992"}
{"text": "Positive impact of the resource on two - way run : +0.83 % accuracy .Negative impact on three - way run : -0.33 % accuracy ( -0.5 % for two - way derived ) .SECOND USE ( WordNet+VerbOcean+DLSIUAES_negation_list ) : positive impact on two - way run : +0.66 % accuracy .", "label": "", "metadata": {}, "score": "58.632133"}
{"text": "Positive impact of the resource on two - way run : +0.83 % accuracy .Negative impact on three - way run : -0.33 % accuracy ( -0.5 % for two - way derived ) .SECOND USE ( WordNet+VerbOcean+DLSIUAES_negation_list ) : positive impact on two - way run : +0.66 % accuracy .", "label": "", "metadata": {}, "score": "58.632133"}
{"text": "Positive impact of the resource on two - way run : +0.83 % accuracy .Negative impact on three - way run : -0.33 % accuracy ( -0.5 % for two - way derived ) .SECOND USE ( WordNet+VerbOcean+DLSIUAES_negation_list ) : positive impact on two - way run : +0.66 % accuracy .", "label": "", "metadata": {}, "score": "58.632133"}
{"text": "Positive impact of the resource on two - way run : +0.83 % accuracy .Negative impact on three - way run : -0.33 % accuracy ( -0.5 % for two - way derived ) .SECOND USE ( WordNet+VerbOcean+DLSIUAES_negation_list ) : positive impact on two - way run : +0.66 % accuracy .", "label": "", "metadata": {}, "score": "58.632133"}
{"text": "Positive impact of the resource on two - way run : +0.83 % accuracy .Negative impact on three - way run : -0.33 % accuracy ( -0.5 % for two - way derived ) .SECOND USE ( WordNet+VerbOcean+DLSIUAES_negation_list ) : positive impact on two - way run : +0.66 % accuracy .", "label": "", "metadata": {}, "score": "58.632133"}
{"text": "Positive impact of the resource on two - way run : +0.83 % accuracy .Negative impact on three - way run : -0.33 % accuracy ( -0.5 % for two - way derived ) .SECOND USE ( WordNet+VerbOcean+DLSIUAES_negation_list ) : positive impact on two - way run : +0.66 % accuracy .", "label": "", "metadata": {}, "score": "58.632133"}
{"text": "Positive impact of the resource on two - way run : +0.83 % accuracy .Negative impact on three - way run : -0.33 % accuracy ( -0.5 % for two - way derived ) .SECOND USE ( WordNet+VerbOcean+DLSIUAES_negation_list ) : positive impact on two - way run : +0.66 % accuracy .", "label": "", "metadata": {}, "score": "58.632133"}
{"text": "For each target noun T i the resulting representation is a vector C ( T i ) of counts for every other word w j and each of the four possible syntactic relations between T i and w j .[Sek92 ] apply a simplified version of the same technique to triples with the following structure : . [", "label": "", "metadata": {}, "score": "60.217667"}
{"text": "In contrast , FLP views language as a system of unstable signs that can be used to talk about the world in creative new ways .There is another key difference : IR is practical , scalable and robust , and in daily use by millions of casual users .", "label": "", "metadata": {}, "score": "61.491173"}
{"text": "RTE5 .Similarity between nouns using WN tool .Ablation test performed .Impact of the resource : +0.34 % accuracy on two - way , -0.17 % on three - way task .UAIC .RTE5 .FIRST USE : Antonymy relation to detect contradiction .", "label": "", "metadata": {}, "score": "61.49286"}
{"text": "RTE5 .Similarity between nouns using WN tool .Ablation test performed .Impact of the resource : +0.34 % accuracy on two - way , -0.17 % on three - way task .UAIC .RTE5 .FIRST USE : Antonymy relation to detect contradiction .", "label": "", "metadata": {}, "score": "61.49286"}
{"text": "We investigate the trade - off between efficiency and accuracy , and find that SASH ( Houle and Sakuma , 2005 ) provides the best balance . by Torsten Zesch , Iryna Gurevych - In Proc . of the Workshop on Linguistic Distances , ACL , 2006 . \" ...", "label": "", "metadata": {}, "score": "61.86136"}
{"text": "Participants are recommended to add further information .UPC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .AUEB .RTE3 .Synonymy resolution .Replacing the words of H with their synonyms in T : on RTE3 data sets 2 % improvement In order to broaden the domain of the antonymy relation , we consider a combination of synonyms and antonyms .", "label": "", "metadata": {}, "score": "61.86477"}
{"text": "RTE5 .Synonyms , derivationally - related forms .Used in the search task .AUEB . RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .BIU .RTE4 .Synonyms , hyponyms ( 2 levels away from the original term ) , the hyponym_instance relation and derivations .", "label": "", "metadata": {}, "score": "61.93876"}
{"text": "RTE5 .Synonyms , derivationally - related forms .Used in the search task .AUEB . RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .BIU .RTE4 .Synonyms , hyponyms ( 2 levels away from the original term ) , the hyponym_instance relation and derivations .", "label": "", "metadata": {}, "score": "61.93876"}
{"text": "RTE5 .Synonyms , derivationally - related forms .Used in the search task .AUEB . RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .BIU .RTE4 .Synonyms , hyponyms ( 2 levels away from the original term ) , the hyponym_instance relation and derivations .", "label": "", "metadata": {}, "score": "61.93876"}
{"text": "RTE4 .Lexical similarity .No precise evaluation of the resource has been carried out .In our second run we used a combined system ( EDITSneg + EDITSallbutneg ) , and we had an improvement of 0.6 % in accuracy with respect to the first run in which only EDITSneg was used .", "label": "", "metadata": {}, "score": "62.518787"}
{"text": "RTE4 .Lexical similarity .No precise evaluation of the resource has been carried out .In our second run we used a combined system ( EDITSneg + EDITSallbutneg ) , and we had an improvement of 0.6 % in accuracy with respect to the first run in which only EDITSneg was used .", "label": "", "metadata": {}, "score": "62.518787"}
{"text": "This article considers how fluent language users are rational in their language processing , rational in the sense that their unconscious language representation . ...LY - SEA _ _ _ _ ? or LANGUAGE - FAC _ _ _ ? )", "label": "", "metadata": {}, "score": "64.19356"}
{"text": "Participants are recommended to add further information .EMORY .Data taken from the RTE4 proceedings .Participants are recommended to add further information .FbkIrst .No precise evaluation of the resource has been carried out .In our second run we used a combined system ( EDITSneg + EDITSallbutneg ) , and we had an improvement of 0.6 % in accuracy with respect to the first run in which only EDITSneg was used .", "label": "", "metadata": {}, "score": "64.88373"}
{"text": "Participants are recommended to add further information .EMORY .Data taken from the RTE4 proceedings .Participants are recommended to add further information .FbkIrst .No precise evaluation of the resource has been carried out .In our second run we used a combined system ( EDITSneg + EDITSallbutneg ) , and we had an improvement of 0.6 % in accuracy with respect to the first run in which only EDITSneg was used .", "label": "", "metadata": {}, "score": "64.88374"}
{"text": "Participants are recommended to add further information .UPC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .AUEB .RTE3 .Synonymy resolution .Replacing the words of H with their synonyms in T : on RTE3 data sets 2 % improvement During the calculation of the similarity measures we treat words from T and H that are synonyms according to WordNet as identical .", "label": "", "metadata": {}, "score": "65.01221"}
{"text": "Participants are recommended to add further information .UPC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .AUEB .RTE3 .Synonymy resolution .Replacing the words of H with their synonyms in T : on RTE3 data sets 2 % improvement During the calculation of the similarity measures we treat words from T and H that are synonyms according to WordNet as identical .", "label": "", "metadata": {}, "score": "65.01221"}
{"text": "In order to broaden the domain of the antonymy relation , we consider a combination of synonyms and antonyms .Used in combination with VerbOcean .In order to broaden the domain of the antonymy relation , we consider a combination of synonyms and antonyms .", "label": "", "metadata": {}, "score": "65.08832"}
{"text": "Positive impact of the resource : +0.34 % on two - way task .PeMoZa . RTE5 .FIRST USE : Derivational Morphology .SECOND USE : Verb Entailment .Ablation tests performed .FIRST USE .Impact of the resource on two - way task : -0.5%/+1 % accuracy respectively on run1 and run2 .", "label": "", "metadata": {}, "score": "65.33822"}
{"text": "Positive impact of the resource : +0.34 % on two - way task .PeMoZa . RTE5 .FIRST USE : Derivational Morphology .SECOND USE : Verb Entailment .Ablation tests performed .FIRST USE .Impact of the resource on two - way task : -0.5%/+1 % accuracy respectively on run1 and run2 .", "label": "", "metadata": {}, "score": "65.33822"}
{"text": "Positive impact of the resource : +0.34 % on two - way task .PeMoZa . RTE5 .FIRST USE : Derivational Morphology .SECOND USE : Verb Entailment .Ablation tests performed .FIRST USE .Impact of the resource on two - way task : -0.5%/+1 % accuracy respectively on run1 and run2 .", "label": "", "metadata": {}, "score": "65.33822"}
{"text": "Positive impact of the resource : +0.34 % on two - way task .PeMoZa . RTE5 .FIRST USE : Derivational Morphology .SECOND USE : Verb Entailment .Ablation tests performed .FIRST USE .Impact of the resource on two - way task : -0.5%/+1 % accuracy respectively on run1 and run2 .", "label": "", "metadata": {}, "score": "65.33822"}
{"text": "Positive impact of the resource : +0.34 % on two - way task .PeMoZa . RTE5 .FIRST USE : Derivational Morphology .SECOND USE : Verb Entailment .Ablation tests performed .FIRST USE .Impact of the resource on two - way task : -0.5%/+1 % accuracy respectively on run1 and run2 .", "label": "", "metadata": {}, "score": "65.33822"}
{"text": "Positive impact of the resource : +0.34 % on two - way task .PeMoZa . RTE5 .FIRST USE : Derivational Morphology .SECOND USE : Verb Entailment .Ablation tests performed .FIRST USE .Impact of the resource on two - way task : -0.5%/+1 % accuracy respectively on run1 and run2 .", "label": "", "metadata": {}, "score": "65.33822"}
{"text": "Positive impact of the resource : +0.34 % on two - way task .PeMoZa . RTE5 .FIRST USE : Derivational Morphology .SECOND USE : Verb Entailment .Ablation tests performed .FIRST USE .Impact of the resource on two - way task : -0.5%/+1 % accuracy respectively on run1 and run2 .", "label": "", "metadata": {}, "score": "65.33822"}
{"text": "Participants are recommended to add further information .UPC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .AUEB .RTE3 .Synonymy resolution .Replacing the words of H with their synonyms in T : on RTE3 data sets 2 % improvement Positive impact of the resource : +3.17 % accuracy on two - way , +4 % on three - way task .", "label": "", "metadata": {}, "score": "66.26846"}
{"text": "RTE5 .Extraction of a set of 2698 English entailment rules for terms connected by the hyponymy and synonymy relations .No ablation test performed .JU_CSE_TAC .RTE5 .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .", "label": "", "metadata": {}, "score": "66.41489"}
{"text": "RTE5 .Extraction of a set of 2698 English entailment rules for terms connected by the hyponymy and synonymy relations .No ablation test performed .JU_CSE_TAC .RTE5 .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .", "label": "", "metadata": {}, "score": "66.41489"}
{"text": "RTE5 .Extraction of a set of 2698 English entailment rules for terms connected by the hyponymy and synonymy relations .No ablation test performed .JU_CSE_TAC .RTE5 .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .", "label": "", "metadata": {}, "score": "66.41489"}
{"text": "RTE5 .Extraction of a set of 2698 English entailment rules for terms connected by the hyponymy and synonymy relations .No ablation test performed .JU_CSE_TAC .RTE5 .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .", "label": "", "metadata": {}, "score": "66.41489"}
{"text": "RTE5 .Extraction of a set of 2698 English entailment rules for terms connected by the hyponymy and synonymy relations .No ablation test performed .JU_CSE_TAC .RTE5 .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .", "label": "", "metadata": {}, "score": "66.41489"}
{"text": "RTE5 .Extraction of a set of 2698 English entailment rules for terms connected by the hyponymy and synonymy relations .No ablation test performed .JU_CSE_TAC .RTE5 .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .", "label": "", "metadata": {}, "score": "66.41489"}
{"text": "RTE5 .Extraction of a set of 2698 English entailment rules for terms connected by the hyponymy and synonymy relations .No ablation test performed .JU_CSE_TAC .RTE5 .WordNet based Unigram match : if any synset for the H unigram matches with any synset of a word in T then the hypothesis unigram is considered as a WordNet based unigram match .", "label": "", "metadata": {}, "score": "66.41489"}
{"text": "The information content ( or entropy ) of a concept c -- which in WordNet corresponds to a set of such as fire _ v_4 , dismiss _ v_4 , terminate _ v_4 , sack _ v_2 -- is formally defined as .", "label": "", "metadata": {}, "score": "66.56774"}
{"text": "UPC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .AUEB .RTE3 .Synonymy resolution .Replacing the words of H with their synonyms in T : on RTE3 data sets 2 % improvement Positive impact of the resource : +3.17 % accuracy on two - way , +4 % on three - way task .", "label": "", "metadata": {}, "score": "67.06808"}
{"text": "THIRD USE : No ablation test performed .FOURTH USE ( WordNet+Framenet ) : positive impact on two - way run : +1.16 % accuracy .Negative impact on three - way run : -0.17 % ( the same for two - way derived ) .", "label": "", "metadata": {}, "score": "67.086555"}
{"text": "THIRD USE : No ablation test performed .FOURTH USE ( WordNet+Framenet ) : positive impact on two - way run : +1.16 % accuracy .Negative impact on three - way run : -0.17 % ( the same for two - way derived ) .", "label": "", "metadata": {}, "score": "67.086555"}
{"text": "THIRD USE : No ablation test performed .FOURTH USE ( WordNet+Framenet ) : positive impact on two - way run : +1.16 % accuracy .Negative impact on three - way run : -0.17 % ( the same for two - way derived ) .", "label": "", "metadata": {}, "score": "67.086555"}
{"text": "THIRD USE : No ablation test performed .FOURTH USE ( WordNet+Framenet ) : positive impact on two - way run : +1.16 % accuracy .Negative impact on three - way run : -0.17 % ( the same for two - way derived ) .", "label": "", "metadata": {}, "score": "67.086555"}
{"text": "THIRD USE : No ablation test performed .FOURTH USE ( WordNet+Framenet ) : positive impact on two - way run : +1.16 % accuracy .Negative impact on three - way run : -0.17 % ( the same for two - way derived ) .", "label": "", "metadata": {}, "score": "67.086555"}
{"text": "THIRD USE : No ablation test performed .FOURTH USE ( WordNet+Framenet ) : positive impact on two - way run : +1.16 % accuracy .Negative impact on three - way run : -0.17 % ( the same for two - way derived ) .", "label": "", "metadata": {}, "score": "67.086555"}
{"text": "THIRD USE : No ablation test performed .FOURTH USE ( WordNet+Framenet ) : positive impact on two - way run : +1.16 % accuracy .Negative impact on three - way run : -0.17 % ( the same for two - way derived ) .", "label": "", "metadata": {}, "score": "67.086555"}
{"text": "For example , when analyzing weather forecasts it is very hard to discover in an unsupervised way which of the expressions among \" south wind \" , \" wind from west \" and \" southerly \" denote the same wind d .. \" ...", "label": "", "metadata": {}, "score": "67.686874"}
{"text": "Positive impact of the two resources together : +1 % accuracy on two - way , +1.33 % on three - way task .SECOND USE : Ablation test performed ( Wordnet + eXtended WordNet ) .Positive impact of the two resources together : +1 % accuracy on two - way , +1.33 % on three - way task .", "label": "", "metadata": {}, "score": "67.86775"}
{"text": "Positive impact of the two resources together : +1 % accuracy on two - way , +1.33 % on three - way task .SECOND USE : Ablation test performed ( Wordnet + eXtended WordNet ) .Positive impact of the two resources together : +1 % accuracy on two - way , +1.33 % on three - way task .", "label": "", "metadata": {}, "score": "67.86775"}
{"text": "Positive impact of the two resources together : +1 % accuracy on two - way , +1.33 % on three - way task .SECOND USE : Ablation test performed ( Wordnet + eXtended WordNet ) .Positive impact of the two resources together : +1 % accuracy on two - way , +1.33 % on three - way task .", "label": "", "metadata": {}, "score": "67.86775"}
{"text": "For example , in the context I read the book , the word book can be replaced by magazine with no violation of the semantic well - formedness of the sentence , and therefore the two words can be said to be paradigmatically similar ; . syntagmatic similarity : two words that are syntagmatically similar significantly occur together in 2text .", "label": "", "metadata": {}, "score": "68.11142"}
{"text": "Positive impact of the two resources together : +1 % accuracy on two - way , +1.33 % on three - way task .AUEB . RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .", "label": "", "metadata": {}, "score": "68.64131"}
{"text": "Positive impact of the two resources together : +1 % accuracy on two - way , +1.33 % on three - way task .AUEB . RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .", "label": "", "metadata": {}, "score": "68.64131"}
{"text": "Boeing . RTE4 .Semantic relation between words .No formal evaluation .Plays a role in most entailments found .Cambridge .RTE4 .Hypernyms , antonyms , indexWords ( N , V , Adj , Adv ) .Used , but no evaluation performed .", "label": "", "metadata": {}, "score": "68.76927"}
{"text": "Boeing . RTE4 .Semantic relation between words .No formal evaluation .Plays a role in most entailments found .Cambridge .RTE4 .Hypernyms , antonyms , indexWords ( N , V , Adj , Adv ) .Used , but no evaluation performed .", "label": "", "metadata": {}, "score": "68.76927"}
{"text": "The first for Wordnet alone , the second for both WordNet and Framenet .Null impact of the resource(s ) on two - way task for both ablations .Ablation test performed .Positive impact of the resource : +4 % accuracy on two - way task .", "label": "", "metadata": {}, "score": "68.86656"}
{"text": "The first for Wordnet alone , the second for both WordNet and Framenet .Null impact of the resource(s ) on two - way task for both ablations .Ablation test performed .Positive impact of the resource : +4 % accuracy on two - way task .", "label": "", "metadata": {}, "score": "68.86657"}
{"text": "The first for Wordnet alone , the second for both WordNet and Framenet .Null impact of the resource(s ) on two - way task for both ablations .UI_ccg .RTE5 .Ablation test performed .Positive impact of the resource : +4 % accuracy on two - way task .", "label": "", "metadata": {}, "score": "68.9692"}
{"text": "The first for Wordnet alone , the second for both WordNet and Framenet .Null impact of the resource(s ) on two - way task for both ablations .UI_ccg .RTE5 .Ablation test performed .Positive impact of the resource : +4 % accuracy on two - way task .", "label": "", "metadata": {}, "score": "68.9692"}
{"text": "The first for Wordnet alone , the second for both WordNet and Framenet .Null impact of the resource(s ) on two - way task for both ablations .UI_ccg .RTE5 .Ablation test performed .Positive impact of the resource : +4 % accuracy on two - way task .", "label": "", "metadata": {}, "score": "68.9692"}
{"text": "UPC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .AUEB .RTE3 .Synonymy resolution .Replacing the words of H with their synonyms in T : on RTE3 data sets 2 % improvement", "label": "", "metadata": {}, "score": "69.127045"}
{"text": "FIRST USE : Ablation test performed ( Wordnet + VerbOcean ) .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .SECOND USE : Ablation test performed ( Wordnet + eXtended WordNet ) .", "label": "", "metadata": {}, "score": "69.65415"}
{"text": "FIRST USE : Ablation test performed ( Wordnet + VerbOcean ) .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .SECOND USE : Ablation test performed ( Wordnet + eXtended WordNet ) .", "label": "", "metadata": {}, "score": "69.65415"}
{"text": "FIRST USE : Ablation test performed ( Wordnet + VerbOcean ) .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .SECOND USE : Ablation test performed ( Wordnet + eXtended WordNet ) .", "label": "", "metadata": {}, "score": "69.65415"}
{"text": "FIRST USE : Ablation test performed ( Wordnet + VerbOcean ) .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .SECOND USE : Ablation test performed ( Wordnet + eXtended WordNet ) .", "label": "", "metadata": {}, "score": "69.65415"}
{"text": "FIRST USE : Ablation test performed ( Wordnet + VerbOcean ) .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .SECOND USE : Ablation test performed ( Wordnet + eXtended WordNet ) .", "label": "", "metadata": {}, "score": "69.65416"}
{"text": "Used , but no evaluation performed .DFKI .RTE4 .Semantic relation between words .No separate evaluation .DLSIUAES .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .EMORY .RTE4 .", "label": "", "metadata": {}, "score": "70.854866"}
{"text": "Used , but no evaluation performed .DFKI .RTE4 .Semantic relation between words .No separate evaluation .DLSIUAES .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .EMORY .RTE4 .", "label": "", "metadata": {}, "score": "70.854866"}
{"text": "Used , but no evaluation performed .DFKI .RTE4 .Semantic relation between words .No separate evaluation .DLSIUAES .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .EMORY .RTE4 .", "label": "", "metadata": {}, "score": "70.854866"}
{"text": "Impact of the resource : -0.17 % accuracy / null respectively on two - way and three - way task for run1 ; +0.16%/+0.34 % for run2 ; +0.17%/+0.17 % for run3 .SECOND USE ( WordNet+VerbOcean ) : null/+0.17 % accuracy respectively on two - way and three - way task for run1 ; +0.5%/+0.67 % for run2 ; +0.17%/+0.17 % for run3 .", "label": "", "metadata": {}, "score": "71.844406"}
{"text": "Impact of the resource : -0.17 % accuracy / null respectively on two - way and three - way task for run1 ; +0.16%/+0.34 % for run2 ; +0.17%/+0.17 % for run3 .SECOND USE ( WordNet+VerbOcean ) : null/+0.17 % accuracy respectively on two - way and three - way task for run1 ; +0.5%/+0.67 % for run2 ; +0.17%/+0.17 % for run3 .", "label": "", "metadata": {}, "score": "71.844406"}
{"text": "Impact of the resource : -0.17 % accuracy / null respectively on two - way and three - way task for run1 ; +0.16%/+0.34 % for run2 ; +0.17%/+0.17 % for run3 .SECOND USE ( WordNet+VerbOcean ) : null/+0.17 % accuracy respectively on two - way and three - way task for run1 ; +0.5%/+0.67 % for run2 ; +0.17%/+0.17 % for run3 .", "label": "", "metadata": {}, "score": "71.844406"}
{"text": "Impact of the resource : -0.17 % accuracy / null respectively on two - way and three - way task for run1 ; +0.16%/+0.34 % for run2 ; +0.17%/+0.17 % for run3 .SECOND USE ( WordNet+VerbOcean ) : null/+0.17 % accuracy respectively on two - way and three - way task for run1 ; +0.5%/+0.67 % for run2 ; +0.17%/+0.17 % for run3 .", "label": "", "metadata": {}, "score": "71.844406"}
{"text": "Impact of the resource : -0.17 % accuracy / null respectively on two - way and three - way task for run1 ; +0.16%/+0.34 % for run2 ; +0.17%/+0.17 % for run3 .SECOND USE ( WordNet+VerbOcean ) : null/+0.17 % accuracy respectively on two - way and three - way task for run1 ; +0.5%/+0.67 % for run2 ; +0.17%/+0.17 % for run3 .", "label": "", "metadata": {}, "score": "71.844406"}
{"text": "Impact of the resource : -0.17 % accuracy / null respectively on two - way and three - way task for run1 ; +0.16%/+0.34 % for run2 ; +0.17%/+0.17 % for run3 .SECOND USE ( WordNet+VerbOcean ) : null/+0.17 % accuracy respectively on two - way and three - way task for run1 ; +0.5%/+0.67 % for run2 ; +0.17%/+0.17 % for run3 .", "label": "", "metadata": {}, "score": "71.844406"}
{"text": "Impact of the resource : -0.17 % accuracy / null respectively on two - way and three - way task for run1 ; +0.16%/+0.34 % for run2 ; +0.17%/+0.17 % for run3 .SECOND USE ( WordNet+VerbOcean ) : null/+0.17 % accuracy respectively on two - way and three - way task for run1 ; +0.5%/+0.67 % for run2 ; +0.17%/+0.17 % for run3 .", "label": "", "metadata": {}, "score": "71.844406"}
{"text": "To determine if parts of an idiom activate ea ... . \" ...The semantic priming task is a valuable tool in the investigation of semantic memory impairments in patients with acquired disorders of language .This is because priming performance reflects automatic or implicit access to semantic information , unlike most other tests of semantic knowledge , which re ... \" .", "label": "", "metadata": {}, "score": "72.966446"}
{"text": "Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .Positive impact of the two resources together : +2 % accuracy on two - way , +1.5 % on three - way task .", "label": "", "metadata": {}, "score": "77.370346"}
{"text": "Participants are recommended to add further information .OAQA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .QUANTA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .", "label": "", "metadata": {}, "score": "79.85715"}
{"text": "Participants are recommended to add further information .OAQA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .QUANTA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .", "label": "", "metadata": {}, "score": "79.85718"}
{"text": "Participants are recommended to add further information .OAQA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .QUANTA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .", "label": "", "metadata": {}, "score": "79.85718"}
{"text": "Participants are recommended to add further information .OAQA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .QUANTA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .", "label": "", "metadata": {}, "score": "79.85718"}
{"text": "Participants are recommended to add further information .OAQA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .QUANTA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .", "label": "", "metadata": {}, "score": "79.85718"}
{"text": "Participants are recommended to add further information .OAQA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .QUANTA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .", "label": "", "metadata": {}, "score": "79.85718"}
{"text": "Participants are recommended to add further information .OAQA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .QUANTA .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .", "label": "", "metadata": {}, "score": "79.85718"}
{"text": "Suppose for example that in calculating the semantic similarity of the two verbs fire , dismiss using the WordNet lexical database we find that the most informative subsuming concept is represented by the synonym set containing the word sense remove _ v_2 .", "label": "", "metadata": {}, "score": "80.553314"}
{"text": "RTE4 .Semantic relation between words .No separate evaluation .DLSIUAES .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .EMORY .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .", "label": "", "metadata": {}, "score": "80.85474"}
{"text": "RTE4 .Semantic relation between words .No separate evaluation .DLSIUAES .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .EMORY .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .", "label": "", "metadata": {}, "score": "80.85474"}
{"text": "SECOND USE : Ablation test performed ( Wordnet + eXtended WordNet ) .Positive impact of the two resources together : +1 % accuracy on two - way , +1.33 % on three - way task .SECOND USE : Ablation test performed ( Wordnet + eXtended WordNet ) .", "label": "", "metadata": {}, "score": "84.74582"}
{"text": "UMD .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UNED .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Uoeltg .RTE4 .", "label": "", "metadata": {}, "score": "93.78371"}
{"text": "UMD .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UNED .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Uoeltg .RTE4 .", "label": "", "metadata": {}, "score": "93.78371"}
{"text": "UMD .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UNED .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Uoeltg .RTE4 .", "label": "", "metadata": {}, "score": "93.78371"}
{"text": "UMD .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UNED .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Uoeltg .RTE4 .", "label": "", "metadata": {}, "score": "93.78371"}
{"text": "UMD .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UNED .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Uoeltg .RTE4 .", "label": "", "metadata": {}, "score": "93.78371"}
{"text": "RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UNED .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Uoeltg .RTE4 .Data taken from the RTE4 proceedings .", "label": "", "metadata": {}, "score": "96.01895"}
{"text": "RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UNED .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Uoeltg .RTE4 .Data taken from the RTE4 proceedings .", "label": "", "metadata": {}, "score": "96.019"}
{"text": "FSC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IIT . RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IPD .RTE4 .", "label": "", "metadata": {}, "score": "98.8034"}
{"text": "FSC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IIT . RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IPD .RTE4 .", "label": "", "metadata": {}, "score": "98.803406"}
{"text": "FSC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IIT . RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IPD .RTE4 .", "label": "", "metadata": {}, "score": "98.803406"}
{"text": "FSC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IIT . RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IPD .RTE4 .", "label": "", "metadata": {}, "score": "98.803406"}
{"text": "FSC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IIT . RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IPD .RTE4 .", "label": "", "metadata": {}, "score": "98.803406"}
{"text": "FSC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IIT . RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IPD .RTE4 .", "label": "", "metadata": {}, "score": "98.803406"}
{"text": "FSC .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IIT . RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .IPD .RTE4 .", "label": "", "metadata": {}, "score": "98.803406"}
{"text": "RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Stanford .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UAIC .RTE4 .Ablation test performed : +3 % precision on two - way task .", "label": "", "metadata": {}, "score": "99.32398"}
{"text": "RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Stanford .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UAIC .RTE4 .Ablation test performed : +3 % precision on two - way task .", "label": "", "metadata": {}, "score": "99.32399"}
{"text": "RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Stanford .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UAIC .RTE4 .Data taken from the RTE4 proceedings .", "label": "", "metadata": {}, "score": "103.17053"}
{"text": "RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Stanford .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UAIC .RTE4 .Data taken from the RTE4 proceedings .", "label": "", "metadata": {}, "score": "103.17053"}
{"text": "RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Stanford .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UAIC .RTE4 .Data taken from the RTE4 proceedings .", "label": "", "metadata": {}, "score": "103.17053"}
{"text": "RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Stanford .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UAIC .RTE4 .Data taken from the RTE4 proceedings .", "label": "", "metadata": {}, "score": "103.17053"}
{"text": "RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .Stanford .RTE4 .Data taken from the RTE4 proceedings .Participants are recommended to add further information .UAIC .RTE4 .Data taken from the RTE4 proceedings .", "label": "", "metadata": {}, "score": "103.17053"}
