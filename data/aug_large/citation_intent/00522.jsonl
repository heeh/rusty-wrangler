{"text": "The recognition of ' unknown ' but well - forme ... \" .In the parser , the PREDICT component is parametrised for different interactive prediction types , the SCAN component is enhanced for the lattice - to - chart mapping problem , and the COMPLETE component is modified to account for competing hypotheses at unconnected chart nodes with temporal offsets relative to each other .", "label": "", "metadata": {}, "score": "40.60406"}
{"text": "The results are reported based on word error rate on the NIST HUB-1 word - lattices .The presented approach is implemented and compared with other syntactic language modeling techniques . \" ...One of the roles of a Natural Language Processing ( NLP ) model in Continuous Speech Recognition ( CSR ) systems is to find the best sentence hypothesis by ranking all n - best sentences according to the grammar .", "label": "", "metadata": {}, "score": "42.880028"}
{"text": "This can be viewed as a linear system with sparsity constraints corrupted by noise , where the objective is to estimate the sparsity pattern of \u03b2 given the observation vector y and the measurement matrix X .First , we derive a nonasymptotic upper bound on the probability that a specific wrong sparsity pattern is identified by the maximum - likelihood estimator .", "label": "", "metadata": {}, "score": "43.653923"}
{"text": "This is executable in parallel with hypothesis testing .This methodology is in sharp contrast to conventional machine reading algorithms which usually segment a word into characters and recognize the individual characters .Thus , a word decision is arrived at as a composite of character decisions .", "label": "", "metadata": {}, "score": "44.48669"}
{"text": "We find that the required growth rate of sample size ? matches the growth rate of previously established necessary conditions .has only ?nonzero entries and ? is a Gaussian noise .Index Terms - Hypothesis testing , random projections , sparsity pattern recovery , subset selection , underdetermined systems of equations .", "label": "", "metadata": {}, "score": "44.892357"}
{"text": "Page 2 . A. Previous Work A large body of recent work , including [ 4]-[10 ] , analyzed reliable sparsity pattern recovery exploiting optimal and sub- optimal decoders for large random Gaussian measurement ma- trices . Thesufficientcon- ditions in [ 6 ] were obtained based on a simple maximum cor- relation algorithm and a closely related thresholding estimator discussed in [ 11].", "label": "", "metadata": {}, "score": "45.791298"}
{"text": "In many of these applications , it is natural to seek for sparse solu- tions ofsuch systems , i.e. , solutions withfewnonzero elements .A common setting is when we believe or we know a priori that only a small subset of the candidate sources , neurons , or genes influence the observations , but their location is unknown .", "label": "", "metadata": {}, "score": "45.876022"}
{"text": "In the special case when the entries of the measurement matrix are i.i.d . normal random variables , we computed an upper bound on the expected error probability .Sufficient conditions on exact sparsity pattern recovery were obtained , and they were shown to improve the previous results [ 4]-[7].", "label": "", "metadata": {}, "score": "46.748413"}
{"text": "-norm of ? ? projected onto the range of columns of ? indexed by thewrong sparsitypattern .Second , when ? israndomlydrawn from a Gaussian ensemble , we calculate a nonasymptotic upper bound on the probability of the maximum - likelihood decoder not declaring ( partially ) the true sparsity pattern .", "label": "", "metadata": {}, "score": "47.525295"}
{"text": "First , we derive a nonasymptotic upper bound on the prob- ability that a specific wrong sparsity pattern is identified by the maximum - likelihood estimator .We find that this probability de- pends ( inversely)exponentially on the difference of ? ? ? ? ?", "label": "", "metadata": {}, "score": "47.89117"}
{"text": "One of the roles of a Natural Language Processing ( NLP ) model in Continuous Speech Recognition ( CSR ) systems is to find the best sentence hypothesis by ranking all n - best sentences according to the grammar .This paper describes a robust parsing algorithm for Spoken Language Recognition ( SLR ) which utilizes a technique that improves the efficiency of parsing .", "label": "", "metadata": {}, "score": "48.725433"}
{"text": "Full - text \u00b7 Article \u00b7 Jan 2013 \u00b7 IEEE Transactions on Signal Processing .We extend the scope of conventional noisy compressive sampling models where U is typically the identity or a matrix with iid components , to allow U that satisfies a certain freeness condition , which encompasses Haar matrices and other unitarily invariant matrices .", "label": "", "metadata": {}, "score": "48.78578"}
{"text": "Differing provisions from the publisher 's actual policy or licence agreement may be applicable . \" These necessary conditions are tightened in [ 17 ] , and a comparison between dense and sparse ensembles is performed .In [ 18 ] , sufficient conditions are derived and shown to be tight in a scaling - law sense by comparison to the necessary conditions of [ 17].", "label": "", "metadata": {}, "score": "49.8677"}
{"text": "First of all , frequency - based method [ 12 , 8 , 18 ] uses the frequencies of the word pairs with the optional help of part - of - speech filter , stop word list and/or acceptable patterns .Secondly , mean and variance - based method [ 14 ] computes the mean and variance of the offsets between the words in the corpus , and the word pairs , which have low variances , are regarded as word co - occurrences .", "label": "", "metadata": {}, "score": "50.66001"}
{"text": "Page 12 .12 Guodong Zhou et al . 1stReading Table 2 .Examples of N - best collocations ( Here , the collocations are sorted according to EPMI first and then EAMI . )No .Table 3 gives some of them .", "label": "", "metadata": {}, "score": "50.6613"}
{"text": "Depending on the extent of context used , there are different levels of postprocessing .In current commercial OCR systems , word - level postprocessing methods , such as dictionary - lookup , have been applied successfully .However , many OCR errors can not be corrected by word - level postprocessing .", "label": "", "metadata": {}, "score": "50.761166"}
{"text": "However , many problems involve more than the two possible outcomes of a binomial , and instead require 3 or more categories , which leads to the multinomial distribution .Just as de Moivre and Laplace sought for and found the normal approximation to the binomial , Pearson sought for and found a multivariate normal approximation to the multinomial distribution .", "label": "", "metadata": {}, "score": "50.875137"}
{"text": "Both these solutions are optimal for the infinite alphabet case .Using these algorithms we present a syntactic pattern rec ... . ...y of the LCS problem has been studied by Aho et . al .[ 1].Besides these deterministic techniques , various probabilistic methods have been studied in the literature [ 2,20,10].", "label": "", "metadata": {}, "score": "50.924393"}
{"text": "In these techniques the task is generally expressed as being one of finding an optimum path through a word lattice .The word lattice encodes the lexical candidates , th ... . \" ...Recognition of degraded text is a challenging problem .", "label": "", "metadata": {}, "score": "50.96296"}
{"text": "( Current Research ) .The Point - to - Point ( P2P ) correspondence goes way back in Computer Vision theory .It holds great interest in both automated surveillance and in some techniques of motion capture .If solved correctly , objects in a video can be tracked regardless of noisy data or scenarios like occlusion .", "label": "", "metadata": {}, "score": "51.07362"}
{"text": "( Current Research ) .The Point - to - Point ( P2P ) correspondence goes way back in Computer Vision theory .It holds great interest in both automated surveillance and in some techniques of motion capture .If solved correctly , objects in a video can be tracked regardless of noisy data or scenarios like occlusion .", "label": "", "metadata": {}, "score": "51.07362"}
{"text": "A metric is given to assign scores to edges , taking into account the whole left context thereby combining acoustic probabilities , n - gram probabilities and unification grammar probabilities .A specialized model for the derivation of typed unification grammars is introduced .", "label": "", "metadata": {}, "score": "51.541306"}
{"text": "This grammar formalism stipulates that a lexical entry for a word contains both semantic and syntactic feature structures .By relaxing the constraints on lexical feature structures , even ill - formed input can be accepted , broadening the coverage of the grammar .", "label": "", "metadata": {}, "score": "51.574944"}
{"text": "Digital Object Identifier 10.1109/TIT.2011.2145670 known covariance equal to responding entry of surement , respectively .The output of the optimal ( sparsity ) decoder is defined as the support set of the sparse solution minimizes the residual sum of squares where 1 .", "label": "", "metadata": {}, "score": "51.621193"}
{"text": "The theory , based on previous studies of how people read , includes three stages : hypothesis generation , hypothesis testing , and global contextual analysis .Hypothesis generation uses gross visual features , such as those ... \" .A computational theory of the visual recognition of words of text is developed .", "label": "", "metadata": {}, "score": "51.873535"}
{"text": "[ 6 ] LRT 's have several desirable properties ; in particular , LRT 's commonly provide the highest power to reject the null hypothesis ( Neyman - Pearson lemma ) .However , the normal and chi - squared approximations are only valid asymptotically .", "label": "", "metadata": {}, "score": "52.058388"}
{"text": "Accordingly , since the cumulative distribution function ( CDF ) for the appropriate degrees of freedom ( df ) gives the probability of having obtained a value less extreme than this point , subtracting the CDF value from 1 gives the p -value .", "label": "", "metadata": {}, "score": "53.40897"}
{"text": "This is done by finding two optimal classes in the collocation net and mapping the less - frequently occurring word and feature bigrams to them through the word- clustering mechanism provided in the collocation net as follows : . indd 711/29/2007 2:52:46 PM .", "label": "", "metadata": {}, "score": "53.587204"}
{"text": "Information - theoretic limits on the number of measurements needed to recover the support set of perfectly are given , and it is shown that significantly fewer measurements can be used if the prior distribution is sufficiently non - uniform .Furthermore , exten - sions of Basis Pursuit , LASSO , and Orthogonal Matching Pursuit which exploit the prior information are presented .", "label": "", "metadata": {}, "score": "53.596333"}
{"text": "Theory , vol .55 , no .5 , pp .2183 - 2202 , May 2009 .[ 11 ] H. Rauhut , K. Schnass , and P. Vandergheynst , \" Compressed sensing and redundant dictionaries , \" IEEE Trans .", "label": "", "metadata": {}, "score": "53.599262"}
{"text": "Page 10 .In this way , we have a large set of collocation candidates with their frequencies .( 4 ) Examine whether the collocation net is to be re - built .For example , whether the average probability ratio between the best parsed tree hypothesis and the second best parsed tree hypothesis for each sentence converges or begins to dropd .", "label": "", "metadata": {}, "score": "53.84752"}
{"text": "Page 3 .Building a Collocation Net 3 1stReading 1.1 .Statistics - based methods The methods in this category are normally used to extract the word co - occurrence relationship , the phenomena where words are likely to occur in the same context , from the raw unparsed corpus .", "label": "", "metadata": {}, "score": "54.105793"}
{"text": "That gave us the sum as a single binomial coefficient , and that was just what was needed for the right - hand side of the equation for the statement corresponding to n+1 .I hope this is clearer .If not , write again .", "label": "", "metadata": {}, "score": "54.13044"}
{"text": "In words , if the SNR is fixed while the dimension of the signal increases unboundedly , it is still possible to recover reliably some fraction of the support .This is in agreement with previous results on partial sparsity pattern recovery [ 5 ] , [ 9].", "label": "", "metadata": {}, "score": "54.355377"}
{"text": "Hypothesis testing uses this set of words to drive further selective image analysis that matches the input to one of the members of this set .This is done with a tree of feature tests that can be executed in several different ways to recognize an input word .", "label": "", "metadata": {}, "score": "54.509705"}
{"text": "Similarly , in analyses of contingency tables , the chi - squared approximation will be poor for small sample size , and it is preferable to use the Fisher Exact test .Ramsey and Ramsey show that the exact binomial test is always more powerful than the normal approximation .", "label": "", "metadata": {}, "score": "54.57169"}
{"text": "Hypothesis generation uses gross visual features , such as those that could be extracted from the peripheral presentation of a word , to provide expectations about word identity .Hypothesis testing integrates the information determined by hypothesis generation with more detailed features that are extracted from the word image .", "label": "", "metadata": {}, "score": "54.990837"}
{"text": "With the aid of the Chernoff is Note that in Gaussian random vectors .This allows us to use standard Gaussian integrals to calculate bound the expectation , is required to be bounded which is a necessary condition in Lemma 6 .", "label": "", "metadata": {}, "score": "55.163208"}
{"text": "A set of recognizer - independent constraints is developed to reflect the severity of the information lost due to each operation .These constraints are solved to assign specific costs to the operations .Experimental results on 2,335 corrupted strings and a lexicon of 21,299 words show higher correcting rates than with the original form .", "label": "", "metadata": {}, "score": "55.18283"}
{"text": "algorithm is available as gsl_randist_binomial_knuth .This will . result in a different sequence of binomial variates in programs using .this function .errors near quarter periods .user - specified tolerance for the SVD cutoff and return the .corresponding effective rank of the design matrix . gracefully ( i.e. quadratrics with a leading coefficient of zero ) .", "label": "", "metadata": {}, "score": "55.278973"}
{"text": "What remains is to see whether the sufficient conditions in Corollary 3 match the necessary conditions proved in [ 8 ] : Theorem 4 [ 8 ] : Suppose that the entries of the measurement matrix are drawn i.i.d . from any distribution with zero - mean and variance one .", "label": "", "metadata": {}, "score": "55.34124"}
{"text": "Page 3 . 4674IEEE TRANSACTIONS ON INFORMATION THEORY , VOL .57 , NO . 7 , JULY 2011 used before for this problem [ 4 ] , [ 5 ] , [ 7 ] ) , asymptotic behavior of binomial coefficients and properties of convex functions .", "label": "", "metadata": {}, "score": "55.36582"}
{"text": "Building a Collocation Net Given a large raw corpus and a general - purpose full parser , a collocation net can be built iteratively as follows : ( 1 ) Parse all the sentences in the large raw corpus into parsed trees using a general - purpose full parser .", "label": "", "metadata": {}, "score": "55.431232"}
{"text": "In this case , the classification can be hierarchical ... \" .A typical syntactic pattern recognition ( PR ) problem involves comparing a noisy string with every element of a dictionary , H. The problem of classification can be greatly simplified if the dictionary is partitioned into a set of sub - dictionaries .", "label": "", "metadata": {}, "score": "55.708946"}
{"text": "Theory , vol .55 , no .12 , pp .5758 - 5772 , Dec. 2009 .[ 7 ] A.Karbasi , A.Hormati , S.Mohajer , andM.Vetterli,\"Supportrecovery in compressed sensing : An estimation theoretic approach , \" in Proc .", "label": "", "metadata": {}, "score": "55.927643"}
{"text": "In this paper the Damerau - Levenshtein string difference metric is generalized in two ways to more accurately compensate for the types of errors that are present in the script recognition domain .First , the basic dynamic programming method for computing such a measure is extended to allow for merges , splits and two - letter substitutions .", "label": "", "metadata": {}, "score": "55.94746"}
{"text": "[14 ] F. Smadja , Retrieving collocations from text : Xtract , Computational Linguistics , 19(1 ) , 1993 , 143 - 177 .[15 ] G. W. Snedecor and G. C. William , Statistical Methods , Iowa State University Press , Ames , Iowa , 1989 , p. 127 .", "label": "", "metadata": {}, "score": "56.013214"}
{"text": ", Table IV .^ a b Hald 1998 , pp .633 - 692 , 27 .Sampling Distributions under Normality .Tools . by Kaizhong Zhang , Jason Wang , Dennis Shasha , Communicated T. Jiang , 1995 . \" ...", "label": "", "metadata": {}, "score": "56.094837"}
{"text": "Using these algorithms we present a syntactic Pattern Recognition ( PR ) scheme which corrects noisy tex ... .The proof is included in the unabridged paper [ 8]. by B. J. Oommen , R. L. Kashyap - In Advances in Structural and Syntactic Pattern Recognition , 1996 . \" ...", "label": "", "metadata": {}, "score": "56.321075"}
{"text": "REFERENCES [ 1 ] M. Zibulevsky and B. Pearlmutter , \" Blind source separation by sparse decomposition in a signal dictionary , \" Neur .Comput . , vol .13 , pp .863 - 882 , 2001 .[ 2 ] W. Vinje and J. Gallant , \" Sparse coding and decorrelation in primary visual cortex during natural vision , \" Science , vol .", "label": "", "metadata": {}, "score": "56.566338"}
{"text": "These methods can extract linguistic related word collocations from the parsed trees and can differentiate between different types of linguistic relations .Normally these 00166 . indd 311/29/2007 2:52:45 PM .Page 4 . 4 Guodong Zhou et al . 1stReading methods are combined with the frequency - based method to reject the ones whose frequencies are below the predefined threshold [ 16].", "label": "", "metadata": {}, "score": "57.085045"}
{"text": "4672 IEEE TRANSACTIONS ON INFORMATION THEORY , VOL .57 , NO . 7 , JULY 2011Nearly Sharp Sufficient Conditions on Exact Sparsity Pattern Recovery Kamiar Rahnama Rad Abstract - Consider the ?-dimensional vector ? where ?This canbeviewed as alinear system withsparsityconstraints cor- rupted by noise , where the objective is to estimate the sparsity pat- tern of ?", "label": "", "metadata": {}, "score": "57.25747"}
{"text": "The parser performs a beam search on the possible paths through the word graph and on the possible derivations of the unification grammar simultaneously .A metric is given to assign scores to ... \" .We present an active chart parser which parses left connected wordgraphs in a strictly time synchronous way .", "label": "", "metadata": {}, "score": "57.47374"}
{"text": "The solution utilizes the Object Migrating Automaton ( OMA ) whose power in clustering objects and images [ 33,35 ] has been reported .The power of the scheme for string taxonomy has been demons ... . ...d in the text recognition process is typically quadratic per word and is linear in the size of the dictionary .", "label": "", "metadata": {}, "score": "57.548332"}
{"text": "Theory , vol .55 , no .12 , pp .5728 - 5741 , Dec. 2009 .[5 ] M. Akcakaya and V. Tarokh , \" Shannon - theoretic limits on noisy compressive sampling , \" IEEE Trans .", "label": "", "metadata": {}, "score": "57.56896"}
{"text": "For example , t - test [ 1 , 3 ] assumes normal distribution and looks at the difference between the observed and expected means , scaled by the variance of the sample data .Chi - square test [ 2 , 15 ] uses n - by - n table to show the dependence of occurrences between words and compares the observed frequencies in the table with the expected frequencies for independence .", "label": "", "metadata": {}, "score": "57.66816"}
{"text": "Testing hypotheses using a normal distribution is well understood and relatively easy .The simplest chi - squared distribution is the square of a standard normal distribution .So wherever a normal distribution could be used for a hypothesis test , a chi - squared distribution could be used .", "label": "", "metadata": {}, "score": "57.761242"}
{"text": "Where are the squared normal distributions in contingency tables ?[ edit ] .Contingency tables are commonly analyzed using Pearson 's chi - squared test .At first glance , it is not obvious where the sum of squared normal distributions from a chi - squared distribution occur in a contingency table .", "label": "", "metadata": {}, "score": "57.87683"}
{"text": "This can be easily done through computing the EAMI and EPMI of all the collocation candidates extracted from the corpus , as described in Section 3 .Then all the collocation candidates whose EPMIs are larger than a threshold ( e.g. 0 ) are kept as collocations and sorted according to their EPMIs .", "label": "", "metadata": {}, "score": "58.024467"}
{"text": "We have two situa- or not : which implies that .This , in conjunction with plies that : is convex for 3 .Either case , i.e. , creasing for all proves the desired inequality ( 22 ) .for , im- is decreasing for . is convex for and convex for or de- , V. CONCLUSION In this paper , we examined the probability that the optimal decoder declares an incorrect sparsity pattern .", "label": "", "metadata": {}, "score": "58.13614"}
{"text": "More explicitly , if A is any ... \" .In this paper we present a foundational basis for optimal and information theoretic syntactic pattern recognition .The scheme is shown to be Functionally Complete and stochastically consistent .Experimental results which involve dictionaries with strings of lengths between 7 and 14 with an overall average noise of 39.75 % demons ... .", "label": "", "metadata": {}, "score": "58.32605"}
{"text": "Two top down and one bottom up method are investigated .In bottom up mode , the decoder sends word hypotheses as they are found from left to right , while the parser keeps step .In verify mode , the decoder is always a frame ahead , while the parser verifies received hypotheses , providing language informat ... . ... gh the set of word hypotheses .", "label": "", "metadata": {}, "score": "58.481483"}
{"text": "Previous work has shown how a back - propagation network with recurrent connections can successfully model many aspects of human spoken word recogni - tion ( Norris , 1988 , 1990 , 1992 , 1993 ) .However , such networks are unable to revise their decisions in the light of subsequent context .", "label": "", "metadata": {}, "score": "58.629074"}
{"text": "Previous work has shown how a back - propagation network with recurrent connections can successfully model many aspects of human spoken word recogni - tion ( Norris , 1988 , 1990 , 1992 , 1993 ) .However , such networks are unable to revise their decisions in the light of subsequent context .", "label": "", "metadata": {}, "score": "58.629074"}
{"text": "Statistical projections show the viability of all three stages of the proposed approach .The traditional case which has been extensively studied in the literature is the one in which Y contains substitution , insertion and deletion ( SID ) errors .", "label": "", "metadata": {}, "score": "58.80646"}
{"text": "Theory , vol .54 , no .5 , pp .2210 - 2219 , May 2008 .[ 12 ] T. A. Severini , Elements of Distribution Theory .Cambridge University Press , 2005 .[ 13 ] P. Bjorstad and J. Mandel , \" On the spectra of sums of orthogonal pro- jections with applications to parallel computing , \" BIT Numer .", "label": "", "metadata": {}, "score": "59.18987"}
{"text": "This problem is motivated by the study of information retrieval for bio - chemical and molecular databases .Suppose we define the distance between two CUAL graphs G1 and G2 to be the weig ... \" .We consider the problem of comparing CUAL graphs ( Connected , Undirected , Acyclic graphs with nodes being Labeled ) .", "label": "", "metadata": {}, "score": "59.33719"}
{"text": ", Loci of contextual effects on visual word recognition , in Attention and Performance V , edited by P. Rabbitt and S. Dornie .Academic Press , 1975 , pp .98 - 116 .[ 12 ] I. C. Ross and J. W. Tukey , Introduction to these volumes , in John Wilder Tukey ( ed . ) , Index to Statistics and Probability , R&D Press , Los Altos , 1975 , pp . iv - x .", "label": "", "metadata": {}, "score": "59.363995"}
{"text": "Indeed , the entire problem of sub - dividing a set of strings into subsets where each subset contains \" similar \" strings has been referred to as the \" String Taxonomy Problem \" .To our knowledge there is no reported solution to this problem ( see footnote on Page 2 ) .", "label": "", "metadata": {}, "score": "59.724022"}
{"text": "In this paper , we introduce a new support recovery algorithm from noisy measurements called Bayesian hypothesis test via belief propagation ( BHT - BP ) .BHT - BP focuses on sparse support recovery rather than sparse signal estimation .The key idea behind BHT - BP is to detect the support set of a sparse vector using hypothesis test where the posterior densities used in the test are obtained by aid of belief propagation ( BP ) .", "label": "", "metadata": {}, "score": "59.85203"}
{"text": "A new model is presented which displays the more desirable properties of each of these models .In contrast to TRACE the new model is entirely bottom - up and can readily perform simulations with vocabularies of tens of thousands of words .", "label": "", "metadata": {}, "score": "60.016056"}
{"text": "A review of such distance measures and ... . ... red to edit one string to another .The GLD is closely related to other measures involving the strings , such as their longest common subsequence [ 2,3].Unfortunately , the GLD is inadequate for recognizing noisy subsequences [ 11 ] and skeletal i m ... . by B. John Oommen , Edward V. De St. Croix - IEEE Transactions on Systems , Man and Cybernetics , 1997 . \" ...", "label": "", "metadata": {}, "score": "60.04183"}
{"text": "One of the salient features of this scheme is that it demonstrates how dynamic programming can be applied to evaluate quantities involv ... .We consider a problem which can greatly enhance the areas of cursive script recognition and the recognition of printed character sequences .", "label": "", "metadata": {}, "score": "60.199333"}
{"text": "The error ratedecreases exponentiallyin the norm of the pro- jection of on the orthogonal subspace spanned by the columns of .This is in agreement with the intuition that the closer different subspaces corresponding to different sets of columns of are , the harder it is to differentiate them , and hence the higher the error probability will be .", "label": "", "metadata": {}, "score": "60.359173"}
{"text": "An interesting open problem is to extend the sufficient conditionsderivedinthisworktonon - Gaussianandsparsemea- surement matrices .Page 8 .RAD : NEARLY SHARP SUFFICIENT CONDITIONS ON EXACT SPARSITY PATTERN RECOVERY4679 ACKNOWLEDGMENT The author would like to express his gratitude to V. Roy- chowdhury for introducing him to this subject .", "label": "", "metadata": {}, "score": "60.38262"}
{"text": "Consequently , we obtain sufficient conditions on the sample size n that guarantee almost surely the recovery of the true sparsity pattern .We find that the required growth rate of sample size n matches the growth rate of previously established necessary conditions .", "label": "", "metadata": {}, "score": "60.407566"}
{"text": "An example class ( \" finance / tax \" ) in the 2nd level of the collocation net . indd 13 11/29/2007 2:52:47 PM .Page 14 .14 Guodong Zhou et al . 1stReading Figure 1 compares the effect of different a 's in full parsing re - ranking .", "label": "", "metadata": {}, "score": "60.429943"}
{"text": "Thus , as the sample size for a hypothesis test increases , the distribution of the test statistic approaches a normal distribution , and the distribution of the square of the test statistic approaches a chi - squared distribution .Just as extreme values of the normal distribution have low probability ( and give small p - values ) , extreme values of the chi - squared distribution have low probability .", "label": "", "metadata": {}, "score": "60.6044"}
{"text": "Building a Collocation Net 11 1stReading from Tij ; CC is the number of collocation candidates extracted from Tij and EPMI(CCi ) is the estimated pair - wise mutual information , which measures the change of information when the collocation candidate CCi is collocated .", "label": "", "metadata": {}, "score": "60.606766"}
{"text": "Their paper formulated the theoretical properties of the measure and de ... \" .Marzal and Vidal [ 8 ] recently considered the problem of computing the normalized edit distance between two strings , and reported experimental results which demonstrated the use of the measure to recognize handwritten characters .", "label": "", "metadata": {}, "score": "60.6353"}
{"text": "Typically , it is represente ... . \" ...In this paper we present a foundational basis for optimal and information theoretic syntactic pattern recognition .More explicitly , if A is any ... \" .In this paper we present a foundational basis for optimal and information theoretic syntactic pattern recognition .", "label": "", "metadata": {}, "score": "60.671444"}
{"text": "Many hypothesis tests use a test statistic , such as the t statistic in a t - test .For these hypothesis tests , as the sample size , n , increases , the sampling distribution of the test statistic approaches the normal distribution ( Central Limit Theorem ) .", "label": "", "metadata": {}, "score": "60.712284"}
{"text": "RAD : NEARLY SHARP SUFFICIENT CONDITIONS ON EXACT SPARSITY PATTERN RECOVERY4675 TABLE I NECESSARY AND SUFFICIENT CONDITIONS ON THE NUMBER OF MEASUREMENTS ?REQUIRED FOR RELIABLE SUPPORT RECOVERY IN THE LINEAR AND THE SUBLINEAR REGIME .THE SUFFICIENT CONDITIONS PRESENTED IN THE FIRST FOUR ROWS ARE A CONSEQUENCE OF PAST WORK [ 4 ] , ALSO RECOVERED BY COROLLARY 3 .", "label": "", "metadata": {}, "score": "60.713722"}
{"text": "The result would be a trajectory of all the foreground objects in the video .As an example , look at the 4 frames below ( left to right , top to bottom ) .They were extracted from a video ( by photoshop - ing the background off ) after every 25 frames .", "label": "", "metadata": {}, "score": "60.86045"}
{"text": "The result would be a trajectory of all the foreground objects in the video .As an example , look at the 4 frames below ( left to right , top to bottom ) .They were extracted from a video ( by photoshop - ing the background off ) after every 25 frames .", "label": "", "metadata": {}, "score": "60.86045"}
{"text": "common vocabularies , part - of - speecb . tag cooccurrence .SlIUctural parsing with a cb.art data structure . and semantic biasing with a thesaurns . by Julie Carson - Berndsen , Martina Pampel , Martina Pampel , Gehort Antragsabschnitt , Interaktive Phonologische Interpretation , 1994 . \" ...", "label": "", "metadata": {}, "score": "61.292763"}
{"text": "\" Evaluating the Normal Approximation to the Binomial Test \" .Journal of Educational Statistics 13 ( 2 ) : 173 - 82 .^ a b Lancaster , H.O. ( 1969 ) , The Chi - squared Distribution , Wiley .", "label": "", "metadata": {}, "score": "61.41486"}
{"text": "Moreover , the extracted collocations or co - occurrences are always stored in a dictionary , which only contains a limited number of entries with limited information for each one .Finally , the collocation dictionary normally does not differentiate the strength of various collocations .", "label": "", "metadata": {}, "score": "61.426006"}
{"text": "Each class in both levels is represented by its collocation candidate distribution , extracted from the linguistic analysis of the raw training corpus , over possible collocation relation types .In this way , all the information extracted from the linguistic analysis is kept in the collocation net .", "label": "", "metadata": {}, "score": "61.733013"}
{"text": "We consider a problem which can greatly enhance the areas of cursive script recognition and the recognition of printed character sequences .This problem involves recognizing words / strings by processing their noisy subsequences .We solve the noisy subsequence recognition problem by defining and using the constrained edit distance between X H and Y subject to any arbitrary edit constraint involving the number and type of edit operations to be performed .", "label": "", "metadata": {}, "score": "61.924614"}
{"text": "In the k - means clustering algorithm , k is fine - tuned to 1000 to achieve proper granity and the frequency distributions of C FDCC are mapped to each class in C2 of the two - level collocation net using cross- validation in this paper .", "label": "", "metadata": {}, "score": "62.030323"}
{"text": "Recog .with Subst . , Insert . , Delet . and Gen. Transpos .... .by Giovanni Seni , V Kripasundar , V Krip Asundar , Rohini K. Srihari - Pattern Recognition , 1996 . \" ...In this paper the Damerau - Levenshtein string difference metric is generalized in two ways to more accurately compensate for the types of errors that are present in the script recognition domain .", "label": "", "metadata": {}, "score": "62.041092"}
{"text": "This suggests the data sparseness problem in building a collocation net and proper handling can improve the performance .For clarity , Table 5 lists the effect of the best full parsing re - ranking system using the collocation net .It shows that the use of the collocation net can increase the F - measure by 1.9 in F - measure .", "label": "", "metadata": {}, "score": "62.129833"}
{"text": "The sufficient conditions of Corollary 3 can be com- pared against the necessary conditions in [ 8 ] for exact sparsity pattern recovery , as shown in Table I. The first paper to estab- lish the sufficient conditions in row 1 and row 4 of Table I is [ 10].", "label": "", "metadata": {}, "score": "62.39843"}
{"text": "Theory , vol .56 , no . 1 , pp .492 - 504 , Jan. 2010 .[ 6 ] A. Fletcher , S. Rangan , and V. Goyal , \" Necessary and sufficient con- ditions on sparsity pattern recovery , \" IEEE Trans .", "label": "", "metadata": {}, "score": "62.62323"}
{"text": "basedon(2)achieves arenonzero .Thefollowing Corollary 3 : For the observational model of ( 4 ) and the esti- mate in ( 2 ) , let , and there exists a constant such that if and scale as a function of . whereis defined , when is sufficient , and is sufficient .", "label": "", "metadata": {}, "score": "62.82428"}
{"text": "19 ] .^ Jonhson , N. L. ; Kotz , S. ; Balakrishnan , N. ( 1994 ) .\" Chi - Squared Distributions including Chi and Rayleigh \" .Continuous Univariate Distributions 1 ( Second ed . )John Willey and Sons .", "label": "", "metadata": {}, "score": "62.883976"}
{"text": "Set the environment variable .To assist debugging , .the test number of each failure is shown in square brackets at the . line - end [ NNNN]. incorrect results for some input matrices . hypot internally to avoid overflow when computing terms like . handle deprecated functions using the GSL_DISABLE_DEPRECATED macro .", "label": "", "metadata": {}, "score": "63.113445"}
{"text": "[ 6 ] included the maximum - to - average ratio3of in their analysis .Necessary and sufficient conditions for frac- tional sparsity pattern recovery were analyzed in [ 5 ] , [ 9].We will discuss the relationship to this work below in more depth , after describing our analysis and results in more detail . , B. Notation The following conventions will remain in effect throughout this paper .", "label": "", "metadata": {}, "score": "63.304337"}
{"text": "We say has sparsity pattern with indices are nonzero .entries that are in but not in .We denote by , the matrix obtained from extracting columns with indices obeying stand for the sparsity pattern or support set of norm of a matrixdefined as if the entries stands for the set of for the cardinality of and by .", "label": "", "metadata": {}, "score": "63.58861"}
{"text": "The objective of postprocessing is to correct errors or to resolve ambiguities in OCR results by using contextual information .Depend ... \" .Recognition of degraded text is a challenging problem .To improve the performance of an OCR system on degraded images of text , postprocessing techniques are critical .", "label": "", "metadata": {}, "score": "63.747643"}
{"text": "5456 , pp .1273 - 1276 , 2000 .Biotech , vol .23 , pp .377 - 383 , Mar. 2005 .[ 4 ] M.Wainwright,\"Information - theoreticlimitationsonsparsityrecovery in the high - dimensional and noisy setting , \" IEEE Trans .", "label": "", "metadata": {}, "score": "64.143234"}
{"text": "The full NEWS file .entry is appended below .GSL is free software distributed under the GNU General Public .License .Thanks to everyone who reported bugs and suggested improvements .Brian Gough .Network Theory Ltd , . variate TPE algorithm by default .", "label": "", "metadata": {}, "score": "64.301636"}
{"text": "\" [ Show abstract ] [ Hide abstract ] ABSTRACT : This paper considers the problem of sparse signal re - covery when the decoder has prior information on the sparsity pat - tern of the data .The data vector has a ran - domly generated sparsity pattern , where the -th entry is non - zero with probability .", "label": "", "metadata": {}, "score": "64.32968"}
{"text": "The model does this without causing inefficient parsing of sentences that do not require relaxation of constraints or dynamic extension of the grammar . by Jonathan J. Hull - Fundamentals in Handwriting Recognition , NATO - Advanced Study Institute Series F , 1994 . \" ...", "label": "", "metadata": {}, "score": "64.358444"}
{"text": "[ 7 ] D. Hindle and M. Rooth , Structural ambiguity and lexical relations , Computational Linguistics , 19(1 ) , 1993 , 102 - 119 .[ 8 ] J. S. Justeson and S. M. Katz , Technical terminology : Some linguistic properties and an algorithm for identification in text , Natural Language Engineering , 1(1 ) , 1995 , 9 - 27 .", "label": "", "metadata": {}, "score": "64.389496"}
{"text": "68 - 73 .[ 10 ] C. D. Manning and H. Schutze , Foundations of Statistical Natural Language Processing , MIT Press , 1999 , p. 185 . indd 1511/29/2007 2:52:48 PM .Page 16 .16 Guodong Zhou et al . 1st", "label": "", "metadata": {}, "score": "64.399536"}
{"text": "Unlike more widely - known distributions such as the normal distribution and the exponential distribution , the chi - squared distribution is rarely used to model natural phenomena .It arises in the following hypothesis tests , among others .It is also a component of the definition of the t - distribution and the F - distribution used in t - tests , analysis of variance , and regression analysis .", "label": "", "metadata": {}, "score": "64.58185"}
{"text": "A low p -value indicates greater statistical significance , i.e. greater confidence that the observed deviation from the null hypothesis is significant .A p -value of 0.05 is often used as a cutoff between significant and not - significant results .", "label": "", "metadata": {}, "score": "64.72438"}
{"text": "If no , re - build the collocation net by adjusting the probability of each PTH and going to Step ( 2 ) .( 13 ) dIn this paper , the threshold for the average probability ratio is set to 0.99 . indd 1011/29/2007 2:52:47 PM .", "label": "", "metadata": {}, "score": "64.78892"}
{"text": "( 2.35 ) , ISBN 978 - 0 - 387 - 34657 - 1 .^ Box , Hunter and Hunter ( 1978 ) .Statistics for experimenters .Wiley .p. 118 .ISBN 0471093157 .^ Bartlett , M. S. ; Kendall , D. G. ( 1946 ) .", "label": "", "metadata": {}, "score": "64.805954"}
{"text": "Extending on this idea , given multiple observers you could possibly track all the people in the crowd .But for a machine , performing a similar task might be quite difficult .This is because , unlike the human brain , a machine processing a video can not automatically infer temporal ( over multiple frames ) associations between different objects of interest .", "label": "", "metadata": {}, "score": "64.85756"}
{"text": "Extending on this idea , given multiple observers you could possibly track all the people in the crowd .But for a machine , performing a similar task might be quite difficult .This is because , unlike the human brain , a machine processing a video can not automatically infer temporal ( over multiple frames ) associations between different objects of interest .", "label": "", "metadata": {}, "score": "64.85756"}
{"text": "However , convergence is slow as the skewness is and the excess kurtosis is 12/ k .The sampling distribution of ln ( \u03c7 2 ) converges to normality much faster than the sampling distribution of \u03c7 2 , [ 13 ] as the logarithm removes much of the asymmetry .", "label": "", "metadata": {}, "score": "64.98654"}
{"text": "IEEE Int .Symp .Information Theory , 2008 , pp .2187 - 2191 .[ 10 ] M. J. Wainwright , \" Sharp thresholds for noisy and high - dimensional recovery of sparsity using ?-constrained quadratic programming ( lasso ) , \" IEEE Trans .", "label": "", "metadata": {}, "score": "65.06099"}
{"text": "Supplement to the Journal of the Royal Statistical Society 8 ( 1 ) : 128 - 138 .JSTOR 2983618 .^ Davies , R.B. ( 1980 ) .\" Algorithm AS155 : The Distributions of a Linear Combination of \u03c7 2 Random Variables \" .", "label": "", "metadata": {}, "score": "65.18298"}
{"text": "However , it should be noted that the word \" term \" has a different meaning in information retrieval , where it refers to words and phrases .There are more and more interest in collocations and co - occurrences partly because this area has been undervalued in the structural linguistic traditions that follow Saussure and Chomsky .", "label": "", "metadata": {}, "score": "65.305084"}
{"text": "Symp .Information Theory , 2009 .[ 8 ] W. Wang , M. Wainwright , and K. Ramchandran , \" Information - theo- retic limits on sparse signal recovery : Dense versus sparse measure- mentmatrices,\"IEEETrans .Inf .Theory , vol.56,no.6,pp.2967 - 2979 , Jun. 2010 .", "label": "", "metadata": {}, "score": "65.48865"}
{"text": "Suppose we define the distance between two CUAL graphs G1 and G2 to be the weighted number of edit operations ( insert node , delete node and relabel node ) to transform G1 to G2 .By reduction from exact cover by 3-sets , one can show that finding the distance between two CUAL graphs is NP - complete .", "label": "", "metadata": {}, "score": "65.66029"}
{"text": "De Moivre and Laplace established that a binomial distribution could be approximated by a normal distribution .Specifically they showed the asymptotic normality of the random variable .In the case of a binomial outcome ( flipping a coin ) , the binomial distribution may be approximated by a normal distribution ( for sufficiently large n ) .", "label": "", "metadata": {}, "score": "65.915436"}
{"text": "Thus in German this was traditionally known as the Helmert'sche ( \" Helmertian \" ) or \" Helmert distribution \" . xxxi - xxxiii , 26 - 28 , Table XII ) .[21 ] The idea of a family of \" chi - squared distributions \" , however , is not due to Pearson but arose as a further development due to Fisher in the 1920s .", "label": "", "metadata": {}, "score": "66.31227"}
{"text": "Through the collocation net , the data sparseness problem is resolved by providing a clustering mechanism and the collocation relationship between any two words can be easily determined and measured from the collocation net .Here , the collocation relationship is calculated using novel estimated pair - wise mutual information ( EPMI ) and estimated average mutual information ( EAMI ) .", "label": "", "metadata": {}, "score": "66.413635"}
{"text": "Define a new random variable Q. To generate a random sample from Q , take a sample from Z and square the value .The distribution of the random variable Q is an example of a chi - squared distribution : The subscript 1 indicates that this particular chi - squared distribution is constructed from only 1 standard normal distribution .", "label": "", "metadata": {}, "score": "67.068504"}
{"text": "The union bound allows us to bound the probability of the event probabilities of events like can be written as for all sparsity patterns by the sum of .In mathematical terms Lemma 8 which is based on generating functions of chi - square distributions introduces an upper bound for the event ; namely with bound obtain an upper bound for the event depend on as long as patterns that are different from .", "label": "", "metadata": {}, "score": "67.21744"}
{"text": "The relation between these ideas is either very remote or nonexistent .I warned you that this might not be the way that the poser of the problem wanted this proved .I would be interested in what method was used , if you care to tell it .", "label": "", "metadata": {}, "score": "67.22157"}
{"text": "It follows from the definition of the chi - squared distribution that the sum of independent chi - squared variables is also chi - squared distributed .Note that we would have obtained the same result invoking instead the central limit theorem , noting that for each chi - squared variable of degree the expectation is , and its variance ( and hence the variance of the sample mean being ) .", "label": "", "metadata": {}, "score": "67.23414"}
{"text": "In addition , BHT - BP has low computational cost compared to the other algorithms by the use of BP .We show the support recovery performance of BHT - BP on the parameters ( N ; M ; K ; SNR ) and compare the performance of BHT - BP to OMP and Lasso via numerical results .", "label": "", "metadata": {}, "score": "67.475174"}
{"text": "Fourthly , mutual information - based method [ 13 , 17 , 19 , 20 ] tells the change of information when two words co - occur .The scores used by t - test and chi - square are difficult to interpret while mutual information - based method is the worst for the low frequently occurred words .", "label": "", "metadata": {}, "score": "67.58546"}
{"text": "Varions aspects of using language\u00b7level syntaCtic and semantic constraints to improve the performance of word recognition algorithms are discnssed .Following a brief presentation of a hypothesis generation model for handwriaen word recognition .varions types of language \u00b7 level constraints ... \" .", "label": "", "metadata": {}, "score": "67.74533"}
{"text": "Table 5 .Application of the collocation net in parse tree re - ranking .P(%)R(%)F1 Before re - ranking After re - ranking 88.26 90.12 88.05 89.98 88.15 90.06 6 .Conclusion This paper proposes a novel structure of two - level collocation net and a method capable of automatically building the collocation net given a large raw corpus .", "label": "", "metadata": {}, "score": "67.98006"}
{"text": "The support set of imizing the probability of identifying a wrong sparsity pattern .First , we are concerned with the likelihood of the sparsity patternof asa functionof and .Weobtainanupperbound on the probability that has any specific sparsity pattern and find that this bound depends ( inversely ) exponentially on the difference of and the -norm of range of columns of indexed by the wrong sparsity pattern .", "label": "", "metadata": {}, "score": "68.07449"}
{"text": "When applied to ordered trees , the degree-2 distance is a genera ... . \" ...A critical feature of any computer system is its interface with the user .This has led to the development of user interface technologies such as mouse , touchscreen and penbased input devices .", "label": "", "metadata": {}, "score": "68.22412"}
{"text": "4678 IEEE TRANSACTIONS ON INFORMATION THEORY , VOL .57 , NO . 7 , JULY 2011Hence , if ( 21 ) thenwegettheequationshownatthebottomofthepage . There-fore , inequalities ( 17 ) and ( 21 ) , which are the main conditions in Theorem 1 , imply that where .", "label": "", "metadata": {}, "score": "68.27464"}
{"text": "If are chi square random variables and , then a closed expression for the distribution of is not known .It may be , however , calculated using the property of characteristic functions of the chi - squared random variable .[ 16 ] .", "label": "", "metadata": {}, "score": "68.35483"}
{"text": "[ 4 ] M. Collins , Head - driven statistical models for natural language parsing , Ph.D. Dissertation , University of Pennsylvania , 1999 .[5 ] T. Dunning , Accurate methods for the statistics of surprise and coincidence , Computational Linguistics , 19(1 ) , 1993 , 61 - 74 .", "label": "", "metadata": {}, "score": "68.39348"}
{"text": "If we replace which follows the definition of with the lower we that does not is fixed .The number of sparsity in exactly elements is by inequality .In the statement of Theorem 2 , we have the that results in the following upper bound : ( 19 ) ( 20 ) .", "label": "", "metadata": {}, "score": "68.467354"}
{"text": "Experimentation is given in Section 5 .Finally , some conclusions are drawn in Section 6 . indd 411/29/2007 2:52:45 PM .Page 5 .Building a Collocation Net 5 1stReading 2 .Collocation Net The collocation net is a kind of two - level structure , which stores rich information about the collocation candidates and others extracted from the linguistic analysis of a large raw corpus .", "label": "", "metadata": {}, "score": "68.629425"}
{"text": "Proof of Lemma 8 : The columns of by definition , disjoint and therefore independent Gaussian random matrices with column spaces spanning random inde- pendent -and -dimensional subspaces , respectively .The Gaussian random vector entries with variance since the random Gaussian vector onto the subspace orthogonal to the random column space of , the quantity chi - square random variable with Thus andare , has i.i.d .", "label": "", "metadata": {}, "score": "68.896255"}
{"text": "The new stronger result in this paper provides the sufficient conditions in row 5 and 6 , which did not appear in previous studies [ 4]-[7 ] , and match the previous necessary con- ditions presented in [ 8].( It is worth reminding that these results are restricted to and . )", "label": "", "metadata": {}, "score": "68.90749"}
{"text": "In contrast , Contextual Theory of Meaning that follows Firth , Halliday and Sinclair , emphasizes the importance of context : the context of social setting , the context of discourse and the context of surrounding words .Such detailed contextual information easily gets lost in structural linguistics .", "label": "", "metadata": {}, "score": "68.93294"}
{"text": "Compared with the traditional collocation dictionary , the collocation net provides a much more powerful facility since it can determine and measure the collocation relationship between any two words quantitatively .The layout of this paper is as follows : Section 2 describes the novel structure of collocation net .", "label": "", "metadata": {}, "score": "69.417404"}
{"text": "Hence are 2 .This allows us to obtain sufficient conditions on the number of measurements as a function of We show that our results strengthen earlier sufficient conditions .for reliable sparsity recovery .1This entails no loss of generality , by standard rescaling of ? 2To the best of our knowledge , Wainwright [ 4 ] was the first to formulate the information theoretic limitations of sparsity pattern recovery using ? of the key parameters .", "label": "", "metadata": {}, "score": "69.56445"}
{"text": "Preliminary experimental results using a Persian continuous speech recognition system show effective improvements in accuracy with little change in recognition time .The word error rate was also reduced by 18 % .ecognition systems .The word lattice used in this system is implemented as a data structure in which every word is linked to the words that immediately follow it in different sentences .", "label": "", "metadata": {}, "score": "69.57043"}
{"text": "from user - defined functions to the top - level in all cases .the input vector .The order of nans in the output is undefined , .although other elements will be sorted correctly .-----BEGIN PGP SIGNATURE----- .Version : GnuPG v1.4.1 ( GNU / Linux ) .", "label": "", "metadata": {}, "score": "69.76587"}
{"text": "II .RESULTS For the observational model in ( 1 ) , assume that the true spar- sity model is ; as a result ( 4 ) 3The maximum - to - average ratio of ? was defined as ? ? ? ? ? ?", "label": "", "metadata": {}, "score": "69.88209"}
{"text": "Lemma 6 follows standard Gaussian integrals [ 12]. A. Proof of Theorem 1 For a given sparsity pattern squares is achieved by , the minimum residual sum of where column space of size , the optimum decoder declares denotes the orthogonal projection operator into the ; that is , among all sparsity patterns with .", "label": "", "metadata": {}, "score": "69.93903"}
{"text": "Varions aspects of using language\u00b7level syntaCtic and semantic constraints to improve the performance of word recognition algorithms are discnssed .Following a brief presentation of a hypothesis generation model for handwriaen word recognition .varions types of language \u00b7 level constraints are rev1?ed .", "label": "", "metadata": {}, "score": "69.9677"}
{"text": "The chi - squared distribution is obtained as the sum of the squares of k independent , zero - mean , unit - variance Gaussian random variables .Generalizations of this distribution can be obtained by summing the squares of other types of Gaussian random variables .", "label": "", "metadata": {}, "score": "70.38117"}
{"text": "Page 6 . 6 Guodong Zhou et al . 1stReading related to Chi .That is , each word and feature bigram or class in the collocation net is represented by the distribution of its related collocation candidates .In this way , all the information extracted via the linguistic analysis is stored in the collocation net .", "label": "", "metadata": {}, "score": "70.59941"}
{"text": "16 ] J. Yang , Towards the automatic acquisition of lexical selection rules , MT Summit VII , Singapore , 1999 , pp .397 - 403 .[17 ] D. Yuret , Discovery of linguistic relations using lexical attraction , Ph .", "label": "", "metadata": {}, "score": "70.85102"}
{"text": "-----END PGP SIGNATURE-----This course introduces the students to the application of statistical theory of science , education , and business .Emphasis is placed on statistical inference , but descriptive work is also considered .Problems of estimation , errors , and hypothesis testing are covered , and the theory of probability is discussed in detail .", "label": "", "metadata": {}, "score": "70.87329"}
{"text": "[20 ] G. D. Zhou and K. T. Lua , Interpolation of N - gram and MI - based trigger pair language modeling in mandarin speech recognition , Computer , Speech and Language , 13(2 ) , 1999 , 123 - 135 . indd 1611/29/2007 2:52:48 PM .", "label": "", "metadata": {}, "score": "71.00697"}
{"text": "Weaimtoprovethatundercertainconditions , forsome , is a decreasing function for increasing function for bound for and an .This yields thedesired upper ( 22 ) Webeginbytakingderivativesof tioned claim toprovetheaforemen-Note that in the following steps , we use inequality ( 15 ) , i.e. , to prove inequality ( 22 ) .", "label": "", "metadata": {}, "score": "71.3352"}
{"text": "The presented approach is hybrid in two senses .First , it combines structural and statistical methods for language modeling task .Second , it employs a chart parser which u ... \" .In this paper , we present a novel approach to integrate speech recognition and rulebased machine translation by lattice parsing .", "label": "", "metadata": {}, "score": "71.391815"}
{"text": "[ 2 ] K. W. Church and A. G. William , A comparison of the enhanced good turing and deleted estimation methods for estimating probabilities of English bigrams , Computer , Speech and Language , 5(1 ) , 1991 , 19 - 54 .", "label": "", "metadata": {}, "score": "71.70342"}
{"text": "Table 4 shows an example class \" finance / tax \" in the second level of the collocation net .In order to further evaluate the usefulness of the collocation net , we have used it in full parsing re - ranking using the standard PARSEVAL metrics .", "label": "", "metadata": {}, "score": "71.933624"}
{"text": "Therefore , we conclude that , is projected is a degrees of freedom .The first inequality follows from Theorem 1 and the second equality comes from the well - known formula ( see for example [ 12 ] ) for the moment - generating function of a chi - square random variable ; that is , .", "label": "", "metadata": {}, "score": "72.22622"}
{"text": "From inequality ( 15 ) , we have which ensures that .This implies the convexity of and the negativity of tions depending on whether 1 . : From inequality ( 15 ) we have has two solutionsand such that ., we have : ; ; .", "label": "", "metadata": {}, "score": "72.29547"}
{"text": "First , it combines structural and statistical methods for language modeling task .Second , it employs a chart parser which utilizes manually created syntax rules in addition to scores obtained after statistical processing during speech recognition .The employed chart parser is a unification - based active chart parser .", "label": "", "metadata": {}, "score": "72.61683"}
{"text": "Look at the errors , like the one in the lower left frame , where the man in the middle , has a broken off leg .A good point - to - point correspondence tracker will mask such errors .Although these frames have been synthetically generated , the errors can be considered quite real because such scenarios usually occur as a result of many background subtraction techniques .", "label": "", "metadata": {}, "score": "72.8798"}
{"text": "Look at the errors , like the one in the lower left frame , where the man in the middle , has a broken off leg .A good point - to - point correspondence tracker will mask such errors .Although these frames have been synthetically generated , the errors can be considered quite real because such scenarios usually occur as a result of many background subtraction techniques .", "label": "", "metadata": {}, "score": "72.8798"}
{"text": "In this short communication we shall demonstrate how this measure is related to an auxiliary measure already defined in the literature -- the inter - string constrained edit distance [ 10,11,15].Since the normalized edit distance can be computed efficiently using the latter , the analytic and experimental results reported in [ 8 ] can be obtained just as accurately , but more efficiently , using the strategies presented here .", "label": "", "metadata": {}, "score": "73.0058"}
{"text": "In this paper , a collocation candidate is represented as a 3tuple : a left side , a right side and a collocation relation type , which represents the collocation relationship between the left side and the right side .Both the left and right sides can be either a word and feature bigram or a class of word and feature bigrams . is the number of the collocation relation types in CR .", "label": "", "metadata": {}, "score": "73.025826"}
{"text": "The matrix Note that if equal to the top eigenvalue of all vector norms are orthonormal operator projecting into the subspace spanned by the columns of be defined as is a positive semi - definite matrix then .Except for the matrix norm , is .", "label": "", "metadata": {}, "score": "73.0585"}
{"text": "-----BEGIN PGP SIGNED MESSAGE-----Hash : SHA1 Version 1.7 of the GNU Scientific Library is now available , ftp://ftp.gnu.org/gnu/gsl/gsl-1.7.tar.gz ( 2.2 MB ) ftp://ftp.gnu.org/gnu/gsl/gsl-1.7.tar.gz.sig ( GPG signature ) .521b9aa094a3dc2cb088f29efca0bda3 ( MD5 checksum ) .The GNU Scientific Library ( GSL ) provides a large collection of .", "label": "", "metadata": {}, "score": "73.07746"}
{"text": "Logical evaluation is carried out according to a data model which acts as optimal input in order that each component participating in the evaluation process can be tested for soundness and completeness .Inconsistencies can thus be remedied before empirical evaluation of the model is undertaken using real data .", "label": "", "metadata": {}, "score": "73.210754"}
{"text": "User code should switch .to the new definitions gsl_fft_forward , gsl_fft_backward , . gsl_wavelet_forward and gsl_wavelet_backward .Selectively define .GSL_DISABLE_DEPRECATED before including the headers to use the new . definitions on either or both modules .Iterations . should now follow Brent 's original description correctly .", "label": "", "metadata": {}, "score": "73.300476"}
{"text": "In the proof I gave , I did just that to establish the induction step .I assumed the statement was true for some particular value n , and then wrote down one side of the equation for the statement corresponding to the next value of n , that is , n+1 .", "label": "", "metadata": {}, "score": "73.35474"}
{"text": "Recent advances in pen - based hardware and wireless communication have been influential factors in the renewed interest in on - line recognition systems .On - line handwriting recognition is fundamentally a pattern classification task ; the objective is to take an input pattern , the handwritten signal collected on - line via a digitizing device , and classify it as one of a pre - specified set of words ( i.e. , the system 's lexicon ) .", "label": "", "metadata": {}, "score": "73.373215"}
{"text": "14 ] Other functions of the chi - squared distribution converge more rapidly to a normal distribution .Some examples are : .A chi - squared variable with k degrees of freedom is defined as the sum of the squares of k independent standard normal random variables .", "label": "", "metadata": {}, "score": "73.43837"}
{"text": "^ den Dekker A. J. , Sijbers J. , ( 2014 ) \" Data distributions in magnetic resonance images : a review \" , Physica Medica , [ 1 ] .^ Chi - Squared Test Table B.2 .Dr. Jacqueline S. McLaughlin at The Pennsylvania State University .", "label": "", "metadata": {}, "score": "73.521324"}
{"text": "Lemma 8 : For Gaussian measurement matrices , with the average error probability that the optimum decoder declares is bounded by where .Lemma 9 : For the function defined on positive integers if ( 15 ) then Before we prove the two lemmas , let us see how they imply Theorem 2 . A. Proof of Theorem 2 In order to find conditions under which asymptotically goes to zero , we exploit the union bound in conjunction with counting arguments and the previously stated two lemmas .", "label": "", "metadata": {}, "score": "73.60771"}
{"text": "Similarly to AMI , the problem with the above equation is that it only works on frequently occurring word and feature bigrams .In order to resolve this problem , we also propose a modified version of PMI , called estimated pair - wise mutual information ( EPMI ) , to calculate the information change of a collocation candidate when one or two word and feature bigrams do not occur frequently .", "label": "", "metadata": {}, "score": "73.607895"}
{"text": "I do understand your point of view for this proof , meaning proof by induction is one way , but I am still confused on the notation of it all .I thought that this notation might be related to eigenvectors in linear algebra .", "label": "", "metadata": {}, "score": "73.9016"}
{"text": "PROOF OF THEOREM 1 We first state three basic lemmas .Lemma 5 : If any early independent then for any sparsity pattern that the difference of projection matrices has pairs of nonzero positive and negative eigenvalues , bounded above by one and bounded below by neg- ative one , respectively , and equal in magnitude .", "label": "", "metadata": {}, "score": "73.95822"}
{"text": "International Journal of Computer Processing of Oriental Languages Vol . a - star .edu.sg This paper presents an approach to build a novel two - level collocation net , which enables calculation of the collocation relationship between any two words , from a large raw corpus .", "label": "", "metadata": {}, "score": "74.03238"}
{"text": "Page 9 .For example , parse tree re - ranking can be performed by considering the EPMI of the included collocation candidates in parse trees .Collocation relationship between any two words Given any two words wi and wj , the EPMI and EAMI between them are defined as the EPMI and EAMI of the optimal collocation candidate related to the two words .", "label": "", "metadata": {}, "score": "74.08144"}
{"text": "In our experimentation , only six most frequently occurring collocation relation types are considered .Table 1 shows them with their occurrence frequencies in the Reuters corpus .Table 1 .Six most frequently occurring collocation relation types ( in predicate + argument/ adjunct or head noun + modifier format ) .", "label": "", "metadata": {}, "score": "74.16521"}
{"text": "A two stage model of diagnostic evaluation is presented consisting of logical and empirical evaluation steps .Logical evaluation is carried out according to ... \" .This report is concerned with a new method of evaluation for the Linguistic Word Recognition component of the Verbmobil - Project : Architektur .", "label": "", "metadata": {}, "score": "74.17484"}
{"text": "Moreover a human brain can trivially extract high - level information from the scenes and use it to draw useful conclusions ( e.g. if a person got into a car , and the car drove away into the distance , probably you would n't see the person walking again ) .", "label": "", "metadata": {}, "score": "75.1102"}
{"text": "Moreover a human brain can trivially extract high - level information from the scenes and use it to draw useful conclusions ( e.g. if a person got into a car , and the car drove away into the distance , probably you would n't see the person walking again ) .", "label": "", "metadata": {}, "score": "75.1102"}
{"text": "Experimentation shows that the collocation net is efficient and effective in solving the data sparseness problem and determining the collocation relationship between any two words .Keywords : Collocation net ; Data sparseness problem ; Clustering .Introduction In any natural language , there always exist many highly associated relationships between words .", "label": "", "metadata": {}, "score": "75.16291"}
{"text": "abilityoftheeventthatthedeclaredsparsitypattern from thetrue sparsity pattern the entries of the measurement matrix standard normal distribution .It is clear that by letting obtain an upper bound on the error probability of exact sparsity pattern recovery . instead of the true one andthetrueparameter differs in no more than indices , when are drawn i.i.d . from a we Theorem 2 : Suppose that for the observational model of ( 4 ) and the estimate in ( 2 ) the entries of .", "label": "", "metadata": {}, "score": "75.34439"}
{"text": "Estimate the probability using normal approximation to the binomial distribution .Estimate the probability using a chi - squared test .This result will be the same as the result for the normal approximation .Using the binomial distribution , the probability of a result as extreme 1 heads in 10 trials is the sum of the probabilities of 0 heads , 1 head , 9 heads , or 10 heads .", "label": "", "metadata": {}, "score": "75.45538"}
{"text": "Page 13 .Building a Collocation Net 13 1stReading Section 24 as development data and Section 23 as testing data ) while 20-best parse trees for each sentence are considered in re - ranking .This is done by building a collocation net on the golden parse trees in the training data and adjusting the probability of each parse tree candidate using the collocation net to achieve full parsing re - ranking , same as Equation ( 13 ) applied in Section 4 .", "label": "", "metadata": {}, "score": "75.46562"}
{"text": "( QS311 will be replace by QS211 Statistics I : Statistics and Probability in the Fall 1998 term . )Prerequisite - QS101 or equivalent 3 Credits", "label": "", "metadata": {}, "score": "76.36853"}
{"text": "Table 2 gives some of the examples .It shows that our method can not only extract the collocations that occur frequently in the corpus but also extract the collocations that seldom occur in the corpus .Another advantage is that our method can determine the collocation relationship between any two words and measure its strength degree .", "label": "", "metadata": {}, "score": "76.59423"}
{"text": "With this metric , we present an efficient algorithm to solve the problem .s the work on the edit distance between strings [ 6 , 11 , 13 , 16 , 20 , 21 , 25 ] and trees [ 19 , 28 , 29].", "label": "", "metadata": {}, "score": "77.244675"}
{"text": "For convenience , each word and feature bigram in the first level is also regarded as a class ( atomic class ) .That is to say , each first level atomic class contains only one bigram while each second level class contains one or more word and feature bigrams clustered from first level atomic classes .", "label": "", "metadata": {}, "score": "77.41362"}
{"text": "Let the positive eigenvalues be denoted by , then with eigenvalue with eigenvalue .Since , the eigenvalues are bounded by one , again by Lemma 5 , is lower bounded by ; consequently .Page 6 . and the top is bounded above by IV .", "label": "", "metadata": {}, "score": "77.50481"}
{"text": "415 - 493 .ISBN 0 - 471 - 58495 - 9 .^ Mood , Alexander ; Graybill , Franklin A. ; Boes , Duane C. ( 1974 ) .Introduction to the Theory of Statistics ( Third ed . )", "label": "", "metadata": {}, "score": "77.8485"}
{"text": "In most current studies on passage - level postprocessing , linguistic context is the major resource to be exploited .This thesis addresses problems in degraded text recognition and discusses potential solutions through passage - level postprocessing .The objective is to develop a postprocessin ... . by Hans Weber - Proceedings of Twente Workshop on Speech and Language Engineering , 1994 . \" ...", "label": "", "metadata": {}, "score": "78.74008"}
{"text": "Collocations are important for a number of applications : natural language generation , computational lexicography , parsing , proper noun discovery , corpus linguistic research , machine translation , information retrieval , etc .As an example , [ 7 ] showed how syntactic related collocation statistics can be used to improve the performance of the parser on sentences such as \" She wanted / placed / put the dress on the rack . \" , where lexical preferences are crucial to resolving the ambiguity of prepositional phrase attachment .", "label": "", "metadata": {}, "score": "78.86622"}
{"text": "The range of space .Therefore , with absolute value less or equal to one ( The eigenvalues of are equal to one only if If is an eigenvector of we have has eigenvalues with is the dimensional nonzeroeigenvalues has . ) with eigenvalue , then Next , we prove that the vector is an eigenvector of presented in the following exploits the definition of the eigen- vector : with eigenvalue .", "label": "", "metadata": {}, "score": "78.91993"}
{"text": "The answer can be traced back to the normal approximation to the binomial distribution .Consider an experiment in which 10 fair coins are tossed , and the number of heads is observed .Suppose that heads is observed 1 times in 10 trials .", "label": "", "metadata": {}, "score": "79.00344"}
{"text": "Proof of Lemma 5 : Before we prove the result , let us intro- duce some notations .( With a slight abuse of notation , for any sparsity pattern , we use It is worthwhile noting that Lemma 4.1 ] , for any and , is defined as the linear , , and , designates the orthog- instead of is empty .", "label": "", "metadata": {}, "score": "79.6064"}
{"text": "This paper will concentrate on \" collocation \" rather than \" co - occurrence \" although there is much overlap between these two terms .There is also considerable overlap between the concept of \" collocation \" and notions like \" term \" , \" technical term \" and \" terminological phrase \" .", "label": "", "metadata": {}, "score": "79.776855"}
{"text": "If you change n to n+1 in the either expression above , what you get is a sum with one additional summand , namely a(n+1 ) .That is what suggests using induction , that the sum of the first n terms can be separated from the ( n+1)st term in this way .", "label": "", "metadata": {}, "score": "80.13951"}
{"text": "Bottom up chart parsing technology has been used in ASR at least since 1983 ( 2 ) ; ( 8) , and suggestions for non - incremental lattice parsing at sentence level have been made by ( 1 ) . \" ...", "label": "", "metadata": {}, "score": "80.17285"}
{"text": "[ 18 ] J. Zhao and C. N. Huang , Aquasi - dependency model for the structural analysis of Chinese BaseNPs , COLING - ACL'1998 , University de Montreal , Canada , 1998 , pp . 1 - 7 . [19 ] G. D. Zhou and K. T. Lua , Word association and MI - trigger - based language modeling , COLING - ACL'1998 , University of Montreal , Canada , 1998 , pp .", "label": "", "metadata": {}, "score": "80.59139"}
{"text": "His research interests include information theory , computational neuro- science , and social learning theory .Data provided are for informational purposes only .Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .", "label": "", "metadata": {}, "score": "81.010956"}
{"text": "The traditional case which has been extensively studied in the literature is the one in which Y contains substitution , insertion and deletion ( SID ) errors .In this paper we present the first reported solution to the analytic problem of editing one string X to another , Y using these four edit operations .", "label": "", "metadata": {}, "score": "81.19895"}
{"text": "ADJ_ADJ(eligible ) can be measured as a collocation with EAMI of 1.01517e-05 and EPMI of 1.174579 although this collocation candidate does not exist in the corpus .The main reason is that the collocation net provides a word - clustering mechanism to resolve the problem of data sparseness .", "label": "", "metadata": {}, "score": "81.847565"}
{"text": "Therefore , word segmentation and unknown word identification techniques must be used in order to identify words in Chinese .In addition , Chinese has very few inflectional or grammatical markers , making purely syntactic approaches to parsing almost impossible .Hence , a unified approach which involves both syntactic and semantic information must be used .", "label": "", "metadata": {}, "score": "82.16818"}
{"text": "1 Introduction This report is concerned with a new approach to evaluation which has been developed in connection with Linguistic Word Recognition in the Verbmobil Project 15.6 Interactive Phonological Interpretation .In the sections below , it is demonstrated how current evaluation procedures ... .", "label": "", "metadata": {}, "score": "82.30672"}
{"text": "Substituting the bounds obtained in Lemma 7 in ( 8) , we have ( 9 ) Finally , to prove Theorem 1 , we take the infimum of overwhich is equal to and obtain the desired bound as shown in the equation at the bottom of the page .", "label": "", "metadata": {}, "score": "82.73139"}
{"text": "Page 15 .Building a Collocation Net 15 1stReading ( EPMI ) as the strength degree .Obviously , the two - level collocation net can be easily extended to more levels through cascading such a two - level structure .", "label": "", "metadata": {}, "score": "83.080475"}
{"text": "85Different extensions of the basic Damerau - Levenshtein metric are reported in the literature .Lowrance and Wagner [ 59 ] extend the metric to allow reversals of characters .Veronis [ 96 ] suggests a modification to co .. \" ...", "label": "", "metadata": {}, "score": "83.59134"}
{"text": "A critical feature of any computer system is its interface with the user .This has led to the development of user interface technologies such as mouse , touchscreen and penbased input devices .Since handwriting is one of the most familiar communication media , pen - based interfaces combined with automatic handwriting recognition offers a very easy and natural input method .", "label": "", "metadata": {}, "score": "83.71406"}
{"text": "I guess what I am saying is that I see how the induction process could be one way to solve this problem , but I am not sure I follow your proof of it .Is there a way that you could help me understand this a little better ?", "label": "", "metadata": {}, "score": "85.32509"}
{"text": "( This is the result of adding up a column of 1 row of numbers containing a(1 ) . )If there are no terms , no adding takes place , and you just have 0 .( This is the result of adding up a column with 0 rows of numbers . )", "label": "", "metadata": {}, "score": "85.95371"}
{"text": "241 - 246 .ISBN 0 - 07 - 042864 - 6 .^ Westfall , Peter H. ( 2013 ) .Understanding Advanced Statistical Methods .Boca Raton , FL : CRC Press .ISBN 978 - 1 - 4665 - 1210 - 8 .", "label": "", "metadata": {}, "score": "86.164215"}
{"text": "We will study more possibilities in the near future .indd 611/29/2007 2:52:46 PM .Page 7 .Building a Collocation Net 7 1stReading 3.1 .EAMI : Estimated Average Mutual Information Traditionally in information theory , average mutual information ( AMI ) measures the co - occurrence relationship between two words as follows : .", "label": "", "metadata": {}, "score": "86.368034"}
{"text": "Lemma7introducesanupperboundfor a lower bound for simplify the upper bound of in the proof of Lemma 7 is the eigenvalue properties of and that can be used to further .The main ingredient ( 8) .Page 5 .4676 IEEE TRANSACTIONS ON INFORMATION THEORY , VOL .", "label": "", "metadata": {}, "score": "86.48764"}
{"text": "The chi - squared test is performed as follows .The observed number of heads is 1 , and the observed number of tails is 9 .The chi - squared statistic ( with Yates 's correction for continuity ) is .", "label": "", "metadata": {}, "score": "88.008675"}
{"text": "I would like to know why you chose mathematical induction and how induction fits with the notation that is given in the stated problem .Once again , I appreciate all your help with this .Any light that you could shed on this issue would be most appreciated .", "label": "", "metadata": {}, "score": "89.191124"}
{"text": "For example , Chinese sentences are composed of strings of characters without word boundaries that are marked by spac ... \" .The Chinese language has many special characteristics which are substantially different from western languages , causing conventional methods of language processing to fail on Chinese .", "label": "", "metadata": {}, "score": "89.94592"}
{"text": "We will discuss this in more detail in Section 3 .Moreover , we also extend the EPMI and EAMI to determine and measure the collocation relationship between any two words .In this way , we can not only determine the most possible collocation relationship between any two words but also measure the strength of the collocation relationship between them .", "label": "", "metadata": {}, "score": "90.26514"}
{"text": "This work was pre- sented at the 43rd Annual Conference on Information Sciences and Systems , March 2009 .The author is with the Department of Statistics , Columbia University , New York , NY 10027 USA ( e - mail : kamiar@stat.columbia.edu ) .", "label": "", "metadata": {}, "score": "90.391495"}
{"text": "25 24 We did not try that yet .25 Their method is a bit cryptical , but the only reference we found in the literature .9 In our incremental architecture ... .by Keh - jiann Chen - International Journal of Computational Linguistics & amp ; Chinese Language Processing , 1996 . \" ...", "label": "", "metadata": {}, "score": "91.40059"}
{"text": "Then I combined that binomial coefficient with the one that was the last term of the sum .This was easy to do by the rule for Pascal 's triangle , which states that every number in the triangle is the sum of the two above it .", "label": "", "metadata": {}, "score": "92.0973"}
{"text": "Date : 10/20/2000 at 14:01:23 From : Doctor Rob Subject : Re : Number theory - Summation Notation Thanks for writing back .Is it the summation notation or the binomial coefficient notation that you find confusing ?Good !That means I have shown you something new , and you have a chance to learn from the experience .", "label": "", "metadata": {}, "score": "92.89638"}
{"text": "Thanks .Date : 10/16/2000 at 13:42:29 From : Doctor Rob Subject : Re : Number theory - Summation Notation I 'm not sure what method of proof you are supposed to use here , but a proof by mathematical induction on n is not very hard .", "label": "", "metadata": {}, "score": "97.6335"}
{"text": "Although \" strong \" and \" powerful \" have similar syntax and semantics , there exist contexts where one is much more appropriate than the other [ 6].aPart of the work was done when the author was at the Institute for Infocomm Research , Singapore . indd 1 11/29/2007 2:52:45 PM .", "label": "", "metadata": {}, "score": "98.65442"}
{"text": "Reading For example , we always say \" strong tea \" instead of \" strong computer \" and \" powerful computer \" instead of \" powerful tea \" .Psychological experiments [ 11 ] also indicated that human 's reaction to a highly associated word pair was stronger and faster than that to a poorly associated one .", "label": "", "metadata": {}, "score": "101.97755"}
{"text": "Date : 10/16/2000 at 11:31:44 From : Bill Lee Subject : Number theory - Summation Notation I am in the process of studying number theory , and I was poring over a problem regarding summation and multiplicative notation .The problem that I was given and can not seem to grasp is this , and I will say I truly do not know where to begin .", "label": "", "metadata": {}, "score": "103.28877"}
{"text": "31 , pp .76 - 88 , 1991 .Cambridge , U.K. : Kamiar Rahnama Rad was born in Darmstadt , Germany .He received the B.Sc . degree in electrical engineering from Sharif University of Technology , Tehran , in 2004 and the M.Sc . degree in electrical engineering from University of California , Los Angeles , in 2006 .", "label": "", "metadata": {}, "score": "106.42842"}
{"text": "Here , Chm can be either C1i itself or any class in L2 while Cgn can be either C1j itself or any class in L2 .That is , C1i / C1j can be either mapped to itself when the word and feature bigram occurs frequently or mapped to any class in L2 when the word and feature bigram does not occur frequently .", "label": "", "metadata": {}, "score": "106.733765"}
{"text": "Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .Publisher conditions are provided by RoMEO .Differing provisions from the publisher 's actual policy or licence agreement may be applicable .", "label": "", "metadata": {}, "score": "109.35786"}
