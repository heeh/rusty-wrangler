{"text": "Within the learning framework of maximum weighted likelihood ( MWL ) proposed by Cheung , 2004 and 2005 , this paper will develop a batch Rival Penalized Expectation - Maximization ( RPEM ) algorithm for density mixture clustering provided that all observations are available before the learning process .", "label": "", "metadata": {}, "score": "30.006968"}
{"text": "We treat the text summarization problem as maximizing a submodular function under a budget constraint .We show , both theoretically and empirically , a modified greedy algorithm can efficiently solve the budgeted submodular maximization problem near - optimally , and we derive new approximation bounds in ... \" .", "label": "", "metadata": {}, "score": "31.500566"}
{"text": "In this work we study the theoretical and empirical properties of various global inference algorithms for multi - document summarization .We start by defining a general framework and proving that inference in it is NP - hard .We then present three algorithms : The first is a greedy approximate method , the second a dynamic programming approach based on solutions to the knapsack problem , and the third is an exact algorithm that uses an Integer Linear Programming formulation of the problem .", "label": "", "metadata": {}, "score": "32.14855"}
{"text": "In this work we study the theoretical and empirical properties of various global inference algorithms for multi - document summarization .We start by defining a general framework and proving that inference in it is NP - hard .We then present three algorithms : The first is a greedy approximate method , the second a dynamic programming approach based on solutions to the knapsack problem , and the third is an exact algorithm that uses an Integer Linear Programming formulation of the problem .", "label": "", "metadata": {}, "score": "32.14855"}
{"text": "The proposed algorithm consists of following steps .( 1 )The informative score of the sentences are estimated using feature vectors .( 2 )Then , similarity between the sentences is estimated using cosine similarity .( 3 )The optimal combination of sentences for subgraph extraction is found , which balances both informative scores and readability using genetic algorithm .", "label": "", "metadata": {}, "score": "32.931953"}
{"text": "We find that our cluster - document graphs give rise to much better retrieval performance than previously proposed document - only graphs do .For example , authority - based re - ranking of documents via a HITS - style cluster - based approach outperforms a previously - proposed PageRank - inspired algorithm applied to solely - document graphs .", "label": "", "metadata": {}, "score": "33.32484"}
{"text": "Genetic algorithm , an evolutionary algorithm , has the ability of avoiding the local search and can increase the probability of finding the global best .The proposed model formulates the sentence extraction problem , that considers both informative score and cohesion using genetic algorithm .", "label": "", "metadata": {}, "score": "33.336685"}
{"text": "Interested readers may refer to the paper [ 14 ] for more details .We summarize the main steps of the adaptive RPEM in Algorithm 1 .Although the experiments have shown the superior performance of the adaptive RPEM on automatic model selection , its convergence speed , however , relies on the value of learning rate .", "label": "", "metadata": {}, "score": "34.398228"}
{"text": "Various attempts were made to improve cohesion in extractive summarization .Smith et al .[ 25 ] investigated four different ways of creating 100 word summaries , and the results proved that the summary produced by a traditional vector space - based summarizer is not less cohesive than a summary created by taking the most important sentences from the summarizer .", "label": "", "metadata": {}, "score": "34.5176"}
{"text": "The remainder of this paper is organized as follows .Section 2 reviews the MWL learning framework .In Section 3 , we present the batch RPEM algorithm in detail , in which the weights involve a coefficient .via maximizing the WL function of ( 5 ) using a stochastic gradient ascent method , which is able to fade out the redundant densities gradually from a density mixture .", "label": "", "metadata": {}, "score": "34.623753"}
{"text": "In this work we study the theoretical and empirical properties of various global inference algorithms for multi - document summarization .We start by defining a general framework and proving that inference in it is NP - hard .We then present three algorithms : The first is a greedy approximate ... \" .", "label": "", "metadata": {}, "score": "35.10388"}
{"text": "In this work we study the theoretical and empirical properties of various global inference algorithms for multi - document summarization .We start by defining a general framework and proving that inference in it is NP - hard .We then present three algorithms : The first is a greedy approximate ... \" .", "label": "", "metadata": {}, "score": "35.10388"}
{"text": "Results of applying the algorithm to sentence clustering tasks demonstrate that the algorithm is capable of identifying overlapping clusters of semantically related sentences , and that it is therefore of potential use in a variety of text mining tasks .We also include results of applying the algorithm to benchmark data sets in several other domains .", "label": "", "metadata": {}, "score": "35.164993"}
{"text": "The converged positions of the seed points are shown in Figure 4(a ) , where the learned positions converged to the cluster centers while driving the redundant seed points to the boundaries of the clusters .That is , the proposed batch algorithm can work quite well as .", "label": "", "metadata": {}, "score": "36.085445"}
{"text": "However , because most sentence similarity measures do not represent sentences in a common metric space , conventional fuzzy clustering approaches based on prototypes or mixtures of Gaussians are generally not applicable to sentence clustering .This paper presents a novel fuzzy clustering algorithm that operates on relational input data ; i.e. , data in the form of a square matrix of pairwise similarities between data objects .", "label": "", "metadata": {}, "score": "36.472973"}
{"text": "[ 2 ] H. Zha , \" Generic Summarization and Keyphrase Extraction Using Mutual Reinforcement Principle and Sentence Clustering , \" Proc . 25thAnn .Int'l ACM SIGIR Conf .Research and Development in Information Retrieval , pp .113 - 120 , 2002 .", "label": "", "metadata": {}, "score": "36.56656"}
{"text": "We study a number of re - ranking criteria based on measures of centrality in the graphs formed by generation links , and show that integrating centrality into standard language - model - based retrieval is quite effective at improving precision at top ranks . .", "label": "", "metadata": {}, "score": "36.783344"}
{"text": "This main operation is based on the differences of randomly sampled pairs of solutions in the population .The algorithm uses mutation operation as a search mechanism and selection operation to direct the search toward the prospective regions in the search space .", "label": "", "metadata": {}, "score": "36.866417"}
{"text": "Finally , it combines individual feature scores linearly into an overall sentence score to create a ranking , which we use to select sentences for the summary .Hybrid hierarchical summarizer , HybHSum [ 26 ] , is based on a hybrid learning approach to extract sentences for generating summary .", "label": "", "metadata": {}, "score": "37.00119"}
{"text": "[ 1 ] V. Hatzivassiloglou , J.L. Klavans , M.L. Holcombe , R. Barzilay , M. Kan , and K.R. McKeown , \" SIMFINDER :A Flexible Clustering Tool for Summarization , \" Proc .NAACL Workshop Automatic Summarization , pp .", "label": "", "metadata": {}, "score": "37.531036"}
{"text": "Inspired by the PageRank and HITS ( hubs and authorities ) algorithms for Web search , we propose a structural re - ranking approach to ad hoc information retrieval : we reorder the documents in an initially retrieved set by exploiting asymmetric relationships between them .", "label": "", "metadata": {}, "score": "37.576107"}
{"text": "Their algorithm selects the interpretation with the strongest cohesion , and then the strong chains are used to generate a summary of the original .In this direction , we exploit the strength of genetic algorithm for improving the readability through optimal combination of sentences based on lexical cohesion , where the number of sentences depends on the compression ratio .", "label": "", "metadata": {}, "score": "37.889854"}
{"text": "McDonald [ 29 ] formalized text summarization as a knapsack problem and obtained the global solution and its approximate solutions .Wang et al .[ 30 ] proposed a Bayesian sentence - based topic model ( BSTM ) for multidocument summarization by making use of both the word - document and word - sentence associations .", "label": "", "metadata": {}, "score": "37.91472"}
{"text": "Tao et al .[ 31 ] have designed word - based and sentence - based association networks and proposed word and sentence weighting approaches based on how much cooccurrence information they contain and applied to text summarization .In [ 32 ] , text summarization formalized as a budgeted median problem .", "label": "", "metadata": {}, "score": "37.98814"}
{"text": "If such a neighbor does not exist , another end neighbor will be considered for value selection which is given in Algorithm 3 .This reduces the probability of big changes in summary fitness , because sentences which are next to each other in chronological order of the text may talk highly about the same idea [ 24 ] .", "label": "", "metadata": {}, "score": "39.315056"}
{"text": "Many natural language processing tasks can benefit from such diversity ranking .Our algorithm is based on random walks in an absorbing Markov chain .We turn ranked items into absorbing states , which effectively prevents redundant items from receiving a high rank .", "label": "", "metadata": {}, "score": "39.43197"}
{"text": "Many natural language processing tasks can benefit from such diversity ranking .Our algorithm is based on random walks in an absorbing Markov chain .We turn ranked items into absorbing states , which effectively prevents redundant items from receiving a high rank .", "label": "", "metadata": {}, "score": "39.43197"}
{"text": "We carry out our analysis using datasets from the Document Understanding Conferences , studying not only the impact of these features on automatic summarizers , but also their role in human summarization .Our research shows that a frequency based summarizer can achieve performance comparable to that of state - of - the - art systems , but only with a good composition function ; context sensitivity improves performance and significantly reduces repetition . .", "label": "", "metadata": {}, "score": "39.49494"}
{"text": "We carry out our analysis using datasets from the Document Understanding Conferences , studying not only the impact of these features on automatic summarizers , but also their role in human summarization .Our research shows that a frequency based summarizer can achieve performance comparable to that of state - of - the - art systems , but only with a good composition function ; context sensitivity improves performance and significantly reduces repetition . .", "label": "", "metadata": {}, "score": "39.49494"}
{"text": "When population initialization , mutation , crossover , and binarization have been implemented , the new generated solution may not satisfy the constraint ( 12 ) .The most popular constraint handling strategy at present is penalty method , which often uses function to convert a constrained problem into an unconstraint one [ 43 ] .", "label": "", "metadata": {}, "score": "39.636307"}
{"text": "The proposed method can be used in a variety of applications that involve text knowledge representation and discovery .Experiments on two sets of selected sentence pairs demonstrate that the proposed method provides a similarity measure that shows a significant correlation to human intuition . .", "label": "", "metadata": {}, "score": "39.784325"}
{"text": "An advantage of this method is that it can incorporate asymmetric relations between sentences in a natural manner .Huang et al .[ 33 ] consider document summarization as a multiobjective optimization problem .In particular , they formulate four objective functions , namely , content coverage , relevancy , redundancy , and text coherence .", "label": "", "metadata": {}, "score": "39.853092"}
{"text": "Extractive multidocument summarization is modeled as a modified p -median problem .The problem is formulated with taking into account four basic requirements , namely , relevance , information coverage , diversity , and length limit that should satisfy summaries .To solve the optimization problem a self - adaptive differential evolution algorithm is created .", "label": "", "metadata": {}, "score": "39.917038"}
{"text": "In this paper we describe a framework in which summary evaluation measures can be instantiated and compared , and we implement a specific evaluation method using very small units of content , called Basic Elements , that address some of the shortcomings of ngrams .", "label": "", "metadata": {}, "score": "39.98076"}
{"text": "In this paper we describe a framework in which summary evaluation measures can be instantiated and compared , and we implement a specific evaluation method using very small units of content , called Basic Elements , that address some of the shortcomings of ngrams .", "label": "", "metadata": {}, "score": "39.98076"}
{"text": "We propose a novel ranking algorithm , DivRank , based on a reinforced random walk in an information network .This model automatically balances the prestige and the diversity of the top ranked vertices in a principled way .DivRank not only has a clear optimization explanation , but also well connects to classical models in mathematics and network science .", "label": "", "metadata": {}, "score": "40.081795"}
{"text": "Actually , the batch RPEM has drove out the redundant seed points far away and maintained some principal components correctly , which therefore leads to a better performance in color image segmentation .Conclusion .In this paper , we have developed a batch RPEM algorithm based on MWL learning framework for Gaussian mixture clustering .", "label": "", "metadata": {}, "score": "40.10235"}
{"text": "We represent generic text summarization as a modified p -median problem .One of the advantages of this approach is that it directly discovers key sentences in the given collection and covers the main content of the original source(s ) .Another advantage of our model is that it can reduce redundancy in the summary .", "label": "", "metadata": {}, "score": "40.165054"}
{"text": "One of them involves replacement of the SaDE algorithm in pSum - SaDE with a better global search method , such as particle swarm optimization .Another direction of future research is related to the different combination of the three terms , namely , relevancy , coverage , and redundancy terms in objective function ( .", "label": "", "metadata": {}, "score": "40.3491"}
{"text": "To extract the summary sentences , Fatma et al .[ 22 ] and Liu et al .[ 23 ] used GAs , to find sets of sentences that maximize summary quality metrics , starting from a random selection of sentences as the initial population .", "label": "", "metadata": {}, "score": "40.475567"}
{"text": "In general , it is a nontrivial task to assign an appropriate value to the learning rate , although we can pay extra efforts to make the learning rate dynamically change over time , for example , see [ 15 ] .", "label": "", "metadata": {}, "score": "40.51208"}
{"text": "As a result , it can learn faster in general and still preserve the capability of automatic model selection analogous to the adaptive one .We have evaluated the proposed batch RPEM algorithm on both synthetic data and color image segmentation .", "label": "", "metadata": {}, "score": "40.665047"}
{"text": "Ouyang et al .[21 ] apply a machine learning approach to topic - based summarization by regarding sentence scoring as a regression problem .The regression function is learned from the Support Vector Regression ( SVR ) model , which is the regression type of Support Vector Machine ( SVM ) and is capable of building state - of - art optimum approximation functions .", "label": "", "metadata": {}, "score": "41.144943"}
{"text": "The usual approach for automatic summarization is sentence extraction , where key sentences from the input documents are selected based on a suite of features .While word frequency often is used as a feature in summarization , its impact on system performance has not been isolated .", "label": "", "metadata": {}, "score": "41.274208"}
{"text": "The usual approach for automatic summarization is sentence extraction , where key sentences from the input documents are selected based on a suite of features .While word frequency often is used as a feature in summarization , its impact on system performance has not been isolated .", "label": "", "metadata": {}, "score": "41.274208"}
{"text": "The usual approach for automatic summarization is sentence extraction , where key sentences from the input documents are selected based on a suite of features .While word frequency often is used as a feature in summarization , its impact on system performance has not been isolated .", "label": "", "metadata": {}, "score": "41.274208"}
{"text": "The usual approach for automatic summarization is sentence extraction , where key sentences from the input documents are selected based on a suite of features .While word frequency often is used as a feature in summarization , its impact on system performance has not been isolated .", "label": "", "metadata": {}, "score": "41.274208"}
{"text": "We present an approach to improving the precision of an initial document ranking wherein we utilize cluster information within a graph - based framework .The main idea is to perform re - ranking based on centrality within bipartite graphs of documents ( on one side ) and clusters ( on the other side ) , on the premise that these are mutually reinforcing entities .", "label": "", "metadata": {}, "score": "41.314888"}
{"text": "The unsupervised methods usually utilize clustering algorithms to score the sentences in the documents by combining a set of predefined features [ 4 - 6 ] .The summarization task can also be categorized as either generic or query oriented .A query - oriented summary presents the information that is more relevant to the given queries , while a generic summary gives an overall sense of the document 's content [ 7 , 8 ] .", "label": "", "metadata": {}, "score": "41.612648"}
{"text": "In the literature , one promising way is to develop a clustering algorithm that is able to perform a correct clustering without preassigning the exact number of clusters .Such algorithms include the RPCL algorithm [ 11 ] and its improved version , namely , RPCCL [ 12 ] .", "label": "", "metadata": {}, "score": "41.83139"}
{"text": "Furthermore , a simplified version of RPEM has included RPCL and RPCCL as its special cases with some new extensions .In the papers [ 13 , 14 ] , the RPEM algorithm learns the parameters via a stochastic gradient ascending method ; that is , we update the parameters immediately and adaptively once the current observation is available .", "label": "", "metadata": {}, "score": "41.879753"}
{"text": "This paper investigates the automatic evaluation of text coherence for machine - generated texts .We introduce a fully - automatic , linguistically rich model of local coherence that correlates with human judgments .Our modeling approach relies on shallow text properties and is relatively inexpensive .", "label": "", "metadata": {}, "score": "41.955505"}
{"text": "This paper investigates the automatic evaluation of text coherence for machine - generated texts .We introduce a fully - automatic , linguistically rich model of local coherence that correlates with human judgments .Our modeling approach relies on shallow text properties and is relatively inexpensive .", "label": "", "metadata": {}, "score": "41.955505"}
{"text": "This paper investigates the automatic evaluation of text coherence for machine - generated texts .We introduce a fully - automatic , linguistically rich model of local coherence that correlates with human judgments .Our modeling approach relies on shallow text properties and is relatively inexpensive .", "label": "", "metadata": {}, "score": "41.955505"}
{"text": "This paper investigates the automatic evaluation of text coherence for machine - generated texts .We introduce a fully - automatic , linguistically rich model of local coherence that correlates with human judgments .Our modeling approach relies on shallow text properties and is relatively inexpensive .", "label": "", "metadata": {}, "score": "41.955505"}
{"text": "When the input text is large , the number of candidate summary sentences is also large and the feasible combination to form an extractive summary thus grows exponentially .So , the search for optimal solutions under multiple criteria has been proven to be computationally demanding and time consuming .", "label": "", "metadata": {}, "score": "42.053288"}
{"text": "The ranking score is obtained for each sentence in the manifold - ranking process to denote the biased information richness of the sentence .Then the greedy algorithm is employed to impose diversity penalty on each sentence .The summary is produced by choosing the sentences with both high biased information richness and high information novelty .", "label": "", "metadata": {}, "score": "42.208076"}
{"text": "The ranking score is obtained for each sentence in the manifold - ranking process to denote the biased information richness of the sentence .Then the greedy algorithm is employed to impose diversity penalty on each sentence .The summary is produced by choosing the sentences with both high biased information richness and high information novelty .", "label": "", "metadata": {}, "score": "42.208076"}
{"text": "Nevertheless , the convergence speed of the RPEM relies on the value of learning rate .Often , by a rule of thumb , we arbitrarily set the learning rate at a small positive constant .If the value of learning rate is assigned too small , the algorithm will converge at a very slow speed .", "label": "", "metadata": {}, "score": "42.56835"}
{"text": "In particular , clustering analysis provides a useful tool to solve the several computer vision problems , for example , multithresholding of gray level images , analysis of the Hough space , and range image segmentation , formulated in the feature space paradigm [ 8 ] .", "label": "", "metadata": {}, "score": "42.597008"}
{"text": "They study two strategies for simultaneously modeling document contents and the query information and present four methods to score sentences in the documents based on the learned topic models .HierSum [ 23 ] is a generative summarization method based on topic models , which uses sentences as an additional level .", "label": "", "metadata": {}, "score": "42.620354"}
{"text": "Text summarization based on machine learning has got tremendous improvement over wide areas of applications .Machine learning algorithms can be applied in almost all the phases of text summarization such as feature selection , finding the optimal weight for each feature , and sentence extraction .", "label": "", "metadata": {}, "score": "42.6448"}
{"text": "[40 ] A.P. Dempster , N.M. Laird , and D.B. Rubin , \" Maximum Likelihood from Incomplete Data via the EM Algorithm , \" J. the Royal Statistical Soc .Series B ( Methodological ) , vol .39 , no . 1 , pp . 1 - 38 , 1977 .", "label": "", "metadata": {}, "score": "42.911076"}
{"text": "791 - 802 , 1991 .View at Publisher \u00b7 View at Google Scholar . A.Dempster , N. Laird , and D. Rubin , \" Maximum likelihood from incomplete data via the EM algorithm , \" Journal of the Royal Statistical Society B , vol .", "label": "", "metadata": {}, "score": "43.127213"}
{"text": "However , it still may converge toward local optimum solutions , need to manually adjust the parameters , and finding the best values for the control parameters is a consuming task .In the paper is proposed a self - adaptive scaling factor in original DE to increase the exploration and exploitation ability .", "label": "", "metadata": {}, "score": "43.246376"}
{"text": "We present a method for measuring the semantic similarity of texts using a corpus - based measure of semantic word similarity and a normalized and modified version of the Longest Common Subsequence ( LCS ) string matching algorithm .Existing methods for computing text similarity have focused mainly on either large documents or individual words .", "label": "", "metadata": {}, "score": "43.2491"}
{"text": "We present a method for measuring the semantic similarity of texts using a corpus - based measure of semantic word similarity and a normalized and modified version of the Longest Common Subsequence ( LCS ) string matching algorithm .Existing methods for computing text similarity have focused mainly on either large documents or individual words .", "label": "", "metadata": {}, "score": "43.2491"}
{"text": "( iii )To solve the modified p -median problem a self - adaptive differential evolution algorithm is created .In particular , in the paper is proposed a self - adaptive scaling factor in original DE to increase the exploration and exploitation ability .", "label": "", "metadata": {}, "score": "43.784416"}
{"text": "Clustering algorithms , Prototypes , Convergence , Extraterrestrial measurements , Data models , Partitioning algorithms , graph centrality , Fuzzy relational clustering , natural language processing .CITATION .Andrew Skabar , Khaled Abdalgader , \" Clustering Sentence - Level Text Using a Novel Fuzzy Relational Clustering Algorithm \" , IEEE Transactions on Knowledge & Data Engineering , vol.25 , no . 1 , pp .", "label": "", "metadata": {}, "score": "43.8603"}
{"text": "be the set of sentences constituting a summary , then the similarity between the set of sentences and the summary is going to be .s .i . m . , which we would like to maximize .As already mentioned above , the offered model is based on the p -median problem .", "label": "", "metadata": {}, "score": "43.88851"}
{"text": "This work firstly clusters the sentences and uses the obtained sentence clusters to generate a summary .The paper [ 16 ] proposes a query - based multidocument summarization method , using NNM semantic features and the clustering method .The works [ 17 - 19 ] use the NGD - based sentence similarity measure to cluster sentences , so that related sentences can be joined together in a briefer representation of the original text .", "label": "", "metadata": {}, "score": "43.922653"}
{"text": "The information overload can be reduced by text summarization together with conventional search engines to efficiently access the relevance of retrieved documents .Automatic document summarization aims to condense the original text into its essential content and to assist in filtering and selection of necessary information [ 1 ] .", "label": "", "metadata": {}, "score": "44.07701"}
{"text": "Graph - ranking algorithms , e.g. , PageRank ( Brin and Pa .. \" ...Information networks are widely used to characterize the relationships between data items such as text documents .Many important retrieval and mining tasks rely on ranking the data items based on their centrality or prestige in the network .", "label": "", "metadata": {}, "score": "44.29858"}
{"text": "Subsequently , the task of clustering analysis is to identify the dense regions of the input ( also called observation interchangeably ) densities in a mixture .Such a clustering is therefore called a density mixture clustering .In general , the Expectation - Maximum ( EM ) algorithm [ 9 , 10 ] has provided a general solution for the parameter estimation of a density mixture model .", "label": "", "metadata": {}, "score": "44.410656"}
{"text": "This is strong evidence against the null hypothesis , indicating that the better median values of the performance metrics produced by pSum - SaDE are statistically significant and have not occurred by chance .Similar results are obtained for all other data sets and for all other methods compared to pSum - SaDE method , establishing the significant superiority of the proposed technique .", "label": "", "metadata": {}, "score": "44.71923"}
{"text": "View at Google Scholar .L. Xu , A. Krzyzak , and E. Oja , \" Rival penalized competive learning for clustering analysis , RBF Net , and curve detection , \" IEEE Transactions on Neural Networks , vol .4 , no .", "label": "", "metadata": {}, "score": "44.978462"}
{"text": "As a result , the batch RPEM converges much faster than the EM .Moreover , we also compared it with the adaptive RPEM , in which we set the learning rate .Figure 5(c ) shows the convergent results of the seed points .", "label": "", "metadata": {}, "score": "45.04899"}
{"text": "The question becomes what level of granularity is appropriate for automatic summary content comparison .It uses ngrams of various lengths , a total of 17 different par ... . \" ...Topic - focused multi - document summarization aims to produce a summary biased to a given topic or user profile .", "label": "", "metadata": {}, "score": "45.099277"}
{"text": "The question becomes what level of granularity is appropriate for automatic summary content comparison .It uses ngrams of various lengths , a total of 17 different par ... . \" ...Topic - focused multi - document summarization aims to produce a summary biased to a given topic or user profile .", "label": "", "metadata": {}, "score": "45.099277"}
{"text": "Furthermore , introducing the same scaling factor for all individuals , by ignoring the differences among individuals ' performances , is not a precise model .In fact , during the search every individual dynamically changes its position , so every individual locates in a complex environment and faces a different situation .", "label": "", "metadata": {}, "score": "45.154434"}
{"text": "We introduce a graph - based WSD algorithm which has few parameters and does not require sense annotated data for training .Using this algorithm , we investigate several measures of graph connectivity with the aim of identifying those best suited for WSD .", "label": "", "metadata": {}, "score": "45.325768"}
{"text": "As a null hypothesis , it is assumed that there are no significant differences between the median values of two groups , whereas the alternative hypothesis is that there is significant difference in the median values of the two groups .It is clear from the table that .", "label": "", "metadata": {}, "score": "45.45852"}
{"text": "It depends on the extraction of the most important sentences from the original text .Most features ( i.e. , sentence centrality ; title feature ; word sentence score ; keyword feature ; similarity to first sentence ) used in this method are combined in a linear combination to show the importance of the sentence .", "label": "", "metadata": {}, "score": "45.604317"}
{"text": "12 , pp .1197 - 1206 , 1994 .View at Publisher \u00b7 View at Google Scholar .J. M. Jolion , P. Meer , and S. Bataouche , \" Robust clustering with applications in computer vision , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .", "label": "", "metadata": {}, "score": "45.623222"}
{"text": "In this paper , we proposed a genetic algorithm - based text summarization that considers informative score , readability score , and sentence similarity for summary extraction .The performance of GA - based summarization is better in .-measure , readability score and cohesion when compared to corpus - based approach and baseline method ( lead ) .", "label": "", "metadata": {}, "score": "45.76313"}
{"text": "This paper focuses directly on computing the similarity between very short texts of sentence length .It presents an algorithm that takes account of semantic information and word order information implied in the sentences .The semantic similarity of two sentences is calculated using information from a structured lexical database and from corpus statistics .", "label": "", "metadata": {}, "score": "45.833435"}
{"text": "Further , the convergence speed of this batch RPEM is faster than the EM and the adaptive RPEM in general .The experiments show the superior performance of the proposed algorithm on the synthetic data and color image segmentation .Introduction .", "label": "", "metadata": {}, "score": "45.84513"}
{"text": "Actually , the adaptive RPEM can be further speed up if an appropriate learning rate is adopted , which , however , is not a trivial task .15 seed points were initialized in the input space arbitrarily .During the learning , the three density components were discarded because their corresponding covariances became singular .", "label": "", "metadata": {}, "score": "46.050377"}
{"text": "Since , in our formulation , it is supposed that the summary will be formed of medians then at choosing of sentences as a median , it is necessary to meet a condition that similarity between them was minimum .This requirement will be provided by the third term .", "label": "", "metadata": {}, "score": "46.059853"}
{"text": "The objective of this work is to maximize the average similarity between the sentences having higher informative score .The objective function is as follows : .Here , the constraint ensures only forward traversal in the graph and ensures that the summary has a cohesive nonredundant candidate sentences .", "label": "", "metadata": {}, "score": "46.154053"}
{"text": "The RPEM learns the density parameters by making mixture component compete each other at each time step .Not only are the associated parameters of the winning density component updated to adapt to an input , but also all rivals ' parameters are penalized with the strength proportional to the corresponding posterior density probabilities .", "label": "", "metadata": {}, "score": "46.255054"}
{"text": "633 - 636 , Cambridge , UK , 2004 . Y. M. Cheung , \" Maximum weighted likelihood via rival penalized EM for density mixture clustering with automatic model selection , \" IEEE Transactions on Knowledge and Data Engineering , vol .", "label": "", "metadata": {}, "score": "46.452003"}
{"text": "Select the individuals with current best and worst solution .Step 4 ( generate trial vector ) .Generate trial vector of the target vector using the mutation ( 17 ) - ( 20 ) and crossover ( 21 ) operators .", "label": "", "metadata": {}, "score": "46.559616"}
{"text": "The pioneer work for diversity - based document summarization is MMR ( Maximal Marginal Relevance ) ; it was introduced by Carbonell and Goldstein [ 11 ] .The method MMR summarizes document by calculating the cosine similarity between a given query and a document and the cosine similarity between the currently selective sentence and the previously selected sentence .", "label": "", "metadata": {}, "score": "46.591583"}
{"text": "Silber and McCoy [ 28 ] discussed that the lexical chains represent the lexical cohesion among the arbitrary number of related words .By using lexical chains , they can find statistically the most important concepts by looking at the structure in the document rather than the deep semantic meaning .", "label": "", "metadata": {}, "score": "46.79201"}
{"text": "Morris and Hirst [ 26 ] introduced the concept of lexical chains .Researchers explored various types of cohesion measures , namely , clue words that are based on stems , semantic distance based on WordNet , and cosine similarity that is based on the word TF - idf vector .", "label": "", "metadata": {}, "score": "46.795685"}
{"text": "Clustering has become an increasingly important topic with explosion of information available via the Internet and electronic government services .It is an important tool in text mining and knowledge discovery .Its ability to automatically group similar textual objects together enables one to discover hidden similarity and key concepts , as well as to summarize a large amount of text into a small number of groups [ 14 ] .", "label": "", "metadata": {}, "score": "46.91741"}
{"text": "i . s .e . . .( .Selection .The next step of the algorithm calls for selection to determine whether the target or the trial vector survives to the next generation , that is , at .Then the objective function values of all trial vectors are evaluated .", "label": "", "metadata": {}, "score": "47.40022"}
{"text": "In this section , a self - adaptive DE ( SaDE ) algorithm is created to solve the optimization problem ( .For each parameter of the problem , there may be a certain range within which the value of the parameter should be restricted , often because parameters are related to physical components or measures that have natural bounds .", "label": "", "metadata": {}, "score": "47.43384"}
{"text": "View at Scopus .J. K. Fatma , M. Jaoua , L. H. Belguith , and A. B. Hamadou , \" Experimentation of two compression strategies for multi - document summarization , \" in Proceedings of the International Conference on Computer and Electrical Engineering ( ICCEE ' 09 ) , pp .", "label": "", "metadata": {}, "score": "47.482185"}
{"text": "The objective of this work is to extract the optimal combination of sentences that increase readability through sentence cohesion using genetic algorithm .The results show that the summary extraction using our proposed approach performs better in .-measure , readability , and cohesion than the baseline approach ( lead ) and the corpus - based approach .", "label": "", "metadata": {}, "score": "47.51435"}
{"text": "Whether a particular sentence is selected or not can be decided by \" 0 \" or \" 1 . \" Though it is simple to implement , when the text size grows , it may be time consuming to generate a summary .", "label": "", "metadata": {}, "score": "47.676865"}
{"text": "DivRank outperforms existing network - based ranking methods in terms of enhancing diversity in prestige .In comparison with hard clustering methods , in which a pattern belongs to a single cluster , fuzzy clustering algorithms allow patterns to belong to all clusters with differing degrees of membership .", "label": "", "metadata": {}, "score": "47.699326"}
{"text": "That is , the maximum generation , population size , and searching range of the parameters in DE are the same as those in adaptive DE .In addition , notice that random number generator is initialized with the same seed values .", "label": "", "metadata": {}, "score": "47.72866"}
{"text": "The significance of learner - dependent features in summary extraction is discussed in [ 30 ] .The sentence score is calculated using weights and features vectors .The sentence combination for summary generation is identified using GA based on sentence similarity and sentence score .", "label": "", "metadata": {}, "score": "47.740223"}
{"text": "To save the costly manual annotation time and effort , they construct training data automatically from the document sets where the reference summaries generated by human have been provided .The paper [ 22 ] investigates the problem of multi - topic - based query - oriented summarization .", "label": "", "metadata": {}, "score": "47.742844"}
{"text": "This paper has found that self - adaptive differential evolution can efficiently find the best solution in comparison with the canonical differential evolution .Experimental results on DUC 2006 dataset have shown that our optimization approach compares well to several summarization methods .", "label": "", "metadata": {}, "score": "47.766815"}
{"text": "We show that this method correlates better with human judgments than any other automated procedure to date , and overcomes the subjectivity / variability problems of manual methods that require humans t ... \" .In this paper we introduce Basic Elements , a new way of automating the evaluation of text summaries .", "label": "", "metadata": {}, "score": "47.79139"}
{"text": "We show that this method correlates better with human judgments than any other automated procedure to date , and overcomes the subjectivity / variability problems of manual methods that require humans t ... \" .In this paper we introduce Basic Elements , a new way of automating the evaluation of text summaries .", "label": "", "metadata": {}, "score": "47.79139"}
{"text": "However , this strategy has some drawbacks and the main one is the requirement of multiple runs for the fine - tuning of penalty factors , which would increase the computational time and degrade the efficiency of the algorithm .In order to overcome the drawbacks of penalty method and handle the constraints of problem effectively , the following heuristic procedure is produced for all NP solutions in the population to resolve the constraint ( 12 ) .", "label": "", "metadata": {}, "score": "47.808586"}
{"text": "In this paper we focus on the widely used binomial crossover that is performed on each of the .n . variables whenever a randomly generated number between 0 and 1 is less than or equal to the CR value .In this case , the number of parameters inherited from the mutant vector has a ( nearly ) binomial distribution .", "label": "", "metadata": {}, "score": "47.891853"}
{"text": "For independent - level reading , SMOG works better than the other formulae .It is intended to measure the readability of the material that the teacher has suggested to a student to use independently [ 39 ] .Figure 3 : Comparison of various summarization methods based on cohesion .", "label": "", "metadata": {}, "score": "48.028816"}
{"text": "1281 - 1286 , 1999 .[ 33 ] T. Geweniger , D. Z\u00fchlke , B. Hammer , and T. Villmann , \" Fuzzy Variant of Affinity Propagation in Comparison to Median Fuzzy c - Means , \" Proc .Seventh Int'l Workshop Advances in Self - Organizing Maps , pp .", "label": "", "metadata": {}, "score": "48.1712"}
{"text": "815 - 824 , Uppsala , Sweden , 2010 . E. Filatova and V. Hatzivassiloglou , \" A formal model for information selection in multi - sentence text extraction , \" in Proceedings of the 20th International Conference on Computational Linguistics , pp .", "label": "", "metadata": {}, "score": "48.2196"}
{"text": "815 - 824 , Uppsala , Sweden , 2010 . E. Filatova and V. Hatzivassiloglou , \" A formal model for information selection in multi - sentence text extraction , \" in Proceedings of the 20th International Conference on Computational Linguistics , pp .", "label": "", "metadata": {}, "score": "48.2196"}
{"text": "J. Carbonell and J. Goldstein , \" The use of MMR , diversity - based reranking for reordering documents and producing summaries , \" in Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , pp .", "label": "", "metadata": {}, "score": "48.508514"}
{"text": "Ranking plays an important role in information retrieval and natural language processing applications .An approach , proposed in [ 25 ] , for producing a summary consists of three steps .First , it associates sentences and queries with a representation in the latent topic space of a PLSA model by estimating their mixing proportions .", "label": "", "metadata": {}, "score": "48.76867"}
{"text": "426 - 444 , 2008 .View at Google Scholar .C. Smith , H. Danielsson , and A. J\u00f6nsson , \" Cohesion in automatically created summaries , \" in Proceedings of the 4th Swedish Language Technology Conference , Lund , Sweden , 2012 .", "label": "", "metadata": {}, "score": "48.803886"}
{"text": "Furthermore , it represents an important \" real world \" scenario where summaries are generated in order to be displayed on small screens , such as mobile devices .This global inference problem is typica ... .by Eduard Hovy , Chin - yew Lin , Liang Zhou - Proceedings of DUC-2005 , 2005 . \" ...", "label": "", "metadata": {}, "score": "48.87818"}
{"text": "Furthermore , it represents an important \" real world \" scenario where summaries are generated in order to be displayed on small screens , such as mobile devices .This global inference problem is typica ... .by Eduard Hovy , Chin - yew Lin , Liang Zhou - Proceedings of DUC-2005 , 2005 . \" ...", "label": "", "metadata": {}, "score": "48.87818"}
{"text": "We present a method for measuring the semantic similarity of texts using a corpus - based measure of semantic word similarity and a normalized and modified version of the Longest Common Subsequence ( LCS ) string matching algorithm .Existing methods for computing text similarity have focused mainly on e ... \" .", "label": "", "metadata": {}, "score": "48.90545"}
{"text": "R. Barzilay and M. Elhadad , \" Using lexical chains for text summarization , \" in Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization , vol .17 , pp .10 - 17 , Madrid , Spain , 1997 .", "label": "", "metadata": {}, "score": "49.10478"}
{"text": "The manifold - ranking process can naturally make full use of both the relati ... \" .Topic - focused multi - document summarization aims to produce a summary biased to a given topic or user profile .This paper presents a novel extractive approach based on manifold - ranking of sentences to this summarization task .", "label": "", "metadata": {}, "score": "49.150917"}
{"text": "The manifold - ranking process can naturally make full use of both the relati ... \" .Topic - focused multi - document summarization aims to produce a summary biased to a given topic or user profile .This paper presents a novel extractive approach based on manifold - ranking of sentences to this summarization task .", "label": "", "metadata": {}, "score": "49.150917"}
{"text": "The initial positions of the three seed points and their converged positions learned by ( b ) EM , ( c ) adaptive RPEM , and ( d ) batch RPEM , respectively .Nevertheless , as shown in Figures 6(c ) and 7 , the batch RPEM converges at 20 epochs , while the EM needs 60 epochs as shown in Figure 6(a ) .", "label": "", "metadata": {}, "score": "49.418983"}
{"text": "1140 - 1144 , Springer , 2006 .View at Google Scholar \u00b7 View at Scopus .V. Qazvinian , L. Sharif , and R. Halavati , \" Summarizing text with a genetic algorithm - based sentence extraction , \" IJKMS , vol .", "label": "", "metadata": {}, "score": "49.599392"}
{"text": "We conducted color image segmentation on a .house image as shown in Figures 9(a ) and 10 , respectively .For the former , we initially assigned 10 seed points randomly .After the convergence of the algorithms ' performance , a snapshot of their segmentation results is shown in Figures 9(b ) and 9(c ) .", "label": "", "metadata": {}, "score": "50.102547"}
{"text": "F. Wei , W. Li , and S. Liu , \" iRANK : a rank - learn - combine framework for unsupervised ensemble ranking , \" Journal of the American Society for Information Science and Technology , vol .61 , no .", "label": "", "metadata": {}, "score": "50.206192"}
{"text": "F. Wei , W. Li , and S. Liu , \" iRANK : a rank - learn - combine framework for unsupervised ensemble ranking , \" Journal of the American Society for Information Science and Technology , vol .61 , no .", "label": "", "metadata": {}, "score": "50.206192"}
{"text": "6 , pp .750 - 761 , 2005 .View at Publisher \u00b7 View at Google Scholar . \" ...Inspired by the PageRank and HITS ( hubs and authorities ) algorithms for Web search , we propose a structural re - ranking approach to ad hoc information retrieval : we reorder the documents in an initially retrieved set by exploiting asymmetric relationships between them .", "label": "", "metadata": {}, "score": "50.253044"}
{"text": "P . , is maintained constant throughout the evolution process .This is a heuristic choice .For example , the value of NP can be increased for obtaining the global solution with higher probability .However , the higher the value of NP is , the higher the number of fitness evaluation is .", "label": "", "metadata": {}, "score": "50.413166"}
{"text": "..the most central questions with the highest repeated possibility can be regarded as the most popular ones regarding the topic .The LexRank estimates the centrality(repeated possibility ) of a question in a manner similar to the PageRank [ 2].", "label": "", "metadata": {}, "score": "50.424614"}
{"text": "'s have successfully stabilized at the corresponding cluster centers , meanwhile the other three redundant seed points have been pushed away and stably located at the boundary of the clusters .That is , the redundant densities have been fade out through the learning , thus the batch RPEM can select the model automatically as well as the adaptive version . 's are correctly allocated at the center of the three clusters and the other redundant seed points were driven away to the boundaries of clusters .", "label": "", "metadata": {}, "score": "50.430393"}
{"text": "To illustrate this scenario , we have utilized two synthetic data sets that are generated from the two bivariate three - Gaussian mixtures individually as shown in Figures 1(a ) and 1(b ) , where each data set consists of ., we randomly initialized the eight seed points in the input space as shown in Figure 2(a ) .", "label": "", "metadata": {}, "score": "50.629757"}
{"text": "Past automated methods such as ROUGE compare using fixed word ngrams , which are not ideal for a variety of reasons .In this paper we describe ... \" .As part of evaluating a summary automatically , it is usual to determine how much of the contents of one or more human - produced ' ideal ' summaries it contains .", "label": "", "metadata": {}, "score": "50.67446"}
{"text": "Past automated methods such as ROUGE compare using fixed word ngrams , which are not ideal for a variety of reasons .In this paper we describe ... \" .As part of evaluating a summary automatically , it is usual to determine how much of the contents of one or more human - produced ' ideal ' summaries it contains .", "label": "", "metadata": {}, "score": "50.67446"}
{"text": "R. Storn and K. Price , \" Differential evolution - a simple and efficient heuristic for global optimization over continuous spaces , \" Journal of Global Optimization , vol .11 , no .4 , pp .341 - 359 , 1997 .", "label": "", "metadata": {}, "score": "50.70664"}
{"text": "R. Storn and K. Price , \" Differential evolution - a simple and efficient heuristic for global optimization over continuous spaces , \" Journal of Global Optimization , vol .11 , no .4 , pp .341 - 359 , 1997 .", "label": "", "metadata": {}, "score": "50.70664"}
{"text": "636 - 649 , 1993 .View at Publisher \u00b7 View at Google Scholar . Y. M. Cheung , \" Rival penalized controlled competitive learning for data clustering with unknown cluster number , \" in Proceedings of the 9th International Conference on Neural Information Processing ( ICONIP ' 02 ) , 2002 . Y. M. Cheung , \" A rival penalized EM algorithm towards maximizing weighted likelihood for density mixture clustering with automatic model selection , \" in Proceedings of the 17th International Conference on Pattern Recognition ( ICPR ' 04 ) , vol .", "label": "", "metadata": {}, "score": "51.01348"}
{"text": "We show that significantly better correla ... \" .Recent research has shown that a balanced harmonic mean ( F1 measure ) of unigram precision and recall outperforms the widely used BLEU and NIST metrics for Machine Translation evaluation in terms of correlation with human judgments of translation quality .", "label": "", "metadata": {}, "score": "51.016747"}
{"text": "We show that significantly better correla ... \" .Recent research has shown that a balanced harmonic mean ( F1 measure ) of unigram precision and recall outperforms the widely used BLEU and NIST metrics for Machine Translation evaluation in terms of correlation with human judgments of translation quality .", "label": "", "metadata": {}, "score": "51.016747"}
{"text": "[19 ] designed a new approach to a multilingual single - document extractive summarization using a genetic algorithm which will find an optimal weighted linear combination of 31 statistical sentence scoring methods with all language - independent features .Yeh et al .", "label": "", "metadata": {}, "score": "51.233093"}
{"text": "Int'l ACM SIGIR Conf .Research and Development in Information Retrieval , pp .307 - 314 , 2008 .[ 31 ] R. Krishnapuram , A. Joshi , and Y. Liyu , \" A Fuzzy Relative of the k - Medoids Algorithm with Application to Web Document and Snippet Clustering , \" Proc .", "label": "", "metadata": {}, "score": "51.322754"}
{"text": "[17 ] investigated the effectiveness of genetic algorithm - based attribute selection to improve the performance of classification algorithms by solving automatic text summarization task .Also , Suanmali et al .[ 18 ] proposed an approach called feature fusion technique to discover which features out of the available ones are most useful for extracting summary sentences .", "label": "", "metadata": {}, "score": "51.562363"}
{"text": "49 ] A. Rosenberg and J. Hirschberg , \" V - Measure : A Conditional Entropy - Based External Cluster Evaluation Measure , \" Proc Conf .Empirical Methods in Natural Language Processing ( EMNLP ' 07 ) , pp .410 - 420 , 2007 .", "label": "", "metadata": {}, "score": "51.59031"}
{"text": "The performance of the proposed approach is tested on the DUC2006 dataset and is compared with baseline systems .The effectiveness of the proposed approach is demonstrated .The rest of this paper is organized as follows .Section 2 gives brief review of related work .", "label": "", "metadata": {}, "score": "51.658134"}
{"text": "Regina Barzilay and Noemie Elhadad .Sentence alignment for monolingual comparable corpora .In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing ( EMNLP-03 ) , 2003 .( PostScript )( PDF ) .Sasha Blair - Goldensohn , Kathleen McKeown , and Andrew Schlaikjer .", "label": "", "metadata": {}, "score": "51.68094"}
{"text": "In general , Vafaie and De Jong [ 16 ] suggested that GAs are a useful tool for solving difficult feature selection problems where both the size of the feature set and the performance of the underlying system are important design considerations .", "label": "", "metadata": {}, "score": "51.76224"}
{"text": "Baseline may be cohesive , but it fails in predicting the better summary sentences .GA considers all factors without losing any of them , namely , .Figure 4 : Comparison of various summarization methods based on readability .Task - Based Evaluation .", "label": "", "metadata": {}, "score": "51.775784"}
{"text": "Roughly , the mixture may overfit the data if too many components are utilized , whereas a mixture with too few components may not be flexible enough to approximate the true underlying model .Subsequently , the EM almost always leads to a poor estimate result if the number of components is misspecified .", "label": "", "metadata": {}, "score": "51.790512"}
{"text": "Table 3 shows the comparison results .We see that our proposed method outperforms the three systems .Comparison with Canonical DE Algorithm .This section demonstrates the feasibility of the SaDE - based document summarization .The results are compared to the results obtained from canonical DE .", "label": "", "metadata": {}, "score": "51.855034"}
{"text": "Check the boundary constraints ( 15 ) for the components of the trial vector using ( 22 ) .Step 6 ( binarization ) .Transform real - coded trial vector to binary - coded trial vector using ( 24 ) .", "label": "", "metadata": {}, "score": "51.975143"}
{"text": "That is , the top items should be different from each other in order to have a broad coverage of the whole item set .Many natural language processing tasks can benefit from such diversity ranki ... \" .We introduce a novel ranking algorithm called GRASSHOPPER , which ranks items with an emphasis on diversity .", "label": "", "metadata": {}, "score": "52.069042"}
{"text": "That is , the top items should be different from each other in order to have a broad coverage of the whole item set .Many natural language processing tasks can benefit from such diversity ranki ... \" .We introduce a novel ranking algorithm called GRASSHOPPER , which ranks items with an emphasis on diversity .", "label": "", "metadata": {}, "score": "52.069042"}
{"text": "View at Scopus .L. Suanmali , N. Salim , and M. S. Binwahlan , \" Genetic algorithm based sentence extraction for text summarization , \" International Journal of Innovative Computing , vol .1 , no . 1 , pp . 1 - 22 , 2011 .", "label": "", "metadata": {}, "score": "52.160072"}
{"text": "In our statement , it is supposed that the summary will be created by median sentences then at a choice of sentence as median , it is necessary to meet a condition that the sum of length of the selected median sentences will not exceed the given summary length .", "label": "", "metadata": {}, "score": "52.238686"}
{"text": "Our objective is to extract summary of a given text that balances .Automatic document summarization takes a source document ( or source documents ) as input , and then it extracts the essence of the source(s ) , to present a well - formed summary to the user [ 11 ] .", "label": "", "metadata": {}, "score": "52.55078"}
{"text": "Knowledge and Data Eng . , vol . 8 , no . 8 , pp .1138 - 1150 , Aug. 2006 .[ 18 ] D. Wang , T. Li , S. Zhu , and C. Ding , \" Multi - Document Summarization via Sentence - Level Semantic Analysis and Symmetric Matrix Factorization , \" Proc . 31st", "label": "", "metadata": {}, "score": "52.658752"}
{"text": "37 , no . 7 , pp .4842 - 4849 , 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .R. Mallipeddi , P. N. Suganthan , Q. K. Pan , and M. F. Tasgetiren , \" Differential evolution algorithm with ensemble of parameters and mutation strategies , \" Applied Soft Computing Journal , vol .", "label": "", "metadata": {}, "score": "52.921074"}
{"text": "37 , no . 7 , pp .4842 - 4849 , 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .R. Mallipeddi , P. N. Suganthan , Q. K. Pan , and M. F. Tasgetiren , \" Differential evolution algorithm with ensemble of parameters and mutation strategies , \" Applied Soft Computing Journal , vol .", "label": "", "metadata": {}, "score": "52.921074"}
{"text": "A .I . for this individual has a big value and scaling factor will be set small , depending on the neighbor of its best fitness to the global best value , to facilitate a finer local explorations and so accelerate convergence .", "label": "", "metadata": {}, "score": "53.010185"}
{"text": "The DE algorithm uses a greedy selection .The selection operator chooses between the target and corresponding trial vectors .A member of the next generation becomes the fittest vector , that is , vector with the better fitness value .For example , if we have a maximization problem , the selection operation can be expressed as follows : . i .", "label": "", "metadata": {}, "score": "53.102135"}
{"text": "In Proceedings of HLT - NAACL 2004 : Short Papers , 2004 .( PostScript )( PDF ) .[ Rosenberg and Binkowski , 2004 ] .Andrew Rosenberg and Ed Binkowski .Augmenting the kappa statistic to determine interannotator reliability for multiply labelled data points .", "label": "", "metadata": {}, "score": "53.1476"}
{"text": "larity is used as a criterion to discover unseen knowledge from textual databases [ 2].These exemplar applications show that the computing of sentence similarity has become a generic component for the research community involved i .. \" ...We present an approach to improving the precision of an initial document ranking wherein we utilize cluster information within a graph - based framework .", "label": "", "metadata": {}, "score": "53.20354"}
{"text": "The rest of the paper is organized as follows .In Section 2 , we discuss the related works in the text summarization using genetic algorithm and cohesive summary extraction .Section 3 describes the proposed methodology .In Section 4 , the results based on intrinsic evaluation are discussed , and the final section deals with discussions on extrinsic evaluation .", "label": "", "metadata": {}, "score": "53.246468"}
{"text": "Handle the constraint ( 12 ) using the strategy described in Section 4.6 .Step 8 ( selection ) .If a trial vector is better than its target vector is , then replace the target vector by trial vector in the next generation .", "label": "", "metadata": {}, "score": "53.320847"}
{"text": "The pseudocode of the proposed SaDE algorithm can be summarized as follows .Step 1 ( initial population ) .Using the rule ( 15 ) create an initial population .Step 2 ( binarization ) .Transform real - coded individuals to binary - coded individuals using ( 24 ) .", "label": "", "metadata": {}, "score": "53.342037"}
{"text": "Figure 5(d ) shows the positions of the three converged seed points , which are all stably located at the corresponding cluster centers .For comparison , we also implemented the EM under the same experimental environment .Figure 5(b ) shows that the EM had successfully located the three seed points as well as the batch RPEM .", "label": "", "metadata": {}, "score": "53.391335"}
{"text": "( 4 ) Length .A summary should be bounded in length .Optimizing all four properties jointly is a challenging task and is an example of a global summarization problem .That is why the inclusion of relevant sentences relies not only on properties of the sentences themselves , but also on properties of every other sentence in the summary [ 33 ] .", "label": "", "metadata": {}, "score": "53.586754"}
{"text": "and .[ . 2 . ] , respectively .Therefore , in ( 9 ) we normalize the second and third terms so that their ranges were also .[ . 1 . ]Thus , we get the following objective function : . s .", "label": "", "metadata": {}, "score": "53.635384"}
{"text": "Conclusion and Future Work .The main contributions of the paper are the following .( i )The paper presents a document summarization model which extracts salient sentences from given documents while reducing redundant information in the summaries with the coverage of latent topics of document collection .", "label": "", "metadata": {}, "score": "53.646072"}
{"text": "In this section , CPU runtimes of the seven tested methods are compared .All the methods were implemented in the Delphi 7 language .The algorithms were run on a Server running Windows Vista with two dual - core Intel Xeon CPU ( 4 GHz ) processors and 4 GB memory .", "label": "", "metadata": {}, "score": "53.664795"}
{"text": "In future , we plan to develop a graded automatic summarization with various levels that can be better suited to a specific range of learners .Conclusion .When the target audience are specific , the usability of summarization can be measured through task - based evaluation .", "label": "", "metadata": {}, "score": "53.69587"}
{"text": "If a term occurs in a sentence , the value of that dimension is nonzero .Values can be binary ( . term is present in the sentence , . term is not present in the sentence ) , frequencies of terms in the sentence , or term weights [ 35 ] .", "label": "", "metadata": {}, "score": "53.697018"}
{"text": "Specifically , for each of the 30 DUC 2003 Task 2 documen ... pSum - SaDE : A Modified p -Median Problem and Self - Adaptive Differential Evolution Algorithm for Text Summarization .Institute of Information Technology of Azerbaijan National Academy of Sciences , B. Vahabzade Street , 9 , AZ1141 Baku , Azerbaijan .", "label": "", "metadata": {}, "score": "53.798157"}
{"text": "M. A. K. Halliday and R. Hasan , Cohesion in english ( english language ) , 1976 .Tools . by Eduard Hovy , Chin - yew Lin , Liang Zhou , Junichi Fukumoto - In Proceedings of the Fifth Conference on Language Resources and Evaluation ( LREC , 2006 . \" ...", "label": "", "metadata": {}, "score": "53.861046"}
{"text": "935 - 952 , 1990 .View at Publisher \u00b7 View at Google Scholar .T. Uchiyama and M. A. Arib , \" Color image segmentation using competitive learning , \" IEEE Transactions on Pattern Analysis and Machine Intelligence , vol .", "label": "", "metadata": {}, "score": "53.981262"}
{"text": "Motivated by what is previously mentioned in this section , the scaling factor is dynamically adapted for every individual by introducing a measure called affinity index , which characterizes the nearness of personal solution of individuals to the global solution of population at the .", "label": "", "metadata": {}, "score": "54.076202"}
{"text": "An important issue in extractive summarization is to extract cohesive summary from the text .Existing summarization approaches focus mostly on informative sentences rather than cohesive sentences .We considered several existing features , including sentence location , cardinality , title similarity , and keywords to extract important sentences .", "label": "", "metadata": {}, "score": "54.089153"}
{"text": "th - dimensional components of the vectors . and . , respectively ; CR is the predefined crossover probability which is usually set to a fixed value in .or changes dynamically within .r . a .n .d . is a number randomly selected from the index set .", "label": "", "metadata": {}, "score": "54.172348"}
{"text": ", we will meet an awkward situation ; that is , the amount of award is negative and the penalty one becomes positive .This implies that we will penalize the winner and award the rivals , which evidently violates our expectations .", "label": "", "metadata": {}, "score": "54.30991"}
{"text": "This is demonstrated on DUC 2005 peer systems and . by Aminul Islam , Diana Inkpen - ACM Transactions on Knowledge Discovery from Data ( TKDD , 2008 . \" ...We present a method for measuring the semantic similarity of texts using a corpus - based measure of semantic word similarity and a normalized and modified version of the Longest Common Subsequence ( LCS ) string matching algorithm .", "label": "", "metadata": {}, "score": "54.341793"}
{"text": "This is demonstrated on DUC 2005 peer systems and . by Aminul Islam , Diana Inkpen - ACM Transactions on Knowledge Discovery from Data ( TKDD , 2008 . \" ...We present a method for measuring the semantic similarity of texts using a corpus - based measure of semantic word similarity and a normalized and modified version of the Longest Common Subsequence ( LCS ) string matching algorithm .", "label": "", "metadata": {}, "score": "54.341793"}
{"text": "Specifically , for each of the 30 DUC 2003 Task 2 documen ...Tools . by Eduard Hovy , Chin - yew Lin , Liang Zhou , Junichi Fukumoto - In Proceedings of the Fifth Conference on Language Resources and Evaluation ( LREC , 2006 . \" ...", "label": "", "metadata": {}, "score": "54.526955"}
{"text": "Document Representation . )The graph representation of a sample document is shown in Figure 2 .Graph - based extractive summarization algorithm aims at identifying the most important sentences from a text , based on information exclusively drawn from text itself [ 31 ] .", "label": "", "metadata": {}, "score": "54.69149"}
{"text": "Existing methods for computing text similarity have focused mainly on either large documents or individual words .We focus on computing the similarity between two sentences or two short paragraphs .The proposed method can be exploited in a variety of applications involving textual knowledge representation and knowledge discovery .", "label": "", "metadata": {}, "score": "54.730938"}
{"text": "In Artifical Intelligence Magazine , Fall Issue 2004 , 2004 .( PostScript )( PDF ) .Sasha Blair - Goldensohn , Kathleen McKeown , and Andrew Schlaikjer .A hybrid approach for qa track definitional questions .In 12th Text Retrieval Conference ( TREC 2003 ) .", "label": "", "metadata": {}, "score": "54.923523"}
{"text": "When mutation is implemented , several differential vectors obtained from the difference of several randomly chosen parameter vectors are added to the target vector to generate a mutant vector .Then , a trial vector is produced by crossover recombining the obtained mutant vector with the target vector .", "label": "", "metadata": {}, "score": "54.951546"}
{"text": "20 ] proposed a novel trainable summarizer , which has several kinds of document features , and two major ideas were employed to improve the conventional corpus - based text summarization .First , sentence positions are ranked to emphasize the significances of different sentence positions ; second , the score function was trained by the genetic algorithm to obtain a suitable combination of feature weights .", "label": "", "metadata": {}, "score": "54.961586"}
{"text": "Solutions in a population are assigned fitness so that feasible solutions are emphasized more than infeasible solutions .The following three criteria are satisfied during the handling process .( i )Any feasible solution wins over any infeasible solution .( ii )", "label": "", "metadata": {}, "score": "55.021835"}
{"text": "The direct way to measure the text comprehension is to evaluate through objective comprehension questions .The experiments were carried out on fifteen learners with reading difficulties ranging from the fourth grade to the seventh grade .Each learner is given two texts , one from text books with comprehension questions and another with a summary followed by the text and objective questions from the grade level text .", "label": "", "metadata": {}, "score": "55.026054"}
{"text": "Let a document collection be decomposed into a set of sentences . , where . is the number of sentences , . denotes .th sentence in .For calculation of similarity between textual units , each of them should be presented as a vector .", "label": "", "metadata": {}, "score": "55.047295"}
{"text": "The first term aims to evaluate the relevancy of the summary .Higher value of the term corresponds to higher relevancy of the summary .The second term aims to evaluate the content coverage of the summary .The high value of the term provides that sentences be well grouped in topics .", "label": "", "metadata": {}, "score": "55.122406"}
{"text": "So , the text readability can be evaluated directly to measure the comprehension of information from a text : objective comprehension questions such as multiple - choice or yes / no type questions , which have been used with learners in educational and psychological studies of comprehension .", "label": "", "metadata": {}, "score": "55.30877"}
{"text": "Last column shows the ranks of the method on their time spent .Statistical Significance Test .To judge the statistical significance of the summarization results , a nonparametric statistical significance test called Wilcoxon 's rank sum test for independent samples [ 48 ] has been conducted at the 5 % significance level .", "label": "", "metadata": {}, "score": "55.442894"}
{"text": "Mathematical regression is a good model to estimate the feature weights .In this model a mathematical function relates output to input as in ( 2 ): .Similarity matrix can be composed using similarity metrics .The lower triangular values are made zero to avoid backward traversal in the graph and to preserve ordering in sentences while extraction , and also the diagonal elements are made zero as there is no self - loop .", "label": "", "metadata": {}, "score": "55.566063"}
{"text": "Challenges do exist while comprehending and organizing information from text for such learners .Learners find greater difficulty when they are reading at their earlier stage because of the amount of information to be read [ 2 ] .Summarizing can either be taught [ 3 ] or understood as one of the several strategies [ 4 ] and can be shown to improve their comprehension and recall skills about whatever is read [ 5 ] .", "label": "", "metadata": {}, "score": "55.73632"}
{"text": "M. S. Binwahlan , N. Salim , and L. Suanmali , \" MMI diversity based text summarization , \" International Journal of Computer Science and Security , vol .3 , no . 1 , pp .23 - 33 , 2009 .", "label": "", "metadata": {}, "score": "55.75778"}
{"text": "Third , we propose a summarization approach based on subjective opinions and integrate it with the graph - based ones .The empirical evaluation shows that the basic clue words have the highest accuracy among the three cohesion measures .Moreover , subjective words can significantly improve accuracy . ... this paper .", "label": "", "metadata": {}, "score": "55.813293"}
{"text": "Therefore we ran self - adaptive DE for .C .R .Other parameters are set as .m . a .x . m .i .n . , and .m . a .x .for all .", "label": "", "metadata": {}, "score": "55.8285"}
{"text": "Figure 8 : The converged positions of the seed points learned by the batch RPEM .Experiment 3 : Batch RPEM on Color Image Segmentation .This experiment further investigated the batch RPEM algorithm on color image segmentation in comparison to the EM algorithm .", "label": "", "metadata": {}, "score": "55.95465"}
{"text": "GAs , introduced by Holland , were proven to be the most powerful optimization technique in a large solution space [ 14 , 15 ] .They are used where exhaustive search for solution is expensive in terms of computation time .", "label": "", "metadata": {}, "score": "55.98468"}
{"text": "These metrics were computed by comparing automatically generated summaries against the model summaries .Table 1 provides the ROUGE scores of the methods .The results reported here are averaged over 20 runs .In Table 1 through pSum - SaDE our method is denoted .", "label": "", "metadata": {}, "score": "56.013855"}
{"text": "Syntactic simplification for improving content selection in multi - document summarization .In 20th International Conference on Computational Linguistics ( COLING 2004 ) , Geneva , Switzerland , 2004 .( PostScript )( PDF ) .Kristinn Thorisson , Hrvoje Benko , Denis Abramov , Andrew Arnold , Sameer Maskey , and Aruchunan Vaseekaran .", "label": "", "metadata": {}, "score": "56.176945"}
{"text": "Repeat Steps 2 - 8 until a user - specified maximum number .m . a .x . of fitness calculation is reached .Step 10 ( output ) .Report the summary obtained by the best individual as the final solution at maximum number of fitness calculation .", "label": "", "metadata": {}, "score": "56.33342"}
{"text": "The authors thank the Professor Chuan - Kang Ting ( the editor ) , and the reviewers providing very helpful comments and suggestions .Their insight and comments led to a better presentation of the ideas expressed in this paper .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . D. Shen , J.-T. Sun , H. Li , Q. Yang , and Z. Chen , \" Document summarization using conditional random fields , \" in Proceedings of the 20th International Joint Conference on Artificial Intelligence , pp .", "label": "", "metadata": {}, "score": "56.630787"}
{"text": "Problem Statement and Its Mathematical Formulation .Problem Statement .In this section , we present our approach towards all of the four aspects of summarization as follows .( 1 ) Relevancy .A good summary should contain the most important information , that is , selected sentences should be relevant to the main content of the source .", "label": "", "metadata": {}, "score": "56.71254"}
{"text": "Single - document summarization can only condense one document into a shorter representation , whereas multidocument summarization can condense a set of documents into a summary .Multidocument summarization can be considered as an extension of single - document summarization and used for precisely describing the information contained in a cluster of documents and facilitate users to understand the document cluster .", "label": "", "metadata": {}, "score": "56.82612"}
{"text": "The population undergoes mutation by an actual change or flipping of one of the genes of the candidate chromosomes , which in turn keeps away from local optima [ 33 ] .A random gene in the chromosome is selected and replaced with values that do not duplicate sentences .", "label": "", "metadata": {}, "score": "56.84046"}
{"text": "In this paper , we study the problem of summarizing email conversations .We first build a sentence quotation graph that captures the conversation structure among emails .We adopt three cohesion measures : clue words , semantic similarity and cosine similarity as the weight of the edges .", "label": "", "metadata": {}, "score": "56.937088"}
{"text": "In this paper , we study the problem of summarizing email conversations .We first build a sentence quotation graph that captures the conversation structure among emails .We adopt three cohesion measures : clue words , semantic similarity and cosine similarity as the weight of the edges .", "label": "", "metadata": {}, "score": "56.937088"}
{"text": "( PDF ) .[Muresan et al . , 2004 ] .Smaranda Muresan , Tudor Muresan , and Judith Klavans .Inducing constraint - based grammars from a small semantic Treebank .In AAAI Spring Symposium 2004 : Language Learning : An Interdisciplinary Perspective , 2004 .", "label": "", "metadata": {}, "score": "57.05668"}
{"text": "5 , no . 1 , pp .35 - 45 , 1997 .View at Google Scholar . S. Y. Chen , H. Y. Tong , Z. J. Wang , S. Liu , M. Li , and B. W. Zhang , \" Improved generalized belief propagation for vision processing , \" Mathematical Problems in Engineering , Article ID 416963 , 12 pages , 2011 .", "label": "", "metadata": {}, "score": "57.06386"}
{"text": "View at Google Scholar . D. S. McNamara , \" Reading both high - coherence and low - coherence texts : effects of text sequence and prior knowledge , \" Canadian Journal of Experimental Psychology , vol .55 , no . 1 , pp .", "label": "", "metadata": {}, "score": "57.141148"}
{"text": "2012 , Article ID 814356 , 18 pages , 2012 .View at Publisher \u00b7 View at Google Scholar .Y. W. Lim and S. U. Lee , \" On the color image segmentation algorithm based on the thresholding and the fuzzy C - means techniques , \" Pattern Recognition , vol .", "label": "", "metadata": {}, "score": "57.166683"}
{"text": "There are two approaches for document summarization : supervised and unsupervised [ 3 ] .The supervised approaches treat document summarization as a classification and the task formalize as identifying whether a sentence should be included in the summary or not .", "label": "", "metadata": {}, "score": "57.216064"}
{"text": "Compared to the adaptive RPEM , this batch one need not assign the learning rate analogous to the EM , but still preserves the capability of automatic model selection .Further , the convergence speed of this batch RPEM is faster than the EM and the adaptive RPEM in general .", "label": "", "metadata": {}, "score": "57.296593"}
{"text": "Word sense disambiguation ( WSD ) , the task of identifying the intended meanings ( senses ) of words in context , has been a long - standing research objective for natural language processing .In this paper we are concerned with graph - based algorithms for large - scale WSD .", "label": "", "metadata": {}, "score": "57.30404"}
{"text": "Word sense disambiguation ( WSD ) , the task of identifying the intended meanings ( senses ) of words in context , has been a long - standing research objective for natural language processing .In this paper we are concerned with graph - based algorithms for large - scale WSD .", "label": "", "metadata": {}, "score": "57.30404"}
{"text": "The cosine similarity uses the weighting terms representation of the sentences .According to the VSM the sentence .represented as a weighting vector of the terms , . [ . .] , where . is the weight of the term .", "label": "", "metadata": {}, "score": "57.387794"}
{"text": "As the learner may have a problem in encoding the text , due to slower encoding speed , units could get lost from the working memory before they are being processed [ 9 ] .Such learners should map the content of the text to an image , so the trigger words could often create confusion to these individuals [ 10 ] .", "label": "", "metadata": {}, "score": "57.414948"}
{"text": "DE proposed by Storn and Price [ 37 ] is a fast and simple technique , which performs well on a wide variety of problems [ 38 - 40 ] .DE is a population - based stochastic search technique like genetic algorithm using the three operators : crossover , mutation , and selection .", "label": "", "metadata": {}, "score": "57.432648"}
{"text": "View at Scopus . A. Haghighi and L. Vanderwende , \" Exploring content models for multi - document summarization , \" in Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pp .", "label": "", "metadata": {}, "score": "57.45771"}
{"text": "View at Scopus . A. Haghighi and L. Vanderwende , \" Exploring content models for multi - document summarization , \" in Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , pp .", "label": "", "metadata": {}, "score": "57.45771"}
{"text": "R. Gunning , \" The fog index after twenty years , \" Journal of Business Communication , vol .6 , no . 2 , pp .3 - 13 , 1969 .View at Google Scholar .G. H. McLaughlin , \" Smog grading - a new readability formula , \" Journal of Reading , vol .", "label": "", "metadata": {}, "score": "57.51013"}
{"text": "K. Deb , \" An efficient constraint handling method for genetic algorithms , \" Computer Methods in Applied Mechanics and Engineering , vol .186 , no . 2 - 4 , pp . 311 - 338 , 2000 .View at Google Scholar \u00b7 View at Scopus A Batch Rival Penalized Expectation - Maximization Algorithm for Gaussian Mixture Clustering with Automatic Model Selection . 1 Faculty of Applied Mathematics , Guangdong University of Technology , Guangzhou 510520 , China 2 Department of Computer Science , Hong Kong Baptist University , Kowloon , Hong Kong 3 Department of Electronics and Information Engineering , Huazhong University of Science & Technology , Wuhan , China .", "label": "", "metadata": {}, "score": "57.55715"}
{"text": "( PDF ) .Pablo A. Duboue , Kathleen R. McKeown , and Vasileios Hatzivassiloglou .ProGenIE : Biographical descriptions for intelligence analysis .In Proceedings of the NSF / NIJ Symposium on Intelligence and Security Informatics , volume 2665 of Lecture Notes in Computer Science , pages 343 - 345 , Tucson , Arizona , June 2003 .", "label": "", "metadata": {}, "score": "57.678387"}
{"text": "We show , both theoretically and empirically , a modified greedy algorithm can efficiently solve the budgeted submodular maximization problem near - optimally , and we derive new approximation bounds in doing so .Experiments on DUC'04 task show that our approach is superior to the bestperforming method from the DUC'04 evaluation on ROUGE-1 scores . by Jun Wang , Xia Hu , Wenhan Chao , Biyun Hu , Zhoujun Li - Dicarbonyl Products of the OH Radical - Initiated Reactions of Naphthalene and the C1and C2-Alkylnaphthalenes , 2007 . \" ...", "label": "", "metadata": {}, "score": "57.757164"}
{"text": "331 - 346 , 1987 .View at Google Scholar . A. S. Palinscar and A. L. Brown , \" Reciprocal teaching of comprehensionfostering and comprehension - monitoring activities , \" Cognition and Instruction , vol .1 , no . 2 , pp .", "label": "", "metadata": {}, "score": "58.069664"}
{"text": "The crossover rate CR is a probability of mixing between trial and target vectors .A large CR often speeds up convergence .However , from a certain value upwards , the convergence speed may decrease or the population may converge prematurely .", "label": "", "metadata": {}, "score": "58.176086"}
{"text": "276 - 305 , 2005 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .P. A. Carpenter and M. Daneman , \" Lexical retrieval and error recovery in reading : A model based on eye fixations , \" Journal of Verbal Learning and Verbal Behavior , vol .", "label": "", "metadata": {}, "score": "58.196472"}
{"text": "In addition , we report the ROUGE-2 and ROUGE - SU4 m .. \" ...This paper describes a method for language independent extractive summarization that relies on iterative graph - based ranking algorithms .Through evaluations performed on a single - document summarization task for English and Portuguese , we show that the method performs equally well regardless of the l ... \" .", "label": "", "metadata": {}, "score": "58.275406"}
{"text": "In addition , we report the ROUGE-2 and ROUGE - SU4 m .. \" ...This paper describes a method for language independent extractive summarization that relies on iterative graph - based ranking algorithms .Through evaluations performed on a single - document summarization task for English and Portuguese , we show that the method performs equally well regardless of the l ... \" .", "label": "", "metadata": {}, "score": "58.275406"}
{"text": "Initial population is generated using the encoding technique explained in previous section : .Fitness Function .After initialization of the population , the process of evaluating the quality of the chromosome is done using the fitness function .The fitness function aids in finding the optimal combination of sentences and tends to balance the informative score and the sentence similarity .", "label": "", "metadata": {}, "score": "58.283417"}
{"text": "A summary should contain every important aspect of the document .By considering coverage , the information loss in summarization can be minimized .( 3 ) Diversity .A good summary should be concise and contain as few redundant sentences as possible , that is , two sentences providing similar information should not be both present in the summary .", "label": "", "metadata": {}, "score": "58.360687"}
{"text": "Information networks are widely used to characterize the relationships between data items such as text documents .Many important retrieval and mining tasks rely on ranking the data items based on their centrality or prestige in the network .Beyond prestige , diversity has been recognized as a crucial objective in ranking , aiming at providing a nonredundant and high coverage piece of information in the top ranked results .", "label": "", "metadata": {}, "score": "58.366657"}
{"text": "Based on this index , every individual could decide how to adjust the values of scaling factor .For this purpose , the mutation strategy is given by .th individual is far away from the global best solution and it needs a strong global exploration , therefore a large perturbation .", "label": "", "metadata": {}, "score": "58.593903"}
{"text": "1232 - 1243 , 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. Hennig , \" Topic - based multi - document summarization with probabilistic latent semantic analysis , \" in Proceedings of the International Conference on Recent Advances in Natural Language Processing , pp .", "label": "", "metadata": {}, "score": "58.606506"}
{"text": "1232 - 1243 , 2010 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. Hennig , \" Topic - based multi - document summarization with probabilistic latent semantic analysis , \" in Proceedings of the International Conference on Recent Advances in Natural Language Processing , pp .", "label": "", "metadata": {}, "score": "58.606506"}
{"text": "[ Filatova and Hatzivassiloglou , 2004b ] .Elena Filatova and Vasileios Hatzivassiloglou .A formal model for information selection in multi - sentence text extraction .In COLING , Geneva , Switzerland , August 2004 , 2004 .( PostScript )", "label": "", "metadata": {}, "score": "58.661064"}
{"text": "The statistics of the data corpus used in the experiments are tabulated in Table 2 .The summaries of these texts are created manually by three independent human annotators .The sentences to be included in the summary are ranked by the annotators .", "label": "", "metadata": {}, "score": "58.726364"}
{"text": "Evaluation Metrics .A well - recognized automatic evaluation toolkit ROUGE [ 47 ] is used in evaluation .It includes five measures , which automatically determine the quality of a machine - generated summary by comparing it to ideal summaries created by humans : ROUGE- . , ROUGE- . , ROUGE- . , ROUGE- . , and ROUGE - SU .", "label": "", "metadata": {}, "score": "58.748085"}
{"text": "Each group consists of the ROUGE scores for the data sets produced by 20 consecutive runs of the corresponding method .The median values , 95 % CI , and standard error ( stdr . ) of ROUGE scores of each group for all the data sets are shown in Table 6 .", "label": "", "metadata": {}, "score": "58.749607"}
{"text": "A .I . and then scaling factor depending on their fitness .While the fitness of an individual is far away from the fitness of the global best , .A .I . for this individual has a small value and the value of scaling factor will be large resulting in strong global search abilities and locate the promising search areas .", "label": "", "metadata": {}, "score": "58.75558"}
{"text": "17 , no . 1 , pp .21 - 48 , 1991 .View at Google Scholar .I. Mani and E. Bloedorn , \" Machine learning of generic and user - focused summarization , \" in Proceedings of the 15th National Conference on Artificial Intelligence ( AAAI ' 98 ) , pp .", "label": "", "metadata": {}, "score": "58.799576"}
{"text": "1679 - 1696 , 2011 .View at Publisher \u00b7 View at Google Scholar .L. Jia , W. Gong , and H. Wu , \" An improved self - adaptive control parameter of differential evolution for global optimization , \" Communications in Computer and Information Science , vol .", "label": "", "metadata": {}, "score": "58.87374"}
{"text": "1679 - 1696 , 2011 .View at Publisher \u00b7 View at Google Scholar .L. Jia , W. Gong , and H. Wu , \" An improved self - adaptive control parameter of differential evolution for global optimization , \" Communications in Computer and Information Science , vol .", "label": "", "metadata": {}, "score": "58.87374"}
{"text": "The raw frequency of a term only states how often a term occurs in a document without measuring the importance of that term within the sentence or within the whole collection .Different weighting schemes are available .The most common and popular one is the tf - isf weighting scheme .", "label": "", "metadata": {}, "score": "58.876045"}
{"text": "Michel Galley , Kathleen McKeown , Julia Hirschberg , and Elizabeth Shriberg .Identifying agreement and disagreement in conversational speech : Use of bayesian networks to model pragmatic dependencies .In ACL 2004 , Barcelona , 2004 .( PostScript )( PDF ) .", "label": "", "metadata": {}, "score": "58.890663"}
{"text": "Given a question as query , our goal is to rank all of the retrieved questions according to their likelihood of being good recommendations for the query .In this paper , we propose ... \" .This paper is concerned with the problem of question recommendation in the setting of Community Question Answering ( CQA ) .", "label": "", "metadata": {}, "score": "59.085316"}
{"text": "Here the size of the chromosome is equal to the size of the summary and is not equal to the input text .Each locus of the chromosome represents the order of sentences in the summary .The size of the chromosome is fixed and is decided by the compression rate ( CR ) of the text .", "label": "", "metadata": {}, "score": "59.33304"}
{"text": "Constraint ( 10 ) ensures that each sentence should be associated with one and only one median , while constraints ( 11 ) restrict sentences to be assigned to open medians .Constraint ( 12 ) implies that the length constraint of summary can not be violated .", "label": "", "metadata": {}, "score": "59.353214"}
{"text": "A term that occurs in every sentence of the collection gets a lower isf value .This reflects the fact that it is not as significant for the distinction between sentences as terms that occur rarely throughout the sentence collection .The isf factor has been introduced to improve the discriminating power of terms in the traditional IR .", "label": "", "metadata": {}, "score": "59.37219"}
{"text": "Section 4 describes a modified DE algorithm to solve the optimization problem .The numerical experiments and results are given in Section 5 .Finally , we conclude our paper in Section 6 .Related Work .Generally , document summarization methods can be divided into two categories : abstractive and extractive [ 4 , 9 ] .", "label": "", "metadata": {}, "score": "59.428303"}
{"text": "Improved name recognition using meta - data dependent name networks .In ICASSP 2004 , Montreal , Canada , 2004 .( PostScript )( PDF ) .[ Maskey et al . , 2004b ] .Sameer Maskey , Alan Black , and Laura Tomokiyo .", "label": "", "metadata": {}, "score": "59.443275"}
{"text": "K. Deb , \" An efficient constraint handling method for genetic algorithms , \" Computer Methods in Applied Mechanics and Engineering , vol .186 , no . 2 - 4 , pp . 311 - 338 , 2000 .View at Google Scholar \u00b7 View at Scopus Papers - Search Results .", "label": "", "metadata": {}, "score": "59.52378"}
{"text": "Qazvinian et al .[ 24 ] used GA to produce document summary .They proposed a fitness function based on following three factors : readability factor ( RF ) , cohesion factor ( CF ) , and topic - relation factor ( TRF ) .", "label": "", "metadata": {}, "score": "59.60847"}
{"text": "Global Term Weighting ( .i .s .f . )The inverse sentence frequency ( isf ) measures the importance of a term within the sentence collection : . i .s .f .l .o .g .", "label": "", "metadata": {}, "score": "59.73576"}
{"text": "The subgraph ( summary ) extraction technique can be formulated as a combinatorial problem .The idea is to extract the high informative score sentences that have good cohesion where the informative score can be calculated using feature score and its weight and cohesion can be measured using the sentence similarity .", "label": "", "metadata": {}, "score": "59.8321"}
{"text": "Furthermore , the summary can be used as an overview before reading the complete text , to improve the readability and comprehension .References .M. Gajria , A. K. Jitendra , S. Sood , and G. Sacks , \" Improving comprehension of expository text in students with LD : A research synthesis , \" Journal of Learning Disabilities , vol .", "label": "", "metadata": {}, "score": "59.841537"}
{"text": "As a strategy performed either during or after reading , summarizing helps readers to focus on the main ideas and other key skill concepts that have been taught and to disregard the less relevant ones [ 6 ] .Reading comprehension is defined [ 7 ] as \" the process of simultaneously extracting and constructing meaning .", "label": "", "metadata": {}, "score": "59.88318"}
{"text": "Local Term Weighting ( .t .f . )It measures the importance of a term within a sentence : . t .f .f .r .e . q . where .f .r .e . q . is the frequency of term . in sentence .", "label": "", "metadata": {}, "score": "59.89383"}
{"text": "The variations are due to the difference in the parameter that metrics consider for readability prediction .Despite their strengths , there are theoretical shortcomings in using readability formulae to evaluate texts .In particular , the emphasis on shallow features like word length and sentence length is difficult to capture the deep , structural properties of the text that reflect cohesion .", "label": "", "metadata": {}, "score": "59.93338"}
{"text": "557 - 564 , Springer , Rome , Italy , 2007 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . H. Takamura and M. Okumura , \" Text summarization model based on the budgeted median problem , \" in Proceedings of the 18th ACM International Conference on Information and Knowledge Management ( CIKM ' 09 ) , pp .", "label": "", "metadata": {}, "score": "59.995434"}
{"text": "557 - 564 , Springer , Rome , Italy , 2007 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . H. Takamura and M. Okumura , \" Text summarization model based on the budgeted median problem , \" in Proceedings of the 18th ACM International Conference on Information and Knowledge Management ( CIKM ' 09 ) , pp .", "label": "", "metadata": {}, "score": "59.995434"}
{"text": "215 - 224 , 2009 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .G. Pampara , A. P. Engelbrecht , and N. Franken , \" Binary differential evolution , \" in Proceedings of the IEEE Congress on Evolutionary Computation , pp .", "label": "", "metadata": {}, "score": "60.03957"}
{"text": "215 - 224 , 2009 .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .G. Pampara , A. P. Engelbrecht , and N. Franken , \" Binary differential evolution , \" in Proceedings of the IEEE Congress on Evolutionary Computation , pp .", "label": "", "metadata": {}, "score": "60.03957"}
{"text": "( PostScript )( PDF ) .[ Filatova and Hatzivassiloglou , 2003 ] .Elena Filatova and Vasileios Hatzivassiloglou .Domain - independent detection , extraction , and labeling of atomic events .In Proceedings of RANLP'03 , 2003 .( PostScript )", "label": "", "metadata": {}, "score": "60.136326"}
{"text": "Evaluation .Extractive summary can be evaluated using various characteristics such as accuracy , cohesion , and readability .Accuracy in extraction measures how far the technique is capable of predicting the correct sentence .Evaluation can be classified into intrinsic and extrinsic evaluation .", "label": "", "metadata": {}, "score": "60.136726"}
{"text": "In single - cut crossover , summaries generated by two different parents are combined at a particular point .In general , after crossover , there is a possibility for occurrences of redundant sentences in summary as the problem is basically a combinatorial one .", "label": "", "metadata": {}, "score": "60.35333"}
{"text": "210 - 225 , 2007 .View at Google Scholar \u00b7 View at Scopus .B. B. Armbruster , T. H. Anderson , and J. Ostertag , \" Does text structure / summarization instruction facilitate learning from expository text ? \"Reading Research Quarterly , vol .", "label": "", "metadata": {}, "score": "60.447685"}
{"text": "Higher cohesion has been found to facilitate comprehension and recall .The optimal level of cohesion depends on the knowledge level of the reader [ 13 ] , and it was found that low knowledge readers could be benefited from high cohesion texts , as most researchers would expect .", "label": "", "metadata": {}, "score": "60.50139"}
{"text": "The major issue of extractive summarization is the lack of cohesion .Cohesion is the extent to which the ideas in the text are expressed clearly and relate to one another in a systematic fashion , by avoiding a confusing jumble of information .", "label": "", "metadata": {}, "score": "60.612625"}
{"text": "FOG and SMOG predict the readability using average sentence length and the percentage of words with at least three syllables as parameters .The Flesch - Kincaid grade level score uses a fixed linear combination of average words per sentence and average syllable per word .", "label": "", "metadata": {}, "score": "60.684242"}
{"text": "The evaluation criterion focuses mainly on readability and cohesion of the summary .Readability .To date , there exist numerous readability metrics for predicting the readability of a given text .We considered FOG [ 36 ] , SMOG [ 37 ] , and Flesch - Kincaid [ 38 ] for predicting the readability of the summary .", "label": "", "metadata": {}, "score": "60.693893"}
{"text": "213 - 234 , 2004 .View at Google Scholar . A. P. Sweet and C. E. Snow , Rethinking Reading Comprehension , Guilford Press , 2003 .D. R. Reutzel , J. A. Smith , and P. C. Fawson , \" An evaluation of two approaches for teaching reading comprehension strategies in the primary years using science information texts , \" Early Childhood Research Quarterly , vol .", "label": "", "metadata": {}, "score": "60.731857"}
{"text": "View at Scopus . H. G. Silber and K. F. McCoy , \" Efficient text summarization using lexical chains , \" in Proceedings of the 5th International Conference on Intelligent User Interfaces ( IUI ' 00 ) , pp .252 - 255 , ACM , January 2000 .", "label": "", "metadata": {}, "score": "60.861748"}
{"text": "A way to measure a text 's difficulty level is to ask the learner various subjective questions in which they must evaluate how easy it is to understand a text .This metacomprehension of text has been measured using Likert scales in educational studies [ 41 ] .", "label": "", "metadata": {}, "score": "61.09328"}
{"text": "I. L. Beck , M. G. McKeown , G. M. Sinatra , and J. A. Loxterman , \" Revising social studies text from a text - processing perspective : evidence of improved comprehensibility , \" Reading Research Quarterly , vol .26 , no . 3 , pp .", "label": "", "metadata": {}, "score": "61.137375"}
{"text": "We provide a comprehensive comparison of CWS with various existing methods on the Enron data set .Preliminary results suggest that CWS provides better summaries than existing methods . ... ch sentence based on its similarity to the TFIDF centroid of the whole document set and other properties such as position in a document , sentence length and inter - sentence similarity [ 7].", "label": "", "metadata": {}, "score": "61.28559"}
{"text": "With the publishing of work [ 27 ] , an optimization approach began to be applied actively in extractive document summarization .It is directly connected with character of the extractive summarization ; in other words , identification of informative sentences in documents by the nature is an optimization problem .", "label": "", "metadata": {}, "score": "61.295044"}
{"text": "( 1 ) Do you think the summary will help you to understand the text better ?( 2 ) Do you think the summary is easy to read ?The feedbacks obtained from the learners are as shown in Figure 5 .", "label": "", "metadata": {}, "score": "61.310593"}
{"text": "r . a .n .d .s .i .g . m .o .t .h .e . r .w .i . s .e . r . a .n .d . is a uniformly distributed random number lying between 0 and 1 , which is instantiated independently for each . represents a candidate solution that first , fourth , and fifth sentences are selected to be included to the summary .", "label": "", "metadata": {}, "score": "61.483498"}
{"text": "( PDF ) .[ Duboue and McKeown , 2003 ] .Pablo A. Duboue and Kathleen R. McKeown .Statistical acquisition of content selection rules for natural language generation .In 2003 Conference on Empirical Methods for Natural Language Processing ( EMNLP 2003 ) , Sapporo , Japan , July 2003 .", "label": "", "metadata": {}, "score": "61.626026"}
{"text": "Binarization .Binary DE is the modified version of DE , which operates in binary search spaces .In the binary DE , the real value of genes is converted to the binary space by the rule [ 42 ] .i .", "label": "", "metadata": {}, "score": "61.761917"}
{"text": "-grams , between the generated summary by a method and a set of reference summaries .The ROUGE- . measure compares .-grams of two summaries and counts the number of matches : .R .O .U .G .", "label": "", "metadata": {}, "score": "61.811653"}
{"text": "View at Google Scholar \u00b7 View at Scopus . H. Vafaie and K. De Jong , \" Genetic algorithms as a tool for feature selection in machine learning , \" in Proceedings of the 4th International Conference on Tools with Artificial Intelligence ( TAI ' 92 ) , pp .", "label": "", "metadata": {}, "score": "61.836136"}
{"text": "We implemented our model on multi - document summarization task .Experiments have shown that the proposed model is competitive on the DUC2006 dataset .Introduction .Automatic document summarization has drawn increasing attention in the past with rapid growth of the Internet and electronic government .", "label": "", "metadata": {}, "score": "61.90546"}
{"text": "In our study , this goal has been reached with modifying of the p -median problem .To apply a p -median problem to sentence - extraction - based document summarization , each sentence in a document collection should be presented as a point in Euclidean space and defined a measure to calculate a similarity between points ( sentences ) .", "label": "", "metadata": {}, "score": "61.92626"}
{"text": "Therefore relevance of the summary will be defined as an affinity measure between them and the centre .O . of all set of sentences , .s .i . m . . . .Under the notations and statements above , text summarization task , we formalize as follows : . maximize .", "label": "", "metadata": {}, "score": "61.99214"}
{"text": "( PDF ) .[ Maskey and Hirschberg , 2003 ] .Sameer Maskey and Julia Hirschberg .Automatic speech summarization of broadcast news using structural features .In Proceedings of Eurospeech 2003 , 2003 .( PostScript )( PDF ) .", "label": "", "metadata": {}, "score": "62.091652"}
{"text": "[ Galley and McKeown , 2003 ] .Michel Galley and Kathleen McKeown .Improving word sense disambiguation in lexical chaining .In Proceedings of 18thInternational Joint Conference on Artificial Intelligence ( IJCAI'03 ) , 2003 .( PostScript )( PDF ) .", "label": "", "metadata": {}, "score": "62.171432"}
{"text": "Dataset .A collection of hundred and fourteen articles from educational text of grade four to grade seven are used for evaluation .The texts are mainly from science and social subjects because of the challenges faced by the reading difficulties in understanding the concepts .", "label": "", "metadata": {}, "score": "62.378918"}
{"text": "For 10 % compression , baseline and GA perform better in extracting a cohesive summary .For 20 % compression , GA extracts a better cohesive summary than FCBA and baseline .For 30 % compression , GA extracts a better summary and the comparison based on cohesion is measured using cumulative sentence similarity as shown in Figure 4 .", "label": "", "metadata": {}, "score": "62.43684"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .X. Cai , W. Li , Y. Ouyang , and H. Yan , \" Simultaneous ranking and clustering of sentences : an reinforcement approach to multi - document summarization , \" in Proceedings of the 23rd", "label": "", "metadata": {}, "score": "62.440388"}
{"text": "Our results demonstrate that certain models capture complementary aspects of coherence and thus can be combined to improve performance . by Alon Lavie , Kenji Sagae , Shyamsundar Jayaraman - In Proceedings of the 6th Conference of the Association for Machine Translation in the Americas ( AMTA-2004 , 2004 . \" ...", "label": "", "metadata": {}, "score": "62.447945"}
{"text": "Our results demonstrate that certain models capture complementary aspects of coherence and thus can be combined to improve performance . by Alon Lavie , Kenji Sagae , Shyamsundar Jayaraman - In Proceedings of the 6th Conference of the Association for Machine Translation in the Americas ( AMTA-2004 , 2004 . \" ...", "label": "", "metadata": {}, "score": "62.447945"}
{"text": "Acknowledgments .This work was also partially supported by the Fundamental Research Funds for the Central Universities , HUST:2010ZD025 , and Hubei Provincial Science Foundation under Grant 2010CDA006 , China .References . U.Fayyad , G. Piatetsky - Shpiro , P. Smyth , and R. Uthurusamy , Advances in Knowledge Discovery and Data Mining , MIT Press , 1996 .", "label": "", "metadata": {}, "score": "62.46647"}
{"text": "( iii )Two infeasible solutions are compared based on the amount of constraint violation .Stopping Criterion .Mutation , crossover and selection continue until some stopping criterion is satisfied .If the predefined maximum iteration number is reached , then the DE algorithm is terminated and outputs the best solution obtained by DE as the result .", "label": "", "metadata": {}, "score": "62.47188"}
{"text": "( PostScript )( PDF ) .[ Filatova and Hatzivassiloglou , 2004a ] .Elena Filatova and Vasileios Hatzivassiloglou .Event - based extractive summarization .In ACL Workshop on Summarization , Barcelona , Spain , 2004 .( PostScript )", "label": "", "metadata": {}, "score": "62.507202"}
{"text": "While this may seem unexpected , since BLEU and NIST focus on n - gram precision and disregard recall , our experiments show that correlation with human judgments is highest when almost all of the weight is assigned to recall .We also show that stemming is significantly beneficial not just to simpler unigram precision and recall based metrics , but also to BLEU and NIST . .", "label": "", "metadata": {}, "score": "62.595947"}
{"text": "While this may seem unexpected , since BLEU and NIST focus on n - gram precision and disregard recall , our experiments show that correlation with human judgments is highest when almost all of the weight is assigned to recall .We also show that stemming is significantly beneficial not just to simpler unigram precision and recall based metrics , but also to BLEU and NIST . .", "label": "", "metadata": {}, "score": "62.595947"}
{"text": "The stopping criteria for implementation purpose can be decided as follows : ( 1 ) when an upper limit on the number of generations is reached or ( 2 ) the chance of getting changes in the consecutive generation is extremely low .", "label": "", "metadata": {}, "score": "62.819023"}
{"text": "( PostScript )( PDF ) .[ Davis et al . , 2003 ] .Peter Davis , David Elson , and Judith Klavans .Methods for precise named entity matching in digital collections .In Proceedings of the Joint Conference on Digital Libraries ( JCDL 2003 ) , 2003 .", "label": "", "metadata": {}, "score": "62.87437"}
{"text": "The extended version is called ROUGE - SU that is a weighted average between ROUGE- . and ROUGE-1 .Performance Evaluation .In this section , we empirically compare the systems using ROUGE-1 , ROUGE-2 , and ROUGE - SU4 metrics .", "label": "", "metadata": {}, "score": "62.95403"}
{"text": "The scaling factor is critical for the performance of DE , which balances global exploration and local exploitation abilities of the population .A large mutation factor facilitates exploration , but it takes the population long time to converge .Conversely , a small scaling factor makes the population fast converge , but it sometimes leads to local optimal .", "label": "", "metadata": {}, "score": "63.163567"}
{"text": "A .I . th individual has a high nearness to the global solution , and so it needs a strong local exploitation , therefore a small perturbation [ 38 , 40 ] .Hence , the value of scaling factor for every target individual in .", "label": "", "metadata": {}, "score": "63.195656"}
{"text": "639 - 646 , 1969 .View at Google Scholar .J. P. Kincaid , L. R. P. Fishburne Jr. , R. L. Rogers , and B. S. Chissom , \" Derivation of new readability formulas ( automated readability index , fog count and esch reading ease formula ) for navy enlisted personnel , \" 1975 .", "label": "", "metadata": {}, "score": "63.58921"}
{"text": "( PDF ) .[ Nenkova and Passonneau , 2004 ] .Ani Nenkova and Rebecca Passonneau .Evaluating content selection in summarization : the Pyramid method .In NAACL - HLT 2004 , 2004 .( PostScript )( PDF ) .", "label": "", "metadata": {}, "score": "63.773037"}
{"text": "Extrinsic evaluation focuses mainly on the quality by its effect on other tasks .We consider both methods because the generated summary should be informative as well as readable .The former part is objective and can be verified using intrinsic evaluation , and the latter part is subjective and can be evaluated using the extrinsic method .", "label": "", "metadata": {}, "score": "63.928753"}
{"text": "The original tobi system and the evolution of the tobi framework .In Sun - Ah Jun , editor , Prosodic models and Transcription : Towards Prosodic Typology .Oxford University Press , 2004 .Sasha Blair - Goldensohn , David Evans , Vasileios Hatzivassiloglou , Kathleen McKeown , Ani Nenkova , Rebecca Passonneau , Barry Schiffman , Andrew Schlaikjer , Advaith Siddharthan , and Sergei Siegelman .", "label": "", "metadata": {}, "score": "63.936035"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . D. Liu , Y. He , D. Ji , and H. Yang , \" Genetic algorithm based multi - document summarization , \" in PRICAI 2006 : Trends in Artificial Intelligence , vol .", "label": "", "metadata": {}, "score": "63.981945"}
{"text": "s .This states that the product of two vectors is given by the product of their norms ( in spatial terms , the length of the vector ) multiplied by the cosine of the angle .s .i . m .", "label": "", "metadata": {}, "score": "64.02966"}
{"text": "pSum - SaDE : A Modified p -Median Problem and Self - Adaptive Differential Evolution Algorithm for Text Summarization .Institute of Information Technology of Azerbaijan National Academy of Sciences , B. Vahabzade Street , 9 , AZ1141 Baku , Azerbaijan .", "label": "", "metadata": {}, "score": "64.1199"}
{"text": "Copyright 2005 ACM 1 - 59593 - 034 - 5/05/0008 ... $ 5.00 .How should we form links in a non - hypertext setting ?Specifically , we emp ... . by Yuhua Li , David Mclean , Zuhair B , James D. O'shea , Keeley Crockett - James O'Shea , Zuhair Bandar and Keeley Crockett . \" ... 1 Abstract : Sentence similarity measures play an increasingly important role in textrelated research and applications in areas such as text mining , web page retrieval and dialogue systems .", "label": "", "metadata": {}, "score": "64.271484"}
{"text": "Selection . \" Survival of the fittest \" can be achieved through the selection operator .The improvement in the average quality of the population can be done by considering good quality chromosome and has to be copied for the next generation .", "label": "", "metadata": {}, "score": "64.39642"}
{"text": "d .s . )We also observe that among other methods the PLSA - JS shows the best results compared to other methods .Compared with the method PLSA - JS the method pSum - SaDE improves the performance by 2.03 % , 2.47 % , and 2.25 % in terms ROUGE-1 , ROUGE-2 , and ROUGE - SU4 metrics , respectively .", "label": "", "metadata": {}, "score": "64.501495"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. Huang , Y. He , F. Wei , and W. Li , \" Modeling document summarization as multi - objective optimization , \" in Proceedings of the 3rd International Symposium on Intelligent Information Technology and Security Informatics , pp .", "label": "", "metadata": {}, "score": "64.69449"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .L. Huang , Y. He , F. Wei , and W. Li , \" Modeling document summarization as multi - objective optimization , \" in Proceedings of the 3rd International Symposium on Intelligent Information Technology and Security Informatics , pp .", "label": "", "metadata": {}, "score": "64.69449"}
{"text": "In this paper , we propose a new framework for email summarization .One novelty is to use a fragment quotation graph to try to capture an email conversation .The second novelty is to use clue words to measure the importance of sentences in conversation summarization .", "label": "", "metadata": {}, "score": "64.737015"}
{"text": "As the text belongs to the educational domain , the genes of the first and last loci are allocated for the first sentence and last sentence of the text , respectively .The genes of the chromosomes are sorted in ascending order after random generation in order to preserve the chronological order of the summary , which helps in better comprehension .", "label": "", "metadata": {}, "score": "65.05046"}
{"text": "To analyze the results , paired .-test is used to compare the mean scores and the significance level of experimental and comparison groups with assistive summary and without assistive summary on comprehension test .There was no significant difference in scores between the two groups , when only the text is provided for comprehension test ( . ) scored high when compared to the comparison group .", "label": "", "metadata": {}, "score": "65.2771"}
{"text": "In 12th Text Retrieval Conference ( TREC 2003 ) .Gaithersburg , MD . , 2003 .( PostScript )( PDF ) .[ Chen and Rambow , 2003 ] .John Chen and Owen Rambow .Use of deep linguistic features for the recognition and labeling of semantic arguments .", "label": "", "metadata": {}, "score": "65.40531"}
{"text": "s .i . m .s .i . m .Now , our objective is to find the binary assignments .[ . . ]and .[ . .] with the high relevancy , best content coverage , and less redundancy such that the summary length is at most .", "label": "", "metadata": {}, "score": "65.50383"}
{"text": "Discourse segmentation of multi - party conversation .In Proceedings of ACL'03 , 2003 .( PostScript )( PDF ) .[ Klavans et al . , 2003 ] .Judith Klavans , Samuel Popper , and Becky Passonneau .Tackling the internet glossary glut : Automatic extraction and evaluation of genus phrases .", "label": "", "metadata": {}, "score": "65.99321"}
{"text": "Modified Crossover .The objective of exploring the search space can be attained using crossover operator .It examines the current solution in order to find the better ones .Crossover in sentence extraction plays the role of exchanging each partial summary of two selected chromosomes in such a way that the offspring produced by the crossover represents single summary .", "label": "", "metadata": {}, "score": "66.33629"}
{"text": "( PostScript )( PDF ) .[ Liscombe et al . , 2003 ] .Jackson Liscombe , Jennifer Venditti , and Julia Hirschberg .Classifying subject ratings of emotional speech using acoustic features .In Proceedings of Eurospeech 2003 , 2003 .", "label": "", "metadata": {}, "score": "66.40302"}
{"text": "To enhance the potential diversity of the population , a crossover operation comes into play after generating the mutant vector through mutation .The mutant vector mixes its components with the target vector .under this operation to form the trial vector .", "label": "", "metadata": {}, "score": "66.46466"}
{"text": "An extract summary consists of sentences extracted from a document while an abstract summary may contain words and phrases which do not exist in the original document [ 11 ] .The sentences are scored using extracted features which are based on importance and readability .", "label": "", "metadata": {}, "score": "66.68713"}
{"text": "Further , the tiny nail regions have been partitioned by the batch RPEM but the EM is not .In other words , the batch RPEM algorithm performs better than the EM algorithm .For the house image , we initially assigned the seed points to be 80 .", "label": "", "metadata": {}, "score": "66.82736"}
{"text": "In Mark Maybury , editor , New Directions In Question Answering .AAAI Press , 2004 .( PDF ) .[ Carlson et al . , 2004 ] .Rolf Carlson , Julia Hirschberg , and Marc Swerts .Prediction of upcoming Swedish prosodic boundaries by Swedish and American listeners .", "label": "", "metadata": {}, "score": "66.82974"}
{"text": "We report results on standard data sets , and show that our graph - based approach performs comparably to the state of the art . \" ...Accessing an ever increasing number of emails , possibly on small mobile devices , has become a major problem for many users .", "label": "", "metadata": {}, "score": "66.83804"}
{"text": "335 - 336 , Melbourne , Australia , 1998 .M. S. Binwahlan , N. Salim , and L. Suanmali , \" MMI diversity based text summarization , \" International Journal of Computer Science and Security , vol .3 , no . 1 , pp .", "label": "", "metadata": {}, "score": "66.979004"}
{"text": "As is evident from Table 6 , the median values of ROUGE-1 , ROUGE-2 , and ROUGE - SU4 scores for pSum - SaDE are better than those for the other methods .To establish that this goodness is statistically significant , Table 7 reports the .", "label": "", "metadata": {}, "score": "67.105865"}
{"text": "View at Google Scholar .View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .X. Cai , W. Li , Y. Ouyang , and H. Yan , \" Simultaneous ranking and clustering of sentences : an reinforcement approach to multi - document summarization , \" in Proceedings of the 23rd", "label": "", "metadata": {}, "score": "67.18455"}
{"text": "As seen , the ranges of the three terms in ( 9 ) are very different .For example , the range of the first term is .[ . 1 . ] , whereas those of the second and third ones are .", "label": "", "metadata": {}, "score": "67.228424"}
{"text": "When sentences in the documents are represented as term vectors , the similarity of two sentences corresponds to the correlation between the vectors .Cohesion .Cohesion is defined as the set of linguistic means available for creating texture [ 40 ] , that is , the property of a text being an interpretable whole ( rather than unconnected sentences ) .", "label": "", "metadata": {}, "score": "67.23605"}
{"text": "C .R .In canonical DE algorithm , the mutation strategy is defined by ( 16 ) , whose parameter .does not change during search process .In our experiment , the scaling factor . is set to 0.5 .", "label": "", "metadata": {}, "score": "67.245"}
{"text": "( PostScript )( PDF ) .Hong Yu , Vasileios Hatzivassiloglou , Andrey Rzhetsky , and John Wilbur .Automatically identifying gene / protein terms in medline abstracts .Journal of Biomedical Informatics , 35(5 - 6):322 - 330 , 2003 .", "label": "", "metadata": {}, "score": "67.42701"}
{"text": "134 - 142 , Beijing , China , 2010 .R. M. Alguliev and R. M. Aliguliyev , \" Evolutionary algorithm for extractive text summarization , \" Intelligent Information Management , vol .1 , no . 2 , pp .128 - 138 , 2009 .", "label": "", "metadata": {}, "score": "67.59704"}
{"text": "134 - 142 , Beijing , China , 2010 .R. M. Alguliev and R. M. Aliguliyev , \" Evolutionary algorithm for extractive text summarization , \" Intelligent Information Management , vol .1 , no . 2 , pp .128 - 138 , 2009 .", "label": "", "metadata": {}, "score": "67.59704"}
{"text": "Flesch - Kincaid predicts the readability of the summary generated using FCBA as better when compared to others , while FOG predicts the summary generated by both FCBA and GA as better .The comparison of readability score of summaries generated through Flesch Kincaid , SMOG , and FOG are shown in Figure 3 .", "label": "", "metadata": {}, "score": "67.79419"}
{"text": "( PDF ) .Jennifer Chu - Carroll , Krzysztof Czuba , John Prager , Abraham Ittycheria , and Sasha Blair - Goldensohn .IBM 's PIQUANT II in TREC 2004 .In 13thText Retrieval Conference ( TREC 2004 ) , Gaithersburg , MD .", "label": "", "metadata": {}, "score": "68.01781"}
{"text": "In VSM , text units of a corpus are represented by vectors .Traditionally a whole document is used as a text unit , but any other text unit like paragraphs or sentences can be used just as well .Each dimension of a vector corresponds to a term that is present in the corpus .", "label": "", "metadata": {}, "score": "68.38133"}
{"text": "-Measure .-measure are tabulated in Table 3 .When the compression ratio is 10 % , GA performs better in summary extraction when compared to modified corpus - based approach [ 30 ] and lead method .When the compression ratio is 20 % , it is better than modified corpus approach with a slight improvement , but when 30 % , the performance is better than the lead method and lower than the modified corpus - based approach .", "label": "", "metadata": {}, "score": "68.42278"}
{"text": "Journal of Bioinformatics , 19(1):340 - 349 , 2003 .( PostScript )( PDF ) .[ Yu and Hatzivassiloglou , 2003 ] .Hong Yu and Vasileios Hatzivassiloglou .Towards answering opinion questions : Separating facts from opinions and identifying the polarity of opinion sentences .", "label": "", "metadata": {}, "score": "68.51091"}
{"text": "The proposed method can be exploited in a variety of applications involving textual knowledge representation and knowledge discovery .Evaluation results on two different data sets show that our method outperforms several competing methods . by Mirella Lapata - In the Intl .", "label": "", "metadata": {}, "score": "68.60176"}
{"text": "The proposed method can be exploited in a variety of applications involving textual knowledge representation and knowledge discovery .Evaluation results on two different data sets show that our method outperforms several competing methods . by Mirella Lapata - In the Intl .", "label": "", "metadata": {}, "score": "68.60176"}
{"text": "The crossover rate CR controls the recombination of target vector and mutant vector to generate trial vector .If the values of some parameters of a newly generated trial vector exceed the corresponding upper and lower bounds , then all the components of the trial vector are checked whether they violate the boundary constraints .", "label": "", "metadata": {}, "score": "68.67922"}
{"text": "y assigning more weight to recall than to precision .In fact , our experiments show that the best correlations are achieved when recall is assigned almost all the weight .Our results show that this is also the case for evaluation of MT .", "label": "", "metadata": {}, "score": "68.682274"}
{"text": "y assigning more weight to recall than to precision .In fact , our experiments show that the best correlations are achieved when recall is assigned almost all the weight .Our results show that this is also the case for evaluation of MT .", "label": "", "metadata": {}, "score": "68.682274"}
{"text": "We clearly observe that our method achieves the highest ROUGE scores and outperforms all the other systems .For comparison we have used the relative improvement .o .u .r . m .e . t .h .o .", "label": "", "metadata": {}, "score": "68.770386"}
{"text": "The informative score can be calculated using feature vectors .where the features vectors of the document can be represented using Vector space model .The vector representation of a given document is shown in Table 1 .The informative score can be calculated by linear combination of all features .", "label": "", "metadata": {}, "score": "69.36771"}
{"text": "1 Abstract : Sentence similarity measures play an increasingly important role in textrelated research and applications in areas such as text mining , web page retrieval and dialogue systems .Existing methods for computing sentence similarity have been adopted from approaches used for long text documents .", "label": "", "metadata": {}, "score": "69.44896"}
{"text": "Detection of topics helps to cover as much as possible themes from the documents .After topics detection to form a summary from each group should be selected such sentences that would be relevant to corresponding topic .For this purpose the informative sentences from each group , that is , median sentences , are selected .", "label": "", "metadata": {}, "score": "69.570724"}
{"text": "X. Wan , \" An exploration of document impact on graph - based multi - document summarization , \" in Proceedings of the Conference on Empirical Methods in Natural Language Processing , pp .755 - 762 , Honolulu , Hawaii , USA , 2008 .", "label": "", "metadata": {}, "score": "69.72651"}
{"text": "( PostScript )( PDF )Papers - Search Results .Eugene Agichtein and Luis Gravano .Querying text databases for efficient information extraction .In IEEE International Conference on Data Engineering , 2003 .( PostScript )( PDF ) .", "label": "", "metadata": {}, "score": "69.772675"}
{"text": "Chromosome Encoding .of the proposed algorithm consists of sequence of positive integers that represent the sentence number of the original text for the summary .To represent the solutions of the sentence extraction problem , effective population coding strategy must be designed .", "label": "", "metadata": {}, "score": "70.08677"}
{"text": "In Proceedings of the 4th International Conference on Language Resources and Evaluation ( LREC 2004 ) , Lisbon , Portugal , May 2004 , 2004 .( PDF ) .Owen Rambow , Lokesh Shrestha , John Chen , and Christy Lauridsen .", "label": "", "metadata": {}, "score": "70.09535"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .J. Tang , L. Yao , and D. Chen , \" Multi - topic based query - oriented summarization , \" in Proceedings of the 9th SIAM International Conference on Data Mining ( SDM ' 09 ) , pp .", "label": "", "metadata": {}, "score": "70.71419"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus .J. Tang , L. Yao , and D. Chen , \" Multi - topic based query - oriented summarization , \" in Proceedings of the 9th SIAM International Conference on Data Mining ( SDM ' 09 ) , pp .", "label": "", "metadata": {}, "score": "70.71419"}
{"text": "137 - 160 , 1981 .View at Google Scholar \u00b7 View at Scopus .R. D. Davis and E. M. Braun , The Gift of Dyslexia : Why Some of the Smartest People Ca n't Read ... and How They Can Learn , Penguin Group , 2010 .", "label": "", "metadata": {}, "score": "71.01718"}
{"text": "Table 4 shows the worst , mean , best , and standard deviation of ROUGE results during 20 runs for each algorithm DE and SaDE .From Table 4 , it is obvious that the worst results obtained by adaptive DE are even better than the best results obtained by DE .", "label": "", "metadata": {}, "score": "71.1463"}
{"text": "Extracting synonymous gene and protein terms from biological literature .In Conference on Intelligent Systems for Molecular Biology , 2003 .( PostScript )( PDF ) .[ Yu and Agichtein , 2003b ] .Hong Yu and Eugene Agichtein .", "label": "", "metadata": {}, "score": "71.152466"}
{"text": "Abstraction can be described as reading and understanding the text to recognize its content , which is then compiled in a concise text .In general , an abstract can be described as summary comprising concepts / ideas taken from the source that are then reinterpreted and presented in a different form , whilst an extract is a summary consisting of units of text taken from the source and presented verbatim [ 10 ] .", "label": "", "metadata": {}, "score": "71.28192"}
{"text": "Columbia 's newsblaster : New features and future directions ( demo ) .In Proceedings of NAACL - HLT'03 , 2003 .( PostScript )( PDF ) .Kathleen McKeown , Noemie Elhadad , and Vasileios Hatzivassiloglou .Leveraging a common representation for personalized search and summarization in a medical digital library .", "label": "", "metadata": {}, "score": "71.67569"}
{"text": "Generating referring expressions in open domains .In 42th Meeting of the Association for Computational Linguistics Annual Conference ( ACL 2004 ) , Barcelona , Spain , 2004 .( PostScript )( PDF ) .[ Siddharthan et al . , 2004 ] .", "label": "", "metadata": {}, "score": "71.762375"}
{"text": "Dataset .We take the DUC 2006 data set as the evaluation corpora [ 44 ] .DUC 2006 provides 50 document sets for evaluation .Each document set includes a fixed number-25 documents .For each topic , four human summarizers are asked to provide a 250-word summary of the topic from the 25 related documents for automatic evaluation .", "label": "", "metadata": {}, "score": "71.9145"}
{"text": "In this paper , we propose a new framework for email summarization .One novelty is to use a fragment quotation grap ... \" .Accessing an ever increasing number of emails , possibly on small mobile devices , has become a major problem for many users .", "label": "", "metadata": {}, "score": "71.93013"}
{"text": "The vector space model represents textual units by counting terms or sequence of terms .Let .represent all the distinct terms occurring in the collection , where . is the number of different terms .Vector Space Model The standard vector space model ( hereinafter referred to as VSM ) is a model for representing text in a vector space based on the bag of words approach .", "label": "", "metadata": {}, "score": "72.356964"}
{"text": "Through evaluations performed on a single - document summarization task for English and Portuguese , we show that the method performs equally well regardless of the language .Moreover , we show how a metasummarizer relying on a layered application of techniques for single - document summarization can be turned into an effective method for multi - document summarization . by Xiaojin Zhu , Andrew B. Goldberg , Jurgen Van , Gael David Andrzejewski - Physics Laboratory - University of Washington , 2007 . \" ...", "label": "", "metadata": {}, "score": "72.45654"}
{"text": "Through evaluations performed on a single - document summarization task for English and Portuguese , we show that the method performs equally well regardless of the language .Moreover , we show how a metasummarizer relying on a layered application of techniques for single - document summarization can be turned into an effective method for multi - document summarization . by Xiaojin Zhu , Andrew B. Goldberg , Jurgen Van , Gael David Andrzejewski - Physics Laboratory - University of Washington , 2007 . \" ...", "label": "", "metadata": {}, "score": "72.45654"}
{"text": "781 - 789 , Athens , Greece , 2009 .R. McDonald , \" A study of global inference algorithms in multi - document summarization , \" in Proceedings of the 29th European Conference on IR Research , LNCS , no .", "label": "", "metadata": {}, "score": "72.69249"}
{"text": "781 - 789 , Athens , Greece , 2009 .R. McDonald , \" A study of global inference algorithms in multi - document summarization , \" in Proceedings of the 29th European Conference on IR Research , LNCS , no .", "label": "", "metadata": {}, "score": "72.69249"}
{"text": "In this paper , we propose a notion of public interest , and show how public interest can boost the performance of question recommendation .In particular , to model public interest in question recommendation , we build a language model to combine relevance score to the query and popularity score regarding question popularity .", "label": "", "metadata": {}, "score": "72.79472"}
{"text": "It can be seen that the texture on the red wall and the green lawn has no longer maintained after the segmentation process both by the EM and the RPEM .However , the small white regions of windows on red wall were disappeared by the EM as well as the triangle shadow area on the wall .", "label": "", "metadata": {}, "score": "73.29546"}
{"text": "In Interspeech 2004 , South Korea , 2004 .( PostScript )( PDF ) .[Muresan , 2004 ] .Smaranda Muresan .Inducing constraint - based grammars using a domain ontology .In Nineth AAAI / SIGART Doctoral Consortium 2004 , 2004 .", "label": "", "metadata": {}, "score": "73.38043"}
{"text": "between two vectors in the VSM .The closer the vectors are to each other the more similar are the sentences .The calculation of an angle between two vectors . can be derived from the Euclidean dot product : . c .", "label": "", "metadata": {}, "score": "73.707535"}
{"text": "th component . is defined as : .( iv ) .is the length ( in words or bytes ) of sentence . , ( v ) .is the length of summary .We attempt to find a subset of the set . that covers the main content of the document collection while reducing the redundancy in the summary .", "label": "", "metadata": {}, "score": "74.093666"}
{"text": "Ani Nenkova , Barry Schiffman , Andrew Schlaiker , Sasha Blair - Goldensohn , Regina Barzilay , Sergey Sigelman , Vasileios Hatzivassiloglou , and Kathleen McKeown .Columbia at the document understanding conference 2003 .In Proceedings of the Document Understanding Workshop ( DUC 2003 ) , 2003 .", "label": "", "metadata": {}, "score": "74.175156"}
{"text": "o .t .h .e . r .w .i . s .e . . .( .Therefore , if the trial vector yields an equal or better value of the objective function , it replaces the corresponding target vector in the next generation ; otherwise the target is retained in the population .", "label": "", "metadata": {}, "score": "74.195854"}
{"text": "Parameter Settings of SaDE Algorithm .The crucial parameters that affect the performance of DE are the population size ( NP ) , crossover rate ( CR ) , and the scaling parameter ( .In the proposed SaDE algorithm the population size , .", "label": "", "metadata": {}, "score": "74.213455"}
{"text": "that is set by the user is generally a key factor affecting the DE 's performance .Choosing suitable value of . is difficult for DE , which is usually problem dependent .Therefore , since introduction , a large body of research has been done to study the performance of DE and to improve its performance .", "label": "", "metadata": {}, "score": "74.242004"}
{"text": "Here , the crossover between two parent chromosomes is possible only if there is a common gene between them at the same position .The crossover probability depends on the degree of randomness in the genes of the parent chromosome .Modified Mutation .", "label": "", "metadata": {}, "score": "74.45526"}
{"text": "Rebecca Passonneau .Computing reliability for coreference annotation .In Proceedings of the Language Resources and Evaluation Conference ( LREC 2004 ) , 2004 .( PostScript )( PDF ) .Dragomir Radev , Tim Allison , Sasha Blair - Goldensohn , John Blitzer , Arda Celebi , Elliott Drabek , Wai Lam , Danyu Liu , Jahna Otterbacher , Hong Qi , Horacio Saggion , Simone Teufel , Michael Topper , Adam Winkel , and Zhu Zhang .", "label": "", "metadata": {}, "score": "75.102905"}
{"text": "P .the recall of .S .K .I .P . is the combination function .One potential problem for ROUGE- . is that it does not give any credit to a candidate sentence if the sentence does not have any word pair co - occurring with its references .", "label": "", "metadata": {}, "score": "75.16174"}
{"text": "( PostScript )( PDF ) .[Shrestha and McKeown , 2004 ] .Lokesh Shrestha and Kathleen McKeown .Detection of question - answer pairs in email conversations .In Proceedings of Coling 2004 , 2004 .( PostScript )", "label": "", "metadata": {}, "score": "75.28284"}
{"text": "S .L .C .S . and skip - bigram cooccurrence averaged with unigram cooccurrence ( ROUGE - SU ) .The way ROUGE- . is calculated is identical to that of ROUGE-2 , except that skip bigrams are defined as subsequences rather than the regular definition of bigrams as substrings .", "label": "", "metadata": {}, "score": "75.74373"}
{"text": "i . m .s .i . m .s .i . m . subject to .where . is the summary and . is the concatenation operation .Sentence concatenation is the operation of joining two sentences end to end .", "label": "", "metadata": {}, "score": "76.07224"}
{"text": "2862 - 2867 , Hyderabad , India , 2007 .X. Wan , \" An exploration of document impact on graph - based multi - document summarization , \" in Proceedings of the Conference on Empirical Methods in Natural Language Processing , pp .", "label": "", "metadata": {}, "score": "76.1037"}
{"text": "( PDF ) .[ Venditti and Hirschberg , 2003 ] .Jennifer Venditti and Julia Hirschberg .Intonation and discourse processing .In Proceedings of ICPhS'03 , 2003 .( PostScript )( PDF ) .[ Yu and Agichtein , 2003a ] .", "label": "", "metadata": {}, "score": "76.111946"}
{"text": "The act of comprehending entails three essential elements , namely , ( 1 ) the reader , ( 2 ) the text , and ( 3 ) the activity [ 8 ] .For learners with reading difficulty , the activity element ( summarization ) can be used to improve reading comprehension .", "label": "", "metadata": {}, "score": "76.1459"}
{"text": "( PostScript )( PDF ) .[ Nenkova and McKeown , 2003 ] .Ani Nenkova and Kathleen McKeown .References to named entities : a corpus study .In Proceedings of NAACL - HLT'03 , 2003 .( PostScript )", "label": "", "metadata": {}, "score": "76.551445"}
{"text": "o .u .n .t .g .r . a .m . ) is the number of .-grams in the reference summaries .ROUGE- . computes the ratio between the length of the summaries ' longest common subsequence ( LCS ) and the length of the reference summary : .", "label": "", "metadata": {}, "score": "79.03488"}
{"text": "-gram , .C .o .u .n .t .m . a .t .c . h .g .r . a .m . ) is the maximum number of .-grams co - occurring in candidate summary and the set of reference - summaries .", "label": "", "metadata": {}, "score": "79.073944"}
{"text": "f .i .s .f .t .f .l .o .g . in a sentence . is defined by the product of the local weight of term . in sentence .and the global weight of term . . . .", "label": "", "metadata": {}, "score": "79.116196"}
{"text": "( PDF ) Use of Genetic Algorithm for Cohesive Summary Extraction to Assist Reading Difficulties .Department of Computer Applications , National Institute of Technology , Tiruchirappalli 620015 , India .Received 4 March 2013 ; Revised 30 April 2013 ; Accepted 23 May 2013 .", "label": "", "metadata": {}, "score": "79.149124"}
{"text": "Introduction .Students with learning difficulties are diverse in nature , and the difficulties include reading difficulties , math difficulties , writing difficulties , and other problems related with the learning process .About 8 % to 10 % of students are having learning difficulties [ 1 ] .", "label": "", "metadata": {}, "score": "80.22261"}
{"text": "In 4th Document Understanding Conference ( DUC 2004 ) at HLT / NAACL 2004 , Boston , MA , 2004 .( PostScript )( PDF ) .Sasha Blair - Goldensohn , Kathleen R. McKeown , and Andrew Hazen Schlaikjer .", "label": "", "metadata": {}, "score": "81.007675"}
{"text": "( PDF ) .[ Elhadad , 2004 ] .Noemie Elhadad .User - sensitive text summarization .In AAAI Doctoral Consortium , 2004 .( PostScript )( PDF ) .[ Elson , 2004 ] .David Elson .", "label": "", "metadata": {}, "score": "82.22612"}
{"text": "The learner is given easy to read important sentences which increases his / her interest and motivation .The objective questions focus much on evaluating recall , recognize , and on analysis or comprehension type questions of Blooms taxonomy .It is clear from the questions answered by the learners that the summary helps them in answering literal questions better than analytical questions .", "label": "", "metadata": {}, "score": "82.500305"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . Y. Ouyang , S. Li , and W. Li , \" Developing learning strategies for topic - based summarization , \" in Proceedings of the 16th ACM Conference on Information and Knowledge Management ( CIKM ' 07 ) , pp .", "label": "", "metadata": {}, "score": "82.50563"}
{"text": "View at Publisher \u00b7 View at Google Scholar \u00b7 View at Scopus . Y. Ouyang , S. Li , and W. Li , \" Developing learning strategies for topic - based summarization , \" in Proceedings of the 16th ACM Conference on Information and Knowledge Management ( CIKM ' 07 ) , pp .", "label": "", "metadata": {}, "score": "82.50563"}
{"text": "In INLG 2004 , 2004 .David Farwell , Stephen Helmreich , Florence Reed , Bonnie Dorr , Nizar Habash , Eduard Hovy , Lori Levin , Keith Miller , Teruko Mitamura , Owen Rambow , and Advaith Siddharthan .Interlingual annotation of multilingual text corpora .", "label": "", "metadata": {}, "score": "82.74717"}
{"text": "[ Siddharthan , 2004 ] .Advaith Siddharthan .Syntactic simplification and text cohesion .Journal of Language and Computation , Kluwer Academic Publishers , the Netherlands , 2004 .( PostScript )( PDF ) .[ Siddharthan and Copestake , 2004 ] .", "label": "", "metadata": {}, "score": "86.68212"}
{"text": "o .s .Mathematical Formulation of Problem .First , we introduce the following variables and notations : ( i ) .i .f .s .e . n .t .e . n .c .e . i . s .", "label": "", "metadata": {}, "score": "87.62076"}
{"text": "n . h .A .I . is the hyperbolic tangent function : . t . a .n .h .e . x .p .e . x .p .e . x .p .e . x . p .", "label": "", "metadata": {}, "score": "88.07648"}
{"text": "View at Google Scholar .National Reading Panel , Teaching Children to Read : An Evidence - Based Assessment of the Scientific Research Literature on Reading and Its Implications for Reading Instruction , National Institute of Child Health and Human Development , National Institutes of Health , 2000 .", "label": "", "metadata": {}, "score": "91.69177"}
{"text": "o .t .h .e . r . m .e . t .h .o .d .s . )o .t .h .e . r . m .e . t .h .", "label": "", "metadata": {}, "score": "93.701614"}
{"text": "r . a .m . )S . u . m . m .r .e . f .g .r . a .m .C .o .u .n .t .g .r . a .", "label": "", "metadata": {}, "score": "94.03013"}
{"text": "I .P .S .K .I .P .S .K .I .P .S .K .I .P .S .K .I .P . and .S .K .", "label": "", "metadata": {}, "score": "96.50344"}
{"text": "m .i .n .i .f .m .i .n . m . a .x .i .f .m . a .x .o .t .h .e . r .", "label": "", "metadata": {}, "score": "96.94801"}
{"text": "e .( ii ) .i .f .s .e . n .t .e . n .c .e . i .s . a .l .l .o .c . a .", "label": "", "metadata": {}, "score": "97.296486"}
{"text": "S .K .I .P .S .K .I .P .S .K .I .P .S .K .I .P .S .K .I .P .S .", "label": "", "metadata": {}, "score": "97.89041"}
{"text": "This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .Abstract .Learners with reading difficulties normally face significant challenges in understanding the text - based learning materials .", "label": "", "metadata": {}, "score": "98.992874"}
{"text": "e . d .t .o .m .e . d .i . a .n .o .t .h .e . r .w .i . s .e .( iii ) .", "label": "", "metadata": {}, "score": "100.78232"}
{"text": "i .f .r . a .n .d .C .R .o .r .r . a .n .d .o .t .h .e . r .w .i . s .", "label": "", "metadata": {}, "score": "102.47003"}
{"text": "e . l .e . c . t .e . d . a .s .m .e . d .i . a .n .o .t .h .e . r .w .", "label": "", "metadata": {}, "score": "102.840775"}
{"text": "S . u . m . m .r .e . f .g .r . a .m .C .o .u .n .t .m . a .t .c . h .", "label": "", "metadata": {}, "score": "104.558846"}
{"text": "C .S .L .C .S .L .C .S .L .C .S .L .C .S .L .C .S .L .C .S .L .", "label": "", "metadata": {}, "score": "109.67759"}
{"text": "Academic Editor : Sheng - yong Chen .Copyright \u00a9 2012 Jiechang Wen et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "114.14586"}
{"text": "Copyright \u00a9 2011 Rasim M. Alguliev et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "115.44566"}
{"text": "Copyright \u00a9 2011 Rasim M. Alguliev et al .This is an open access article distributed under the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited .", "label": "", "metadata": {}, "score": "115.44566"}
