{"text": "Sometimes , the basic selectional - restriction matching procedure can not completely disambiguate the word senses of a given lexeme .In this case , the authors present different back - up strategies , such as dynamic tightening of selectional restrictions or comparing distances in ontological space .", "label": "", "metadata": {}, "score": "27.72803"}
{"text": "Sometimes , the basic selectional - restriction matching procedure can not completely disambiguate the word senses of a given lexeme .In this case , the authors present different back - up strategies , such as dynamic tightening of selectional restrictions or comparing distances in ontological space .", "label": "", "metadata": {}, "score": "27.72803"}
{"text": "Despite the persistence of this theory , however , there is widespread agreement about its empirical shortcomings ( McCawley , 1968 ; Fodor , 1977 ) .As an alternative , some critics of the Katz - Fodor theory ( e.g. ( Johnson - Laird , 1983 ) ) have abandoned the treatment of selectional constraints as semantic , instead treating them as indistinguishable from inferences made on the basis of factual knowledge .", "label": "", "metadata": {}, "score": "35.574074"}
{"text": "That 's an adequate answer , but the truth is that the primary disambiguation strategy employed here is not selectional restrictions at all , but a parallelism constraint .There is a preference to understand a conjuction \" and \" as connecting two similar entities , rather than two dissimilar entities .", "label": "", "metadata": {}, "score": "38.10826"}
{"text": "Deterministic annealing is used to find lowest distortion sets of clusters : as the an-nealing parameter increases , existing clusters become unstable and subdivide , yielding a hierarchi- cal \" soft \" clustering of the data .Clusters are used as the basis for class models of word coocurrence , and the models evaluated with respect to held - out test data . .", "label": "", "metadata": {}, "score": "38.939125"}
{"text": "We describe and evaluate experimentally a method for clustering words according to their dis- tribution in particular syntactic contexts .Words are represented by the relative frequency distributions of contexts in which they appear , and relative entropy between those distributions is used as the si ... \" .", "label": "", "metadata": {}, "score": "41.961952"}
{"text": "In this dissertation , I suggest that an answer to this question lies in the representation of conceptual . \" ... Introduction An impressive array of statistical methods have been developed for word sense identification .They range from dictionary - based approaches that rely on definitions ( Vronis and Ide 1990 ; Wilks et al .", "label": "", "metadata": {}, "score": "42.16922"}
{"text": "Therefore , proper names are already discovered by a preprocessing component of the analyser .Other unattested input is processed by the available morphological , syntactic and semantic analyzers to assign as many features to it as possible given the fact that no lexicon entry is available .", "label": "", "metadata": {}, "score": "42.45716"}
{"text": "Therefore , proper names are already discovered by a preprocessing component of the analyser .Other unattested input is processed by the available morphological , syntactic and semantic analyzers to assign as many features to it as possible given the fact that no lexicon entry is available .", "label": "", "metadata": {}, "score": "42.45716"}
{"text": "If you use selectional restriction , explain what are the features , the relation , and the constraint involved .If you use frequency in context , explain how the context is established by other parts of the sentence .If you use world knowledge , explain the rules being used .", "label": "", "metadata": {}, "score": "42.736115"}
{"text": "If you use selectional restriction , explain what are the features , the relation , and the constraint involved .If you use frequency in context , explain how the context is established by other parts of the sentence .If you use world knowledge , explain the rules being used .", "label": "", "metadata": {}, "score": "42.736115"}
{"text": "First , the advantages and disadvantages of generative vs. enumerative lexicons are discussed and the authors explain why they think that every good lexicon , including ontological semantic ones , should be capable of accommodating novel meanings and therefore be generative .", "label": "", "metadata": {}, "score": "43.847763"}
{"text": "First , the advantages and disadvantages of generative vs. enumerative lexicons are discussed and the authors explain why they think that every good lexicon , including ontological semantic ones , should be capable of accommodating novel meanings and therefore be generative .", "label": "", "metadata": {}, "score": "43.847763"}
{"text": "Specifically , the proposed measure is a combined approach that inherits the edge - based approach of the edge counting scheme , which is then enhanced by the node - based approach of the information content calculation .When tested on a common data set of word pair similarity ratings , the proposed approach outperforms other computational models .", "label": "", "metadata": {}, "score": "44.01191"}
{"text": "It combines a lexical taxonomy structure with corpus statistical information so that the semantic distance between nodes in the semantic space constructed by the taxonomy can be better quantifie ... \" .This paper presents a new approach for measuring semantic similarity / distance between words and concepts .", "label": "", "metadata": {}, "score": "45.051483"}
{"text": "Still they did not explain any completely automatic methods for acquiring them , but only some tools to facilitate the whole process for the linguist a little bit .It might be interesting to see what other methods could fit here into the theory of ontological semantics to gain an easier acquisition of new resources and save time and money for new applications .", "label": "", "metadata": {}, "score": "45.29744"}
{"text": "Still they did not explain any completely automatic methods for acquiring them , but only some tools to facilitate the whole process for the linguist a little bit .It might be interesting to see what other methods could fit here into the theory of ontological semantics to gain an easier acquisition of new resources and save time and money for new applications .", "label": "", "metadata": {}, "score": "45.29744"}
{"text": "n tendencies into associations of words to certain hidden senses classes and associations between the classes themselves .More specifically , we model senses as probabilistic concepts or clusters c with corresponding clus ... . \" ...Selectional constraints are limitations on the applicability of predicates to arguments .", "label": "", "metadata": {}, "score": "45.643078"}
{"text": "Semantic analysis interprets the meaning of each individual sentence , based on the meanings of the words and the syntax of the sentence .The input is the parse tree constructed by the syntactic analysis .The output is a symbolic representation of the meaning of the sentence .", "label": "", "metadata": {}, "score": "45.70389"}
{"text": "Semantic analysis interprets the meaning of each individual sentence , based on the meanings of the words and the syntax of the sentence .The input is the parse tree constructed by the syntactic analysis .The output is a symbolic representation of the meaning of the sentence .", "label": "", "metadata": {}, "score": "45.70389"}
{"text": "What is the value of the standard error function for this perceptron ?B. Find a set of weights and a threshhold that categorizes all this data correctly .( Hint : Sketch a graph of the instances in the plane where the coordinates are A and B. ) Natural Language Processing .", "label": "", "metadata": {}, "score": "45.727833"}
{"text": "What is the value of the standard error function for this perceptron ?The total error is therefore 1.0 .B. Find a set of weights and a threshhold that categorizes all this data correctly .( Hint : Sketch a graph of the instances in the plane where the coordinates are A and B. ) Sample problems from 2nd half of course .", "label": "", "metadata": {}, "score": "45.86872"}
{"text": "Since the object is the abstract entity \" prohibition \" , the relation involved can not be \" on top of \" .Problem 2 .Explain how each of the ambiguities specified below can be resolved using selectional restrictions or world knowledge .", "label": "", "metadata": {}, "score": "46.234367"}
{"text": "We first describe an algorithm for converting the hierarchical structure of WordNet [ 13 ] ... \" .We discuss a method for augmenting and rearranging a structured lexicon in order to make it more suitable for a topic labeling task , by making use of lexical association information from a large text corpus .", "label": "", "metadata": {}, "score": "46.25699"}
{"text": "We then use lexical cooccurrence statistics in combination with these categories to classify proper names , assign more specific senses to broadly defined terms , and classify new words into existing categories .We also describe how to use these statistics to assign schema - like information to the categories and show how the new categories improve a text - labeling algorithm .", "label": "", "metadata": {}, "score": "46.889736"}
{"text": "Inheritance mechanisms are available and also multiple inheritance is allowed , although seldom used in real applications until now .Semantic properties describe the nature of objects and events in the ontology , such as physical properties , inherent properties , is - a - properties , and also properties specifying the semantic arguments ( i.e. case roles for predicates ) .", "label": "", "metadata": {}, "score": "47.069153"}
{"text": "Inheritance mechanisms are available and also multiple inheritance is allowed , although seldom used in real applications until now .Semantic properties describe the nature of objects and events in the ontology , such as physical properties , inherent properties , is - a - properties , and also properties specifying the semantic arguments ( i.e. case roles for predicates ) .", "label": "", "metadata": {}, "score": "47.069153"}
{"text": "Problem 7 .List the major modules of a natural language interpretation system and explain their function .Answer : .Morphological analysis identifies the structure of each individual word , separating it into a root word ( or words ) combined with prefixes , suffixes , and inflections .", "label": "", "metadata": {}, "score": "47.617226"}
{"text": "Problem 7 .List the major modules of a natural language interpretation system and explain their function .Answer : .Morphological analysis identifies the structure of each individual word , separating it into a root word ( or words ) combined with prefixes , suffixes , and inflections .", "label": "", "metadata": {}, "score": "47.617226"}
{"text": "Thereby , processes at the suprapositional level consists of reference and coreference phenomena , temporal ordering within TMRs and discourse relations .The preprocessing is again divided into different phases : tokenization and morphological analysis , lexical lookup , syntactic analysis .", "label": "", "metadata": {}, "score": "48.021362"}
{"text": "Thereby , processes at the suprapositional level consists of reference and coreference phenomena , temporal ordering within TMRs and discourse relations .The preprocessing is again divided into different phases : tokenization and morphological analysis , lexical lookup , syntactic analysis .", "label": "", "metadata": {}, "score": "48.021362"}
{"text": "In addition , the authors explain different architectures , such as the stratified model , the flat model and the constraint - satisfaction model ; the latter being largely adopted in ontological semantics .Also the relations of ontological semantics to the non - semantic components of an NLP system and the development of ontological semantics over the last years are briefly outlined .", "label": "", "metadata": {}, "score": "48.051685"}
{"text": "In addition , the authors explain different architectures , such as the stratified model , the flat model and the constraint - satisfaction model ; the latter being largely adopted in ontological semantics .Also the relations of ontological semantics to the non - semantic components of an NLP system and the development of ontological semantics over the last years are briefly outlined .", "label": "", "metadata": {}, "score": "48.051685"}
{"text": "Introduction An impressive array of statistical methods have been developed for word sense identification .They range from dictionary - based approaches that rely on definitions ( Vronis and Ide 1990 ; Wilks et al .1993 ) to corpus - based approaches that use only word cooccurrence frequencies extracted from large textual corpora ( Schfitze 1995 ; Dagan and Itai 1994 ) .", "label": "", "metadata": {}, "score": "48.406586"}
{"text": "D. Propagating modification to weights on the arcs from the output layer to the input layer . E.Adding nodes and links in the hidden layers .F. Both adding and deleting nodes and links in the hidden layers .Long Answer Problems .", "label": "", "metadata": {}, "score": "48.936146"}
{"text": "The word \" high \" can be disambiguated by selectional restrictions .Only entitities with a physical location can be elevated , whereas neither \" taxes \" or \" inheritances \" characteristically have a physical location .Disambiguating \" they \" requires reasoning that a reason for reducing X is that X is too large .", "label": "", "metadata": {}, "score": "49.038868"}
{"text": "The automatic disambiguation of word senses has been an interest and concern since the earliest days of computer treatment of language in the 1950 's .Sense disambiguation is an \" intermediate task \" ( Wilks and Stevenson , 1996 ) which is not an end in itself , but rather is necessary at one level o ... \" .", "label": "", "metadata": {}, "score": "49.08212"}
{"text": "Furthermore , they discuss the relationship between ontological matching and lexical constrains .The fact repository can be semi - automatically acquired by means of information extraction techniques used on web pages .Finally Chapter 10 gives a short conclusion and an outlook on future work areas .", "label": "", "metadata": {}, "score": "49.141228"}
{"text": "Furthermore , they discuss the relationship between ontological matching and lexical constrains .The fact repository can be semi - automatically acquired by means of information extraction techniques used on web pages .Finally Chapter 10 gives a short conclusion and an outlook on future work areas .", "label": "", "metadata": {}, "score": "49.141228"}
{"text": "We also conclude that events that occur only once in the training set have major impact on similarity - based estimates . by Marti A. Hearst , Hinrich Sch\u00fctze - Proc . of the Workshop on Extracting Lexical Knowledge , 1996 . \" ...", "label": "", "metadata": {}, "score": "49.49414"}
{"text": "This can not be done automatically at the moment , but requires trained people to work on this task .The lexicon can at least be acquired by some automatic support .In addition , ontological semantics uses lexical rules to derive the properties of some deverbal adjectives from their corresponding verbs for example , such as ' abhorrent ' from ' abhor ' .", "label": "", "metadata": {}, "score": "50.109665"}
{"text": "This can not be done automatically at the moment , but requires trained people to work on this task .The lexicon can at least be acquired by some automatic support .In addition , ontological semantics uses lexical rules to derive the properties of some deverbal adjectives from their corresponding verbs for example , such as ' abhorrent ' from ' abhor ' .", "label": "", "metadata": {}, "score": "50.109665"}
{"text": "In addition , they discuss possibilities to represent synonyms and paraphrases in TMR .Chapter 7 explains the different static knowledge sources , such as the ontology , the fact repository and the lexicons and their relations .The ontology consists of definitions of concepts representing classes of objects or events in the real world .", "label": "", "metadata": {}, "score": "50.198082"}
{"text": "In addition , they discuss possibilities to represent synonyms and paraphrases in TMR .Chapter 7 explains the different static knowledge sources , such as the ontology , the fact repository and the lexicons and their relations .The ontology consists of definitions of concepts representing classes of objects or events in the real world .", "label": "", "metadata": {}, "score": "50.198082"}
{"text": "Each entry contains information on the lexical category , the orthography , phonology , morphology , syntax , etc .In the onomasticon , proper nouns can be found .Chapter 8 outlines the basic processing mechanisms in ontological semantic text analysis .", "label": "", "metadata": {}, "score": "50.199726"}
{"text": "Each entry contains information on the lexical category , the orthography , phonology , morphology , syntax , etc .In the onomasticon , proper nouns can be found .Chapter 8 outlines the basic processing mechanisms in ontological semantic text analysis .", "label": "", "metadata": {}, "score": "50.199726"}
{"text": "Furthermore , the chapter discusses sentential meaning and the relation to the meaning of the words in detail .In ontological semantics , semantic meaning is defined as a text - meaning expression obtained through the application of rules for syntactic analysis , for linking syntactic and semantic dependencies and for establishing the meaning of lexical units .", "label": "", "metadata": {}, "score": "50.290092"}
{"text": "Furthermore , the chapter discusses sentential meaning and the relation to the meaning of the words in detail .In ontological semantics , semantic meaning is defined as a text - meaning expression obtained through the application of rules for syntactic analysis , for linking syntactic and semantic dependencies and for establishing the meaning of lexical units .", "label": "", "metadata": {}, "score": "50.290092"}
{"text": "The two traditions complement each other .Corpus - based approaches have the advantage of being generally applicable to new texts , domains , and corpora without needing costly and perhaps error - prone parsing or semantic analysis .They require only training corpora in which the sense distinctions have been marked , but therein lies their weakness .", "label": "", "metadata": {}, "score": "50.418488"}
{"text": "Problem 8 . A. Give an example of a sentence or pair of sentences in which selectional restrictions can be used to disambiguate potential anaphoric ambiguity .Explain the ambiguity and the selectional restriction used .Answer : There are lots of answers .", "label": "", "metadata": {}, "score": "50.491104"}
{"text": "Problem 8 . A. Give an example of a sentence or pair of sentences in which selectional restrictions can be used to disambiguate potential anaphoric ambiguity .Explain the ambiguity and the selectional restriction used .Answer : There are lots of answers .", "label": "", "metadata": {}, "score": "50.491104"}
{"text": "In the language modeling task , a similarity - based model is used to improve probability estimates for unseen bigrams in a back - off language model .The similaritybased method yields a 20 % perplexity improvement in the prediction of unseen bigrams and statistically significant reductions in speech - recognition error .", "label": "", "metadata": {}, "score": "50.83074"}
{"text": "The authors also explain the relation between theories and methodologies associated with them .In addition , this chapter discusses practical applications of theories and their influence on relations between theories and methodologies .Finally , the authors describe how this philosophical approach can be used to characterize and analyze ontological semantics .", "label": "", "metadata": {}, "score": "51.22953"}
{"text": "The authors also explain the relation between theories and methodologies associated with them .In addition , this chapter discusses practical applications of theories and their influence on relations between theories and methodologies .Finally , the authors describe how this philosophical approach can be used to characterize and analyze ontological semantics .", "label": "", "metadata": {}, "score": "51.22953"}
{"text": "Statistical NLP methods determine the likelihood of a word combination from its frequency in a training corpus .However , the nature of language is such that many word combinations are infrequent and do not occur in any given corpus .In this work we propose a method for estimating the probability of such previously unseen word combinations using available information on \" most similar \" words .", "label": "", "metadata": {}, "score": "51.486797"}
{"text": "It is built on microtheories covering such diverse areas as specific language phenomena , processing heuristics , and implementation system architecture .All these theories are coordinated at the level of knowledge acquisition and runtime system architecture implementation .The second part deals with the content of ontological semantics .", "label": "", "metadata": {}, "score": "52.19026"}
{"text": "It is built on microtheories covering such diverse areas as specific language phenomena , processing heuristics , and implementation system architecture .All these theories are coordinated at the level of knowledge acquisition and runtime system architecture implementation .The second part deals with the content of ontological semantics .", "label": "", "metadata": {}, "score": "52.19026"}
{"text": "Words are represented by the relative frequency distributions of contexts in which they appear , and relative entropy between those distributions is used as the similarity measure for clustering .Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership .", "label": "", "metadata": {}, "score": "52.524628"}
{"text": "Sense disambiguation is an \" intermediate task \" ( Wilks and Stevenson , 1996 ) which is not an end in itself , but rather is necessary at one level or another to accomplish most natural language processing tasks .It is . by Lillian Lee , Fernando C. N. Pereira , Claire Cardie , Raymond Mooney - Machine Learning , 1999 . \" ... Abstract .", "label": "", "metadata": {}, "score": "52.636337"}
{"text": "The propositions are units of semantic representation corresponding to single predications in context ( typically realized as clauses ) .This means that the TMR results above all from the process of disambiguation by the analyzer .Therefore , ontological semantics uses semantic selectional restrictions stored in the lexicon and the ontology described in detail in chapter 8 .", "label": "", "metadata": {}, "score": "52.68747"}
{"text": "The propositions are units of semantic representation corresponding to single predications in context ( typically realized as clauses ) .This means that the TMR results above all from the process of disambiguation by the analyzer .Therefore , ontological semantics uses semantic selectional restrictions stored in the lexicon and the ontology described in detail in chapter 8 .", "label": "", "metadata": {}, "score": "52.68747"}
{"text": "In addition , the chapter summarizes the ideas on compositional semantics and their influence on ontological semantics .The authors also discuss key ideas from other semantic traditions and evaluate them against ontological semantics .Chapter 4 , together with chapter 3 , relates ontological semantics to other important semantic approaches and issues .", "label": "", "metadata": {}, "score": "53.209015"}
{"text": "In addition , the chapter summarizes the ideas on compositional semantics and their influence on ontological semantics .The authors also discuss key ideas from other semantic traditions and evaluate them against ontological semantics .Chapter 4 , together with chapter 3 , relates ontological semantics to other important semantic approaches and issues .", "label": "", "metadata": {}, "score": "53.209015"}
{"text": "What is the value of the standard error function for this perceptron ?The total error is therefore 1.0 .B. Find a set of weights and a threshhold that categorizes all this data correctly .( Hint : Sketch a graph of the instances in the plane where the coordinates are A and B. ) Tools . by Jay J. Jiang , David W. Conrath - Proc of 10th International Conference on Research in Computational Linguistics , ROCLING'97 , 1997 . \" ...", "label": "", "metadata": {}, "score": "53.4035"}
{"text": "Raskin , V. and S. Nirenburg .Adjectival Modification in Text Meaning Representation .Proceedings of COLING 96 .Schank , R. and R. Abelson .Scripts , Plans , Goals and Understanding .Hillsdale .NJ : Erlbaum .Searle , J. ( 1969 )", "label": "", "metadata": {}, "score": "53.52202"}
{"text": "Raskin , V. and S. Nirenburg .Adjectival Modification in Text Meaning Representation .Proceedings of COLING 96 .Schank , R. and R. Abelson .Scripts , Plans , Goals and Understanding .Hillsdale .NJ : Erlbaum .Searle , J. ( 1969 )", "label": "", "metadata": {}, "score": "53.52202"}
{"text": "Last but not least , an axiomatic definition of the ontology is given .The fact repository includes records of past experience .Therefore , you can find in the fact repository instances of ontological concepts .The lexicon contains a collection of entries indexed with their citation form in the languages available in the system .", "label": "", "metadata": {}, "score": "53.705017"}
{"text": "Last but not least , an axiomatic definition of the ontology is given .The fact repository includes records of past experience .Therefore , you can find in the fact repository instances of ontological concepts .The lexicon contains a collection of entries indexed with their citation form in the languages available in the system .", "label": "", "metadata": {}, "score": "53.705017"}
{"text": "C. Propagating modification to weights on the arcs from the input layer to the output layer .D. Propagating modification to weights on the arcs from the output layer to the input layer . E.Adding nodes and links in the hidden layers .", "label": "", "metadata": {}, "score": "53.93267"}
{"text": "C. Propagating modification to weights on the arcs from the input layer to the output layer .D. Propagating modification to weights on the arcs from the output layer to the input layer . E.Adding nodes and links in the hidden layers .", "label": "", "metadata": {}, "score": "53.93267"}
{"text": "The book only briefly mentions some examples , but a complete workflow is missing and would be interesting to get a general impression of the power of this approach .Another interesting application for ontological semantics might be dialogue processing which is only very briefly mentioned in this book .", "label": "", "metadata": {}, "score": "54.825108"}
{"text": "The book only briefly mentions some examples , but a complete workflow is missing and would be interesting to get a general impression of the power of this approach .Another interesting application for ontological semantics might be dialogue processing which is only very briefly mentioned in this book .", "label": "", "metadata": {}, "score": "54.825108"}
{"text": "Chapter 9 deals with the acquisition of static knowledge sources for ontological semantics .The authors explain the immense effort necessary to develop such natural language resources , both in time and in trained human resources .Therefore , automatic knowledge acquisition is desirable .", "label": "", "metadata": {}, "score": "55.37388"}
{"text": "Chapter 9 deals with the acquisition of static knowledge sources for ontological semantics .The authors explain the immense effort necessary to develop such natural language resources , both in time and in trained human resources .Therefore , automatic knowledge acquisition is desirable .", "label": "", "metadata": {}, "score": "55.37388"}
{"text": "Which of the following expresses the independence assumption that is used in deriving the formula for Naive Bayesian learning , for the classification problem in problem ? ? ?Problem 12 .Consider the following data set T. A and B are numerical attributes and Z is a Boolean classification .", "label": "", "metadata": {}, "score": "55.387695"}
{"text": "The output is a set of morphemes .Syntactic analysis finds the grammatical structure of each individual sentence , described as a parse tree ( plus transformations ) .The input is a single sentence , plus the output of the morphological analysis on the words of the sentence .", "label": "", "metadata": {}, "score": "55.423065"}
{"text": "The output is a set of morphemes .Syntactic analysis finds the grammatical structure of each individual sentence , described as a parse tree ( plus transformations ) .The input is a single sentence , plus the output of the morphological analysis on the words of the sentence .", "label": "", "metadata": {}, "score": "55.423065"}
{"text": "Chapter 1 gives an introduction to ontological semantics .The approach is centered around the metaphor of an intelligent agent .Therefore , two intelligent agents are necessary at least : The discourse producer and the discourse consumer .The model consists of the following dynamic knowledge sources : an analyzer , a generator , and a module for world knowledge maintenance and reasoning .", "label": "", "metadata": {}, "score": "55.48615"}
{"text": "Chapter 1 gives an introduction to ontological semantics .The approach is centered around the metaphor of an intelligent agent .Therefore , two intelligent agents are necessary at least : The discourse producer and the discourse consumer .The model consists of the following dynamic knowledge sources : an analyzer , a generator , and a module for world knowledge maintenance and reasoning .", "label": "", "metadata": {}, "score": "55.48615"}
{"text": "Then the authors explain the text meaning representation ( TMR ) giving different examples .The TMR includes the lexical information and the results of morphological and syntactic analysis of the input text .Therefore , the text meaning representation uses two basic means : instantiation of ontological concepts and instantiation of semantic parameters not connected to the ontology .", "label": "", "metadata": {}, "score": "55.54707"}
{"text": "Then the authors explain the text meaning representation ( TMR ) giving different examples .The TMR includes the lexical information and the results of morphological and syntactic analysis of the input text .Therefore , the text meaning representation uses two basic means : instantiation of ontological concepts and instantiation of semantic parameters not connected to the ontology .", "label": "", "metadata": {}, "score": "55.54707"}
{"text": "Problem 2 .Problem 3 .Compositional semantics is . A. The principle that the meaning of a sentence is derived by combining the meanings of the words in a mode indicated by the syntactic structure .B. A technique for applying world knowledge to semantic interpretation .", "label": "", "metadata": {}, "score": "55.63128"}
{"text": "The object of the action \" slice \" must have the feature CONCRETE OBJECT ; since \" taxes \" does not have this feature , that interpretation of \" cut \" is excluded .( Selectional restriction ) .The meaning \" physically elevated \" can only apply to entities with the features \" PHYSICAL OBJECT \" , which is not a feature of either \" taxes \" or \" inheritances \" ( generally ) , the two possible antecedents for \" they \" .", "label": "", "metadata": {}, "score": "55.99856"}
{"text": "Problem 2 .Answer : E. .Problem 3 .Compositional semantics is . A. The principle that the meaning of a sentence is derived by combining the meanings of the words in a mode indicated by the syntactic structure .B. A technique for applying world knowledge to semantic interpretation .", "label": "", "metadata": {}, "score": "56.10833"}
{"text": "Problem 2 .Answer : E. .Problem 3 .Compositional semantics is . A. The principle that the meaning of a sentence is derived by combining the meanings of the words in a mode indicated by the syntactic structure .B. A technique for applying world knowledge to semantic interpretation .", "label": "", "metadata": {}, "score": "56.10833"}
{"text": "Problem 8 . A. Give an example of a sentence or pair of sentences in which selectional restrictions can be used to disambiguate potential anaphoric ambiguity .Explain the ambiguity and the selectional restriction used .B. Give an example of a sentence or pair of sentences in which there is a potential anaphoric ambiguity that can not be disambiguated using selectional restrictions .", "label": "", "metadata": {}, "score": "56.121742"}
{"text": "Answer : Obviously , selectional restrictions do not apply , since John and his father are entities of the same kind with the same features .Note also that the first \" his \" must unambiguously refer to \" John \" .", "label": "", "metadata": {}, "score": "57.040035"}
{"text": "\" This can be ruled out by selectional restrictions : it requires an animate object , unlike \" driving \" .B. \" driving \" can mean : .i. forcing an object to move against resistance , as above .ii .", "label": "", "metadata": {}, "score": "57.585358"}
{"text": "\" This can be ruled out by selectional restrictions : it requires an animate object , unlike \" driving \" .B. \" driving \" can mean : .i. forcing an object to move against resistance , as above .ii .", "label": "", "metadata": {}, "score": "57.585358"}
{"text": "Given a multidimensional space upon which a node represents a 2unique concept consisting of a certain amount of information , and an edge represents a direct association between two concepts , ... .by Fernando Pereira , Naftali Tishby , Lillian Lee - In Proceedings of the 31st", "label": "", "metadata": {}, "score": "58.120827"}
{"text": "In this problem and in problem 11 , we consider a data set with three Boolean predictive attributes , A , B , C , and a Boolean classification , Z. . A. Suppose that your data is completely characterized by the following rules : .", "label": "", "metadata": {}, "score": "58.48342"}
{"text": "In this problem and in problem 11 , we consider a data set with three Boolean predictive attributes , A , B , C , and a Boolean classification , Z. . A. Suppose that your data is completely characterized by the following rules : .", "label": "", "metadata": {}, "score": "58.48342"}
{"text": "( Selectional restriction . )The causal chain \" A reduces X because X is too large \" is coherent .The causal chain \" A reduces X , a penalty associated with Y , because Y is too large , \" is much less coherent .", "label": "", "metadata": {}, "score": "58.539665"}
{"text": "( d ) and ( f ) are independence assumptions , but not the ones we need .( a ) and ( e ) are junk .Problem 12 ( 10 points )Consider the following data set T. A and B are numerical attributes and Z is a Boolean classification .", "label": "", "metadata": {}, "score": "58.69922"}
{"text": "( d ) and ( f ) are independence assumptions , but not the ones we need .( a ) and ( e ) are junk .Problem 12 ( 10 points )Consider the following data set T. A and B are numerical attributes and Z is a Boolean classification .", "label": "", "metadata": {}, "score": "58.69922"}
{"text": "The first section explains the need for philosophical discussions in general and in the field of computational linguistics in particular .Then the authors give definitions for the main components in scientific theories , such as purview , premises , body , and justification .", "label": "", "metadata": {}, "score": "59.322384"}
{"text": "The first section explains the need for philosophical discussions in general and in the field of computational linguistics in particular .Then the authors give definitions for the main components in scientific theories , such as purview , premises , body , and justification .", "label": "", "metadata": {}, "score": "59.322384"}
{"text": "\" Ontological semantics \" is an interesting and valuable contribution to the NLP community .It offers a clear outline of the theory of ontological semantics and explains the differences to other theories and traditions .Especially the first part of the book is very theoretical and might not be easy to read , especially for beginners in semantics .", "label": "", "metadata": {}, "score": "60.610725"}
{"text": "\" Ontological semantics \" is an interesting and valuable contribution to the NLP community .It offers a clear outline of the theory of ontological semantics and explains the differences to other theories and traditions .Especially the first part of the book is very theoretical and might not be easy to read , especially for beginners in semantics .", "label": "", "metadata": {}, "score": "60.610725"}
{"text": "( World knowledge ) .C. Resolve the syntactic ambiguities of the prepositional phrase attachments in the sentence \" We have to write a paper on prohibition for \" Twentieth Century American History \" by Monday . \"( Compare : \" We have to read a book on prescription drug benefits for senior citizens by an expert on Medicare . \" )", "label": "", "metadata": {}, "score": "60.859985"}
{"text": "At the worst , one can use the complete decision tree , where all tests on all attributes are made , and so each different instance is represented by one leaf .Problem 11 ( 5 points ) Which of the following expresses the independence assumption that is used in deriving the formula for Naive Bayesian learning , for the classification problem in problem 3 .", "label": "", "metadata": {}, "score": "61.214035"}
{"text": "At the worst , one can use the complete decision tree , where all tests on all attributes are made , and so each different instance is represented by one leaf .Problem 11 ( 5 points ) Which of the following expresses the independence assumption that is used in deriving the formula for Naive Bayesian learning , for the classification problem in problem 3 .", "label": "", "metadata": {}, "score": "61.214035"}
{"text": "Petra Gieselmann , Interactive Systems Lab , University of Karlsruhe .This book aims to describe a comprehensive approach called ontological semantics to the treatment of text meaning by various NLP - applications , such as machine translation , information extraction , etc .", "label": "", "metadata": {}, "score": "62.021507"}
{"text": "Problem 9 .Consider the sentence \" Hammers are for driving nails into surfaces .\" Name two words in this sentence that are lexically ambiguous .( There are at least four . )For each of these two words , describe a disambiguation technique which will choose the right interpretation over at least one of the wrong interpretations .", "label": "", "metadata": {}, "score": "62.277534"}
{"text": "Problem 9 .Consider the sentence \" Hammers are for driving nails into surfaces .\" Name two words in this sentence that are lexically ambiguous .( There are at least four . )For each of these two words , describe a disambiguation technique which will choose the right interpretation over at least one of the wrong interpretations .", "label": "", "metadata": {}, "score": "62.277534"}
{"text": "Be specific .Problem 10 .In this problem and in problem 10 , we consider a data set with three Boolean predictive attributes , A , B , C , and a Boolean classification , Z. . A. Suppose that your data is completely characterized by the following rules : .", "label": "", "metadata": {}, "score": "62.60165"}
{"text": "Selectional restrictions ( NLU 10.1 & 10.2 ) Semantic grammars ( NLU 11.2 ) Word - sense disambiguation ( NLU 10.4 )Homework : selectional restrictions .Anaphora .Local discourse context and coreference ( NLU chapter 14 ) Handling anaphora in information extraction Homework : anaphora .", "label": "", "metadata": {}, "score": "62.8226"}
{"text": "The chapter explains the differences between ontology and natural language giving some examples of crosslinguistic semantic divergences which result in problems for multilingual ontologies .Chapter 6 is the first chapter of the second part .It deals with meaning representation in ontological semantics .", "label": "", "metadata": {}, "score": "63.16114"}
{"text": "The chapter explains the differences between ontology and natural language giving some examples of crosslinguistic semantic divergences which result in problems for multilingual ontologies .Chapter 6 is the first chapter of the second part .It deals with meaning representation in ontological semantics .", "label": "", "metadata": {}, "score": "63.16114"}
{"text": "The similarity - based methods perform up to 40 % better on this particular task .We al ... \" .We compare four similarity - based estimation methods against back - off and maximum - likelihood estimation methods on a pseudo - word sense disambiguation task in which we controlled for both unigram and bigram frequency .", "label": "", "metadata": {}, "score": "64.314705"}
{"text": "Syntax analysis , cont'd : .Chart parsers ( NLU , 3.4 & 3.6 ) Morphological processing ( NLU , 3.7 ) Limitations of context - free analysis ; augmented grammars ( NLU , 4.1 ) English feature systems ( NLU 4.2 )", "label": "", "metadata": {}, "score": "65.47967"}
{"text": "But in this case they mean the same thing ; We will write about prohibition , and the paper will be about prohibition .Syntactically , \" for ' Twentieth Century American History ' \" can attach either to \" prohibition \" , to \" paper \" , or to \" write \" .", "label": "", "metadata": {}, "score": "65.6598"}
{"text": "ii .motion through a boundary into the interior of another region , as above . iv . \" against \" as in \" He ran into a brick wall \" .Here , I think , one has to rely on world knowledge that a hammer is used to drive a nail through the surface of an object into its interior .", "label": "", "metadata": {}, "score": "65.72064"}
{"text": "ii .motion through a boundary into the interior of another region , as above . iv . \" against \" as in \" He ran into a brick wall \" .Here , I think , one has to rely on world knowledge that a hammer is used to drive a nail through the surface of an object into its interior .", "label": "", "metadata": {}, "score": "65.72064"}
{"text": "B. True or false : Given any consistent set of rules like those above , it is possible to construct a decision tree that executes that set of rules .By \" consistent \" , I mean that there are no examples where two different rules give different answers .", "label": "", "metadata": {}, "score": "65.958115"}
{"text": "B. True or false : Given any consistent set of rules like those above , it is possible to construct a decision tree that executes that set of rules .By \" consistent \" , I mean that there are no examples where two different rules give different answers .", "label": "", "metadata": {}, "score": "65.958115"}
{"text": "B. True or false : Given any consistent set of rules like those above , it is possible to construct a decision tree that executes that set of rules .By \" consistent \" , I mean that there are no examples where two different rules give different answers .", "label": "", "metadata": {}, "score": "65.958115"}
{"text": "That can perhaps be justified purely on grounds of grammatical frequency ; attaching prepositional phrases to a proper noun is comparatively rare , though certainly possible .G. Joe hurt his chances of getting the job by showing up an hour late to the interview .", "label": "", "metadata": {}, "score": "66.84261"}
{"text": "Answer : World knowledge .Shutters are part of a house , not part of a door .It is unusual to go places carrying shutters .In the seventh inning , the pitcher was replaced ' ' .Answer : Frequency in context .", "label": "", "metadata": {}, "score": "66.87912"}
{"text": "Answer : World knowledge .Shutters are part of a house , not part of a door .It is unusual to go places carrying shutters .In the seventh inning , the pitcher was replaced ' ' .Answer : Frequency in context .", "label": "", "metadata": {}, "score": "66.87912"}
{"text": "The first \" his \" can be disambiguated using the rule that , if X effects a result using speech , it is almost always using X 's own speech , rather than someone else 's speech .The disambiguation of the second \" his \" is really quite difficult ; one needs some substantial body of knowledge about typical insults to realize that it is more likely for X to insult Y by talking about Y 's clothes than by talking about X 's own clothes .", "label": "", "metadata": {}, "score": "67.18071"}
{"text": "Problem 4 .Bayes ' Law states that .Answer : D. .Problem 5 .In a feed - forward , back - propagation network , learning proceeds by . A. Propagating activation levels from the input layer to the output layer .", "label": "", "metadata": {}, "score": "67.34946"}
{"text": "Problem 4 .Bayes ' Law states that .Answer : D. .Problem 5 .In a feed - forward , back - propagation network , learning proceeds by . A. Propagating activation levels from the input layer to the output layer .", "label": "", "metadata": {}, "score": "67.34946"}
{"text": "If there is evidence that the recipient of the proposal was a unique person and there is no indication of the content of the proposal , then the default interpretation is \" proposed to X that they get married \" .In this case , the content is quite clearly unconnected to marriage , so that default does not apply .", "label": "", "metadata": {}, "score": "67.68146"}
{"text": "Facts of world knowledge : .The giver of a present is rarely the same as the recipient .A person is more likely to receive than to give a present on his birthday ( among us ; the hobbits have the opposite custom . )", "label": "", "metadata": {}, "score": "67.91604"}
{"text": "I asked about the attachment . \" on prohibition \" can be attached either to \" paper \" or to \" write \" .This is actually genuinely ambiguous ; it is an instance of the category , not rare in English , of syntactic ambiguities that do n't actually make any difference .", "label": "", "metadata": {}, "score": "68.66366"}
{"text": "Give a method for carrying out the disambiguation .Problem 9 .Consider the sentence \" Hammers are for driving nails into surfaces .\" Name two words in this sentence that are lexically ambiguous .( There are at least four . )", "label": "", "metadata": {}, "score": "69.27685"}
{"text": "The similaritybased methods perform up to 40 % better on this particular task . ...Sections 2.3.1 and 2.3.2 discuss two related information - theoretic functions , the KL divergence and the Jensen - Shannon divergence .Section 2.3.3 describes the L 1 norm , ... . by Ido Dagan , Lillian Lee , Fernando Pereira - In Proceedings of the Association for Computational Linguistics , 1997 . \" ...", "label": "", "metadata": {}, "score": "69.29637"}
{"text": "Chapter 5 discusses the differences between ontological semantics and other ontological efforts .The first section places ontology in the context of metaphysics .The authors discuss formal ontology and its contributions to ontological semantics as far as theoretical and also practical issues are concerned .", "label": "", "metadata": {}, "score": "70.53915"}
{"text": "Chapter 5 discusses the differences between ontological semantics and other ontological efforts .The first section places ontology in the context of metaphysics .The authors discuss formal ontology and its contributions to ontological semantics as far as theoretical and also practical issues are concerned .", "label": "", "metadata": {}, "score": "70.53915"}
{"text": "Your explanation should specify what are the constraints and the features involved .Comment : It was careless on my part that 6 out of the 7 examples could be resolved on the ANIMATE feature . A. Resolve the lexical ambiguity of \" pitcher \" in \" The pitcher drank a cup of coffee . \"", "label": "", "metadata": {}, "score": "70.578384"}
{"text": "Approximate schedule of classes .Computational linguistics : applications and approaches ( NLU , chapter 1 ) Begin : principal syntactic structures of English ( NLU , chapter 2 ) Homework : Studying paraphrase in news stories .Syntax analysis : .", "label": "", "metadata": {}, "score": "70.833176"}
{"text": "According to the influential theo ... \" .Selectional constraints are limitations on the applicability of predicates to arguments .For example , the statement \" The number two is blue \" may be syntactically well formed , but at some level it is anomalous - BLUE is not a predicate that can be applied to numbers .", "label": "", "metadata": {}, "score": "70.93678"}
{"text": "Problem 4 .Bayes ' Law states that .Problem 5 .In a feed - forward , back - propagation network , learning proceeds by . A. Propagating activation levels from the input layer to the output layer .B. Propagating activation levels from the output layer to the input layer .", "label": "", "metadata": {}, "score": "71.30354"}
{"text": "( Actually , there are other meanings of \" wore \" -- \" She wore a smile \" , \" The lecture wore me out \" etc .but none that allows a lawsuit as object . )Sentence B can be disambiguated using frequency in context .", "label": "", "metadata": {}, "score": "71.89992"}
{"text": "( Actually , there are other meanings of \" wore \" -- \" She wore a smile \" , \" The lecture wore me out \" etc .but none that allows a lawsuit as object . )Sentence B can be disambiguated using frequency in context .", "label": "", "metadata": {}, "score": "71.89992"}
{"text": "Scoping phenomena and resolution ( NLU 12.1 - 3 ) Application to data - base access ( NLU 12.3 ) .Representing and using world knowledge ( NLU chapters 13 & 15 ) .Dialog ( NLU chapter 17 ) .Natural language applications : .", "label": "", "metadata": {}, "score": "72.24162"}
{"text": "E.g. ( ii ) requires a car as object ; ( iii ) and ( v ) require animate objects , etc . .C. \" nails \" can be either the tool or fingernails .However , frequency in the context of \" hammer \" gives a preference for the tool . D. \" into \" can mean .", "label": "", "metadata": {}, "score": "74.03386"}
{"text": "E.g. ( ii ) requires a car as object ; ( iii ) and ( v ) require animate objects , etc . .C. \" nails \" can be either the tool or fingernails .However , frequency in the context of \" hammer \" gives a preference for the tool . D. \" into \" can mean .", "label": "", "metadata": {}, "score": "74.03386"}
{"text": "What disambiguation strategy can be used ? ) D. Joe 's head hurts him .F. Sam hurt Joe with his rude remarks about his clothes .G. Joe hurt his chances of getting the job by showing up an hour late to the interview .", "label": "", "metadata": {}, "score": "74.173836"}
{"text": "A due date \" by Monday \" can only apply to an event , such as \" write \" , not to \" paper \" or \" Twentieth - Century American History .\" What follows is a review or discussion note contributed to our Book Discussion Forum .", "label": "", "metadata": {}, "score": "74.27551"}
{"text": "F. Sam hurt Joe with his rude remarks about his clothes .Answer : The word \" hurt \" can be disambiguated using selectional restrictions on the instrument \" with ... remarks \" ; the instrument of \" cause physical pain \" must be a physical object , not remarks .", "label": "", "metadata": {}, "score": "74.40744"}
{"text": "This can be derived by selectional restrictions ; the actor must be animate . E. Joe 's head hurts him .Answer : World knowledge : It is less likely that a person 's own body part is causing them pain than that it is in pain .", "label": "", "metadata": {}, "score": "75.2092"}
{"text": "Cambridge : Cambridge University Press .Petra Gieselmann has a M.A. in Computational Linguistics .Currently , she works at the university of Karlsruhe in the Interacitve Systems Lab towards her PhD. Her research interest lies in the field of dialogue management and speech understanding .", "label": "", "metadata": {}, "score": "76.28"}
{"text": "If you are interested in leading a book discussion , look for books announced on LINGUIST as \" available for review . \" Then contact Sheila Dooley at collberg linguistlist.org .This book aims to describe a comprehensive approach called ontological semantics to the treatment of text meaning by various NLP - applications , such as machine translation , information extraction , etc .", "label": "", "metadata": {}, "score": "76.47887"}
{"text": "Explain why not .Give a method for carrying out the disambiguation .Answer : \" Margaret invited Susan for lunch but she declined .\" The anaphoric ambiguity of \" she \" can not be resolved by selectional restrictions , since Margaret and Susan have all the same features .", "label": "", "metadata": {}, "score": "76.977905"}
{"text": "Explain why not .Give a method for carrying out the disambiguation .Answer : \" Margaret invited Susan for lunch but she declined .\" The anaphoric ambiguity of \" she \" can not be resolved by selectional restrictions , since Margaret and Susan have all the same features .", "label": "", "metadata": {}, "score": "76.977905"}
{"text": "Cambridge : Cambridge University Press .ABOUT THE REVIEWER .Petra Gieselmann has an M.A. in Computational Linguistics .Currently , she works at the university of Karlsruhe in the Interacitve Systems Lab towards her PhD. Her research interest lies in the field of dialogue management and speech understanding .", "label": "", "metadata": {}, "score": "77.59454"}
{"text": "\" The choice of attaching this to \" paper \" or to \" write \" is again a distinction without a difference .Syntactically , \" by Monday \" can attach to \" History \" , to \" paper \" or to \" write \" .", "label": "", "metadata": {}, "score": "78.27203"}
{"text": "That this is the key disambiguation strategy here can be seen from the following two examples .G. Resolve the lexical ambiguity of the word \" on \" in the sentence \" We have to write a paper on prohibition for \" Twentieth Century American History \" by Monday . \"", "label": "", "metadata": {}, "score": "79.03703"}
{"text": "\" When I cut the steak with my knife , I found that it was undercooked \" ( Contrast \" ... its blade broke off its handle \" ) . \"Undercooked \" can only modify an object with feature FOOD ; hence \" it \" can be \" steak \" but not \" knife \" .", "label": "", "metadata": {}, "score": "79.641205"}
{"text": "\" When I cut the steak with my knife , I found that it was undercooked \" ( Contrast \" ... its blade broke off its handle \" ) . \"Undercooked \" can only modify an object with feature FOOD ; hence \" it \" can be \" steak \" but not \" knife \" .", "label": "", "metadata": {}, "score": "79.641205"}
{"text": "Assigned : Nov. 17 Due : Dec. 3 .Note : This is due in TWO weeks .If you are submitting this by email , please send it to Ernie Davis , davise@cs.nyu.edu , not to the TA .Problem 1 .", "label": "", "metadata": {}, "score": "79.99497"}
{"text": "They were very excited . \"Answer : The adjective \" excited \" must modify an object that is has the feature ANIMATE ; hence , not toys .D. Resolve the anaphoric ambiguity of \" They \" in \" The children got new toys for Christmas , but they all broke within half an hour . \"", "label": "", "metadata": {}, "score": "80.35811"}
{"text": "Problem 1 .cook : noun , verb eggs : noun fish : noun , verb .Which of the following parse tree are correct : . A. All four .B. Only ( i ) C. ( i ) , ( iii ) , and ( iv ) . D. ( i ) and ( iii ) . E. ( i ) and ( iv ) .", "label": "", "metadata": {}, "score": "80.82411"}
{"text": "Chapter 3 deals with the history of semantics and different philosophical and linguistic traditions .First , the chapter briefly describes the roots of linguistic semantics starting already with Plato .The authors explain the different semantic traditions covering also diachronic semantics and examinations on the historical meaning change .", "label": "", "metadata": {}, "score": "82.35209"}
{"text": "Chapter 3 deals with the history of semantics and different philosophical and linguistic traditions .First , the chapter briefly describes the roots of linguistic semantics starting already with Plato .The authors explain the different semantic traditions covering also diachronic semantics and examinations on the historical meaning change .", "label": "", "metadata": {}, "score": "82.35209"}
{"text": "Syntax analysis , cont'd : .Feature grammar and parser ( NLU 4.3 - 4.5 )Grammar : verb groups ( NLU 5.1 )Homework : feature grammar .Syntax analysis , cont'd : .Semantic analysis : .Semantics and logical form ( NLU chapter 8.1 - 8.6 ) Information templates for information extraction Homework : logical form .", "label": "", "metadata": {}, "score": "82.41231"}
{"text": "B. Emily cuts Anne whenever they meet , because she was once noisily drunk at Emily 's dinner party .Answer : The word \" cuts \" can be disambiguated using world knowledge ; it is possible for one person to physically cut another once or twice , but it would be peculiar for this to happen habitually .", "label": "", "metadata": {}, "score": "83.83883"}
{"text": "E. Resolve the syntactic ambiguity of the conjunction in \" The captain of the ship and the first mate swam to shore . \"( Is it \" The captain of [ the ship and the first mate ] \" or \" [ The captain of the ship ] and the first mate . \" Hence \" the first mate \" can not be conjoined with ship .", "label": "", "metadata": {}, "score": "83.91585"}
{"text": "Answer : Selectional restrictions .The subject of ' ' ate ' ' must be ANIMATE : ' ' wooden club ' ' is not ANIMATE .I went up to the door of the house with the red shutters '' [ ' ' with the red shutters ' ' is attached to ' ' house ' ' not ' ' door ' ' or ' ' went ' ' .", "label": "", "metadata": {}, "score": "84.02748"}
{"text": "Answer : Selectional restrictions .The subject of ' ' ate ' ' must be ANIMATE : ' ' wooden club ' ' is not ANIMATE .I went up to the door of the house with the red shutters '' [ ' ' with the red shutters ' ' is attached to ' ' house ' ' not ' ' door ' ' or ' ' went ' ' .", "label": "", "metadata": {}, "score": "84.02748"}
{"text": "Problems : . A. President Bush proposes to cut taxes on inheritances because they are too high .Answer : \" proposes \" can be disambiguated using frequency in context .In a political context ( established by \" President Bush \" and \" taxes \" ) , the meaning \" proposes marriage \" is rare . \" cut \" can be disambiguated using selectional restrictions .", "label": "", "metadata": {}, "score": "84.84523"}
{"text": "( 4 ) and ( 5 ) together are supporting evidence that the birthday involved is John 's , rather than supposing that a 16 year old father will be giving a car to an infant John .B. President Bush proposed to cut taxes on inheritances because they are too high .", "label": "", "metadata": {}, "score": "84.926346"}
{"text": "Multiple choice problems .Problem 1 .cook : noun , verb eggs : noun fish : noun , verb .Which of the following parse tree are correct : . A. All four .B. Only ( i ) C. ( i ) , ( iii ) , and ( iv ) . D. ( i ) and ( iii ) . E. ( i ) and ( iv ) .", "label": "", "metadata": {}, "score": "85.0022"}
{"text": "iii . impelling a person to undesired behaviors ( as in \" driving me crazy \" , \" driving me to drink \" ) .quite a few other specialized meanings ( iv . \" driving \" in golf , v. \" driving cattle \" , etc . ) .", "label": "", "metadata": {}, "score": "85.081665"}
{"text": "iii . impelling a person to undesired behaviors ( as in \" driving me crazy \" , \" driving me to drink \" ) .quite a few other specialized meanings ( iv . \" driving \" in golf , v. \" driving cattle \" , etc . ) .", "label": "", "metadata": {}, "score": "85.081665"}
{"text": "Date : Tue , 17 May 2005 13:50:43 +0200 From : Petra Gieselmann Subject : Ontological Semantics .AUTHORS : Nirenburg , Sergei ; Raskin , Victor TITLE : Ontological Semantics SERIES : Language , Speech , and Communication PUBLISHER : MIT Press YEAR :", "label": "", "metadata": {}, "score": "85.52567"}
{"text": "Linking syntax and semantics ( NLU , 9.1 - 9.3 )Building IE templates Homework : building simple templates .Semantic analysis , cont'd : .Linking syntax and semantics , cont'd Interpreting questions ( NLU 9.5 )Homework : semantic interpretation rules .", "label": "", "metadata": {}, "score": "87.41621"}
{"text": "Introduction to Artificial Intelligence : Problem Set 4 .Assigned : Feb. 12 Due : Feb 21 ( Feb. 19 is a holiday ) .Problem 1 : .For each of the ambiguities listed below , explain how it can be disambiguated using either selectional restrictions , frequency in context ( for lexical ambiguity ) , or world knowledge .", "label": "", "metadata": {}, "score": "88.3958"}
{"text": "Introduction to Artificial Intelligence : Problem Set 4 .Assigned : Feb. 12 Due : Feb 21 ( Feb. 19 is a holiday ) .Problem 1 : .For each of the ambiguities listed below , explain how it can be disambiguated using either selectional restrictions , frequency in context ( for lexical ambiguity ) , or world knowledge .", "label": "", "metadata": {}, "score": "88.3958"}
{"text": "Sample problems from 2nd half of course .Multiple choice problems .Problem 1 .cook : noun , verb eggs : noun fish : noun , verb .Which of the following parse tree are correct : . A. All four .", "label": "", "metadata": {}, "score": "88.86583"}
{"text": "B. Resolve the lexical ambiguity of \" pitcher \" in \" Joe poured a cup of coffee from the pitcher \" .( Same ambiguity as in ( A ) ; different decision . )Answer : The source of a \" pouring \" action must have the feature CONTAINER ; hence , not the baseball player .", "label": "", "metadata": {}, "score": "92.69574"}
{"text": "Answer : D. .Long Answer Problems .Problem 6 .Consider the following pair of sentences : A. Joe wore a wool suit .The suit is in the court .Explain how the disambiguation techniques of selectional restriction and frequency in context can be applied in these two sentences .", "label": "", "metadata": {}, "score": "93.06024"}
{"text": "Answer : D. .Long Answer Problems .Problem 6 .Consider the following pair of sentences : A. Joe wore a wool suit .The suit is in the court .Explain how the disambiguation techniques of selectional restriction and frequency in context can be applied in these two sentences .", "label": "", "metadata": {}, "score": "93.06024"}
{"text": "Consider the following pair of sentences : A. Joe wore a wool suit .The suit is in the court .Explain how the disambiguation techniques of selectional restriction and frequency in context can be applied in these two sentences .Problem 7 .", "label": "", "metadata": {}, "score": "94.258514"}
{"text": "Therefore , relaxation of selectional restrictions in the ontology is possible so that sentences such as ' The baby ate a piece of paper . 'or non - literal meanings such as ' The pianist played Bach . 'can be resolved .", "label": "", "metadata": {}, "score": "99.61296"}
{"text": "Therefore , relaxation of selectional restrictions in the ontology is possible so that sentences such as ' The baby ate a piece of paper . 'or non - literal meanings such as ' The pianist played Bach . 'can be resolved .", "label": "", "metadata": {}, "score": "99.61296"}
{"text": "For example , a speech recognizer may need to determine which of the two word combinations \" eat a peach \" and \" eat a beach \" is more likely .Statistical NLP met ... \" .Abstract .In many applications of natural language processing ( NLP ) it is necessary to determine the likelihood of a given word combination .", "label": "", "metadata": {}, "score": "100.00552"}
{"text": "The disambiguation of \" she \" requires the world knowledge that X being noisily drunk at Y 's party is a social offense that may result in Y snubbing X. .C. Sam hurt Joe with a baseball bat .Answer : Selectional restictions on the instrumentality of a physical object \" baseball \" suggest the meaning \" caused pain \" .", "label": "", "metadata": {}, "score": "100.5047"}
{"text": "A person does not generally receive a car until he / she is nearly 16 years old .From ( 3 ) it follows that \" he \" is not John ; hence \" he \" is the father .From ( 1 ) it follows that \" him \" is John .", "label": "", "metadata": {}, "score": "102.285416"}
{"text": "Problems : . A. President Bush proposes to cut taxes on inheritances because they are too high .B. Emily cuts Anne whenever they meet , because she was once noisily drunk at Emily 's dinner party .C. Sam hurt Joe with a baseball bat . D. The baseball bat hurt Joe .", "label": "", "metadata": {}, "score": "102.67551"}
{"text": "( Is it \" [ the red beard and the glass eye ] \" or \" [ The man with the red beard ] and the glass eye \" ? )Answer : The subject of the verb \" swam \" must have the feature ANIMATE ; hence , not the glass eye .", "label": "", "metadata": {}, "score": "106.51808"}
{"text": "( Why would it important in semantic processing to distinguish this from the meaning in sentence ( C ) ?What disambiguation strategy can be used ? )Answer : It is important to recognize that here \" baseball bat \" , the grammatical subject of \" hurt \" is the instrument of the action \" cause pain \" , whereas in sentence ( C ) \" Sam \" , the grammatical subject , is the actor .", "label": "", "metadata": {}, "score": "107.728"}
{"text": "Answer : . A. The preposition \" for \" has many different meanings .Even in the phrase \" are for \" it can mean : .i. \" are used for \" as above .ii .\" favors \" as in \" Cheney is for burning more fossil fuel and against conserving resources .", "label": "", "metadata": {}, "score": "110.97175"}
{"text": "Answer : . A. The preposition \" for \" has many different meanings .Even in the phrase \" are for \" it can mean : .i. \" are used for \" as above .ii .\" favors \" as in \" Cheney is for burning more fossil fuel and against conserving resources .", "label": "", "metadata": {}, "score": "110.97175"}
