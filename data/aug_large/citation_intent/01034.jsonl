{"text": "On a broader perspective our approach contributes to a better understanding on where corpuslinguistics and theoretical linguistics can meet and enrich each other .The need of large - scale corpora for higherlevel syntactic frameworks is addressed in Sadler et al ( 2000 ) , Frank ( 2000 ) , Frank et al ( 2001 ) , who develop methods to enrich treebanks with higher - level ... . by", "label": "", "metadata": {}, "score": "34.04339"}
{"text": "On a broader perspective our approach contributes to a better understanding on where corpuslinguistics and theoretical linguistics can meet and enrich each other .The need of large - scale corpora for higherlevel syntactic frameworks is addressed in Sadler et al ( 2000 ) , Frank ( 2000 ) , Frank et al ( 2001 ) , who develop methods to enrich treebanks with higher - level ... . by", "label": "", "metadata": {}, "score": "34.04339"}
{"text": "More specifically , each verb occurring in the Treebank has been treated as a semantic predicate and the surrounding text has been annotated for arguments and adjuncts of the predicate .The verbs have also been tagged with coarse grained senses and with inflectional information .", "label": "", "metadata": {}, "score": "34.674854"}
{"text": "We have coordinated with Roberto Navigli and Ken Litkowski so that their Coarse - grained All - Words task annotates the same data .Since there is no training data for this task there is no Closed track .Track : Open track -- participants can use any additional data , including the entire Treebank and PropBank ( if they are LDC members ) .", "label": "", "metadata": {}, "score": "36.39833"}
{"text": ", 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs of a statistical parser ( Collins , 2000 ) and ranking sentence plans ( Walker , Rambow and Rogati , 2001 ) .", "label": "", "metadata": {}, "score": "38.493156"}
{"text": ", 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs of a statistical parser ( Collins , 2000 ) and ranking sentence plans ( Walker , Rambow and Rogati , 2001 ) .", "label": "", "metadata": {}, "score": "38.493156"}
{"text": "Treebanks are important resources in descriptive , theoretical and computational linguistic research , development and teaching .This paper presents a treebank tool suite ( TTS ) for and derived from the Penn - II treebank resource ( Marcus et al , 1993 ) .", "label": "", "metadata": {}, "score": "39.519875"}
{"text": "We have supplied a 5000 word chunk of WSJ where all of the verbs and the head words of the verb arguments have WordNet 2.1 sense tags .This is for testing purposes only , and has no training annotation associated with it , or PropBank or VerbNet labels .", "label": "", "metadata": {}, "score": "39.68869"}
{"text": "In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the coverage of harid - crafted grammars .", "label": "", "metadata": {}, "score": "40.181576"}
{"text": "In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the coverage of harid - crafted grammars .", "label": "", "metadata": {}, "score": "40.181576"}
{"text": "The conversion and grammar extraction process imports linguistic generalisations that are missing the in original treebank .This supports the extraction of a linguistically sound grammar with maximal generalisation , as well as grammar induction techniques to capture unseen data in stochastic parsing .", "label": "", "metadata": {}, "score": "40.715004"}
{"text": "The conversion and grammar extraction process imports linguistic generalisations that are missing the in original treebank .This supports the extraction of a linguistically sound grammar with maximal generalisation , as well as grammar induction techniques to capture unseen data in stochastic parsing .", "label": "", "metadata": {}, "score": "40.715004"}
{"text": "On the other hand , special rules for their treatment should also be included in the system .Identifying multiword expressions is not unequivocal since constructions with similar syntactic structure ( e.g. verb + noun combinations ) can belong to different subclasses on the productivity scale ( i.e. productive combinations , light verb constructions and idioms ) .", "label": "", "metadata": {}, "score": "42.22352"}
{"text": "This is all terribly problematic for the \" traditional \" parsing model of first running tokenization , then running analysis .The problem is that the tokenization depends on the analysis and vice - versa .At least with the Penn approach , there 's code to do their ad hoc sentence splitting and then their ad hoc heuristic tokenization .", "label": "", "metadata": {}, "score": "42.402542"}
{"text": "3,324 such files have been created , totalling about 5.5 MB of uncompressed data .The Annotation .There are approximately 113,000 annotated verb tokens .These verb tokens include all those occurring in over one million words of the Wall Street Journal section of the Penn Treebank , excluding ' be ' and auxiliary uses of ' do ' and ' have . '", "label": "", "metadata": {}, "score": "42.79546"}
{"text": "In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .Because of the highly lexicalized nature of the LTAG formalism , we experimentally show that notions other than sentence length play a factor in observed parse times .", "label": "", "metadata": {}, "score": "43.54738"}
{"text": "In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .Because of the highly lexicalized nature of the LTAG formalism , we experimentally show that notions other than sentence length play a factor in observed parse times .", "label": "", "metadata": {}, "score": "43.54738"}
{"text": "VerbNet class membership and VerbNet thematic role labels for the same targets .Charniak parses .This will support a second subtask for SRL , in both PropBank style and VerbNet style .We propose that the SRL subtask have two evaluation tracks .", "label": "", "metadata": {}, "score": "43.549507"}
{"text": "We extract different LTAGs from the Penn Treebank .We show that certain strategies yield an improved extracted LTAG in terms of compactness , broad coverage , and supertagging accuracy .Furthermore , we perform a preliminary investigation in smoothing these grammars by means of an external linguistic resource , namely , the tree families of an XTAG grammar , a hand built grammar of English . by Hans Van Halteren , Jakub Zavrel , Walter Daelemans - Computational Linguistics , 2000 . \" ... this paper , we combine different systems employing known representations .", "label": "", "metadata": {}, "score": "44.55172"}
{"text": "We extract different LTAGs from the Penn Treebank .We show that certain strategies yield an improved extracted LTAG in terms of compactness , broad coverage , and supertagging accuracy .Furthermore , we perform a preliminary investigation in smoothing these grammars by means of an external linguistic resource , namely , the tree families of an XTAG grammar , a hand built grammar of English . by Hans Van Halteren , Jakub Zavrel , Walter Daelemans - Computational Linguistics , 2000 . \" ... this paper , we combine different systems employing known representations .", "label": "", "metadata": {}, "score": "44.55172"}
{"text": "Organizers .Sameer Pradhan , Martha Palmer , and Edward Loper .This task consists of lexical sample style training and testing data for 35 nouns and 65 verbs in the WSJ Penn Treebank II as well as the Brown corpus .", "label": "", "metadata": {}, "score": "45.24256"}
{"text": "In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) and in Kinyon ( 00b ) , which allows to factor the information contained in several Supertags into a single structure and to encode functional information in a systematic manner .", "label": "", "metadata": {}, "score": "45.492367"}
{"text": "In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) and in Kinyon ( 00b ) , which allows to factor the information contained in several Supertags into a single structure and to encode functional information in a systematic manner .", "label": "", "metadata": {}, "score": "45.492367"}
{"text": "Unfortunately , words are assigned on average a much higher number of Supertags than traditional POS .In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) ... \" .Srinivas ( 97 ) enriches traditional morpho - syntactic POS tagging with syntactic information by introducing Supertags .", "label": "", "metadata": {}, "score": "46.54738"}
{"text": "Unfortunately , words are assigned on average a much higher number of Supertags than traditional POS .In this paper , we develop the notion of Hypertag , first introduced in Kinyon ( 00a ) ... \" .Srinivas ( 97 ) enriches traditional morpho - syntactic POS tagging with syntactic information by introducing Supertags .", "label": "", "metadata": {}, "score": "46.54738"}
{"text": "The hope is that by making the token decisions more intelligently , downstream processing like part - of - speech tagging is easier .For instance , it 's difficult to even make sense of assigning part - of - speech tags to three tokens derived from \" p-53 \" , namely \" p \" , \" - \" and \" 53 \" .", "label": "", "metadata": {}, "score": "46.733307"}
{"text": "As described above , the OntoNotes senses have links to WN senses .Subtask 2 : Coarse - grained English Lexical Sample SRL .For the same lemmas ( but not necessarily exactly the same training and testing instances ) , we will also supply : .", "label": "", "metadata": {}, "score": "47.186157"}
{"text": "At the BioNLP workshop at ACL 2008 , Peter Corbett presented a paper ( with Anne Copestake ) on Cascaded Classifiers for Confidence - Based Chemical Named Entity Recognition .It 's a really neat paper that addresses issues of confidence estimation , and particularly trading precision for recall ( or vice - versa ) .", "label": "", "metadata": {}, "score": "47.41929"}
{"text": "Each type of learning method brings its own ' inductive bias ' to the task and will produce a classifier with slightly different characteristics , so that different methods will tend to produce different errors . ... eras , 1999 ) for combining ensembles of neural networks .", "label": "", "metadata": {}, "score": "47.57158"}
{"text": "Each type of learning method brings its own ' inductive bias ' to the task and will produce a classifier with slightly different characteristics , so that different methods will tend to produce different errors . ... eras , 1999 ) for combining ensembles of neural networks .", "label": "", "metadata": {}, "score": "47.57158"}
{"text": ".. sister adjunction can be used to create parse trees for all input strings , with only a slight penalty in accuracy .The results are graphed in Figure 14 .They use a different set of Supertags and so we used their result simply to get an approxima ... . \" ...", "label": "", "metadata": {}, "score": "47.574966"}
{"text": ".. sister adjunction can be used to create parse trees for all input strings , with only a slight penalty in accuracy .The results are graphed in Figure 14 .They use a different set of Supertags and so we used their result simply to get an approxima ... . \" ...", "label": "", "metadata": {}, "score": "47.574966"}
{"text": "gDelta : This tool uses data mining methods to assess the impact of a grammar change at a more fine - grained level than the counts of items parsed and readings that the standard treebank profiling tool reports .It provides different visualisations of a change , focussing on changes in which rules were applied .", "label": "", "metadata": {}, "score": "47.711746"}
{"text": "Corpus data make it possible to investigate the co - occurrences of different types of MWEs and NEs within the same domain and also to train and evaluate MWE detectors and NER applications .4FX The 4FX corpus contains English , Spanish , German and Hungarian legislative texts from the JRC - Acquis Multilingual Parallel Corpus , which are manually annotated for light verb constructions , following standardized annotation principles .", "label": "", "metadata": {}, "score": "48.22666"}
{"text": "Such representations are provided by a hand - built HPSG grammar with a wide linguistic coverage .A specific semantic representation , called linked predicate argument structure ( LPAS ) , has been worked out , which describes the explicit embedding relationships among predicate argument structures .", "label": "", "metadata": {}, "score": "48.744034"}
{"text": "Grammars are core elements of many NLP applications .In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the cove ... \" .", "label": "", "metadata": {}, "score": "48.80011"}
{"text": "Grammars are core elements of many NLP applications .In this paper , we present a system that automatically extracts lexicalized grammars from annotated corpora .The data produced by this system have been used in several tasks , such as training NLP tools ( such as Supertaggers ) and estimating the cove ... \" .", "label": "", "metadata": {}, "score": "48.80011"}
{"text": "( van Halteren , 1996 ) ) .RankBoost can also use a variety of local and long distance features more easily than n - gram - based approaches ( cf .( Chen , Bangalore and Vijay - Shanker , 1999 ) ) because it makes sparse data less of an issue . \" ...", "label": "", "metadata": {}, "score": "48.807007"}
{"text": "( van Halteren , 1996 ) ) .RankBoost can also use a variety of local and long distance features more easily than n - gram - based approaches ( cf .( Chen , Bangalore and Vijay - Shanker , 1999 ) ) because it makes sparse data less of an issue . \" ...", "label": "", "metadata": {}, "score": "48.807007"}
{"text": "The verbs and adjectives have also been tagged with coarse grained senses .This work was done in the Computer and Information Sciences Department at the University of Pennsylvania .The XML format and KSC 5,601 character set encoding are used in the frames file .", "label": "", "metadata": {}, "score": "48.83366"}
{"text": "To get around that problem , our named - entity detector just treats each character as a token ; that worked pretty well for our entry in the SIGHAN 3 bakeoff .There were even two papers on jointly modeling segmentation and tagging for Chinese at this year 's ACL ( Jiang et al . and Zhang et al . ) .", "label": "", "metadata": {}, "score": "49.13227"}
{"text": "The corpus has 14,261 sentence alignment units , which contain 1370 occurrences of light verb constructions .Szeged Treebank FX The Szeged Treebank - a database in which words are morphosyntactically tagged and sentences are syntactically parsed - was annotated for light verb constructions manually .", "label": "", "metadata": {}, "score": "49.763077"}
{"text": "Track 1 : Closed track -- participants can use only the training data supplied , plus Charniak parses provided with the data , along with any other features that can be extracted from WordNet 2.1 as well as any unsupervised techniques .", "label": "", "metadata": {}, "score": "50.087883"}
{"text": "Corpora .The Szeged Treebank 2.0 annotated for light verb constructions [ download ] TTS - A Treebank Tool Suite .Cahill , Aoife and van Genabith , Josef ( 2002 ) TTS - A Treebank Tool Suite .In : The Third International Conference on Language Resources and Evaluation , May 27th -- June 2nd , 2002 , Las Palmas de Grand Canaria , Spain .", "label": "", "metadata": {}, "score": "51.43648"}
{"text": "..We just list two of them which seem to be most relevant : C4 uses a reduced tagset while C3 uses the PTB tagset . 9 Instead , we re - ran 8 All use Section 2 - 21 of the PTB for training , and Section 22 or 23 for testing .", "label": "", "metadata": {}, "score": "51.513657"}
{"text": "..We just list two of them which seem to be most relevant : C4 uses a reduced tagset while C3 uses the PTB tagset . 9 Instead , we re - ran 8 All use Section 2 - 21 of the PTB for training , and Section 22 or 23 for testing .", "label": "", "metadata": {}, "score": "51.513657"}
{"text": "The VerbNet labels were attached to the PropBank data at the University of Colorado using a semi - automatic process that involved a hand correction step .This was funded by AQUAINT , and is described in a NAACL-07 paper , ( Yi , Loper , Palmer ) .", "label": "", "metadata": {}, "score": "52.175453"}
{"text": "During the question period , we got to the bottom of what was going on , which turned out to be intelligent tokenization making mistakes so that entities were n't extractable because they were only parts of tokens .I 'm hoping Peter does the analysis to see how many entities are permanently lost due to tokenization errors .", "label": "", "metadata": {}, "score": "52.180126"}
{"text": "Introduction As a first step prior to parsing , traditional Part of Speech ( POS ) tagging assigns limited morpho - syntactic information to lexical items .These labels can be more or less fine - grained depending on the tagset , but syntactic information is often absent or limited .", "label": "", "metadata": {}, "score": "52.98556"}
{"text": "Introduction As a first step prior to parsing , traditional Part of Speech ( POS ) tagging assigns limited morpho - syntactic information to lexical items .These labels can be more or less fine - grained depending on the tagset , but syntactic information is often absent or limited .", "label": "", "metadata": {}, "score": "52.98556"}
{"text": "There are two basic components to Korean Propbank : .The Verb Lexicon .A frames file , consisting of one or more frame sets , has been created for each predicate occurring in the Treebank .These files serve as a reference for the annotators and for users of the data .", "label": "", "metadata": {}, "score": "53.184513"}
{"text": "All data is the result of double blind , adjudicated annotation .Data .There are two basic components to Propbank : .The Verb Lexicon .A frames file , consisting of one or more frame sets , has been created for each verb occuring in the Treebank .", "label": "", "metadata": {}, "score": "53.78866"}
{"text": "We ... \" .this paper , we combine different systems employing known representations .The observation that suggests this approach is that systems that are designed differently , either because they use a different formalism or because they contain different knowledge , will typically produce different errors .", "label": "", "metadata": {}, "score": "54.166534"}
{"text": "We ... \" .this paper , we combine different systems employing known representations .The observation that suggests this approach is that systems that are designed differently , either because they use a different formalism or because they contain different knowledge , will typically produce different errors .", "label": "", "metadata": {}, "score": "54.166534"}
{"text": "Rules can be ordered by frequency and the user can set frequency thresholds .The system is implemented in Java and Perl .We employ the InterArbora module based on the Thistle display engine ( LTG , 2001 ) as our tree grapher .", "label": "", "metadata": {}, "score": "54.808975"}
{"text": "Although lexical amb ...The Curse of \" Intelligent \" Tokenization .We 're now running into a problem we 've run into before : so - called \" intelligent \" tokenization .The earliest version of this of which I 'm aware is the Penn Treebank tokenization , which assumes sentence splitting has already been done .", "label": "", "metadata": {}, "score": "55.42673"}
{"text": "Note that the Treebank tokenizer also replaces double quotes with either left or right LaTex - style quotes , so there 's no way to reconstruct the underlying text from the tokens .Like many other projects , they also throw away the whitespace information in the data , so there 's no way to train something to do tokenization that 's whitespace sensitive because we just do n't have the whitespace .", "label": "", "metadata": {}, "score": "55.64184"}
{"text": "Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .We believe that is largely in part due to the absence of large corpora accurately bracketed in terms of a perspicuous yet broad coverage LTAG .", "label": "", "metadata": {}, "score": "55.94066"}
{"text": "CoNLL-2003 dataset annotated for LVCs The CoNLL-2003 dataset was originally developed for named entity recognition in short news domain .500 randomly selected pieces of short news were taken from the CoNLL-2003 dataset and LVCs in them were annotated .This corpus contains 381 occurrences of manually annotated LVCs in 8,467 sentences .", "label": "", "metadata": {}, "score": "57.262512"}
{"text": "Our own approach ( in practice - in theory we can plug and play any tokenizer that can be coded ) has been to take very fine - grained tokenizations so that the tokenization would be compatible with any old kind of tagger .", "label": "", "metadata": {}, "score": "57.299088"}
{"text": "In this paper we propose to use supertags to expose syntactic dependencies which are unavailable with POS tags .We first propose a novel method of app ... \" .Supertagging is the tagging process of assigning the correct elementary tree of LTAG , or the correct supertag , to each word of an input sentence .", "label": "", "metadata": {}, "score": "57.45443"}
{"text": "In this paper we propose to use supertags to expose syntactic dependencies which are unavailable with POS tags .We first propose a novel method of app ... \" .Supertagging is the tagging process of assigning the correct elementary tree of LTAG , or the correct supertag , to each word of an input sentence .", "label": "", "metadata": {}, "score": "57.45443"}
{"text": "Track 2 : Open track -- participants can use any additional data , including the entire training portions ( sections 02 - 21 ) of Treebank and PropBank ( if they are LDC members ) or tools trained on those data .", "label": "", "metadata": {}, "score": "57.691193"}
{"text": "Practically speaking , the data 's out of bounds anyway because of its research - only license .Unlike the Penn Treebank or French Treebank , there 's no option to buy commercial licenses .I 've just been struggling with the French Treebank , which follows the Penn Treebank 's lead in using \" intelligent \" tokenization .", "label": "", "metadata": {}, "score": "57.699516"}
{"text": "Corpora .Several manually annotated corpora have been created by us , listed below .SzegedParalellFX The SzegedParalell English - Hungarian parallel corpus constitutes the basis of the SzegedParalellFX , in which light verb constructions are manually annotated .Three novels , texts from magazines and language books and economic and legal texts were selected for annotation .", "label": "", "metadata": {}, "score": "57.820896"}
{"text": "In this talk , I am going to present details of two of them : .MUPS :The aim of this project is to provide a means to build a statistical parse selection model without the manual treebanking stage .Our first attempt uses supertag sequences to direct the Maximum Entropy estimation towards preferred analyses .", "label": "", "metadata": {}, "score": "58.32653"}
{"text": "The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .We believe that is largely in part due to the absence of large corpora accurately bracketed in terms of a perspicuous yet broad coverage LTAG .", "label": "", "metadata": {}, "score": "58.37565"}
{"text": "Following the presented approach , the HPSG ERG grammar can be used for annotating some standard treebank , e.g. , the Penn Treebank , with its fine - grained semantics .In this vein , I point out opportunities for a fruitful cooperation of the HPSG annotated Redwood Treebank and the Penn PropBank .", "label": "", "metadata": {}, "score": "58.689438"}
{"text": "We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .", "label": "", "metadata": {}, "score": "59.062836"}
{"text": "We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .", "label": "", "metadata": {}, "score": "59.062836"}
{"text": "We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .", "label": "", "metadata": {}, "score": "59.062836"}
{"text": "We present a method for rule - based structure conversion of existing treebanks , which aims at the extraction of linguistically sound , corpus - based grammars in a specific grammatical framework .We apply this method to the NEGRA treebank to derive an LTAG grammar of German .", "label": "", "metadata": {}, "score": "59.062836"}
{"text": "Palmer , Martha , et al .Korean Propbank LDC2006T03 .Web Download .Philadelphia : Linguistic Data Consortium , 2006 .Introduction .Korean Propbank Annotations is a semantic annotation of the Korean English Treebank Annotations and Korean Treebank Version 2.0 .", "label": "", "metadata": {}, "score": "59.126633"}
{"text": "RankBoost ( Freund et al ., 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs ... \" .this paper , we investigate an approach to such a choice based on reranking a set of candidate supertags and their confidence scores .", "label": "", "metadata": {}, "score": "59.409218"}
{"text": "RankBoost ( Freund et al ., 1998 ) is the boosting algorithm that we use in order to learn to rerank outputs .It also has been used with good effect in reranking outputs ... \" .this paper , we investigate an approach to such a choice based on reranking a set of candidate supertags and their confidence scores .", "label": "", "metadata": {}, "score": "59.409218"}
{"text": "Tokenization is particularly vexing in the bio - medical text domain , where there are tons of words ( or at least phrasal lexical entries ) that contain parentheses , hyphens , and so on .This turned out to be a problem for WordNet ) .", "label": "", "metadata": {}, "score": "59.904198"}
{"text": "Palmer , Martha , et al .Proposition Bank I LDC2004T14 .Web Download .Philadelphia : Linguistic Data Consortium , 2004 .Introduction .Proposition Bank I was produced by Linguistic Data Consortium ( LDC ) catalog number LDC2004T14 and ISBN 1 - 58563 - 304 - 6 .", "label": "", "metadata": {}, "score": "60.30082"}
{"text": "We show how a Supertagger can be used to drastically reduce the syntactic lexical ambiguity for a given input and can be used in combination with an LTAG parser to radically improve parsing efficiency .We then turn our attention to from parsing efficiency to parsing accuracy and provide a method by which we can effectively combine the output of a Supertagger and a statistical LTAG parser using a co - training algorithm for bootstrapping new labeled data .", "label": "", "metadata": {}, "score": "60.676018"}
{"text": "We show how a Supertagger can be used to drastically reduce the syntactic lexical ambiguity for a given input and can be used in combination with an LTAG parser to radically improve parsing efficiency .We then turn our attention to from parsing efficiency to parsing accuracy and provide a method by which we can effectively combine the output of a Supertagger and a statistical LTAG parser using a co - training algorithm for bootstrapping new labeled data .", "label": "", "metadata": {}, "score": "60.676018"}
{"text": "There , the data 's not even consistently tokenized , because they left it to annotators to decide on token boundaries .They then use statistical chunkers to uncover the tokenizations probabilistically .Google 's n - gram data is also distributed without a tokenizer .", "label": "", "metadata": {}, "score": "60.8301"}
{"text": "Al- though the approach is applicable to any type of language model , we focus on the case of statistical disambiguators that are trained on annotated corpora .The examples of the task that are present in the corpus and its annotation are fed into a learning algorithm , which induces a model of the desired input - output mapping in the form of a classifier .", "label": "", "metadata": {}, "score": "61.307518"}
{"text": "Al- though the approach is applicable to any type of language model , we focus on the case of statistical disambiguators that are trained on annotated corpora .The examples of the task that are present in the corpus and its annotation are fed into a learning algorithm , which induces a model of the desired input - output mapping in the form of a classifier .", "label": "", "metadata": {}, "score": "61.307518"}
{"text": "A compound is a lexical unit that consists of two or more elements that exist on their own .Orthographically , a compound may include spaces ( high school ) or hyphen ( well - known ) or none of them ( headmaster ) .", "label": "", "metadata": {}, "score": "61.343575"}
{"text": "The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .We believe that is largely in part due to the absence of large cor ... \" .", "label": "", "metadata": {}, "score": "61.89843"}
{"text": "Although lexical amb ...Tools . \" ...The accuracy of statistical parsing models can be improved with the use of lexical information .Statistical parsing using Lexicalized tree adjoining grammar ( LTAG ) , a kind of lexicalized grammar , has remained relatively unexplored .", "label": "", "metadata": {}, "score": "62.302246"}
{"text": "This version of the Treebank contains 6734 occurrences of 1215 light verb constructions altogether in 82,099 sentences .Wiki50 The Wiki50 corpus contains 50 English Wikipedia articles ( 4350 sentences ) , in which several types of multiword expressions and four classes of Named Entities were manually annotated by professional linguists .", "label": "", "metadata": {}, "score": "63.666157"}
{"text": "We first propose a novel method of applying Sparse Network of Winnow ( SNoW ) to sequential models .Then we use . \" ...In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .", "label": "", "metadata": {}, "score": "63.906395"}
{"text": "We first propose a novel method of applying Sparse Network of Winnow ( SNoW ) to sequential models .Then we use . \" ...In this paper we study various reasons and mechanisms for combining Supertagging with Lexicalized Tree - Adjoining Grammar ( LTAG ) parsing .", "label": "", "metadata": {}, "score": "63.906395"}
{"text": "Some initial experiments have been conducted to convert MRS expressions into LPASs .A simple constraint solver is developed to resolve the underspecified dominance relations between the predicates and their arguments in MRS expressions .LPASs are useful for high - precision information extraction and question answering tasks because of their fine - grained semantic structures .", "label": "", "metadata": {}, "score": "64.20538"}
{"text": "The sense tags will be evaluated using Precision and Recall the same way Senseval English sense tags have been evaluated .Deadline : .We have extended the deadline for submitting the results to the midnight of April 4 th .Multiword expressions .", "label": "", "metadata": {}, "score": "66.23441"}
{"text": "Updates .Please check the Propbank homepage for updates , tools , annotation guidelines , and published papers .Sponsorship .This work was funded by DoD Grant MDA904 - 00C-2136 , NSF grant IIS-9800658 , and the Institute for Research in Cognitive Science at the University of Pennsylvania NSF - STC grant SBR-89 - 20230 .", "label": "", "metadata": {}, "score": "66.856804"}
{"text": "There are two annotation files .The virginia - verbs .pb file has 9,588 annotated predicate tokens .The newswire - verbs .pb file has 23,707 annotated predicate tokens .In many cases , NLP is a consumer of the results of grammar engineering , but NLP methods can also be used to contribute to the grammar engineering process .", "label": "", "metadata": {}, "score": "67.5114"}
{"text": "/PUNCT \" - you just do n't know if there was space between that final verb \" ran \" and the full stop \" .\" You 'll also see their script builds in all sorts of knowledge about English , such as a handful of contractions , so that \" can not \" is split out into two tokens , \" can \" and \" not \" .", "label": "", "metadata": {}, "score": "71.13947"}
{"text": "We welcome any feedback on the usefulness of these tools and on what other features or information could be helpful .", "label": "", "metadata": {}, "score": "72.920135"}
{"text": "Specifically , \" Mr. Smith ran .Then he jumped .\" gets split into two sentences , \" Mr. Smith ran . \" and \" Then he jumped .\" Now the fun starts .The periods at the end of a sentence are split off into their own token .", "label": "", "metadata": {}, "score": "77.419495"}
