{"text": "A method for electronically generating high - quality feature vectors that can be used in connection with electronic data processing systems implementing Maximum Entropy or other statistical models to accurately normalize abbreviations in text such as medical records .An abbreviation database and a training text database are provided .", "label": "", "metadata": {}, "score": "28.307892"}
{"text": "A notable advantage of the algorithm is that , unlike other approaches , it does not require any training data . \" ... Introduction An impressive array of statistical methods have been developed for word sense identification .They range from dictionary - based approaches that rely on definitions ( Vronis and Ide 1990 ; Wilks et al .", "label": "", "metadata": {}, "score": "28.6231"}
{"text": "The abbreviation system can then score the candidate expansions for an abbreviation by generating the features and calculating their scores from a weighted combination of the features .This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description .", "label": "", "metadata": {}, "score": "29.054665"}
{"text": "2 , Oct. 9 , 1994 , pp .540 - 543 , XP010216362 ISBN : 0 - 8186 - 6270 - 0 .A method and system for identifying expansions of abbreviations using learned weights is provided .An abbreviation system generates features for various expansions of an abbreviation and generates a score indicating the likelihood that an expansion is a correct expansion of the abbreviation .", "label": "", "metadata": {}, "score": "29.690598"}
{"text": "In this paper we show that the problem of identifying abbreviations ' definitions can be solved with a much simpler algorithm than that proposed by other research efforts .The algorithm achieves 96 % precision and 82 % recall on a standard test collection , which is at least as good as existing approaches .", "label": "", "metadata": {}, "score": "30.384518"}
{"text": "Second , it requires a rule - based system for assigning correct expansions to their abbreviations .Any such system would likely become large and difficult to maintain .Third , the distinctions made between various expansions are likely to be coarse .", "label": "", "metadata": {}, "score": "30.396116"}
{"text": "First , the accuracy of the abbreviation expansions depends on the effectiveness of the heuristics , which in general can not perform as well as a human editor .Second , it is difficult to extend such heuristics to account for new types of abbreviations such as \" XML \" for \" extensible Markup Language \" in which the initial letter of a word of an expansion is not used , but a non - initial letter is used .", "label": "", "metadata": {}, "score": "30.685308"}
{"text": "The method should be capable of generating training data that will enable the text normalization modeling systems to normalize the text to a relatively high degree of accuracy .A system of this type that can be used to normalize abbreviations and acronyms in medical text would be particularly useful .", "label": "", "metadata": {}, "score": "30.851957"}
{"text": "The study was designed to address several questions .One was whether local sentence - level context can be used successfully to disambiguate abbreviation expansion .A third question is whether it is more beneficial to construct multiple ME models limited to a single abbreviation .", "label": "", "metadata": {}, "score": "30.870155"}
{"text": "A method and system for identifying expansions of abbreviations using learned weights is provided .In one embodiment , an abbreviation system generates features for various expansions of an abbreviation and generates a score indicating the likelihood that a candidate expansion is a correct expansion of the abbreviation .", "label": "", "metadata": {}, "score": "31.034073"}
{"text": "\" Unfortunately , this method of using the global context to resolve abbreviation ambiguity suffers from a number of drawbacks that limit its use in automatic document processing applications .First , it requires a database of abbreviations and their expansions linked with possible contexts in which particular expansions can be used .", "label": "", "metadata": {}, "score": "31.116415"}
{"text": "Additional error analysis could be done on the output of the other systems .It may also be useful to combine the outputs of multiple taggers as well .The second aspect has to do with the use of dictionaries .Our system used a simple algorithm to exploit a single data resource from the NCBI .", "label": "", "metadata": {}, "score": "31.91779"}
{"text": "towards the refinement of grammar descriptions ( Wallis pp .27 - 38 ) .In the previous decade , numerous corpus exploitation tools became . available on the market ( see detailed surveys by Schulze et al .1994 , .", "label": "", "metadata": {}, "score": "32.003826"}
{"text": "A method and system for identifying expansions of abbreviations using learned weights is provided .An abbreviation system generates features for various expansions of an abbreviation and generates a score indicating the likelihood that an expansion is a correct expansion of the abbreviation .", "label": "", "metadata": {}, "score": "32.124672"}
{"text": "A candidate expansion with the same number of words as letters in the abbreviation is more likely in general to be a correct expansion than an expansion with more or fewer words .The abbreviation system calculates a score based on a weighted combination of the features .", "label": "", "metadata": {}, "score": "32.414562"}
{"text": "An abbreviation system generates features for various expansions of an abbreviation and generates a score indicating the likelihood that an expansion is a correct expansion of the abbreviation .A expansion with the same number of words as letters in the abbreviation is more likely in general to be a correct expansion than an expansion with more or fewer words .", "label": "", "metadata": {}, "score": "32.472183"}
{"text": "d ) the text in the memory containing words and abbreviations ; and .A second principal object and advantage of the data processing apparatus and method is that it allows for adding to , editing , updating and customizing the list of words and phrases and abbreviations which are to correspond to each other within the apparatus and method .", "label": "", "metadata": {}, "score": "32.666054"}
{"text": "Corpus Annotation ( a. encoding ; b. tagging ; c. parsing ) , 3 .Linguistic exploration of the data ( Oostdijk and de Haan 1994 , Svartvik 1992 , Meijs 1987 ) .As we have moved into 21st century , the focus of Corpus Linguistics has moved too , and publications such as the present volume are a sign that it really has .", "label": "", "metadata": {}, "score": "32.770184"}
{"text": "To ensure that the abbreviation dictionaries are up to date , some dictionaries allow users to submit new abbreviations and their expansions .Some of these abbreviation dictionaries may have editors who carefully review each submission and determine whether it should be added to the dictionary , while other abbreviation dictionaries simply add submissions to the dictionary without any editorial review .", "label": "", "metadata": {}, "score": "33.839058"}
{"text": "The search engine service provides search results that include links to documents relating to the abbreviation along with snippets from those documents .A snippet is typically a passage extracted from the document relating to the abbreviation .The abbreviation system then identifies candidate expansions from the passages .", "label": "", "metadata": {}, "score": "34.22159"}
{"text": "This scheme allows the definition and combination of \" word lists , prefix and suffix lists , and punctuation models \" , including some that are \" derived from a regular expression grammar \" .The dictionaries and lexical templates can be searched in parallel , and include a prior probability for each expression .", "label": "", "metadata": {}, "score": "34.695927"}
{"text": "Our study suggests that this would be helpful for improving recall at least modestly .Conclusion .The POS - tagging - based approach that we took from the ABGene system worked reasonably well .Post - processing rules , which included pattern - based rules , rules that used abbreviation recognition heuristics , and lexicon - based rules , worked well to increase both precision and recall .", "label": "", "metadata": {}, "score": "34.77099"}
{"text": "Text categorisation and document clustering have been of .interest particularly to those in the area of Artificial Intelligence .( e.g. Machine Translation ) , although research outcomes depend largely .on how the corpus available has been accessed : raw , annotated or . analysed ( McNaught 1993 ) .", "label": "", "metadata": {}, "score": "34.960327"}
{"text": "Just as with Tables 3 and 4 , the statistics reported in Table 5 are averaged across 10 iterations of cross - validation .The results of this study indicate that using Maximum Entropy modeling for abbreviation disambiguation is a sound approach for text normalization tasks involving abbreviations .", "label": "", "metadata": {}, "score": "34.97074"}
{"text": "The abbreviations to include in the training / testing were selected based on the following criteria : 1 ) at least two expansions ; and 2 ) they have 100 - 1000 training data samples .The data compiled for each set and subset was split at random in the 80/20 fashion into training and testing data .", "label": "", "metadata": {}, "score": "34.979034"}
{"text": "how far the normalization procedures should go is still debated .( Oostdjik pp .59 - 85 ) .Parsing a corpus in order to build a syntactic .representation for it is of course barely an end in itself .", "label": "", "metadata": {}, "score": "35.12031"}
{"text": "There .now seems to be agreement that both approaches are equally valid and . ''potentially complementary ' ' , hence a collective effort to establish .the direction and future of Corpus Linguistics research ( see .Grefenstette 1998 on ' ' Approximate Linguistics ' ' ) .", "label": "", "metadata": {}, "score": "35.226326"}
{"text": "This was motivated by the idea that ME models trained on corpora focused on a single abbreviation may perform more accurately , even though such an approach may be computationally expensive .Two sets of data were generated for the test .", "label": "", "metadata": {}, "score": "36.061615"}
{"text": "Table 3 summarizes the results of training Local Context models with the data from Set A ( one abbreviation per corpus ) .Table 3 as well as Table 4 display the accuracy , the number of training and testing events / samples , the number of outcomes ( possible expansions for a given abbreviation ) and the number of contextual predicates averaged across ten iterations of the cross - validation test .", "label": "", "metadata": {}, "score": "36.339382"}
{"text": "Calculating prior probabilities over all encountered templates allows templates of varying number of letters to be compared .This means that the language model can assist in decoding input where letter or word segmentation is not known , or a number of alternate segmentation paths are possible .", "label": "", "metadata": {}, "score": "36.409286"}
{"text": "Proceedings of the 19th International Conference on Computational Linguistics ( COLING 2002 ) 765 - 771 .Schwartz AS , Hearst MA : A Simple Algorithm For Identifying Abbreviation Definitions in Biomedical Text .Proceedings of the Pacific Symposium on Biocomputing 2003 , 8 : 451 - 462 .", "label": "", "metadata": {}, "score": "36.49746"}
{"text": "He is currently acting as Local .Arrangements Chair of IWPT 2000 ( Sixth International Workshop on .Parsing Technologies ) which will be held in Trento from 23 to 25 .February 2000 .Data processing apparatus and method for converting words to abbreviations , converting abbreviations to words , and selecting abbreviations for insertion into text US 7475343 B1 .", "label": "", "metadata": {}, "score": "36.50206"}
{"text": "Since the abbreviation for a given expression will typically occur in the same context as the expression itself , a feature vector generated on the basis of the context of the expression will enable the abbreviation to be accurately normalized .Although the embodiment of the method described herein uses the surrounding terms and section of the health record to characterize the context of the expansions in the feature vectors , it is to be understood that there are a wide variety of other and/or additional approaches for defining context .", "label": "", "metadata": {}, "score": "36.835754"}
{"text": "While some recognition systems bypass character recognition altogether ( known as holistic word recognition ) most recognition systems make some attempt to identify individual characters in the input signal .Systems that do not do this are overly dependent on dictionaries during recognition , and support for the recognition of out - of - vocabulary words ( i.e. words not in the dictionary ) is usually not available .", "label": "", "metadata": {}, "score": "37.05687"}
{"text": "The abbreviation system can then score the candidate expansions for an abbreviation by generating the features and calculating their scores from a weighted combination of the features .In this way , the abbreviation system is provided with features that may be relevant to abbreviation expansions and learns the effectiveness of each feature at representing a correct expansion of an abbreviation .", "label": "", "metadata": {}, "score": "37.106884"}
{"text": "The results of this study raised four questions that we believe should be addressed in the near future - two general to the entire effort , and two specific to our system .First , it would have been useful to have an estimate of the upper bound on accuracy for any entity identification system trained on the BioCreAtIvE corpus , which is a function of how consistent and correct that data is .", "label": "", "metadata": {}, "score": "37.219254"}
{"text": "Since then fully - parsed corpora have become available ( e.g. ICE - GB ) and a structurally annotated corpus to replicate Biber 's Multi- Feature / Multi - Dimension method has \" simplified and improved the search for the linguistic features considerably \" ( p. 23 ) .", "label": "", "metadata": {}, "score": "37.369072"}
{"text": "Introduction An impressive array of statistical methods have been developed for word sense identification .They range from dictionary - based approaches that rely on definitions ( Vronis and Ide 1990 ; Wilks et al .1993 ) to corpus - based approaches that use only word cooccurrence frequencies extracted from large textual corpora ( Schfitze 1995 ; Dagan and Itai 1994 ) .", "label": "", "metadata": {}, "score": "37.410187"}
{"text": "Our use of domain - specific dictionaries was less effective , giving an increase of only 0.5 in F - measure to 80.9(open division ) compared to the post - processing without dictionaries approach .Our conclusion is that either much more sophisticated algorithms that make use of dictionaries need to be employed , or the dictionaries themselves are not sufficient .", "label": "", "metadata": {}, "score": "37.83166"}
{"text": "Corpus annotation adds interpretative ( especially linguistic ) information to an existing corpus of spoken and/or written language , by some kind of coding attached to , or interspersed with , the electronic representation of the language material itself ( Leech 1987 , 1993 ) .", "label": "", "metadata": {}, "score": "37.910797"}
{"text": "First of all , the accuracy results on the small pilot sample of 6 abbreviations as well as the larger sample with 69 abbreviations are quite encouraging in light of the fact that the training of the ME models is largely unsupervised .", "label": "", "metadata": {}, "score": "38.10047"}
{"text": "Handwritten text also exhibits ambiguity not only at the character level , but also at the word level , particularly in cursive writing .Recognition systems address this issue by including word - based language models , the most common of which is the use of a pre - defined dictionary .", "label": "", "metadata": {}, "score": "38.195885"}
{"text": "Even so , with large numbers of letter combinations provided in a given language , the use of such systems is limited , and requires very data intensive processing , thereby limiting the range of applications of the technique .However , the use of these techniques is limited to circumstances in which strict adherence to limited formats is provided .", "label": "", "metadata": {}, "score": "38.49788"}
{"text": "As a result , some kind of language - based post - processing is generally required to resolve the real meaning of the input .Many systems include simple heuristics that define a set of language rules for handwritten text .However , these heuristics are time - consuming and difficult to define , fragile to change , and are usually incomplete .", "label": "", "metadata": {}, "score": "38.54702"}
{"text": "A computer - readable medium encoded with instructions for controlling a computing system to identify expansions of abbreviations , by a method comprising : . identifying candidate expansions of an abbreviation from passages ; . generating features of the candidate expansions ; and .", "label": "", "metadata": {}, "score": "38.579117"}
{"text": "If the search fails , \" a stroke match function and spell - aid dictionary is used to construct a list of possible words \" .Similarly , U.S. Pat .No .5,151,950 describes using a tree - structured dictionary as a deterministic finite automaton to merge classifier results with contextual information .", "label": "", "metadata": {}, "score": "38.79036"}
{"text": "Annotation ( a. encoding ; b. tagging ; c. parsing ) , 3 .Linguistic .exploration of the data ( Oostdijk and de Haan 1994 , Svartvik 1992 , .Meijs 1987 ) .As we have moved into 21st century , the focus of Corpus .", "label": "", "metadata": {}, "score": "38.844196"}
{"text": "Because abbreviations are so pervasive in some domains , it can be difficult for a reader , even one experienced in the domain , to understand the expansion of all abbreviations .In addition , many abbreviations have multiple expansions within a domain and between domains .", "label": "", "metadata": {}, "score": "39.20919"}
{"text": "( f ) scanning the pre - existing text for abbreviations to be converted to words and converting abbreviations selected by the data processing method to corresponding words using the second data structure and replacing the abbreviations in the pre - existing text with the corresponding words .", "label": "", "metadata": {}, "score": "39.369312"}
{"text": "Like Tanabe and Wilbur [ 1 , 2 ] , we approached the molecular biology entity identification problem as a part - of - speech ( POS ) tagging task , adding to the standard POS tag set one or more gene tags for genes and gene products .", "label": "", "metadata": {}, "score": "39.50408"}
{"text": "Alternatively , the text segments from a number of top scoring templates can be processed using an additional language model , with the resulting scores being combined to produce a final word probability .Accordingly , it will be appreciated that the process described above provides a method for contextual processing using statistical language templates for handwritten character recognition .", "label": "", "metadata": {}, "score": "39.675568"}
{"text": "The method of .claim 16 including : . receiving an abbreviation and passages ; . identifying from the passages candidate expansions of the abbreviation ; . generating features for the candidate expansions ; and .generating scores indicating correctness of the candidate expansions for the abbreviation by combining the generated features for the candidate expansions using the learned weights of the features .", "label": "", "metadata": {}, "score": "39.6937"}
{"text": "The learn feature weights component then applies a regression technique to learn the weights for the features .The component stores the weights of these features in the weights store .The abbreviation system also includes components to identify expansions for a given abbreviation .", "label": "", "metadata": {}, "score": "39.732944"}
{"text": "For example , the reference corpus may include extended words that are obtained using words relevant to the target domain and an ontology .[ 0038 ]As another example , the first extraction unit 120 may determine whether one or more sentences of the collection of corpora include the words that are included in the reference corpus .", "label": "", "metadata": {}, "score": "39.865604"}
{"text": "No . 6,084,985 describes a method for on - line handwriting recognition based on a hidden Markov model and uses real - time sensing of at least an instantaneous write position of the handwriting , deriving from the handwriting a time - conforming string of segments each associated to a handwriting feature vector .", "label": "", "metadata": {}, "score": "39.92475"}
{"text": "In the past , corpus texts were usually categorised according to their primary discourse function ( Sinclair 1987:12 ; Rissanen et al .1987 ) .Biber 's extensive work on the typology of English texts showed that a thorough definition of the target population based on the co - occurrence of grammatical features was possible ( e.g. 1989 , 1990 ) .", "label": "", "metadata": {}, "score": "40.13807"}
{"text": "The use of human editors to maintain an abbreviation dictionary presents several problems .First , it can be time - consuming and expensive to manually create an abbreviation dictionary .Second , because so many documents are being published on a daily basis , it is virtually impossible for human editors to manually identify all new abbreviations and their expansions .", "label": "", "metadata": {}, "score": "40.186886"}
{"text": "A method for electronically generating high - quality feature vectors that can be used in connection with electronic data processing systems implementing Maximum Entropy or other statistical models to accurately normalize abbreviations in text such as medical records .Method for generating training data for medical text abbreviation and acronym normalization US 7028038 B1 .", "label": "", "metadata": {}, "score": "40.2137"}
{"text": "Accordingly , the hash in database 12 need only include the one or more abbreviations it is desired to normalize , and the associated expansions to which it is desired to normalize the abbreviations .As described in greater detail below , the method implemented by system 10 use a corpus of clinical notes or other health records in which the expansions of the abbreviations to be trained for are found .", "label": "", "metadata": {}, "score": "40.280556"}
{"text": "The abbreviation system learns the weights for the features from training data of abbreviations , candidate expansions , and scores for the candidate expansions .A computer system for identifying expansions of abbreviations , comprising : . a component that learns weights of features of abbreviation expansions , the weights representing effectiveness of a feature at indicating correctness of an abbreviation expansion ; . a component that receives an abbreviation ; . submitting the abbreviation as a query to a search engine service ; and .", "label": "", "metadata": {}, "score": "40.660484"}
{"text": "c ) selecting a word in the text to be converted to an abbreviation and converting the selected word to a corresponding abbreviation using the first data structure ; and .d ) selecting an abbreviation in the text to be converted to a word and converting the abbreviation to a word using the second data structure .", "label": "", "metadata": {}, "score": "40.67363"}
{"text": "Then it proposes an algorithm for segmenting Swedish texts into clauses and evaluates its performance , comparing the results on automatically and manually tagged texts .Between finite state and Prolog : constraint - based automata for efficient recognition of phrases by Klaus U. Schulz and Tomek Mikolajewski The paper describes \" constraint - based automata \" , that incorporate features from finite state techniques and constraint programming .", "label": "", "metadata": {}, "score": "40.722183"}
{"text": "Description .BACKGROUND OF THE INVENTION .A number of professions , industries , trades and occupations use standard abbreviations for certain words and phrases .The data processing apparatus and method of this patent application also enables users of word processing programs to select from a list of standard abbreviations for insertion into the text .", "label": "", "metadata": {}, "score": "40.846153"}
{"text": "( c ) a second data structure recorded in the memory , the second data structure encoding a plurality of abbreviations and corresponding words ; .( d ) pre - existing text in the memory containing words and abbreviations ; .", "label": "", "metadata": {}, "score": "40.924347"}
{"text": "As a result , a large amount of research has been directed at applying syntactic and linguistic constraints to handwritten text recognition .Similar work has been performed in the field of speech recognition , natural language processing , and machine translation .", "label": "", "metadata": {}, "score": "40.92753"}
{"text": "The utility of the data processing apparatus and method is therefore dynamic .The list of words and phrases and abbreviations may be modified based on the unique needs of the user and developments in various professions , industries , trades and occupations .", "label": "", "metadata": {}, "score": "40.960915"}
{"text": "Abbreviations .There are many instances in the corpora in which a full gene name is immediately followed by an appositive parenthesized symbol or abbreviation .In many cases , the tagger would recognize either the full gene name or the symbol / abbreviation , but not both .", "label": "", "metadata": {}, "score": "41.090202"}
{"text": "The algorithms tested include statistical , neural - network , decision - tree , rule - based , and case - based classification techniques .The sp ... \" .This paper describes an experimental comparison of seven different learning algorithms on the problem of learning to disambiguate the meaning of a word from context .", "label": "", "metadata": {}, "score": "41.20581"}
{"text": "No .5,377,281 , employs a knowledge - based approach to post - processing character recognition strings .The knowledge source used includes word - probabilities , word di - gram probabilities , statistics that relate the likelihood of words with particular character prefixes , and rewrite suggestions and their costs , and are derived from a text corpus .", "label": "", "metadata": {}, "score": "41.21322"}
{"text": "( i ) wherein the computer program automatically converts abbreviations selected by the computer program throughout the pre - existing text to corresponding words and replaces the selected abbreviations in the pre - existing text with the corresponding words .( a ) a computer having a memory , a central processing unit , and an input / output unit ; .", "label": "", "metadata": {}, "score": "41.305523"}
{"text": "( b ) the user instructing the data processing method to select a position anywhere in the pre - existing text for insertion of an abbreviation ; .( c ) displaying a list of words and corresponding abbreviations from the first data structure ; .", "label": "", "metadata": {}, "score": "41.335"}
{"text": "One of these challenges arises from the frequent use of novel abbreviations in these texts , thus requiring that biomedical lexical ontologies be continually updated .In this paper w ... \" .The volume of biomedical text is growing at a fast rate , creating challenges for humans and computer systems alike .", "label": "", "metadata": {}, "score": "41.389317"}
{"text": "No .5,987,170 , uses a combination of word and grammatical dictionaries for the recognition of oriental script .U.S. Pat .No . 6,005,973 , derives both dictionary strings and a most - likely digit string during recognition , which are presented to the writer for selection .", "label": "", "metadata": {}, "score": "41.428833"}
{"text": "No .5,392,363 , uses character- and word - grammar models for disambiguation in a frame - based probabilistic classifier .U.S. Pat .No .5,787,197 , uses a dictionary - based post - processing technique for online handwriting recognition .", "label": "", "metadata": {}, "score": "41.643246"}
{"text": "In particular , Table 1 contains the twenty templates with the highest frequency of occurrence in the written text corpus ( and thus have the highest prior probability ) .The table reveals a number of obvious properties of written text , such as short words are generally more common than longer words , and commas and periods are the most likely punctuation characters and appear as word suffixes .", "label": "", "metadata": {}, "score": "41.80853"}
{"text": "In particular , the training data is used in connection with Maximum Entropy or other statistical modeling techniques implemented in text processing and analysis systems .The preferred embodiment of the invention described herein generates Maximum Entropy training data in the form of feature vectors used to normalize abbreviations and acronyms found in medical text .", "label": "", "metadata": {}, "score": "41.90841"}
{"text": "In other words , no such data sets have been fully analyzed using computational techniques .Until recently , it was also uncommon to create corpora in bilingual or multilingual settings ( Kurtb\u00f6ke 2000 ) .In corpus construction , on the other hand , some still discuss whether texts of mixed nature should be allowed into a corpus at all .", "label": "", "metadata": {}, "score": "42.105415"}
{"text": "A number of existing products have some , but not all , features of the present invention .For example , the CiteRite \u2122 II software from Lexis - Nexis checks legal citations only for proper form and flags errors .This software is not general enough to use with abbreviations in other fields , and does not convert abbreviations to words .", "label": "", "metadata": {}, "score": "42.183643"}
{"text": "Three articles in the . present volume relate to this aspect of Corpus Linguistics : Renouf on .a new tool development ' ' WebCorp ' ' ( pp .39 - 58 ) ; Peters and Smith on . how e- documents are slowly but firmly changing the conventional print . documents ( 71 - 85 ) ; Schmied on the Internet Grammar project at Chemnitz .", "label": "", "metadata": {}, "score": "42.263016"}
{"text": "FIG .2 .It should be understood the order of execution of these steps is not critical .Illustrative windows for the apparatus 's features are shown in .FIGS .3 through 6 .Step 100 : Adding to , editing , updating and customizing a list of words and phrases and corresponding abbreviations .", "label": "", "metadata": {}, "score": "42.290855"}
{"text": "A hybrid class of machine learning techniques for WSD relies on a small set of hand labeled data used to bootstrap a larger corpus of training data .One way to take context into account is to encode the type of discourse in which the abbreviation occurs . \" Discourse \" can , for example , be defined as the type of medical document and the medical specialty .", "label": "", "metadata": {}, "score": "42.399582"}
{"text": "U.S. Pat .No .6,137,908 , describes using a trigram language model in combination with other heuristics to improve the accuracy of character segmentation and recognition .In U.S. Pat .No .6,111,985 , a character grammar during recognition , and a traditional maximum likelihood sequence estimation algorithm ( i.e. Viterbi decoding ) are used to disambiguate words from numeric strings using an N - gram character model .", "label": "", "metadata": {}, "score": "42.422554"}
{"text": "his research , no corpora were available that had been annotated with . detailed syntactic information ' ' ( p. 16 ) .Since then fully - parsed .corpora have become available ( e.g. ICE - GB ) and a structurally . annotated corpus to replicate Biber 's Multi- Feature / Multi - Dimension .", "label": "", "metadata": {}, "score": "42.425426"}
{"text": "6 is a schematic of the window which suggests and enables the user to select from conversions of an abbreviation with more than one corresponding word or phrase .DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS .The data processing apparatus and method for converting words and phrases to abbreviations , and converting abbreviations to words and phrases , is illustrated in the attached block diagram ( .", "label": "", "metadata": {}, "score": "42.53852"}
{"text": "The program should also scan an entire text for a word or abbreviation to be converted and automatically make the conversion .SUMMARY OF THE INVENTION .a ) storing in a memory a first data structure encoding a plurality of words and corresponding abbreviations ; .", "label": "", "metadata": {}, "score": "42.545815"}
{"text": "Many web - based abbreviation dictionaries are available to assist users in determining the meaning of abbreviations .To use these dictionaries , a user inputs the abbreviation and receives possible expansions for the abbreviation .One abbreviation dictionary reports 73 possible expansions for the abbreviation \" PTO .", "label": "", "metadata": {}, "score": "42.620842"}
{"text": "features considerably ' ' ( p. 23 ) .Also ' ' a factor analysis carried out .on the frequency counts of a set of word class tags resulted in .pp .15 - 25 ) .Parsing has been one of the concerns of computational corpus research . since early 1970s ( e.g. TOSCA in Nijmegen ) .", "label": "", "metadata": {}, "score": "42.99784"}
{"text": "Extending the Scope of Corpus - Based Research : New Applications , New Challenges , Rodopi .Much of 1980s and 1990s were taken up by considerations of three major .areas in the field of Corpus Linguistics : 1 .Corpus design ; 2 .", "label": "", "metadata": {}, "score": "43.064514"}
{"text": "d ) Title .Lastly , most of the contributors are Corpus Linguists ' ' firmly . established ' ' in their area of research and it is much to our .community 's benefit that they felt ' ' the need to ask [ themselves ] .", "label": "", "metadata": {}, "score": "43.158024"}
{"text": "A fourth principal object and advantage of the data processing apparatus and method is that it can scan an entire text for instances of a selected word or abbreviation and automatically convert each instance to the corresponding abbreviation or word .A fifth principal object and advantage of the data processing apparatus and method is that it displays a list of possible conversions from which the user can select .", "label": "", "metadata": {}, "score": "43.34279"}
{"text": "The present invention is an automated data processing method for generating high - quality training data that can be used with statistical text normalization systems .One embodiment of the invention includes providing a corpus of text having expansions of the abbreviations to be normalized .", "label": "", "metadata": {}, "score": "43.4612"}
{"text": "This rule applies only to the open division .If one of the previous rules did not tag the long form and the abbreviation with GENE , then apply the following .If the abbreviation was more than three characters long and was tagged as GENE , then we double - checked it against data from NCBI ( see Section Dictionary - based post - processing below ) .", "label": "", "metadata": {}, "score": "43.4915"}
{"text": "This is not surprising because the training data was derived from a relatively small subset of 10,000 notes .The other set ( Set B ) is similar to the first corpus of training events .However , it is not limited to just one abbreviation sample per corpus .", "label": "", "metadata": {}, "score": "43.535538"}
{"text": "The component then returns the internal proximity features .FIG .9 is a flow diagram that illustrates the processing of the identify enveloping sub - phrase component of the abbreviation system in one embodiment .The component is passed a mapping and identifies the first word and last word of the enveloping sub - phrase .", "label": "", "metadata": {}, "score": "43.58049"}
{"text": "REFERENCE TO RELATED APPLICATION .This application claims the benefit of U.S. Provisional Application Ser .No .60/393,907 , filed Jul. 3 , 2002 and entitled Semi - Supervised Maximum Entropy Based Approach to Acronym and Abbreviation Normalization in Medical Texts , which is hereby incorporated by reference in its entirety .", "label": "", "metadata": {}, "score": "43.633545"}
{"text": "For example , a corpus may include text corpus that is collected from novels , magazines , newspapers , dictionaries , usage instructions , text available on the web , and the like .As another example , a corpus may include a speech corpus that is obtained from the transcripts of conversations , interviews , speeches , and the like .", "label": "", "metadata": {}, "score": "43.641376"}
{"text": "\" This abbreviation normalization is effectively a special case of word sense disambiguation ( WSD ) .Approaches to WSD include supervised machine learning techniques , where some amount of training data is marked up by hand and used to train a classifier .", "label": "", "metadata": {}, "score": "43.648052"}
{"text": "FIG .1 are shown in line 104 .The abbreviation system uses the capital as initial ( \" Cl \" ) feature to measure how many capital letters of the abbreviation correspond to initial letters of words in a candidate expansion .", "label": "", "metadata": {}, "score": "43.684464"}
{"text": "v. .Oostdijk , N. and P. de Haan ( eds . )( 1994 ) Corpus - Based Research into Language : In Honour of Jan Aarts .Rodopi , Amsterdam .Quirk , R. ( 1992 )On corpus principles and design .", "label": "", "metadata": {}, "score": "43.71336"}
{"text": "In block 508 , the component ranks the candidate expansions based on their scores and then returns the ranked candidate expansions .FIG .6 is a flow diagram that illustrates the processing of the score candidate expansions component of the abbreviation system in one embodiment .", "label": "", "metadata": {}, "score": "43.72132"}
{"text": "4 is a schematic of the window which displays the list of abbreviations , from which the user can insert an abbreviation into the text ; .FIG .5 is a schematic of the window which suggests and enables the user to select from conversions of a word or phrase with more than one corresponding abbreviation ; and .", "label": "", "metadata": {}, "score": "43.803543"}
{"text": "230 ; Schmied on German - English pp .231 - 247 ) .In the past , corpus texts were usually categorised according to their . primary discourse function ( Sinclair 1987:12 ; Rissanen et al .1987 ) .Biber 's extensive work on the typology of English texts showed that a .", "label": "", "metadata": {}, "score": "43.837524"}
{"text": "U.S. Pat .No .5,680,511 , uses a word - based language model \" to recognize an unrecognized or ambiguous word that occurs within a passage of words .\" The method is described in the context of spoken or handwritten text recognition .", "label": "", "metadata": {}, "score": "43.864685"}
{"text": "BACKGROUND .Abbreviations are used extensively in a variety of domains as replacements for their expansions .As used in this specification , an abbreviation refers to a shortened form of a phrase that is derived from letters of the phrase .", "label": "", "metadata": {}, "score": "43.89336"}
{"text": "One skilled in the art will appreciate that many different features may be used to represent the relationships between an abbreviation and a candidate expansion .The abbreviation system can be used to learn the weights for features irrespective of how the features are defined .", "label": "", "metadata": {}, "score": "43.904926"}
{"text": "An expansion tree 100 lists possible mappings of the abbreviation to the candidate expansion .The first subscript of a letter represents the word of the candidate expansion that contains the letter , and the second subscript of a letter represents the occurrence of that letter in the word .", "label": "", "metadata": {}, "score": "43.92225"}
{"text": "3 is a schematic of the window which displays , and enables the user to modify , the list of words and phrases and corresponding abbreviations described above .Step 200 : Inserting abbreviations from said list into the text .The user can automatically insert an abbreviation into the text via a window which displays the list of words and phrases and corresponding abbreviations described in Step 100 above .", "label": "", "metadata": {}, "score": "43.94092"}
{"text": "177 - 193 ) ; and Kjellmer 's article ( pp .149 - 158 ) on potential words . which constitute unexpected ' ' lexical gaps ' ' in the Bank of English , . are indeed evidence that Pshycholinguistics and Corpus Research are . coming closer .", "label": "", "metadata": {}, "score": "44.079468"}
{"text": "Parsing a corpus in order to build a syntactic representation for it is of course barely an end in itself .The syntactic structure usually serves as input to some further processing towards the refinement of grammar descriptions ( Wallis pp .", "label": "", "metadata": {}, "score": "44.157345"}
{"text": "Acquiring rules for reducing morphological ambiguity from POS tagged corpus in Korean by Jae - Hoon Kim and Byung - Gyu Jang It presents a method for reducing morphological ambiguities when performing morphological analysis of Korean texts .The method automatically infers rules ( called subsumption conditions ) from a POS tagged corpus .", "label": "", "metadata": {}, "score": "44.244495"}
{"text": "The subject is of interest to biologists because it is a necessary first step in many kinds of applications that are of interest to them , including information extraction , information retrieval , and bibliometrics .It is of interest to linguists and computer scientists because it seems to be more difficult than entity identification in \" general English \" domains [ 1 ] .", "label": "", "metadata": {}, "score": "44.264263"}
{"text": "Examination of how instances of word types are tagged in the training and devtest corpora 's lexicon revealed effective post - processing rules .For the lexicon - based post - processing steps , tag set 2 , which has detailed boundary information , is used .", "label": "", "metadata": {}, "score": "44.314743"}
{"text": "Decoding is performed on a set of letter hypotheses generated by a character classifier that represents an input word or series of words .The probabilities associated with the templates mean that features such as word lengths and the location of punctuation characters can be used for statistical word segmentation .", "label": "", "metadata": {}, "score": "44.33912"}
{"text": "Term - level scores ( i.e. , for performance on full gene names , analogous to the strict metric of Olsson et al .[5 ] ) were obtained using the BioCreAtIvE scoring software .We evaluated performance both with and without post - processing .", "label": "", "metadata": {}, "score": "44.42048"}
{"text": "A simplified parser , called stapler , is also described ; the stapler is used in conjunction with the results of the application of EBL techniques .Experimental results of such approach are presented , comparing the performance with respect to the original system in terms of recall , number of parses and processing time .", "label": "", "metadata": {}, "score": "44.476665"}
{"text": "a component that generates a score indicating correctness of a candidate expansion for the abbreviation by combining the generated features for a candidate expansion using the learned weights of the features .The computer system of .claim 1 wherein the component that learns weights inputs abbreviations and passages for each abbreviation , identifies candidate expansions from passages for each abbreviation , generates features of the candidate expansions , and inputs an indication of correctness of candidate expansions .", "label": "", "metadata": {}, "score": "44.553955"}
{"text": "slightly different version ) .The editorial care of the book is not completely satisfactory .There . are a few typos ( not so many but they could be easily detected using a . spelling checker ) .Sometimes acronyms are used without being defined .", "label": "", "metadata": {}, "score": "44.691895"}
{"text": "R. Srihari , \" Use of Lexical and Syntactic Techniques in Recognizing Handwritten Text \" , ARPA Workshop on Human Language Technology , Princeton , N.J. , March 1994 describes using a combination of lexical and syntactic techniques to disambiguate the results of a handwriting recognition system .", "label": "", "metadata": {}, "score": "44.746468"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .FIG .1 illustrates various mappings of a candidate expansion to an abbreviation .FIG .2 is a block diagram that illustrates components of the abbreviation system in one embodiment .FIG .3 is a flow diagram that illustrates the processing of the learn feature weights component of the abbreviation system in one embodiment .", "label": "", "metadata": {}, "score": "44.75696"}
{"text": "The use of statistical or probabilistic methods such as Maximum Entropy and Markov Models to normalize or rationalize text during electronic document processing is generally known .Text normalization , the process of identifying variants and bringing them to a common ( normalized ) form , is an important aspect of successful information retrieval from medical documents such as health records , clinical notes , radiology reports and discharge summaries .", "label": "", "metadata": {}, "score": "44.843636"}
{"text": "b ) the user instructing the data processing method to select a position in the text for insertion of an abbreviation ; .c ) displaying a list of words and corresponding abbreviations from the first data structure ; .d ) the user instructing the data processing method to select an abbreviation from the list ; and .", "label": "", "metadata": {}, "score": "44.9804"}
{"text": "The purpose of generating statistical language templates is to identify common written - text idioms , and to calculate the probability of the idiom being encountered in written text .Model training proceeds by tokenising the letters in each white - space separated word , and storing the resulting template in a table , typically in the database 11 .", "label": "", "metadata": {}, "score": "45.10772"}
{"text": "Rule - based post - processing .We applied a number of simple , pattern - based rules to fix cases where the BioCreAtIvE task definition specified that a different boundary for the gene name than the one returned by the raw tagger output .", "label": "", "metadata": {}, "score": "45.11796"}
{"text": "Post - processing is effective on all gene mentions of any length .However , it seems that improvement in performance is greater for longer gene mentions .This is probably due to lexicon - based post - processing that corrects boundaries .", "label": "", "metadata": {}, "score": "45.328693"}
{"text": "In the previous decade , numerous corpus exploitation tools became available on the market ( see detailed surveys by Schulze et al .1994 , Christ 1996 ) .However , as the advances in computer technology facilitated the exchange of on - line textual resources and electronic transfer on the internet , the largest corpus has become the Web itself .", "label": "", "metadata": {}, "score": "45.3879"}
{"text": "( e ) inserting the selected abbreviation at the selected position in the pre - existing text .The data processing method of .claim 7 , further comprising a step of adding to , editing , updating and customizing the first data structure and second data structure .", "label": "", "metadata": {}, "score": "45.40737"}
{"text": "These techniques will now be described in more detail .Statistical Template Generation .This section describes the generation of statistical templates from a text corpus , and gives examples of templates that have been statistically derived .Overview .Letters represent the fundamental primitive of classification for a handwritten text recognition system .", "label": "", "metadata": {}, "score": "45.415012"}
{"text": "In particular , the processing system can be adapted to generate statistical templates from a text corpus and/or use statistical templates in the decoding of handwritten text .In the case of template generation , the processing system is adapted to analyse text , which is typically stored in the database 11 .", "label": "", "metadata": {}, "score": "45.439922"}
{"text": "Not all of the possible expansions found in the UMLS for a given abbreviation will be found in the text of the clinical notes .Table 2 shows the number of expansions actually found in the rheumatology training data for each of the six abbreviations used for the test as well as the expansions found for a given abbreviation in the UMLS database .", "label": "", "metadata": {}, "score": "45.484325"}
{"text": "The check can be initiated via a mouse or keyboard command .The mouse command involves pointing the cursor at an on - screen button or drop - down menu item .The user can check the text for words and phrases corresponding to abbreviations , and converting said words and phrases to said abbreviations , via a window that suggests said conversions .", "label": "", "metadata": {}, "score": "45.530106"}
{"text": "x .i . )c . i .j .n .c .j .B . where : .B is the number of unique templates derived from the corpus ; .\u03bb is a smoothing factor ( empirically set to 0.5 ) .", "label": "", "metadata": {}, "score": "45.536755"}
{"text": "The present invention relates generally to probabilistic modeling of text .In particular , the invention is a method for automatically generating training data that can be used in connection with Maximum Entropy or other probabilistic models for abbreviation and acronym normalization / disambiguation in medical or other kinds of text .", "label": "", "metadata": {}, "score": "45.5898"}
{"text": "Most character classification systems generate a set of possible letter matches and associated confidence scores for an input letter .For example , when classifying a letter ' a ' , a classifier letter hypothesis could be as set out in Table 3 below .", "label": "", "metadata": {}, "score": "45.639"}
{"text": "1 are shown in line 103 .The abbreviation character distribution feature is the normalized square of the difference between the length of the abbreviation occurrence pattern and the number of letters of the abbreviation .The square is normalized by dividing by the number of letters in the abbreviation .", "label": "", "metadata": {}, "score": "45.665752"}
{"text": "For example , one such contextual predicate could be the type of discourse that an outcome occurs in .The Context Generator class of the Maxent package was modified to allow for the features described herein .Use of the feature vectors in this manner effectively assumes that given an abbreviation and one of it 's expansions , the two will likely have a similar distribution .", "label": "", "metadata": {}, "score": "45.74507"}
{"text": "[0009 ] The domain actions may be categories of user intentions for inducing actions and/or responses from an intention analysis system .[ 0011 ] The apparatus may further comprise a removal unit configured to remove at least one of ungrammatical words or sentences from the extracted corpus .", "label": "", "metadata": {}, "score": "45.84333"}
{"text": "The templates in the table given above detail a number of rather obvious language rules that could be described by a number of simple heuristics ( although it is unlikely that the prior probabilities for these rules could be easily and accurately estimated ) .", "label": "", "metadata": {}, "score": "45.854877"}
{"text": "expressions for language engineering \" by Lauri Karttunen , Jean - Pierre .Chanod , Gregory Grefenstette and Anne Schiller , \" Finite state . morphology and information retrieval \" by Kimmo Koskeniemmi , and .\"Multilingual text analysis for text - to - speech synthesis \" by Richard .", "label": "", "metadata": {}, "score": "45.866104"}
{"text": "These templates model the interaction between alphabetic letters , digits , and punctuation and implicitly define a set of rules about the structure of written text .It will be noted that the strength of this technique lies in the generation of a large number of templates , and the corresponding relative probabilities of the templates .", "label": "", "metadata": {}, "score": "45.869865"}
{"text": "15 - 25 ) .Parsing has been one of the concerns of computational corpus research since early 1970s ( e.g. TOSCA in Nijmegen ) .Raw ( spoken ) data may need \" normalization \" before syntactic parsing can proceed , although how far the normalization procedures should go is still debated ( Oostdjik pp .", "label": "", "metadata": {}, "score": "45.902794"}
{"text": "Researchers in three areas , LANGUAGE CONTACT , CORPUS LINGUISTICS and .NATURAL LANGUAGE PROCESSING , are now starting to think about the . problem of how to treat mixed linguistic data computationally , even .though some still fail to go beyond the traditional ' ' borrowing''- . ''", "label": "", "metadata": {}, "score": "45.913483"}
{"text": "Throughout the remainder of this document , the word \" abbreviation \" is used to mean both \" abbreviation \" and \" acronym \" since the two words can be used interchangeably for the purposes of this document and invention .Numerous abbreviations are used routinely throughout such medical text and identifying their meaning is critical to understanding the document .", "label": "", "metadata": {}, "score": "45.976357"}
{"text": "pp . 1 - 15 .Leech , G ( 1993 ) Corpus Annotation Schemes .Literary and Linguistic Computing 8:4:276 - 281 .Lux , P. and W. Grabe ( 1991 )Multivariate approaches to contrastive rhetoric .Lenguas Modernas 18:133 - 60 .", "label": "", "metadata": {}, "score": "46.052067"}
{"text": "A similar process is applied to the right edge of the multi - word gene mention using the list of words known not to be tagged as GENE_END .The following lines show the POS counts in the training corpus for the words binding and regulator .", "label": "", "metadata": {}, "score": "46.209644"}
{"text": "( b ) a first data structure recorded in the memory , the first data structure encoding a plurality of words and corresponding abbreviations ; .( c ) a second data structure recorded in the memory , the second data structure encoding a plurality of abbreviations and corresponding words ; .", "label": "", "metadata": {}, "score": "46.214424"}
{"text": "; Seneff 1992 ) .The problem of word sense disambiguation ( WSD ) has ... . by Dan Roth - In Proceedings of the National Conference on Artificial Intelligence .Segond F. , Schiller A. , Grefenstette & amp ; Chanod F.P , 1998 . \" ... distinct semanticonceptsuch as interest rate and has interest in Math are conflated in ordinary text .", "label": "", "metadata": {}, "score": "46.22981"}
{"text": "However , the description given below assumes that word segmentation has been performed , and the decoding procedure is only required to find the most likely letter sequence given the output of the character classifier .This is done by finding the template that gives the maximum score given the character probabilities generated by the classifier combined with the prior probability of the template likelihood : .", "label": "", "metadata": {}, "score": "46.23159"}
{"text": "1990 ) .The studies reported in the present volume pleasantly add to the Language Learning - Teaching research library .It would be worthwhile though to extend the boundaries of such investigation to more typologically different language pairs .b ) Corpus - based vs corpus - driven .", "label": "", "metadata": {}, "score": "46.367737"}
{"text": "The two traditions complement each other .Corpus - based approaches have the advantage of being generally applicable to new texts , domains , and corpora without needing costly and perhaps error - prone parsing or semantic analysis .They require only training corpora in which the sense distinctions have been marked , but therein lies their weakness .", "label": "", "metadata": {}, "score": "46.36847"}
{"text": "the correct form .Each of the methods makes a priori assumptions , which Many of these arc important stand - alone problems it employs , given the data , when searching for its hy- but even more important is thei role in many applicapothesis .", "label": "", "metadata": {}, "score": "46.382076"}
{"text": "This suggests that the lexicon contained in the training data is very important for being able to successfully apply our post - processing steps .We believe that a larger training set covering a larger lexicon would help improve the performance of our system .", "label": "", "metadata": {}, "score": "46.407257"}
{"text": "The Quickwords \u2122 software from Corel only works with a single word processor , WordPerfect \u2122 , and only converts words to abbreviations , not abbreviations to words .There is a need for a completely generalized word - to - abbreviation and abbreviation - to - word converter program that works with any type of text containing abbreviations from any profession , industry , trade , or occupation .", "label": "", "metadata": {}, "score": "46.45735"}
{"text": "In corpus construction , on the other . hand , some still discuss whether texts of mixed nature should be . allowed into a corpus at all .And in computational research , entire .funds are still dedicated to the resolution of monolingual grammars by .", "label": "", "metadata": {}, "score": "46.761585"}
{"text": "Paper presented at 21stICAME Conference , Macquairie University , Sydney .Leech , G ( 1987 )General Introduction .In R. Garside et al .( eds ) , The Computational Analysis of English - a corpus - based approach .", "label": "", "metadata": {}, "score": "46.86239"}
{"text": "An example of this is described in H. Beigi and T. Fujisaki , \" A Character Level Predictive Language Model and Its Application to Handwriting Recognition \" , Proceedings of the Canadian Conference on Electrical and Computer Engineering , Toronto , Canada , Sep. 13 - 16 , 1992 , Vol .", "label": "", "metadata": {}, "score": "46.942165"}
{"text": "Quirk , R. ( 1992 )On corpus principles and design .In Svartvik , . pp .457- 469 .English Texts .In Meijs , pp .21 - 32 .Sinclair , J ( 1996 )The Search for Units of Meaning .", "label": "", "metadata": {}, "score": "46.97004"}
{"text": "The extracting the corpus may comprise using vectors to represent the collection of corpora and a reference corpora , and extracting the corpus relevant to the target domain based on a comparison of the vectors .[ 0025 ] Other features and aspects may be apparent from the following detailed description , the drawings , and the claims .", "label": "", "metadata": {}, "score": "46.976383"}
{"text": "London .pp . 1 - 15 .Leech , G ( 1993 ) Corpus Annotation Schemes .Literary and Linguistic .Computing 8:4:276 - 281 .Lux , P. and W. Grabe ( 1991 )Multivariate approaches to contrastive . rhetoric .", "label": "", "metadata": {}, "score": "47.001453"}
{"text": "FIG .1 is a block diagram of the principal functions of the data processing method and apparatus ; .FIG .2 is a flowchart of the data processing method ; .FIG .3 is a schematic of the window which displays the list of abbreviations , from which the user can add to , edit , update and customize the list of words and phrases and abbreviations which are to correspond to each other ; .", "label": "", "metadata": {}, "score": "47.07554"}
{"text": "Our approach to Task 1A was inspired by Tanabe and Wilbur 's ABGene system [ 1 , 2 ] .Like Tanabe and Wilbur , we approached the problem as one of part - of - speech tagging , adding a GENE tag to the standard tag set .", "label": "", "metadata": {}, "score": "47.100765"}
{"text": "Issues in Applied Linguistics .Applied Linguistics 15:2:169 - 189 .Christ , O. ( 1996 )Corpus Exploration Tools .Tutorial script .EURALEX .Clear , J. et al .( 1996 ) COBUILD , The State of the Art .", "label": "", "metadata": {}, "score": "47.13375"}
{"text": "The first extraction unit 120 may divide the corpus 200 into a plurality of sentences , and may tag each sentence on a morpheme - by - morpheme basis .[ 0049 ] The removal unit 130 may remove one or more ungrammatical words and/or sentences from the corpus 200 .", "label": "", "metadata": {}, "score": "47.18611"}
{"text": "With the shift of emphasis in the late 1980s and early 1990s from language system to language use , it became obvious that the data extracted from corpora were more complex than was described by the rule - based systems .For example , the traditional parsing technology ignored certain aspects of the lexicon such as collocations and word associations since they were too difficult to capture using rule - based systems ( Atkins et al .", "label": "", "metadata": {}, "score": "47.18965"}
{"text": "I , pp .WA1.28.1 - 4 , a generic template language model for use in situations that \" are very limited in format or their vocabulary \" .In this case , templates are applied by integrating an elastic - matching character - classification score with a model probability using a search heuristic .", "label": "", "metadata": {}, "score": "47.32062"}
{"text": "( g ) wherein the computer program displays a list of words corresponding to selected abbreviations to the operator through the input / output unit ; .( h ) wherein the computer program automatically converts words selected by the computer program throughout the pre - existing text to corresponding abbreviations and replaces the selected words in the pre - existing text with the corresponding abbreviations ; .", "label": "", "metadata": {}, "score": "47.363434"}
{"text": "457- 469 .Rissanen , M. , O. Ihalainen and M. Kyt\u00f6 ( 1987 )The Helsinki Corpus of English Texts .In Meijs , pp .21 - 32 .Sinclair , J ( 1996 )The Search for Units of Meaning .", "label": "", "metadata": {}, "score": "47.416588"}
{"text": "The training text database includes a corpus of text having expansions of the abbreviations to be normalized .The corpus of text is processed as a function of the abbreviation data to identify the expansions in the corpus of text .Context information describing the context of the text in which the expansions were identified is generated .", "label": "", "metadata": {}, "score": "47.488087"}
{"text": "[ 0057 ] In 320 , the apparatus removes any ungrammatical words and/or sentences from the extracted corpus .In 330 , the apparatus classifies the extracted corpus into a plurality of domain actions .In 340 , the apparatus extracts one or more concepts from each of the domain actions .", "label": "", "metadata": {}, "score": "47.549683"}
{"text": "[ 0063 ] A number of examples have been described above .Nevertheless , it should be understood that various modifications may be made .For example , suitable results may be achieved if the described techniques are performed in a different order and/or if components in a described system , architecture , device , or circuit are combined in a different manner and/or replaced or supplemented by other components or their equivalents .", "label": "", "metadata": {}, "score": "47.596283"}
{"text": "Likewise , the user can convert an abbreviation in the text to a corresponding word or phrase by highlighting said abbreviation and initiating conversion via a mouse or keyboard command .The mouse command involves pointing the cursor at an on - screen button or drop - down menu item .", "label": "", "metadata": {}, "score": "47.765076"}
{"text": "Conclusion .Our results show that a part - of - speech tagger can be augmented with post - processing rules resulting in an entity identification system that competes well with other approaches .Background .This paper describes the methods we used to accomplish entity identification ( also known as named entity recognition ) in the molecular biology domain .", "label": "", "metadata": {}, "score": "47.852936"}
{"text": "In block 1002 , the component sets the length of the abbreviation occurrence pattern to the number of characters in the abbreviation occurrence pattern .In block 1003 , the component sets the length of the abbreviation to the number of letters in the abbreviation .", "label": "", "metadata": {}, "score": "47.937138"}
{"text": "Description : .CROSS -REFERENCE TO RELATED APPLICATION(S ) .BACKGROUND .[0002 ] 1 .Field .[ 0003 ] The following description relates to a technique that automatically generates grammar for use in the analysis of the intention of a user based on audio data or text that is input by the user .", "label": "", "metadata": {}, "score": "47.94005"}
{"text": "More corpus research on typologically different language pairs .L2 acquisition has been subject of corpus research before .For . example , Biber et al .( 1994 ) used corpus analysis to examine the . development of discourse competence and register awareness of the . adult learners of English .", "label": "", "metadata": {}, "score": "47.944023"}
{"text": "EXTENDING THE SCOPE OF CORPUS - BASED RESEARCH is a happy indication .that the scene might be changing , with articles reporting on the . analysis of contact data , be it in the local press ( Hajar & Harjita on .", "label": "", "metadata": {}, "score": "48.076317"}
{"text": "The approach uses a combination of linguistic and statistical techniques for POS disambiguation .Experimental results for French POS tagging are presented .Colonies : a multi - agent approach to language generation by Erzsebet Csuhaj - Varju ( ECAI )The paper presents \" colonies \" , multi - agent symbol systems whose behavior is jointly determined by the combination of very simple grammars .", "label": "", "metadata": {}, "score": "48.101982"}
{"text": "A final word from the Editors Granger .and Petch - Tyson as to how they see the work in progress reported in .this volume will develop in the future would have been a nicer closure .for an elegant volume showing how far Corpus Linguistics has come .", "label": "", "metadata": {}, "score": "48.153748"}
{"text": "To assist in the general recognition of alphabetic characters , dictionaries and character grammars are often used for disambiguation .Generally , dictionaries and character grammars include only alphabetic characters ( although apostrophes are sometimes included to model compound words such as \" they 're \" and \" he 'll \" ) .", "label": "", "metadata": {}, "score": "48.22366"}
{"text": "With the points above considered , perhaps the title of the book could have been THE SCOPE OF CORPUS RESEARCH - A VIEW OF THE PRESENT IN TERMS OF THE PAST rather than \" Extending the scope of corpus - based research - new applications , new challenges \" .", "label": "", "metadata": {}, "score": "48.2705"}
{"text": "Dictionary - based post - processing in the open division .We employed a dictonary - based post - processing step that uses NCBI LocusLink symbols database for the open division .LocusLink database used for this research has 279,007 symbols that include official symbols or other aliases that are used to refer to a given gene .", "label": "", "metadata": {}, "score": "48.444332"}
{"text": "However , the dictionary - based approach increased our F - measure by only 0.5 % .Baseline , and normalizing for the difficulty of the task .As a baseline for understanding the difficulty of the task , we measured the performance achieved by simply assigning each word the most frequent tag seen with that word in the training set .", "label": "", "metadata": {}, "score": "48.452087"}
{"text": "Each character probability represents a likelihood of the respective hand - written character being a respective one of a plurality of predetermined characters .Each predetermined character has a respective character type .Character templates having the known number of characters are next identified .", "label": "", "metadata": {}, "score": "48.553986"}
{"text": "Similar examples may be listed from all over the world .Regardless of the commonness of bilingual or multilingual settings , . studies reporting computational treatment of mixed linguistic data are . rare .In other words , no such data sets have been fully analyzed . using computational techniques .", "label": "", "metadata": {}, "score": "48.701347"}
{"text": "FIG .5 .The user can check the text for abbreviations corresponding to words and phrase , and converting said abbreviations to said words and phrases , via a window that suggests said conversions .The window is similar to that depicted in .", "label": "", "metadata": {}, "score": "48.70629"}
{"text": "5 is a flow diagram that illustrates the processing of the identify expansions component of the abbreviation system in one embodiment .The component is passed an abbreviation and passages and generates a ranking of the possible expansions of the abbreviation .", "label": "", "metadata": {}, "score": "48.83186"}
{"text": "The method may further comprise extracting one or more concepts from each of the domain actions , wherein the generating the grammar comprises generating the grammar based on the domain actions and the concepts that are extracted from each of the domain actions .", "label": "", "metadata": {}, "score": "48.87905"}
{"text": "( a ) storing in a memory a first data structure encoding a plurality of words and corresponding abbreviations ; .( b ) storing in a memory a second data structure encoding a plurality of abbreviations and corresponding words ; .", "label": "", "metadata": {}, "score": "48.99533"}
{"text": "Step 401 : Selecting from multiple words or phrases corresponding to an abbreviation .Occasionally more than one abbreviation corresponds to a word or phrase , and more than one word or phrase corresponds to an abbreviation .If this situation applies to an abbreviation or word or phrase that the user is converting ( as described in Steps 300 and 400 above ) , the window depicted in .", "label": "", "metadata": {}, "score": "49.006813"}
{"text": "( 1994 ) used corpus analysis to examine the development of discourse competence and register awareness of the adult learners of English .Similarly , Lux and Grabe ( 1991 ) used corpus - based analysis to compare the compositions of university students , written in Ecuadorian Spanish and English .", "label": "", "metadata": {}, "score": "49.014744"}
{"text": "However , it is costly and time - consuming to generate an analysis device that can analyze a large amount of grammar , and there is a limit in properly creating grammar to reflect a variety of vocabulary and expressions .SUMMARY . [", "label": "", "metadata": {}, "score": "49.052338"}
{"text": "information extraction and intelligent human - machine We use this to build an argument for a data driven interaction .Most of the ambiguity resolution problems approach which merely searches for a good linear sepa- are at the lower level of the natural language inferences rator in the feature space , without further assumptions chain ; a wide range and a large number of ambigui- . \" ...", "label": "", "metadata": {}, "score": "49.103714"}
{"text": "( especially linguistic ) information to an existing corpus of spoken .and/or written language , by some kind of coding attached to , or . interspersed with , the electronic representation of the language . material itself ( Leech 1987 , 1993 ) . ''", "label": "", "metadata": {}, "score": "49.122673"}
{"text": "Experiments on both text and speech translation from Spanish to English are described .This paper is a considerably extended version of the ECAI workshop paper by J.M. Vilar , E. Vidal & J.C. Amengual .Finite state segmentation of discourse into clauses by Eva Ejerhed ( ECAI )", "label": "", "metadata": {}, "score": "49.13721"}
{"text": "The abbreviation system learns the weights for the features from training data of abbreviations , candidate expansions , and scores for the candidate expansions .To learn the weights , the abbreviation system generates features for each candidate expansion and inputs a score indicating the likelihood that the candidate expansion is a correct expansion for an abbreviation .", "label": "", "metadata": {}, "score": "49.178223"}
{"text": "The automatic disambiguation of word senses has been an interest and concern since the earliest days of computer treatment of language in the 1950 's .Sense disambiguation is an \" intermediate task \" ( Wilks and Stevenson , 1996 ) which is not an end in itself , but rather is necessary at one level o ... \" .", "label": "", "metadata": {}, "score": "49.262398"}
{"text": "This process includes storing the expansion itself and its associated abbreviation as indicated by steps 42 and 44 .The associated context information is also generated and stored as indicated by steps 46 and 48 .As discourse context information , this embodiment of the invention identifies and stores the section identifier ( ID ) of the health record in which the expansion was located .", "label": "", "metadata": {}, "score": "49.273026"}
{"text": "The studies reported in the present .volume pleasantly add to the Language Learning - Teaching research . library .It would be worthwhile though to extend the boundaries of .such investigation to more typologically different language pairs .b ) Corpus - based vs corpus - driven .", "label": "", "metadata": {}, "score": "49.305046"}
{"text": "Further , Mooney [ 17 ] has also compared all previously cited methods on a very restricted domain and including Decision Trees and Rule Induction algorithms .Unfortunately , ...Sign up to receive free email alerts when patent applications with chosen keywords are published SIGN UP .", "label": "", "metadata": {}, "score": "49.32637"}
{"text": "Linguistics in general was that it would advance in two directions : . computational corpus research and the mental lexicon ( Halliday 1998 ) .Sampson 's article on WORDINESS - or LEXICAL DENSITY in Hallidayian . terms ( Halliday and Martin 1993 ) - in children 's writing .", "label": "", "metadata": {}, "score": "49.33015"}
{"text": "The method of .claim 1 wherein : . the method further includes providing stored abbreviation data representative of abbreviations and associated expansions for which training data is to be generated ; and .processing the text to identify the expansions includes processing the corpus of text as a function of the stored abbreviation data .", "label": "", "metadata": {}, "score": "49.335682"}
{"text": "-Weighted automata in text and speech processing by Mehryar Mohri , .Fernando Pereira and Michael Riley .- Finite - state methods , binding , and anaphora by Richard Oehrle . -Efficient finite - state approximation of context free grammars by .", "label": "", "metadata": {}, "score": "49.46957"}
{"text": "Accordingly , it can be seen that each of the above methods suffer from a variety of disadvantages .In particular , the majority of the techniques tend to require large amounts of data processing .This can limit the circumstances in which the techniques can be implemented , in particular because powerful processors are required to perform , the recognition .", "label": "", "metadata": {}, "score": "49.475586"}
{"text": "3 is a flow diagram that illustrates the processing of the learn feature weights component of the abbreviation system in one embodiment .The component is provided with abbreviations , passages , and scores and learns weights for mapping the features to the scores .", "label": "", "metadata": {}, "score": "49.517574"}
{"text": "248 - 261 ) shows that the tension between corpus - based versus task - based approaches to language teaching is no longer there .Learner corpora in a classroom setting provide naturally occurring examples for the instant use of the teacher and the student , whereas in the past , language course books as well as traditional grammars and dictionaries , used invented examples , which seemed intuitively right to the native - speaker .", "label": "", "metadata": {}, "score": "49.54435"}
{"text": "This may be because larger tag sets are sometimes harder to learn because there are fewer examples for each tag .We speculate that tag sets two and three could possibly outperform the others if we had more training data .However , because the simplest tagging scheme performed the best , we used this scheme for all subsequent experiments described below .", "label": "", "metadata": {}, "score": "49.679848"}
{"text": "Each feature vector including the context information generated for the associated expansion identified in the corpus of text .A method for generating training data that can be used with statistical models to normalize abbreviations in text , including : . providing a corpus of text including expansions of the abbreviations to be normalized ; . processing the corpus of text to identify the expansions in the corpus of text ; . processing the corpus of text to generate context information describing the context of the text in which the expansions were identified ; and .", "label": "", "metadata": {}, "score": "49.693687"}
{"text": "The paper by Csuhaj - Varju ( chapter 17 ) .presents some results from the field of formal languages .As far as I . understand , the only link with NLP is that some languages that can be .described using such results ( e.g. , the languages of multiple . agreement , crossed agreements and replication ) would present . structures that are present in natural languages ; no further evidence .", "label": "", "metadata": {}, "score": "49.76149"}
{"text": "( 2003 )Extending the Scope of Corpus - Based Research : New Applications , New Challenges , Rodopi .Petek Kurtb\u00f6ke , Ph.D. .Much of 1980s and 1990s were taken up by considerations of three major areas in the field of Corpus Linguistics : 1 .", "label": "", "metadata": {}, "score": "49.870888"}
{"text": "Hence corpus - based and task - based approaches no longer stand in opposition but they have become complementary .CRITICAL COMMENTS . a )More corpus research on typologically different language pairs .L2 acquisition has been subject of corpus research before .", "label": "", "metadata": {}, "score": "49.890823"}
{"text": "The method starts by determining character probabilities for each hand - written character in the character string .Classifying a string formed from a known number of hand - written characters US 8000531 B2 .Resumen .A method of classifying a character string formed from a known number of hand - written characters is disclosed .", "label": "", "metadata": {}, "score": "49.89707"}
{"text": "With the shift of emphasis in the late 1980s and early 1990s from .language system to language use , it became obvious that the data .extracted from corpora were more complex than was described by the . rule - based systems .", "label": "", "metadata": {}, "score": "49.900166"}
{"text": "The component then returns the abbreviation character distribution feature .FIG .11 is a flow diagram that illustrates the processing of the generate abbreviation occurrence pattern component of the abbreviation system in one embodiment .The component is passed an abbreviation and a mapping of a candidate expansion and returns the abbreviation occurrence pattern .", "label": "", "metadata": {}, "score": "49.922295"}
{"text": "Svartvik , J. ( 1992 ) Corpus linguistics comes of age .In J Svartvik ( ed ) Directions in Corpus Linguistics .Proceedings of Nobel Symposium 82 .Stockholm , 4 - 8 August 1991 .Mouton de Gruyter , Berlin .", "label": "", "metadata": {}, "score": "50.032013"}
{"text": "Sinclair , J ( ed . )( 1987 )Looking Up : An Account of the Cobuild Project in Lexical Computing .Collins , London .Schulze , B. M. et al .( 1994 ) DECIDE Designing and Evaluating Extraction Tools for Collocations in Dictionaries and Corpora .", "label": "", "metadata": {}, "score": "50.07502"}
{"text": "Examples of the domain types include a TV control domain , a video search domain , a personal information management system domain , and the like .[ 0035 ] The first extraction unit 120 may extract a corpus that is relevant to the target domain from a collection of corpora .", "label": "", "metadata": {}, "score": "50.089725"}
{"text": "FIG .4 is a schematic of the window .Step 300 : Converting a word or phrase in the text to a corresponding abbreviation .Step 400 : Converting an abbreviation in the text to a corresponding word or phrase .", "label": "", "metadata": {}, "score": "50.1372"}
{"text": "In block 1105 , the component selects the next letter of the abbreviation .In decision block 1106 , if all the letters of the abbreviation have already been selected , then the component continues at block 1110 , else the component continues at block 1107 .", "label": "", "metadata": {}, "score": "50.170128"}
{"text": "In decision block 1102 , if the first letter is within the first word , then the component continues at block 1104 , else the component continues at block 1103 .In block 1103 , the component outputs underscore(s ) to the abbreviation occurrence pattern for the first word(s ) of the candidate expansion that does not contain the first letter of the abbreviation .", "label": "", "metadata": {}, "score": "50.215584"}
{"text": "The generation of the grammar for use in the processing of a natural language by the apparatus 100 is further described with reference to FIG .2 .Although not shown in FIG .1 , the apparatus 100 may include a storage for storing the plurality of domains , the collection of corpora , the domain actions , the classes , and the like .", "label": "", "metadata": {}, "score": "50.223633"}
{"text": "corpus available to the teacher and the learner , tasks in the .classroom are now designed around the application of corpus examples . to discourse organization .Hence corpus - based and task - based .approaches no longer stand in opposition but they have become . complementary .", "label": "", "metadata": {}, "score": "50.28833"}
{"text": "The component then returns .FIG .8 is a flow diagram that illustrates the processing of the calculate internal proximity component of the abbreviation system in one embodiment .The component is passed an abbreviation and a mapping to a candidate expansion and returns the internal proximity feature .", "label": "", "metadata": {}, "score": "50.399925"}
{"text": "1 are shown in line 102 .The abbreviation system uses an abbreviation character distribution ( \" ACD \" ) feature to measure the distribution of letters of the abbreviation through a candidate expansion .A mapping with a distribution of one letter of an abbreviation to each successive word of the candidate expansion is more likely a correct mapping than one with multiple letters mapping to a word or one with no letter mapping to a word .", "label": "", "metadata": {}, "score": "50.50172"}
{"text": "View Article PubMed .Tanabe L , Wilbur WJ : Tagging gene and protein names in full text articles .Proceedings of the workshop on biomedical natural language processing in the biomedical domain Association for Computational Linguistics 2002 , 9 - 13 .", "label": "", "metadata": {}, "score": "50.530655"}
{"text": "[0017 ] The method may further comprise classifying the extracted corpus into one or more domain actions that correspond to the target domain .[ 0018 ] The domain actions may be categories of user intentions for inducing actions and/or responses from an intention analysis system .", "label": "", "metadata": {}, "score": "50.635777"}
{"text": "Each token in the task1A corpus is labeled with a POS tag or a gene tag .Because the default tagging seemed overly simplistic , we hypothesized that expanding the gene tag set to incorporate boundary information would improve performance .We tested the following gene tag sets : .", "label": "", "metadata": {}, "score": "50.776176"}
{"text": "An example of this is described in D. Tugwell , \" A Markov Model of Syntax \" , Paper presented at the 1stCLUK Colloquium , University of Sunderland , UK 1998 .However , again , the use of language post processing is data intensive , thereby limiting the applications in which the techniques may be applied .", "label": "", "metadata": {}, "score": "50.808563"}
{"text": "[ 0043 ] The class conversion unit 160 may convert one or more words from each of the domain actions into classes .For example , a class may include a word included in a corpus , a synonym of the word , a category corresponding to the word , and the like .", "label": "", "metadata": {}, "score": "50.86603"}
{"text": "In block 1111 , the component outputs underscore(s ) for the remaining word(s ) of the candidate expansion to the abbreviation occurrence pattern and then returns the abbreviation occurrence pattern .FIG .12 is a flow diagram that illustrates the processing of the calculate capitals as initial component of the abbreviation system in one embodiment .", "label": "", "metadata": {}, "score": "50.86637"}
{"text": "The component then returns the score .FIG .7 is a flow diagram that illustrates the processing of the calculate external proximity component of the abbreviation system in one embodiment .The component is passed an abbreviation and a mapping to a candidate expansion and returns an external proximity feature .", "label": "", "metadata": {}, "score": "51.084187"}
{"text": "Christ , O. ( 1996 )Corpus Exploration Tools .Tutorial script .EURALEX 96 , University of G\u00f6teborg , Sweden .Clear , J. et al .( 1996 ) COBUILD , The State of the Art .International Journal of Corpus Linguistics 1:2:303 - 314 .", "label": "", "metadata": {}, "score": "51.15243"}
{"text": "The prior probabilities can then be calculated based on the number of template counts of the template group , rather than the sum of all counts over all groups .Smoothing .The above procedure produces a maximum - likelihood estimate ( MLE ) of the template probabilities based on the text corpus .", "label": "", "metadata": {}, "score": "51.163193"}
{"text": "With the . points above considered , perhaps the title of the book could have been .THE SCOPE OF CORPUS RESEARCH - A VIEW OF THE PRESENT IN TERMS OF THE .PAST rather than ' 'Extending the scope of corpus - based research - new .", "label": "", "metadata": {}, "score": "51.229378"}
{"text": "c ) Written vs spoken corpus material .The volume places emphasis on devising better methods of differentiation between speech and writing , although this seems to be a contradiction in terms .One can not ignore that the use of the internet for daily communication , and the globalisation factor creating new diasporas , are two strong forces that are rapidly narrowing the gap between the spoken and written input .", "label": "", "metadata": {}, "score": "51.27204"}
{"text": "The main effect of rule - based and lexicon - based post - processing is an increase in precision .In cross - validation for full gene names , average precision increased from 68.0 to 82.0 , and average recall increased from 76.6 to 81.1 .", "label": "", "metadata": {}, "score": "51.286148"}
{"text": "McNaught , J. ( 1993 ) User needs for textual corpora in Natural Language .Processing .Literary and Linguistic Computing 8:227 - 234 .Meijs , W. ( 1987 )Preface .In W. Meijs ( ed . )Corpus Linguistics and .", "label": "", "metadata": {}, "score": "51.383854"}
{"text": "Such a volume is also a confirmation that the tension of 1990s , . between ' ' ( a ) those who want[ed ] to know as much as possible about .language [ ... ] and ( b ) those who want[ed ] to know as much as possible .", "label": "", "metadata": {}, "score": "51.387867"}
{"text": "The ECAI papers not present in the book are listed below : . - Language modeling for speech recognition by Frederick Jelinek .- Regular expressions for finite - state syntactic description by Lauri .Karttunen . - Finite - state morphology and information retrieval by Kimmo .", "label": "", "metadata": {}, "score": "51.520096"}
{"text": "The computing device on which the abbreviation system is implemented may include a central processing unit , memory , input devices ( e.g. , keyboard and pointing devices ) , output devices ( e.g. , display devices ) , and storage devices ( e.g. , disk drives ) .", "label": "", "metadata": {}, "score": "51.566475"}
{"text": "The specific problem tested involves disambiguating six senses of the word \" line \" using the words in the current and proceeding sentence as context .The statistical and neural - network methods perform the best on this particular problem and we discuss a potential reason for this ob- served difference .", "label": "", "metadata": {}, "score": "51.714367"}
{"text": "The paper by Srinivas ( chapter 15 ) is a long and complex but .well - written contribution that proposes an approach that combines .manually developed generic grammars with domain - specific constraints .extracted from a corpus .The interesting experimental results seem .", "label": "", "metadata": {}, "score": "51.733078"}
{"text": "For example , if the abbreviation has four letters , then the candidate expansions may be all phrases less than eight words .Each candidate expansion may have one or more mappings to the letters of the abbreviation .FIG .1 illustrates various mappings of a candidate expansion to an abbreviation .", "label": "", "metadata": {}, "score": "51.744118"}
{"text": "4 is a flow diagram that illustrates the high - level processing of the generate candidate expansions component of the abbreviation system in one embodiment .FIG .5 is a flow diagram that illustrates the processing of the identify expansions component of the abbreviation system in one embodiment .", "label": "", "metadata": {}, "score": "51.852737"}
{"text": "\"Alternatively , the abbreviation system may score only one mapping for each candidate expansion .In such a case , the abbreviation system may rank the mappings and select the mapping with the highest rank to represent the candidate expansion .", "label": "", "metadata": {}, "score": "51.913155"}
{"text": "( f ) wherein the computer program displays a list of abbreviations corresponding to selected words to the operator through the input / output unit ; .( g ) wherein the computer program displays a list of words corresponding to selected abbreviations to the operator through the input / output unit ; .", "label": "", "metadata": {}, "score": "51.9999"}
{"text": "FIG .1 , which shows a processing system 10 adapted to perform handwriting recognition .An external interface is also provided as shown at 25 , for coupling the processing system to a store 11 , such as a database .", "label": "", "metadata": {}, "score": "52.01443"}
{"text": "During the generation of templates , individual letters are converted into tokens that represent the class ( or character type ) to which the letter belongs .The definition of letter classes is domain - specific and is selected based on the ambiguity that needs to be resolved .", "label": "", "metadata": {}, "score": "52.107094"}
{"text": "The aim of handwritten character recognition is to accurately convert the pen strokes generated by a writer into the corresponding text .However , handwritten text in inherently ambiguous and thus the use of contextual information is required to decode the input .", "label": "", "metadata": {}, "score": "52.1949"}
{"text": "Step 500 : Checking the text for words and phrases corresponding to abbreviations , and converting said words and phrases to said abbreviations .Step 600 : Checking the text for abbreviations corresponding to words and phrases , and converting said abbreviations to said words or phrases .", "label": "", "metadata": {}, "score": "52.199654"}
{"text": "However , these heuristic approaches are generally not very robust , leading to common misrecognition problems such as : . alphabetic strings recognized as numbers , .numeric strings recognized as alphabetic , . words containing text and numbers ( e.g. 2nd , V8 , B2 ) misrecognized as alphabetic or numeric strings , . misrecognition of punctuation as alphabetic or numeric letters , and . misrecognition of alphabetic or numeric letters as punctuation .", "label": "", "metadata": {}, "score": "52.294514"}
{"text": "others by the same author , for instance that contained in ( Roche and .Schabes 1997 ) .The papers by Tateno , Masuichi & Umemoto and Kim & Jang ( chapters 6 . and 7 ) fail to clearly explain the background and the issues specific .", "label": "", "metadata": {}, "score": "52.357594"}
{"text": "MLAP .Project 93- 19 .Svartvik , J. ( 1992 ) Corpus linguistics comes of age .In J Svartvik .( ed ) Directions in Corpus Linguistics .Proceedings of Nobel Symposium .Stockholm , 4 - 8 August 1991 .", "label": "", "metadata": {}, "score": "52.43123"}
{"text": "In order to better characterize the effect of unknown words on the performance of our system , we analyzed false positives that are one word in length .The percentage of false positives that are one word long is 40 % and 43 % for our system without post - processing and with post - processing , respectively .", "label": "", "metadata": {}, "score": "52.444016"}
{"text": "The abbreviation system calculates a score based on a weighted combination of the features .The abbreviation system learns the weights for the features from training data of abbreviations , candidate expansions , and scores for the candidate expansions .To learn the weights , the abbreviation system generates features for each candidate expansion and inputs a score indicating the likelihood that the candidate expansion is a correct expansion for an abbreviation .", "label": "", "metadata": {}, "score": "52.487915"}
{"text": "In block 1305 , the component increments the count of the capitals of the abbreviation that are not initial letters of words in the mapping and then loops to block 1301 to select the next letter .In block 1306 , the component sets the length of the abbreviation to the number of letters in the abbreviation .", "label": "", "metadata": {}, "score": "52.53249"}
{"text": "The goal of BioCreAtIvE Task1A is to assess the ability of an automated system to identify mentions of genes in text from biomedical literature .The corpus used for Task1A consists of sentences drawn from Medline abstracts and is divided into three sets : training , devtest , and official test .", "label": "", "metadata": {}, "score": "52.537315"}
{"text": "After all text in the corpus has been processed , the table contains a list of all templates encountered in the text , and a count of the number of times each template was seen .To calculate the prior probabilities for a template , the template count is simply divided by the sum of all template counts .", "label": "", "metadata": {}, "score": "52.704895"}
{"text": "In this paper Schapire and Singer 's AdaBoost .MH boosting algorithm is applied to the Word Sense Disambiguation ( WSD ) problem .Initial experiments on a set of 15 selected polysemous words show that the boosting approach surpasses Naive Bayes and Exemplar - based approaches , which represent stat ... \" .", "label": "", "metadata": {}, "score": "52.72464"}
{"text": "0012 ]The apparatus may further comprise a class conversion unit configured to convert one or more words included in the extracted corpus into classes .[ 0013 ] The classes may comprise one or more of a word included in a corpus , a synonym of a word included in the corpus , and a category corresponding to a word in the corpus .", "label": "", "metadata": {}, "score": "52.727985"}
{"text": "This can then be used in the recognition of hand - written text .In particular , if the processor 20 obtains hand - written text , for example from the input device 22 , or the database 11 , the processor will perform an initial assessment to identify character strings , and then attempt to determine the identity of each character in the string .", "label": "", "metadata": {}, "score": "52.7722"}
{"text": "Based on careful error analysis , we implemented a set of post - processing rules to correct both false positives and false negatives .We participated in both the open and the closed divisions ; for the open division , we made use of data from NCBI .", "label": "", "metadata": {}, "score": "52.77488"}
{"text": "It will also be appreciated that more accurate probabilities will be obtained the larger the text corpus used in determining the probabilities .Sample Results .The training procedure was run over a large text corpus , which in this example is the D. Harman and M. Liberman , Complete TIPSTER Corpus , 1993 to generate a set of statistical language templates .", "label": "", "metadata": {}, "score": "52.89453"}
{"text": "In block 311 , the component learns the weights for the features from the training data .In block 312 , the component stores the weights in the weights store and then completes .FIG .4 is a flow diagram that illustrates the high - level processing of the generate candidate expansions component of the abbreviation system in one embodiment .", "label": "", "metadata": {}, "score": "52.947716"}
{"text": "The class conversion unit 160 may convert a noun phrase or an adverb phrase into a noun phrase class or an adverb phrase class .[0045 ] The generation unit 170 may generate grammar for use in the target domain , based on the domain actions provided by the classification unit 140 and the concepts extracted from the corresponding domain actions by the second extraction unit 150 .", "label": "", "metadata": {}, "score": "52.9713"}
{"text": "Proceedings of the Sixth Applied Natural Language Processing Conference ( ANLP-2000 ) .Fukuda K , Tsunoda T , Tamura A , Takagi T : Toward information extraction : identifying protein names from biological papers .Pacific Symposium for Biocomputing 1998 , 3 : 705 - 716 .", "label": "", "metadata": {}, "score": "52.98739"}
{"text": "This suggests that in unseen sentences that it will not likely appear as the last word of a gene mention .The following examples demonstrate how the boundary correction post - processing step would change two gene mentions that mistakenly include the word binding .", "label": "", "metadata": {}, "score": "53.363697"}
{"text": "Journal of Corpus Linguistics 1:2:303 - 314 .Grefenstette , G. ( 1998 )The Future of Linguistics and Lexicographers : .Will there be lexicographers in the year 3000 ? Plenary . address .pp .25 - 41 .Halliday , M. A. K. ( 1998 )", "label": "", "metadata": {}, "score": "53.50621"}
{"text": "In addition , the instructions , data structures , and message structures may be stored or transmitted via a data transmission medium , such as a signal on a communication link .Various communication links may be used , such as the Internet , a local area network , a wide area network , a point - to - point dial - up connection , a cell phone network , and so on .", "label": "", "metadata": {}, "score": "53.514744"}
{"text": "Biber , D. ( 1990 ) Methodological Issues Regarding corpus - based Analyses of Linguistic variation .Literary and Linguistic Computing 5:4:257 - 269 .Biber , D. , S. Conrad and R. Reppen ( 1994 ) Corpus - based Approaches to Issues in Applied Linguistics .", "label": "", "metadata": {}, "score": "53.57129"}
{"text": "When post - processing was applied , average precision and recall were 82.0 and 81.1 .Post - processing improved both the precision and the recall , having a much larger effect on precision than on recall .This tendency is reasonable because our algorithms focus on repairing or removing gene mentions found by the base system and concentrate less on finding new gene mentions that were mistakenly tagged with POS tags such as NN or NNS .", "label": "", "metadata": {}, "score": "53.586708"}
{"text": "The capital as initial features for the mappings of .FIG .1 are shown in line 105 .The abbreviation system uses the capital as non - initial ( \" CNI \" ) feature to measure how many capital letters of the abbreviation correspond to non - initial letters of words in a candidate expansion .", "label": "", "metadata": {}, "score": "53.690254"}
{"text": "FIG .10 is a flow diagram that illustrates the processing of the calculate abbreviation character distribution component of the abbreviation system in one embodiment .The component is passed an abbreviation and a mapping for a candidate expansion and returns the abbreviation character distribution feature .", "label": "", "metadata": {}, "score": "53.928974"}
{"text": "In particular , these techniques generally allow faster , more accurate hand writing recognition to be performed , using less processing power , than in the prior art methods .Baird , HS et al . , \" A Family of European Page Readers \" Pattern Recognition , 1994 , vol .", "label": "", "metadata": {}, "score": "54.028545"}
{"text": "expertise to thoroughly evaluate all the contributions ( and , at the . same time , prospective readers will be probably interested only on a . subset of the papers , depending on their areas of interest ) .Obviously also this review is partly influenced by the reviewer 's . limited knowledge in some areas of NLP ( particularly statistical . techniques ) .", "label": "", "metadata": {}, "score": "54.154446"}
{"text": "If the last word of the long form was tagged as a gene , then we changed any non - gene tags in the long form and abbreviation to GENE .For example , if a long form / abbreviation pair contained the tag sequence JJ NN NN GENE ( NNP ) , then we changed the tags to GENE GENE GENE GENE ( GENE ) .", "label": "", "metadata": {}, "score": "54.322002"}
{"text": "For example , the paper . by Watson ( chapter 4 ) mentions an interest in using the toolkit by . computational linguists .This same generic claim was present in the .original paper at the ECAI workshop .Provided that the ECAI workshop .", "label": "", "metadata": {}, "score": "54.380375"}
{"text": "The papers that appeared also in the ECAI workshop proceedings are marked with \" ECAI \" near the name of the authors .Note that sometimes the ECAI'96 versions are considerably shorter than those in the book .Extended finite state models of language by Andras Kornai This is a general introduction with a brief presentation of the papers contained in the book and of the contents of the CD - ROM 2 .", "label": "", "metadata": {}, "score": "54.396904"}
{"text": "because of some reorganization undergone by the respective web sites .The correct locations should be : .In conclusion , the book is a useful reading for people interested in .the use of finite state techniques in NLP and provides an interesting .", "label": "", "metadata": {}, "score": "54.426495"}
{"text": "0004 ] 2 .Description of the Related Art .[ 0005 ] An increasing amount of attention has been drawn to techniques to search and/or manage information or control various devices using voice data and/or text data input by users .", "label": "", "metadata": {}, "score": "54.504486"}
{"text": "The amount of readily available online text has reached hundreds of billions of words and continues to grow .Yet for most core natural language tasks , algorithms continue to be optimized , tested and compared after training on corpora consisting of only one million words or less .", "label": "", "metadata": {}, "score": "54.6001"}
{"text": "The amount of readily available online text has reached hundreds of billions of words and continues to grow .Yet for most core natural language tasks , algorithms continue to be optimized , tested and compared after training on corpora consisting of only one million words or less .", "label": "", "metadata": {}, "score": "54.6001"}
{"text": "In decision block 302 , if all the abbreviations have already been selected , then the component continues at block 311 , else the component continues at block 303 .In block 303 , the component invokes the generate candidate expansions component to generate candidate expansions from the passages for the selected abbreviation .", "label": "", "metadata": {}, "score": "54.664505"}
{"text": "In block 1201 , the component selects the next letter of the abbreviation .In decision block 1202 , if all the letters have already been selected , then the component continues at block 1206 , else the component continues at block 1203 .", "label": "", "metadata": {}, "score": "54.77227"}
{"text": "Also shown is the distribution of the lengths ( in words ) of the gene mentions .Task1A has two divisions : open and closed .The open division permits systems to use external data resources such as online dictionaries or databases while the closed division does not .", "label": "", "metadata": {}, "score": "54.778633"}
{"text": "We used the training and devtest data to find ambiguous types that have zero or low probability ( less than 3 % ) of having the GENE_BEGIN or GENE_END tag in a multi - word gene name .For all multi - word gene mentions output by the tagger , we check the first word to see if it is on a list of words known not to be tagged GENE_BEGIN .", "label": "", "metadata": {}, "score": "54.80645"}
{"text": "We introduce the reader to the motivations for solving the ambiguity of words and provide a description of the task .We overview supervised , unsupervised , and knowledge - based approaches .The assessment of WSD systems is discussed in the context of the Senseval / Semeval campaigns , aiming at the objective evaluation of systems participating in several different disambiguation tasks .", "label": "", "metadata": {}, "score": "54.83624"}
{"text": "[ 0042 ] The second extraction unit 150 may extract one or more concepts from each domain action classified by the classification unit 140 .For example , the concepts may be parameters that are used for completing each domain action , i.e. , the intention of each sentence .", "label": "", "metadata": {}, "score": "54.956917"}
{"text": "5 or .FIG .6 opens .The window depicted in .FIG .5 enables the user to select from suggested conversions of a word or phrase with more than one corresponding abbreviation .The window depicted in .FIG .", "label": "", "metadata": {}, "score": "54.97516"}
{"text": "[ 0021 ] The method may further comprise converting one or more words included in the extracted corpus into classes .[ 0022 ] The classes may comprise one or more of a word included in a corpus , a synonym of a word included in the corpus , and a category corresponding to a word in the corpus .", "label": "", "metadata": {}, "score": "54.990093"}
{"text": "The capital as non - initial feature is a count of the number of capital letters of the abbreviation that map to non - initial letters of words of the candidate expansion divided by the number of letters of the abbreviation .", "label": "", "metadata": {}, "score": "55.126747"}
{"text": "In one embodiment , the abbreviation system generates features to represent various relationships between an abbreviation and a candidate expansion .The abbreviation system uses an external proximity ( \" EP \" ) feature to represent the difference between the number of words of the candidate expansion and the number of words enveloped by a mapping .", "label": "", "metadata": {}, "score": "55.16078"}
{"text": "Sense disambiguation is an \" intermediate task \" ( Wilks and Stevenson , 1996 ) which is not an end in itself , but rather is necessary at one level or another to accomplish most natural language processing tasks .It is . \" ...", "label": "", "metadata": {}, "score": "55.17354"}
{"text": "This is . obviously due to the fact that the bibliographical references are the .sum of the references of the single contributions ; perhaps it would . have been better if every contribution had listed its references . separately .The links mentioned on page 2 for HTK ( Hidden Markov Model Toolkit ) .", "label": "", "metadata": {}, "score": "55.236946"}
{"text": "Press , London .YapIlIr .Paper presented at 21stICAME Conference , Macquairie .University , Sydney .Leech , G ( 1987 )General Introduction .In R. Garside et al .( eds ) , The .Computational Analysis of English - a corpus - based approach .", "label": "", "metadata": {}, "score": "55.23862"}
{"text": "WSD is considered an AI - complete problem , that is , a task whose solution is at least as hard as the most difficult problems in artificial intelligence .We introduce the reader to the ... \" .Word sense disambiguation ( WSD ) is the ability to identify the meaning of words in context in a computational manner .", "label": "", "metadata": {}, "score": "55.2397"}
{"text": "Our goal was to improve recall without a decrease in precision .Our approach was to examine previously unseen words that were tagged as nouns and were four or more characters in length .If such a word matched a LocusLink symbol , then we tagged it as GENE .", "label": "", "metadata": {}, "score": "55.344795"}
{"text": "The best variant , which we call LazyBoosting , is tested on the largest sense -- tagged corpus available containing 192,800 examples of the 191 most frequent and ambiguous English words .Again , boosting compares favourably to the other benchmark algorithms . .", "label": "", "metadata": {}, "score": "55.36185"}
{"text": "Finite state based reductionist parsing for French by Jean - Pierre Chanod and Pasi Tapanainen ( ECAI ; but see below the description of the paper )The paper describes a parser based on finite state methods .The system includes nondeterministic tokenization , lexical analysis , multiword recognition , shallow syntactic analysis .", "label": "", "metadata": {}, "score": "55.378197"}
{"text": "and an applicative perspective .However , it suffers from a defect .that is often present in books originating from workshops , i.e. the .fact that contributions are uneven in both quality ( i.e. , clarity of .the presentation , systematic coverage of all the main areas in the . field ) and quantity ( length and thoroughness of papers ) .", "label": "", "metadata": {}, "score": "55.399864"}
{"text": "This is repeated for the entire string , such that a number of potential character identity combinations , corresponding to different potential strings , exist .The templates described above are then accessed by the processor 20 , which selects templates having the same number of characters as the respective string .", "label": "", "metadata": {}, "score": "55.431946"}
{"text": "Our experience suggests that the Brill tagger is susceptible to specific kinds of performance problems that we hoped to avoid .However , we did not rigorously compare the performance of the two taggers .The main difference between the two systems is our focus on tailoring the post - processing steps for the BioCreAtIvE task .", "label": "", "metadata": {}, "score": "55.45633"}
{"text": "Learner corpora in a classroom setting provide . naturally occurring examples for the instant use of the teacher and .the student , whereas in the past , language course books as well as . traditional grammars and dictionaries , used invented examples , which . seemed intuitively right to the native - speaker .", "label": "", "metadata": {}, "score": "55.51889"}
{"text": "FIG .1 are shown in line 106 .In one embodiment , the abbreviation system learns the weights of the various features by a regression method based on training data .A linear regression method explains the relationship between x and y with a straight line fit to the training data .", "label": "", "metadata": {}, "score": "55.523293"}
{"text": "FIG .1 are shown in line 101 .The abbreviation system uses an internal proximity ( \" IP \" ) feature to represent a normalized difference between the number of words enveloped by a mapping and the length of the abbreviation .", "label": "", "metadata": {}, "score": "55.84716"}
{"text": "In block 404 , the component establishes an initial probability for each phrase based on the number of occurrences of the phrase .In blocks 405 - 408 , the component iterates identifying phrases with a high probability .In block 405 , the component segments the phrases based on probabilities .", "label": "", "metadata": {}, "score": "55.89475"}
{"text": "In decision block 305 , if all the candidate expansions have already been selected , then the component loops to block 301 to select the next abbreviation , else the component continues at block 306 .In block 306 , the component selects the next mapping for the selected abbreviation to the selected candidate expansion .", "label": "", "metadata": {}, "score": "55.903282"}
{"text": "For example , the domain actions may be categories of user intentions for inducing certain actions or responses from an intention analysis system .The domain actions may differ from one domain to another domain .The classification unit 140 may classify the corpus provided by the removal unit 130 into one or more domain actions corresponding to the target domain .", "label": "", "metadata": {}, "score": "55.905663"}
{"text": "FIG .1 is a functional block diagram of a data processing system that can be used to generate statistical model training data in accordance with the present invention .FIG .2 is a flowchart of a method implemented by the processor shown in .", "label": "", "metadata": {}, "score": "56.180126"}
{"text": "The method of .claim 1 wherein : . generating context information includes generating local context information and discourse context information ; and .storing training data includes storing local context data and discourse data as training data .The method of . claim 1 and further including processing text using a Maximum Entropy model and the stored feature vectors to normalize abbreviations in the text .", "label": "", "metadata": {}, "score": "56.211594"}
{"text": "The computer system of .claim 1 wherein the features are selected from a group consisting of an external proximity feature , an internal proximity feature , an abbreviation character distribution feature , a capital as initial feature , and a capital as non - initial feature .", "label": "", "metadata": {}, "score": "56.215622"}
{"text": "To avoid the combinatorial memory and processing requirements for large - vocabulary word N - grams , some systems use word - class N - grams , where the transition probabilities are defined for the part - of - speech tag of the word ( e.g. noun or verb ) rather than for individual words .", "label": "", "metadata": {}, "score": "56.216324"}
{"text": "a ) a computer having a memory , a central processing unit , and an input / output unit ; .b ) a first data structure recorded in the memory , the first data structure encoding a plurality of words and corresponding abbreviations ; .", "label": "", "metadata": {}, "score": "56.385788"}
{"text": "Long before the age of ' multiculturalism ' and computers , most communities used at least some elements from a second language as part of their daily communication , or from more languages .Similar examples may be listed from all over the world .", "label": "", "metadata": {}, "score": "56.405273"}
{"text": "The list of . bibliographical references presents some mistakes : for example , Roche .& Schabes 1997 is wrongly cited as \" Finite - State Devices for Natural .Language Processing \" ( the correct title is \" Finite - State Language .", "label": "", "metadata": {}, "score": "56.41619"}
{"text": "The POS tagger .Past experience with the ABGene system in our lab suggested that the POS - tagging - based approach to entity identification is workable in the molecular biology domain .Previous experiments with the TnT Trigrams ' n ' Tags POS tagger , using the GENIA corpus for cross - validation , showed good results with no post - processing of the output .", "label": "", "metadata": {}, "score": "56.496277"}
{"text": "In block 1108 , the component outputs underscore(s ) to the abbreviation occurrence pattern for the next word(s ) that does not contain the selected letter .In block 1109 , the component outputs the selected letter to the abbreviation occurrence pattern and then loops to block 1105 to select the next letter .", "label": "", "metadata": {}, "score": "56.600464"}
{"text": "- Kim : the morphological analyzer described in chapter 7 . -Kornai : the NewsMonitor system , described in chapter 10 .-Uniparse : the source code of the parser described in chapter 2 by .Joshi and Hopely .", "label": "", "metadata": {}, "score": "56.78611"}
{"text": "3 illustrates an example of a method for automatically generating grammar for use in the processing of natural language .[ 0056 ] Referring to FIG .3 , in 300 , one of a plurality of domains is set as a target domain that is to be processed by an intention analysis system .", "label": "", "metadata": {}, "score": "56.843346"}
{"text": "Language Model Combination .In the example given above , the string of the best matching template was selected as the decoded string .Usually , however , the matched template will be combined with other language models for additional processing .", "label": "", "metadata": {}, "score": "56.86388"}
{"text": "Sometimes the link between formal results . and NLP is more explicit : the theoretical paper by Nederhof & Bertsch .( chapter 18 ) provides some more direct hints at the usefulness of the .results proposed for NLP .Given my limited knowledge of statistical techniques , I can not . thoroughly evaluate the paper by Ristad ( chapter 19 ) .", "label": "", "metadata": {}, "score": "56.88208"}
{"text": "The collection of corpora may be updated periodically or aperiodically .[0036 ] For example , if the target domain is a TV control domain , the first extraction unit 120 may extract a corpus that is relevant to the TV control domain from among the collection of corpora .", "label": "", "metadata": {}, "score": "56.8964"}
{"text": "It uses a second - order Markov model with tags as states and words as outputs .Smoothing is done with linear interpolation of unigrams , bigrams , and trigrams , with \u03bb estimated by deleted interpolation .Unknown words are handled by learning tag probabilities for word endings .", "label": "", "metadata": {}, "score": "56.9069"}
{"text": "Context information describing the context of the text in which the expansions were identified is generated .Training data is then stored as a function of the context information .In other embodiments of the invention , the context information stored as the training data includes local context level information and discourse level information .", "label": "", "metadata": {}, "score": "56.9132"}
{"text": "MH boosting algorithm is applied to the Word Sense Disambiguation ( WSD ) problem .Initial experiments on a set of 15 selected polysemous words show that the boosting approach surpasses Naive Bayes and Exemplar - based approaches , which represent state - of - the - art accuracy on supervised WSD .", "label": "", "metadata": {}, "score": "56.91938"}
{"text": "REFERENCES .Atkins , B. T. S. , B. Levin and A. Zampolli ( 1994 ) Computational Approaches to the Lexicon : An Overview .In B.T.S. Atkins and A. Zampolli ( eds . )Computational Approaches to the Lexicon .Oxford University Press , Oxford .", "label": "", "metadata": {}, "score": "57.07528"}
{"text": "Both parties have used computers , the former to interpret and the latter to generate natural language .Generally - speaking , the term ' natural language ' has been perceived as speech or writing produced in ' natural settings ' , with the term ' natural ' meaning ' ideal ' in a setting where only one language is used with its rules perfectly in place .", "label": "", "metadata": {}, "score": "57.103462"}
{"text": "The resulting average precision and recall with post - processing was 82.0 and 81.1 , respectively .The averaged results of the cross - validation runs are shown in Figure 1A .The results for official test are shown in Figure 1B .", "label": "", "metadata": {}, "score": "57.109787"}
{"text": "Finite automata for processing word order by Wojciech Skut . - Multilingual text analysis for text - to - speech synthesis by Richard .Sproat .CRITICAL EVALUATION .The book contains papers that cover the application of finite state . techniques to a wide range of NLP areas ( morphological analysis , POS . tagging , clause boundary detection , syntactic analysis , etc . ) .", "label": "", "metadata": {}, "score": "57.11881"}
{"text": "On the level of individual token ( including unknown words ) , post - processing had a much smaller , and not always positive , effect .The main effect of dictionary - based post - processing is an increase in recall .", "label": "", "metadata": {}, "score": "57.154198"}
{"text": "Statistical language template processing is a method of encoding prior information regarding the structure of written text that models the interaction between alphabetic , numeric , and punctuation characters using a probabilistic model .The model considers positional information , and is able to model letter dependencies globally by considering the entire input word ( rather than a fixed number of local preceding states as in character N - grams ) .", "label": "", "metadata": {}, "score": "57.159447"}
{"text": "For example , discourse characterizations could be expanded to include the type of medical service associated with the record ( e.g. , cardiology , rheumatology and endocrinology ) .In the non - medical area the field could be considered ( e.g. , legal , banking and accounting ) .", "label": "", "metadata": {}, "score": "57.182426"}
{"text": "claim 1 , wherein the character types include digits , letters , and punctuation marks .The method of .claim 1 , wherein the template probability is determined by statistical analysis of a text corpus .Descripci\u00f3n .CROSS REFERENCES TO RELATED APPLICATIONS .", "label": "", "metadata": {}, "score": "57.25792"}
{"text": "As another example , the second extraction unit 150 may extract the word ' next ' from the ' GetNextProgram ' domain action 213 as a ' genre ' concept 225 .[0052 ] The class conversion unit 160 may convert one or more words in each of the domain actions into classes .", "label": "", "metadata": {}, "score": "57.3056"}
{"text": "An evaluation of the parser effectiveness in analyzing a large corpus is presented .Vectorized finite state automata by Andras Kornai ( ECAI )It presents a technique of finite state parsing based on vectorization and describes the application of such technique to the problem of extracting relational information from texts .", "label": "", "metadata": {}, "score": "57.524567"}
{"text": "The volume places emphasis on devising better methods of .differentiation between speech and writing , although this seems to be .a contradiction in terms .One can not ignore that the use of the . internet for daily communication , and the globalisation factor . creating new diasporas , are two strong forces that are rapidly .", "label": "", "metadata": {}, "score": "57.546722"}
{"text": "In one embodiment , the component identifies candidate expansions from snippets using a language model to identify sequences of phrases with the highest probabilities .In block 401 , the component identifies phrases within the passages up to a length of N. In block 402 , the component counts the number of occurrences of each phrase .", "label": "", "metadata": {}, "score": "57.701336"}
{"text": "6 is a flow diagram that illustrates the processing of the score candidate expansions component of the abbreviation system in one embodiment .FIG .7 is a flow diagram that illustrates the processing of the calculate external proximity component of the abbreviation system in one embodiment .", "label": "", "metadata": {}, "score": "57.70804"}
{"text": "8 is a flow diagram that illustrates the processing of the calculate internal proximity component of the abbreviation system in one embodiment .FIG .9 is a flow diagram that illustrates the processing of the identify enveloping sub - phrase component of the abbreviation system in one embodiment .", "label": "", "metadata": {}, "score": "57.88131"}
{"text": "Example : the / DT dnHLH / NEWGENE protein / NEWGENE Id1/ NEWGENE1 inhibits / VBZ .Tag set 2 : Detailed boundary information .This tag set contains four gene tags : ' GENE_BEGIN ' , ' GENE_INSIDE ' , ' GENE_END ' , and ' GENE_ONEWORD ' .", "label": "", "metadata": {}, "score": "57.93796"}
{"text": "Tree Adjoining Grammars ) because they crucially employ some of its . specific characteristics .In the paper by Kornai ( chapter 10 ) it would have been interesting to .provide more details about the application of vectorized finite state . automata , i.e. the NewsMonitor system ( also present in the . accompanying CD - ROM ) .", "label": "", "metadata": {}, "score": "57.964798"}
{"text": "Experiments conducted to test this hypothesis demonstrate a high degree of correlation in the distribution of abbreviations compared to the distribution of their expansions .The experiment was conducted by processing a corpus of approximately 171,000 rheumatology notes .Here w i is either the abbreviation \" DJD \" or it 's multi - word expansion \" degenerative joint disease . \"", "label": "", "metadata": {}, "score": "58.03396"}
{"text": "claim 1 , wherein the word is selected by the user using a mouse .The method of .claim 1 , wherein the abbreviation is selected by the user using a keyboard command .The method of .claim 1 , wherein the abbreviation is selected by the user using a mouse .", "label": "", "metadata": {}, "score": "58.10854"}
{"text": "pp .17 - 45 .Biber , D. ( 1989 )A Typology of English texts .Linguistics 27:3 - 43 .Biber , D. ( 1990 ) Methodological Issues Regarding corpus - based Analyses . of Linguistic variation .Literary and Linguistic Computing .", "label": "", "metadata": {}, "score": "58.115517"}
{"text": "Sentence as the central unit of linguistic analysis was questioned ( Sinclair 1996 ) and alternative units of analysis continue to be discussed today ( Mukherjee on tone- unit pp .21 - 134 ) .As 20th century came to an end , a prediction as to the future of Linguistics in general was that it would advance in two directions : computational corpus research and the mental lexicon ( Halliday 1998 ) .", "label": "", "metadata": {}, "score": "58.1417"}
{"text": "13 is a flow diagram that illustrates the processing of the calculate capitals as non - initial component of the abbreviation system in one embodiment .The component is passed an abbreviation and a mapping to a candidate expansion and returns the capital as non - initial feature .", "label": "", "metadata": {}, "score": "58.224693"}
{"text": "Rule 2 .Rule 3 .If the last word was one of a small list of gene keywords such as protein and factor derived from the BioCreAtIvE specification , then all tags in the long form ( and the abbreviation ) were changed to GENE .", "label": "", "metadata": {}, "score": "58.426193"}
{"text": "The default gene tag set contains two gene tags : ' NEWGENE ' and ' NEWGENE1 ' .The latter tag is used when two gene mentions are immediately next to each other in the text .Approximately 1.1 % of the gene mentions in the training and devtest sets are tagged with the ' NEWGENE1 ' tag .", "label": "", "metadata": {}, "score": "58.439545"}
{"text": "If a word contains hyphen and the characters preceding the hyphen are capitalized letters or digits and the material following the hyphen is a gene keyword such as mutan t , then it is tagged GENE , e.g. SH2-mutant , and ANP - receptor .", "label": "", "metadata": {}, "score": "58.46084"}
{"text": "Natural .Language Engineering , 2(4 ) : 337 - 344 .( appeared also in the Proceedings . of the ESSLLI ' 96 Robust Parsing Workshop ; also available at the .Eva Ejerhed , Frederic Jelinek , Lauri Karttunen , Andras Kornai ( eds . )", "label": "", "metadata": {}, "score": "58.512703"}
{"text": "FIG .1 is a functional schematic illustration of a data processing system 10 that can be used in accordance with a preferred embodiment of the present invention to generate Maximum Entropy feature vectors .As shown , system 10 includes abbreviation / expansion database 12 , health record database 14 , feature vector database 16 and processor 18 .", "label": "", "metadata": {}, "score": "58.601013"}
{"text": "If a words length has less than two characters and contains digits , Greek letters or roman numerals , then it is tagged NN . ...If the word mutation is followed by a word tagged GENE , then the word is tagged NN .", "label": "", "metadata": {}, "score": "58.68245"}
{"text": "0058 ]In 350 , the apparatus converts one or more words in each of the domain actions into classes .In 360 , the apparatus generates grammar for use in the target domain for each of the domain actions , based on the concepts extracted from each of the domain actions .", "label": "", "metadata": {}, "score": "58.71093"}
{"text": "Processing .MIT Press , Cambridge , MA .XTAG Group 1995 .A Lexicalized Tree Adjoining Grammar for English .Technical Report IRCS 95 - 03 , University of Pennsylvania .ABOUT THE REVIEWER .Alberto Lavelli is a researcher at ITC - IRST in Trento ( Italy ) .", "label": "", "metadata": {}, "score": "58.727512"}
{"text": "We are fortunate that for this particular application , correctly labeled training data is free .Since this will often not be the case , we examine methods for effectively exploiting very large corpora when labeled data comes at a cost . \" ...", "label": "", "metadata": {}, "score": "58.779198"}
{"text": "If Entrez returned any items , then we tagged the word as GENE .Declarations .Acknowledgements .We would like to thank Thorsten Brants who made TnT available for this research .We also wish to acknowledge NIH / NIAAA grant 5U01 AA13524 - 02 ( Hunter , PI ) which supported this research , and Fujitsu , Inc. , which funded a year - long internship for SK in the Hunter laboratory .", "label": "", "metadata": {}, "score": "58.841343"}
{"text": "The apparatus of claim 1 , further comprising a removal unit configured to remove at least one of ungrammatical words or sentences from the extracted corpus .The apparatus of claim 1 , further comprising a class conversion unit configured to convert one or more words included in the extracted corpus into classes .", "label": "", "metadata": {}, "score": "58.860268"}
{"text": "Table 4 shows the individual post - processing effects in our cross - validation testing .It shows that removing rule - based post - processing or removing the lexicon - based post - processing from the post - processing steps has nearly the same effect .", "label": "", "metadata": {}, "score": "58.98624"}
{"text": "English Language Research on Computerised Corpora .Rodopi , .Amsterdam . pp . ii-v. .Oostdijk , N. and P. de Haan ( eds . )( 1994 ) Corpus - Based Research into .Language : In Honour of Jan Aarts .", "label": "", "metadata": {}, "score": "59.03284"}
{"text": "Although the subject matter has been described in language specific to structural features and/or methodological acts , it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above .", "label": "", "metadata": {}, "score": "59.043465"}
{"text": "Similarly if the template contains a ' d ' , the score of the highest ranked digit is used .For punctuation , the score of the specified punctuation character is used .If log - probabilities are used for the templates , the classifier output must also be converted to log - probabilities , and the decoding procedure finds the maximum of : .", "label": "", "metadata": {}, "score": "59.048466"}
{"text": "The Future of Linguistics and Lexicographers : Will there be lexicographers in the year 3000 ?Plenary address .EURALEX 98 , Proceedings , Univ . of Li\u00e8ge .pp .25 - 41 .Halliday , M. A. K. ( 1998 )", "label": "", "metadata": {}, "score": "59.23793"}
{"text": "English pp .159 - 175 ) or in language learning contexts ( Aronsson . on Swedish - English pp .197 - 210 ; Neff et al . on .Spanish / Dutch / Italian / French / German in contact with English pp .", "label": "", "metadata": {}, "score": "59.27269"}
{"text": "corpus - based analysis to compare the compositions of university .students , written in Ecuadorian Spanish and English .Also in Canada , .the acquisition of French by the Portugese as well as other migrant . groups as a second language has been investigated using a corpus - based . approach ( Bazergui et al .", "label": "", "metadata": {}, "score": "59.378082"}
{"text": "3 is a flowchart illustrating an example of a method for automatically generating grammar for use in the processing of natural language .[ 0029 ] Throughout the drawings and the detailed description , unless otherwise described , the same drawing reference numerals will be understood to refer to the same elements , features , and structures .", "label": "", "metadata": {}, "score": "59.47738"}
{"text": "Among the contributions included in the NLE special issue and not . present in the book for various reasons , I have found particularly . interesting the paper \" Partial parsing via finite - state cascades \" by .Steven Abney .", "label": "", "metadata": {}, "score": "59.519325"}
{"text": "0037 ]For example , the first extraction unit 120 may use vectors to represent the collection of corpora and a reference corpus .The first extraction unit 120 may extract the corpus relevant to the target domain by comparing the similarity between the vectors .", "label": "", "metadata": {}, "score": "59.542694"}
{"text": "Statistical template generation is performed using a written - text corpus ( a large set of text files collected from a number of sources ) .To generate template statistics , each file in the corpus is processed as a sequential set of letters delimited by white space ( i.e. word , sentence , and paragraph markers ) .", "label": "", "metadata": {}, "score": "59.688766"}
{"text": "An abbreviation occurrence pattern includes each letter of the abbreviation along with underscores to indicate transitions between words .For example , the abbreviation occurrence pattern for \" MSRA \" in the mapping \" Microsoft Research Asia \" as indicated by the underlined letters is \" Ms_R_A \" and for \" MSRA \" in the mapping \" Microsoft Research Asia \" is \" M_s_r_A. \" The abbreviation occurrence patterns for the mappings of .", "label": "", "metadata": {}, "score": "59.718307"}
{"text": "The Unified Medical Language System ( UMLS ) is a database containing biomedical information and tools developed at the National Library of Medicine .It has been estimated that about 33 % of the abbreviations in the UMLS are ambiguous .In addition to problems associated with text interpretation , abbreviations constitute a major source of errors in a system that automatically generates lexicons for medical natural language processing ( NLP ) .", "label": "", "metadata": {}, "score": "59.772217"}
{"text": "i .f .x .i .y .i .i .i .i .i .n .FIG .2 is a block diagram that illustrates components of the abbreviation system in one embodiment .The abbreviation system 230 may be connected to various server systems 210 and client systems 211 via communications link 220 .", "label": "", "metadata": {}, "score": "59.876106"}
{"text": "corpus research but the title of the volume EXTENDING THE SCOPE OF .CORPUS - BASED RESEARCH must have been selected with this distinction in . mind .In the data - driven approach the linguist investigates the corpus .with an open mind to discover how language really works as opposed to .", "label": "", "metadata": {}, "score": "59.97663"}
{"text": "According to an aspect of the present invention there is provided a method of classifying a character string formed from a known number of hand - written characters , said method comprising the steps of : . determining by a processor character probabilities for each hand - written character in the character string , each character probability representing a likelihood of the respective hand - written character being a respective one of a plurality of predetermined characters , each predetermined character has a respective character type ; . identifying by the processor character templates having the known number of characters , each character template having a respective predetermined probability and representing a respective combination of character types ; . classifying by the processor the character string as the sequence of characters having the highest character sequence probability .", "label": "", "metadata": {}, "score": "60.05842"}
{"text": "1 ) , whose functions are explained further in the flowcharts .It will be understood by one of ordinary skill in the art that .FIG .1 also serves as a pictorial description of the data structures created by the apparatus in order to carry out the described data processing .", "label": "", "metadata": {}, "score": "60.064083"}
{"text": "The apparatus of claim 1 , wherein the first extraction unit uses vectors to represent the collection of corpora and a reference corpora , and the first extraction unit extracts the corpus relevant to the target domain based on a comparison of the vectors .", "label": "", "metadata": {}, "score": "60.17917"}
{"text": "The abbreviation system includes components for learning the weights for the features .The components include a collect data component 231 , a learn feature weights component 232 , and a weights store 233 .The collect data component may submit various abbreviations as queries to a search engine service and stores the resulting snippets as training data .", "label": "", "metadata": {}, "score": "60.186687"}
{"text": "Referring back to .FIG .2 , the method begins by processing the health records to locate the desired expansions as shown at step 40 .In one embodiment of the invention , step 40 is performed by filtering the health record through a dynamic sliding window buffer having a maximum window size set to the maximum length of any desired expansion .", "label": "", "metadata": {}, "score": "60.26037"}
{"text": "BACKGROUND ART .The reference to any prior art in this specification is not , and should not be taken as , an acknowledgment or any form of suggestion that the prior art forms part of the common general knowledge .One of the major issues faced in the development of highly accurate handwriting recognition systems is the inherent ambiguity of handwriting .", "label": "", "metadata": {}, "score": "60.416862"}
{"text": "[ 0033 ] Natural language processing is an artificial intelligence ( AI ) technique that may be used to understand , analyze , and/or create human language using an intention analysis system .For example , natural language may be created based on text , audio data , graphic data , and the like .", "label": "", "metadata": {}, "score": "60.514545"}
{"text": "3 is an illustration of an exemplary format for such a feature vector .Steps 40 , 42 , 44 , 46 and 48 are repeated for each desired health record in database 14 .A file of one or more , and typically many feature vectors are thereby generated for each abbreviation and expansion set .", "label": "", "metadata": {}, "score": "60.525436"}
{"text": "1 to generate training data in accordance with the present invention .FIG .3 is an illustration of an example of the format of training data that can be generated in accordance with the method shown in .FIG .2 . DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS .", "label": "", "metadata": {}, "score": "60.5442"}
{"text": "The same techniques can therefore easily be applied in this situation .In this example , Lidstones 's Law , as described in \" Foundations of Statistical Natural Language Processing \" , mentioned above has been used to smooth the generated probabilities , such that : .", "label": "", "metadata": {}, "score": "60.562294"}
{"text": "For example , the software and data may be stored by one or more computer readable storage mediums .Also , the described unit to perform an operation or a method may be hardware , software , or some combination of hardware and software .", "label": "", "metadata": {}, "score": "60.57263"}
{"text": "The method of claim 11 , wherein the domain actions are categories of user intentions for inducing actions and/or responses from an intention analysis system .The method of claim 11 , further comprising extracting one or more concepts from each of the domain actions , wherein the generating the grammar comprises generating the grammar based on the domain actions and the concepts that are extracted from each of the domain actions .", "label": "", "metadata": {}, "score": "60.630028"}
{"text": "[ 0039 ] The removal unit 130 may remove unnecessary words and/or sentences from the corpus extracted by the first extraction unit 120 .For example , the removal unit 130 may remove words and/or sentences that are not grammatical or irrelevant to the target domain from the corpus extracted by the first extraction unit 120 .", "label": "", "metadata": {}, "score": "60.657482"}
{"text": "1996 ) .While the majority of the . contributions in the volume may be considered corpus - based , some may . be considered corpus - driven ( e.g. Gotti on the use of SHALL and WILL .pp .135 - 148 ) .", "label": "", "metadata": {}, "score": "60.70516"}
{"text": "1 is an example of a processing system suitable for performing the present invention .MODES FOR CARRYING OUT THE INVENTION .The following modes are described as applied to the written description and appended claims in order to provide a more precise understanding of the subject matter of the present invention .", "label": "", "metadata": {}, "score": "60.749004"}
{"text": "6 .LINGUIST List 14.2667 .Fri Oct 3 2003 .Review : Text / Corpus Ling : Granger & Petch - Tyson ( 2003 ) .What follows is a review or discussion note contributed to our Book Discussion Forum .", "label": "", "metadata": {}, "score": "60.79525"}
{"text": "None of the probability distribution is assigned to templates that were not encountered in the training text , and thus these templates are assigned a zero - probability .Since the text corpus can only ever represent a subset of the potential input to the language model , a smoothing model must be applied to decrease the probability of the observed events by a small amount and assign the residual probability mass to unseen events .", "label": "", "metadata": {}, "score": "60.930107"}
{"text": "i .n .P .x .i . )For classifiers that do not generate probabilities ( for example , classifiers that report distance values ) , the output score vector should be normalised to ensure the above rules hold .", "label": "", "metadata": {}, "score": "61.21505"}
{"text": "WA1.27.1 - 4 .In this case , the Viterbi algorithm uses classifier scores and word probabilities to decode input text sentences .In this case , domain - specific knowledge that Zip codes have a fixed length , and each digit in the code has a specific physical meaning is used to aid recognition .", "label": "", "metadata": {}, "score": "61.407196"}
{"text": "[ 0060 ] Program instructions to perform a method described herein , or one or more operations thereof , may be recorded , stored , or fixed in one or more computer - readable storage media .The program instructions may be implemented by a computer .", "label": "", "metadata": {}, "score": "61.42982"}
{"text": "A method of classifying a character string formed from a known number of hand - written characters , said method comprising the steps of : . determining by a processor character probabilities for each hand - written character in the character string , each character probability representing a likelihood of the respective hand - written character being a respective one of a plurality of predetermined characters , each predetermined character has a respective character type ; . identifying by the processor character templates having the known number of characters , each character template having a respective predetermined probability and representing a respective combination of character types ; . classifying by the processor the character string as the sequence of characters having the highest character sequence probability .", "label": "", "metadata": {}, "score": "61.504204"}
{"text": "That both sets of results show the same trends shows that our system did not over - train on the devtest corpus and that it performs consistently .Precision and Recall .Figure 1A shows the precision and recall for the cross validation data .", "label": "", "metadata": {}, "score": "61.522907"}
{"text": "Literary and Linguistic Computing 8:227 - 234 .Meijs , W. ( 1987 )Preface .In W. Meijs ( ed . )Corpus Linguistics and Beyond - Proceedings of the Seventh International Conference on English Language Research on Computerised Corpora .", "label": "", "metadata": {}, "score": "61.576958"}
{"text": "2 n. 4 , December 1996 ) a set of articles partially overlapping with those present in this book appeared ( some of the NLE papers are only abstracts of 2 or 3 pages ) .The electronic versions of the papers presented at the ECAI'96 workshop are included in the CD - ROM accompanying the book .", "label": "", "metadata": {}, "score": "61.692772"}
{"text": "Character sequence probabilities corresponding to each of the character templates having the known number of characters are next determined .The character sequence probabilities are a function of the predetermined probability of the respective character template and the character probabilities of the hand - written character in the character string .", "label": "", "metadata": {}, "score": "61.71331"}
{"text": "Recall actually degraded somewhat .These data are consistent with our findings that many of our post - processing steps correct the boundaries of gene mentions at the term level .Per - token performance on unknown words .We use the phrase unknown word to describe a word that was not previously seen in the training corpora .", "label": "", "metadata": {}, "score": "61.720367"}
{"text": "[ 0006 ] In order to analyze the intention of a user based on audio or text data input by the user , grammar is typically used ( i.e. spoken words or written / typed words ) .For example , a user intention analysis device may use grammar such as audio or text data input by a user to analyze the intention of the user .", "label": "", "metadata": {}, "score": "61.80253"}
{"text": "Both the commercial and the non - commercial toolkit implement algorithms for building automata from regular expressions and for minimizing deterministic finite automata .Finite state morphology and formal verification by Manuel Vilares Ferro , Jorge Grana Gil and Pilar Alvarino Alvarino It presents the use of verification methods to ease maintenance during the development of resources for morphological analyzers .", "label": "", "metadata": {}, "score": "61.806007"}
{"text": "In block 902 , the component sets the last word to the word of the candidate expansion that contains the last letter of the mapping .In block 903 , the component sets a sub - phrase to the first word and the last word .", "label": "", "metadata": {}, "score": "62.034496"}
{"text": "English and German .We were impressed by its availability on a variety of platforms , its intuitive interface , and the stability of its distribution , which installed easily and never crashed .For the official test we trained TnT on both the training corpus and devtest corpus and then tested it on the official test set .", "label": "", "metadata": {}, "score": "62.080902"}
{"text": "System 10 generates sample vectors or feature vectors for one or more specific abbreviations to be normalized by the data processing system with which the training data is to be subsequently used .These feature vectors are also generated for each selected expansion or possible meaning of the abbreviation that it is desired to subsequently normalize .", "label": "", "metadata": {}, "score": "62.153362"}
{"text": "claim 1 , further comprising the step of adding to , editing , updating and customizing the first data structure and second data structure .The method of .claim 1 , wherein the word is selected by the user using a keyboard command .", "label": "", "metadata": {}, "score": "62.22773"}
{"text": "While the majority of the contributions in the volume may be considered corpus - based , some may be considered corpus - driven ( e.g. Gotti on the use of SHALL and WILL pp .91 - 109 ; Ketteman , K\u00f6nig and Marko on the morpheme ECO pp .", "label": "", "metadata": {}, "score": "62.42896"}
{"text": "Center for Computational Pharmacology , University of Colorado School of Medicine .Fujitsu Ltd , BioChemical Information Project .Dept . of Computer Science , University of Colorado at Boulder .References .Tanabe L , Wilbur WJ : Tagging gene and protein names in biomedical text .", "label": "", "metadata": {}, "score": "62.479427"}
{"text": "Statistical Template Processing .This section describes the use of statistical templates in the decoding of handwritten text .The general procedure is given , together with some example processing .A description of how to combine this technique with other language models is also given .", "label": "", "metadata": {}, "score": "62.490875"}
{"text": "As said above , given .the wide range of NLP areas covered by the contributions , many .prospect readers will probably be interested only in part of the . papers in the book .BIBLIOGRAPHY .Steven Abney 1996 .", "label": "", "metadata": {}, "score": "62.50971"}
{"text": "The expression \" w/o post - p \" is used as \" without post - processing \" .Table 2 .The term - level score comparison between the cross - validation and official test .This table shows the term - level scores about the cross - validation data and official test .", "label": "", "metadata": {}, "score": "62.634953"}
{"text": "This paper describes a parser based on a cascade of finite state transducers developed at the University of Pennsylvania in 1958 .The parser is remarkably modern when compared to some of the recent work on finite state transducers .A faithful reconstruction of the parser is available on the CD - ROM .", "label": "", "metadata": {}, "score": "62.663147"}
{"text": "10 is a flow diagram that illustrates the processing of the calculate abbreviation character distribution component of the abbreviation system in one embodiment .FIG .11 is a flow diagram that illustrates the processing of the generate abbreviation occurrence pattern component of the abbreviation system in one embodiment .", "label": "", "metadata": {}, "score": "62.822647"}
{"text": "The mapping ( M 11 , s 11 , R 21 , a 21 ) represents a mapping to the underlined letters in \" Microsoft Research Asia .\" The abbreviation system generates a score for each mapping of the candidate expansions and ranks candidate expansions based on the scores of their mappings .", "label": "", "metadata": {}, "score": "62.868484"}
{"text": "Tests of the invention described below were conducted on a Maximum Entropy implementation similar to that described in the Ratnaparkhi paper and developed as part or the open source Maxent 1.2.4 package .Ratnaparkhi , Maximum Entropy Part of Speech Tagger , Proceedings of the Conference on Empirical Methods in Natural Language Processing , University of Pennsylvania , ( May , 1996 ) .", "label": "", "metadata": {}, "score": "62.90413"}
{"text": "The feature vectors generated in this manner are then stored in database 16 .FIG .2 is a flowchart illustrating the processing method performed by processor 18 to generate the feature vectors .The method generates feature vectors that describe the context in which the expansions occur in the medical records .", "label": "", "metadata": {}, "score": "63.008804"}
{"text": "[0031 ] FIG .1 illustrates an example of an apparatus for automatically generating grammar for use in the processing of natural language .The apparatus may be included in a terminal , for example , a computer , a mobile terminal , a smart phone , a camera , an MP3 player , a tablet , a home appliance , and the like . [ 0032 ] Referring to FIG .", "label": "", "metadata": {}, "score": "63.03627"}
{"text": "However , if the performance has not yet flattened off ( or worsened ) , then there is hope that our system can be improved simply by training on more data .There are two aspects specific to our system that we would like to explore .", "label": "", "metadata": {}, "score": "63.07821"}
{"text": "The method of claim 10 , further comprising converting one or more words included in the extracted corpus into classes .The method of claim 10 , wherein the classes comprise one or more of a word included in a corpus , a synonym of a word included in the corpus , and a category corresponding to a word in the corpus .", "label": "", "metadata": {}, "score": "63.26164"}
{"text": "In decision block 1204 , if the selected letter is the initial letter of the word according to the mapping , then the component continues at block 1205 , else the component loops to block 1201 to select the next letter .", "label": "", "metadata": {}, "score": "63.373253"}
{"text": "there has been a tendency to view the ' natural setting ' as . monolingual , although it is hardly the case in everyday life .Long . before the age of ' multiculturalism ' and computers , most communities .used at least some elements from a second language as part of their .", "label": "", "metadata": {}, "score": "63.406536"}
{"text": "The media may include , alone or in combination with the program instructions , data files , data structures , and the like .Examples of program instructions include machine code , such as produced by a compiler , and files containing higher level code that may be executed by the computer using an interpreter .", "label": "", "metadata": {}, "score": "63.533638"}
{"text": "In block 502 , the component selects the next candidate expansion .In decision block 503 , if all the candidate expansions have already been selected , then the component continues at block 508 , else the component continues at block 504 .", "label": "", "metadata": {}, "score": "63.549786"}
{"text": "empirically verify the claims about the advantages of the proposed .method with respect to the standard ones .Most contributions provide some kind of experimental evaluation of the .proposed techniques .However , it is not always clear if such .", "label": "", "metadata": {}, "score": "63.632603"}
{"text": "In this analysis a true positive is a single word that is tagged as GENE both in the gold standard and by our system .As would be expected , performance on single words is better than the term - level results , with an average precision of 88.3 and average recall of 78.7 without post - processing , and an average precision of 92.5 and average recall of 77.8 with post - processing .", "label": "", "metadata": {}, "score": "63.79513"}
{"text": "In block 1206 , the component sets the length of the abbreviation to the number of letters in the abbreviation .In block 1207 , the component sets the capital as initial feature to the count divided by the length of the abbreviation and then returns the capital as initial feature .", "label": "", "metadata": {}, "score": "64.37038"}
{"text": "Figure 2A shows the effect of term length for the cross validation data .Figure 2B shows the effect of term length for the official test data .Recall and precision tend to be better for shorter gene mentions .However precision tends to degrade slightly for gene mentions that are only one word long .", "label": "", "metadata": {}, "score": "64.38899"}
{"text": "j .p .b .j .x .j .e . where q represents a value between 0 and 1 .The abbreviation system uses a maximum likelihood method to select weights that maximize the probability of getting the scores .", "label": "", "metadata": {}, "score": "64.44333"}
{"text": "DETAILED DESCRIPTION .[ 0030 ] The following description is provided to assist the reader in gaining a comprehensive understanding of the methods , apparatuses , and/or systems described herein .Accordingly , various changes , modifications , and equivalents of the methods , apparatuses , and/or systems described herein will be suggested to those of ordinary skill in the art .", "label": "", "metadata": {}, "score": "64.540215"}
{"text": "The modeling includes a set of training data known as feature vectors , which are predefined features or constraints that uniformly distribute the probability space between the candidates that do not conform to the constraints .Features are represented by indicator functions of the following kind .", "label": "", "metadata": {}, "score": "64.64752"}
{"text": "Results .Overall .We did five rounds of cross - validation , training on four subsets of the data and testing on a fifth using a combined corpus consisting of the training and devtest data .We evaluated our results using the scoring software provided with the BioCreAtIvE data .", "label": "", "metadata": {}, "score": "64.79024"}
{"text": "For official test the score achieved precision of 41.3 and recall of 43.4 .These results are considerably worse than even our without - post - processing results .Per - token precision and recall .We then determined the results on a per - word basis .", "label": "", "metadata": {}, "score": "64.8077"}
{"text": "The apparatus may extract a corpus relevant to the target domain from a collection of corpora and generate grammar based on the extracted corpus .Claims : .The apparatus of claim 1 , further comprising a classification unit configured to classify the extracted corpus into one or more domain actions that correspond to the target domain .", "label": "", "metadata": {}, "score": "64.894875"}
{"text": "However , as the advances in computer technology . facilitated the exchange of on - line textual resources and electronic . transfer on the internet , the largest corpus has become the Web . itself .This development has moved the focus of tool design from the .", "label": "", "metadata": {}, "score": "65.05293"}
{"text": "The processor determines the types of the characters in each word or string , such as whether the characters are letters , numbers or punctuation .The processor then determines a template representative of the string .In this regard , the template is formed from tokens representing the respective character types .", "label": "", "metadata": {}, "score": "65.2819"}
{"text": "The computer - readable medium of .claim 9 including learning the weights by identifying candidate expansions from passages for abbreviations , generating features of the candidate expansions , and inputting indications of correctness of candidate expansions .The computer - readable medium of .", "label": "", "metadata": {}, "score": "65.31395"}
{"text": "Models of Language , Budapest , Hungary ( also available at the .Andras Kornai ( ed . )Special issue on Extended Finite State .Models of Language .Natural Language Engineering , 2(4 ) .Emmanuel Roche and Yves Schabes ( eds . )", "label": "", "metadata": {}, "score": "65.48901"}
{"text": "As an example , the set of grammar generation rules may include a set of rules for inserting one or more operators indicating the spaces between words and whether there are words that can be omitted .The generation unit 170 may also generate grammar 242 and 243 for the ' GetProgram ' and ' GetNextProgram ' domain actions 212 and 213 , respectively , using the same method that is used to generate the grammar 241 .", "label": "", "metadata": {}, "score": "65.51459"}
{"text": "A word is tagged GENE if it matches one of the following patterns : .The word starts with the character p and is followed by two or more digits , e.g. p53 , and p69/71 .The word starts with pp or gp and is followed by two or more digits , e.g. pp43 , pp85 , gp27 , and gp120 \u00d7 41 .", "label": "", "metadata": {}, "score": "65.74974"}
{"text": "Table 5 displays the results for the set of tests performed on data containing multiple abbreviations - Set B but contrasts the Local Context Model with the Combo Model .CM .The first row shows that LCM model performs with 89.17 % accuracy .", "label": "", "metadata": {}, "score": "65.80873"}
{"text": "10/492,161 filed Apr. 9 , 2004 , now issued U.S. Pat .No .7,444,021 , which is a 371 of PCT / AU02/01392 filed on Oct. 15 , 2002 all of which are herein incorporated by reference .TECHNICAL FIELD .", "label": "", "metadata": {}, "score": "65.89538"}
{"text": "This paper is a considerably extended version of the ECAI workshop paper by the same authors .Light parsing as finite state filtering by Gregory Grefenstette ( ECAI )The paper presents an approach to parsing useful in case of applications that need to extract relevant information without necessarily performing a full parse of the text .", "label": "", "metadata": {}, "score": "65.91275"}
{"text": "Generally - speaking , the term . 'natural language ' has been perceived as speech or writing produced in . 'natural settings ' , with the term ' natural ' meaning ' ideal ' in a . setting where only one language is used with its rules perfectly in . place .", "label": "", "metadata": {}, "score": "65.97461"}
{"text": "However , distinguishing between \" rheumatoid arthritis \" and \" right atrium \" becomes more of a challenge and may require introducing additional rules that further complicate the system .Maximum Entropy is statistical technique that has been used for Natural Language Processing .", "label": "", "metadata": {}, "score": "66.01603"}
{"text": "As another example , the class conversion unit 160 may convert the word ' drama ' in the ' GetNextProgram ' domain action 213 into a ' & genre ' class 235 .[0053 ] The generation unit 170 may generate grammar for use in the target domain .", "label": "", "metadata": {}, "score": "66.02777"}
{"text": "w .i . )P .t .i . ) j .n .P .x . ij . )As an example , assume a classifier has produced the scores shown in Table 4 from the input string \" 30-day \" , for the characters indicated .", "label": "", "metadata": {}, "score": "66.10942"}
{"text": "Atkins , B. T. S. , B. Levin and A. Zampolli ( 1994 ) Computational .Approaches to the Lexicon : An Overview .In B.T.S. Atkins and A. .Zampolli ( eds . )Computational Approaches to the Lexicon .Oxford .", "label": "", "metadata": {}, "score": "66.17793"}
{"text": "2 , Oct. 9 , 1994 , pp .540 - 543 , XP010216362 ISBN : 0 - 8186 - 6270 - 0 .Baird , HS et al . , \" A Family of European Page Readers \" Pattern Recognition , 1994 , vol .", "label": "", "metadata": {}, "score": "66.286934"}
{"text": "1994 ) .Sentence as the central unit of .linguistic analysis was questioned ( Sinclair 1996 ) and alternative . units of analysis continue to be discussed today ( Mukherjee on tone- . unit pp .21 - 134 ) .", "label": "", "metadata": {}, "score": "66.30083"}
{"text": "For example , \" PAC \" is an acronym derived from \" Political Action Committee , \" and \" Sgt . \" is an abbreviation , but not an acronym , derived from \" Sergeant .\" Abbreviations allow a writer in a specific domain to effectively convey concepts without burdening a reader experienced in the domain with the full expansion .", "label": "", "metadata": {}, "score": "66.330894"}
{"text": "Black , An Experiment in Computational Discrimination of English Word Senses , IBM Journal of Research and Development , 32(2 ) , pp .185 - 194 ( 1988 ) .Fully unsupervised learning methods such as clustering have also been successfully used .", "label": "", "metadata": {}, "score": "66.42042"}
{"text": "claim 3 wherein the sentence level information includes words in a sentence in which the identified expansion is located .The method of .claim 1 wherein : . generating context information includes generating discourse context information ; and .storing training data includes storing discourse context data as training data .", "label": "", "metadata": {}, "score": "66.46559"}
{"text": "Sinclair , J ( ed . )( 1987 )Looking Up : An Account of the Cobuild Project . in Lexical Computing .Collins , London .Schulze , B. M. et al .( 1994 ) DECIDE Designing and Evaluating .", "label": "", "metadata": {}, "score": "66.516266"}
{"text": "y .b .j .p .b .j .x .j .e .Therefore , the linear combination with b j should be better than those with any other coefficients .Alternatively , the abbreviation system may use a logistics regression technique .", "label": "", "metadata": {}, "score": "66.554825"}
{"text": "The computer - readable medium of .claim 9 wherein the weights are learned using a technique selected from the group consisting of linear regression , logistics regression , and support vector regression .The computer - readable medium of .claim 9 wherein a feature is an abbreviation character distribution feature .", "label": "", "metadata": {}, "score": "66.99608"}
{"text": "Table 3 shows the effectiveness of post - processing on one - word false positives with respect to the number of times the words corresponding to the false positives were seen in the training data .This table shows that 12.3 % of one - word false positives that correspond to unknown words were corrected while 85.2 % of one - word false positives that correspond to a word that had been seen twice or more in the training data were corrected .", "label": "", "metadata": {}, "score": "67.113"}
{"text": "For example , apostrophes can be indicative of a text string , while commas , currency symbols , and periods can be indicative of numeric strings .Words that include dashes often contain a mixture of numeric and alphabetic strings ( e.g. \" 30-year - old \" or \" 20-pound \" ) .", "label": "", "metadata": {}, "score": "67.224464"}
{"text": "( This means that the publisher has sent us a review copy . )Then contact Andrew Carnie at carnie linguistlist.org .Directory .Andras Kornai ( ed . ) , 1999 , Extended Finite State Models of Language , Cambridge University Press , pages 278+xii ( plus a CD - ROM ) .", "label": "", "metadata": {}, "score": "67.29967"}
{"text": "For example , the mapping of \" MSRA \" to \" Microsoft Research Asia \" as indicated by the underlined letters is more likely correct than the mapping to \" Microsoft Research Asia \" because the latter mapping has the extra word \" Asia .", "label": "", "metadata": {}, "score": "67.327515"}
{"text": "If a word is tagged GENE and is followed by a number , Roman numeral , or Greek letter , then the number / numeral / letter is tagged GENE .If a word is tagged GENE and it is followed by parenthesized material that is five characters or longer , then the parenthesized material is tagged with GENE .", "label": "", "metadata": {}, "score": "67.64509"}
{"text": "WA1.27.1 - 4 .In particular , these systems utilise language models defining the probability of observing a certain character given a sequence of previous characters .For example , the letter ' e ' is much more likely to follow ' th ' than the letter ' q ' .", "label": "", "metadata": {}, "score": "67.70173"}
{"text": "Hidden Markov models with finite state supervision by Eric Sven Ristad The paper presents a supervised training approach to Hidden Markov Models ( HMMs ) .The author claims that , unlike popular ad hoc techniques , the proposed approach is completely general , need not make any simplifying assumptions about independence , and can take better advantage of the information contained in the training corpus .", "label": "", "metadata": {}, "score": "67.978966"}
{"text": "17 - 45 .Bazergui , N. et al.(eds ) ( 1990 ) Acquisition du fran\u00e7ais chez des adultes \u00e0 Montr\u00e9al .Office de la langue fran\u00e7aise , Qu\u00e9bec .Biber , D. ( 1989 )A Typology of English texts .", "label": "", "metadata": {}, "score": "68.01953"}
{"text": "claim 9 wherein a feature is a capital as initial feature .The computer - readable medium of .claim 9 wherein a feature is a capital as non - initial feature .A method in a computer system for generating weights for expansions of abbreviations , comprising : . providing abbreviations and passages ; . identifying candidate expansions from passages for each abbreviation ; . inputting indications of correctness of candidate expansions ; . learning by the computer system weights for the features based on the generated features and input indications ; and .", "label": "", "metadata": {}, "score": "68.142426"}
{"text": "In block 407 , the component discards phrases below a probability threshold .In decision block 408 , if the selection of phrases is complete , then the component returns the phrases , else the component loops to block 405 to perform another iteration .", "label": "", "metadata": {}, "score": "68.23522"}
{"text": "w .i . )P .t .i . ) j .n .P .x . ij . ) where : .When calculating the value of P(x ij ) , the highest scoring member ( using the classifier hypothesis at letter position j ) of the token class is used .", "label": "", "metadata": {}, "score": "68.29167"}
{"text": "BRIEF DESCRIPTION OF FIGURES .The present invention should become apparent from the following description , which is given by way of example only , of a preferred but non - limiting embodiment thereof , described in connection with the accompanying FIGURE , wherein : .", "label": "", "metadata": {}, "score": "68.34709"}
{"text": "For example , the mapping of \" MSRA \" to \" Microsoft Research Asia \" is more likely correct than the mapping of \" MSRA \" to \" Microsoft Research Asia \" because the first mapping maps \" A \" to the initial letter of \" Asia .", "label": "", "metadata": {}, "score": "68.397194"}
{"text": "[ 0026 ] FIG .1 is a diagram illustrating an example of an apparatus for automatically generating grammar for use in the processing of natural language .[ 0027 ] FIG .2 is a diagram illustrating an example of a process for generating grammar for use in the processing of natural language .", "label": "", "metadata": {}, "score": "68.41989"}
{"text": "Finite state transducers : parsing free and frozen sentences by Emmanuel Roche ( ECAI )In NLP finite state models are usually considered a lesser evil with respect to more powerful techniques .The author instead claims that they are quite suitable for representing accurately complex linguistic phenomena .", "label": "", "metadata": {}, "score": "68.45044"}
{"text": "A logistic function generates a value between 0 and 1 with an S - shaped curve .The initial growth of the curve is approximately exponential , which slows over time .The abbreviation system may represent the logistic function by the following equation : . logit . q . ) log . q . q . )", "label": "", "metadata": {}, "score": "68.593636"}
{"text": "Our guess is that an F - measure of 80 is probably within seven points of the upper limit .Another important question that arises from this effort is to determine the effect of training corpus size on performance .This could be achieved by training on successively bigger percentages of the training corpus .", "label": "", "metadata": {}, "score": "68.6508"}
{"text": "o .c . ) if .o .x . and .c .y . otherwise .Where \" o \" stands for outcome and \" c \" stands for context .This function maps contexts and outcomes to a binary set .", "label": "", "metadata": {}, "score": "69.15198"}
{"text": "The cross - validation average precision was 81.3 and average recall was 75.9 without post - processing .Average precision was 82.3 and average recall was 77.6 with post - processing .Post - processing yielded little improvement in performance for unknown words .", "label": "", "metadata": {}, "score": "69.21517"}
{"text": "2 illustrates an example of generating grammar for use in the processing of natural language .For example , the grammar may be generated by the apparatus 100 that is illustrated in FIG .1 . [0048 ] Referring to FIGS . 1 and 2 , a TV control domain is set as a target domain by the setting unit 110 .", "label": "", "metadata": {}, "score": "69.26764"}
{"text": "( one who means ) .Plenary Address .Intl .Conference on Representing The .Child .Monash University , Melbourne .2 - 3 October .Halliday , M. A. K. and J. R. Martin ( 1993 )Writing Science .", "label": "", "metadata": {}, "score": "69.31278"}
{"text": "To find the maximum entropy distribution the Generalized Iterative Scaling ( GIS ) algorithm is used , which is a procedure for finding the maximum entropy distribution that conforms to the constraints imposed by the empirical distribution of the modeled properties in the training data .", "label": "", "metadata": {}, "score": "69.49811"}
{"text": "Provided is an apparatus and method for automatically generating grammar for use in the processing of natural language .The apparatus may extract a corpus relevant to a target domain from a collection of corpora and may generate grammar for use in the target domain based on the extracted corpus .", "label": "", "metadata": {}, "score": "69.70173"}
{"text": "12 is a flow diagram that illustrates the processing of the calculate capitals as initial component of the abbreviation system in one embodiment .FIG .13 is a flow diagram that illustrates the processing of the calculate capitals as non - initial component of the abbreviation system in one embodiment .", "label": "", "metadata": {}, "score": "70.027626"}
{"text": "The method of .claim 1 wherein : . generating context information includes generating local context information ; and .storing training data includes storing local context data as training data .The method of . claim 2 wherein the local context information and local context training data includes sentence level information .", "label": "", "metadata": {}, "score": "70.216866"}
{"text": "[ 0051 ] The second extraction unit 150 may extract one or more concepts from each of the domain actions that are provided by the classification unit 140 .For example , the second extraction unit 150 may extract the words ' CBS ' and ' drama ' from the ' SetChannel ' domain action 211 as a ' channel ' concept 221 and a ' genre ' concept 222 , respectively .", "label": "", "metadata": {}, "score": "70.23124"}
{"text": "Tag set 4 : Simplest tag set .This tag set is a simplified version of tag set 1 .Tokens that were tagged ' NEWGENE ' or ' NEWGENE1 ' are all tagged ' GENE ' .Thus , there is only one gene tag in this set : ' GENE ' .", "label": "", "metadata": {}, "score": "70.51308"}
{"text": "[0062 ]A computing system or a computer may include a microprocessor that is electrically connected with a bus , a user interface , and a memory controller .It may further include a flash memory device .The flash memory device may store N - bit data via the memory controller .", "label": "", "metadata": {}, "score": "70.8737"}
{"text": "A term is tagged NN if it contains the word virus and matches one of the following patterns : .The last or second - to - last word of the term contains virus , e.g. type I herpes simplex virus , adenovirus , reovirus RNAs , and rotavirus genome .", "label": "", "metadata": {}, "score": "71.03194"}
{"text": "Mon Jan 17 2000 .Review : Kornai : Extended Finite State Models of Lang .What follows is another discussion note contributed to our Book Discussion Forum .We expect these discussions to be informal and interactive ; and the author of the book discussed is cordially invited to join in .", "label": "", "metadata": {}, "score": "71.064125"}
{"text": "w .i . )To calculate P(w i ) for template \" dddddd \" , the calculation is : .P .w .i . )The highest scoring template ( \" dd - aaa \" ) is found , and the corresponding text is selected as the correct string ( \" 30-day \" ) .", "label": "", "metadata": {}, "score": "71.17079"}
{"text": "For example , the class conversion unit 160 may convert the words ' CBS ' and ' drama ' in the ' SetChannel ' domain action 211 into a ' & channel ' class 231 and a ' & genre ' class 232 , respectively .", "label": "", "metadata": {}, "score": "71.2617"}
{"text": "pp . 7 - 13 .ABOUT THE REVIEWER .Her . thesis was titled \" A Corpus - driven Study of Turkish - English Language .Contact in Australia \" ( 1998 ) .Affiliated with .Affiliated with .Abstract .", "label": "", "metadata": {}, "score": "71.73552"}
{"text": "It will be appreciated that identical templates will be generated for different strings .Accordingly , for example , the word \" cat \" will result in an identical template to the word \" the \" .The processor 20 records the number of times each template is determined in the database 11 .", "label": "", "metadata": {}, "score": "71.86668"}
{"text": "Table 4 .The effect of the post - processing procedures on overall system performance .This table shows the effects of each post - processing procedures in comparison with the all post - processing results .For example , No rule column shows the results without rule - based post - processing , that shows 4.5 % lower score than All Post - processing in F - measure .", "label": "", "metadata": {}, "score": "72.360596"}
{"text": "Plenary Address .Intl .Conference on Representing The Child .Monash University , Melbourne .2 - 3 October .Halliday , M. A. K. and J. R. Martin ( 1993 )Writing Science .The Falmer Press , London .", "label": "", "metadata": {}, "score": "72.37684"}
{"text": "Our base system without post - processing achieved a precision and recall of 68.0 % and 77.2 % , respectively , giving an F - measure of 72.3 % .The full system with post - processing achieved a precision and recall of 80.3 % and 80.5 % giving an F - measure of 80.4 % .", "label": "", "metadata": {}, "score": "72.54277"}
{"text": "In decision block 1302 , if all the letters have already been selected , then the component continues at block 1306 , else the component continues at block 1303 .In decision block 1303 , if the selected letter is a capital letter , then the component continues at block 1304 , else the component loops to block 1301 to select the next letter .", "label": "", "metadata": {}, "score": "73.04835"}
{"text": "For example , in the .Balkans , communities have used a mixture of two or three of the . following languages contemporarily in speech for centuries , ( in spite . of nationalistic language planning movements to discourage this . tendency ) : Greek , Turkish , Albanian , Croatian , Serbian , Slovenian and .", "label": "", "metadata": {}, "score": "73.08449"}
{"text": "x .y .f .x . otherwise .Thus , support vector regression is formalized as minimization of the following function : . min .C .t .n .i .i .y .i .f .", "label": "", "metadata": {}, "score": "73.106125"}
{"text": "It presents some brief remarks by Karttunen who underlines the modernity of the parser described in the previous chapter by Joshi and Hopely .Implementing and using finite automata toolkits by Bruce W. Watson ( ECAI )It describes a toolkit ( FIRE Lite ) developed by the author while at the Eindhoven University of Technology and now freely available for non - commercial use .", "label": "", "metadata": {}, "score": "74.15937"}
{"text": "Boundary Correction : IgG / NEWGNE binding / NN .Output : regulator / NEWGENE virF / NEWGNE .Boundary Correction : regulator / NN viF / NEWGENE .Single - word false positive correction .We applied a similar process to detect single - word false positives output by the POS tagger using a list of ambiguous types that were observed in the training and devtest data to have a zero or very low probability ( less than 5 % ) of being tagged GENE_ONEWORD .", "label": "", "metadata": {}, "score": "74.23037"}
{"text": "In block 504 , the component selects the next mapping .In decision block 505 , if all the mappings have already been selected , then the component continues at block 507 , else the component continues at block 506 .In block 506 , the component invokes the score candidate expansions component to score the candidate expansion for the selected mapping and then loops to block 504 to select the next mapping .", "label": "", "metadata": {}, "score": "74.90037"}
{"text": "Hearst , Noun Homograph Disambiguation Using Local Context In Large Text Corpora , In Proc . , 7th Annual Conference of the University of Waterloo Center for the New OED and Text Research , Oxford , pp . 1 - 15 ( 1991 ) .", "label": "", "metadata": {}, "score": "75.061905"}
{"text": "The result was that \" DJD \" occurred 2906 times , and \" degenerative joint disease \" occurred 2517 times .For purposes of testing the accuracy of normalization conducted using feature vectors generated in accordance with the present invention , two kinds of models were trained for each data set : local context models ( LCM ) and combo ( CM ) models .", "label": "", "metadata": {}, "score": "75.4371"}
{"text": "The word pathway never occurs in the corpora tagged as GENE_ONEWORD while the word estrogen is tagged GENE_ONEWORD in one ( or 4.5 % ) of 22 occurrences .The following lines show the POS counts in the training corpus for the words pathway and estrogen .", "label": "", "metadata": {}, "score": "75.54162"}
{"text": "In block 601 , the component invokes the calculate external proximity component to calculate the external proximity feature for the candidate expansion .In block 602 , the component invokes the calculate internal proximity component to calculate the internal proximity feature for the candidate expansion .", "label": "", "metadata": {}, "score": "75.78816"}
{"text": "In block 802 , the component invokes the identify enveloping sub - phrase component to identify the sub - phrase enveloped by the mapping .In block 803 , the component sets the length of the sub - phrase to the number of words in the enveloping sub - phrase .", "label": "", "metadata": {}, "score": "76.02517"}
{"text": "As an example , the string \" 15-years ? \" is converted to the template \" dd - aaaaa ? \"Note that alternative tokenisation schemes could be used to model other language formations , such as upper and lower case distinction ( e.g. \" MacDonald \" as \" ullulllll \" with ' u ' for upper case and ' l ' for lower case alphabetic characters ) .", "label": "", "metadata": {}, "score": "76.32248"}
{"text": "Generally , program modules include routines , programs , objects , components , data structures , and so on that perform particular tasks or implement particular abstract data types .Typically , the functionality of the program modules may be combined or distributed as desired in various embodiments .", "label": "", "metadata": {}, "score": "76.34022"}
{"text": "\u00a9 Kinoshita et al 2005 .This article is published under license to BioMed Central Ltd. Date : Thu , 02 Oct 2003 14:04:22 +0000From : Petek Kurtb\u00f6ke Subject : Extending the Scope of Corpus - Based Research : New Applications , New Challenges .", "label": "", "metadata": {}, "score": "76.537384"}
{"text": "The log - probability of template t i is : .P .t .i . ) log .c . i .j .n .c .j . ) where : .c i is the number of times template i was encountered in the training text .", "label": "", "metadata": {}, "score": "76.716415"}
{"text": "Going to the analysis of some of the papers , I found the contribution . by Joshi & Hopely ( chapter 2 ) particularly interesting as it provides .a useful historical perspective on the work in the field .Too often we . tend to concentrate only on the most recent contributions running the . risk to reinvent the wheel and this paper reminds us not to neglect .", "label": "", "metadata": {}, "score": "76.73218"}
{"text": "The internal proximity feature is thus the absolute value of difference between the number of words enveloped by a mapping and the number of letters in the abbreviation , divided by the number of letters in the abbreviation .The internal proximity features for the mappings of .", "label": "", "metadata": {}, "score": "77.23558"}
{"text": "In this example , the long form is Insulin - like growth factor 1 and the abbreviation is IGF-1 .We developed a number of rules that we applied to long form / abbreviation pairs found by the Schwartz and Hearst algorithm : .", "label": "", "metadata": {}, "score": "77.89651"}
{"text": "In fact , computational applications in linguistics have so far tested the grammars proposed by theoretical linguists .There is endless literature on these experiments and their results , in which the language , most commonly English , is treated in terms of a limited set of rules .", "label": "", "metadata": {}, "score": "77.999405"}
{"text": "Example : androgen / GENE_BEGIN receptor / GENE_END ( AR / GENE_ONEWORD ) .Example : Syn / GENE_BEGIN 5/GENE_INSIDE locus / GENE_END .Tag set 3 : Simplified boundary information .This tag set is a simplified version of tag set 2 .", "label": "", "metadata": {}, "score": "78.276344"}
{"text": "For each tag set we modified the training corpus to comply with the tag set and then trained TnT. We tested the four models on the devtest set .The result of this experiment is shown in Table 5 .The differences in performance between the four tag sets are very small .", "label": "", "metadata": {}, "score": "78.368286"}
{"text": "In fact , computational applications in .linguistics have so far tested the grammars proposed by theoretical .linguists .There is endless literature on these experiments and their .results , in which the language , most commonly English , is treated in . terms of a limited set of rules .", "label": "", "metadata": {}, "score": "78.56904"}
{"text": "Health records of these types are typically divided or segmented into a number of sections , each of which may have a discourse marker .For example , clinical notes maintained by the Mayo Clinic in Rochester , Minn. include as subsections and associated markers Chief Complaint ( CC ) , History of Present Illness ( HPI ) , Impression / Report / Plan ( IP ) and Final Diagnoses ( DX ) .", "label": "", "metadata": {}, "score": "79.20434"}
{"text": "Explanation - based learning and finite state transducers : applications to parsing lexicalized tree adjoining grammars by Srinivas Banglore ( ECAI )The paper describes the application of explanation - based learning ( EBL ) techniques to parsing Lexicalized Tree Adjoining Grammars .", "label": "", "metadata": {}, "score": "79.831505"}
{"text": "To calculate P(w i ) for the template \" dd - aaa \" , the calculation performed by the processor 20 is as follows : .P .w .i . )To calculate P(w i ) for template \" aaaaaa \" , the calculation is : .", "label": "", "metadata": {}, "score": "80.62054"}
{"text": "Where the computing system or computer is a mobile apparatus , a battery may be additionally provided to supply operation voltage of the computing system or computer .It will be apparent to those of ordinary skill in the art that the computing system or computer may further include an application chipset , a camera image processor ( CIS ) , a mobile Dynamic Random Access Memory ( DRAM ) , and the like .", "label": "", "metadata": {}, "score": "81.101326"}
{"text": "A head - to - head competition between the TnT tagger , the Brill tagger , and perhaps others would help determine whether or not the choice of tagger is an important decision .We would look at both the raw performance of each tagger as well as the performance of post - processing rules applied to the results of each tagger .", "label": "", "metadata": {}, "score": "81.21535"}
{"text": "In block 702 , the component invokes the identify enveloping sub - phrase component to identify the sub - phrase of the candidate expansion enveloped by the mapping .In block 703 , the component calculates the length of the enveloping sub - phrase as the number of words it contains .", "label": "", "metadata": {}, "score": "82.21489"}
{"text": "The computer system of .claim 1 wherein the component that learns weights applies a linear regression technique .The computer system of .claim 1 wherein the component that learns weights applies a logistics regression technique .The computer system of .", "label": "", "metadata": {}, "score": "82.63976"}
{"text": "Support vector regression operates by finding a hyper - surface in the space of possible inputs .Support vector regression applies a loss function represented by the following : .L .y .f .x . if .y .", "label": "", "metadata": {}, "score": "83.49007"}
{"text": "The papers by Chanod & Tapanainen and Grefenstette ( chapters 8 and 9 ) .provide a useful indication of the current advances in the application . of finite - state techniques at Xerox Research Centre Europe in .Grenoble , one of the leading centers in this area .", "label": "", "metadata": {}, "score": "84.3302"}
{"text": "In block 308 , the component calculates the features for the selected mapping .In block 309 , the component inputs an overall score for the mapping .In block 310 , the component saves the features and the overall score for use in training .", "label": "", "metadata": {}, "score": "84.4655"}
{"text": "ABOUT THE REVIEWER : ABOUT THE REVIEWER Petek Kurtb\u00f6ke holds a Ph .D from Monash University , Melbourne .Her thesis was titled \" A Corpus - driven Study of Turkish - English Language Contact in Australia \" ( 1998 ) .", "label": "", "metadata": {}, "score": "84.634964"}
{"text": "No .12/831,244 filed Jul. 6 , 2010 , which is a Continuation of U.S. Ser .No .12/202,384 filed Sep. 1 , 2008 , now issued U.S. Pat .No .7,756,336 , which is a Continuation of U.S. Ser .", "label": "", "metadata": {}, "score": "84.64711"}
{"text": "claim 1 , wherein the function is of the predetermined probability of the respective character template and the character probabilities having character types corresponding to the combination of character types represented by the respective character template .The method of .claim 1 , wherein the function is of the predetermined probability of the respective character template and the highest character probabilities having character types corresponding to the combination of character types represented by the respective character template .", "label": "", "metadata": {}, "score": "85.445656"}
{"text": "In block 604 , the component invokes the calculate capitals as initial component to calculate the capital as initial feature of the candidate expansion .In block 605 , the component invokes the calculate capitals as non - initial component to calculate the capital as non - initial feature of the candidate expansion .", "label": "", "metadata": {}, "score": "87.00214"}
{"text": "For example , if searching for documents containing the term \" rheumatoid arthritis , \" it would be desirable to retrieve all those documents that use the abbreviation \" RA \" in the sense of \" rheumatoid arthritis .\" At the same time , it is desirable not to identify documents that use the same abbreviation , but with a sense different from that of \" rheumatoid arthritis . \"", "label": "", "metadata": {}, "score": "88.66462"}
{"text": "If you are interested in leading a book discussion , look for books announced on LINGUIST as \" available for review . \" Then contact Simin Karimi at simin linguistlist.org .Directory .Granger , Sylviane and Stephanie Petch - Tyson , ed .", "label": "", "metadata": {}, "score": "89.74799"}
{"text": "Tokens that were tagged ' GENE_END ' are now tagged ' GENE_INSIDE ' and tokens that were tagged ' GENE_ONEWORD ' are now tagged ' GENE_BEGIN ' .Example : androgen / GENE_BEGIN receptor / GENE_INSIDE ( AR / GENE_BEGIN ) .", "label": "", "metadata": {}, "score": "91.7141"}
{"text": "For example , tokens of the ambiguous type binding are tagged as JJ , NN , and GENE_INSIDE .Correctly tagging tokens of ambiguous types is a difficult task .Boundary correction .The POS tagger 's output sometimes contains boundary errors such as the following : .", "label": "", "metadata": {}, "score": "94.14124"}
{"text": "Gold Standard : IgG / GENE_ONEWORD binding / NONGENE .Problem : Right boundary is wrong .Output : regulator / GENE_BEGINvirF / GENE_END .Gold Standard : regulator / NONGENE virF / GENE_ONEWORD .Problem : Left boundary is wrong .", "label": "", "metadata": {}, "score": "105.802"}
