{"text": "Thus , substantially identical data objects may be identified with a high degree of certainty without requiring large computational overhead .The approach to identifying substantially identical data objects adopted by the preferred embodiment of the present invention may be applied to help resolve broken links in hypertext documents .", "label": "", "metadata": {}, "score": "31.502895"}
{"text": "Other techniques .The patent goes into a very detailed description of how substantially similar pages could be identified , and then how the URLs of those pages could be compared to come up with patterns , and then rules .Conclusion .", "label": "", "metadata": {}, "score": "34.134163"}
{"text": "The implementation of near - duplicate detection algorithms forces trade - offs between efficiency and effectiveness , entailing careful testing and measurement to ensure acceptable performance .In this thesis , we describe and evaluate a scalable implementation of a near - duplicate detection algorithm , based on standard shingling techniques , running under a MapReduce framework .", "label": "", "metadata": {}, "score": "34.47192"}
{"text": "Therefore , the sequences of shingles - and thus the super shingles - for the larger document will be different than those of the smaller document .While we will soon discuss some specific applications related to clustering the Web , we also want to point out that our resemblance and clustering techniques are not limited to text documents .", "label": "", "metadata": {}, "score": "34.64257"}
{"text": "It is contemplated that a single counterexample will render the rule invalid .As a result , the web crawler will avoid multiple downloads of substantially similar documents .[ 0096 ] .FIG .3 is a block diagram of an exemplary system that identifies duplicate web pages in accordance with the present invention .", "label": "", "metadata": {}, "score": "34.96866"}
{"text": "System and method for detecting duplicate and similar documents US 20030172066 A1 .Abstract .A system and a method are described for rapidly determining document similarity among a set of documents , such as a set of documents obtained from an information retrieval ( IR ) system .", "label": "", "metadata": {}, "score": "35.134445"}
{"text": "Aspects of the present invention are directed to identifying URLs that address substantially identical documents on the same web server , and then inferring per - web server rewriting rules for transforming URLs into canonical URLs addressing substantially identical documents .[ 0035 ] .", "label": "", "metadata": {}, "score": "35.293625"}
{"text": "A number of optimizations may be applied to the above - described approach .For example , where the word occurrence lists are quite long , jump - ahead pointers may be utilized at fixed locations within the list to expedite searching of the list .", "label": "", "metadata": {}, "score": "35.58674"}
{"text": "In view of the foregoing description it will be appreciated that the inventors have defined similar documents as ones that have essentially the same sentences and paragraphs , but not necessarily in exactly the same order .It has been found that one may accurately compute whether documents are similar by comparing the number of terms found using a phrase recognition program , such as Textract or similar programs .", "label": "", "metadata": {}, "score": "35.597244"}
{"text": "Identical documents obviously share the same set of shingles and so , for the clustering algorithm , we only need to keep one representative from each group of identical documents .Therefore , for each document we generate a fingerprint that covers its entire contents .", "label": "", "metadata": {}, "score": "35.686283"}
{"text": "In fact , it is likely more efficient to look at multiple documents concurrently .Those skilled in the art will appreciate that different threshold values may be utilized depending on the degree of exactitude that is required for data objects to be considered substantially identical .", "label": "", "metadata": {}, "score": "35.97806"}
{"text": "Any documents that share a super shingle resemble each other are added into the cluster .( If we want a higher threshold we can compute their actual resemblance . )So , the entire third phase of the basic algorithm where we generate and merge the document ID pairs is not needed .", "label": "", "metadata": {}, "score": "36.293823"}
{"text": "Therefore , it would be advantageous if a web crawler could identify URL equivalence patterns in multiple different URLs that reference substantially identical pages and download only one document , as opposed to downloading all the substantially identical documents addressed by the multiple different URLs .", "label": "", "metadata": {}, "score": "36.53946"}
{"text": "A further optimization is to perform calculation of identical documents only upon demand ( i.e. , after a broken link arrives ) .While the present invention has been described with reference to a exemplary embodiment thereof , those skilled in the art will appreciate that various changes in form and detail may occur without departing from the intended scope of the present invention as defined in the appended claims .", "label": "", "metadata": {}, "score": "36.573227"}
{"text": "At an even more simplistic level , an algorithm has been described for detecting plagiarism in which one simply searches for matches of six or more successive words between two documents .[0010 ] .As should be apparent , a need exists to provide an accurate and efficient algorithm and system for determining a degree of likeness between electronically represented documents .", "label": "", "metadata": {}, "score": "37.354992"}
{"text": "When the broken link is detected , one of the substantially identical objects that holds media content is returned rather than displaying an error message .The exemplary embodiment of the present invention described herein builds a database containing sets of substantially identical data objects , such as web pages .", "label": "", "metadata": {}, "score": "37.580772"}
{"text": "We also believe that our techniques can generalize to other problem domains .Given any technique that extracts a set of features from an object , we can measure the similarity of any two objects or cluster the sets of similar objects from a large number of objects .", "label": "", "metadata": {}, "score": "37.616234"}
{"text": "This approach can be viewed as the node model for the representation of the structural information , since this approach only uses information about the tags of the various nodes in the corresponding tree model .[0007 ] .The method of Isabel et al relies on the assumption that tag frequencies reflect some inherent characteristics of Web documents and correlate with its structure .", "label": "", "metadata": {}, "score": "38.12148"}
{"text": "This algorithm finds such documents even when relatively simpler methods would not .[ 0063 ] .It is noted that one may remove a document from the cluster of very similar documents if the terms that are different between them include a term that is also contained in the original query .", "label": "", "metadata": {}, "score": "38.14382"}
{"text": "If there are no errors , the rule is activated and is then used by the web crawler for future crawling to avoid the download of duplicative web pages or web resources .A method for normalizing uniform resource locators ( URLs ) corresponding to a plurality of web resources , comprising : . analyzing the content of at least two web resources to determine whether the web resources are substantially identical ; and . determining a rule for the URLs of the web resources if the web resources are substantially identical .", "label": "", "metadata": {}, "score": "38.19236"}
{"text": "If the lists are very nearly identical , the documents are considered to be closely related .These teachings also pertain to a single numerical document signature that can be used for rapid comparison of longer documents .These teachings are also directed to a technique to recognize documents which are revisions of other documents , i.e. , those which contain new material but which also contain much of the original document .", "label": "", "metadata": {}, "score": "38.32107"}
{"text": "In addition , we investigate the prevalence of near - duplicate documents in the runs submitted to the adhoc task of TREC 2009 web track .Documents are represented based on their structure , which arises from the relationship between various elements in the document .", "label": "", "metadata": {}, "score": "38.45556"}
{"text": "We have developed an efficient way to determine the syntactic similarity of files and have applied it to every document on the World Wide Web .Using this mechanism , we built a clustering of all the documents that are syntactically similar .", "label": "", "metadata": {}, "score": "38.4786"}
{"text": "For example , files containing only graphical content may be compared on a block - by - block basis to determine whether the files are substantially identical or not .It should also be noted that the present invention will be described below relative to an implementation on the Internet , but those skilled in the art will appreciate that the present invention may be practiced generally in a distributed environment and may be practiced on intranets .", "label": "", "metadata": {}, "score": "38.724976"}
{"text": "Our experiments with real datasets and workloads demonstrate the effectiveness of our techniques .Although we present our techniques in the context of keyword search , our techniques apply to other types of ranked searches ( e.g. , multimedia search ) as well .", "label": "", "metadata": {}, "score": "38.765236"}
{"text": "0007 ] .For example , Eric W. Brown and John M. Prager in U.S. Pat .No .5,913,208 note that documents having identical metadata such as size , date , and base filename are likely to be copies kept on different directories or on different servers , and can effectively be reduced to one single occurrence .", "label": "", "metadata": {}, "score": "38.841923"}
{"text": "Creating a normalization rule .A URL normalization rule may be able to be determined based on the patterns , so that substantially similar pages will only be identified by one URL .Two URLs that have been transformed to the same normalized URL should refer to substantially identical web pages .", "label": "", "metadata": {}, "score": "39.059464"}
{"text": "Thus , for instance , the 4-shingling of .For a given shingle size , the resemblance r of two documents A and B is defined as .Experiments show that these mathematical definitions effectively capture our informal notions of \" roughly the same \" and \" roughly contained .", "label": "", "metadata": {}, "score": "39.218494"}
{"text": "If the number of terms found to not be contained in both documents is less than some predetermined threshold compared to the total number of terms in the document , these documents are determined to be very similar .It is shown that these techniques may be employed to accurately recognize that documents , that have been revised to contain parts of other documents , are still closely related to the original document .", "label": "", "metadata": {}, "score": "39.223106"}
{"text": "The next step would be to test the rule .Testing may involve , for example , applying the rule to various URLs , and then determining if the ones predicted to have substantially identical content are , in fact , substantially identical .", "label": "", "metadata": {}, "score": "39.61446"}
{"text": "Related sampling mechanisms for determining similarity were also developed by Manber [ 3 ] and within the Stanford SCAM project [ 1 , 4 , 5 ] .With respect to clustering , there is a large body of literature related to semantic clustering , a rather different concept .", "label": "", "metadata": {}, "score": "40.178986"}
{"text": "Once we are given the set of features for each object , we can then apply the algorithms described above to compute the resemblance of the objects and to cluster groups of similar objects .For documents and objects other than text , there are many potential features for computing resemblance .", "label": "", "metadata": {}, "score": "40.261765"}
{"text": "Elements that appear as a result of repetition differ in their positional indices , and thus have different XPaths .This is unlike the situation in the bag of tree paths model , in which all such paths are identical .Therefore , if the similarity measure defined for the bag of tree paths model is directly used in the bag of XPaths model , two documents that differ only in the number of repeating elements will have a relatively low similarity value .", "label": "", "metadata": {}, "score": "40.267273"}
{"text": "Check - summing , .Lexical comparison , .Others .It looks to see : .Are the pages completely identical ?Whether the non - markup words ( as opposed to the HTML markup ) on two pages are identical , or ; .", "label": "", "metadata": {}, "score": "40.577835"}
{"text": "A system and a method are described for rapidly determining document similarity among a set of documents , such as a set of documents obtained from an information retrieval ( IR ) system .A ranked list of the most important terms in each document is obtained using a phrase recognizer system .", "label": "", "metadata": {}, "score": "40.759045"}
{"text": "After the clustering has been completed , the other identical documents are added into the cluster containing the one kept version .We can expand the collection of identical documents with the \" lexically - equivalent \" documents and the \" shingle - equivalent \" documents .", "label": "", "metadata": {}, "score": "40.77617"}
{"text": "An important aspect of the bag of tree paths model is that the model can take into account markup language issues , such as repetition of elements in the similarity measure .Ideally , similarity value between a pair of documents should be high if the documents differ only in the number of times a particular markup language subelement occurs under an element .", "label": "", "metadata": {}, "score": "40.844795"}
{"text": "In choosing only those Shingles that are connected to a stopword antecedent , however , SpotSigs tends to extract more robust signatures than plain Shingling .At the same time it allows for a more efficient and less error - prone signature extraction as compared to many of the far more sophisticated tools for HTML layout analysis .", "label": "", "metadata": {}, "score": "40.95068"}
{"text": "Each such signature may be utilized to identify substantially identical image files and , thus , may be used to help resolve broken references to an image file .A suitable strategy for identifying component features of image files is described in copending application entitled \" An Image Classification and Retrieval System Using a Query - By - Example Paradigm , \" application Ser .", "label": "", "metadata": {}, "score": "41.18818"}
{"text": "More specifically , these teachings provide for characterizing documents in accordance with the major terms discovered in them using phrase recognition software .These teachings generally operate on the hypothesis that documents having identical lists of discovered terms are effectively identical in content .", "label": "", "metadata": {}, "score": "41.195145"}
{"text": "The method of . claim 17 , wherein constructing the URL normalization rule comprises pattern matching .The method of . claim 17 , further comprising validating the URL normalization rule .The method of . claim 17 , wherein determining if the plurality of web resources are substantially identical comprises at least one of shingling , check - summing , and lexical comparison .", "label": "", "metadata": {}, "score": "41.26483"}
{"text": "The system of .claim 11 , wherein the processor is adapted to search for a recurring pattern in the URLs corresponding to the at least two substantially identical web resources .The system of . claim 15 , wherein the processor is adapted to perform at least one of shingling , check - summing , and lexical comparison .", "label": "", "metadata": {}, "score": "41.284508"}
{"text": "[ 0006 ] .One of the continuing problems in information retrieval is related to the fact that in the Web environment , there are a large number of near - duplicate documents returned from most searches .A number of methods have been proposed for recognizing and eliminating such duplicates .", "label": "", "metadata": {}, "score": "41.44037"}
{"text": "Some work in this area used insertion and deletion of leaf nodes and relabelling of a node anywhere in the tree .Several other approaches with different sets of edit operations are proposed .These tree edit distance measures have been modified to address issues such as repetitive and optional fields .", "label": "", "metadata": {}, "score": "41.575737"}
{"text": "This approach enables the exemplary embodiment of the present invention to quickly discern which data objects within a fairly large set of data objects are potentially identical to a given data object .Moreover , this approach can then very quickly identify which data objects amongst the candidates are substantially identical without exhausting a large amount of computational effort .", "label": "", "metadata": {}, "score": "41.59107"}
{"text": "Clustering the documents found in a series of sweeps can be made relatively efficient as it is not necessary to perform the entire clustering from scratch each time .Instead , we need only sketch the documents from the last sweep and merge them into the existing clusters .", "label": "", "metadata": {}, "score": "41.72609"}
{"text": "Lexically - equivalent documents are found with the fingerprint of the entire canonicalized contents .Shingle equivalent documents are found with the fingerprint of the set of selected shingles .The second and third phases of our algorithm require a great deal of disk space for the pairs and the triplets .", "label": "", "metadata": {}, "score": "41.76572"}
{"text": "In this paper , we consider a class of queries called the \" object finder \" queries .Our goal is to return the top K objects that best match a given set of keywords by exploiting the relationships between documents and objects .", "label": "", "metadata": {}, "score": "42.00908"}
{"text": "Once a rule is determined , it is applied to the class of web pages to identify errors , at step 250 .This rule may then be tested by , for example , applying the rule to various URLs , and then determining if the ones predicted to have substantially identical content are , in fact , substantially identical .", "label": "", "metadata": {}, "score": "42.154175"}
{"text": "If it is identical , one may then also compute whether these documents contain similar terms .[ 0074 ] .In the foregoing the problem of finding very similar documents was discussed , where in most cases the documents are so similar that only one of them need be returned from a search .", "label": "", "metadata": {}, "score": "42.18956"}
{"text": "Once we have the sketches , clusters and auxiliary data structures , we can use them for several interesting applications .As we discuss the different applications , we will consider their storage and performance characteristics .There are two approaches : .", "label": "", "metadata": {}, "score": "42.26213"}
{"text": "The URLs of the web pages that have been determined to be substantially identical are then analyzed for recurring patterns .Example from the Patent Application .The following URLs all refer to the same page : .Identifying a pattern .", "label": "", "metadata": {}, "score": "42.43062"}
{"text": "[ 0063 ] .[ 0064 ] .[0065 ] .More particularly , an embodiment of the invention comprises two learning steps .In the first step ( step 230 ) , it attempts to learn what portions of the URLs within an equivalence class of substantially identical documents are relevant and which portions are not .", "label": "", "metadata": {}, "score": "42.70317"}
{"text": "According to aspects of the invention , an exemplary method compares all the web resources on a web site to identify whether two resources downloaded from a web site are identical or near identical .Once identical ( or near identical ) web resources with different URLs are found , the different URLs are then analyzed to identify what portions of the URL are essential for identifying a particular web resource , and what portions are irrelevant .", "label": "", "metadata": {}, "score": "42.787132"}
{"text": "Andrews et al further give a method to cluster documents based on this distance measure .The algorithm to compute the tree edit distance for a pair of documents is of quadratic complexity in the combined size of the two documents .", "label": "", "metadata": {}, "score": "42.89482"}
{"text": "We believe that our system provides new functionality for dealing with the sea of information on the Web .It allows users to find syntactically related documents anywhere on the World Wide Web .It allows search engines to better present results to their clients .", "label": "", "metadata": {}, "score": "42.89643"}
{"text": "BACKGROUND OF THE INVENTION .Internet usage has increased dramatically in the past few years and as a result , the usage of hypertext documents that contain hypermedia links has also increased dramatically .Hypermedia links provide an address path to access media content that is related to or associated with text , graphics , video or audio .", "label": "", "metadata": {}, "score": "42.9551"}
{"text": "Given a complete clustering and the auxiliary files for mapping URLs to document IDs and mapping document IDs back to URLs , we can very efficiently compute all of the URLs for the documents in the cluster .Unfortunately , clustering must be done with a single fixed threshold for resemblance and we must decide in advance if we want contained and containing documents included in the clusters .", "label": "", "metadata": {}, "score": "43.01434"}
{"text": "An exemplary embodiment of the present invention will be described below relative to the following figures .FIG .1A is a block diagram of a conventional system that is used to access media content on the Internet .FIG .1B is a block diagram of a conventional system wherein a client seeks access to a resource on a server .", "label": "", "metadata": {}, "score": "43.110527"}
{"text": "Once this has been done for each set of substantially identical web pages or web resources ( also referred to as an \" equivalence class \" herein ) , these per - equivalence - class rules are generalized to trans - equivalence - class rules .", "label": "", "metadata": {}, "score": "43.12484"}
{"text": "Once this has been done for each set of substantially identical web pages or web resources ( also referred to as an \" equivalence class \" herein ) , these per - equivalence - class rules are generalized to trans - equivalence - class rules .", "label": "", "metadata": {}, "score": "43.12484"}
{"text": "This repairing of broken links may be performed transparently relative to the user and does not require user input .The present invention may also be applied to resolve and repair other references to objects , files and network resources that are not hyperlinks .", "label": "", "metadata": {}, "score": "43.15267"}
{"text": "Given the weights for each of the terms within each of the documents , the exemplary embodiment of the present invention then calculate s which web page documents are identical .For a given web page document , the identicals are calculated step 102 in FIG .", "label": "", "metadata": {}, "score": "43.38626"}
{"text": "[ 0046 ] .Once the data from a collection of documents have been analyzed using Textract , it is useful to construct a system for managing that data in a way that facilitates sorting the terms by document , by IQ and by term type .", "label": "", "metadata": {}, "score": "43.472824"}
{"text": "For instance , we can observe a page at different times and see how similar each version is to the preceding version .When we have this information for many web pages , we can answer some basic questions about the Web : .", "label": "", "metadata": {}, "score": "43.65477"}
{"text": "The Web has undergone exponential growth since its birth , and this expansion has generated a number of problems ; in this paper we address two of these : .The proliferation of documents that are identical or almost identical .The instability of URLs .", "label": "", "metadata": {}, "score": "43.66998"}
{"text": "These methods define the structural dissimilarity between a pair of documents as the edit distance between the corresponding labeled trees .This is the tree model for the representation of the structural information .[ 0003 ] .The basic idea behind all tree edit distance algorithms is to find the cheapest sequence of edit operations that will transform one tree into another .", "label": "", "metadata": {}, "score": "43.700687"}
{"text": "We sort this list using the divide , sort , merge approach outlined above .In the third phase , we generate a list of all the pairs of documents that share any shingles , along with the number of shingles they have in common .", "label": "", "metadata": {}, "score": "43.7042"}
{"text": "0068 ] .Step 430 .Use the similarity measure given in Equation [ 1 ] or Equation [ 2 ] to obtain the similarity value between two documents based on the bag of Paths model or bag of XPaths model .", "label": "", "metadata": {}, "score": "43.72045"}
{"text": "It should be appreciated that word occurrence list entries are stored in a sorted order with the highest weighted terms at the front of the word occurrence list .For a given web page document , the calculation of identicals begins by locating the highest weighted term within the document ( step 106 in FIG .", "label": "", "metadata": {}, "score": "43.891384"}
{"text": "In general , Textract recognizes named entities , multi - word terms and named and unnamed relations between terms .Further reference in this regard can be had to Y. Ravin and N. Wacholder , AExtracting Names from Natural - Language Text,@ IBM Research Report 20338 ; J. S. Justeson and S. Katz \" Technical terminology : some linguistic properties and an algorithm for identification in text . @", "label": "", "metadata": {}, "score": "44.064484"}
{"text": "To do this , simply calculate the score between every pair of documents in the system , and keep those pairs that score over a threshold .One application from the original paper was to allow a \" lost and found \" service for moved web pages , by identifying where documents had moved to once they were no longer available on a given url by updating the clusters and tagging URLs with a date .", "label": "", "metadata": {}, "score": "44.198814"}
{"text": "Get the sketch of the input document by .Looking up the sketch for the URL , or .Computing the sketch from the document itself .Look up each shingle from the input document in the sorted file .For each document that shares a shingle , maintain the count of common shingles .", "label": "", "metadata": {}, "score": "44.229355"}
{"text": "[0081 ] .When all of the documents are relatively short , it is feasible to perform this processing in real time or substantially real time .However , when longer documents make the phrase mining processes too slow , it is desirable to index and mine the documents in advance and to cache the results , in a manner similar to the procedures done for document search indexes .", "label": "", "metadata": {}, "score": "44.614174"}
{"text": "The method of .claim 1 , wherein the rule is based on a recurring pattern in the URLs corresponding to the at least two substantially identical web resources .The method of .claim 1 , wherein analyzing the content comprises comparing the content in the at least two web resources .", "label": "", "metadata": {}, "score": "44.639797"}
{"text": "When identical , or nearly identical , pages with different URLs are located , the different URLs are analyzed to identify what portions of the URL are essential for identifying a particular web resource , and what portions are irrelevant .This is done to see if rules can be developed for a site that can be applied to other pages on the site or server .", "label": "", "metadata": {}, "score": "44.810295"}
{"text": "We compute super shingles by sorting the sketch 's shingles and then shingling the shingles .The document 's meta - sketch is then determined by its set of super shingles .If two documents have even one super shingle in common , then that means their sketches have a sequence of shingles in common .", "label": "", "metadata": {}, "score": "44.83336"}
{"text": "By navigating from one object to another , a user may find other objects of interest .[ 0004 ] .In a network environment , the components of a text search system may be distributed across multiple computers .A network environment includes as a minimum two or more computers connected by a local or wide area network , ( e.g. , Ethernet , the telephone network , and the Internet ) .", "label": "", "metadata": {}, "score": "44.96929"}
{"text": "When we looked at the most common shingles , we found that they were nearly all mechanically generated .They include : .HTML comment tags identifying the program that generated the HTML .Shared header or footer information on a large number of automatically generated pages ( forms or views on databases ) .", "label": "", "metadata": {}, "score": "44.9852"}
{"text": "[ 0061 ] . [0062 ] .It is noted that bucketizing URLs is independent of whether shingling or any other mechanism for comparing web pages coming from the same server is used .Then , the buckets are examined , one bucket at a time .", "label": "", "metadata": {}, "score": "45.01796"}
{"text": "0058 ] .FIG .2 is a flow diagram of an exemplary method of identifying duplicate web pages or web resources in accordance with the present invention .[ 0059 ] .More particularly , in accordance with an embodiment , the web pages or resources downloaded by the search engine 's web crawler are shingled .", "label": "", "metadata": {}, "score": "45.097553"}
{"text": "These teachings relate generally to information retrieval systems and methods and , more specifically , relate to systems and methods for comparing documents one to another .Even more specifically , these teachings relate to digital libraries of documents , and more particularly relate to the search and retrieval of documents relevant to a query , and to techniques to detect that some of the documents are identical , or very nearly identical .", "label": "", "metadata": {}, "score": "45.14784"}
{"text": "2 is a flow diagram of another exemplary method of identifying duplicate documents , web resources , or web pages in accordance with the present invention ; .[ 0031 ] .FIG .3 is a block diagram of an exemplary system that identifies duplicate documents , web resources , or web pages in accordance with the present invention ; and .", "label": "", "metadata": {}, "score": "45.298294"}
{"text": "Information regarding what documents are substantially identical to a selected document is stored within the index as well .The information regarding substantially identical documents is added to the index after the completion of step 44 in FIG .3 , where data objects ( i.e. , web page documents ) are compared to determine which web pages are substantially identical .", "label": "", "metadata": {}, "score": "45.315887"}
{"text": "A method for processing data representing documents , comprising : . for individual ones of documents , executing a software program to obtain a list of terms found in each document ; . computing a document signature for each document from the list of terms obtained for the document ; . comparing the document signature for a first document to the document signature for a second document ; and .", "label": "", "metadata": {}, "score": "45.316143"}
{"text": "0093 ] .By examining a sufficiently large number of URLs on a particular web site , it can be learned which per - equivalence - class rewriting rules generalize to the entire site .In other words , the URL is normalized .", "label": "", "metadata": {}, "score": "45.331543"}
{"text": "On the other hand , if it is determined that the document similarity score is not above the threshold then more terms within the web page document being analyzed must be examined .If there are any more terms remaining ( see step 118 ) the next highest weighted term is located ( see step 106 in FIG .", "label": "", "metadata": {}, "score": "45.51593"}
{"text": "Another possible way to compare all pages on a web server is to reduce each page to a set of \" rare \" words occurring in that page ( the assumption being that if two pages contain the same rare words , they must be highly similar ) .", "label": "", "metadata": {}, "score": "45.541893"}
{"text": "( Cancelled ) .A program storage device readable by computer , tangibly embodying a program of instructions executable by said computer to perform a method for determining a degree of similarity between documents , the method comprising : . storing , for at least two documents , labeled tree representations of respective documents ; . storing , for at least two documents , path representations relating to paths that occur in the documents from root nodes to leaf nodes in the labeled tree representations of the respective documents ; and . calculating a measure of similarity between two of the documents based upon the frequency of occurrence of similar paths specified by the path representations .", "label": "", "metadata": {}, "score": "45.721405"}
{"text": "Current search engines like AltaVista try to return the most relevant answers to a query first .Often this means several similar versions of a document are returned as separate entries .Clustering allows us to display this similarity to the user and present the search results more compactly .", "label": "", "metadata": {}, "score": "45.739178"}
{"text": "[ 0049 ] .These cases are more difficult to solve rapidly , and it is these cases that are particularly amenable to being processed by the system and methods in accordance with these teachings .[ 0050 ] .Duplicate documents may be defined as those that have essentially the same words in the same sentences and paragraphs .", "label": "", "metadata": {}, "score": "45.805256"}
{"text": "One application of such weights is to assign weights to terms in web page documents .The weights assigned to the terms may then be utilized to determine whether web page documents are substantially identical .A set of identicals may be generated for each web page that is indexed by the system and utilized to repair broken hyperlinks .", "label": "", "metadata": {}, "score": "45.988777"}
{"text": "The mechanism we present here provides an alternative solution .Our approach to determining syntactic similarity is related to the sampling approach developed by Heintze [ 2 ] , though there are many differences in detail and in the precise definition of the measures used .", "label": "", "metadata": {}, "score": "46.04567"}
{"text": "This model can accommodate other aspects , such as optional elements and recursive elements , by using other subsume and generalize functions .If the application at hand requires optional and recursive control structures to be incorporated in the similarity measure , suitable subsume and generalize functions for these control structures can be used .", "label": "", "metadata": {}, "score": "46.105667"}
{"text": "We can that take the modulo of that number , and keep only the ones that are modulo of some chosen value .This gives us a much smaller set of shingles to work with , but distributed in such a way that similar documents are still likely to share shingles .", "label": "", "metadata": {}, "score": "46.151962"}
{"text": "These teachings further provide for the computation of a document signature that can then be used to make a rapid comparison between documents that are likely to be identical .for individual documents of a set of documents , executing a software program to obtain a list of terms found in each document ; . comparing the list of terms for a first document to the list of terms for a second document ; and .", "label": "", "metadata": {}, "score": "46.17711"}
{"text": "A wrapper is created to capture the extraction rules based on the patterns exhibited by the indicated fields in the example page .The wrapper is then used to extract similar information from all the pages that are structurally similar to the given example page .", "label": "", "metadata": {}, "score": "46.20246"}
{"text": "Similar difficulties may be encountered in different environments .Other references to objects or files may also be subject to change that makes them unresolvable .For example , links and path names that refer to other files or objects may change .", "label": "", "metadata": {}, "score": "46.204956"}
{"text": "It should be appreciated that the present invention may also be applied to finding and accessing resources in a LAN or WAN .The resources may be , for example , stored on a server that a client wishes to access .", "label": "", "metadata": {}, "score": "46.302063"}
{"text": "The result is a table of all documents that are identical and all documents that are very similar .[ 0031 ] .It should be apparent that these teachings provide a system and method for detecting documents returned from a search that are identical or very nearly identical .", "label": "", "metadata": {}, "score": "46.34491"}
{"text": "SpotSigs automatically discards such synthetic documents .As a second focus of the paper , SpotSigs also addresses some algorithmic challenges by tackling the inherent quadratic complexity when having to consider all candidate pairs of documents for the deduplication step .Here , our entire clustering algorithm is developed on the simple idea that we may never need to compare documents ( or their respective signature sets ) if they already substantially vary in length - at least if some set - resemblance - based similarity measure such as Jaccard similarity is used .", "label": "", "metadata": {}, "score": "46.35729"}
{"text": "Shingling provides a convenient way of testing whether two documents are near identical .Other possible methods : .Using the Unix tool \" diff \" , .Computing a hash value ( e.g. , an MD5 checksum or a Rabin fingerprint ) of each page downloaded from a web server , .", "label": "", "metadata": {}, "score": "46.38242"}
{"text": "The keywords may not necessarily occur in the textual descriptions of target objects ; they occur only in the documents .In order to answer these queries , we exploit the relationships between the documents containing the keywords and the target objects related to those documents .", "label": "", "metadata": {}, "score": "46.423233"}
{"text": "This phase is relatively inexpensive and the output clusters are relatively compact .Another issue is that basic clustering can only support queries about URLs that are part of the input , and the clusters are based on the contents of the URLs at the time they were retrieved .", "label": "", "metadata": {}, "score": "46.47325"}
{"text": "Rather , the inventors have contemplated that the claimed subject matter might also be embodied in other ways , to include different steps or combinations of steps similar to the ones described in this document , in conjunction with other present or future technologies .", "label": "", "metadata": {}, "score": "46.503975"}
{"text": "If there are no errors , the rule is activated and is then used by the web crawler for future crawling to avoid the download of duplicative web pages or web resources .Some tests that might be involved in determining whether two pages are substantially similar : .", "label": "", "metadata": {}, "score": "46.52653"}
{"text": "The content of the page is compared , not merely the URL .This step is repeated for the documents or web pages being tested .The documents , web resources , or web pages desirably correspond to a text document , an image , an audio file , and/or a video file , for example , but are not limited thereto .", "label": "", "metadata": {}, "score": "46.555084"}
{"text": "[ 0060 ] .Shingling is one way to determine whether two pages or resources are substantially identical , but there are many other techniques .For example , one might use the Unix tool \" diff \" ( which compares two text documents and outputs all the lines that differ between them ) to pair - wise compare all pages downloaded from a web server .", "label": "", "metadata": {}, "score": "46.571373"}
{"text": "Shingling - Near Duplicate Detection .Determining whether two documents are exactly the same is pretty easy , just use some suitably sized hash and look for a match .A document will generally only hash to the same as another though if they are identical - the smallest change , or the same content on another site with a different header and footer , for example , will cause the hash to be quite different .", "label": "", "metadata": {}, "score": "46.590286"}
{"text": "Nevertheless , audio information may also be retrieved and output .FIG .1A is a block diagram that illustrates the basic scheme that is employed in retrieving such media content with a conventional web browser 10 .The web browser 10 is run on a client computer system 12 .", "label": "", "metadata": {}, "score": "46.609024"}
{"text": "Second , super shingles can not detect containment .Suppose we have two documents and the larger one completely contains the smaller one .Then , the sketch of the larger document includes all of the shingles of the smaller document along with additional shingles from its extra material .", "label": "", "metadata": {}, "score": "46.712494"}
{"text": "[0008 ] .In view of the above comments , a need clearly exists for an improved manner of comparing documents for determining the structural similarity of the documents .SUMMARY .[ 0009 ] .Techniques are presented herein for measuring the similarity between two pages based on their structural syntax .", "label": "", "metadata": {}, "score": "46.721756"}
{"text": "In general , however , any feature selection method that is deemed suitable can be used .[ 0030 ] .[ 0031 ] .The bag of tree paths model for a document captures only some of the structural relationships present in the tree .", "label": "", "metadata": {}, "score": "46.812927"}
{"text": "[ 0032 ] .The method uses sophisticated , but fast , term recognition software to characterize documents by a list of the major , salient terms in each of the documents .When a search is performed , the terms in the returned documents can either be recognized rapidly , as described in FIG .", "label": "", "metadata": {}, "score": "46.83792"}
{"text": "This rule may then be tested , at step 130 .Testing may involve , for example , applying the rule to various URLs , and then determining if the ones predicted to have substantially identical content are , in fact , substantially identical .", "label": "", "metadata": {}, "score": "46.94276"}
{"text": "Moreover , those skilled in the art will appreciate that the invention may be practiced with other computer system configurations .An embodiment of the invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network or other data transmission medium .", "label": "", "metadata": {}, "score": "47.014248"}
{"text": "An important aspect of these teachings is that after the terms are recognized a very simple and fast database query can be used to return a list of all the terms which two documents do not have in common .The database can be any relational database , and may store the data in any convenient form either in memory or in standard database tables .", "label": "", "metadata": {}, "score": "47.1065"}
{"text": "0044 ] .The Textract system has been previously employed to characterize documents in a number of ways .[ 0045 ] .In a similar fashion , it has been reported that one could characterize documents of little significant content using the measures generated by Textract , and then eliminate them from lists of results returned from searches .", "label": "", "metadata": {}, "score": "47.1268"}
{"text": "The most straightforward application is a service to locate highly similar alternatives to a given URL .In this case , the user has the URL of a document and for some reason wants to find another document that resembles it .", "label": "", "metadata": {}, "score": "47.254166"}
{"text": "Conclusion .[0085 ] .A method , computer software , and a computer system are each described herein in the context of document structure comparison .Various alterations and modifications can be made to the techniques and arrangements described herein , as would be apparent to one skilled in the relevant art .", "label": "", "metadata": {}, "score": "47.4999"}
{"text": "[ 0056 ] .At step 120 , a URL normalization rule is determined based on the patterns .A rule matches some URLs , and transforms each matching URL into a normalized URL .Two URLs that are transformed to the same normalized URL are predicted to refer to substantially identical web pages .", "label": "", "metadata": {}, "score": "47.58591"}
{"text": "The result was that there were no documents returned on how to repair a Thinkpad(tm ) .However , many of the top 50 documents contained all of these terms in some context or other .Of the top 50 , 36 could be downloaded and analyzed .", "label": "", "metadata": {}, "score": "47.594463"}
{"text": "10 is a flowchart illustrating the steps that are performed to generate a set of identical web pages for a given web page .FIG .11 is a flowchart illustrating the steps that are performed to determine whether data objects are substantially identical or not .", "label": "", "metadata": {}, "score": "47.608772"}
{"text": "The cluster containing the original ruling would assist in producing the list of contacts .In contrast , with a search engine a query wide enough to cover all the variations would result in a large number of irrelevant hits that would have to be filtered out .", "label": "", "metadata": {}, "score": "47.61859"}
{"text": "Therefore , if the tags of all nodes are rearranged , the representation does not change .Thus , the model is adequate only when the templates are drastically different from each other , that is , they have very few tags in common .", "label": "", "metadata": {}, "score": "47.629913"}
{"text": "It is especially useful to know where the interesting parts of a web page are when they are interspersed with \" added - value \" content such as advertisements or navigational banners .This is most strikingly the case with online news articles , but applies more generally across the web .", "label": "", "metadata": {}, "score": "47.696163"}
{"text": "Sort , threshold and present the result .This method requires more space and time , but it offers greater flexibility than precomputed clusters .It also allows any document , even a document that was not part of the original input , to be compared for resemblance .", "label": "", "metadata": {}, "score": "47.71872"}
{"text": "These are in a false match that was generated by eliminating both unknown words and unknown names from the comparison .If one does not exclude unknown names ( which in this case are part and model numbers ) the documents are not suggested as being similar .", "label": "", "metadata": {}, "score": "47.72216"}
{"text": "The computer - readable medium of claim 28 wherein the computer executable instructions further comprise instructions for performing the step of determining that the first and second data objects are not substantially identical when values of the first and second weights are not substantially similar to each other .", "label": "", "metadata": {}, "score": "47.760838"}
{"text": "In order to apply these teachings to this type of problem it may be desirable to relax the restrictions regarding the percentage of terms that could be different , and the size differences allowed between documents that are compared .EXAMPLE 3 . [", "label": "", "metadata": {}, "score": "47.80107"}
{"text": "1 but described below , operates to determine salient terms in a document and processes the documents .For the purposes of this description a salient term is a single word or a multi - word term that meets a predetermined confidence .", "label": "", "metadata": {}, "score": "48.11405"}
{"text": "[ 0040 ] .Textract reduces related forms of a term to a single canonical form that it can then use in computing term occurrence statistics more accurately .In addition , it recognizes abbreviations and finds the canonical forms ofthe words they stand for , and aggregates these terms into a vocabulary for the entire collection , and for each document , keeping both document and collection - level statistics on these terms .", "label": "", "metadata": {}, "score": "48.23417"}
{"text": "Reference in this regard can be made to J. W. Cooper , AThe Technology of Lexical Navigation,@ Workshop on Browsing Technology , First Joint Conference on Digital Libraries , Roanoke , Va. , 2001 , and to J. W. Cooper , C. Cesar , E. So and R. L. Mack , AConstruction of an OO Framework for Text Mining,@", "label": "", "metadata": {}, "score": "48.283005"}
{"text": "In the first phase , we calculate a sketch for every document .This step is linear in the total length of the documents .In the second phase , we produce a list of all the shingles and the documents they appear in , sorted by shingle value .", "label": "", "metadata": {}, "score": "48.30355"}
{"text": "The system and method detects documents having much similar content , such as documents that are revisions of each other , by comparing the number of similar terms in each document .BRIEF DESCRIPTION OF THE DRAWINGS .[ 0015 ] .", "label": "", "metadata": {}, "score": "48.48578"}
{"text": "At step 110 , the URLs of the web pages that have been determined to be substantially identical are then analyzed for recurring patterns .For example , in which the following sixteen URLs all refer to substantially the same web page : . [ 0037 ] .", "label": "", "metadata": {}, "score": "48.586815"}
{"text": "Sketches are an effective method for estimating the resemblance of two documents because they are easily compared , canonical representations of the documents .Hence , we can estimate the resemblance of two documents with the ratio of the number of shingles they have in common to total number of shingles between them .", "label": "", "metadata": {}, "score": "48.628994"}
{"text": "The list is stored in a database and is used to compute document similarity with a simple database query .If the number of terms found to not be contained in both documents is less than some predetermined threshold compared to the total number of terms in the document , these documents are determined to be very similar .", "label": "", "metadata": {}, "score": "48.64053"}
{"text": "A method as in .claim 1 , wherein if the predetermined number is about 90 % of the terms or greater the first document is declared to be substantially identical to the second document .A method as in .claim 1 , wherein the set of documents is obtained in response to a search query made to a data communications network .", "label": "", "metadata": {}, "score": "48.677086"}
{"text": "[ 0011 ] .The foregoing and other problems are overcome , and other advantages are realized , in accordance with the presently preferred embodiments of these teachings .[ 0012 ] .Described herein is a system and a method of computing whether two documents are identical , or very similar , based on a similarity between lists of terms and possibly phrases found in common between the two documents .", "label": "", "metadata": {}, "score": "48.690876"}
{"text": "[ 0069 ] .It should be further noted that while individual strings usually have unique hash codes , there is a somewhat larger probability that the sum of a series of hash codes will be less unique .However , the probability of these collisions is small enough that these document signatures remain quite useful .", "label": "", "metadata": {}, "score": "48.706745"}
{"text": "Pages dynamically generated on servers using server code .Pages generated in accordance of a template .[ 0021 ] .The techniques now described define a procedure for conducting a comparison of documents to reach a quantitative determination of the degree of structural similarity between documents .", "label": "", "metadata": {}, "score": "48.716534"}
{"text": "The search also returned two other closely related document pairs as shown in Table 4 .Documents 9 and 10 are in fact a draft and a final PDF document of the same technical paper .Since these papers are quite different in size and format , they would probably not have been found as similar by conventional techniques .", "label": "", "metadata": {}, "score": "48.761673"}
{"text": "Database cleanup utility .Marketing campaign .PDF document .Product attribute .Shopper request .[0068 ] .Note that two documents could be considered identical by this procedure if they contained the same paragraphs in a different order , or even the same sentences in a different order .", "label": "", "metadata": {}, "score": "48.94776"}
{"text": "a calculator operable for calculating a measure of similarity between two of the documents based upon the frequency of occurrence of similar paths specified by the path representations .The computer system device in .claim 29 , wherein said method further comprises the tree representation is a Document Model Object representation .", "label": "", "metadata": {}, "score": "48.9653"}
{"text": "1 is a high level flow diagram of an exemplary method of identifying duplicate documents , web resources , or web pages in accordance with the present invention .At step 100 , all the web pages downloaded by the web crawler from a given web server are examined to identify all pages that are near identical ( i.e. , substantially identical ) .", "label": "", "metadata": {}, "score": "49.027794"}
{"text": "On the other hand , we can easily compute from .( We simply keep only those elements divisible by . )Thus , if we are given two documents , A and B , and was the modulus used by the longer document , we use and for our estimates .", "label": "", "metadata": {}, "score": "49.09615"}
{"text": "[0002 ] .Regardless of the search technology that is employed , most conventional search systems follow the same basic procedure for indexing and searching a database in a digital library .First , the data to be searched must be input to the search system for indexing .", "label": "", "metadata": {}, "score": "49.350792"}
{"text": "[ 0014 ] .Disclosed herein is a system and method that detects duplicate and very similar documents by comparing the number of similar terms in each document , and that detects very similar documents by comparing the number of similar terms in each document .", "label": "", "metadata": {}, "score": "49.46823"}
{"text": "In the drawings : .[ 0029 ] .FIG .1 is a high level flow diagram of an exemplary method of identifying duplicate documents , web resources , or web pages in accordance with the present invention ; .[ 0030 ] .", "label": "", "metadata": {}, "score": "49.596046"}
{"text": "Instead of just clustering the current contents of the Web , we cluster the contents of the web from multiple sweeps over the web done at different times .As long as any one sweep has found a particular URL , we can find its current location by taking the most recent URL from its cluster .", "label": "", "metadata": {}, "score": "49.615807"}
{"text": "( i ) calculating a collection frequency component that identifies how often the selected term appears within documents in a collection of documents ; .( ii ) calculating first and second term frequency components for the first and second documents equal to a number of times that the selected term appears within the first and second documents , respectively ; and .", "label": "", "metadata": {}, "score": "49.622223"}
{"text": "[0054 ] .[ 0055 ] .Upon examining other URLs identifying documents on a web site , it is found that there are many similar URLs that follow a similar pattern , where multiple URLs identify substantially the same web page .", "label": "", "metadata": {}, "score": "49.654476"}
{"text": "Alternatively , the most highly weighted terms may be cached in the catalog .In one term weighting schemes ( such as the weighted probabilistic function ) , the most important term can be determined without referencing the index .The occurrence streams 50 are examined to locate any other web page documents that contain the given term with the same or substantially the same weight ( step 108 in FIG .", "label": "", "metadata": {}, "score": "49.691307"}
{"text": "In general , finding the edit distance between unordered labeled trees is computationally more complex than finding the edit distance between ordered labeled trees .A key differentiator among the various tree distance algorithms is the set of edit operations allowed .", "label": "", "metadata": {}, "score": "49.727905"}
{"text": "There are several induction algorithms that attempt to learn the DTD from a set of examples .These approaches assume that all the examples come from the same DTD .If the XML pages in a given collection come from different DTDs , these algorithms can not be used directly , since it is theoretically infeasible to learn a single DTD for the entire collection .", "label": "", "metadata": {}, "score": "49.748554"}
{"text": "Finally , it is quite reasonable to store the document signature as part of the database document table , to speed the comparison of documents even further .[ 0082 ] .When comparing documents that contained embedded additional material , these criteria were relaxed to 50 % , with little performance penalty .", "label": "", "metadata": {}, "score": "49.83716"}
{"text": "[ 0024 ] .Embodiments of the invention are directed to predicting when different URLs actually reference the same document or web resource , and then using that information to only download one instance of a document or web resource from a web site .", "label": "", "metadata": {}, "score": "50.136177"}
{"text": "It should also be appreciated that the present invention may be applied to objects and files that hold non - textual features .For example , the present invention may be applied to files or objects that hold images and/or audio data .", "label": "", "metadata": {}, "score": "50.160862"}
{"text": "The shingle - equivalent documents are documents that have identical shingle values after the set of shingles has been selected .Obviously , all identical documents are lexically - equivalent , and all lexically equivalent documents are shingle equivalent .We can find each set of documents with a single fingerprint .", "label": "", "metadata": {}, "score": "50.190838"}
{"text": "These web pages include text and it is the terms within the text that serve as the features that are compared to identify substantially identical web pages .Each term in a web page document is assigned a weight that identifies the distinguishing weight of the term relative to other documents .", "label": "", "metadata": {}, "score": "50.205414"}
{"text": "In a presently preferred , but not limiting embodiment a suite of text analysis tools collectively known as Talent ( Text Analysis and Language Engineering Tools ) are employed for analyzing documents in a collection of documents .[ 0039 ] .", "label": "", "metadata": {}, "score": "50.257385"}
{"text": "[ 0035 ] .These teachings can also be used to recognize documents that are similar by virtue of being revisions of each other .In this embodiment , the variables X% and Y% described in FIG .3 are made larger .", "label": "", "metadata": {}, "score": "50.346626"}
{"text": "Given a source document we can detect if all or parts of it have been substantially copied or if small changes were made to documents that were supposed to be left unchanged ( eg license agreements ) .However , the security of our approach is rather limited , since we have a single , static sketching policy .", "label": "", "metadata": {}, "score": "50.433952"}
{"text": "Manager1.htm .[0065 ] .When documents are very large , it is not usually convenient to run phrase recognition software on the entire set of documents in real time when they are returned from a query .However , as part of the indexing process , it is not unreasonable to catalog the major terms in each document .", "label": "", "metadata": {}, "score": "50.455883"}
{"text": "A method as in . claim 10 , wherein the step of computing a document signature computes a hash code for each term of the list of terms , and then sums all of the hash codes to form the document signature .", "label": "", "metadata": {}, "score": "50.644554"}
{"text": "This is a particularly challenging setting because the page layouts are often literally drenched with ads or navigational banners as added by the different sites .The actual core articles constitute only a minor fraction of the overall page , which makes online news a very hard setting for any unsupervised clustering or deduplication approach .", "label": "", "metadata": {}, "score": "50.77167"}
{"text": "Extensions .For better performance , shingling can be extended by shingling the shingles to get ( believe it or not ) supershingles .On a reasonable length document the chance of two similar documents sharing a supershingle is high , so this can save a lot of checking and give fast lookups , but might have problems on shorter documents , or when length is very variable .", "label": "", "metadata": {}, "score": "50.778862"}
{"text": "We examine each triplet and decide if the document pair exceeds our threshold for resemblance .If it does , we add a link between the two documents in a union - find algorithm .The connected components output by the union - find algorithm form the final clusters .", "label": "", "metadata": {}, "score": "51.09343"}
{"text": "The resulting list of identicals is then stored within the catalog 52 of the index 38 ( step 104 in FIG .10 ) .FIG .11 illustrates in more detail how identicals for a data object are calculated in step 102 of FIG .", "label": "", "metadata": {}, "score": "51.156654"}
{"text": "if the first and second documents are substantially identical , accessing the second document , in response to a request emanating from a requesting party to access the first document , when the first document can not be accessed in a predefined manner by the requesting party .", "label": "", "metadata": {}, "score": "51.17937"}
{"text": "These files or objects may have moved from one machine to another in a distributed environment .As such , the references associated with links may change .The present invention may be applied to identify a proper reference to repair the broken link .", "label": "", "metadata": {}, "score": "51.226044"}
{"text": "View/ Open .Date .Author .Metadata .Abstract .Near - duplicate documents can adversely affect the efficiency and effectiveness of search engines .Due to the pairwise nature of the comparisons required for near - duplicate detection , this process is extremely costly in terms of the time and processing power it requires .", "label": "", "metadata": {}, "score": "51.365356"}
{"text": "For documents in foreign language , the features could be labels from a multi - lingual concordance .Musical features could be based on Sequences of notes or chords .As techniques are developed for identifying features in other data types , there are no limits on the objects that can be compared for resemblance : images , video sequences , or databases .", "label": "", "metadata": {}, "score": "51.415688"}
{"text": "In view of the above , we can choose a random permutation and afterwards keep for each document D a sketch consisting only of the set F ( D ) and/or V ( D ) .The sketches suffice to estimate the resemblance or the containment of any pair of documents without any need for the original files .", "label": "", "metadata": {}, "score": "51.46099"}
{"text": "The cosine normalization function will be preferred in many applications since the resulting number may be used both for word weight calculation and for the measurement of progress in reaching the \" perfect score \" for the document , as discussed below .", "label": "", "metadata": {}, "score": "51.46893"}
{"text": "To compute the resemblance and/or the containment of two documents it suffices to keep for each document a sketch of a few hundred bytes .The sketches can be efficiently computed ( in time linear in the size of the documents ) and , given two sketches , the resemblance or the containment of the corresponding documents can be computed in time linear in the size of the sketches .", "label": "", "metadata": {}, "score": "51.59607"}
{"text": "While this algorithm is quite simple , a naive implementation is impractical .Our test case is a set 30,000,000 HTML and text documents retrieved from the Web .A pairwise comparison would involve O(10 15 ) ( a quadrillion ) comparisons .", "label": "", "metadata": {}, "score": "51.631477"}
{"text": "In the third phase - the creation of triples - the storage requirements grew to about 20 Gbytes .( We save some space because there are shingles that only appear in one document , but we lose on the quadratic expansion of document ID lists to document ID pairs .", "label": "", "metadata": {}, "score": "51.6639"}
{"text": "The inventors have also shown that one may compute a document signature that can then be used to make a rapid comparison between documents that are likely to be identical .[ 0084 ] .In the course of the experiments discussed above the IQ threshold and the term frequency threshold were varied , and for various types of applications these values may be adjusted .", "label": "", "metadata": {}, "score": "51.67701"}
{"text": "We then apply the divide , sort , merge procedure ( adding the counts for matching ID - ID pairs ) to produce a single file of all triplets sorted by the first document ID .This phase requires the greatest amount of disk space because the initial expansion of the document ID triplets is quadratic in the number of documents sharing a shingle , and initially produces many triplets with a count of 1 .", "label": "", "metadata": {}, "score": "51.73116"}
{"text": "Determining structural similarity in semi - structured documents US 20050038785 A1 .Abstract .Documents are represented based on their structure , which arises from the relationship between various elements in the document .After representing documents based on their structure in vector form , a method of measuring similarity between vectors is used to obtain the measure of structural similarity between two given documents .", "label": "", "metadata": {}, "score": "51.757042"}
{"text": "Some of them are need to identify the page , and others are optional and are related to co - branding .If you were to put the optional components into square brackets , the URLs could be described as follows .", "label": "", "metadata": {}, "score": "51.888588"}
{"text": "Thus , the present invention is not limited in scope to objects that are identified by URLs and an Internet or intranet environment .Instead , the present invention applies more broadly to different types of data objects that have various reference mechanisms .", "label": "", "metadata": {}, "score": "51.958916"}
{"text": "claim 6 , wherein paths that occur highly frequently or highly infrequently are eliminated from the path dictionary ( Dict paths ) .The method as claimed in .claim 7 , further comprising the step of computing the frequency of occurrence ( f j ( p i ) ) of a path ( p i ) in a document ( d j ) .", "label": "", "metadata": {}, "score": "52.11201"}
{"text": "The method as claimed in . claim 17 , further comprising the step of normalising the measure of similarity by a term that represents the number of unique path representations shared by the two documents .The method as claimed in .", "label": "", "metadata": {}, "score": "52.1323"}
{"text": "[ 0047 ] .In any Web search , it is likely that some documents that are returned are very similar .Since these are very well known and described , they are readily eliminated using any one of a number of existing techniques .", "label": "", "metadata": {}, "score": "52.210228"}
{"text": "The results are shown in Table 8 .Buiding .Ebusmark .RetailB .[ 0076 ] .It was concluded that documents of whatever size difference that had less than 20 % of the terms different were likely to represent documents that were related and contained much the same text .", "label": "", "metadata": {}, "score": "52.24576"}
{"text": "When implemented on a general - purpose processor , the program code combines with the processor to provide a unique apparatus that operates to perform the functionality of the present invention .[ 0111 ] .Therefore , the present invention should not be limited to any single embodiment , but rather construed in breadth and scope in accordance with the appended claims .", "label": "", "metadata": {}, "score": "52.31718"}
{"text": "The proposed similarity measure can be used to cluster pages based on structural similarity .[heading-0081 ] .Application to Document Type Defining ( DTD ) Induction .[ 0082 ] .In the case of XML documents , knowledge of the DTD can facilitate the identification of structurally similar pages .", "label": "", "metadata": {}, "score": "52.326164"}
{"text": "\" or not to be \" . \" not to be that \" . \" to be that is \" . \" be that is the \" .\" that is the question \" .Any duplicates would be removed .If we had the two sets of shingles for two different document we could calculate the Jaccard coefficient , which gives a similarity score between two sets .", "label": "", "metadata": {}, "score": "52.330406"}
{"text": "However , to check for duplicates in a collection we 're still effectively comparing all the words against each other for each pair of documents , which is not likely to be cheap !Estimating & Sampling .The solution is to estimate the resemblance by just taking a sampling of the shingles .", "label": "", "metadata": {}, "score": "52.339912"}
{"text": "0010 ] .Several techniques exist to measure similarity between two numeric vectors .Such techniques are used to measure the similarity between two documents , and between a document and a document collection .[ 0011 ] .For measuring the structural similarity between documents , documents are represented based on their structure .", "label": "", "metadata": {}, "score": "52.36144"}
{"text": "This entry includes the list of identicals ( i.e. , it contains the doc IDs for the identicals ) .One of the identicals is then used to repair the link .In particular , the catalog 52 is again consulted to determine a uniform resource locator ( URL ) for the substantially identical data object .", "label": "", "metadata": {}, "score": "52.381252"}
{"text": "2 is a block diagram depicting a computing environment that is suitable for practicing the exemplary embodiment to the present invention .FIG .3 is a flowchart that provides an overview of the steps performed by the exemplary embodiment of the present invention .", "label": "", "metadata": {}, "score": "52.395157"}
{"text": "12 is a flowchart illustrating the steps that are performed to repair a hyperlink in the exemplary embodiment of the present invention .DETAILED DESCRIPTION OF THE INVENTION .The exemplary embodiment of the present invention described below provides an approach to comparing data objects to quickly and easily determine whether the data objects are substantially identical .", "label": "", "metadata": {}, "score": "52.478683"}
{"text": "FIG .8 depicts the steps that are performed to build the index .The exemplary embodiment of the present invention utilizes a web crawler that crawls web sites as a background process and locates changes in content on web sites that are indexed by the index 38 .", "label": "", "metadata": {}, "score": "52.57701"}
{"text": "[ 0069 ] .[0070 ] .[ 0071 ] .[ 0072 ] .[0073 ] .[ 0074 ] .[0075 ] .d. Compare the right - hand sides of the rewrite rules of associated with different equivalence classes , and generalize rules that have similar right - hand sides by parameterizing them .", "label": "", "metadata": {}, "score": "52.62964"}
{"text": "In the second stage ( step 240 ) , normalized URLs are compared and parameterized normalization rules that work across equivalence classes are derived .[0067 ] .A more detailed description of this embodiment would be : . [0068 ] .", "label": "", "metadata": {}, "score": "52.701912"}
{"text": "FIG .4 is a flowchart of steps in a procedure for comparing a pair of documents .[ 0016 ] .FIG .5 is a schematic representation of a computer system suitable for performing the techniques described with reference to FIGS . 1 to 4 . DETAILED DESCRIPTION .", "label": "", "metadata": {}, "score": "52.826347"}
{"text": "Mechanically generated pages with artificially different URLs and internal links .These common shingles either have no effect on the overall resemblance of the documents or they have the effect of creating a false resemblance between two basically dissimilar documents .Therefore , we ignore all very common shingles .", "label": "", "metadata": {}, "score": "52.889427"}
{"text": "Those skilled in the art , however , will appreciate that the index could be located remotely relative to the client and remotely accessed by the client .Furthermore , the index could be pre - built by another entity and used by the client 24 .", "label": "", "metadata": {}, "score": "53.064575"}
{"text": "The present invention may also apply to a standalone computing device , having programming language functionality , interpretation and execution capabilities .[0109 ] .The various systems , methods , and techniques described herein may be implemented with hardware or software or , where appropriate , with a combination of both .", "label": "", "metadata": {}, "score": "53.11695"}
{"text": "For use with a computer system , a computer - readable medium storing computer - executable instructions for performing a method comprising the computer - implemented steps of : . providing a hypertext document having a hyperlink to a first web page holding media content ; . in response to a party selecting the hyperlink , attempting to access the first web page so as to define an access attempt ; and .", "label": "", "metadata": {}, "score": "53.18627"}
{"text": "In general , there is an inverse relationship between meaningfulness and the number of documents in which the term occurs .The document frequency component is then calculated for the term ( step 98 in FIG .9 ) .The document frequency component indicates the number of times that a term occurs within a document .", "label": "", "metadata": {}, "score": "53.264393"}
{"text": "In addition , it is significant that six of these documents have identical signatures ( shown in boldface ) even though they are of four different sizes .This illustrates the utility of the signature method for rapid identification of documents .", "label": "", "metadata": {}, "score": "53.283997"}
{"text": "11 .If it is supposed that the threshold value is 0.8 , it is concluded that the candidate document is not identical to the web page document being analyzed .It should be appreciated that multiple candidate documents may be processed concurrently .", "label": "", "metadata": {}, "score": "53.37933"}
{"text": "Very common shingles ( for us , this means shingles shared by more than 1000 documents ) are a performance problem during the third phase of our algorithm .As we have discussed , the number of document ID pairs is quadratic in the number of documents sharing a shingle .", "label": "", "metadata": {}, "score": "53.44702"}
{"text": "In such a case , the weight for the next highest scoring term in the web page document being analyzed is identified , and it is determined whether the candidate web page document includes a substantially similar weight for the term ( see step 108 in FIG .", "label": "", "metadata": {}, "score": "53.455475"}
{"text": "Using the similarity measure described herein , one can determine an approach to identify this template information .The documents from a collection are first clustered based on their structure .A cluster contains pages that share a common look and feel .", "label": "", "metadata": {}, "score": "53.503975"}
{"text": "( Posted by Martin Theobald ) .In almost all classical Information Retrieval settings that have a text processing component , stopwords are first discarded before anything interesting happens with the document . \"Interesting \" here might mean indexing the content for search , extracting features for automatic classification , or some other form of content analysis of whatever flavor .", "label": "", "metadata": {}, "score": "53.53459"}
{"text": "In the bag of Xpaths model , a representation of a document as a labeled tree includes a positional index along with the label for each node .The positional index of a node n advises that the number of previous sibling nodes with the same label as that of node n. .", "label": "", "metadata": {}, "score": "53.563534"}
{"text": "However , they are gradually combined together as the files are merged . )At the end of the third phase , the sorted file of triples took up 6 Gbytes .The final clustering phase is the most memory intensive phase since we want the entire union - find data structure to be in memory .", "label": "", "metadata": {}, "score": "53.653267"}
{"text": "To process queries , the search server needs to access just the database index , which may be located on the same computer as the search server or yet another computer on the network .The actual objects in the database may be located on any computer on the network .", "label": "", "metadata": {}, "score": "53.70873"}
{"text": "Different URLs that actually reference the same web page or other web resource are detected and that information is used to only download one instance of a web page or web resource from a web site .All web pages or web resources downloaded from a web server are compared to identify which are substantially identical .", "label": "", "metadata": {}, "score": "53.728165"}
{"text": "Unfortunately , such an object identifier , path name or resource identifier may not be current .As a result , access to the resource may not be possible .SUMMARY OF THE INVENTION .In accordance with a first aspect of the present invention , weights for features of a first data object and a second data object are provided .", "label": "", "metadata": {}, "score": "53.729782"}
{"text": "In other words , the precision and recall were 100 % .On the other hand , the algorithm did not identify the short IBM press release document as being related to any of the others by containment , since it was relatively short , and contained only a few salient terms .", "label": "", "metadata": {}, "score": "53.762787"}
{"text": "0017 ] .Two documents are typically assessed to be structurally similar if they have a similar \" look and feel \" , or layout .By way of example , structurally similar pages might be generated in the following ways : .", "label": "", "metadata": {}, "score": "53.773537"}
{"text": "Again , one can use the proposed similarity measure to cluster the pages based on \" structural similarity \" .[ heading-0083 ] .Application to Template Removal .[ 0084 ] .Common information contained in templates hinders the performance of many information retrieval and data mining algorithms .", "label": "", "metadata": {}, "score": "53.788338"}
{"text": "In view of the foregoing , there is a need for systems and methods that overcome such deficiencies .SUMMARY OF THE INVENTION .[ 0023 ] .The following summary provides an overview of various aspects of the invention .It is not intended to provide an exhaustive description of all of the important aspects of the invention , nor to define the scope of the invention .", "label": "", "metadata": {}, "score": "53.874687"}
{"text": "That describes an algoritm that tries to identify substantially similar pages at different URLs on a site , and was co - authored by Ziv Bar - Yossef , who is now at Google .Ideally , a site owner or builder will try to reduce or eliminate the possibility that a page can show up under more than one URL on the same site as much as possible .", "label": "", "metadata": {}, "score": "53.920708"}
{"text": "[ heading-0079 ] .Application to Information Extraction .[ 0080 ] .There has been much work in the area of information extraction from Web pages in the recent years .One approach to this problem is to generate a wrapper using an example page .", "label": "", "metadata": {}, "score": "53.924667"}
{"text": "[ 0095 ] .The rules learned for a particular web site may be desirably validated against the documents that have been downloaded from that web site so far ( possibly within a bounded time interval , to deal with the fact that URL naming schemes may change over time ) .", "label": "", "metadata": {}, "score": "54.097153"}
{"text": "0073 ] .The documents in Table 7 are all very similar , since they differ in only one or two terms out of 47 , and all have similar sizes .Based on size alone , one would identify only four pairs of identical documents .", "label": "", "metadata": {}, "score": "54.12421"}
{"text": "What was returned was the count of the number of terms that appear in document 2 that are not in document 1 .While it might appear that n 2 queries are necessary to accomplish this , it is in fact only necessary to traverse the upper triangle of this matrix .", "label": "", "metadata": {}, "score": "54.144653"}
{"text": "The file containing just the URLs of the documents took up 1.8 Gbytes ( an average of 60 bytes per URL ) .We sketched all of the documents with 10 word long shingles to produce 40 bit ( 5 byte ) shingle fingerprints .", "label": "", "metadata": {}, "score": "54.26789"}
{"text": "claim 7 , wherein analyzing the content comprises at least one of shingling , check - summing , and lexical comparison .The method of .claim 1 , further comprising testing the rule .The method of .claim 1 , further comprising receiving the at least two web resources from a web server prior to analyzing .", "label": "", "metadata": {}, "score": "54.276115"}
{"text": "( ii ) calculating first and second term frequency components for the first and second documents equal to a number of times that the selected term appears within the first and second documents , respectively ; and .( iii ) calculating first and second products of the collection frequency component and the first and second term frequency components , respectively , and normalizing the first and second products to respectively produces the first and second word weights ; . comparing the first word weight with the second word weight so as to determine whether the first and second documents are substantially identical ; and .", "label": "", "metadata": {}, "score": "54.381943"}
{"text": "If the two documents are identical , then every shingle will be present in both documents , and the two numbers will be the same , giving a score of 1 .The easiest way to work around this is to just count the ones in the intersection twice , since they must have been in both sets .", "label": "", "metadata": {}, "score": "54.40833"}
{"text": "In a computer system , a method comprising the steps of : . providing a hypertext document having a hyperlink to a first web page holding media content ; . in response to a party selecting the hyperlink , attempting to access the first web page so as to define an access attempt ; and .", "label": "", "metadata": {}, "score": "54.45305"}
{"text": "We have implemented the sketching , clustering and clustering on - the- fly algorithms and produced a working demonstration system .We tested our algorithms on a collection of 30,000,000 HTML and text documents from a walk of the web performed by AltaVista in April of 1996 .", "label": "", "metadata": {}, "score": "54.62556"}
{"text": "The duplication problem arises in two ways : First , there are documents that are found in multiple places in identical form .Some examples are .FAQ ( Frequently Asked Questions ) or RFC ( Request For Comments ) documents .", "label": "", "metadata": {}, "score": "54.70205"}
{"text": "A system as in .claim 25 , wherein said processor computes the document signature by computing a hash code for each term of the list of terms , and summing all of the hash codes to form the document signature .", "label": "", "metadata": {}, "score": "54.770584"}
{"text": "This process repeats for all documents larger than document I ( step 307 ) and for all remaining documents ( step 308 ) .The result is a table of all documents that are identical and all documents that are very similar .", "label": "", "metadata": {}, "score": "54.7782"}
{"text": "To capture the informal notions of \" roughly the same \" and \" roughly contained \" in a rigorous way , we use the mathematical concepts of resemblance and containment as defined below .The resemblance of two documents A and B is a number between 0 and 1 , such that when the resemblance is close to 1 it is likely that the documents are \" roughly the same . \"", "label": "", "metadata": {}, "score": "54.825443"}
{"text": "[ 0036 ] .Having thus provided a description of the system and methods in accordance with these teachings a further , more detailed description is now provided of the various text analysis and processing tools and procedures that were mentioned above .", "label": "", "metadata": {}, "score": "54.85961"}
{"text": "The method of claim 10 further comprising the step of determining that the first and second web pages are not substantially identical when values of the first and second weights are not substantially similar to each other .The method of claim 10 wherein the comparing step comprises the step of comparing additional corresponding ones of the weights in the first and second pluralities of weights for additional associated ones of the terms of said first and second web pages , respectively .", "label": "", "metadata": {}, "score": "54.896946"}
{"text": "11 .The above discussion is focused on the instance where at least one identical weight for a term has been found within a candidate document .It is useful to also consider the case where the term or a similar weight is not found within the candidate document .", "label": "", "metadata": {}, "score": "55.00514"}
{"text": "The computer - readable medium of claim 34 wherein the computer executable instructions further comprise instructions for performing the step of determining each of the weights .The computer - readable medium of claim 34 wherein the computer executable instructions further comprise instructions for performing the step of storing the weights in the first and second pluralities in an index of web pages that indexes terms within web pages .", "label": "", "metadata": {}, "score": "55.023186"}
{"text": "[ 0016 ] .[ 0016]FIG .1 is a block diagram of a networked search system in accordance with one embodiment of these teachings ; .[0017 ] .[ 0017]FIG .2 is a flowchart illustrating how a query returns documents and how terms are recognized and stored in a database ; .", "label": "", "metadata": {}, "score": "55.043163"}
{"text": "First , super shingles do not work well for short documents .Short documents do not contain many shingles and so , even with regular shingles , the error in estimating document resemblance is greater .Super shingles make this problem worse .", "label": "", "metadata": {}, "score": "55.05165"}
{"text": "[ 0088 ] .Thus , while described in the context of presently preferred embodiments , those skilled in the art should appreciate that changes in the form and details of these teachings may be made without deviating from the scope and spirit of this invention .", "label": "", "metadata": {}, "score": "55.0521"}
{"text": "Any algorithm involving random disk accesses or that causes paging activity is completely infeasible .In the design of our algorithms , we use a single , simple approach for dealing with so much data - divide , compute , merge .", "label": "", "metadata": {}, "score": "55.24134"}
{"text": "The main advantage of URNs is that they are location independent .A single , stable URN can track a resource as it is renamed or moves from server to server .A URN could direct a user to the instance of a replicated resource that is in the nearest mirror site , or is given in a desired language .", "label": "", "metadata": {}, "score": "55.24354"}
{"text": "PERSON .A person .ORG .An organization .[ 0043 ] .While Textract is the presently preferred phrase recognition tool , it is noted that there are a number of other systems that have been developed for phrase recognition . of the RIAO Conference , Paris , France , 2000 ) .", "label": "", "metadata": {}, "score": "55.274628"}
{"text": "A ranked list of the most important terms in each document is obtained using a phrase recognizer system . 054366 , 10054366 , US 2003/0172066 A1 , US 2003/172066 A1 , US 20030172066 A1 , US 20030172066A1 , US 2003172066 A1 , US 2003172066A1 , US - A1 - 20030172066 , US - A1 - 2003172066 , US2003/0172066A1 , US2003/172066A1 , US20030172066", "label": "", "metadata": {}, "score": "55.315983"}
{"text": "In another embodiment the terms are recognized in advance at indexing time for each document , and a hash code is computed for each term .The sum of these hash codes constitutes a document signature that is sufficiently unique to use as a comparison among documents returned from a query .", "label": "", "metadata": {}, "score": "55.377865"}
{"text": "The link resolution then either fails or exceeds within a predetermined period of time .The web browser may employ a timer such that when a fixed time period elapses ( see step 132 ) , link repair is initiated .The web browser 36 then locates a substantially similar data object ( see step 134 ) within the index 38 .", "label": "", "metadata": {}, "score": "55.44983"}
{"text": "[ 0064 ] .Step 410 .Model all the documents as labeled trees and build a dictionary of paths or XPaths based on the bag of Paths or bag of XPaths model as required .[ 0066 ] .Step 420 .", "label": "", "metadata": {}, "score": "55.57251"}
{"text": "On - the - fly resemblance .If we are able to keep the full sketches of every document and the file of sorted pairs , then we can perform on the fly resemblance .In this case , the input can be any document ; either from a URL or stored locally ; whether is was part of the initial clustering or not ; whether it has changed or not .", "label": "", "metadata": {}, "score": "55.585663"}
{"text": "In addition , the existence of a single common super shingle means it is likely that two documents resemble each other .To compute resemblance with regular shingles , we need to collect and count the common shingles .To detect resemblance with super shingles , we only need to find a single common super shingle .", "label": "", "metadata": {}, "score": "55.64637"}
{"text": "Two of the major outputs of Textract are the IQ and the collection statistics for each of the canonical terms , and tables of the terms found in each document .The terms per document are not canonical forms , since this information is generated during a second pass .", "label": "", "metadata": {}, "score": "55.73694"}
{"text": "In accordance with a further aspect of the present invention , a word weight is calculated for a term within a first document , and a second word weight is calculated for the same term within a second document .For each document , the word weight is calculated by first calculating a collection frequency component that identifies how often the term appears within documents that are part of collection documents .", "label": "", "metadata": {}, "score": "55.794235"}
{"text": "If such a document containing the highest weighted term and a substantially similar weight for the term is found ( see step 110 ) , each such document is considered a potential candidate for the set of identicals .The document similarity value is initially calculated as the dot product of the weight for the term in the first web page document with the weight for this term in the second document .", "label": "", "metadata": {}, "score": "55.825424"}
{"text": "One application of such weights is to assign weights to terms in web page documents .Method for providing a substitute for a requested inaccessible object by identifying substantially similar objects using weights corresponding to object features US 5941944 A .R\u00e9sum\u00e9 .", "label": "", "metadata": {}, "score": "55.929077"}
{"text": "The method of claim 10 wherein the method further comprises the step of determining each of the weights .The method of claim 10 further comprising the step of storing the weights in the first and second pluralities in an index of web pages that indexes terms within web pages .", "label": "", "metadata": {}, "score": "55.9357"}
{"text": "The parent - child relationship is sufficient for measuring the structural similarity of documents , if the documents contain many levels of nesting ( that is , the depth of the corresponding trees is relatively high ) .If , however , the documents do not contain many levels of nesting ( that is , the corresponding trees are shallow ) , then the documents will more probably contain the same paths , even if the overall structure differs substantially .", "label": "", "metadata": {}, "score": "55.961143"}
{"text": "FIELD OF THE INVENTION .[ 0001 ] .The present invention relates generally to the field of web crawlers , and , more particularly , to inferring uniform resource locator ( URL ) normalization rules for substantially identical web resources having different URLs .", "label": "", "metadata": {}, "score": "56.000122"}
{"text": "These shared properties are assumed to be relevant to identifying the document returned by the web server , while non - shared properties are deemed irrelevant .[ 0066 ] .At the end of this stage , one \" canonical \" URL per equivalence class is provided .", "label": "", "metadata": {}, "score": "56.003365"}
{"text": "Abstract .Different URLs that actually reference the same web page or other web resource are detected and that information is used to only download one instance of a web page or web resource from a web site .All web pages or web resources downloaded from a web server are compared to identify which are substantially identical .", "label": "", "metadata": {}, "score": "56.079483"}
{"text": "Accordingly , an alternative similarity measure , which incorporates the issue of repetition for the bag of XPaths model , is now defined .[ heading-0049 ] .Similarity Measure .[ 0050 ] .A special type of defined generalized predicate is referred to as repetitive predicate .", "label": "", "metadata": {}, "score": "56.101364"}
{"text": "One or more programs are preferably implemented in a high level procedural or object oriented programming language to communicate with a computer system .However , the program(s ) can be implemented in assembly or machine language , if desired .In any case , the language may be a compiled or interpreted language , and combined with hardware implementations .", "label": "", "metadata": {}, "score": "56.142776"}
{"text": "The computer - readable medium of claim 45 wherein the computer executable instructions further comprise instructions for performing the step of returning , in response to the request , the second document to the requesting party .Description .TECHNICAL FIELD .", "label": "", "metadata": {}, "score": "56.16076"}
{"text": "This canonical form ignores minor details such as formatting , HTML commands , and capitalization .We then associate with every document D a set of subsequences of tokens S ( D , w ) .A contiguous subsequence contained in D is called a shingle .", "label": "", "metadata": {}, "score": "56.245567"}
{"text": "Here 's the code for a simple shingling class .The documents are broken down into their w - shingles , and the ones that fit the modulo stored .The numeric value for each shingle is calculated by taking the first few characters of an MD5 .", "label": "", "metadata": {}, "score": "56.24741"}
{"text": "The web crawler enables the index 38 to be incrementally updated .The web crawler locates newly added data objects , such as web page documents ( step 90 in FIG .8) .Features are then extracted from the new data object and tokenized ( step 92 ) .", "label": "", "metadata": {}, "score": "56.312023"}
{"text": "The inclusion of a tag inside the scope of another tag is captured by a \" parent - child \" relationship in the labeled tree .Text nodes are excluded from the labeled tree , as text nodes are immaterial to the structural properties of the document .", "label": "", "metadata": {}, "score": "56.360336"}
{"text": "Web crawlers traverse web sites and download all pages referenced by the URLs of the web site .However , many web sites use different URLs to reference the same web page or document , for various reasons .It is quite common for the same document to be identified by several and possibly many URLs .", "label": "", "metadata": {}, "score": "56.368057"}
{"text": "Similarly , where the first weight and the second weight are not substantially similar , it may , in some instances , be determined that the first object and the second object are not substantially identical .Additional weights for additional terms may be compared to more conclusively determine whether the first data object and the second data object are substantially identical .", "label": "", "metadata": {}, "score": "56.408302"}
{"text": "Additional features and advantages of the invention will be made apparent from the following detailed description of illustrative embodiments that proceeds with reference to the accompanying drawings .BRIEF DESCRIPTION OF THE DRAWINGS .[ 0028 ] .The foregoing summary , as well as the following detailed description of preferred embodiments , is better understood when read in conjunction with the appended drawings .", "label": "", "metadata": {}, "score": "56.48282"}
{"text": "The method of claim 20 wherein the identifying , accessing and returning steps all occur substantially transparently to the party .In a computer system , a method comprising the computer - implemented steps of : . calculating first and second word weights for a selected term within a first document and for the selected term within a second document , respectively , by : .", "label": "", "metadata": {}, "score": "56.541008"}
{"text": "The other approaches work because the factors that they measure represent a telltale statistical signature that seldom occurs in non - identical documents .Consider the following example document concerning orphans : .Orphan , a minor who has lost one or both parents .", "label": "", "metadata": {}, "score": "56.641495"}
{"text": "A suitable normalization component is the square root of the sum of the squared weights of the other terms in the documents .Those skilled in the art will recognize this as the cosine normalization function and will recognize that other word weight and normalization functions may be used as well .", "label": "", "metadata": {}, "score": "56.6994"}
{"text": "Each of these documents was returned as a PDF file and was converted to HTML using the Gemini(tm ) plug - in mentioned above .In Table 3 , documents 1 and 2 and documents 3 and 4 are almost certainly absolutely identical .", "label": "", "metadata": {}, "score": "56.755997"}
{"text": "a processor for analyzing the content of at least two web resources to determine whether the web resources are substantially identical , and determining a rule for the URLs of the web resources if the web resources are substantially identical .The system of .", "label": "", "metadata": {}, "score": "57.04333"}
{"text": "The method of claim 20 wherein the media content in the first web page comprises text .The method of claim 20 wherein the hyperlink comprises information specifying a network location of the first web site and wherein the access attempt is not successful because the information is incorrect .", "label": "", "metadata": {}, "score": "57.10009"}
{"text": "These documents are identical by any measure and can be easily recognized and collapsed to a single entity .aixy2k1.html .Client.html .Conf.html .[ 0061 ] .Table 3 shows a cluster of eight documents which have similar names , but different sizes .", "label": "", "metadata": {}, "score": "57.131523"}
{"text": "Kaushik Chakrabarti , Venkatesh Ganti , Jiawei Han , and Dong Xin 2006 .Abstract .In many document collections , documents are related to objects such as document authors , products described in the document , or persons referred to in the document .", "label": "", "metadata": {}, "score": "57.17597"}
{"text": "3 ) .In such an instance , the steps depicted in FIG .12 are performed .The web browser 36 attempts to resolve a link within a hypermedia document .Suppose that the web browser 36 attempts to resolve a link that points to the media 40a on server 26 ( see step 130 in FIG .", "label": "", "metadata": {}, "score": "57.18418"}
{"text": "Two documents are identical if they have all of the major terms identical , and very nearly identical if the number of different terms is less than some threshold value , such as 10 % , of the total number of terms .", "label": "", "metadata": {}, "score": "57.27661"}
{"text": "One of the causes for such unresolvable links is that the storage location of the media 18 may be changed without updating the links contained within the Hypertext document .In such cases , the web browser 10 returns an error message because the media content is no longer located at the address path specified by the link .", "label": "", "metadata": {}, "score": "57.360184"}
{"text": "[ 0066 ] .This problem is overcome , as described above , by computing the digital signature of each document , based on the terms found in the document .Such a signature can be as simple as a sum of the hash codes of the term strings that make up these major terms .", "label": "", "metadata": {}, "score": "57.40104"}
{"text": "lk . )The method as claimed in .claim 1 , wherein the tree representation of a document includes a positional index , which represents , for a node ( n ) , the number of previous sibling nodes with the same label as that of node ( n ) .", "label": "", "metadata": {}, "score": "57.407364"}
{"text": "The KSS Java libraries were used to load these result files into a database ( DB2(tm ) ) and these result files were subjected to various SQL queries to determine the number of terms that the downloaded documents had in common .", "label": "", "metadata": {}, "score": "57.437866"}
{"text": "11 ) .This value is calculated as one minus the contribution of the term to the document similarity score .If a candidate did not include the term \" orphans \" in the above example , the best possible document similarity score would be 1 - 0.4433 or 0.5566 .", "label": "", "metadata": {}, "score": "57.68449"}
{"text": "[0058 ] .[ 0059 ] .Now , the similarity measure for a pair of documents d i and d j can be defined as follows as expressed in Equation [ 2 ] below . sim .d .i .", "label": "", "metadata": {}, "score": "57.71711"}
{"text": "These localized signatures exploit the observation that stopwords are frequently and uniformly distributed throughout any form of natural - language text - at least in Western languages - but they remain very infrequent in the typical headline - style banners or ads .", "label": "", "metadata": {}, "score": "57.724094"}
{"text": "min .d . ik .d .lk . ) k .N . max .d . ik .d .lk . )[ . 1 . ] [ 0033 ] .The numerator of the right hand side of Equation [ 1 ] is the sum ( over all paths k in the dictionary of paths ) of the minimum of the two frequencies of occurrence of a path k in the two documents d i and d l .", "label": "", "metadata": {}, "score": "57.786995"}
{"text": "We calculated our clusters based on a 50 % resemblance .We found 3.6 million clusters containing a total of 12.3 million documents .Of these , 2.1 million clusters contained only identical documents ( 5.3 million documents ) .The remaining 1.5 million clusters contained 7 million documents ( a mixture of exact duplicates and similar ) .", "label": "", "metadata": {}, "score": "57.798233"}
{"text": "[ 0051 ] .[ 0052 ] .[ 0053 ] .it is noted that the URL comprises a number of components , only some of which are needed to identify the web page , with the others being related to co - branding , for example .", "label": "", "metadata": {}, "score": "57.85742"}
{"text": "The method of claim 25 wherein the first and second documents are first and second web pages , respectively .The method of claim 25 further comprising the step of returning , in response to the request , the second document to the requesting party .", "label": "", "metadata": {}, "score": "57.90119"}
{"text": "claim 14 , further comprising the step of storing as a path representation a set that defines positional information of sibling nodes under a parent node .The method as claimed in . claim 15 , further comprising the step of storing precise path representations that precisely define a document structure , and generalised path representations that partially generalise structural aspects of precise path representations of a document .", "label": "", "metadata": {}, "score": "57.913113"}
{"text": "To validate the results of this computation , a query was run to find which terms actually appear in document 2 that do not appear in document 1 .These are shown in Table 6 .TABLE 6 .Terms found in Document 2 but not in Document 1 .", "label": "", "metadata": {}, "score": "57.96418"}
{"text": "The number suffixes are used to indicate identical url names from different servers .Client .Conf .[0067 ] .Examining Table 5 , it is clear that even though documents 1 and 2 and documents 3 and 4 have similar names and identical sizes , they are not exactly the same , since the signatures differ .", "label": "", "metadata": {}, "score": "58.050148"}
{"text": "In addition , the references to objects or files need not be URLs .The references may be path names , links ( such as Microsoft \u00ae OLE links ) , network operating system resource identifiers or object identifiers .Still further , the present invention may be practiced in non - Internet and non - intranet environments and may be practiced by applications other than web browsers . H. Turtle et al . , \" Inference Networks for Document Retrieval \" , Proceedings of the Thirteenth International Conference on Research and Development in Information Retrieval ( \u00a9 1990 , Assoc .", "label": "", "metadata": {}, "score": "58.111984"}
{"text": "[ 0005 ] .A Web environment , such as the World Wide Web ( WWW ) on the Internet , is a network environment where Web servers and browsers are used .Having gathered and indexed all of the documents available in the collection , the index can then be used , as described above , to search for documents in the collection .", "label": "", "metadata": {}, "score": "58.14746"}
{"text": "For purposes of the discussion below , it is assumed that these resources are media content .A database , denoted as an \" index \" 38 , is also stored on the storage 32 .As will be described in more detail below , the index 38 contains information regarding what web pages are substantially identical to each other .", "label": "", "metadata": {}, "score": "58.174324"}
{"text": "At the end , the score is calculated as a ratio of matched shingles over available shingles ( in the question document ) , and the values compared to a threshhold .This threshold will be in the range 0 - 1 , with the lower end returning documents that matched on a few shingles , the upper end being ones that matched on most .", "label": "", "metadata": {}, "score": "58.43464"}
{"text": "claim 16 , wherein if the predetermined number is about 90 % of the terms or greater the first document is declared to be substantially identical to the second document .A system as in .claim 16 , wherein the set of documents is obtained in response to a search query made to a data communications network .", "label": "", "metadata": {}, "score": "58.4505"}
{"text": "The web browser then utilizes this URL to request that the substantially similar data object be returned ( step 136 in FIG .12 ) .Hence , if the media 40a could not be returned from server 26 as a result of a broken link in a Hypertext document , the web browser 36 could locate the URL to return the media 40b from server 28 that is substantially identical to the media 40a .", "label": "", "metadata": {}, "score": "58.517166"}
{"text": "[ 0021 ] .Web crawlers can download only a finite number of documents or web pages in a given amount of time .Therefore , it would be advantageous if a web crawler could identify URL equivalence patterns in multiple different URLs that reference substantially identical pages and download only one document , as opposed to downloading all the substantially identical documents addressed by the multiple different URLs .", "label": "", "metadata": {}, "score": "58.519333"}
{"text": "As was discussed above , the dictionary 48 may be used to access the word occurrence list ( see FIG .5 ) for a given term .The word occurrence list contains a list of which documents contain the term and the weight assigned to the term for those documents .", "label": "", "metadata": {}, "score": "58.54876"}
{"text": "0054 ] .In accordance with this procedure one first finds the significant terms in each document .Initially , all of the terms were ranked ( except the unknown word types ) in order of decreasing IQ , and then filtered to eliminate those terms which only appear once in the collection , that is , those that have a frequency of 1 . [ 0055 ] .", "label": "", "metadata": {}, "score": "58.64298"}
{"text": "The word weight is determined by calculating a product of the collection frequency component and the term frequency component for the respective documents and normalizing the product .The word weight for the term in the first document is compared with the word weight for the term in the second document and is utilized to determine whether the documents are substantially identical .", "label": "", "metadata": {}, "score": "58.77765"}
{"text": "The same sequence of node labels can occur in two or more distinct paths .For example , node 5 and 6 in .FIG .1 contributes the same sequence of node labels .A sequence of node labels is referred to as a path .", "label": "", "metadata": {}, "score": "58.78302"}
{"text": "4 is a block diagram that illustrates components of the index .FIG .5 is a diagram that depicts an example of a portion of the dictionary of FIG .4 .FIG .6 is a diagram that illustrates the format of a word occurrence list entry that is part of a word occurrence list .", "label": "", "metadata": {}, "score": "58.796665"}
{"text": "FIG .9 illustrates a flowchart of the steps that are performed to assign such weights .The steps of FIG .9 are performed for each term that appears within a web page document .A collection frequency component is calculated for each word within the web page document ( step 96 in FIG .", "label": "", "metadata": {}, "score": "58.80734"}
{"text": "[ 0020]FIG .5 illustrates a flowchart of a process for comparing documents for identity using a signature , and then for close similarity .DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS .[ 0021 ] .[ 0021]FIG .1 illustrates an exemplary networked search system 100 that may be used when searching , analyzing and displaying text documents in accordance with the teachings herein .", "label": "", "metadata": {}, "score": "58.844086"}
{"text": "claim 1 , further comprising analyzing the URLs to identify what portions of the URL are essential for identifying each web resource , and what portions are irrelevant .The method of . claim 2 , wherein the rule is a per - equivalence class rule , and further comprising generalizing the rule to a trans - equivalence class rule .", "label": "", "metadata": {}, "score": "59.27249"}
{"text": "Everyone is aware that URLs are not good forever .Pages get renamed , pages move , web sites get rearranged , servers get renamed , and users change internet service providers .Every good URL eventually becomes yet another dead link .", "label": "", "metadata": {}, "score": "59.28776"}
{"text": "[ 0026 ] .Once a rule is determined , it is applied to the class of web resources to identify errors .If there are no errors , the rule is activated and is then used by the web crawler for future crawling to avoid the download of duplicative web resources .", "label": "", "metadata": {}, "score": "59.29344"}
{"text": "Features having the most distinguishing characteristic ( as reflected in the weights ) are compared first so as to minimize the required number of comparisons of features and to quickly be able to determine whether data objects are substantially identical or not .", "label": "", "metadata": {}, "score": "59.38326"}
{"text": "On one fairly complex site I worked upon , due to a quirk of the content management system being used , a single page was indexed by Google over 15,000 times under different URLs .That 's not something you want happening with your site .", "label": "", "metadata": {}, "score": "59.40017"}
{"text": "The method as claimed in .The method as claimed in .The method as claimed in .The method as claimed in .claim 12 , wherein the function for computing the similarity between a pair of documents ( d i , d l ) .", "label": "", "metadata": {}, "score": "59.406136"}
{"text": "Microsoft Creating Rules for Canonical URLs .There may be more than one URL for a single page on a website , which can cause problems when a search engine attempts to crawl and index pages on that site .The \" canonical \" version of a URL would be a standard single version , when there may be more than one way to represent the URL ( or address ) of a page .", "label": "", "metadata": {}, "score": "59.551464"}
{"text": "FIG .4 is a block diagram showing an example computing environment in which aspects of the invention may be implemented .DETAILED DESCRIPTION OF ILLUSTRATIVE EMBODIMENTS .[ 0033 ] .The subject matter is described with specificity to meet statutory requirements .", "label": "", "metadata": {}, "score": "59.654297"}
{"text": "The method as claimed in .claim 14 , further comprising the step of storing as a path representation a sequence of terms separated by a delimiting symbol , in which each term is represented by a label and a parenthesised predicate that specifies the positional index of the term either specifically or generally .", "label": "", "metadata": {}, "score": "59.783165"}
{"text": "Documents , as well as document collections , are represented as vectors of feature values .These features are based on the words and phrases occurring in the document collection .Therefore , this representation of a document describes text ( or possibly semantic ) content of documents , and the similarity values describe a type of text or content similarity between the documents .", "label": "", "metadata": {}, "score": "59.85862"}
{"text": "After representing documents based on their structure in vector form , an existing method of measuring similarity between vectors is used to obtain the measure of structural similarity between two given documents .DESCRIPTION OF DRAWINGS .[ 0012 ] .FIG .", "label": "", "metadata": {}, "score": "59.90499"}
{"text": "j . )e . s .n . m .e . [ . 2 . ] [ 0060 ] .In Equation [ 2 ] above , e is the number of XPaths that are common to both d i , d j .", "label": "", "metadata": {}, "score": "59.98483"}
{"text": "As noted above , though the term XPath is used herein in a more precise and restricted sense .An XPath is considered herein as a path in a tree representation of a document that has the capability to include the positional information of the preceding siblings that have the same label as a given node in the tree .", "label": "", "metadata": {}, "score": "60.006653"}
{"text": "PDF files , and a Gemini(tm ) plug - in for the Adobe Acrobat(tm ) reader was used to export these files into HTML .[ 0053 ] .A single collection of these documents was then assembled and analyzed using Textract .", "label": "", "metadata": {}, "score": "60.044968"}
{"text": "[ heading-0062 ] .Overview of Procedure .[ 0063 ] .FIG .4 is a flowchart 400 that represents , in overview , steps in a simple example of comparing two documents .The flowchart 400 describes the procedure for obtaining the similarity between two documents d i and d l in a given document collection .", "label": "", "metadata": {}, "score": "60.055473"}
{"text": "[ 0071 ] .[ 0072 ] .The results included eight pairs of identical documents , as measured by size and the signature process described above .In addition , the results contained the 13 very similar documents shown in Table 7 . News10 .", "label": "", "metadata": {}, "score": "60.066006"}
{"text": "FIELD OF THE INVENTION .[ 0001 ] .The present invention relates to determining structural similarity in semi - structured documents .BACKGROUND .[0002 ] .Several methods exist that model documents as labeled trees .These methods are based on the fact that any semi - structured document that uses a markup language can be represented as a tree such as a Document Object Model ( DOM ) tree .", "label": "", "metadata": {}, "score": "60.09798"}
{"text": "These terms are tokenized by using conventional natural language processing techniques .The tokens are then added to the index 38 ( step 94 in FIG .8) .Specifically , the tokens are used to build the dictionary 48 and the occurrence streams 50 in accordance with conventional natural language processing techniques .", "label": "", "metadata": {}, "score": "60.100754"}
{"text": "The IQ was found to change somewhat based on the contents of the documents returned .A term that was highly salient in one document set might appear too frequently to be very selective in another set .However , much of this dependence could be eliminated by simply requiring that the IQ value be non - zero .", "label": "", "metadata": {}, "score": "60.331993"}
{"text": "The present invention is not limited to accessing objects in an object - oriented environment ; rather it may be applied more generally to a broader category of resources , such as files , printers and machines , that have associated information for accessing the resources .", "label": "", "metadata": {}, "score": "60.33205"}
{"text": "In our system , we implement the sketches as follows : .We canonicalize documents by removing HTML formatting and converting all words to lowercase .The shingle size w is 10 .We use a 40-bit fingerprint function , based on Rabin fingerprints [ 7 ] , enhanced to behave as a random permutation .", "label": "", "metadata": {}, "score": "60.3512"}
{"text": "Textract further categorizes the entities it discovers into one of the categories shown in Table 1 .The earlier categories have the least certainty and the later ones higher certainty .Probably a place .PERSON ?Probably a person .PLACE .", "label": "", "metadata": {}, "score": "60.3545"}
{"text": "Shingling is one process for relatively cheaply detecting these duplicates .Shingling .The shingle , or more precisely w - shingle , is a continuous w word long sequence , and the complete w - shingling of a document is every unique w length sequence in that document .", "label": "", "metadata": {}, "score": "60.435337"}
{"text": "11 ) .A suitable threshold value is 0.8 .If the document similarity score exceeds the threshold in step 114 , it is concluded that the candidate is identical and should be added to the identicals list ( step 116 in FIG .", "label": "", "metadata": {}, "score": "60.66143"}
{"text": "A party selects the hyperlink and in response , an attempt is made to access the selected web site .When the attempt to access the selected web site is not successful , another web site is identified that holds substantially identical media content as the selected web site .", "label": "", "metadata": {}, "score": "60.67999"}
{"text": "We choose the piece size m so that the computation can be done entirely in memory .Merging the results is a simple , but time consuming process due to the required I / O. Each merge pass is linear , but log(n / m ) passes are required , so the overall performance of the process is dominated by a O(n log(n / m ) ) term .", "label": "", "metadata": {}, "score": "60.756985"}
{"text": "From these high confidence terms , an additional level of scrutiny is performed to select the salient terms .[ 0025 ] .Once the salient terms are determined , the transcript analysis and indexing process 183 creates the relations index 135 from the salient terms and index 130 from the documents .", "label": "", "metadata": {}, "score": "60.846237"}
{"text": "It was expected that this last document would have a markedly different vocabulary from the other 13 .The supercomputer document was processed to cut out a 2533 byte segment comprising the main news story , without any of the surrounding HTML formatting , and this segment was pasted it into each of the other 13 financial documents .", "label": "", "metadata": {}, "score": "60.920166"}
{"text": "If the test succeeds for more than a certain threshold number of URLs and does not fail for any URL , the rule is marked as accepted and subsequently used to normalize URLs processed by the web crawler .The rule may be applied to subsequent web page crawling , to reduce the number of substantially identical pages that are downloaded .", "label": "", "metadata": {}, "score": "60.974968"}
{"text": "If the test succeeds for more than a certain threshold number of URLs and does not fail for any URL , the rule is marked as accepted and subsequently used to normalize URLs processed by the web crawler .The rule may be applied to subsequent web page crawling , to reduce the number of substantially identical pages that are downloaded .", "label": "", "metadata": {}, "score": "60.974968"}
{"text": "[ 0108 ] .One of ordinary skill in the art can appreciate that a computer 810 or other client devices can be deployed as part of a computer network .In this regard , the present invention pertains to any computer system having any number of memory or storage units , and any number of applications and processes occurring across any number of storage units or volumes .", "label": "", "metadata": {}, "score": "60.980022"}
{"text": "Similarly , we can discover when a document is \" roughly contained \" in another .Applying this mechanism to the entire collection of documents found by the AltaVista spider yields a grouping of the documents into clusters of closely related items .", "label": "", "metadata": {}, "score": "61.042175"}
{"text": "The system of .claim 11 , wherein determining the rule comprises determining for each equivalence class what portions of the URLs in that class are relevant for selecting the page and what portions are not , and generalizing the per - equivalence - class rules to cover a plurality of equivalence classes .", "label": "", "metadata": {}, "score": "61.06389"}
{"text": "A method as in .A method as in . claim 10 , and further comprising storing the computed document signatures in a database .A method as in . claim 10 , and further comprising storing the computed document signature in association with the list of terms for each document .", "label": "", "metadata": {}, "score": "61.201817"}
{"text": "Each weight specifies a measure of how greatly the feature distinguishes the data object within a collection of data objects .A first weight for a feature in the first data object is compared with a second weight for the same feature in the second data object to determine whether the first data object and the second data object are substantially identical .", "label": "", "metadata": {}, "score": "61.247547"}
{"text": "0008 ] .These are then converted to Afingerprints@ using a method originally described by M. O. Rabin , AFingerprinting by random polynomials \" , Center for Research in Computing Technology , Harvard University , Report TR-15 - 81 , 1981 .", "label": "", "metadata": {}, "score": "61.26408"}
{"text": "As a result , the normalized weight for this term is 0.66581 .For another document to have precisely a weight of 0.66581 for the term \" orphans , \" the other document would have to have exactly the same combination of word weights as the source document .", "label": "", "metadata": {}, "score": "61.340767"}
{"text": "Some important information is widely disseminated and quoted throughout the Web , with slight local changes .For instance there are many slightly reformatted , full or partial copies of an FTC ( Federal Trade Commission ) ruling regarding consumer credit .", "label": "", "metadata": {}, "score": "61.38869"}
{"text": "HTML e - mail option may disappear , but we know many of our readers only read e - mail , so we are offering it to determine demand .", "label": "", "metadata": {}, "score": "61.477238"}
{"text": "All nodes evaluated by X 2 are also evaluated by X 1 , and hence one concludes that the XPath X 1 subsumes the XPath X 2 .The function subsume given in Table 1 below does not evaluate the given XPaths on a tree , but uses another way to determine subsumption .", "label": "", "metadata": {}, "score": "61.53596"}
{"text": "In general , a normalization approach which expresses dependence on specific word values , such as those employing the sums of word weights , would work better than those approaches which are independent of specific word values , such as byte length .", "label": "", "metadata": {}, "score": "61.805363"}
{"text": "Further , suppose that the candidate includes the weight for the term \" care \" that matches the score for the term within the web page document being analyzed .The square of the weight of the term \" care \" is then added to the document similarity score in step 112 .", "label": "", "metadata": {}, "score": "61.82898"}
{"text": "Let m i be the number of leaf nodes present in tree d i .There are thus mi paths in tree d i .Thus , feature selection techniques are used to remove non - informative paths , to simplify the model .", "label": "", "metadata": {}, "score": "61.94439"}
{"text": "Typically , for a web page , the copy of the media content 20 is forwarded as a hypertext markup language ( HTML ) document .The HTML document may contain a number of hyperlinks that enable the user to gain access to other web sites .", "label": "", "metadata": {}, "score": "61.96641"}
{"text": "In these experiments the above - described Textract text mining program was run on the collection of documents ( approximately 50 ) that were returned from the query .Low - level DB2 table load files were then generated from the Textract output and the terms / document data was then loaded into DB2 .", "label": "", "metadata": {}, "score": "61.968697"}
{"text": "The document identifier for the identicals may be stored within the list 82 .Other property information 84 is also stored within the catalog entries 76 and 78 , including the uniform resource locator ( URL ) for the document .As discussed above relative to step 42 of FIG .", "label": "", "metadata": {}, "score": "61.9952"}
{"text": "[ 0032 ] .The similarity between a pair of documents ( d j , d l ) is defined as expressed in Equation [ 1 ] below . sim .d .i .d .l . ) k .", "label": "", "metadata": {}, "score": "62.09837"}
{"text": "What I personally like about SpotSigs is that all its parts - from the signature extraction , over to the partitioning and index pruning - seamlessly fit together like some seemingly random pieces of a puzzle that finally make a nice picture .", "label": "", "metadata": {}, "score": "62.102753"}
{"text": "The method of claim 1 further comprising the step of determining each of said weights .The method of claim 1 wherein the computer system is a distributed system having an network operating system and wherein each of the first data and second objects is a resource , in the distributed system , accessible via the network operating system .", "label": "", "metadata": {}, "score": "62.16562"}
{"text": "Tokenizers are available for audio files to digitize spoken language into phonemes that uniquely identify the content of the audio files .Such tokenized audio data may be utilized to uniquely identify an audio file and help repair a broken reference to an audio file by adopting an approach like that described in more detail below .", "label": "", "metadata": {}, "score": "62.19364"}
{"text": "A method as in .claim 1 , wherein the step of executing a software program assigns to each term a collection - level importance ranking or Information Quotient ( IQ ) , and wherein the IQ is considered during the step of comparing .", "label": "", "metadata": {}, "score": "62.279682"}
{"text": "An index contains data that is used by the search system to process queries and identify relevant objects .After the index is created , queries may be submitted to the search system .The query represents information needed by the user and is expressed using a query language and syntax defined by the search system .", "label": "", "metadata": {}, "score": "62.363422"}
{"text": "EXAMPLE 2 ( QUERY 2 ) .[0070 ] .In a second series of experiments , a more focused query AProgram ViaVoice in Java@ was issued , and 47 of the top 50 returned documents were able to be retrieved ( ViaVoice is a registered trademark of the International Business Machines Corporation ) .", "label": "", "metadata": {}, "score": "62.51182"}
{"text": "The method of claim 1 further comprising the step of returning , in response to the request , the second data object to the requesting party .The method of claim 1 further comprising the step of determining that the first and second data objects are not substantially identical when values of the first and second weights are not substantially similar to each other .", "label": "", "metadata": {}, "score": "62.64765"}
{"text": "The computer - readable medium of claim 42 wherein the hyperlink comprises information specifying a network location of the first web site and wherein the access attempt is not successful because the information is incorrect .The computer - readable medium of claim 42 wherein the access attempt is not successful because a predetermined time interval has elapsed since the request was initiated but before the first web site could be accessed .", "label": "", "metadata": {}, "score": "62.76351"}
{"text": "The computer - readable medium of claim 34 wherein the request comprises a uniform resource locator ( URL ) for the first web page .The computer - readable medium of claim 35 wherein the first web page can not be accessed because the URL in the request is not valid for the first web page .", "label": "", "metadata": {}, "score": "62.76381"}
{"text": "The number of compares may be further reduced by limiting the test to documents that are no more than 10 % larger than the compared document .[ 0060 ] .The results obtained indicated that six clusters of documents existed in the 36 documents that were analyzed in the first query .", "label": "", "metadata": {}, "score": "62.94474"}
{"text": "The term n is the number of XPaths in d i , and m is the number of XPaths in d j .To compute s , the function subsume described above with reference to Table 1 is used .[ 0061 ] .", "label": "", "metadata": {}, "score": "63.019493"}
{"text": "7 depicts an example of entries within the catalog of FIG .4 . FIG .8 is a flowchart illustrating the steps that are performed to build the index .FIG .9 is a flowchart illustrating the steps that are performed to calculate a word weight for a term .", "label": "", "metadata": {}, "score": "63.02156"}
{"text": "If , as a site owner or builder , you avoid the need for a search engine to determine which URL is canonical for a page , you get to control which version of URL is used for a page .Different URLs that actually reference the same web page or other web resource are detected and that information is used to only download one instance of a web page or web resource from a web site . 089988 , 11089988 , US 2006/0218143 A1 , US 2006/218143 A1 , US 20060218143 A1 , US 20060218143A1 , US 2006218143 A1 , US 2006218143A1 , US - A1 - 20060218143 , US - A1 - 2006218143 , US2006/0218143A1 , US2006/218143A1 , US20060218143 A1 , US20060218143A1 , US2006218143 A1 , US2006218143A1 .", "label": "", "metadata": {}, "score": "63.072166"}
{"text": "As a second example , if an equivalence class contains the six URLs : . [0085 ] .[ 0086 ] .[ 0087 ] .[ 0088 ] .[ 0089 ] .[ 0090 ] .[ 0091 ] .", "label": "", "metadata": {}, "score": "63.076694"}
{"text": "claim 29 , wherein said method further comprises the step of generating a path representation for a path of a document as a sequence of labels representative from a root node to a leaf node in the labeled tree representation of the document .", "label": "", "metadata": {}, "score": "63.14469"}
{"text": "0079 ] .In a final test , both experiments were simultaneously , and it was found that all of the similar documents were detected as before .In addition , and in an unexpected result , all of the documents with the Ibmtop text were found to be similar to the corresponding document with the inserted CRM text as well .", "label": "", "metadata": {}, "score": "63.151047"}
{"text": "3 is a flowchart that provides an overview of the sequential steps that are performed by the exemplary embodiment of the present invention .First , in step 42 , the exemplary embodiment of the present invention builds the index 38 .", "label": "", "metadata": {}, "score": "63.42299"}
{"text": "The Web server 170 executes a server program ( SP ) 173 .The server workstation 175 includes a database ( DB ) 115 that may contain or be associated with an index ( I ) 130 and a relations index ( RI ) 135 .", "label": "", "metadata": {}, "score": "63.5285"}
{"text": "The system would then generalize these rules , marking the value of articleID a variable ( say \u03b1 ) : .[ 0076 ] .[ 0077 ] .[ 0078 ] .[0079 ] .[ 0080 ] .It is contemplated that there are other heuristics for canonicalizing the URLs in an equivalence class .", "label": "", "metadata": {}, "score": "63.56196"}
{"text": "The most likely high weight terms can be determined on the fly by referencing the dictionary portion of the index .The collection frequency counts n ay be stored at the leaves of the dictionary .These collection frequency counts indicate relative weights of the words .", "label": "", "metadata": {}, "score": "63.644318"}
{"text": "[ 0018]FIG .3 is a flowchart illustrating how documents are compared for identity and close similarity ; . [ 0019 ] .[ 0019]FIG .4 is a flowchart that depicts a process for computing a document signature ; and .", "label": "", "metadata": {}, "score": "63.694035"}
{"text": "From this , the system returns a list of topically relevant objects , often referred to as a Ahit - list@ The user may then select relevant objects from the hit - list for viewing and processing .[ 0003 ] .", "label": "", "metadata": {}, "score": "63.77214"}
{"text": "This can be accomplished with a single SQL query of the sort : . [ 0056 ] .[ 0057 ] . not in ( select terms from doc2 where . . . ) .[0058 ] .The requirement of terms having a greater frequency than 1 was not used in this example , since this was found to make the comparisons of shorter documents less accurate .", "label": "", "metadata": {}, "score": "63.784298"}
{"text": "The computer - readable medium of claim 28 wherein the computer executable instructions further comprise instructions for performing the step of returning , in response to the request , the second data object to the requesting party .The computer - readable medium of claim 28 wherein the first and second data objects are substantially identical only if values of the first and second weights equal each other .", "label": "", "metadata": {}, "score": "64.322044"}
{"text": "claim 1 , further comprising the step of storing , as path representations , sets of sequenced labels representative of distinct paths in a labeled tree representation of a corresponding document .The method as claimed in .The method as claimed in . claim 5 , further comprising the step of eliminating selected paths from the path dictionary ( Dict paths ) .", "label": "", "metadata": {}, "score": "64.325066"}
{"text": "The size of V ( D ) grows as D grows , but allows the estimation of both resemblance and containment .To limit the size of V ( D ) we can proceed as follows : for documents that have size between ( say ) and , we store the set .", "label": "", "metadata": {}, "score": "64.348724"}
{"text": "The software program starts at step 500 with the list of the documents 205 that are returned from a search ordered by increasing document size .The method begins with two indexes I and j ( steps 509 , 513 ) and checks at step 501 to determine if the document signatures match .", "label": "", "metadata": {}, "score": "64.360275"}
{"text": "Each hash table desirably maintains a list of all URLs on that web server which have an identical megashingle .Once all the URLs in a bucket have been processed , the hash tables are examined , and for any megashingle that maps to more than one URL , the URLs are recorded .", "label": "", "metadata": {}, "score": "64.5314"}
{"text": "[ 0029]FIG .4 shows a flowchart of a method for computing a signature for each document .For each document in the list of documents 205 , the method obtains the major terms from the database 206 .For each term ( step 401 ) a standard function ( step 402 ) is used ( such as the getHashcode method known from Java ) to compute a hash code for the corresponding character string .", "label": "", "metadata": {}, "score": "64.60188"}
{"text": "These and other suitable packages are generally available via the Web .The Jtidy package not only corrects common HTML errors , but also \" XMLizes \" the document and provides the corresponding DOM tree for the document .[ 0025 ] .", "label": "", "metadata": {}, "score": "64.70439"}
{"text": "Using the collection frequency component and the document frequency component , the client computer system 24 calculates a weight for the term ( step 100 in FIG .9 ) .In general , the weight is calculated as the product of the collection frequency component with the document frequency component , divided by a normalization component .", "label": "", "metadata": {}, "score": "65.02587"}
{"text": "[ 0082 ] .Thus , according to an embodiment , the URLs in each equivalence class may be examined for shared prefixes and suffixes .For example , if an equivalence class contains the URLs : .[ 0083 ] .", "label": "", "metadata": {}, "score": "65.05388"}
{"text": "This may be performed by , for example , for each URL in the same equivalence class , viewing each slash as a field separator .The URLs are segmented into multisets of fields , the multisets are intersected , and the canonical URL is derived from this intersection .", "label": "", "metadata": {}, "score": "65.05538"}
{"text": "If the signatures do not match , the next step 502 of the method checks to determine if the documents are within X% of the same size .In this ( non - limiting ) embodiment , a value of 10 % is used for X. If the sizes are similar , a database SELECT query ( step 503 ) is issued against the database of terms per document 206 to obtain a list of the terms in document j that are not in document i. If the number of terms not in document j is less than Y% of the total number of terms in document I ( step 504 ) the document j is flagged as being very similar to I ( step 510 ) .", "label": "", "metadata": {}, "score": "65.16014"}
{"text": "The method of claim 4 wherein the first and second data objects are substantially identical only if values of the first and second weights equal each other .The method of claim 4 wherein the comparing step comprises the step of determining that the first and second data objects are not substantially identical when values of the first and second weights are not substantially similar to each other .", "label": "", "metadata": {}, "score": "65.3995"}
{"text": "The documents may be in different forms , such as HTML and PDF , and they may vary slightly in header information .[ 0051 ] .EXAMPLE 1 ( QUERY 1 ) .[ 0052 ] .In a first experiment a popular search engine site was accessed , with all enhancements turned off , and the query Afix broken Thinkpad@ was issued ( AThinkpad@ is a registered trademark of the International Business Machines Corporation ) .", "label": "", "metadata": {}, "score": "66.05524"}
{"text": "In this context , the keys are the terms contained within the web page documents .FIG .5 illustrates an example of a small portion of the dictionary 48 .Those skilled in the art will appreciate that the dictionary may be organized in a different fashion and that the portion of the dictionary 48 shown in FIG .", "label": "", "metadata": {}, "score": "66.06487"}
{"text": "This suggests that for future work , thinking about how to personalize the signature extraction step beyond just using stopword anchors would certainly be an intriguing direction .Links .Subscribe .We offer two methods to subscribe to the InfoBlog : RSS / Atom ( preferred ) and HTML e - mail .", "label": "", "metadata": {}, "score": "66.310974"}
{"text": "These trees only differ in the frequency of the path a / b / e .By contrast , the tree 210 has two paths that do not appear in tree 220 at all .The proposed similarity measure determines that two documents that differ only in the frequency of the paths to be more similar than two documents that differ in the occurrence of paths .", "label": "", "metadata": {}, "score": "66.54712"}
{"text": "[ heading-0037 ] .Bag of XPaths Model .[ 0038 ] .The bag of XPaths model is described , which captures some sibling information in addition to all the parent / child relationships captured in the bag of tree paths model described above .", "label": "", "metadata": {}, "score": "66.58858"}
{"text": "Navigation is the process of moving from one hypermedia object to another hypermedia object by traversing a hyperlink pointer between the objects .This operation is typically facilitated by a user interface that displays hypermedia objects , highlights the hyperlinks in those objects , and provides a simple mechanism for traversing a hyperlink and displaying the referent object .", "label": "", "metadata": {}, "score": "66.61145"}
{"text": "The method as claimed in .claim 1 , wherein the tree representation is a Document Model Object representation .The method as claimed in .claim 1 , further comprising the step of generating a path representation for a path of a document as a sequence of labels representative from a root node to a leaf node in the labeled tree representation of the document .", "label": "", "metadata": {}, "score": "66.669266"}
{"text": "The IQ is effectively a measure of the document selectivity of a particular term : a term that appears in only a few documents is highly selective and has a high IQ .On the other hand , a term that appears in many documents is far less selective and has a low IQ .", "label": "", "metadata": {}, "score": "66.69869"}
{"text": "The IQ measure is based on the number of occurrences of a term in a collection , the number of documents the term occurs in and the number documents the term occurs in more than once .Thus , the value of the IQ is collection dependent and a term ( such as Acomputer@ ) that is salient in a collection of documents about entertainment may have a very low IQ in a collection of documents about computer technology .", "label": "", "metadata": {}, "score": "66.751526"}
{"text": "0048 ] .However , more difficult cases occur when there are several versions of the same document on various servers , or the same document is found in several forms , such as HTML and PDF , or when one document is embedded in another .", "label": "", "metadata": {}, "score": "66.76231"}
{"text": "While a general purpose computer is described below , this is but one example .The present invention also may be operable on a thin client having network server interoperability and interaction .[ 0098 ] .Generally , program modules include routines , programs , objects , components , data structures and the like that perform particular tasks or implement particular abstract data types .", "label": "", "metadata": {}, "score": "66.883606"}
{"text": "It is helpful to return to the example discussed above where the web page document being analyzed contained the term \" orphans \" as did the candidate web page document .Suppose that the next most significantly weighted term in the web page document being analyzed is \" care .", "label": "", "metadata": {}, "score": "66.929276"}
{"text": "The collection frequency component indicates how frequently the term appears within the collection of documents being indexed .The collection frequency component may be calculated as the logarithm base 10 of ( the number of documents in the collection ) divided by ( the number of documents in which the term occurs ) .", "label": "", "metadata": {}, "score": "67.0746"}
{"text": "Suppose that the document 's similarity score as calculated in step 112 of FIG .11 is not above the threshold ( see step 114 in FIG .11 ) and that there are more terms within the document ( see step 118 in FIG .", "label": "", "metadata": {}, "score": "67.155624"}
{"text": "[ 0024 ] .FIG .1 depicts an XML document 110 and its corresponding DOM tree 120 .Given a semi - structured document , one can generate its DOM tree manually , or using any suitable parser programme that analyses XML or related documents .", "label": "", "metadata": {}, "score": "67.16311"}
{"text": "Similarly , the predicate can be referenced by term.predicate .An index of an equality term can be referenced by term.index .[ 0045 ] .An XPath not only captures the parent / child relationships between nodes but also incorporates some sibling information .", "label": "", "metadata": {}, "score": "67.301506"}
{"text": "By way of example , and not limitation , communication media includes wired media such as a wired network or direct - wired connection , and wireless media such as acoustic , radio frequency ( RF ) , infrared , and other wireless media .", "label": "", "metadata": {}, "score": "67.46534"}
{"text": "The method of claim 10 wherein the request comprises a uniform resource locator ( URL ) for the first web page .The method of claim 11 wherein the first web page can not be accessed because the URL in the request is not valid for the first web page .", "label": "", "metadata": {}, "score": "67.46832"}
{"text": "287 - 298 . H. Turtle et al ., Inference Networks for Document Retrieval , Proceedings of the Thirteenth International Conference on Research and Development in Information Retrieval ( 1990 , Assoc .for Computing Machinery ) , pp .287 298 .", "label": "", "metadata": {}, "score": "67.786224"}
{"text": "[ 0000 ] .Example Computing Environment .[0097 ] .FIG .4 and the following discussion are intended to provide a brief general description of a suitable computing environment in which an example embodiment of the invention may be implemented .", "label": "", "metadata": {}, "score": "68.05708"}
{"text": "[0081 ] .According to another embodiment , the equivalence class may be analyzed to determine the portion of the string that is common to all URLs , and that is labeled as the prefix .The suffix may then be analyzed to determine the portions that have no effect on the identity of the referenced web page .", "label": "", "metadata": {}, "score": "68.22177"}
{"text": "URNs are a generalized form of URLs ( Uniform Resource Locators ) .However , instead of naming a resource directly - as URLs do by giving a specific server , port and file name for the resource - URNs point to the resource indirectly through a name server .", "label": "", "metadata": {}, "score": "68.25948"}
{"text": "[0028]FIG .3 illustrates a method for comparing documents to discover if they are identical or very similar .The software program starts with a list of the documents 205 that are returned from a search ordered by increasing document size .", "label": "", "metadata": {}, "score": "68.32703"}
{"text": "[0017 ] .[ 0018 ] .[ 0019 ] .[ 0020 ] .These web pages are therefore downloaded duplicatively by a web crawler .This is a concern as superfluous downloads waste bandwidth and computational resources of both the web server ( operated by the web content provider ) and the web crawler ( operated by the search engine ) .", "label": "", "metadata": {}, "score": "68.36391"}
{"text": "In this example , the value of diff is 5 and the value for init is 1 .[ 0051 ] .A generalized XPath , which contains only equality and repetitive predicates , is called a repetitive XPath .As such a repetitive XPath contains at least one repetitive predicate as defined above .", "label": "", "metadata": {}, "score": "68.60148"}
{"text": "The word occurrence list 60 and 66 are part of the occurrence streams 50 shown in FIG .4 .The occurrence streams 50 hold information about the occurrence of terms within documents in a compressed form .Specifically , the word occurrence information is stored as a stream that does not include redundant information .", "label": "", "metadata": {}, "score": "68.967636"}
{"text": "For purposes of the discussion , it is assumed that the accessing code is a web browser .Nevertheless , those skilled in the art will appreciate that the accessing code 36 , more generally may be any code , such as an operating system or network operating system , that is used to gain access to a resource .", "label": "", "metadata": {}, "score": "69.0833"}
{"text": "0048 ] .If the number of repeating elements are different , then there are some XPaths that differ only in the positional index .An element gets its positional index based on how many preceding sibling nodes have the same label .", "label": "", "metadata": {}, "score": "69.11131"}
{"text": "[0099 ] .Neither should the computing environment 800 be interpreted as having any dependency or requirement relating to any one or combination of components illustrated in the exemplary operating environment 800 .[ 0100 ] .With reference to .", "label": "", "metadata": {}, "score": "69.216"}
{"text": "claim 23 , wherein said method further comprises the tree representation is a Document Model Object representation .The program storage device in .claim 23 , wherein said method further comprises the step of generating a path representation for a path of a document as a sequence of labels representative from a root node to a leaf node in the labeled tree representation of the document .", "label": "", "metadata": {}, "score": "69.29502"}
{"text": "claim 16 , wherein said processor is further operable , before comparing the lists of terms , to sort the documents into a document list in order of increasing size , and to then compare a given document with the next larger documents in the document list .", "label": "", "metadata": {}, "score": "69.302536"}
{"text": "FIG .2 is a block diagram that illustrates an example of a computing environment 22 that is suitable for practicing the exemplary embodiment of the present invention .The computing environment 22 includes a client computer system 24 that may communicate with servers 26 and 28 via a network connection .", "label": "", "metadata": {}, "score": "69.5958"}
{"text": "A document d can be defined by the set of all equality XPaths corresponding to the leaf nodes of the DOM tree for d. Note that each equality XPath occurs only once in a document .[ 0047 ] .A dictionary Dict XPath can be constructed in a fashion similar to the one described in the bag of paths model , based on the equality XPaths for all the leaf nodes of the DOM trees in the document collection .", "label": "", "metadata": {}, "score": "69.73031"}
{"text": "[ 0101 ] .Computer 810 typically includes a variety of computer readable media .Computer readable media can be any available media that can be accessed by computer 810 and includes both volatile and nonvolatile , removable and non - removable media .", "label": "", "metadata": {}, "score": "69.91908"}
{"text": "[0002 ] .The World Wide Web is a large , distributed , decentralized collection of documents .Documents ( often referred to as \" web resources \" or \" web pages \" ) can be downloaded from computers called \" web servers \" ; there are tens of millions of web servers serving billions of web pages .", "label": "", "metadata": {}, "score": "69.9313"}
{"text": "This signature code is then stored at step 405 back into the database 206 .[ 0030 ] . [0030]FIG .5 shows a method for comparing documents to discover if they are identical or very similar , using the document signatures that were stored at step 405 of FIG .", "label": "", "metadata": {}, "score": "70.16146"}
{"text": "3 ) .In order to gain a better appreciation of the role of the index 38 it is helpful to review the major components of the index 38 .As shown in FIG .4 , the index includes three primary components : a dictionary 48 , an occurrence stream 50 , and a catalog 52 .", "label": "", "metadata": {}, "score": "70.35138"}
{"text": "claim 23 , wherein said method further comprises the step of storing , as path representations , sets of sequenced labels representative of distinct paths in a labeled tree representation of a corresponding document .The program storage device in .claim 23 , wherein the tree representation of a document includes a positional index , which represents , for a node ( n ) , the number of previous sibling nodes with the same label as that of node ( n ) .", "label": "", "metadata": {}, "score": "70.404495"}
{"text": "There were about 600 M shingles so the raw sketch files took up 3 Gbytes ( 5 bytes per shingle ) .During the first phase of the clustering algorithm , this expanded to about 5.5 Gbytes ( 9 bytes per entry - 5 bytes for the shingle and 4 bytes for the document ID ) .", "label": "", "metadata": {}, "score": "70.53783"}
{"text": "Each such path contributes a sequence of labels to the model .[ 0028 ] .As an example , leaf node 3 of the DOM tree 120 given in .FIG .1 contributes the sequence a / b / c .", "label": "", "metadata": {}, "score": "70.54338"}
{"text": "return null . if ( term t 1 . index ) .continue .else . index mod diff . \" ] \" .[ 0055 ] .A document d i can be represented as a N bit binary vector where N is the number of terms in Dict XPaths .", "label": "", "metadata": {}, "score": "70.54353"}
{"text": "claim 29 , wherein said method further comprises the step of storing , as path representations , sets of sequenced labels representative of distinct paths in a labeled tree representation of a corresponding document .The computer system device in .claim 29 , wherein the tree representation of a document includes a positional index , which represents , for a node ( n ) , the number of previous sibling nodes with the same label as that of node ( n ) .", "label": "", "metadata": {}, "score": "70.7775"}
{"text": "1 depicts an XML document 110 and its corresponding DOM tree 120 .[ heading-0026 ] .Bag of Tree Paths Model .[ 0027 ] .In the bag of tree paths model , a document is represented by a set of sequences of labels that occur in the paths from the root node to the leaf nodes of the corresponding tree representation ( in this case , a DOM tree ) .", "label": "", "metadata": {}, "score": "70.78662"}
{"text": "claim 25 , wherein the documents are obtained in response to a search query made to a data communications network , and where the processor executes the comparing and declaring functions in substantially real time as the documents are returned by the query .", "label": "", "metadata": {}, "score": "71.15552"}
{"text": "Specifically , the user positions a mouse cursor over the link ( which is highlighted or displayed in a color that indicates that it is a link ) and clicks the mouse to retrieve media content accessible through the link .Upon the user selection of the link , a web browser program accesses the address path of the media content that is encoded in the link , retrieves the media content and renders the media content to the user .", "label": "", "metadata": {}, "score": "71.18286"}
{"text": "These programs are funded by government agencies and by religious and charitable organizations .See also Adoption .Suppose this document is part of a collection of 25,000 documents and suppose that the term \" orphans \" occurs in only 44 of the 25,000 documents .", "label": "", "metadata": {}, "score": "71.2092"}
{"text": "return false .else . index ) .[0054 ] .Table 2 below presents pseudocode that defines a function called generalize(X 1 , X 2 ) .This code either returns a generalized(repetitive ) XPath that subsumes both XPaths X 1 and X 2 , or returns \" null \" .", "label": "", "metadata": {}, "score": "71.50325"}
{"text": "In a networked environment , program modules depicted relative to the computer 810 , or portions thereof , may be stored in the remote memory storage device .By way of example , and not limitation , .FIG .4 illustrates remote application programs 885 as residing on memory device 881 .", "label": "", "metadata": {}, "score": "71.623024"}
{"text": "Similarly , the leaf node 64 points to a word occurrence list 66 for the term \" DOG .\" As will be described in more detail below , each word occurrence list identifies which document the associated term appears in and where the term appears within the document .", "label": "", "metadata": {}, "score": "71.80461"}
{"text": "The web pages are provided to a processor 320 and a storage device 330 , for analysis and storage .The web pages may be analyzed by the processor 320 as set forth above with respect to .FIGS . 1 and 2 , for example .", "label": "", "metadata": {}, "score": "72.03234"}
{"text": "A predicate filters the node - set specified by the nodetest further into a smaller node - set and is always placed inside a pair of square brackets .[ 0043 ] .Other predicates are termed generalized predicates .An XPath is called an equality XPath if all the terms in the XPath contain only equality predicates .", "label": "", "metadata": {}, "score": "72.16176"}
{"text": "The denominator of Equation [ 1 ] is the sum of the maximum of the frequencies of occurrence over all paths k , and serves as a normalizations factor .[ 0034 ] .The frequencies f j ( p i ) can be ignored , and the occurrence or non - occurrence of the path used .", "label": "", "metadata": {}, "score": "72.502975"}
{"text": "For example , in .FIG .3 , the XPath for node 3 is /a[1]/b[1]/c[1].For node 6 , the XPath is /a[1]/b[1]/d[1]/e[2].[0044 ] .Both of these XPaths are equality XPaths .Note that the last term of the XPath contains a generalized predicate .", "label": "", "metadata": {}, "score": "72.58876"}
{"text": "claim 32 , wherein the document signature is computed by computing a hash code for each term of the list of terms , and summing together all of the hash codes to form the document signature .Description .TECHNICAL FIELD .", "label": "", "metadata": {}, "score": "72.749626"}
{"text": "All Jewish institutions and most Protestant institutions , for example , provide for the education of their charges in public schools in which they can meet and associate with other children .In addition , increasing emphasis is given to securing qualified supervisory personnel with medical , psychiatric , dietary , and social work training .", "label": "", "metadata": {}, "score": "72.82724"}
{"text": "[ 0071 ] .FIG .5 is a schematic representation of a computer system 500 that can be used to implement the techniques described herein .Computer software executes under a suitable operating system installed on the computer system 500 to assist in performing the described techniques .", "label": "", "metadata": {}, "score": "72.95498"}
{"text": "The ordinal values indicate a location of the term within the document .For example , an ordinal value of 56 indicates that the term appears as the fifty - sixth word within the document .Returning to FIG .4 , the catalog 52 serves as a property cache for holding property information regarding web page documents .", "label": "", "metadata": {}, "score": "73.11215"}
{"text": "Both of these embodiments utilize the search engine 120 to search these indices .A user can employ the search and display process 193 and may enter query search terms .In one embodiment , the system 100 also uses the Web server computer 170 that provides a means for viewing the documents 140 , links between them , query search terms , and results .", "label": "", "metadata": {}, "score": "73.46849"}
{"text": "[0085 ] .It should be noted that when performing the database comparisons the SQL query could be speeded up if the terms are compared by an integer key rather than using a string comparison .[ 0086 ] .[ 0087 ] .", "label": "", "metadata": {}, "score": "73.6566"}
{"text": "[ 0077 ] .In this experiment the financial document , called CRM in Table 8 , was selected , and 3276 bytes of it , comprising nearly all of the non - markup text , was inserted into all of the other documents in the set .", "label": "", "metadata": {}, "score": "73.670456"}
{"text": "FIG .3 shows an example of a labeled tree 310 .Each node in the tree contains a label as well as a positional index .The term index is used as an abbreviation for positional index .An XPath is defined in some contexts to be a path expression that locates nodes in a DOM tree .", "label": "", "metadata": {}, "score": "73.67777"}
{"text": "Fund3 .Fund5 .[0062 ] .One can readily see that these documents must be closely related versions of the same information .In fact , they are all different versions of the same IBM manual describing a Websphere(tm ) server product .", "label": "", "metadata": {}, "score": "73.90065"}
{"text": "These usually have RT prepended , but may also have some other edits ( to fit into the limit , or to add some commentary for example ) .I grabbed 45 tweets from the search \" phpnw09 \" , the hashtag for the PHP Northwest conference , to check for matches .", "label": "", "metadata": {}, "score": "73.99478"}
{"text": "claim 1 , and further comprising storing the lists of terms in a database .A method as in .claim 1 , and further comprising computing a signature for each document , and storing the computed document signature .A method as in .", "label": "", "metadata": {}, "score": "74.00372"}
{"text": "Further , it should be appreciated that the dictionary need not include the terms depicted within FIG .5 .As shown in FIG .5 , the dictionary contains a number of nodes 54 , 56 , 58 , 62 and 64 .", "label": "", "metadata": {}, "score": "74.0205"}
{"text": "0105 ] .A monitor 891 or other type of display device is also connected to the system bus 821 via an interface , such as a video interface 890 .In addition to monitor 891 , computers may also include other peripheral output devices such as speakers 897 and printer 896 , which may be connected through an output peripheral interface 895 .", "label": "", "metadata": {}, "score": "74.166275"}
{"text": "[ 0013 ] .FIG .2 is a schematic representation of three respective Document Object Model ( DOM ) trees that are represented for purpose of comparison .[ 0014 ] .FIG .3 is a schematic representation of an example DOM tree labeled with positional indices , and is represented for the purpose of discussion .", "label": "", "metadata": {}, "score": "74.2494"}
{"text": "The query is sent over a network , such as the network 105 , to the search engine 202 that looks up the query word(s ) in the search index 204 and returns a list of documents 205 .Copies of the actual documents 208 are then obtained from the document collection 203 .", "label": "", "metadata": {}, "score": "74.43559"}
{"text": "Other configurations or types of computer systems can be equally well used to implement the described techniques .The computer system 500 described above is described only as an example of a particular type of system suitable for implementing the described techniques .", "label": "", "metadata": {}, "score": "74.49002"}
{"text": "A system as in .claim 25 , and further comprising a memory containing a database for storing the computed document signatures .A system as in .claim 29 , and further comprising storing the computed document signature in association with the list of terms for each document .", "label": "", "metadata": {}, "score": "75.2063"}
{"text": "Client workstation 190 and stand - alone workstation 195 each include search and display processes ( SDP ) 193 .[ 0022 ] .The network 105 may be a local area network ( LAN ) , a wide area network ( WAN ) , the Internet , or a combination of the foregoing .", "label": "", "metadata": {}, "score": "75.625626"}
{"text": "FIG .1B shows the case where an operating system ( OS ) or network operating system ( NOS ) 11 at a client 12 seeks access to a resource 13 stored on a server 16 .The server 16 may be connected to the client 12 via a local area network ( LAN ) or wide area network ( WAN ) .", "label": "", "metadata": {}, "score": "75.62978"}
{"text": "The magnitude of the input data imposed severe restrictions on the design of our data structures and algorithms .Just one bit per document in a data structure requires 4 Mbytes .A sketch size of 800 bytes per document requires 24 Gbytes .", "label": "", "metadata": {}, "score": "75.66003"}
{"text": "The computer 810 may also include other removable / non - removable , volatile / nonvolatile computer storage media .By way of example only , .[ 0104 ] .The drives and their associated computer storage media discussed above and illustrated in .", "label": "", "metadata": {}, "score": "75.988945"}
{"text": "The example of FIG .1 shows two separate tools that are most germane to an understanding of these teachings .These tools are the transcript analysis and indexing process 183 and the search and display process 193 .[ 0024 ] .", "label": "", "metadata": {}, "score": "76.138336"}
{"text": "The I / O devices 34 may include but are not limited to a keyboard , a mouse , a video display , a modem , and audio loudspeakers .The storage 32 may include both primary storage and secondary storage .", "label": "", "metadata": {}, "score": "76.841385"}
{"text": "As the negative effects of institutional regimentation on children 's personalities became better understood , however , the emphasis shifted to care in foster homes and to adoption opportunities .In most countries , including Great Britain and the United States , orphans are recognized as wards of the state , and governmental provision is made for their care .", "label": "", "metadata": {}, "score": "77.2563"}
{"text": "FIG .2 schematically represents three DOM trees 210 , 220 , 230 .A meaningful similarity measure should yield a higher value of similarity for the pair of trees 210 and 230 than for the pair of trees 210 and 220 .", "label": "", "metadata": {}, "score": "77.431244"}
{"text": "claim 1 , wherein determining the rule comprises determining for each equivalence class what portions of the URLs in that class are relevant for selecting the page and what portions are not , and generalizing the per - equivalence - class rules to cover a plurality of equivalence classes .", "label": "", "metadata": {}, "score": "77.50847"}
{"text": "Computer storage media includes both volatile and nonvolatile , removable and non - removable media implemented in any method or technology for storage of information such as computer readable instructions , data structures , program modules or other data .Communication media typically embodies computer readable instructions , data structures , program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media .", "label": "", "metadata": {}, "score": "77.563065"}
{"text": "In one embodiment , the system 100 has a workstation 185 containing a collection of documents 140 and corresponding indexes 130 , 135 .In another embodiment the system 100 has the workstation 175 which contains only the indexes 130 and 135 to the documents 140 .", "label": "", "metadata": {}, "score": "77.84354"}
{"text": "An XPath , however , does not capture sibling information of nodes whose node labels are different from that of the given node .For example , the XPath for node 6 in .FIG .3 is /a[1]/b[1]/d[1]/e[2].The positional index 2 for the node label e shows that this node has another sibling node with the label e. There is no reference hence to the sibling node f. .", "label": "", "metadata": {}, "score": "78.68925"}
{"text": "[ 0041 ] .The term XPath is defined herein as a sequence of terms separated by the character ' / ' .In the existing technical literature , however , the term XPath is used more generically to denote path expressions that locate nodes in a DOM tree .", "label": "", "metadata": {}, "score": "78.83914"}
{"text": "In this embodiment a value of 10 % is used for X , while in other embodiments other values may be used .If the number of terms not in document I is less than Y% of the total number of terms in document I(step 305 ) the method flags this document j as being very similar to I(step 311 ) .", "label": "", "metadata": {}, "score": "79.04416"}
{"text": "By way of example , and not limitation , .FIG .4 illustrates operating system 834 , application programs 835 , other program modules 836 , and program data 837 .RAM 832 may contain other data and/or program modules .", "label": "", "metadata": {}, "score": "79.60355"}
{"text": "4 , an example system for implementing the invention includes a general purpose computing device in the form of a computer 810 .Components of computer 810 may include , but are not limited to , a processing unit 820 , a system memory 830 , and a system bus 821 that couples various system components including the system memory to the processing unit 820 .", "label": "", "metadata": {}, "score": "79.64247"}
{"text": "We can run this a couple of times , just to check we get what we expect .The first test is a message that was retweeted a few times in the data : \" phpnw09 : 1 Week ' til # phpnw09 - let me hear you say w00 t !", "label": "", "metadata": {}, "score": "79.673355"}
{"text": "Document Object Model .[ 0023 ] .A document is modelled as a labeled tree in the Document Object Model ( DOM ) .In the labeled tree model of a document , each node in the tree corresponds to an element of the markup language in the document .", "label": "", "metadata": {}, "score": "79.68354"}
{"text": "claim 16 , said processor being further operable for computing a signature for each document , and further comprising a memory for storing the computed document signature in association with the list of terms for each document .A system as in .", "label": "", "metadata": {}, "score": "79.89511"}
{"text": "A tree path to XPath index is created so that for any given tree path , one can quickly obtain the set of equality XPaths that have the same tree path .[ 0057 ] .Let X denote one such set of equality XPaths , and let T be the number of terms in any XPath \u03b5 X. All the XPaths will have same number of terms . index .", "label": "", "metadata": {}, "score": "81.12638"}
{"text": "Table 1 below presents pseudocode that defines a Boolean function called subsume(X 1 , X 2 ) , in which X 1 and X 2 are XPaths ( either equality or repetitive ) .The function returns \" true \" if the set of nodes evaluated by the XPath X 2 is a subset of the nodes evaluated by X 1 for the same tree .", "label": "", "metadata": {}, "score": "81.14289"}
{"text": "7 depicts the format of a portion of the catalog 52 .Specifically , FIG .7 depicts catalog entries 76 and 78 that are associated with two distinct documents .Each of the catalog entries 76 includes a DOCID 80 , which serves as an indexing key into the catalog .", "label": "", "metadata": {}, "score": "81.51843"}
{"text": "claim 1 , wherein the step of comparing includes a preliminary step of sorting the documents into a document list in order of increasing size , and where the step of comparing compares a given document with the next larger documents in the document list .", "label": "", "metadata": {}, "score": "81.697266"}
{"text": "claim 16 , and further comprising a memory containing a database for storing the lists of terms .A system as in .claim 16 , said processor being further operable for computing a signature for each document , and further comprising a memory for storing the computed document signature .", "label": "", "metadata": {}, "score": "81.9041"}
{"text": "The abuses of the workhouse system led in the 18th century to the establishment by the government of separate residential schools , called barrack schools , for the housing and instruction of orphans , and to a growing number of orphan asylums founded by private groups .", "label": "", "metadata": {}, "score": "82.42476"}
{"text": "The port component identifies the networking \" port \" ( an Internet abstraction used to multiplex different logical communication channels over the same physical networking device ) used by the web server running the specified host ; if the port is omitted , it defaults to 80 .", "label": "", "metadata": {}, "score": "82.80053"}
{"text": "The function evaluate(p , i ) returns \" true \" if the index i satisfies the predicate p. Here , term j i represents the j th term in the XPath X i .The algorithm compares the given XPaths term by term and returns true if predicates for all the terms either match exactly or the index of second XPath is satisfied by the predicate of first XPath . continue .", "label": "", "metadata": {}, "score": "83.0261"}
{"text": "[ 0056 ] .A set of generalized XPaths is generated , based on pairs of equality XPaths in D ei using the algorithm defined in Table 2 .Let D gi denote the set of all generalized XPaths that are obtained using generalize(X 1 , X 2 ) .", "label": "", "metadata": {}, "score": "83.52493"}
{"text": "Ibmtop .[ 0078 ] .Again , all of the documents with the inserted text were detected as similar to the originals and no false positives were detected .The fraction of terms that were different was 0.125 or under , except for the case where the larger CRM document was added to the smaller Ibmtop document .", "label": "", "metadata": {}, "score": "83.71199"}
{"text": "0075 ] .Each of the components of the computer 520 is connected to an internal bus 530 that includes data , address , and control buses , to allow components of the computer 520 to communicate with each other via the bus 530 .", "label": "", "metadata": {}, "score": "84.02664"}
{"text": "FIG .6 depicts an entry 68 for a single document .The entry 68 includes a document identifier ( DOCID ) 70 and a weight 72 for the term .The weight calculation for a term will be described in more detail below .", "label": "", "metadata": {}, "score": "84.26043"}
{"text": "d .i .d .l . ) sim .d .i .d .l . ) k .N .min .d . ik .d .lk . ) k .N . max .d . ik .", "label": "", "metadata": {}, "score": "85.316864"}
{"text": "The computer system 500 can be connected to one or more other similar computers via a input / output ( I / O ) interface 565 using a communication channel 585 to a network , represented as the Internet 580 .[ 0077 ] .", "label": "", "metadata": {}, "score": "85.418106"}
{"text": "Each node is associated with a letter .The path formed by nodes 54 , 56 and 58 is associated with the word \" DAD , \" whereas the path from nodes 54 , 62 and 64 is associated with the term \" DOG .", "label": "", "metadata": {}, "score": "85.61702"}
{"text": "Operating system 844 , application programs 845 , other program modules 846 , and program data 847 are given different numbers here to illustrate that , at a minimum , they are different copies .A user may enter commands and information into the computer 810 through input devices such as a keyboard 862 and pointing device 861 , commonly referred to as a mouse , trackball or touch pad .", "label": "", "metadata": {}, "score": "85.836174"}
{"text": "[ 0102 ] .The system memory 830 includes computer storage media in the form of volatile and/or nonvolatile memory such as ROM 831 and RAM 832 .A basic input / output system 833 ( BIOS ) , containing the basic routines that help to transfer information between elements within computer 810 , such as during start - up , is typically stored in ROM 831 .", "label": "", "metadata": {}, "score": "85.95756"}
{"text": "The term nodetest is a label that defines a set of nodes ( which are referred to as a node - set ) , in which each node in the set is a child node of the current node that has nodetest as its label .", "label": "", "metadata": {}, "score": "86.43646"}
{"text": "4 : juokaz : RT @phpnw09 : 1 Week ' til # phpnw09 - let me hear you say w00 t ! :) 5 : DragonBe : RT @phpnw : RT @phpnw09 : 1 Week ' til # phpnw09 - let me hear you say w00 t !", "label": "", "metadata": {}, "score": "86.66742"}
{"text": "The responsibility of the community for the care of orphans was recognized by the early Christians , and collections to raise funds were taken among the members of congregations .Later church charity provided for the establishment of orphan asylums as well as for the care of orphans in monasteries .", "label": "", "metadata": {}, "score": "87.127945"}
{"text": "4 provide storage of computer readable instructions , data structures , program modules and other data for the computer 810 .In .FIG .4 , for example , hard disk drive 841 is illustrated as storing operating system 844 , application programs 845 , other program modules 846 , and program data 847 .", "label": "", "metadata": {}, "score": "87.578705"}
{"text": "The computer 810 may operate in a networked environment using logical connections to one or more remote computers , such as a remote computer 880 .FIG .4 .The logical connections depicted in .FIG .4 include a local area network ( LAN ) 871 and a wide area network ( WAN ) 873 , but may also include other networks .", "label": "", "metadata": {}, "score": "88.94365"}
{"text": "Some computers may be occasionally connected to the network 105 and operate as stand - alone computers .For example , stand - alone workstation 195 connects to network 105 through an intermittent connection 196 that is , for example , a Digital Subscriber Line ( DSL ) or a dial - up modem .", "label": "", "metadata": {}, "score": "89.2148"}
{"text": "Orphanages in the U.S. are also maintained by religious organizations , by social or fraternal organizations , and by private endowment .In recent times orphanages have been organized on the so - called cottage system , in which children live together in small groups under the care of a house mother .", "label": "", "metadata": {}, "score": "89.534515"}
{"text": "[ 0107 ] .When used in a LAN networking environment , the computer 810 is connected to the LAN 871 through a network interface or adapter 870 .When used in a WAN networking environment , the computer 810 typically includes a modem 872 or other means for establishing communications over the WAN 873 , such as the Internet .", "label": "", "metadata": {}, "score": "90.39935"}
{"text": "Typically , this request 14 is a GET request that complies with the hypertext transfer protocol ( HTTP ) .The server computer 16 receives the request 14 , accesses the media content 18 stored therein and returns a copy of the media content 20 to the client computer system 12 .", "label": "", "metadata": {}, "score": "92.131424"}
{"text": "For illustrative purposes in the discussion below , it is assumed that the connection is an Internet connection and that servers 26 and 28 reside on the Internet .The client computer 24 includes a central processing unit ( CPU ) 30 , such as a microprocessor .", "label": "", "metadata": {}, "score": "92.292366"}
{"text": "A user is enabled to use the search and display process 193 to search , by entering query terms , for relevant documents 188 , and the user can select an appropriate document for display .[ 0027 ] .[ 0027]FIG .", "label": "", "metadata": {}, "score": "96.54214"}
{"text": "[ 0005 ] .[ 0006 ] .[0007 ] .[0008 ] .[ 0009 ] .[0010 ] .[ 0011 ] .[ 0012 ] .[ 0013 ] .[ 0014 ] .[ 0015 ] .", "label": "", "metadata": {}, "score": "100.21823"}
{"text": "w00 t !:-D 8 : ruby gem : RT @phpcodemonkey : RT @phpnw09 : 1 Week ' til # phpnw09 - let me hear you say w00 t ! 9 : oatie : RT @phpcodemonkey : RT @phpnw09 : 1 Week ' til # phpnw09 - let me hear you say w00 t ! 10 : DASPRiD : RT @DragonBe RT @phpnw : RT @phpnw09 : 1 Week ' til # phpnw09 - let me hear you say w00 t !", "label": "", "metadata": {}, "score": "100.46417"}
{"text": "0073 ] .The processor 540 is a central processing unit ( CPU ) that executes the operating system and the computer software executing under the operating system .The memory 550 includes random access memory ( RAM ) and read - only memory ( ROM ) , and is used under direction of the processor 540 .", "label": "", "metadata": {}, "score": "105.013596"}
{"text": "The video interface 545 is connected to video display 590 and provides video signals for display on the video display 590 .User input to operate the computer 520 is provided from the keyboard 510 and mouse 515 .The storage device 555 can include a disk drive or any other suitable storage medium .", "label": "", "metadata": {}, "score": "106.09894"}
{"text": "[ 0039 ] .[ 0040 ] .[ 0041 ] .[ 0042 ] .[ 0043 ] .[0044 ] .[ 0045 ] .[ 0046 ] .[ 0047 ] .[0048 ] .[ 0049 ] .", "label": "", "metadata": {}, "score": "117.31026"}
{"text": "[ 0072 ] .The components of the computer system 500 include a computer 520 , a keyboard 510 and mouse 515 , and a video display 590 .The computer 520 includes a processor 540 , a memory 550 , input / output ( I / O ) interfaces 560 , 565 , a video interface 545 , and a storage device 555 .", "label": "", "metadata": {}, "score": "117.41229"}
{"text": "Alternatively , the computer software can be accessed directly from the Internet 580 by the computer 520 .In either case , a user can interact with the computer system 500 using the keyboard 510 and mouse 515 to operate the programmed computer software executing on the computer 520 .", "label": "", "metadata": {}, "score": "117.66354"}
