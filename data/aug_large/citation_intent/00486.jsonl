{"text": "Application of the appropriate transformational rules should enable conversion from one language to another .The method used an automatic dictionary lookup and application of grammar rules to rearrange the word equivalents obtained from the dictionary .There was some awareness that ambiguities and idioms might present problems , requiring the involvement of some manual editing .", "label": "", "metadata": {}, "score": "37.351208"}
{"text": "By performing the lexical , morphological and syntactic analyses of a sentence , a syntactic structure as a tree of generalized constituents can be established .The syntactic structure of a sentence is transformed into a semantic structure by semantic interpretation of language - specific elements of the syntactic structure of the sentence and a tree of surface constituents are transformed into a tree of deep constituents and a language - independent semantic structure is formed .", "label": "", "metadata": {}, "score": "37.835056"}
{"text": "In these languages , word endings are used in order to show agreement between words in number , gender , case , verb tense , etc . .Sometimes , ensuring \" syntactically coherent output \" requires full syntactic parsing of both the source and database sentences in order to substitute the corresponding nodes and even sub - trees in the output sentence with the appropriate items which have the required morphological characteristics .", "label": "", "metadata": {}, "score": "37.892967"}
{"text": "Once a complete set of pairs of \" lexical meaning - grammatical value \" for the source sentence 512 are made , merging of the grammatical values 1008 are performed .[ 0134 ] Once the lexical - morphological structure is constructed and generalized grammatical values , if generalization / merging is possible , are provided for each word form , a syntactic analysis is performed .", "label": "", "metadata": {}, "score": "38.598583"}
{"text": "Additionally , a syntactic tree may be created for the substitute fragment .The system contains a large number of linguistic descriptions for both the source and the output language and can use any of the syntactic and morphological descriptions available to it .", "label": "", "metadata": {}, "score": "38.78563"}
{"text": "The parser uses the rules of grammar and word meanings ( in a lexicon ) .This mapping could be sequential or simultaneous .A contextual interpretation maps the logical form to its final knowledge representation .As already alluded to , there are different ways ( separate or simultaneous ) to accomplish the syntactic and semantic analysis , in short , the parsing , but there will be common elements in any such parsing .", "label": "", "metadata": {}, "score": "38.903957"}
{"text": "This induc - tion set - up is attractive because such annotations provide use - ful clues about the underlying syntactic structure , and they are readily available in many domains ( e.g. , info - boxes ... \" .We present a method for dependency grammar induction that utilizes sparse annotations of semantic relations .", "label": "", "metadata": {}, "score": "39.062805"}
{"text": "From the syntactic structure of a sentence the NLP system will attempt to produce the logical form of the sentence .Logical form is context - free in that it does not require that the sentence be interpreted within its overall context in the discourse or conversation in which it occurs .", "label": "", "metadata": {}, "score": "39.435215"}
{"text": "He also suggests that the content of complex expressions is not compositionally determined , although it is determined by its structure and the occasion meanings of its constituents .Higginbotham ( 1985 , 2007 ) argues that questions of grammaticality must be kept separate from questions of meaningfulness .", "label": "", "metadata": {}, "score": "39.869633"}
{"text": "During the lexical analysis stage , all these lexical meanings are generalized , but the whole list of these lexical meanings is stored / saved in order to use their surface and deep models for further analysis .[0133 ] Since every lexical meaning in any given language goes back to the parent semantic class and inherits some its characteristics , a corresponding lexical description 503 with its surface model 810 and deep model 912 can be found in the lexical - semantic dictionary 1004 .", "label": "", "metadata": {}, "score": "39.887535"}
{"text": "The syntactic structure represents a full syntactic analysis of the sentence , indicates its surface and deep slots , and lexical meanings which have been unambiguously selected by this stage .Presence of non - tree links in the sentence determines , in the general case , generation of several different final structures according to different variants of establishing non - tree links .", "label": "", "metadata": {}, "score": "39.930954"}
{"text": "On the syntactic structure of a sentence movements are restored and the linear order is determined , the morphological synthesis of the cores of constituents is performed to obtain the natural language sentence .Also , the computer system can implement all the methods , steps , actions automatically .", "label": "", "metadata": {}, "score": "40.144943"}
{"text": "The DCG allows the inclusion of additional arguments to handle this information ; the parser can then tell whether the noun - phrase and verb - phrase are each singular or plural , for example , so that the parser can make sure they agree .", "label": "", "metadata": {}, "score": "40.201572"}
{"text": "In an NLP , a structural requirement on a segment is that sentences within the segment will share such properties as : .A technique based on recency ( such as a history list ) to be used for referential analysis and handling ellipsis .", "label": "", "metadata": {}, "score": "40.378433"}
{"text": "[0067 ] FIG .2 illustrates in detail an embodiment of the step 110 of translating the document fragments by means of a translation database , a terminology dictionary , and a translation dictionary , in accordance with one embodiment .", "label": "", "metadata": {}, "score": "40.78936"}
{"text": "One or more possible constituents for a lexical meaning of a word form of a source sentence may be represented by surface syntactic models , e.g. , the surface models 810 .Each constituent is viewed as the realization of the constituent model by means of selecting a corresponding syntform 812 .", "label": "", "metadata": {}, "score": "40.79626"}
{"text": "[ 0149 ] A generalized constituent 1222 describes all the constituents with all the possible boundaries in a given source sentence which have a word form as the core constituent and various lexical meanings of this word form .Since the constituents are generalized , a single constituent for each lexical meaning corresponding to each entity of a sentence , including homonyms , is built , and their syntactic forms may be analyzed simultaneously .", "label": "", "metadata": {}, "score": "40.908356"}
{"text": "\" Syntactic representations of language use context - free grammars , which show what phrases are parts of other phrases in what might be considered a context - free form .Then the result of the semantic analysis will yield the logical form of the sentence .", "label": "", "metadata": {}, "score": "40.974365"}
{"text": "The syntactic structures generated for a source sentence and/or an output sentence are limited only by the syntax of an input language or output language without any other artificial restrictions .[ 0055 ] FIG .1 illustrates a flow chart of the method 100 for translating a source document 102 in a source language into an output document 104 in an output language , in accordance with one embodiment .", "label": "", "metadata": {}, "score": "41.098667"}
{"text": "This novel two - step syntactic analysis approach ensures the meaning of the source sentence to be accurately represented into a best syntactic structure which is chosen from the one or more syntactic trees .In addition , hypotheses for a portion of a sentence for analyzing its meaning and generating an appropriate language structure are verified within the hypotheses about the language structure for the whole sentence .", "label": "", "metadata": {}, "score": "41.539856"}
{"text": "For a more recent proposal , see B\u00e5ve ( 2008 ) .Such theories violate compositionality because they maintain that the semantic value of a that - clause includes phonological information even though the semantic values of their constituents and their mode of combination do not .", "label": "", "metadata": {}, "score": "41.592228"}
{"text": "The rules of a grammar allow replacing one view of an element with particular parts that are allowed to make it up .For example , a sentence consists of a noun phrase and a verb phrase , so to analyze a sentence , these two types can replace the sentence .", "label": "", "metadata": {}, "score": "41.645573"}
{"text": "Hence , the system ends up providing methods for knowledge acquisition and word - sense disambiguation within the context of semantic parsing in a single elegant framework .Experiments on these various tasks indicate the promise of the approach . ... a linguist .", "label": "", "metadata": {}, "score": "41.649857"}
{"text": "The NLP system might keep track of these by grouping the possible antecedents of pronouns into a discourse entity list or history list .The simple algorithm already mentioned might then be used to require that the most recent on the list be checked as a possible referent of the pronoun in question .", "label": "", "metadata": {}, "score": "41.955467"}
{"text": "In particular , our learning approach takes semantic annotations encoding underlying embedded struc - tural relations and automatically induces derivation rules that map sentences to their semantic meaning representa - tions .ports rightbranching semantic structures .However these systems either require a hand - built , ambiguous combinatory categorial grammar template to learn a probabilistic semantic parser [ 6 ] , or assume the existence of an unambiguous , context- ...", "label": "", "metadata": {}, "score": "42.089886"}
{"text": "However , they may remain untranslated fragments .In this case , other search methods may be applied , including fuzzy search and translation employing the NLC system .[0073 ]FIG .3 illustrates still another embodiment of the method for translating a document in a source language into a document in an output language with performing a fuzzy search in a database of translations .", "label": "", "metadata": {}, "score": "42.189964"}
{"text": "To make these clearer , we can turn the above into a set of grammar rules with a slightly different notation : .This should be rather easy to read .A sentence can be rewritten as a noun - phrase and a verb .", "label": "", "metadata": {}, "score": "42.223648"}
{"text": "It provides a highly modular syntax - semantics interface that has been applied to a variety of grammatical formalisms ( including LFG , HPSG , LTAG , and D - Tree grammar ) , and to a variety of meaning representations ( including higher - order intensional logic , lambda - DRT and UDRT ) .", "label": "", "metadata": {}, "score": "42.43715"}
{"text": "Basically , the parser can work either of these two ways in parsing .The algorithm will take a sentence and consider a variety of grammatical possibilities for it .For example , it considers the first possible rewrite that interprets it in some particular way , say as having two constituents .", "label": "", "metadata": {}, "score": "42.59765"}
{"text": "Much of semantic meaning is independent of context , and the type of information found in dictionaries , for example , can be used in the semantic analysis to produce the logical form .Relevant information here includes the basic semantic properties of words ( they refer to relations , objects , and so forth ) and the different possible senses for a word .", "label": "", "metadata": {}, "score": "42.603477"}
{"text": "This agreement rule determines the morphological value of the core .[ 0256 ] Prior to generating a word form with the help of the morphological description 501 , a lexeme must be selected which corresponds to the selected grammatical value .", "label": "", "metadata": {}, "score": "42.96093"}
{"text": "Syntactically coherent output \" means that the substituted words must agree , both between themselves and with the other words in the sentence , morphologically and syntactically .This is particularly important for affixing languages ( also known as synthetic languages ) , i.e. languages where words take on different flexions .", "label": "", "metadata": {}, "score": "43.26098"}
{"text": "In this thesis , we focus on the task of semantic parsing , which maps a natural language sentence into a complete , formal meaning representation in a meaning representation language .We present two novel state - of - the - art learned syntax - based semantic parsers using statistical syntactic parsing techniques , motivated by the following two reasons .", "label": "", "metadata": {}, "score": "43.283012"}
{"text": "One of the improvements that DCG allows over the context - free grammar ( Backus - Naur ) form in Prolog is that DCG can contain other information such as tense , number , and gender about the parts of a sentence .", "label": "", "metadata": {}, "score": "43.450554"}
{"text": "The sentences have the same basic structure .Your background general knowledge of human life spans , reading speeds , and the theory of evolution enabled you to sort it out .When a pronoun is used in a sentence , we must determine its referent .", "label": "", "metadata": {}, "score": "43.723778"}
{"text": "For example , consider the particular sentence that can be defined in terms of a noun phrase and a verb phrase .The noun phrase is a non - terminal , which is then defined in terms of a determiner followed by a noun .", "label": "", "metadata": {}, "score": "43.72549"}
{"text": "In recent years there has been considerable interest in corpus - based methods for constructing natural language parsers .These empirical approaches replace hand - crafted grammars with linguistic models acquired through automated training over language corpora .A common thread among such methods to date is the use of propositional or probablistic representations for the learned knowledge .", "label": "", "metadata": {}, "score": "43.770744"}
{"text": "Allen notes that it is not clear that there really is any context independent sense , but it is advantageous for NLP to try to develop one .Mapping a sentence to its logical form , or meaning , is called \" semantic interpretation , \" and mapping the logical form to the final knowledge representation ( KR ) is called \" contextual interpretation .", "label": "", "metadata": {}, "score": "43.83379"}
{"text": "[0226 ] Lexical selection 2220 is selecting one or more lexical meanings for a deep constituent core .Any constituent has a word at its core and can include child constituents at lower levels .As a rule , the grammatical , syntactical and morphological properties of the deep constituent , expressed by means of a set of semantemes , are the same as the properties of its core .", "label": "", "metadata": {}, "score": "43.852394"}
{"text": "In this specialized sense , the method of semantic interpretation allows logical forms to be computed while parsing .A popular version of this pursues a rule - by - rule style , with each syntactic rule corresponding to a semantic rule , so that each well - formed syntactic constituent will have a corresponding well - formed semantic ( logical form ) meaning constituent .", "label": "", "metadata": {}, "score": "43.92223"}
{"text": "The semantic analysis treats the syntactic structure of a sentence in any language as a surface representation of a language - independent semantic structure .[ 0211 ] A semantic structure 2002 is built from the selected syntactic structure 1402 by performing steps 2010 , 2020 , 2030 of generating semantic structure , calculating communicative semantemes , and normalizating and calculating semantemes , among others .", "label": "", "metadata": {}, "score": "43.93445"}
{"text": "Using statistical machine translation techniques , a semantic parser based on a synchronous context - free grammar augmented with lambda - operators is learned given a set of training sentences and their correct logical forms .The resulting parser is shown to be the best - performing system so far in a database query domain .", "label": "", "metadata": {}, "score": "43.96782"}
{"text": "[ 0057 ] Then , if the document still contains untranslated fragments , the NLC machine translation system is used at step 120 , which analyzes each sentence by employing linguistic descriptions of the source language .The linguistic descriptions useful for analyzing the source sentence may include morphological descriptions , syntactic descriptions , lexical descriptions , and semantic descriptions which are relevant to various languages .", "label": "", "metadata": {}, "score": "44.01264"}
{"text": "To acquire such grammar rules automatically in an unsupervised manner , we also propose a novel approach with a generative model , which maps from sub - expressions of logical forms to word sequences in natural language sentences .Experiments on benchmark datasets for both English and Chinese generation tasks yield significant improvements over results obtained by two state - of - the - art machine translation models , in terms of both automatic metrics and human evaluation . \" ...", "label": "", "metadata": {}, "score": "44.10385"}
{"text": "Additionally , the grammatical agreement between each element of the sentence , which may be as a relationship of control , for example , a controller and a controlled element , using the referential and structural control description 856 , is checked .", "label": "", "metadata": {}, "score": "44.27993"}
{"text": "The grammar specifies the legal ways for combining the units ( syntactically and semantically ) to result in other constituents .A lexicon indicating the types of speech for words will also be used ; sometimes this is considered part of the grammar .", "label": "", "metadata": {}, "score": "44.333313"}
{"text": "This extra information may be considered context information , and context - free grammars will not include it .So definite clause grammars improve on context - free grammars in this regard by allowing the storage of such information .Because the grammar definitions are parsed in a recursive fashion , information interpreted at any point can be passed forward or backward to be compared to such information for other parts of the sentence .", "label": "", "metadata": {}, "score": "44.384434"}
{"text": "Through a ( modified ) form of functional application ( or beta reduction ) , the focus part of ( 10 ) and ( 11 ) is projected up through the syntax to the sentential level .Importantly , each intermediate level has distinct meaning .", "label": "", "metadata": {}, "score": "44.511642"}
{"text": "A deeper semantic analysis provides a representation of the sentence in predicate logic or other formal language which supports automated reasoning .We have developed methods for automatically learning semantic parsers from annotated corpora using inductive logic programming and other learning methods .", "label": "", "metadata": {}, "score": "44.60995"}
{"text": "Our system uses a syntactic combinatorial categorial parser to parse natural language sentences and also to construct the semantic meaning of the sentences as directed by their parsing .The same parser is used for both .In addition to the inverse \u03bb - calculus operators , our system uses a notion of generalization to learn semantic representation of words from the semantic representation of other words that are of the same category .", "label": "", "metadata": {}, "score": "44.686428"}
{"text": "[ 11 ] [ 12 ] .Standard generative approaches to grammar argue that phonology and semantics can not exchange information directly ( See Fig . 1 ) .Therefore , syntactic mechanisms including features and transformations include prosodic information regarding focus that is passed to the semantics and phonology .", "label": "", "metadata": {}, "score": "44.69603"}
{"text": "However , it does not scale to problems with a large set of potential meanings for each sentence , such as the navigation instruction following task studied by Chen and Mooney ( 2011 ) .This paper presents an enhancement of the PCFG approach that scales to such problems with highly - ambiguous supervision .", "label": "", "metadata": {}, "score": "44.939278"}
{"text": "A semantic structure , unlike a syntactic structure , uses universal language - independent concepts and components , such as semantic classes , semantemes , deep slots , among others .[ 0221 ] As shown in FIG .20 , a dispatcher 2040 for dispatching semanteme rules is adapted to execute the normalization of the semantic structure 2002 and calculating semantemes by applying the analysis rules 860 .", "label": "", "metadata": {}, "score": "44.959534"}
{"text": "Each constituent can be attached to a constituent at a higher level if the surface slots 815 of the constituent at the higher level can be filled .Thus , the constituents are further expanded to include the neighboring constituents built at previous constituent building process until all of the possible constituents have been built to cover the entire sentence .", "label": "", "metadata": {}, "score": "44.968426"}
{"text": "Many such interpretations of coherence will be implications rather than entailments ; in other words , they are defeasible and might be overridden by later information .We can now get even more specific about the notion of local discourse .The local discourse situation includes local connections between sentences .", "label": "", "metadata": {}, "score": "45.113884"}
{"text": "[0143 ] The preliminary assembly 1210 of the constituents during the rough syntactic analysis 530 is performed on the lexical - morphological structure 1201 of the sentence to be analyzed , including certain word groups , the words in brackets , inverted commas , etc .", "label": "", "metadata": {}, "score": "45.231632"}
{"text": "[0053 ] The rest of the document ( i.e. the \" untranslated fragments \" ) may be translated by means of the NLC system , which analyzes each sentence , recognizes its linguistic structure and semantics in order to \" understand \" its meaning .", "label": "", "metadata": {}, "score": "45.25187"}
{"text": "0097 ] Word - inflexion description 710 describes how the main form of a word form may change according to its case , gender , number , tense , etc . and broadly includes all possible forms for a given word .", "label": "", "metadata": {}, "score": "45.318394"}
{"text": "Problems of syntactical and semantic ambiguities which may appear during the process of translation can be reliably handled .[0054 ] Maximum use of linguistic knowledge and natural language descriptions enable generation of a language - independent semantic structure which contains a large amount of various data information about the meaning of the source sentence .", "label": "", "metadata": {}, "score": "45.782867"}
{"text": "[ 0255 ] The morphological synthesis 2280 of the constituent cores is performed on the basis of the morphological description 501 .The grammatical value of a constituent core is determined on the basis of the grammatical value of the constituent and the already - detected syntactic form .", "label": "", "metadata": {}, "score": "45.833908"}
{"text": "We tend to assume that a computer could be given the dictionary meanings of words , along with the type of speech for each and the rules of grammar , and by using this information process a natural language sentence .It should be a purely mechanical process of searching a database and classifying the sentence parts .", "label": "", "metadata": {}, "score": "45.90417"}
{"text": "[0157 ] As shown in FIG .12 , the coordination processing 1250 is also performed on the graph 1202 of the generalized constituents .Coordination is a language phenomenon which is presented in sentences with enumeration and/or a coordinating conjunction , such as \" and \" , \" or \" , \" but \" , etc .", "label": "", "metadata": {}, "score": "45.916912"}
{"text": "In future work , we intend to pursue several directions in developing accurate semantic parsers for a variety of application domains .This will involve exploiting prior knowledge about the natural - language syntax and the application domain .We also plan to construct a syntax - aware word - based alignment model for lexical acquisition .", "label": "", "metadata": {}, "score": "45.98694"}
{"text": "Such prior rough ratings include ratings of lexical meanings , ratings of fillers , ratings of the correspondence to semantic descriptions , among others .[ 0146 ] The filtering 1270 during the rough syntactic analysis 530 include filtering of a set of syntforms 812 performed prior to and during the building 1220 of generalized constituents .", "label": "", "metadata": {}, "score": "46.1361"}
{"text": "We have used the phrase \" semantic interpretation \" loosely for the latter process ; actually we might think of semantic interpretation as going from the sentence to the logical form or from the syntactic structure or representation to the logical form .", "label": "", "metadata": {}, "score": "46.29876"}
{"text": "The same parser is used for both .In addition to the inverse \u03bb - calculus operators , our system uses a notion of generalization to learn semantic representation of words from the semantic representation of other words that are of the same category .", "label": "", "metadata": {}, "score": "46.308876"}
{"text": "The main innovation of the algorithm is its use of state - of - the - art statistical machine translation techniques .A statistical word alignment model is used for lexical acquisition , and the parsing model itself can be seen as an instance of a syntax - based translation model .", "label": "", "metadata": {}, "score": "46.373825"}
{"text": "We present a new approach to learning a semantic parser ( a system that maps natural language sentences into logical form ) .Unlike previous methods , it exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .", "label": "", "metadata": {}, "score": "46.462845"}
{"text": "[0092 ] At step 550 , a semantic analysis is performed to transition the best syntactic structure 546 of the source sentence in the natural language into a language - independent semantic structure 552 .The language - independent semantic structure 552 is generated to fully convey the meaning of the source sentence in the source natural language and represent the source sentence in a language - independent form .", "label": "", "metadata": {}, "score": "46.524048"}
{"text": "An overview of the system is presented followed by recent experimental results on corpora of Spanish geography queries and English job - search queries .ML ID : 75 .An Inductive Logic Programming Method for Corpus - based Parser Construction [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney January 1997 .", "label": "", "metadata": {}, "score": "46.587166"}
{"text": "Most recent work on semantic analysis of natural language has focused on ' ' shallow ' ' semantics such as word - sense disambiguation and semantic role labeling .Our work addresses a more ambitious task we call semantic parsing where natural language sentences are mapped to complete formal meaning representations .", "label": "", "metadata": {}, "score": "46.698772"}
{"text": "Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing user - friendly natural language interfaces to computing systems .Most of the research in natural language understanding , however , has mainly focused on shallow semantic analysis like case - role analysis or word sense disambiguation .", "label": "", "metadata": {}, "score": "46.773064"}
{"text": "In one embodiment of the invention , the syntactic analysis includes a rough syntactic analysis and a precise syntactic analysis .When analyzing the meaning of the source sentence , a two - step analysis algorithm ( e.g. , rough syntactic analysis and precise syntactic analysis ) is implemented .", "label": "", "metadata": {}, "score": "46.83573"}
{"text": "Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations .Finally , we show that hybridizing these two approaches results in still more accurate generation systems .Automatic and human evaluation of generated sentences are presented across two domains and four languages .", "label": "", "metadata": {}, "score": "46.895947"}
{"text": "^ Mel'\u010duk , Igor A. ( 2001 ) , Communicative Organization in Natural Language : The Semantic - Communicative Structure of Sentences , Amsterdam : John Benjamins .^ Prince , E ( 1981 ) , Towards a taxonomy of given - new information , New York : Academic Press .", "label": "", "metadata": {}, "score": "46.93794"}
{"text": "For future work , I propose to extend our PCFG induction model in several ways : improving the lexicon learning algorithm , discriminative re - ranking of top - k parses , and integrating the meaning representation language ( MRL ) grammar for extra structural information .", "label": "", "metadata": {}, "score": "46.94465"}
{"text": "The parsing and generation algorithms learn all of their linguistic knowledge from annotated corpora , and can handle natural - language sentences that are conceptually complex .A nice feature of our algorithms is that the semantic parsers and tactical generators share the same learned synchronous grammars .", "label": "", "metadata": {}, "score": "47.010246"}
{"text": "Accordingly , those lexical meanings in the semantic class are selected , which have deep slots , and those semantic classes of deep slot fillers in their deep models 912 , which correspond to the deep slots and semantic classes of deep slot fillers of the constituent core .", "label": "", "metadata": {}, "score": "47.072598"}
{"text": "Recognition of these clues helps it try to match the pattern of the phrase or sentence against some common structures it knows to look for .It might take a preposition as a clue to look for a prepositional phrase , or an auxiliary verb as a clue to look for a verb phrase .", "label": "", "metadata": {}, "score": "47.10083"}
{"text": "[0130 ] During the initial stage of the lexical - morphological analysis 520 , lemmatization ( searching and assigning lexemes ) and obtaining pairs of lexical meaning - grammatical value are concurrently made .The lexeme of the word form , its lemma , and morphological grammatical values for all elements for the source sentence 512 are searched and found by using the lexical descriptions 503 .", "label": "", "metadata": {}, "score": "47.10501"}
{"text": "Performing the rough syntactic analysis may require the use of the syntactical descriptions 502 , the lexical descriptions 503 of the source language , and the semantic descriptions 504 .[ 0090 ] At step 540 , the precise analysis is performed on the graph of generalized constituents 532 .", "label": "", "metadata": {}, "score": "47.129375"}
{"text": "The KRL must also include a method of representing and reasoning about temporal event information , such as that contained in the tense of verbs and in adverbials ( e. g. , \" yesterday \" ) .The logical form language used model operators ( PAST , PRES , FUT ) and temporal connectives ( BEFORE , DURING ) .", "label": "", "metadata": {}, "score": "47.16975"}
{"text": "These classifiers are further refined using EM - type iterations based on their performance on the training data .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .Our experiments on two real - world data sets that have deep meaning representations show that this approach compares favorably to other existing systems in terms of accuracy and coverage .", "label": "", "metadata": {}, "score": "47.210747"}
{"text": "All available information from linguistic descriptions of the output language is used .[0276 ] While the foregoing is directed to embodiments of the present invention , other and further embodiments of the invention may be devised without departing from the basic scope thereof , and the scope thereof is determined by the claims that follow .", "label": "", "metadata": {}, "score": "47.347"}
{"text": "For example , the parser set up to \" clear data \" when it sees those two terms in a sentence such as \" Clear the data from the database \" might initiate such an action on reading \" Clear the top of the data operations workspace . \"", "label": "", "metadata": {}, "score": "47.34887"}
{"text": "This information might allow specification of the referent of a pronoun or other definite noun phrase occurring in the input sentence , or it might provide the meaning of a verb phrase ellipsis in the input sentence that refers to a previously described event .", "label": "", "metadata": {}, "score": "47.398956"}
{"text": "What we need , then , for a logical form language , is something that can capture sense meanings but also how they apply to objects and can combine into more complex expressions .Allen introduces a language resembling the first order predicate calculus ( FOPC ) that enables this .", "label": "", "metadata": {}, "score": "47.487442"}
{"text": "Finally , it is not even clear whether Fregean senses can be properly construed as linguistic meanings .For more on Frege and compositionality , see Janssen ( 2001 ) and Pelletier ( 2001 ) .They also provide good bibliographies .", "label": "", "metadata": {}, "score": "47.52641"}
{"text": "The latter is taken to be a principle of parsing which states that an expression must be assigned a complete syntactic structure before it is semantically evaluated .The AoS commits no hostages to the temporal dynamics involved in parsing .Parsing could interleave syntactic and semantic rules without the latter conditioning the former .", "label": "", "metadata": {}, "score": "47.549057"}
{"text": "I first present a historical view of the shifting emphasis of research on various tasks in natural language processing and then briefly review our own work on learning for semantic interpretation .I will then attempt to encourage others to study such problems and explain why I believe logical approaches have the most to offer at the level of producing semantic interpretations of complete sentences .", "label": "", "metadata": {}, "score": "47.60218"}
{"text": "Finally , we test the system on an alternate sentence representation , and on a set of large , artificial corpora with varying levels of ambiguity and synonymy .One difficulty in using machine learning methods for building natural language interfaces is building the required annotated corpus .", "label": "", "metadata": {}, "score": "47.720097"}
{"text": "^ a b c d e f g h i j k l m n German , J. , Pierrehumbert , J. and Kaufmann , S. ( 2006 ) , Evidence for phonological constraints on nuclear accent placement , Language 82(1 ) , 151 - 168 .", "label": "", "metadata": {}, "score": "47.72271"}
{"text": "[0122 ] While the surface model 810 describes the syntactic roles of surface slots and their fillers , the deep model 912 generally describes the semantic roles of the surface slots and the fillers .A deep slot description 920 expresses the semantic types of possible fillers and/or the properties or attributes of the objects denoted by the words of any natural language .", "label": "", "metadata": {}, "score": "47.730625"}
{"text": "Chomsky and Halle [ 18 ] formulated a Nuclear Stress Rule that proposed there to be a relation between the main stress of a sentence and a single constituent .Since this constituent is prominent sententially in a way that can contrast with lexical stress , this was originally referred to as \" nuclear \" stress .", "label": "", "metadata": {}, "score": "47.77004"}
{"text": "We focus on two important sub - tasks , semantic parsing and tactical generation .The key idea is that both tasks can be treated as the translation between natural languages and formal meaning representation languages , and therefore , can be performed using state - of - the - art statistical machine translation techniques .", "label": "", "metadata": {}, "score": "47.77829"}
{"text": "Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans for our limited domain .ntence is annotated with its semantic meaning .Since the world never provides any direct feedback on syntactic structure , language - learning methods that 424TRAINING", "label": "", "metadata": {}, "score": "47.804314"}
{"text": "[ 0094 ] At step 570 , morphological synthesis is performed on the surface / syntactic structure 562 to generate the output sentence 514 .The morphological synthesis may require the use of the morphological descriptions 501 and the lexical descriptions 503 of the output language .", "label": "", "metadata": {}, "score": "47.840668"}
{"text": "Foc relates F - marking to accent placement .Foc simply requires that a constituent(s ) of an F - marked phrase contain an accent .AvoidF states that less F - marking is preferable to more F - marking .HeadArg encodes the head - argument asymmetry into the grammar directly .", "label": "", "metadata": {}, "score": "47.88556"}
{"text": "Given ( C ) , we have a violation of compositionality ; cf .Stanley and Szab\u00f3 ( 2000 ) .Pelletier ( 2003 ) claims that the four assumptions are compatible with compositionality because the syntactic rule which combines the quantifier and the noun may be associated with a context - sensitive semantic rule .", "label": "", "metadata": {}, "score": "47.911377"}
{"text": "Semantic analysis .Once the computer has arrived at an analysis of the input sentence 's syntactic structure , a semantic analysis is needed to ascertain the meaning of the sentence .Two caveats are needed before I proceed .First , as before , the subject is more complex than can be thoroughly discussed here , so I will proceed by describing what seem to me to be the main issues and giving some examples .", "label": "", "metadata": {}, "score": "47.91696"}
{"text": "Phrase structure grammar stems from Zelig Harris ( 1951 ) , who thought of sentences as comprising structures .The parsing of such sentences requires a top - down recursive analysis of the components until terminating units ( words ) are reached .", "label": "", "metadata": {}, "score": "47.923985"}
{"text": "A grammar comprises the rules for constructing sentences in the language .Allen mentions that several components distinguish a good grammar from a poor one .Generality involves the range of sentences the grammar analyzes correctly .Selectivity involves the range of non - sentences it identifies as problematic .", "label": "", "metadata": {}, "score": "47.96112"}
{"text": "Besides involving the rules of the grammar , parsing will involve a particular method of trying to apply the rules to the sentences .This is the parsing algorithm .Allen defines a parsing algorithm as a procedure that searches through various ways of combining grammatical rules and finds a combination of these rules that generates a tree or list that could be the structure of the input sentence being analyzed .", "label": "", "metadata": {}, "score": "47.967827"}
{"text": "A lexeme is a meaningful linguistic unit that is an item in the vocabulary , such as the lexical - semantic dictionary 1004 of a language .[0127 ]As shown in FIG .5B , the lexical - morphological analysis 520 is performed on the source sentence 512 .", "label": "", "metadata": {}, "score": "47.998497"}
{"text": "Any possible differences of the child lexical meanings are saved in a list semantemes generated during the application of the analysis rules 860 .A description of a constituent in the final semantic structure 2002 includes semantic classes which are parents for lexical meanings represented in the best syntactic structure 1402 , semantemes which are calculated according to the analysis rules 860 or assigned to corresponding parent semantic classes , and child constituents .", "label": "", "metadata": {}, "score": "48.093147"}
{"text": "To interpret natural language sentences correctly , the system will not only have to parse the sentences grammatically but also associate the words with things in the world and with the general context of utterance of the sentence .And then once one has the syntactic analysis , semantics and pragmatics are needed to understand the full meaning of the sentence .", "label": "", "metadata": {}, "score": "48.12403"}
{"text": "The lexicon , or the mapping from words to meanings , is one component that is typically difficult to update and that changes from one domain to the next .Therefore , automating the acquisition of the lexicon is an important task in automating the acquisition of NLP systems .", "label": "", "metadata": {}, "score": "48.127247"}
{"text": "[ 0141 ] Some of the constituents which are built for the same element of the lexical - morphological structure may be generalized to obtain generalized constituents .Constituents are generalized by the lexical meanings 1012 , by the grammatical values 814 , for example , by parts of speech , by their boundaries , among others .", "label": "", "metadata": {}, "score": "48.129066"}
{"text": "A morphological paradigm as a part of word - inflection description 710 of morphological description 501 contains all information about word - inflection of one or more part of speech .[0163 ] Links in the graph 1300 represent filled surface slots of constituent cores .", "label": "", "metadata": {}, "score": "48.221504"}
{"text": "We then will proceed with a consideration of pragmatics , and so finally we need a general knowledge representation , which allows a contextual interpretation of the context - free form analysis and logical form .Keep in mind that I write as if the overall analysis proceeds in discrete stages , each stage yielding an output that serves as input for the next stage .", "label": "", "metadata": {}, "score": "48.265594"}
{"text": "If this can not be done , the hypothesis is deleted .A preliminary rating for each hypothesis is calculated and they are arranged in the order of descending rating scores .[ 0245 ] The syntactic forms are analyzed in the order of descending rating .", "label": "", "metadata": {}, "score": "48.339825"}
{"text": "The second expression occurs when we use the rules to express the actual analysis of a particular sentence ; this is what parsing is .In either case mentioned below , we 're going to introduce some of the common notations that are used in discussing syntactic analysis .", "label": "", "metadata": {}, "score": "48.37402"}
{"text": "This pair is referred to as a structured meaning .Structured meanings allow for a compositional semantic approach to sentences that involve single or multiple foci .This approach follows Frege 's ( 1897 )Principle of Compositionality : the meaning of a complex expression is determined by the meanings of its parts , and the way in which those parts are combined into structured meanings .", "label": "", "metadata": {}, "score": "48.385994"}
{"text": "The semantic structure 2002 is language - independent and may include , but is not limited to , a tree of deep constituents , deep constituents , and semantic classes which are the fillers of deep slots .Accordingly , the semantic structure 2002 can be applied to describe the meanings of a sentence from any natural or artificial languages .", "label": "", "metadata": {}, "score": "48.394737"}
{"text": "A null theory of phrase and compound stress ' .Linguistic Inquiry 24:239 - 267 .Neeleman , Ad and Tanya Reinhart ( 1998 ) . 'Scrambling and the PF - Interface ' .In The Projection of Arguments , CSLI Publications , 309 - 353 .", "label": "", "metadata": {}, "score": "48.56952"}
{"text": "A controller can have several controlled element variants as different alternatives .Ideally , all available proforms are inserted .However , in the final syntactic tree , there may be only one of the control element variant remained .In addition , the set of meanings for a controlled element may be calculated from the controller ; for example , a set of lexical meanings may be taken from the controller , a set of grammatical values may be limited by the agreement rule , etc .", "label": "", "metadata": {}, "score": "48.623753"}
{"text": "As shown in FIG .12 , information from the syntforms 812 of the syntactic descriptions 502 as well as the semantic descriptions 504 are used to build the models 1232 of the generalized constituents .Such compatibility analysis allows the wrong syntactic relationships to be discarded early .", "label": "", "metadata": {}, "score": "48.701122"}
{"text": "And if the system is translating a text about tools , it will select the translation which means \" a machinists ' file .\" [ 0083 ] Referring to FIG .3 , if , after fuzzy search step 115 , there remain untranslated fragments in the document , at step 120 other translation methods may be applied to them , including translation by the NLC system .", "label": "", "metadata": {}, "score": "48.750835"}
{"text": "A natural language processor using a DCG first breaks up a sentence into its component parts .It begins with the basic noun phrase and verb phrase and eventually delineates the nouns , verbs , prepositions , etc .It thus proceeds in a top - down fashion , with each pass breaking up each unit further in a recursive fashion until the entire sentence is parsed .", "label": "", "metadata": {}, "score": "48.775517"}
{"text": "These syntactic structures or syntactic structure variants generated from different syntactic trees may vary in the inserted proforms , their positions in the tree , and non - tree links .To be able to define an antecedent in the previous text , several of the syntactic structures 1475 of previous sentences from the previous syntactic analysis can be saved .", "label": "", "metadata": {}, "score": "48.796158"}
{"text": "9 ) .The diatheses 817 are represented by the link 624 between syntactic descriptions 502 and semantic descriptions 504 ( as shown in FIG .6 ) .The communicative descriptions 880 describe communicative order of the words in a sentence .", "label": "", "metadata": {}, "score": "48.80123"}
{"text": "Lexical Functional Grammar Conference 2006 ; 2006 July 10 - 13 ; Konstanz ; Germany .Publications : Learning for Semantic Parsing .Semantic parsing is the process of mapping a natural - language sentence into a formal representation of its meaning .", "label": "", "metadata": {}, "score": "48.918777"}
{"text": "A child constituent is a dependent constituent and may be attached to other constituents ( as parent constituents ) for building the syntactic structure of a source sentence .[0099 ] FIG .8 illustrates exemplary syntactic descriptions .The components of the syntactic descriptions 502 may include , but are not limited to , surface models 810 , surface slots descriptions 820 , referential and structural control description 830 , government and agreement description 840 , non - tree syntax description 850 , and analysis rules 860 .", "label": "", "metadata": {}, "score": "49.06431"}
{"text": "Our work is also the first attempt to use the same automatically - learned grammar for both parsing and generation .Unlike previous systems that require manually - constructed grammars and lexicons , our systems require much less knowledge engineering and can be easily ported to other languages and domains .", "label": "", "metadata": {}, "score": "49.14087"}
{"text": "New words are often accented while given words are not .The accented word(s ) forms the focus domain .However , not all of the words in a focus domain need be accented .( See [ 14 ] [ 15 ] [ 16 ] for rules on accent placement and focus - marking ) .", "label": "", "metadata": {}, "score": "49.17444"}
{"text": "For these precise constituents , syntactic forms , the boundaries of the child constituents and the surface slots are determined .The different syntactic trees are built in the order of descending of their structural rating .Lexical ratings can not be fully used because their deep semantic structure is not defined yet .", "label": "", "metadata": {}, "score": "49.21019"}
{"text": "Therefore in ( 2 ) , focus is marked via word order and a nuclear pitch accent .Focus also relates to phonology and has ramifications for how and where suprasegmental information such as rhythm , stress , and intonation is encoded in the grammar , and in particular intonational tunes that mark focus .", "label": "", "metadata": {}, "score": "49.23146"}
{"text": "Variables are also used , but not exactly like in FOPC .In FOPC a variable 's assignment extends only as far as the scope of the quantifier , but in natural languages , with pronouns referring to things introduced earlier , we need variables to continue their existence beyond the initial quantifier scope .", "label": "", "metadata": {}, "score": "49.252785"}
{"text": "argue for a stochastic constraint - based grammar similar to Anttila [ 34 ] and Boersma [ 35 ] that more fluidly accounts for how speakers accent words in discourse .^ a b Halliday , M. ( 1967 ) , Notes on Transitivity and Theme in English ( Part 2 ) , Journal of Linguistics 3 . ,", "label": "", "metadata": {}, "score": "49.28444"}
{"text": "Given a lexicon telling the computer the part of speech for a word , the computer would be able to just read through the input sentence word by word and in the end produce a structural description .But problems arise for several reasons .", "label": "", "metadata": {}, "score": "49.294994"}
{"text": "In general , the parent constituent may be left unchanged for a period of time without changing its grammatical value , and the lexical meaning of the parent constituent may be checked again at a later stage .Similarly , the controller may not be modified until a later stage .", "label": "", "metadata": {}, "score": "49.300045"}
{"text": "The mutual semantic representability means that it is possible the transition not only from the lexical meaning to the semantic class , but from the semantic class to the lexical meaning .Any semantic class always has at least one such lexical meaning - representative in the given natural language .", "label": "", "metadata": {}, "score": "49.40572"}
{"text": "Here are some more terms .An interpretation process maps natural language sentences to the formal language , or from one formal language to others .But there are different types of interpretation process , depending on which formal language and stage is being considered .", "label": "", "metadata": {}, "score": "49.563004"}
{"text": "[0138 ]The building of the graph 1202 of generalized constituents starts with building those constituents which have only the core word form and further expands to build constituents of the next level by including neighboring constituents .If an appropriate syntform 812 is found in the surface model 810 of the corresponding lexical meaning , the selected lexical meaning may be the core of a new constituent .", "label": "", "metadata": {}, "score": "49.59908"}
{"text": "Typically , the fillers of the deep slots 914 have the same semantic properties even in different languages .Lexical meanings 1012 of a lexical description of a language inherit properties of semantic class from its parent and adjust its deep model 912 .", "label": "", "metadata": {}, "score": "49.74563"}
{"text": "A simple extension using transductive SVMs enables the system to do semi - supervised learning and improve its performance utilizing unannotated sentences which are usually easily available .Another extension involving EM - like retraining makes the system capable of learning under ambiguous supervision in which the correct meaning representation for each sentence is not explicitly given , but instead a set of possible meaning representations is given .", "label": "", "metadata": {}, "score": "49.782936"}
{"text": "Thus at any given step in the analysis , each part of a sentence can be seen as a terminal or non - terminal .Terminals would be the actual individual words ( you ca n't analyze them further ) and non - terminals would be clauses or phrases that are not yet fully broken down .", "label": "", "metadata": {}, "score": "49.846542"}
{"text": "A special slot , such as relativization and question , presupposing a special lexeme ( relative or interrogative pronoun ) , is filtered out if the special lexeme is not present in the sentence .[ 0147 ] In general , the syntax forms ( syntforms 812 ) which do not have fillers for at least one surface slot can be filtered and discarded .", "label": "", "metadata": {}, "score": "49.941154"}
{"text": "We also intend to broaden the scope of application domains , for example , domains where the sentences are noisy as typical in speech , or domains where corpora available for training do not have natural language sentences aligned with their unique meaning representations .", "label": "", "metadata": {}, "score": "49.993095"}
{"text": "A sentence may have multiple possible syntactic structures , and each of these may have multiple possible logical forms .The words in the sentence might even have multiple senses .With all this ambiguity the number of possible logical forms to be dealt with may be huge .", "label": "", "metadata": {}, "score": "50.032562"}
{"text": "Accordingly , the different types of movement may express different communicative or stylistic aspects , for example , to mark out the focus or emphasis of the sentence to be generated .This may entail a modification of a linear order .", "label": "", "metadata": {}, "score": "50.06696"}
{"text": "The former is supposed to be derived from the standing meaning via a mandatory process he calls saturation , while the latter is supposed to be arrived at employing the full array of contextual processes , including optional modulation as well .", "label": "", "metadata": {}, "score": "50.098984"}
{"text": "[ 0059 ] Then , at step 120 , after the language - independent semantic structure is constructed , the output sentence is generated from the language - independent semantic structure in order to represent the meaning of the source sentence in the output language .", "label": "", "metadata": {}, "score": "50.106483"}
{"text": "( Other more sophisticated algorithms could be developed too . )Besides pronouns , other expressions might need resolution .Other referring expressions might be interpreted using pattern matching techniques that find syntactic similarities between the current clause and preceding ones .", "label": "", "metadata": {}, "score": "50.149704"}
{"text": "When attaching child constituents , restrictions which the child constituents impose on the set of meanings of a parent constituent are taken into account , and the upper lexical rating of the link is calculated .Additionally , deep rating is obtained as a degree of conformity of the deep slot with these restrictions .", "label": "", "metadata": {}, "score": "50.22919"}
{"text": "Semantic parsing is the construction of a complete , formal , symbolic meaning representation of a sentence .While it is crucial to natural language understanding , the problem of semantic parsing has received relatively little attention from the machine learning community .", "label": "", "metadata": {}, "score": "50.37252"}
{"text": "[ 10 ] Recent attempts to explain focus phenomena in terms of discourse function , including those by Knud Lambrecht and Talmy Giv\u00f3n , often connect focus with the packaging of new , old , and contrasting information .Lambrecht in particular distinguishes three main types of focus constructions : predicate - focus structure , argument - focus structure , and sentence - focus structure .", "label": "", "metadata": {}, "score": "50.37793"}
{"text": "So , in the model , to represent the meaning of a sentence we need a more precise , unambiguous method of representation .We will use formal languages .Starting with a sentence in natural language , the result of syntactic analysis will yield a syntactic representation in a grammar ; this is form is often displayed in a tree diagram or a particular way of writing it out as text .", "label": "", "metadata": {}, "score": "50.441532"}
{"text": "Since it is not clear that structure itself is the sort of thing that can represent ( and hence can have meaning )I assume that compositionality should be interpreted as ( C ) .The difference becomes important if proponents of the weaker principle also allow that syntactic rules may have context - dependent meanings .", "label": "", "metadata": {}, "score": "50.45067"}
{"text": "We have also explored methods for learning semantic lexicons , i.e. databases of words or phrases paired with one or more alternative formal meaning representations .Semantic lexicons can also be learned from semantically annotated sentences and are an important source of knowledge for semantic parsing .", "label": "", "metadata": {}, "score": "50.464073"}
{"text": "According to one aspect of the invention , when establishing syntactic relationships for elements of a source sentence , one or more constituent models are used .A constituent may include a contiguous group of words from the source sentence and behaves as one entity .", "label": "", "metadata": {}, "score": "50.526127"}
{"text": "[0195 ] Near the end of the stage 1460 , a syntactic tree with a fully - defined syntactic structure is built , i.e. the syntactic form , child constituents and surface slots that they fill are defined .Since this tree is generated on the basis of the best hypothesis about the syntactic structure of the initial sentence , this tree is called the best syntactic tree 1420 .", "label": "", "metadata": {}, "score": "50.526947"}
{"text": "Semantics via f - structure rewriting .LFG Conference 2006 .This paper discusses how the XLE general purpose ordered rewrite rule system is used to produce semantic representations from syntactic f - structures .The rules apply efficiently because they operate on the packed input of f - structures to produce packed semantic structures .", "label": "", "metadata": {}, "score": "50.575073"}
{"text": "A principle of integral and purpose - driven recognition , i.e. hypotheses about the structure of the part of a sentence are verified within the hypotheses about the structure of the whole sentence , is implemented as during the analysis stage as during the synthesis stage .", "label": "", "metadata": {}, "score": "50.604874"}
{"text": "Invited paper .Semantic parsing is the task of mapping a natural language sentence into a complete , formal meaning representation .Over the past decade , we have developed a number of machine learning methods for inducing semantic parsers by training on a corpus of sentences paired with their meaning representations in a specified formal language .", "label": "", "metadata": {}, "score": "50.78769"}
{"text": "However , I believe that logical approaches may have the most relevance and impact at the level of semantic interpretation , where a logical representation of sentence meaning is important and useful .We have explored the use of inductive logic programming for learning parsers that map natural - language database queries into executable logical form .", "label": "", "metadata": {}, "score": "50.805016"}
{"text": "This paper presents an approach for inducing transformation rules that map natural - language sentences into a formal semantic representation language .The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .", "label": "", "metadata": {}, "score": "50.891518"}
{"text": "A value of said prior rough rating is saved by each arrow denoting a filled surface slot .Surface slot and relationships with high rating scores are selected hierarchically during the next step of syntactic analysis .[0164 ]Often several arrows may connect the same pairs of constituents .", "label": "", "metadata": {}, "score": "50.89897"}
{"text": "Expectations can be generated by information about , among other things , action and causality , causes and effects , preconditions , enabling , decomposition , and generation .A possible interpretation of the input sentence can then be compared / matched to the expectations .", "label": "", "metadata": {}, "score": "50.935654"}
{"text": "Current activities focus on : development of broad coverage semantic lexicons ; robust interpretation in response to ill - formed / out - of - coverage input ; further refinements of packed proof - search algorithms for managing syntactic and semantic ambiguity .", "label": "", "metadata": {}, "score": "50.96221"}
{"text": "However , the types of sentences that can be parsed is so limited that another approach must be used for anything resembling a useful natural language processor for ordinary conversation .These preliminary issues out of the way , lets discuss the notion of a grammar .", "label": "", "metadata": {}, "score": "51.020996"}
{"text": "Recent empirical work by German et al .[ 32 ] suggests that both Selkirk 's [ 14 ] [ 15 ] and Schwarzschild 's [ 16 ] theory of accentuation and F - marking makes incorrect predictions .Consider the following context : .", "label": "", "metadata": {}, "score": "51.051277"}
{"text": "As lexical meanings 1012 in lexical description 503 have their semantic values 1010 which are also expressed by means of a set of semantemes , and those lexical meanings in the semantic class are selected , which have a most number of semantemes of the constituent core .", "label": "", "metadata": {}, "score": "51.057823"}
{"text": "[ 0252 ] Additionally , determining precise values of relational grammatical categories is executed .The relational grammatical categories may express grammatical properties of a child constituent , such as a gender , a number and so on , which depend on properties of the parent constituent .", "label": "", "metadata": {}, "score": "51.090073"}
{"text": "The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non - terminal symbols in this grammar .The learned transformation rules incrementally map a natural - language sentence or its syntactic parse tree into a parse - tree for the target formal language .", "label": "", "metadata": {}, "score": "51.264664"}
{"text": "This algorithm of building 2240 the surface structure is a two - level search with independent selection and filtering at each level .At the upper level hypotheses are generated and assigned their ratings .These hypotheses consist of three components : lexical meaning , surface slot , and syntactic form .", "label": "", "metadata": {}, "score": "51.315865"}
{"text": "[0151 ] The syntforms 812 and the surface slots 815 that are significant for this lexeme are selected with the help of the bit - mask .In addition , models of the generalized constituents are built because a constituent is generalized not only by lexical meanings and syntactic forms of its core , but also by the fragments it fills .", "label": "", "metadata": {}, "score": "51.34745"}
{"text": "The components of the semantic descriptions 504 are also language - independent and may include , but are not limited to , a semantic hierarchy 910 , deep slots descriptions 920 , a system of semantemes 930 , and pragmatic descriptions 940 .", "label": "", "metadata": {}, "score": "51.347733"}
{"text": "Krifka claims the advantages of structured meanings are twofold : 1 ) We can access the meaning of an item in focus directly , and 2 ) Rooth 's [ 20 ] [ 21 ] alternative semantics can be derived from a structured meaning approach but not vice versa .", "label": "", "metadata": {}, "score": "51.354492"}
{"text": "Preliminary experimental results show that this system can learn correct and useful mappings .The correctness is evaluated by comparing a known lexicon to one learned from the training input .The usefulness is evaluated by examining the effect of using the lexicon learned by WOLFIE to assist a parser acquisition system , where previously this lexicon had to be hand - built .", "label": "", "metadata": {}, "score": "51.372223"}
{"text": "The repeated lexical selection is performed as follows : the lexical meanings which have a syntactic form which is suitable for the parent surface slot , and the lexical selection 2220 in the sub - tree of this constituent is started .", "label": "", "metadata": {}, "score": "51.378845"}
{"text": "A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .", "label": "", "metadata": {}, "score": "51.401768"}
{"text": "The normalization rules 864 are generally used as transformational rules to describe transformations of semantic structures which may be different in various languages .[ 0112 ] FIG .9 illustrates exemplary semantic descriptions .As stated above in reference to FIG .", "label": "", "metadata": {}, "score": "51.419296"}
{"text": "We present a system to translate natural language sentences to formulas in a formal or a knowledge representation language .Our system uses two inverse \u03bb - calculus operators and using them can take as input the semantic representation of some words , phrases and sentences and from that derive the semantic representation of other words and phrases .", "label": "", "metadata": {}, "score": "51.45457"}
{"text": "Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers .Our experiments on two real - world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise .", "label": "", "metadata": {}, "score": "51.490036"}
{"text": "A straightforward method is to find the most recently used possible reference , and use that .Some domain information may be helpful in determining what recently used nouns really are possible for the pronoun to match .For example : .", "label": "", "metadata": {}, "score": "51.532608"}
{"text": "Generally , the properties of new and given are referred to as a word 's discourse status .Definitions of new and given vary .Halliday [ 1 ] defines given as \" anaphorically \" recoverable , while new is defined to be \" textually and situationally non - derivable information \" .", "label": "", "metadata": {}, "score": "51.60221"}
{"text": "Because we do not have gold - standard references for training a secondary conditional reranker , we incorporate weak supervision of evaluations against the perceptual world during the process of improving model performance .All these approaches are evaluated on the two publicly available domains that have been actively used in many other grounded language learning studies .", "label": "", "metadata": {}, "score": "51.71772"}
{"text": "0121 ] Each lexical meaning 1012 is connected with its deep model 912 , which is described in language - independent terms , and surface model 810 , which is language - specific .Diatheses can be used as the interface between the surface models 810 and the deep models 912 for each lexical meaning 1012 or for a part of speech with some specific grammatical value .", "label": "", "metadata": {}, "score": "51.766052"}
{"text": "A system which is based on purely statistical approach would not know anything about the connections between these variants and would not be able to obtain a correct translation of one phrase on the basis of another .In addition , most - used probabilistic ( statistic ) approaches and statistics - based systems have a common drawback of taking no consideration of semantics .", "label": "", "metadata": {}, "score": "51.786213"}
{"text": "^ Schwarzschild , R. ( 1997 ) , Why Some Foci Must Associate , Unpublished ms . , Rutgers University .^ Vallduvi , E. ( 1990 ) , The Information Component , Ph.D. thesis , University of Pennsylvania .^ a b Williams , E. ( 1997 ) , Blocking and Anaphora , Linguistic Inquiry 28(4 ) , 577 - 628 .", "label": "", "metadata": {}, "score": "51.82161"}
{"text": "Integral models for describing the syntax and semantics of the source language are used in order to recognize the meanings of the source sentence , analyze and translate complex language structures , and correctly convey information encoded in the source sentence .", "label": "", "metadata": {}, "score": "51.834877"}
{"text": "Processing a sentence syntactically involves determining the subject and predicate and the place of nouns , verbs , pronouns , etc .I must again mention that tokenization must occur to get to the point of enabling syntactic analysis .Every programming language compiler or interpreter must have some kind of built - in tokenizer that affords recognition of the ASCII characters typed at the keyboard or input from a file as data or commands of a particular type .", "label": "", "metadata": {}, "score": "51.955914"}
{"text": "Verbs commonly have senses that correspond to n - ary predicates .Allen points out that other systems of semantic representation besides the type he uses have ways of making similar distinctions .Continuing the similarity with FOPC , logical operators are also used .", "label": "", "metadata": {}, "score": "51.95803"}
{"text": "It has a large list of common terms classified into parts of speech .It looks for such terms , matches them to the proper part of speech , and then tries to classify the larger phrase including the term .This clues it into the sentence structure .", "label": "", "metadata": {}, "score": "51.992126"}
{"text": "This puts the machine in a particular state to expect only certain kinds of words to follow , such as a verb .The next word is then read in , and the machine moves from one state to another .Eventually the machine will be able to report the parts of the sentence , and remove some types of possible ambiguity .", "label": "", "metadata": {}, "score": "52.000004"}
{"text": "[ 1 ] Focus is related to information structure .Contrastive focus specifically refers to the coding of information that is contrary to the presuppositions of the interlocutor .[ 2 ] [ 3 ] [ 4 ] .Information structure has been described at length by a number of linguists as a grammatical phenomenon .", "label": "", "metadata": {}, "score": "52.020164"}
{"text": "Semantic knowledge : how words have \" meaning \" ; how words have reference ( denotation ) and associated concepts ( connotations ) .Pragmatic knowledge : \" how sentences are used in different situations and how use affects the interpretation of the sentence , \" this involves the intentions and context of the conversation .", "label": "", "metadata": {}, "score": "52.056355"}
{"text": "^ Halliday , M.A.K. ( 1967 ) , Notes on Transitivity and Theme in English , New York : Academic Press .^ Weil , H. ( 1887 ) , The order of words in ancient languages compared with that of modern languages , Boston : Ginn .", "label": "", "metadata": {}, "score": "52.06585"}
{"text": "Apparently if it has trouble resolving the referent of a pronoun it can ask the user to clarify who or what the referent is .Using this information and the best match for the structure , PT - Thinker can then accept the statement , and tell you that , and then later answer questions that refer back to that statement .", "label": "", "metadata": {}, "score": "52.09552"}
{"text": "Just as in the case of syntactic analysis , statistics might be used to disambiguate words into the most likely sense .Pragmatics .So far we have discussed the processes of arriving at the syntactic representation of a sentence or clause and the semantic meaning , the logical form , or the sentence or clause .", "label": "", "metadata": {}, "score": "52.096737"}
{"text": "Thus the intent seems to be to make it closer to the notion of a proposition than to the original sentence .I follow Allen 's distinctions here .This context independent sense , or logical form , is the meaning .", "label": "", "metadata": {}, "score": "52.1167"}
{"text": "ML ID : 273 . \"Grounded \" language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts .Borschinger et al .( 2011 ) introduced an approach to grounded language learning based on unsupervised PCFG induction .", "label": "", "metadata": {}, "score": "52.138306"}
{"text": "Thus , the semantic normalization rules 864 can be used prior to calculating the semantemes and after calculating the semantemes using the respective semantic normalization rules 864 .[ 0217 ]In general , rules used during the semantic analysis 550 are applied to the constituents of the semantic structure 2002 from the top down ; from a parent constituent to child constituents .", "label": "", "metadata": {}, "score": "52.178383"}
{"text": "The local discourse context , generated from the sentences in the segment .The semantic content of the segment sentences and the semantic relationships that make them cohere .The NLP then can process sentences as belonging to a particular segment and then use this information to resolve ambiguity and supply implied information .", "label": "", "metadata": {}, "score": "52.178776"}
{"text": "This paper presents a general framework , learning search - control heuristics for logic programs , which can be used to improve both the efficiency and accuracy of knowledge - based systems expressed as definite - clause logic programs .The approach combines techniques of explanation - based learning and recent advances in inductive logic programming to learn clause - selection heuristics that guide program execution .", "label": "", "metadata": {}, "score": "52.200684"}
{"text": "The resulting semantic structure 2002 is a tree ( containing established non - tree links ) , with language - independent semantic classes as nodes and a set of semantemes and deep slots as branches .[ 0214 ] At the step 2020 , communicative semantemes for constituents in the semantic structure 2002 are calculated using semantemes calculating rules 862 and communicative descriptions 880 .", "label": "", "metadata": {}, "score": "52.308277"}
{"text": "She does not fully articulate the notion of discourse status and its relation to accent marking .Schwarzschild differs from Selkirk in that he develops a more robust model of discourse status .Discourse status is determined via the entailments of the context .", "label": "", "metadata": {}, "score": "52.33487"}
{"text": "Natural language understanding ( NLU ) aims to map sen - tences to their semantic mean representations .Statistical approaches to NLU normally require fully - annotated train - ing data where each sentence is paired with its word - level semantic annotations .", "label": "", "metadata": {}, "score": "52.35965"}
{"text": "Further abilities of the NLP system to interpret natural language conversations involve the notions of expectations , scripts and plans .First let 's talk of expectations .With respect to an input sentence , the content of the previous sentences and any inferences made in interpreting these sentences will form what might be called the \" specific setting .", "label": "", "metadata": {}, "score": "52.36423"}
{"text": "No . 11/548,214 , filed Oct. 10 , 2006 and in U.S. patent application Ser .No .11/690,099 , 11/690,102 , and 11/690,104 filed Mar. 22 , 2007 , may be used .The system provides syntactically coherent output .Syntactic and morphological descriptions of the input and output languages are used for this purpose .", "label": "", "metadata": {}, "score": "52.37136"}
{"text": "Or , after the original consideration of the first possibility with the rewrite , it can move on to the next part of the sentence directly , rather than considering all the possibilities generated for the first part of the first part of the first part , etc .", "label": "", "metadata": {}, "score": "52.492115"}
{"text": "[ 0137 ] To build all possible constituents , every element of the source sentence 512 which is not a space or a punctuator is viewed as a potential core of a constituent .The building of the graph 1202 of generalized constituents starts with building those constituents which have only the core word form and further expands to build constituents of the next level by including neighboring constituents .", "label": "", "metadata": {}, "score": "52.50687"}
{"text": "So , the graph of precise constituents represents a set of possible trees -- syntactic trees , because each slot can have several alternative fillers .The fillers with the best rating may form a precise constituent ( a tree ) with the best rating .", "label": "", "metadata": {}, "score": "52.51774"}
{"text": "But it is overwhelmingly plausible that even if syntax is not fully independent of semantics , we can not explain all syntactic regularities semantically .Thus the proposal is that compositionality is a contingent linguistic universal .It has the same status as the syntactic hypothesis that in natural languages all branching in a phrase structure tree is binary or the semantic hypothesis that in natural languages all quantificational determiners are conservative .", "label": "", "metadata": {}, "score": "52.5328"}
{"text": "Since PT - thinker is written in Prolog , presumably it uses a top - down , depth - first algorithm , but personally I ca n't ascertain this from my scan of the parser code .It seems to have the ability to keep track of some intrasentence context information , such as person ( first , second , etc . ) and tense , so in this sense it does n't look like its grammar is context free .", "label": "", "metadata": {}, "score": "52.55246"}
{"text": "The preliminary assembly 1210 is performed early during the rough syntactic analysis 530 before building 1220 of generalized constituents and building 1230 of the generalized constituent models to cover all the boundaries of the whole sentence .[ 0144 ] Building 1220 of generalized constituents generally require that all possible pairs of the lexical meaning 1012 and the grammatical value 814 are found or assigned for each of the constituents and attach the surface slots of the child constituents thereof to each of the constituents .", "label": "", "metadata": {}, "score": "52.56976"}
{"text": "[ 16 ] .Selkirk [ 14 ] [ 15 ] develops an explicit account of how F - marking propagates up syntactic trees .Accenting indicates F - marking .F - marking projects up a given syntactic tree such that both lexical items , i.e. terminal nodes and phrasal levels , i.e. nonterminal nodes , can be F - marked .", "label": "", "metadata": {}, "score": "52.578293"}
{"text": "Open - text ( or open - domain ) semantic parsers are designed to interpret any statement in natural language by inferring a corresponding meaning representation ( MR ) .Unfortunately , large scale systems can not be easily machine - learned due to lack of directly supervised data .", "label": "", "metadata": {}, "score": "52.606297"}
{"text": "Open - text ( or open - domain ) semantic parsers are designed to interpret any statement in natural language by inferring a corresponding meaning representation ( MR ) .Unfortunately , large scale systems can not be easily machine - learned due to lack of directly supervised data .", "label": "", "metadata": {}, "score": "52.606297"}
{"text": "Second , and related to this , there may be several possible interpretations of the structure of a sentence .How are we to decide which is the correct analysis ?Third , in searching for the interpretation of a sentence , there may be different ways to do this , some more efficient than others .", "label": "", "metadata": {}, "score": "52.669945"}
{"text": "In a complete database - query application , parsers learned by CHILL outperform an existing hand - crafted system , demonstrating the promise of empricial techniques for automating the construction certain NLP systems .ML ID : 71 .Semantic Lexicon Acquisition for Learning Parsers [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney 1997 .", "label": "", "metadata": {}, "score": "52.69877"}
{"text": "[0114 ] Each semantic class in the semantic hierarchy 910 is supplied with a deep model 912 .The deep slots 914 express semantic relationships between constituents , including , for example , \" agent \" , \" addressee \" , \" instrument \" , \" quantity \" , etc .", "label": "", "metadata": {}, "score": "52.744892"}
{"text": "Performing the precise syntactic analysis may require the use of the syntactical descriptions 502 , the lexical descriptions 503 , and the semantic descriptions 504 .Step 544 indicates that the syntactic analysis is performed repeatedly if the best syntactic structure 546 is not successfully built .", "label": "", "metadata": {}, "score": "52.79098"}
{"text": "Semantic parsing , on the other hand , involves deep semantic analysis in which word senses , semantic roles and other components are combined to produce useful meaning representations for a particular application domain ( e.g. database query ) .Prior research in machine learning for semantic parsing is mainly based on inductive logic programming or deterministic parsing , which lack some of the robustness that characterizes statistical learning .", "label": "", "metadata": {}, "score": "52.814747"}
{"text": "A compositional - semantics procedure is then used to map the augmented parse tree into a final meaning representation .Training the system requires sentences annotated with augmented parse trees .We evaluate the system in two domains , a natural - language database interface and an interpreter for coaching instructions in robotic soccer .", "label": "", "metadata": {}, "score": "52.832275"}
{"text": "First , parsing searching methods can be top - down or bottom - up .A top - down strategy starts with S and searches through different ways to rewrite the symbols until it generates the input sentence ( or it fails ) .", "label": "", "metadata": {}, "score": "52.850807"}
{"text": "1B illustrates still another embodiment of the method for translating a document in a source language into a document in an output language .[ 0024 ] FIG .2 illustrates an embodiment of the method for translating the document fragments by means of a translation database , a terminology dictionary , and a translation dictionary .", "label": "", "metadata": {}, "score": "52.85168"}
{"text": "Some semantemes may be realized only by means of substituting auxiliary words into the parent constituent , for example , modal or auxiliary verbs .In this case , the rule creates and substitutes a new parent constituent .The new parent constituent contains a semantic class which is attached to a slot of the initial parent constituent .", "label": "", "metadata": {}, "score": "52.868088"}
{"text": "Another attempt to avoid ambiguity is based not on the encoding of heuristic rules but on probability theory .The basic idea is that alternative syntactic analyses can be accorded a probability , and the algorithm can be directed to pursue interpretations having the highest probability .", "label": "", "metadata": {}, "score": "52.876816"}
{"text": "So we have to go further in our analysis .In processing a natural language , some types of ambiguity arise that can not be resolved without consideration of the context of the sentence utterance .General knowledge about the world may be involved as well as specific knowledge about the situation .", "label": "", "metadata": {}, "score": "52.893726"}
{"text": "Our system produces improved results on standard corpora on natural language interfaces for robot command and control and database queries . \" ...Natural language understanding ( NLU ) aims to map sen - tences to their semantic mean representations .Statistical approaches to NLU normally require fully - annotated train - ing data where each sentence is paired with its word - level semantic annotations .", "label": "", "metadata": {}, "score": "52.89467"}
{"text": "Empirical methods for building natural language systems has become an important area of research in recent years .Most current approaches are based on propositional learning algorithms and have been applied to the problem of acquiring broad - coverage parsers for relatively shallow ( syntactic ) representations .", "label": "", "metadata": {}, "score": "52.90098"}
{"text": "We present a system to translate natural language sentences to formulas in a formal or a knowledge representation language .Our system uses two inverse \u03bb - calculus operators and using them can take as input the semantic representation of some words , phrases and sentences and from that derive the sema ... \" .", "label": "", "metadata": {}, "score": "52.948715"}
{"text": "However , it is not always possible to restrict the set of possible alignments to such limited numbers .Thus , we present another system that allows each sentence to be aligned to one of exponentially many connected subgraphs without explicitly enumerating them .", "label": "", "metadata": {}, "score": "52.95227"}
{"text": "They can also provide insight into important issues in human language acquisition .However , within AI , computational linguistics , and machine learning , there has been relatively little research on developing systems that learn such semantic parsers .This paper briefly reviews our own work in this area and presents semantic - parser acquistion as an important challenge problem for AI .", "label": "", "metadata": {}, "score": "53.015747"}
{"text": "This is known as association with focus .[ 13 ] It is claimed that focus operators must c - command their focus .Beginning with Rooth , [ 20 ] [ 21 ] the effects of focus on semantics can be said to be the introduction of a set of alternatives that contrasts with the ordinary semantic meaning of a sentence .", "label": "", "metadata": {}, "score": "53.0437"}
{"text": "The rule must attach the current constituent to the deep slot of the substituted parent constituent .For the semantic class of new parent constituent the lexical selection 2220 in the sub - tree of this constituent is executed .[ 0244 ] During building 2240 the surface structure , for each hypothesis about surface structure of a constituent all syntactic forms which correspond to the calculated grammatical value are detected , and each hypothesis is considered separately for each detected syntactic form .", "label": "", "metadata": {}, "score": "53.053352"}
{"text": "0170 ]The best syntactic tree is selected as the syntactic structure hypothesis with the highest rating value available from the graph 1202 of the generalized constituents .This syntactic tree is considered as the best ( the most probable ) hypothesis about the syntactic structure of the source sentence 512 .", "label": "", "metadata": {}, "score": "53.07506"}
{"text": "No generative syntax , no complex thoughts , no unbounded structures .The syntax generates the structures that the semantics ( and phonology ) interprets .But , the semantics and phonology as such have no generative powers .If PoSt holds true then the first interpretation of the AoS follows .", "label": "", "metadata": {}, "score": "53.087822"}
{"text": "One author notes two opposite approaches to natural language processing .One approach tries to use all the information in a sentence , as a human would , with the goal of making the computer able to process to the degree that it could converse with a human .", "label": "", "metadata": {}, "score": "53.105152"}
{"text": "I conjecture that all these moves would burden the syntax and/or the semantics of traffic signs with implausible features . )[ Sign images are from the Manual of Traffic Signs , by Richard C. Moeur .]This is not a substantive claim as long as we keep in mind the difference between linguistic understanding and utterance understanding .", "label": "", "metadata": {}, "score": "53.154987"}
{"text": "For example , \" t1 .We earlier gave some examples of the importance of general knowledge .But some problems in interpreting a natural language sentence involve bringing in not general knowledge but the more particular local discourse context ( the conversation ) .", "label": "", "metadata": {}, "score": "53.159676"}
{"text": "The two models we present overcome such limitations by employing a learned semantic lexicon as a basic correspondence unit between NL and MR for PCFG rule generation .Finally , we present a method of adapting discriminative reranking to grounded language learning in order to improve the performance of our proposed generative models .", "label": "", "metadata": {}, "score": "53.17373"}
{"text": "The number of grammar rules for a natural language is large .And contextual information within the sentence can be useful in analyzing a natural language .So many natural language parsers make use of a different grammar and a different parser to go with this grammar .", "label": "", "metadata": {}, "score": "53.19467"}
{"text": "In natural language acquisition , it is difficult to gather the annotated data needed for supervised learning ; however , unannotated data is fairly plentiful .Active learning methods ( Cohn , Atlas , & Ladner , 1994 ) attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .", "label": "", "metadata": {}, "score": "53.34277"}
{"text": "Initial experiments show that this approach is able to construct accurate parsers which generalize well to novel sentences and significantly outperform previous approaches to learning case - role mapping based on connectionist techniques .Planned extensions of the general framework and the specific applications as well as plans for further evaluation are also discussed .", "label": "", "metadata": {}, "score": "53.366077"}
{"text": "0093 ] At step 560 , syntactic structure synthesis is performed on the language - independent semantic structure 552 to build a surface / syntactic structure 562 .The syntactic structure synthesis may include , but not limited to , performing a lexical selection on the language - independent semantic structure 552 using the linguistic descriptions of the output language .", "label": "", "metadata": {}, "score": "53.431274"}
{"text": "Syntactic analysis .Semantic analysis .Pragmatics .For the most part there is agreement on what fits into each of these categories .I use the term \" pragmatics \" here broadly ; some authors use it more narrowly and add categories that I consider to be within pragmatics broadly .", "label": "", "metadata": {}, "score": "53.502884"}
{"text": "[ 0006 ] One of the traditional approaches is based on translation rules or transformation rules and is called Rule - Based MT ( RBMT ) .This approach , however , is rather limited when it comes to working with complex language phenomena .", "label": "", "metadata": {}, "score": "53.51069"}
{"text": "[ 0128 ] The morphological descriptions 501 for the source language ( e.g. , the word - inflexion description 710 and the word - formation description 730 , etc . ) are used to provide a set of lexemes for each word form .", "label": "", "metadata": {}, "score": "53.522514"}
{"text": "Focus was later suggested to be a structural position at the beginning of the sentence ( or on the left periphery ) in Romance languages such as Italian , as the lexical head of a Focus Phrase ( or FP , following the X - bar theory of phrase structure ) .", "label": "", "metadata": {}, "score": "53.550957"}
{"text": "Rules 2224 of lexical selection and structure correction are connected with deep slots 914 and transform a sub - tree with the current constituent at the top .During this process the rules can substitute a new parent constituent .Since the category of electiveness is calculated and not assigned in the lexical description 503 , this selection condition can not be described in the semantic hierarchy 910 but can only be specified with the help of the rule 2224 of lexical selection and structure correction .", "label": "", "metadata": {}, "score": "53.579323"}
{"text": "Additionally , information can be stored about the correspondences between the fragment boundaries in the source and output languages .[ 0071 ] The step 230 of editing a fragment is optional , but in some cases it may be practical to give the user the opportunity to correct the obtained translation variant as the user sees fit .", "label": "", "metadata": {}, "score": "53.582176"}
{"text": "Next , I present a PCFG induction model for grounded language learning that extends the model of Borschinger , Jones , and Johnson ( 2011 ) by utilizing a semantic lexicon .Our model overcomes such limitations by employing a semantic lexicon as the basic building block for PCFG rule generation .", "label": "", "metadata": {}, "score": "53.582928"}
{"text": "0181 ] The masks of grammemes for all child constituents which could be attached are merged .The mask on grammatical values of the parent constituent is used for calculating its grammatical value .For example , when child constituents are attached , the grammatical value of the syntactic form according to its correspondence with the child constituents is defined more precisely .", "label": "", "metadata": {}, "score": "53.61267"}
{"text": "A database of this kind may be generated automatically by merging several databases with identical or close ratings , in which case multiple translation variants , if any , will be assigned different ratings .[ 0064 ] After the translation database is created or selected from the available databases , step 110 is applied .", "label": "", "metadata": {}, "score": "53.686363"}
{"text": "Sometimes it is the specific knowledge of the situation that enables you to sort out the referent of a noun phrase or resolve other ambiguities .Without the inference techniques the knowledge in the knowledge base will be useless .As already mentioned , the language used to define the KB will be the knowledge representation language , and while this could be the same as the logical form language , Allen thinks it should be different for reasons of efficiency .", "label": "", "metadata": {}, "score": "53.700584"}
{"text": "Each constituent has also a syntactic value ( S - value ) , expressed as the grammemes of the syntactic categories thereof .These grammemes are the properties of the syntactic forms selected for the constituent during the precise syntactic analysis 540 .", "label": "", "metadata": {}, "score": "53.74268"}
{"text": "Empirical results show that the learned parsers generalize well to novel sentences and out - perform previous approaches based on connectionist techniques .ML ID : 25 .Learning Search - Control Heuristics for Logic Programs : Applications to Speedup Learning and Language Acquisition [ Details ] [ PDF ] John M. Zelle March 1993 .", "label": "", "metadata": {}, "score": "53.758194"}
{"text": "This process is intelligent , but the main problem of such systems is that the used linguistic descriptions must be exhaustive and complete .The more complete the descriptions , the better the quality of translation .However , the creation of such linguistic descriptions is a long and labor - intensive process , as most of the work must be done manually .", "label": "", "metadata": {}, "score": "53.78322"}
{"text": "Further , each surface slot in a syntform can have grammatical and semantic restrictions on their fillers .[0105 ] Linear order description 816 is represented as linear order expressions which are built to express a sequence in which various surface slots 815 can occur in the sentence .", "label": "", "metadata": {}, "score": "53.818935"}
{"text": "Experimental results with a complete database - query application for U.S. geography show that CHILL is able to learn parsers that outperform a pre - existing , hand - crafted counterpart .These results demonstrate the ability of a corpus - based system to produce more than purely syntactic representations .", "label": "", "metadata": {}, "score": "53.82894"}
{"text": "As previously mentioned , pitch accenting can relate to focus .Accented words are often said to be in focus or F - marked often represented by F - markers .The relationship between accent placement is mediated through the discourse status of particular syntactic nodes .", "label": "", "metadata": {}, "score": "53.834442"}
{"text": "Morphemes include \" run , \" \" laugh , \" \" non-, \" \" -s , \" and \" -es .\" Programs can be written to process tokens of words or even the more basic level of morphemes .Syntactic knowledge : how sequences of words form correct sentences .", "label": "", "metadata": {}, "score": "53.863655"}
{"text": "In the future , we intend to pursue several directions in developing more accurate semantic parsing algorithms and automating the annotation process .This work will involve exploring alternative tree representations for better generalization in parsing .We also plan to apply discriminative reranking methods to semantic parsing , which allows exploring arbitrary , potentially correlated features not usable by the baseline learner .", "label": "", "metadata": {}, "score": "53.875183"}
{"text": "So a good grammar will have generality , selectivity , and understandability .We must note that there are two different grammars or senses of \" grammar \" being considered here .First , as a method or set of rules for constructing sentences in a particular language , a grammar defines whether a sentence is constructed correctly ( maybe a purported sentence is not even a sentence if it does n't follow the grammar ) .", "label": "", "metadata": {}, "score": "53.88035"}
{"text": "For example , the user may choose to merge to fragments into one or divide one fragment into two .Once segmenting and editing is completed , the step 110 of translating the document fragments which are already available in a translation database , a terminology dictionary , and a translation dictionary is applied .", "label": "", "metadata": {}, "score": "54.106403"}
{"text": "[ 0200 ] Non - tree links are established on the best syntactic tree 1420 - -the tree of constituents with unambiguously fixed fillers of child slots .However , during the stage 1470 , many different non - tree links for the syntactic tree , which may be the best at the current moment , can be generated .", "label": "", "metadata": {}, "score": "54.135426"}
{"text": "For example , one could classify parsers by grammar , or by algorithm , or by grammar - algorithm combination , or perhaps in some other way .There are several aspects to the algorithm of a parser , so one might even let these differences further influence the classification .", "label": "", "metadata": {}, "score": "54.1858"}
{"text": "In this way some authors write of tokenization as the first step of parsing and preceding syntactic analysis .In this sense tokenization is needed not just for natural language processing but for any language processing on the part of the computer .", "label": "", "metadata": {}, "score": "54.195763"}
{"text": "Let me end with one more quick distinction : The AoS should also be distinguished from another important claim , which I will dub the Primacy of Syntax thesis ( PoSt ) .PoSt is a substantive claim asserting that syntax is where generativity lives .", "label": "", "metadata": {}, "score": "54.200706"}
{"text": "^ Givon , Talmy ( 2001 ) , Syntax : An Introduction Vol .II , Amsterdam : John Benjamins Publishing Co. ^ Lambrecht , Knud ( 1994 ) , Information Structure and Sentence Form : Topic , Focus , and the Mental Representation of Discourse Referents , Cambridge : Cambridge University Press .", "label": "", "metadata": {}, "score": "54.24289"}
{"text": "Some of the applied analysis rules are displayed near rectangles with the semantic class .Deep slots are represented as arrows and named ; for example , Object , Agent , Locative , etc .Non - tree links are represented as dotted arrows .", "label": "", "metadata": {}, "score": "54.264343"}
{"text": "But this will be rare , and so the vocabulary list is going to have to be quite large to do anything useful .And complex sentences can confuse a typical state - machine parser .For example , Chomsky noted that any sentence in English can be extended by appending or including another structure or sentence .", "label": "", "metadata": {}, "score": "54.291306"}
{"text": "Our system produces improved results on standard corpora on natural language interfaces for robot command and control and database queries . \" ...We present a system to translate natural language sentences to formulas in a formal or a knowledge representation language .", "label": "", "metadata": {}, "score": "54.308975"}
{"text": "0139 ]The graph 1202 of generalized constituents is first built as a tree , from the leaves to the root ( bottom up ) .Building of additional constituents is performed bottom - up by attaching child constituents to parent constituents via filling the surface slots 815 of parent constituents to cover all the initial lexical units of the source sentence 512 .", "label": "", "metadata": {}, "score": "54.311928"}
{"text": "0166 ] The precise syntactic analysis 540 is performed to build a syntactic tree , which is a tree of the best syntactic structure 1402 , for the source sentence .Many syntactic structures can be built and the most probable syntactic structure is obtained as the best syntactic structure 1402 .", "label": "", "metadata": {}, "score": "54.38705"}
{"text": "Again , to construct a tree or a list like that above , we must know the rewrite rules that let us replace one part by its components .Recall that a grammar is a formal specification of the structures allowable in the language .", "label": "", "metadata": {}, "score": "54.403107"}
{"text": "Toward this goal , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .With such ambiguous supervision , it is required to resolve the ambiguity between a natural language ( NL ) sentence and a corresponding set of possible logical meaning representations ( MR ) .", "label": "", "metadata": {}, "score": "54.41401"}
{"text": "Currently , there are two central themes in research on focus in generative linguistics .First , given what words or expressions are prominent , what is the meaning of some sentence ?Rooth , [ 20 ] Jacobs , [ 23 ] Krifka , [ 22 ] and von Stechow [ 24 ] claim that there are lexical items and construction specific - rules that refer directly to the notion of focus .", "label": "", "metadata": {}, "score": "54.450645"}
{"text": "The pragmatic context 2044 and the analysis rules 860 , such as the semantemes calculating rules 862 and normalization rules 864 , may be used during semantemes normalization to remove language asymmetries .The semantic normalization rules 864 are applied to remove language asymmetries .", "label": "", "metadata": {}, "score": "54.48133"}
{"text": "Besides being robust , this approach is also flexible and able to learn under a wide range of supervision , from extra to weaker forms of supervision .It can easily utilize extra supervision given in the form of syntactic parse trees for natural language sentences by using a syntactic tree kernel instead of a string kernel .", "label": "", "metadata": {}, "score": "54.49295"}
{"text": "0205 ] The referential and structural control description 856 contains rules which can generate several alternative controlled elements during the stage 1470 .The search for controlled elements can be organized as a call of all the rules in the slots of the syntactic tree which have already been filled .", "label": "", "metadata": {}, "score": "54.537827"}
{"text": "Abstract : .A translation is readily available if a search reveals at least one matching translation for the document fragment in a translation database .Claims : .The method of claim 1 , wherein steps a ) and b ) are performed automatically .", "label": "", "metadata": {}, "score": "54.55133"}
{"text": "[ 13 ] Second , given the meaning and syntax of some sentence , what words or expressions are prominent ?Focus directly affects the semantics , or meaning , of a sentence .Different ways of pronouncing the sentence affects the meaning , or , what the speaker intends to convey .", "label": "", "metadata": {}, "score": "54.580696"}
{"text": "In this proposal , we present a new approach to semantic parsing based on string - kernel - based classification .Our system takes natural language sentences paired with their formal meaning representations as training data .For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .", "label": "", "metadata": {}, "score": "54.587433"}
{"text": "For example , logical form will capture ambiguity but not resolve it , whereas the knowledge representation aims to resolve it .Of course , in very simple NLP systems there might not be any way to handle general world knowledge or specific discourse or situation knowledge , so the logical form is as far as the system will go .", "label": "", "metadata": {}, "score": "54.60594"}
{"text": "Another way to understand this is to .The standard PROLOG interpretation algorithm has the same search strategy as the depth - first , top - down parsing algorithm .This makes PROLOG amenable to reformulating context - free grammar rules as clauses in PROLOG if one wishes to pursue this strategy .", "label": "", "metadata": {}, "score": "54.62341"}
{"text": "Rating scores are calculated and obtained / stored .[0167 ] Hypotheses about the overall syntactic structure of the sentence are generated .Each hypothesis is represented by a tree which is a subgraph of the graph 1202 of the generalized constituents to cover the entire sentence , and rating is calculated for each syntactic tree .", "label": "", "metadata": {}, "score": "54.65857"}
{"text": "[0017 ] For the rest of the fragments ( hereinafter the \" untranslated fragments \" ) a fuzzy search may be used .\" Fuzzy search \" comprises looking for similar sentences in the database .The found sentences may differ from the \" ideal match \" in one or more words , but the matching words are arranged in them in the same order as in the source sentence .", "label": "", "metadata": {}, "score": "54.683556"}
{"text": "In particular , if the translation database is supplied with an index , the index may be used for quick searches .The actions performed at step 110 are described in detail in FIG .2 . [ 0056 ] Additionally , for those fragments for which no translations have been found in the translation database , a terminology dictionary and a translation dictionary may be used .", "label": "", "metadata": {}, "score": "54.756145"}
{"text": "Semantic parsing involves deep semantic analysis that maps natural language sentences to their formal executable meaning representations .This is a challenging problem and is critical for developing computing systems that understand natural language input .This thesis presents a new machine learning approach for semantic parsing based on string - kernel - based classification .", "label": "", "metadata": {}, "score": "54.762184"}
{"text": "The precise constituents are formed into a graph such that a certain constituent can be included into several alternative parent constituents in order to optimize further analysis for selecting syntactic trees .Such an intermediate graph structure is rather compact for calculating structural ratings .", "label": "", "metadata": {}, "score": "54.836044"}
{"text": "All of these tasks are accomplished within the same framework , using a single , general learning method that can acquire new syntactic and semantic categories for resolving ambiguities .Experimental evidence from both aritificial and real - world corpora demonstrate that CHILL learns parsers as well or better than previous artificial neural network or probablistic approaches on comparable tasks .", "label": "", "metadata": {}, "score": "54.916145"}
{"text": "In Backus - Naur form : .An element 's name is on the left and its definition is on the right .The name of only one element appears on the left .The definition consists of terminal and/or nonterminals separated by commas .", "label": "", "metadata": {}, "score": "54.940598"}
{"text": "ML ID : 47 .Acquisition of a Lexicon from Semantic Representations of Sentences [ Details ] [ PDF ] Cynthia A. Thompson In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics ( ACL-95 ) , 335 - 337 , Cambridge , MA , 1995 .", "label": "", "metadata": {}, "score": "54.97288"}
{"text": "Experimental results are presented that demonstrate WOLFIE 's ability to learn useful lexicons for a realistic domain .The lexicons learned by WOLFIE are also compared to those learned by another lexical acquisition system , that of Siskind ( 1996 ) .", "label": "", "metadata": {}, "score": "54.99386"}
{"text": "Variables can be qualified or quantified ( use of \" any \" for example ) .Verbs can be defined as transitive or intransitive ( take a direct object or not ) .But even a DCG parser will not resolve all problems of ambiguity .", "label": "", "metadata": {}, "score": "55.044777"}
{"text": "[ 0074 ] \" Fuzzy search \" comprises finding similar fragments in the database .The found similar fragment may differ from the \" ideal match \" in one or more words , but the matching words in the found fragment must be arranged in exactly the same linear order as in the source fragment .", "label": "", "metadata": {}, "score": "55.04905"}
{"text": "The alignment of parallel texts may be implemented manually or through some automatic method .[ 0015 ] Suppose we have text ( a document ) in a source language .First , the text is segmented or divided into fragments .", "label": "", "metadata": {}, "score": "55.054153"}
{"text": "Structural control check allows filtering out wrong surface structures .The relations between the controlling constituent -- controller -- and the constituent controlled by it are checks .For example , a verb attribute of a noun phrase can generally be expressed by a participial clause or a relative clause .", "label": "", "metadata": {}, "score": "55.057358"}
{"text": "Syntactic analysis gets at the structure or grammar of the sentences .Semantic analysis deals with the meaning of words and sentences , the ways that words and sentences refer to elements in the world . \"Meaning \" in these discussions is usually associated with semantics , but in other contexts I 've seen syntax associated with \" syntactic meaning . \" Pragmatics concerns how the meaning of a sentence depends on its function in everyday life , that is , the larger context of the conversation and so forth , and so it too seems concerned with meaning .", "label": "", "metadata": {}, "score": "55.063377"}
{"text": "In terms of breakthroughs in NLP , it appears to me to be not all that significant , except maybe as a commentary on the replacability of therapists using the client - centered methods of Carl Rogers .In the seventies Roger Schank developed MARGIE , which reduced all English verbs to eleven semantic primitives ( such as ATRANS , or Abstract Transfer , and PTRANS , or Physical Transfer ) .", "label": "", "metadata": {}, "score": "55.111732"}
{"text": "Let 's just say the sentence has a meaning that the processor understands .Also , we 're not going to decide the issue between sentential AI and PDP / connectionist AI perspectives about the form of that meaning in humans , whether it is some sort of internal proposition or representation in the mind or brain of the processor .", "label": "", "metadata": {}, "score": "55.12223"}
{"text": "Syntactic analysis .Let 's proceed then to syntactic analysis .The topic is too big to cover thoroughly here , so I 'm just going to try to summarize the main issues and use examples to give insight into some of the problems that arise .", "label": "", "metadata": {}, "score": "55.13044"}
{"text": "The arrows are marked by the names of the surface slots , such as Modal , Verb , Subject , Demonstrative , etc . , and for some of the surface slots , the corresponding rating scores are shown .[ 0199 ] During the stage 1470 , non - tree links are specified for the best syntactic tree 1420 .", "label": "", "metadata": {}, "score": "55.186142"}
{"text": "The use of heuristics may be pursued to help choose between alternative syntactic analyses , although these heuristic principles may be difficult to encode as rules in a program .Here are two examples of such principles , based on psychological principles humans seem to follow : .", "label": "", "metadata": {}, "score": "55.19151"}
{"text": "A communicative form which realizes communicative semantemes for the syntform must be selected on the basis of communicative description 880 , and the order of slots is synthesized .Communicative forms are searched in the order of their description .The first form which meets all the requirements and includes all slots is selected .", "label": "", "metadata": {}, "score": "55.20715"}
{"text": "Automatic Construction of Semantic Lexicons for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixteenth National Conference on Artificial Intelligence ( AAAI-99 ) , 487 - 493 , Orlando , FL , July 1999 .", "label": "", "metadata": {}, "score": "55.265224"}
{"text": "0058 ]At step 120 , after the source sentence is analyzed , a deep language - independent semantic structure is constructed to represent the meaning of the source sentence .The language - independent semantic structure is a generalized data structure in language - independent form / format used as an intermediate language - independent semantic representation when translating the source sentence from the source language into the output language .", "label": "", "metadata": {}, "score": "55.34777"}
{"text": "[ 0196 ] FIG .15 illustrates schematically an exemplary syntactic tree according to one embodiment of the invention .In FIG .15 , constituents are shown as rectangles , arrows show filled surface slots .A constituent has a word at its core ( Core ) with its morphological value ( M - value ) and semantic parent ( Semantic class ) and can have smaller constituents of the lower level attached .", "label": "", "metadata": {}, "score": "55.349403"}
{"text": "It need not directly represent logical formulas or use theorem proving techniques as a model of inference .Rather , the knowledge representation system could be a semantic network , a connectionist model , or any other formalism that has the proper expressive power .", "label": "", "metadata": {}, "score": "55.418762"}
{"text": "When we converse we sometimes take a brief excursus that shifts focus for a moment , and we must be able to see that , for example , a noun phrase refers back to an earlier focus rather than the excursus .", "label": "", "metadata": {}, "score": "55.472233"}
{"text": "When a precise constituent is analyzed to calculate the rating of the syntactic tree which can be generated on the basis of the precise constituent , child constituents with the best rating are analyzed in every surface slot .[ 0192 ] During the stage 1460 , rating calculation for the second - best syntactic tree differs , but not limited to , in the fact that for one of the child slots , its second - best child constituent is selected .", "label": "", "metadata": {}, "score": "55.54818"}
{"text": "Our results demonstrate that even a small amount of semantic annotations greatly improves the accu - racy of learned dependencies when tested on both in - domain and out - of - domain texts.1 . \" ...This paper presents an effort to enable robots to utilize open - source knowledge resources autonomously for human - robot interaction .", "label": "", "metadata": {}, "score": "55.57229"}
{"text": "Many words , as in the above example , fit into more than one category , thus requiring additional information to be stored and adding complexity and time to the searching routines .But the large lexicon would presumably be needed anyway if we were trying to develop a parser to fully handle a natural language , so whether this will be a special problem caused by this type of parser will depend on what one is trying to do .", "label": "", "metadata": {}, "score": "55.59642"}
{"text": "The next type of parser on the above list is the state - machine parser .It starts by reading the first word in the input sentence .The words read are compared to the vocabulary , and once the type of word is ascertained , the machine predicts the possibilities for the next word .", "label": "", "metadata": {}, "score": "55.599968"}
{"text": "For most natural language processing tasks , a parser that maps sentences into a semantic representation is significantly more useful than a grammar or automata that simply recognizes syntactically well - formed strings .This paper reviews our work on using inductive logic programming methods to learn deterministic shift - reduce parsers that translate natural language into a semantic representation .", "label": "", "metadata": {}, "score": "55.636765"}
{"text": "In syntax this can be done assigning focus markers , as shown in ( 1 ) , or by preposing as shown in ( 2 ) : .( 1 ) I saw [ JOHN ] f .In ( 1 ) , focus is marked syntactically with the subscripted ' f ' which is realized phonologically by a nuclear pitch accent .", "label": "", "metadata": {}, "score": "55.66696"}
{"text": "Experimental results show that the number of examples needed to reach a given level of performance can be significantly reduced with this method .ML ID : 90 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney In Proceedings of the Sixth Workshop on Very Large Corpora , Montreal , Quebec , Canada , August 1998 .", "label": "", "metadata": {}, "score": "55.762177"}
{"text": "Grammemes synthesis rules 2242 calculate grammemes , representing grammatical and morphological values of a constituent , on the basis a set of semantemes , taking into account the initial grammatical value of the lexical meaning , parent surface slot and syntactic form .", "label": "", "metadata": {}, "score": "55.832886"}
{"text": "A set of speakers and hearers .A fixed set of relevant background assumptions .There are two approaches to further delineating segments .An intentional approach holds that the sentences within the segment contribute to a common purpose or communicative goal .", "label": "", "metadata": {}, "score": "55.923218"}
{"text": "Translation databases may be pre - defined or selected by the user .The segmentation is usually performed automatically , but it may also be performed with human assistance .[ 0016 ] Once the document is divided into fragments , the system starts searching for identical fragments in the database(s ) .", "label": "", "metadata": {}, "score": "56.022255"}
{"text": "This has to do with how Prolog reads statements and can not really be explained without going too far into Prolog here . )This obviously gives DCG an advantage over a context - free grammar in handling a natural language .", "label": "", "metadata": {}, "score": "56.034534"}
{"text": "FIG .17 is one of syntactic trees for the sentence extracted from the graph of generalized constituents from FIG .13 , it is the first from generated trees which eventuate successfully of the stage 1470 .So , the tree 1700 is considered as the best syntactic tree .", "label": "", "metadata": {}, "score": "56.10245"}
{"text": "For each deep slot of the parent constituent in its diathesis all surface slots are searched for which meet the diathesis restrictions .At least one slot may be found .If no slot has been found , the returning back 2230 to the stage of lexical selection 2220 is provided , and the lexical meaning which has the next - best rating in the semantic class is selected .", "label": "", "metadata": {}, "score": "56.119305"}
{"text": "[ 0072 ] As a result of step 110 , the source document 102 is , in a general case , partly translated into the output language , i.e. the fragments that have been found in the database are replaced with their translations .", "label": "", "metadata": {}, "score": "56.169067"}
{"text": "The paper gives a very efficient algorithm to compute it .This kernel is also an improvement over the word subsequence kernel because it only counts linguistically meaningful word subsequences which are based on word dependencies .It overcomes some of the difficulties encountered by syntactic tree kernels as well .", "label": "", "metadata": {}, "score": "56.174385"}
{"text": "0125 ] Each surface model 810 of a lexical meaning includes one or more syntforms 812 .Semantic restrictions on a surface slot filler are a set of semantic classes , whose objects can fill a given surface slot .The diatheses 817 are a part of relationship 624 between syntactic descriptions 502 and semantic descriptions 504 , and represent correspondences between , the surface slots 815 and the deep slots 914 of the deep model 912 .", "label": "", "metadata": {}, "score": "56.190323"}
{"text": "\" Fragment \" is a more common notion than \" sentence \" and may describe a paragraph , a sentence , a title , a part of a sentence , a word combination , a noun group , etc . .Also , translation databases may be obtained as result of the alignment ( segmentation ) of existing parallel texts .", "label": "", "metadata": {}, "score": "56.307953"}
{"text": "[0109 ] Communicative descriptions 880 describe a word order in the syntform 812 from the point of view of communicative acts to be represented as communicative order expressions , which are similar to linear order expressions .The government and agreement description 840 contains rules and restrictions on grammatical values of attached constituents which are used during syntactic analysis .", "label": "", "metadata": {}, "score": "56.341892"}
{"text": "A non - tree link of type \" Anaphoric Model -- Subject \" 2410 is established from the constituent \" MaK : BOY \" 2420 to the constituent \" MaK : BOY \" 2430 to identify the subjects of the two parts of the complex sentence .", "label": "", "metadata": {}, "score": "56.35813"}
{"text": "Those hypotheses that may result in a best rating are served at first .For each surface slot 815 , syntactic forms 812 which meet the requirements of the surface slot are searched for .If a suitable syntactic form has not been detected , this hypothesis is penalized by means of rating reduction .", "label": "", "metadata": {}, "score": "56.398216"}
{"text": "0008 ]Another traditional approach is Knowledge - Based MT ( KBMT ) which uses semantic descriptions .While the MBMT approach is based on knowledge about a language , the KBMT approach considers translation as a process of understanding based on real knowledge about the World .", "label": "", "metadata": {}, "score": "56.428238"}
{"text": "An example of a context - free grammar is the following , using an arrow operator to express allowable decomposition : .Abbreviations are also used .So these might be some of the allowable rules in a grammar , and they could be applied as rewrites in a parsing .", "label": "", "metadata": {}, "score": "56.493427"}
{"text": "MARGIE gave way to SAM ( Script Applier Mechanism ) , which was able to translate limited sentences from a variety of languages ( English , Chinese , Russian , Dutch , and Spanish ) .In the late seventies , Scripts resulted in PAM , for Plan Applier Mechanism , from the work of Schank , Abelson , and Wilensky .", "label": "", "metadata": {}, "score": "56.499126"}
{"text": "[0126 ] Referring back to FIG .5 , the lexical analysis 510 is performed on the source sentence 512 represented in a source / input language , which may be any natural language .In one embodiment , all the necessary language descriptions for the source sentence 512 are created .", "label": "", "metadata": {}, "score": "56.522095"}
{"text": "These rules for such substitution are rewrite rules or production rules of how each of the parts may be constructed from others .In the following examples , we 're going to use two expressions of decomposition .The first expression occurs in the statement of the rules themselves .", "label": "", "metadata": {}, "score": "56.523617"}
{"text": "In Proceedings of International Conference on Speech Prosody 2004 , Nara , Japan : 81 - 84 .There are some authors who call the following weaker thesis the principle of compositionality : The meaning of a complex expression is determined by the meaning of its structure and the meanings of its constituents .", "label": "", "metadata": {}, "score": "56.53625"}
{"text": "The non - tree syntax description 850 include ellipsis description 852 , coordination description 854 , as well as , referential and structural control description 856 , among others .[ 0111 ]Analysis rules 860 , as a part of the syntactic descriptions 502 , may include , but are not limited to , semantemes calculating rules 862 and normalization rules 864 .", "label": "", "metadata": {}, "score": "56.60018"}
{"text": "[0065 ] FIG .1B illustrates still another example of the method 100 for translating the document 102 in a source language into the output document 104 in an output language .As in the previously described embodiment , this example may also include the step 105 of creating or selecting the translation database .", "label": "", "metadata": {}, "score": "56.613712"}
{"text": "Second , the intuitive version of this interpretation of the AoS has been regularly violated in practice from the earliest days of generative grammar .Indeed , this is so for all cases of movement .Perhaps this version of the AoS had greater purchase in the Aspects era when the Katz - Postal hypothesis ( KPH ) was widely adopted .", "label": "", "metadata": {}, "score": "56.630074"}
{"text": "It encounters the first word in the sentence to be a noun , and so the rest is considered a verb phrase .Obviously though , the vocabulary is going to have to be quite large to pick up on all possible nouns , etc . .", "label": "", "metadata": {}, "score": "56.645424"}
{"text": "Tutorial on semantic parsing presented at ACL 2010 : .Using natural language to write programs is a touchstone problem for computational linguistics .We present an approach that learns to map natural - language descriptions of simple \" if - then \" rules to executable code .", "label": "", "metadata": {}, "score": "56.662525"}
{"text": "A plan , a set of actions , is used to achieve a goal , and this notion can be used by the NLP to infer the plan of an agent based on the agent 's actions .This is plan recognition or plan inference .", "label": "", "metadata": {}, "score": "56.69609"}
{"text": "Allen mentions the varied types of knowledge relevant to natural language understanding 8 : .Phonetic and phonological knowledge : how words are related to sounds .Morphological knowledge : how words are built from more primitive morphemes ( e. g. , how \" friendly \" comes from \" friend . \"", "label": "", "metadata": {}, "score": "56.744614"}
{"text": "It can take the first constituent and consider the possibilities for that , which might break it down into two constituents , and then take the first constituent of that part , etc .It goes all the way down those first possibilities before it back tracks one level and tries the second possibility of the lowest level rewrite .", "label": "", "metadata": {}, "score": "56.771282"}
{"text": "Each applied rule determines more accurately the grammatical meaning of the constituent as it is written in the applied productions .If a production tries to assign to a constituent a grammatical value that contradicts the value that the constituent already has , such a production will not work even if its requirement is met by the current constituent .", "label": "", "metadata": {}, "score": "56.78069"}
{"text": "We also present a novel algorithm for learning which events are worth describing .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans for our limited domain .", "label": "", "metadata": {}, "score": "56.805763"}
{"text": "[ 1 ] .The second interpretation of the AoS is more theory internal : it asserts that the application of syntactic operations is not conditional on semantic factors .Here is a useful formulation stolen form a handout of Fritz Newmeyer .", "label": "", "metadata": {}, "score": "56.81463"}
{"text": "Rough Syntactic Analysis .[ 0135 ]During the rough syntactic analysis , as shown on FIG .12 , a graph 1202 of generalized constituents is build from the lexical - morphological structure 1201 of the source sentence 512 .All the possible surface syntactic models for each element of lexical - morphological structure 1201 are applied , and all the possible constituents are built and generalized .", "label": "", "metadata": {}, "score": "56.827404"}
{"text": "In general , contact pairs of constituents representing contact groups of words in the sentence can be included in the request queue .[ 0155 ] A constituent can be attached to different surface slots of another constituent and a child constituent can be attached to different parent constituents .", "label": "", "metadata": {}, "score": "56.8402"}
{"text": "I will first present a system we completed that can describe events in RoboCup 2D simulation games by learning only from sample language commentaries paired with traces of simulated activities without any language - specific prior knowledge .By applying an EM - like algorithm , the system was able to simultaneously learn a grounded language model as well as align the ambiguous training data .", "label": "", "metadata": {}, "score": "56.869118"}
{"text": "[0068 ] At step 210 , the document fragments for which exact matches have been found in a translation database may be substituted with their translations .These exact matches are known as matching translations .If the text was segmented into fragments manually or automatically by employing a special algorithm , the system searches only for exact matches .", "label": "", "metadata": {}, "score": "56.871246"}
{"text": "This new precise constituent in its turn generates a syntactic tree with the second - best value of the rating score .Accordingly , on the basis of the precise constituent , the best syntactic tree may be obtained , and a new precise constituent may be built .", "label": "", "metadata": {}, "score": "56.8984"}
{"text": "Allen notes that there is no consensus on how segmentation should be done or on what the segments of a particular discourse are , though almost all researchers share the intuition that some sentences group together into such units .But still two important outstanding issues are , first , techniques to analyze sentences within a segment , and second , the relation of segments to one another .", "label": "", "metadata": {}, "score": "56.912106"}
{"text": "^ Dryer , M. S. ( 1994 ) , The pragmatics of association with only , Paper presented at the 1994 Winter Meeting of the L.S.A. Boston , Massachusetts .^ Kadmon , N. ( 2001 ) , Formal Pragmatics : Semantics , Pragmatics , Presupposition and Focus , Oxford : Blackwell .", "label": "", "metadata": {}, "score": "56.964745"}
{"text": "This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with meaning representations .", "label": "", "metadata": {}, "score": "56.976074"}
{"text": "For a semantic parser to work well , conformity between natural language and meaning representation grammar is necessary .However meaning representation grammars are typically designed to best suit the application which will use the meaning representations with little consideration for how well they correspond to natural language semantics .", "label": "", "metadata": {}, "score": "57.0094"}
{"text": "Insofar as some authors talk of signal processing as the conversion of speech into text , and the text is recognized as words , some tokenization might already be involved .However , one might instead think of the signal processing as purely a conversion of audio to some kind of textual stream , with no processing of the stream as words or individual characters per se , i.e. , no data typing on the part of the computer .", "label": "", "metadata": {}, "score": "57.089462"}
{"text": "( 16 ) Definition of given : An utterance of U counts as given if it has a salient antecedent A and .b. otherwise : modulo -type - shifting , A entails the existential F - closure of U. .The operation in ( 16b ) can apply to any constituent .", "label": "", "metadata": {}, "score": "57.13759"}
{"text": "We present a novel statistical approach to semantic parsing , WASP , for constructing a complete , formal meaning representation of a sentence .A semantic parser is learned given a set of sentences annotated with their correct meaning representations .The main innovation of WASP is its use of state - of - the - art statistical machine translation techniques .", "label": "", "metadata": {}, "score": "57.204582"}
{"text": "Experimental results are presented demonstrating WOLFIE 's ability to learn useful lexicons for a database interface in four different natural languages .The lexicons learned by WOLFIE are compared to those acquired by a competing system developed by Siskind ( 1996 ) .", "label": "", "metadata": {}, "score": "57.253937"}
{"text": "This paper describes a system , WOLFIE ( WOrd Learning From Interpreted Examples ) , that learns a semantic lexicon from a corpus of sentences paired with representations of their meaning .The lexicon learned consists of words paired with representations of their meaning , and allows for both synonymy and polysemy .", "label": "", "metadata": {}, "score": "57.28199"}
{"text": "Our immediate question instead is how we are to consider this topic for a computer .I generally follow Allen 's use of terms here , though many other authors have a similar understanding .As we attempt to model natural language processing , if we want to depict or represent the meaning of a sentence for such a model , we ca n't just use the sentence itself because ambiguities may be present .", "label": "", "metadata": {}, "score": "57.291603"}
{"text": "This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus .The approach is built on top of a novel reduction - based weighted synchronous context free grammar formalism , which facilitates the transformation process from typed lambda calculus into natural language sentences .", "label": "", "metadata": {}, "score": "57.339115"}
{"text": "A generator 1485 for generating non - tree links is adapted to perform the stage 1470 .[0176 ] As shown in FIG .14 , the fragment specification 1410 of the precise syntactic analysis 540 is performed initially to consider various fragments which are continuous segments of a parent constituent .", "label": "", "metadata": {}, "score": "57.35012"}
{"text": "[ 0239 ] The hypotheses about surface structure of a constituent are analyzed during building 2240 the surface structure in the order of descending rating .If a suitable syntactic form for an analyzed hypothesis is n't found , an alternative realization rule 2244 may be applied .", "label": "", "metadata": {}, "score": "57.406803"}
{"text": "( 22 ) entails ( 23 ) .Therefore , the VP of ( 21b ) counts as given .Schwarzschild [ 16 ] assumes an optimality theoretic grammar .[ 33 ] Accent placement is determined by a set of violable , hierarchically ranked constraints as shown in ( 24 ) : .", "label": "", "metadata": {}, "score": "57.49829"}
{"text": "It can look for connectives , such as \" then , \" \" either , \" \" both , \" \" and , \" etc . to try to break up a sentence into clauses .It can recognize common greetings such as \" Hello .", "label": "", "metadata": {}, "score": "57.564762"}
{"text": "If the stage 1450 for generating the graph of the precise constituents has failed to produce the graph of the precise constituents 1430 which would cover the entire sentence , a procedure which attempts to cover the sentence with syntactically - separate fragments is initiated .", "label": "", "metadata": {}, "score": "57.62464"}
{"text": "\" Finding \" the \" forced you to backtrack and change the categorization of \" old \" to a noun and \" man \" to a verb .It seems to me that this type of parser pursues a bottom - up , breadth - first strategy .", "label": "", "metadata": {}, "score": "57.65855"}
{"text": "The text may be divided into fragments either manually or automatically by employing a special algorithm .For example , fragments may be identified based on sentence boundaries or based on paragraph boundaries .Finally , the following advanced search method may be used to find the required fragment : the system each time looks in the database for the longest fragment which starts with the current word .", "label": "", "metadata": {}, "score": "57.683746"}
{"text": "A glue interpreter has been integrated with the XLE parser .Current activities focus on : development of broad coverage semantic lexicons ; robust interpretation in response to ill - formed / out - of - coverage input ; further refinements of packed proof - search algorithms for managing syntactic and semantic ambiguity .", "label": "", "metadata": {}, "score": "57.794533"}
{"text": "This will occur for the natural language sentence that is being analyzed , but also for all of the processing commands that the computer is following as it analyzes .How this occurs will involve the particular programming language in which the natural language processing program is written .", "label": "", "metadata": {}, "score": "57.907555"}
{"text": "The semantic normalization rules 864 are lexicalized and linked to specific semantic classes and lexical meanings .There are two types of the semantic normalization rules 864 : rules to be used prior to calculating the semantemes for generating the semantic structure 2002 ; rules to be used after calculating the semantemes .", "label": "", "metadata": {}, "score": "57.96293"}
{"text": "If no translations for the differing parts have been found or if multiple variants have been found , the system may ask the user to type in the translation or to select the best translation from the list of available variants .", "label": "", "metadata": {}, "score": "58.009914"}
{"text": "0140 ] The root of the tree is the main clause , represented by a special constituent corresponding to various types of maximal units of a text analysis ( complete sentences , enumerations , titles , etc . ) .The core of the main clause is generally a predicate .", "label": "", "metadata": {}, "score": "58.086678"}
{"text": "If correct , transformations have to be meaning preserving as their outputs , Surface Structures , do not feed semantic interpretation .In such a context semantic concerns can not motivate a particular transformation .If one identifies \" transformational \" with \" syntactic \" ( a mistake , as Deep Structure is also a syntactic level in an Aspects style theory ) the avoidance of \" semantic \" considerations would make sense .", "label": "", "metadata": {}, "score": "58.09527"}
{"text": "Only in the second instance of \" grammar , \" where it means the method of analysis or the rules used in my natural language processor , can it be good or bad at finding out whether the sentence is proper or improper .", "label": "", "metadata": {}, "score": "58.106476"}
{"text": "The Inverse Entailment approach to ILP , implemented in the Progol and Aleph systems , starts with the construction of a bottom clause , the most specific hypothesis covering a seed example .When mining relational data with a large number of background facts , the bottom clause becomes intractably large , making learning very inefficient .", "label": "", "metadata": {}, "score": "58.133083"}
{"text": "The semantic descriptions 504 , however , are language - independent and are used to describe language - independent semantic features of objects , meanings , processes , events , etc . in various languages and to construct language - independent semantic structures .", "label": "", "metadata": {}, "score": "58.177563"}
{"text": "Training employs only ambiguous supervision consisting of a stream of descriptive textual comments and a sequence of events extracted from the simulation trace .The system simultaneously establishes correspondences between individual comments and the events that they describe while building a translation model that supports both parsing and generation .", "label": "", "metadata": {}, "score": "58.249893"}
{"text": "In this paper , we explored a learning approach which combines different learning methods in inductive logic programming ( ILP ) to allow a learner to produce more expressive hypothese than that of each individual learner .Such a learning approach may be useful when the performance of the task depends on solving a large amount of classification problems and each has its own characteristics which may or may not fit a particular learning method .", "label": "", "metadata": {}, "score": "58.264893"}
{"text": "This attachment is shown by means of arrows named Surface Slot .Each constituent may also include syntactic values and grammatical values , expressed via the grammemes of the syntactic categories thereof .These grammemes are the properties of the syntactic forms selected for the constituent during the building 2240 the surface structure .", "label": "", "metadata": {}, "score": "58.369793"}
{"text": "Next , we describe two PCFG induction models for grounded language learning that extend the previous grounded language learning model of Borschinger , Jones , and Johnson ( 2011 ) .Borschinger et al .'s approach works well in situations of limited ambiguity , such as in the sportscasting task .", "label": "", "metadata": {}, "score": "58.37473"}
{"text": "World knowledge : general knowledge about for example , other users ' beliefs and goals in a conversation .I think Allen uses it in a narrower sense .The result of a human person processing a sentence in a natural language is that the person understands the meaning of the sentence .", "label": "", "metadata": {}, "score": "58.376785"}
{"text": "There are also a number of extensions to basic FOPC that must be made in the logical form language .These include generalized quantifiers , modal operators , and predicate operators , which we will now describe .We already mentioned that the logical form language will have more quantifiers than the two of FOPC .", "label": "", "metadata": {}, "score": "58.429585"}
{"text": "The system of claim 23 , wherein steps a ) and b ) are performed automatically .The system of claim 24 , wherein a translation is readily available if a search reveals at least one matching translation for the document fragment in a translation database .", "label": "", "metadata": {}, "score": "58.437546"}
{"text": "This paper presents approaches for automatically transforming a meaning representation grammar ( MRG ) to conform it better with the natural language semantics .It introduces grammar transformation operators and meaning representation macros which are applied in an error - driven manner to transform an MRG while training a semantic parser learning system .", "label": "", "metadata": {}, "score": "58.44278"}
{"text": "Discussions also distinguish among different types of parser .Here is where things get complicated and sometimes unclear in the literature .Recall that we distinguished among different components that any parser will have : the grammar , the algorithm , and the oracle .", "label": "", "metadata": {}, "score": "58.475372"}
{"text": "It is a methodological principle regulating what counts as a valid motivation for a syntactic proposal .Barbara interprets this to mean that semantic \" facts \" can not justify postulating syntactic structure , only syntactic \" facts \" can .I find this version of the AoS problematic and am unsure if it ever had much of a hold on syntactic practice , though if it did it should n't have .", "label": "", "metadata": {}, "score": "58.525703"}
{"text": "1 illustrates one embodiment of the method for translating a document in a source language into a document in an output language .[ 0022 ]FIG .1A illustrates another embodiment of the method for translating a document in a source language into a document in an output language .", "label": "", "metadata": {}, "score": "58.577515"}
{"text": "0238 ] Since there may be many surface slots 815 meeting the conditions of diatheses 817 for each lexical meaning 1012 , each of these surface slots may be considered as a hypothesis related to a surface structure of a corresponding constituent .", "label": "", "metadata": {}, "score": "58.593674"}
{"text": "Although the system described here could by no means be described as a theory of the syntax - semantics interface , from a practical stand point it can efficiently and robustly produce semantic structures from broad - coverage syntactic ones .citation .", "label": "", "metadata": {}, "score": "58.637665"}
{"text": "The graph of linear division 1440 ( GLD ) can be built as the result of the fragment specification 1410 to reflect the relationships of the parent constituent fragments with the core and child constituents .Additionally , the surface slot for the corresponding child constituents is assigned .", "label": "", "metadata": {}, "score": "58.65267"}
{"text": "The choice of this second word limits what can be used as a third , etc .So the state - machine parser changes its state each time it reads the next word of a sentence , until a final state is reached .", "label": "", "metadata": {}, "score": "58.715748"}
{"text": "which means that most of the objects \" d1 \" that satisfy \" ( DOG1 d1 ) \" also satisfy \" ( BARKS1 d1 ) .\" A type of generalized quantifier is used for the articles \" the \" and \" a. \" To capture the meaning of a sentence , obviously something must do the work of these articles .", "label": "", "metadata": {}, "score": "58.734962"}
{"text": "Generation is when you start from the S symbol and obtain a sequence of words by applying the rewrite rules .These could be applied randomly if you wanted to generate just any old sentence .As we have seen , parsing identifies the structure of the sentence given a particular grammar , so its not going to proceed by randomly applying rules but rather in some systematic fashion .", "label": "", "metadata": {}, "score": "58.748535"}
{"text": "On the notion of focus in spoken Spanish : An empirical approach .In Theory , Practice , and Acquisition , ed . by Paula Kempchinsky and Carlos - Eduardo Pineros .Sommerville : Cascadilla Press , 207 - 226 .Pereltsvaig , Asya ( 2002 ) . '", "label": "", "metadata": {}, "score": "58.831596"}
{"text": "\" The logical form language will allow operators similar to the truth functional connectives in FOPC for disjunction , conjunction , and the conditional ( \" what is often called implication \" ) .Since English terms for and , or , but , etc . can have connotations not captured by the operators and connectives of FOPC , the logical form language will allow for these also .", "label": "", "metadata": {}, "score": "58.928"}
{"text": "By purpose and usage , the system of semantemes 930 may be divided into various kinds , including , but not limited to , grammatical semantemes 932 , lexical semantemes 934 , and classifying grammatical ( differentiating ) semantemes 936 .[ 0118 ] Grammatical semantemes 932 are used to describe grammatical properties of constituents when transforming a syntactic tree ( a language dependent object ) into a semantic structure ( a language independent object ) and backwards during syntactic structure synthesis 560 from the semantic structure .", "label": "", "metadata": {}, "score": "58.933464"}
{"text": "Discriminative Reranking for Semantic Parsing [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of the 21stInternational Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics ( COLING / ACL-06 ) , Sydney , Australia , July 2006 .", "label": "", "metadata": {}, "score": "58.94677"}
{"text": "Each proposition could be a belief .Two spaces would be useful for a conversation , one for the agent 's beliefs and the other to represent its beliefs about the other agent 's beliefs .In particular , the agent must be able to recognize the other agent 's intentions , and for this , plan recognition can be used .", "label": "", "metadata": {}, "score": "58.951008"}
{"text": "ML ID : 45 .Learning Semantic Grammars With Constructive Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In Proceedings of the 11th National Conference on Artificial Intelligence , 817 - 822 , 1993 .", "label": "", "metadata": {}, "score": "58.952797"}
{"text": "( PAST ( SEES1 JOHN1 FIDO1 ) ) ( FUT ( SEES1 JOHN1 FIDO1 ) ) .Now let 's turn to predicates again in this logical form language .We already mentioned that there will be unary , binary , and n - ary predicates .", "label": "", "metadata": {}, "score": "59.00267"}
{"text": "The semantic parents of the lexical meanings are shown by means of a colon and capital letters , for example , \" life : LIVE \" .Grammatical values are displayed in broken brackets .Because the deep slots have already been determined in the end of precise analysis 540 , instead of the surface slots the corresponding deep slots are displayed in FIG .", "label": "", "metadata": {}, "score": "59.02746"}
{"text": "A proform model may include templates ( patterns ) of syntforms .These proform templates determine the required surface slots and their linear order .All constituents in the sentence for each proform are searched and the possibility to attach the constituent to the first of the required slots of the syntform - template is determined .", "label": "", "metadata": {}, "score": "59.079124"}
{"text": "\" We assume the agent realizes we have the goal of actually learning the time , not just whether he knows it .For the natural language processor to interpret such sentences correctly it must have a lot of background information on such scenarios and be able to apply it .", "label": "", "metadata": {}, "score": "59.08384"}
{"text": "5A , 5B , and others .Additionally , as the system may suggest more than one translation variant , the selection 420 of the best variant by the user or by the system is provided ( optionally ) .In the case of selection by the user , the choice is made from the list of suggestions made by the system .", "label": "", "metadata": {}, "score": "59.095825"}
{"text": "Since surface structure is fixed in a given , constituent , adjustments of structural rating scores , including punishing syntforms which are difficult or do not correspond to the style , or rating the communicative linear order , etc . , may be made .", "label": "", "metadata": {}, "score": "59.154636"}
{"text": "Semantic Analysis .[ 0209 ]As shown in FIG .5 , the semantic analysis 550 is performed after precise syntactic analysis 540 when one or more the syntactic trees are formed and the best one with the highest rating score found .", "label": "", "metadata": {}, "score": "59.256073"}
{"text": "One way to represent these states is as nodes in a diagram , with arrowed lines ( arcs ) connecting them .The states and transitions compose the finite - state grammar , which may be called a transition network .We can see that two databases are needed for this kind of parser : one containing a vocabulary of words and their types , and the other containing the current state of the sentence bring parsed .", "label": "", "metadata": {}, "score": "59.26162"}
{"text": "When I use the phrase , I mean human language in all its messiness and varied use .Second , the phrase \" natural language processing \" is not always used in the same way .There is a broad sense and a narrow sense .", "label": "", "metadata": {}, "score": "59.31527"}
{"text": "0234 ] As a result , during the lexical selection 2202 the source semantic structure 2002 may be transformed and each constituent has one or more lexical meaning selected for its core .On such specified semantic structure 2002 with specified lexical meanings of the constituents the building 2240 the surface structure is performed .", "label": "", "metadata": {}, "score": "59.4207"}
{"text": "However , constructing such corpora can be expensive and time - consuming due to the expertise it requires to annotate such data .In this thesis , we explore alternative ways of learning which do not rely on direct human supervision .", "label": "", "metadata": {}, "score": "59.450974"}
{"text": "Amherst : Graduate Linguistics Students Association .^ a b c d Rooth , M. ( 1992 ) , A Theory of Focus Interpretation , Natural Language Semantics 1 , 75 - 116 .^ a b c d Krifka , Manfred ( 1992 ) , \" A Compositional Semantics For Multiple Focus Constructions \" , in Jacobs , Joachim , Informationsstruktur und Grammatik , Opladen : Westdeutscher Verlag , pp .", "label": "", "metadata": {}, "score": "59.464844"}
{"text": "More precisely , an inductive logic programming ( ILP ) method , TABULATE , is developed for learning multiple models that are integrated via linear weighted combination to produce probabilistic models for statistical semantic parsing .Initial experimental results from three different domains suggest that an integration of statistical and logical approaches to semantic parsing can outperform a purely logical approach .", "label": "", "metadata": {}, "score": "59.489548"}
{"text": "For example , pragmatic context may be considered when generating natural language sentences .[0120 ] FIG .10 illustrates exemplary lexical descriptions .The lexical descriptions 503 represent a plurality of lexical meanings 1012 in a specific language .For each lexical meaning 1012 , a link 1002 to its language - independent semantic parent may be established to indicate the location of a given lexical meaning in the semantic hierarchy 910 .", "label": "", "metadata": {}, "score": "59.57023"}
{"text": "Clearly much work remains to be done in the area of developing and perfecting the above techniques .As Allen says \" Significant work needs to be done before these techniques can be applied successfully in realistic domains .Natural language generation .", "label": "", "metadata": {}, "score": "59.593815"}
{"text": "But context - free grammars are a good starting place for understanding the topic .We have n't discussed parsers yet , but I will note that context - free parsers are used in virtually all computer languages , and thus a natural language parser can use some of the parsing techniques developed for such contexts .", "label": "", "metadata": {}, "score": "59.61245"}
{"text": "Once the communicative semantemes are calculated at step 2020 , all other semantemes can be calculated , replacing grammemes with the resulting calculated semantemes .The communicative semantemes are used to express the communicative properties of a sentence , such as the standard linear order , the inverse linear order of a relative clause , or the linear order of an interrogative sentence .", "label": "", "metadata": {}, "score": "59.635128"}
{"text": "For every production in the formal language grammar , a Support - Vector Machine ( SVM ) classifier is trained using string similarity as the kernel .Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these classifiers .", "label": "", "metadata": {}, "score": "59.65893"}
{"text": "At the stage 1460 , these alternatives are searched and one or more trees with a fixed syntactic structure are built .Non - tree links in the built trees are not defined yet .The result of this step is a set of best syntactic trees 1420 which have the best rating values .", "label": "", "metadata": {}, "score": "59.686214"}
{"text": "In order to synthesize the syntactically and stylistically correct English phrase \" two pieces of news \" , the following structure correction rule may be used : \" NEWS \" [ Quantity : x , ?These rules are lexicalized , i.e. they are connected with ( assigned to ) certain objects of the semantic hierarchy 910 and are only called when such an object is the core of the initial constituent .", "label": "", "metadata": {}, "score": "59.695633"}
{"text": "Plan recognition also involves the fact that understanding natural language often requires understanding of the intentions of the agents involved .We assume that people do not act randomly but have goals and their actions are part of a plan for reaching the goal .", "label": "", "metadata": {}, "score": "59.711815"}
{"text": "These rules are shown in ( 1 ) and ( 2 ) : .a. F - marking the head of a phrase licenses F - marking of the phrase .b. F - marking of the internal argument of a head licenses the F - marking of the head .", "label": "", "metadata": {}, "score": "59.749817"}
{"text": "One core issue toward this goal is \" grounded \" language learning , a process of learning the semantics of natural language with respect to relevant perceptual inputs .In order to ground the meanings of language in a real world situation , computational systems are trained with data in the form of natural language sentences paired with relevant but ambiguous perceptual contexts .", "label": "", "metadata": {}, "score": "59.762486"}
{"text": "If for such a predicate , a proposition containing it can not be proven true , then its negation is assumed to be true .We already mentioned that Allen 's KRL resembles FOPC in including quantification and truth - functional connectives or operators .", "label": "", "metadata": {}, "score": "59.763683"}
{"text": "But on the face of it , at least , it would seem to be a great thing if we could converse with computers as we do with one another .What does natural language processing include ?Broadly construed , natural language processing ( with respect to the interpretation side ) is considered to involve at least the following subtopics 5 : .", "label": "", "metadata": {}, "score": "59.83181"}
{"text": "Learning Language Semantics from Ambiguous Supervision [ Details ] [ PDF ] Rohit J. Kate and Raymond J. Mooney In Proceedings of the 22nd Conference on Artificial Intelligence ( AAAI-07 ) , 895 - 900 , Vancouver , Canada , July 2007 .", "label": "", "metadata": {}, "score": "59.848248"}
{"text": "0190 ] For example , two kinds of ratings can be kept for each precise constituent during the stage 1460 , the quality of the best syntactic tree which can be built on the basis of this precise constituent , and the quality of the second - best syntactic tree .", "label": "", "metadata": {}, "score": "59.908386"}
{"text": "By using a top - down approach to heuristically guide the construction of generalizations of a bottom clause , Beth combines the strength of both approaches .Learning patterns for detecting potential terrorist activity is a current challenge problem for relational data mining .", "label": "", "metadata": {}, "score": "59.932186"}
{"text": "The actions performed at step 110 will be described in detail in FIG .2B and FIGS .5 - 24 .[ 0060 ] As a result , all the fragments translated both at step 110 and at step 120 , are joined together in the correct order and in the required format in the output document 104 .", "label": "", "metadata": {}, "score": "59.96379"}
{"text": "If non - tree relationships can not be assigned in the selected best syntactic tree , the syntactic tree with the second - best rating is selected as the best syntactic tree for further analysis .The graph 1202 of generalized constituents is analyzed during the preliminary stage which prepares the data for the precise syntactic analysis 540 .", "label": "", "metadata": {}, "score": "60.003757"}
{"text": "Compared to a previous generative model for semantic alignment , it also supports full semantic parsing .Experimental results on the Robocup sportscasting corpora in both English and Korean indicate that our approach produces more accurate semantic alignments than existing methods and also produces competitive semantic parsers and improved language generators .", "label": "", "metadata": {}, "score": "60.018585"}
{"text": "[ 0069 ] Searches in a translation database may be performed in many different ways , depending on the structure of the database .In particular , if the translation database is supplied with an index , the index may be used for quick searches .", "label": "", "metadata": {}, "score": "60.121403"}
{"text": "It is done by means of assigning to the proform a corresponding relational meaning by the control rule .[ 0253 ] The linear order is determined after detecting relational grammatical meanings because they may affect the linear order ( for example , the type of a pronoun ) .", "label": "", "metadata": {}, "score": "60.123413"}
{"text": "Back to grammars .To see how grammar in a natural language works , many investigators , as a preliminary , first try to develop an understanding of a context - free grammar ( CFG ) .Just like it sounds , a context - free grammar consists of rules that apply independent of the context , whether the context of other elements or parts of the sentence or of the larger discourse context of the sentence .", "label": "", "metadata": {}, "score": "60.19976"}
{"text": "ILP algorithms , which learn relational ( first - order ) rules , are used in a parser acquisition system called CHILL that learns rules to control the behavior of a traditional shift - reduce parser .Using this approach , CHILL is able to learn parsers for a variety of different types of analyses , from traditional syntax trees to more meaning - oriented case - role and database query forms .", "label": "", "metadata": {}, "score": "60.21646"}
{"text": "In this logical form language , word senses will be the atoms or constants , and these are classified by the type of things they describe .Constants describing objects are terms , and constants describing relations and properties are predicates .", "label": "", "metadata": {}, "score": "60.235317"}
{"text": "Thus , the deep slots 914 are language - independent .[ 0116 ] System of semantemes 930 represents a set of semantic categories and semantemes , which represent the meanings of the semantic categories .As an example , a semantic category \" DegreeOfComparison \" , can be used to describe the degrees of comparison expressed by various forms of adjectives , for example , \" easy \" , \" easier \" and \" easiest \" .", "label": "", "metadata": {}, "score": "60.244667"}
{"text": "We present a system that learns to transform natural - language navigation instructions into executable formal plans .Given no prior linguistic knowledge , the system learns by simply observing how humans follow navigation instructions .The system is evaluated in three complex virtual indoor environments with numerous objects and landmarks .", "label": "", "metadata": {}, "score": "60.308884"}
{"text": "[ 0119 ] Pragmatic descriptions 940 are used to assign a corresponding theme , style or genre to texts and objects of the semantic hierarchy 910 .For example , \" Economic Policy \" , \" Foreign Policy \" , \" Justice \" , \" Legislation \" , \" Trade \" , \" Finance \" , etc .", "label": "", "metadata": {}, "score": "60.317352"}
{"text": "The best hypothesis is represented by a best surface structure , which is a tree ( best surface tree ) , the nodes of which are constituents with selected lexical meanings and corresponding syntax forms and the branches are the surface slots .", "label": "", "metadata": {}, "score": "60.418476"}
{"text": "We show that our method performs overall better and faster than previous approaches in both domains .ML ID : 160 .Learning Transformation Rules for Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate , Yuk Wah Wong , Ruifang Ge , and Raymond J. Mooney April 2004 .", "label": "", "metadata": {}, "score": "60.604984"}
{"text": "The first two types of parsers we have just discussed follow this latter approach .We already mentioned that although context - free grammars are useful in parsing artificial languages , it is debatable to what extent a natural language such as English can be modeled by context - free rules .", "label": "", "metadata": {}, "score": "60.6929"}
{"text": "3 illustrates still another embodiment of the method for translating a document in a source language into a document in an output language by performing a fuzzy search in a database of translations .[ 0027 ] FIG .4 illustrates an embodiment of the method for translating the untranslated fragments by the NLC which uses linguistic descriptions according to one embodiment of the invention .", "label": "", "metadata": {}, "score": "60.703552"}
{"text": "The performance of SCISSOR is further improved by using discriminative reranking for incorporating non - local features .The second semantic parser , SYNSEM , exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation .", "label": "", "metadata": {}, "score": "60.751648"}
{"text": "The movements may be represented in the surface structure by means of non - tree links too , or otherwise , corresponding non - tree links may be restored by means of special structural control rules .[ 0248 ] A movement is a phenomenon of various natural languages .", "label": "", "metadata": {}, "score": "60.849773"}
{"text": "[ 0131 ] For example , six pairs of \" lexical meaning - grammatical value \" are found for the word form \" smart \" , as shown in FIG .11 .As a result , the word form \" smart \" may have the same lexical meaning of \" smart \" but six ( 6 ) different grammatical values 1008 .", "label": "", "metadata": {}, "score": "60.924553"}
{"text": "The grammatical values 1008 are represented as a set of values of grammatical attributes ( expressed in grammemes ) of a word form .Examples of these grammatical attributes include , but are not limited to , the part of speech , number , gender , case , etc .", "label": "", "metadata": {}, "score": "60.935204"}
{"text": "Let 's turn to some examples of the place of general knowledge .General knowledge about the world can be specified in terms of types of objects in the world , with no mention of particular individuals .( Information about particular individuals would be included in knowledge of the specific setting or situation . )", "label": "", "metadata": {}, "score": "60.969875"}
{"text": "As stated , ( C occ ) is oversimplified : it evaluates each constituent of a complex expression within the same context .A more adequate formulation would allow for context - shift within larger expressions .To formulate such a principle adequately one must take a stand on what contexts are - a question I am bypassing here .", "label": "", "metadata": {}, "score": "61.033356"}
{"text": "This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural - language interface for database queries .CHILL treats parser acquisition as the learning of search - control rules within a logic program representing a shift - reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge .", "label": "", "metadata": {}, "score": "61.053894"}
{"text": "Let 's talk more about parsing methods .As can be observed above , grammars have a special symbol called a start symbol , which might be S for sentence .A grammar can be said to derive a sentence if a sequence of rules would allow you to rewrite the start symbol into the sentence .", "label": "", "metadata": {}, "score": "61.15198"}
{"text": "We present a method for integrating statistical and relational learning techniques for this task which exploits the strength of both approaches .Experimental results from three different domains suggest that such an approach is more robust than a previous purely logic - based approach .", "label": "", "metadata": {}, "score": "61.17563"}
{"text": "Therefore , the generators are said to be the inverse of the parsers , an elegant property that has been widely advocated .Furthermore , we show that our parsers and generators can handle formal meaning representation languages containing logical variables , including predicate logic .", "label": "", "metadata": {}, "score": "61.187172"}
{"text": "The problem occurs in the domain of lexical acquisition .The ambiguous and synonymous nature of words causes the difficulty of using standard induction techniques to learn a lexicon .Additionally , negative examples are typically unavailable or difficult to construct in this domain .", "label": "", "metadata": {}, "score": "61.206062"}
{"text": "ML ID : 66 .Corpus - Based Lexical Acquisition For Semantic Parsing [ Details ] [ PDF ] Cynthia Thompson February 1996 .Ph.D. proposal .Building accurate and efficient natural language processing ( NLP ) systems is an important and difficult problem .", "label": "", "metadata": {}, "score": "61.236633"}
{"text": "The lexicon learned consists of words paired with meaning representations .Wolfie is part of an integrated system that learns to parse novel sentences into semantic representations , such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .", "label": "", "metadata": {}, "score": "61.253365"}
{"text": "In this proposal , we present a novel statistical approach to semantic parsing , WASP , which can handle meaning representations with a nested structure .The WASP algorithm learns a semantic parser given a set of sentences annotated with their correct meaning representations .", "label": "", "metadata": {}, "score": "61.259666"}
{"text": "Shoham , Uoav , Artificial Intelligence Techniques in Prolog ( San Francisco : Morgan Kaufmann , 1994 ) .Steedman , Mark , \" Natural Language Processing , \" in Margaret A. Boden , editor , Artificial Intelligence ( San Diego : Academic Press , 1996 ) .", "label": "", "metadata": {}, "score": "61.34343"}
{"text": "[0045 ] FIG .21 is an exemplary semantic structure with semantemes and exemplary analysis rules according to one or more embodiments of the NLC method .[ 0046 ]FIG .22 is a process flow diagram illustrating an output natural language sentence synthesis according to one or more embodiments of the NLC method .", "label": "", "metadata": {}, "score": "61.478676"}
{"text": "If this program is written in Prolog , when the machine reaches a particular point in the sentence and it will not parse , then it can backtrack to an earlier point and try another interpretation of the earlier word .This takes advantage of a ability of Prolog to backtrack .", "label": "", "metadata": {}, "score": "61.615826"}
{"text": "This procedure is applied recursively to the child precise constituent .[0189 ] On the basis of each precise constituent , the best syntactic tree with a certain rating score can be generated .This rating score can be calculated beforehand and specified in the precise constituent .", "label": "", "metadata": {}, "score": "61.697243"}
{"text": "Reference List and Bibliography .Allen , James , Natural Language Understanding , second edition ( Redwood City : Benjamin / Cummings , 1995 ) .Bratko , Ivan , Prolog , second edition ( Workingham : Addison - Wesley , 1990 ) .", "label": "", "metadata": {}, "score": "61.69939"}
{"text": "7 illustrates exemplary morphological descriptions .As shown , the components of the morphological descriptions 501 include , but are not limited to , word - inflexion description 710 , grammatical system 720 ( e.g. , grammemes ) , and word - formation description 730 .", "label": "", "metadata": {}, "score": "61.709618"}
{"text": "0173 ] The preliminary stage of the precise syntactic analysis 540 may include fragment specification 1410 and generating 1450 of a graph of precise constituents to obtain a graph of linear division 1440 and a graph of precise constituents 1430 , respectively .", "label": "", "metadata": {}, "score": "61.724632"}
{"text": "In this case , the second - best syntactic tree 1420 may be analyzed .If non - tree links have not been successfully established , a returning back 1472 to the stage 1460 is provided to obtain the next syntactic tree , which may have a different rating score , for generating another syntactic structure with non - tree links as the best syntactic structure .", "label": "", "metadata": {}, "score": "61.772694"}
{"text": "[0188 ] During the stage 1460 , the best syntactic tree 1420 may generally be built recursively and traversally from the graph 1430 of precise constituents .The best syntactic subtrees are built for the best child precise constituents , syntactic structure is built on the basis of the given precise constituent , and child subtrees are attached to the generated syntactic structure .", "label": "", "metadata": {}, "score": "61.784492"}
{"text": "A better human - computer interface that could convert from a natural language into a computer language and vice versa .A natural language system could be the interface to a database system , such as for a travel agent to use in making reservations .", "label": "", "metadata": {}, "score": "61.85203"}
{"text": "This paper presents an effort to enable robots to utilize open - source knowledge resources autonomously for human - robot interaction .The main challenges include how to extract knowledge in semi - structured and unstructured natural languages , how to make use of multiple types of knowledge in decision making , and how to identify the knowledge that is missing .", "label": "", "metadata": {}, "score": "61.87175"}
{"text": "ML ID : 130 .Acquiring Word - Meaning Mappings for Natural Language Interfaces [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Journal of Artificial Intelligence Research , 18:1 - 44 , 2003 .This paper focuses on a system , Wolfie ( WOrd Learning From Interpreted Examples ) , that acquires a semantic lexicon from a corpus of sentences paired with semantic representations .", "label": "", "metadata": {}, "score": "62.01245"}
{"text": "[0193 ] When the stage 1460 , additional restrictions on constituents may be taken into account .Each precise constituent which gets into the best tree may be checked for additional restrictions .If a constituent or one of its child constituents does not meet the restrictions , the constituent may receive a mark that its best tree does not meet the additional restrictions .", "label": "", "metadata": {}, "score": "62.044487"}
{"text": "[0012 ]The present invention generally relates to methods , computer - readable media , devices and systems for translating a sentence from an input language into an output language .To improve the efficiency and speed of such systems , databases of previous translations ( hereinafter \" translation databases \" ) may be used .", "label": "", "metadata": {}, "score": "62.04592"}
{"text": "To simplify , we are assuming certain notions about the algorithm commonly used in parsers using DCG , and we get these assumptions by the literature describing DCG parsers .Thus Prolog has built into it the definite clause grammar ( DCG ) parsing technique .", "label": "", "metadata": {}, "score": "62.095"}
{"text": "A noise - disposal parser scans a sentence looking for selected words , which are in its defined vocabulary .When one of the words is found , the computer initiates the desired action .During the perusal , any words not in the list of those the computer is looking for are considered \" noise \" and discarded .", "label": "", "metadata": {}, "score": "62.118736"}
{"text": "More precisely , into one that is compositional given the usual weak understanding of determination in ( C ) .See section 1.4 .for more detail about this matter .The original meaning is uniformly recoverable in principle .There is no constraint here on how complex a calculation might be required to determine the value \u03bc ( s ) ( s ) .", "label": "", "metadata": {}, "score": "62.163292"}
{"text": "Initially , the system will passively observe a human giving instruction to another human , and try to learn the correspondences between the instructions and the intended plan .After the system has a decent understanding of the language , it can then participate in the interactions to learn more directly by playing either the role of the instructor or the follower .", "label": "", "metadata": {}, "score": "62.17074"}
{"text": "The type of ambiguity here could be lexical syntactic ambiguity ( a word might be either a noun or verb , for instance ) , or structural syntactic ambiguity .This latter type of ambiguity involves the fact that there may be more than one way to combine the same lexical categories to result in a legal sentence .", "label": "", "metadata": {}, "score": "62.176308"}
{"text": "[ 1 ] This is speaking inexactly for ' grammatical ' contrasts with ' meaningful ' in being a technical term .The predicate for observables is ' acceptable . 'What the AoS examples above observe is that a notion of syntactic well - formedness is required in addition to meaningfulness if relative acceptability is to be accounted for .", "label": "", "metadata": {}, "score": "62.185844"}
{"text": "A translation program that could translate from one human language to another ( English to French , for example ) .Even if programs that translate between human languages are not perfect , they would still be useful in that they could do the rudimentary translation first , with their work checks and corrected by a human translator .", "label": "", "metadata": {}, "score": "62.186462"}
{"text": "To understand a natural language requires distinguishing between deductive and nondeductive inference , with the latter including inductive inference and abductive inference .The system may allow the use of default rules , which can allow exceptions ( they are defeasible ) .", "label": "", "metadata": {}, "score": "62.222977"}
{"text": "In an NLP dealing with the presence of segments , the individual segments can be captured in discourse states , which allow the temporary suspending of one segment while a new one is pursued .A discourse state consists of : .", "label": "", "metadata": {}, "score": "62.258347"}
{"text": "Recall that the logical form language needed to be able to deal with ambiguity , which will not always be resolvable without a consideration of the larger discourse context , not available at this stage of the analysis .It will not necessarily be able to resolve ambiguity , but it needs to be able to represent it .", "label": "", "metadata": {}, "score": "62.30342"}
{"text": "Since many different non - tree links may be specified , several syntactic structures with defined non - tree links , i.e. with a fully - defined surface structure , may be obtained .The stage 1470 may result a syntactic structure 1402 with the best rating -- the best syntactic structure .", "label": "", "metadata": {}, "score": "62.362865"}
{"text": "Unlike conventional reranking used in syntactic and semantic parsing , gold - standard reference trees are not naturally available in a grounded setting .Instead , we show how the weak supervision of response feedback ( e.g. successful task completion ) can be used as an alternative , experimentally demonstrating that its performance is comparable to training on gold - standard parse trees .", "label": "", "metadata": {}, "score": "62.419186"}
{"text": "\" Fragment \" is a more common notion than \" sentence \" and may describe a paragraph , a sentence , a title , a part of a sentence , a word combination , for example , a noun group , etc . .", "label": "", "metadata": {}, "score": "62.450092"}
{"text": "[0168 ] The calculated rating scores for each hypothesis may be obtained on the basis of a priori rough ratings found during the rough syntactic analysis 530 .For example , a rough assessment is made for each generalized constituent in the graph 1202 of the generalized constituents and ratings scores can be calculated .", "label": "", "metadata": {}, "score": "62.479725"}
{"text": "Existing hand - crafted systems can provide in - depth analysis of domain sub - languages , but are often notoriously fragile and costly to build .Existing machine - learned systems are considerably more robust , but are limited to relatively shallow NLP tasks .", "label": "", "metadata": {}, "score": "62.494186"}
{"text": "International Conference on Computational Linguistics ( COLING 2010 ) , 543 - -551 , Beijing , China , August 2010 .We present a probabilistic generative model for learning semantic parsers from ambiguous supervision .Our approach learns from natural language sentences paired with world states consisting of multiple potential logical meaning representations .", "label": "", "metadata": {}, "score": "62.548473"}
{"text": "We present a method for utilizing unannotated sentences to improve a semantic parser which maps natural language ( NL ) sentences into their formal meaning representations ( MRs ) .Given NL sentences annotated with their MRs , the initial supervised semantic parser learns the mapping by training Support Vector Machine ( SVM ) classifiers for every production in the MR grammar .", "label": "", "metadata": {}, "score": "62.5796"}
{"text": "The way to provide for this is to encode this information in structures known as frames .A frame is a cluster of facts and objects about some typical object , situation , or action , along with specific strategies of inference for reasoning about such a situation .", "label": "", "metadata": {}, "score": "62.601685"}
{"text": "Computing Meaning , volume 1 ( Studies in Linguistics and Philosophy , 73 ) , Kluwer .Revised version of paper in Proc . 2ndInternational Workshop on Computational Semantics , Tilburg , 1997 .[ iwcs.pdf ] .( Richard Crouch ) in Fragments : Studies in Ellipsis and Gapping ( edited by Shalom Lappin and Elabbas Benmamoun ) Oxford University Press .", "label": "", "metadata": {}, "score": "62.66789"}
{"text": "Computing Meaning , volume 1 ( Studies in Linguistics and Philosophy , 73 ) , Kluwer .Revised version of paper in Proc . 2ndInternational Workshop on Computational Semantics , Tilburg , 1997 .[ iwcs.pdf ] .( Richard Crouch ) in Fragments : Studies in Ellipsis and Gapping ( edited by Shalom Lappin and Elabbas Benmamoun ) Oxford University Press .", "label": "", "metadata": {}, "score": "62.66789"}
{"text": "SYNSEM also significantly improves results with limited training data , and is shown to be robust to syntactic errors .ML ID : 246 .Training a Multilingual Sportscaster : Using Perceptual Context to Learn Language [ Details ] [ PDF ] David L. Chen , Joohyun Kim , Raymond J. Mooney Journal of Artificial Intelligence Research , 37:397 - -435 , 2010 .", "label": "", "metadata": {}, "score": "62.74922"}
{"text": "In this paper I 'll use the phrase natural language processing , but keep in mind I 'm mostly just discussing interpretation rather than generation .This use of the phrase alludes to two distinct goals of this field of research .", "label": "", "metadata": {}, "score": "62.770145"}
{"text": "Additional rough syntactic analysis 530 can be performed with additional consideration of any syntforms which may not have been analyzed previously .[ 0207 ] As a result of the rough syntactic analysis 530 and the precise syntactic analysis 540 , the syntactic structure with specified surface and deep slots is built .", "label": "", "metadata": {}, "score": "62.950672"}
{"text": "[ 0136 ] In one embodiment , all the possible syntactic descriptions and syntactic structures for the source sentence 512 are considered and generalized .As a result , the graph 1202 of the generalized constituents is built , having each constituent generalized from all the possible constituents for each element of the source sentence 512 , and building generalized constituents are performed for all the elements of the source sentence 512 .", "label": "", "metadata": {}, "score": "62.98162"}
{"text": "0197 ] FIG .16 is an example of syntactic tree of the above mentioned sentence \" This boy is smart , he 'll succeed in life .\" [ 0198 ] A rectangle shows a constituent with the selected lexical meaning of the core and its morphological paradigm in broken brackets , for example , Verb or Noun&Pronoun .", "label": "", "metadata": {}, "score": "63.016914"}
{"text": "Clauses for direct speech and proper names are substituted .[ 0162 ] FIG .13 is an example of a graph 1300 of generalized constituents for the sentence \" This boy is smart , he 'll succeed in life .\" The constituents are represented by rectangles , each constituent having a lexeme as its core .", "label": "", "metadata": {}, "score": "63.061012"}
{"text": "ML ID : 314 .Semantic Parsing using Distributional Semantics and Probabilistic Logic [ Details ] [ PDF ][Poster ] Islam Beltagy and Katrin Erk and Raymond Mooney In Proceedings of ACL 2014 Workshop on Semantic Parsing ( SP-2014 ) , 7 - -11 , Baltimore , MD , June 2014 .", "label": "", "metadata": {}, "score": "63.106422"}
{"text": "0124 ] In addition , lexical meanings 1012 may contain their own characteristics as well as inherit other characteristics from language - independent parent semantic class .These characteristics of the lexical meanings 1012 may include grammatical values 1008 and semantic value 1010 , which can be expressed as grammemes and semantemes , respectively .", "label": "", "metadata": {}, "score": "63.119186"}
{"text": "This was developed further into the notion of Scripts , which we mentioned above .The idea was that the computer could be given background information ( a SCRIPT ) about what sorts of things happened in typical everyday scenarios , and it would then infer information not explicitly provided .", "label": "", "metadata": {}, "score": "63.15856"}
{"text": "0081 ] When selecting the best translation for the differing words , the subject domain of the document may be taken into account .For example , to translate the English word \" file \" , which the system assumes to be a noun , the system will select the translation equivalent meaning a \" computer file \" if it is translating a text about computers and software .", "label": "", "metadata": {}, "score": "63.246426"}
{"text": "The usual goal is to process the natural language sentences into some sort of knowledge representation that is most easily interpreted as corresponding to an internal meaning representation or proposition in humans .The machines and programs used for the natural language processing simulations or programs are usually geared to sequential processing on traditional digital computers , so it is understandable why this should be so .", "label": "", "metadata": {}, "score": "63.27395"}
{"text": "ML ID : 95 .Active Learning for Natural Language Parsing and Information Extraction [ Details ] [ PDF ] Cynthia A. Thompson , Mary Elaine Califf and Raymond J. Mooney In Proceedings of the Sixteenth International Conference on Machine Learning ( ICML-99 ) , 406 - 414 , Bled , Slovenia , June 1999 .", "label": "", "metadata": {}, "score": "63.29697"}
{"text": "The non - tree links are shown as dotted arrows .These non - tree links may be kept in the language - independent semantic structure , for example , in the case when this language - independent semantic structure was obtained as result of analysis of the sentence in the same or another natural language .", "label": "", "metadata": {}, "score": "63.335144"}
{"text": "For every element of the sentence which can be a controller , its own proform is inserted .If a pronoun ( or a proform substituted during the rough syntactic analysis ) is controlled , a copy of the pronoun is uniformly made .", "label": "", "metadata": {}, "score": "63.355507"}
{"text": "1A illustrates another example of the method 100 for translating the document 102 in a source language into the output document 104 in an output language .At step 105 , a translation database is either created or selected from the available databases .", "label": "", "metadata": {}, "score": "63.3638"}
{"text": "The system learns to parse and generate commentaries without any engineered knowledge about the English language .Training is done using only ambiguous supervision in the form of textual human commentaries and simulation states of the soccer games .The system simultaneously tries to establish correspondences between the commentaries and the simulation states as well as build a translation model .", "label": "", "metadata": {}, "score": "63.3899"}
{"text": "A semantemes calculating rule can check the presence of certain semantemes of other constituents .Such a rule can only work after all the semantemes which are specified in this rule have been calculated .To cope with this situation , the rules are started from the child constituents to the parent constituents .", "label": "", "metadata": {}, "score": "63.420322"}
{"text": "Obviously a noise - disposal type of parser has a limited application .Maybe it can be used to tell a computer to open a particular file , with the computer looking for any input with the word \" open \" and the name of a file listed in its current directory .", "label": "", "metadata": {}, "score": "63.424217"}
{"text": "This algorithm may be performed recursively for each child constituent .Otherwise , the movements which are described in the surface slots of this constituent are restored .If the movement can not be restored , the constituent is deleted .[ 0246 ] In the end of the considering of each hypothesis about surface structure of a constituent final rating of the hypothesis is calculated .", "label": "", "metadata": {}, "score": "63.42975"}
{"text": "Evolution of MBMT systems is connected with developing complex language models on all levels of language descriptions .The need in today 's modern world requires translation between many different languages .Creating such MBMT systems is only possible within a large - scale project to integrate the results of engineering and linguistic research .", "label": "", "metadata": {}, "score": "63.451176"}
{"text": "A vertical bar on the right can separate definitions , either of which can be used .Grammar rules state acceptable forms of sentences , etc . .For example , a number may be defined as a digit or a plus or minus sign followed by a number : .", "label": "", "metadata": {}, "score": "63.613472"}
{"text": "Wolfie is part of an integrated system that learns to parse representations such as logical database queries .Experimental results are presented demonstrating Wolfie 's ability to learn useful lexicons for a database interface in four different natural languages .The usefulness of the lexicons learned by Wolfie are compared to those acquired by a similar system developed by Siskind ( 1996 ) , with results favorable to Wolfie .", "label": "", "metadata": {}, "score": "63.6325"}
{"text": "Instead , we use distributional semantics to generate only the relevant part of an on - the - fly ontology .Sentences and the on - the - fly ontology are represented in probabilistic logic .For inference , we use probabilistic logic frameworks like Markov Logic Networks ( MLN ) and Probabilistic Soft Logic ( PSL ) .", "label": "", "metadata": {}, "score": "63.65554"}
{"text": "Our system uses two inverse \u03bb - calculus operators and using them can take as input the semantic representation of some words , phrases and sentences and from that derive the semantic representation of other words and phrases .Our inverse \u03bb operator works on many formal languages including first order logic , database query languages and answer set programming .", "label": "", "metadata": {}, "score": "63.711"}
{"text": "Here is a specific difference between the logical form language and the knowledge representation language .The logical form language contains a wide range of quantifiers , while the KRL , like FOPC , uses only existential and universal quantifiers .Allen notes that if the ontology of the KRL is allowed to include sets , finite sets can be used to give the various logical form language quantifiers approximate meaning .", "label": "", "metadata": {}, "score": "63.738556"}
{"text": "As yet another example , \" EvaluationObjective \" , as a semantic category , may describe an objective assessment , such as \" Bad \" , \" Good \" , etc . .[0117 ] The systems of semantemes 930 include language - independent semantic attributes which express semantic characteristics as well as stylistic , pragmatic and communicative characteristics .", "label": "", "metadata": {}, "score": "63.742546"}
{"text": "The ATIS corpus of airline information queries was used to test the acquisition of syntactic parsers , and CHILL performed competitively with recent statistical methods .English queries to a small database on U.S. geography were used to test the acquisition of a complete natural language interface , and the parser that CHILL acquired was more accurate than an existing hand - coded system .", "label": "", "metadata": {}, "score": "63.77181"}
{"text": "0183 ] Additionally , ellipsis is also processed when a child constituent attached during the stage 1450 .Surface slots which are required in the syntform and do not permit ellipsis may be empty .In this case , when generating a precise constituent , a proform is placed in the empty slot .", "label": "", "metadata": {}, "score": "63.896336"}
{"text": "^ Antilla , A. ( 1997 ) , Variation in Finnish phonology and morphology , Stanford , CA : Stanford University dissertation .^ Boersma , P. ( 1997 ) , How we learn variation , optionality , and probability , Proceedings of the Institute of Phonetic Sciences of the University of Amsterdam 21.43 - 58 .", "label": "", "metadata": {}, "score": "63.951412"}
{"text": "[0169 ] Those hypotheses with the most probable syntactic structure of a whole sentence can also be generated and obtained .From syntactic structure 1402 variants with higher ratings to syntactic structure 1402 variants with more lower ratings , syntactic structure hypotheses are generated during precise syntactic analysis until a satisfactory result is obtained and a best syntactic tree which has the highest possible rating can be built .", "label": "", "metadata": {}, "score": "63.968407"}
{"text": "The phrase is not a pronoun , but still we need to determine to what it refers .So we see that the broader plan referred to is the business plan , not the marketing plan .One aspect that is important here is that we assume that the discourse is coherent , which allows us to determine how the sentences relate to one another .", "label": "", "metadata": {}, "score": "64.151886"}
{"text": "The rough syntactic analysis 530 is impossible to succeed if there is no syntform and no filled surface slot , and as such the filtering 1270 is performed .[ 0148 ] Once all possible constituents are built , the generalization procedure is performed for building 1220 of the generalized constituents .", "label": "", "metadata": {}, "score": "64.18103"}
{"text": "For each built path on the graph 1440 of linear division , the set of syntforms is determined ; linear order is checked ( verified ) and rated for each of the syntforms .Accordingly , a precise constituent is created for each of the syntforms , and the building of precise child constituents is recursively initiated .", "label": "", "metadata": {}, "score": "64.203125"}
{"text": "Training data consists of natural language sentences annotated with multiple potential meaning representations , only one of which is correct .Such ambiguous supervision models the type of supervision that can be more naturally available to language - learning systems .Given such weak supervision , our approach produces a semantic parser that maps sentences into meaning representations .", "label": "", "metadata": {}, "score": "64.218956"}
{"text": "Rating scores are obtained , and these calculated rating scores are used to generate hypotheses about the overall syntactic structure of the sentence .To achieve this , the hypotheses with the highest rating are selected .These hypotheses are generated by advancing hypotheses about the structure of the child constituents which are most probable in order to obtain the most probable hypothesis about the overall syntactic structure of the sentence .", "label": "", "metadata": {}, "score": "64.22241"}
{"text": "A new system , Wolfie , learns semantic lexicons to be used as background knowledge by a previously developed parser acquisition system , Chill .The combined system is tested on a real world domain of answering database queries .We also compare this combination to a combination of Chill with a previously developed lexicon learner , demonstrating superior performance with our system .", "label": "", "metadata": {}, "score": "64.22976"}
{"text": "Proceedings of the Conference on the Interaction between Syntax and Pragmatics at UCL .Szendr\u0151i , Kriszta ( 2004 ) . 'Focus and the interaction between syntax and pragmatics ' .Lingua 114(3 ) , 229 - 254 .Xu , Y. , C. X. Xu and X. Sun ( 2004 ) . '", "label": "", "metadata": {}, "score": "64.23041"}
{"text": "To me , to say that a system is capable of natural language understanding does not imply that the system can generate natural language , only that it can interpret natural language .To say that the system can process natural language allows for both understanding ( interpretation ) and generation ( production ) .", "label": "", "metadata": {}, "score": "64.23494"}
{"text": "The grammemes are units of the grammatical systems 720 and , as shown by a link 722 and a link 724 , the grammemes can be used to build the word - inflexion description 710 and the word - formation description 730 .", "label": "", "metadata": {}, "score": "64.26232"}
{"text": "Generative Models of Grounded Language Learning with Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joohyun Kim Technical Report , PhD proposal , Department of Computer Science , The University of Texas at Austin , June 2012 . \"", "label": "", "metadata": {}, "score": "64.278854"}
{"text": "11/690,099 , filed Mar. 22 , 2007 .BACKGROUND OF THE INVENTION .[0002 ] 1 .Field of the Invention .[0004 ] 2 .Description of the Related Art .[ 0005 ] Prior machine translation ( MT ) systems differ in the approaches and methods that they use and also in their abilities to recognize various complex language constructs and produce quality translation of texts from one language into another .", "label": "", "metadata": {}, "score": "64.32853"}
{"text": "Not all humans can process natural language at the same level , so we can not answer this question precisely , but the ability to interpret and converse with humans in normal , ordinary human discourse would be the goal .This would be no mean feat .", "label": "", "metadata": {}, "score": "64.34065"}
{"text": "Unlike many current corpus - based approaches that use propositional or probabilistic learning algorithms , CHILL uses techniques from inductive logic programming ( ILP ) to learn relational representations .The reported experiments compare CHILL 's performance to that of a more naive application of ILP to parser acquisition .", "label": "", "metadata": {}, "score": "64.34396"}
{"text": "[ 0063 ] The choice of database may be determined , for example , by the subject domain , the genre , or style of the source document .It may also be determined by the authors or company 's preferences , etc .", "label": "", "metadata": {}, "score": "64.47739"}
{"text": "Alternative realization rules 2244 usually substitute some semantic class as the parent constituent and/or transform the semantic structure 2002 what enable to build the surface structure with another lexical meaning .[ 0240 ] Alternative realization rules 2244 are lexicalized , i.e. they are connected with ( assigned to ) certain objects of the semantic hierarchy 910 and are a part of lexical description 503 .", "label": "", "metadata": {}, "score": "64.490746"}
{"text": "Structuring the rules of a natural language grammar is also a great task .But there is also the problem of general world knowledge .Much of the problem stems from the lack of common sense knowledge on the part of the computer .", "label": "", "metadata": {}, "score": "64.533165"}
{"text": "[ 0152 ] The generalized diatheses are built during the rough syntactic analysis 530 as the correspondences between generalized surface models and generalized deep models .The list of all possible semantic classes for all the diatheses 817 of the lexeme is calculated for each surface slot 815 .", "label": "", "metadata": {}, "score": "64.55457"}
{"text": "In this thesis , we focus on devising effective models for simultaneously disambiguating such supervision and learning the underlying semantics of language to map NL sentences into proper logical MRs .We present probabilistic generative models for learning such correspondences along with a reranking model to improve the performance further .", "label": "", "metadata": {}, "score": "64.56756"}
{"text": "Our method is based on the intuition that syntactic realizations of the same semantic predicate exhibit some degree of consistency .We incorporate this intuition in a directed graphical model that tightly links the syntactic and semantic structures .This design enables us to exploit syn - tactic regularities while still allowing for variations .", "label": "", "metadata": {}, "score": "64.69011"}
{"text": "Examples of the surface slot 815 may include \" Subject \" , \" Object_Direct \" , \" Object_Indirect \" , \" Relative Clause \" , among others .[ 0103 ] As part of a syntactic description , any constituent model uses a plurality of surface slots 815 of child constituents along with their linear order descriptions 816 to describe the grammatical values 814 of possible fillers of these surface slots 815 .", "label": "", "metadata": {}, "score": "64.842896"}
{"text": "Building natural language parsing systems by hand is a tedious , error - prone undertaking .We build on previous research in automating the construction of such systems using machine learning techniques .The result is a combined system that learns semantic lexicons and semantic parsers from one common set of training examples .", "label": "", "metadata": {}, "score": "64.87543"}
{"text": "More current information about the state of the art on the above topics can be obtained by searching the World Wide Web using keywords such as natural language processing , natural language understanding , machine learning , computational linguistics , etc .", "label": "", "metadata": {}, "score": "64.955086"}
{"text": "[ 0087 ] At step 510 , a lexical analysis is performed on the source sentence 512 in a source / input language .At step 520 , a lexical - morphological analysis is also performed on the source sentence 512 to generate a lexical - morphological structure 522 of the source sentence 512 using information from the morphological descriptions 501 and the lexical descriptions 501 of the source language .", "label": "", "metadata": {}, "score": "64.97026"}
{"text": "Also appears as Technical Report AI 99 - 278 , Artificial Intelligence Lab , University of Texas at Austin .A long - standing goal for the field of artificial intelligence is to enable computer understanding of human languages .A core requirement in reaching this goal is the ability to transform individual sentences into a form better suited for computer manipulation .", "label": "", "metadata": {}, "score": "65.00866"}
{"text": "[0009 ] Example - Based MT ( EBMT ) relates to machine translation systems using automated analysis of \" examples \" , which is very similar to Statistics - Based MT ( SBMT ) .The TM systems have demonstrated their practical efficiency when translating recurrent text fragments on the basis of minimal knowledge about languages such that researchers and developers are encouraged to try and create advanced and relatively exhaustive SBMT systems .", "label": "", "metadata": {}, "score": "65.03461"}
{"text": "But if an exact match is not possible , other considerations will enter .There are many possible situations and scenarios that will generate expectations .One way to control the generation of expectations is to store large units of information that identify common situations .", "label": "", "metadata": {}, "score": "65.05534"}
{"text": "^ a b Jacobs , J. ( 1983 ) , Fokus und Skalen , T\u00a8ubingen : Niemeyer .^ von Stechow , A. ( 1989 ) , Focusing and backgrounding operators , Universitat Konstanz , Fachgruppe Sprachwissenschaft , Arbeitspapier Nr .Konstanz .", "label": "", "metadata": {}, "score": "65.09944"}
{"text": "However , the production experiment reported in German et al .[ 32 ] showed that subjects are more likely to accent verbs or nouns as opposed to prepositions in the narrow focused context , thus ruling out accent patterns shown in ( 28 ) .", "label": "", "metadata": {}, "score": "65.28291"}
{"text": "25 is a block diagram of one illustrative embodiment of a computer system where the method of translating documents can be implemented .[ 0050 ]FIG .26 illustrates another example of a computer system in accordance with one embodiment of the invention .", "label": "", "metadata": {}, "score": "65.288895"}
{"text": "Since this requires highly annotated training data and/or MRs built specifically for one domain , such approaches typically have a restricted vocab ... . \" ...This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus .", "label": "", "metadata": {}, "score": "65.32706"}
{"text": "At other times the phrase is used more narrowly to include only syntactic and semantic analysis and processing .Third , even if this confusion is overcome , the phrase \" natural language processing \" may or may not be taken as synonymous with \" natural language understanding . \"", "label": "", "metadata": {}, "score": "65.33094"}
{"text": "The above set of concepts is called a BDI model ( belief , desire , and intention ) .Perception , planning , commitment , and acting are processes , while beliefs , desires , and intentions are part of the agent 's cognitive state .", "label": "", "metadata": {}, "score": "65.35867"}
{"text": "Notice that the relevant local discourse context might not be just the previous sentence but some larger set , as in the bananas example .To prefigure a topic we will consider more thoroughly shortly , let us note that a more thorough discourse analysis involves identifying the intended focus of a portion of language in order to understand it .", "label": "", "metadata": {}, "score": "65.36008"}
{"text": "We first present a system that learned to sportscast for RoboCup simulation games by observing how humans commentate a game .Using the simple assumption that people generally talk about events that have just occurred , we pair each textual comment with a set of events that it could be referring to .", "label": "", "metadata": {}, "score": "65.38906"}
{"text": "If the stage 1470 is unsuccessful , the returning back 1472 to the stage 1460 is provided to obtain the next - best syntactic tree 1420 with the next value of rating score .[0201 ] Many other syntactic trees may be generated during precise syntactic analysis 540 .", "label": "", "metadata": {}, "score": "65.40662"}
{"text": "( Cleo Condoravdi , Richard Crouch & Martin van den Berg ) Proceedings 13th Amsterdam Colloquium , pages 67 - 72 , Amsterdam .[ . pdf ] .( Ash Asudeh & Richard Crouch ) Proceedings 8thInt .Conference on Head - Driven Phrase Structure Grammar , Trondheim . [ . pdf ] .", "label": "", "metadata": {}, "score": "65.55702"}
{"text": "( Cleo Condoravdi , Richard Crouch & Martin van den Berg ) Proceedings 13th Amsterdam Colloquium , pages 67 - 72 , Amsterdam .[ . pdf ] .( Ash Asudeh & Richard Crouch ) Proceedings 8thInt .Conference on Head - Driven Phrase Structure Grammar , Trondheim . [ . pdf ] .", "label": "", "metadata": {}, "score": "65.55702"}
{"text": "Often times changes in discourse segment are introduced but cue phrases such as \" by the way . \"Natural language processing must consider this extended discourse context , including multiple segments .For example , a pronoun may refer to a referent not mentioned in the previous segment but in an earlier segment .", "label": "", "metadata": {}, "score": "65.60899"}
{"text": "These integers are the numbers ( addresses , coordinates ) of the occurrences of each given word ( or wordform ) in the text .Therefore , an indexed database may be searched by accessing the index in order to find the numbers that correspond to the words in the search query .", "label": "", "metadata": {}, "score": "65.6225"}
{"text": "[ 0043 ] FIG .19 is one example of the best syntactic structure with semantic parents of lexical meanings and their grammemes , non - tree links generated and deep slots for the exemplary sentence .[0044 ] FIG .", "label": "", "metadata": {}, "score": "65.69107"}
{"text": "0270 ]A source sentence to be translated by the translation application 2630 may be for example , entered from the keyboard 2658 and selected on the screen of the display 2662 .A microphone 2656 and a speech recognition system can also be used and adapted for machine translation .", "label": "", "metadata": {}, "score": "65.72716"}
{"text": "At present , this is concentrating on the use of semantics and inference to detect inconsistent and redundant content in document collections .Brief History Before joining PARC in December 1998 , I was a lecturer ( i.e. assistant professor in U.S. terminology ) in the Department of Computer Science at Nottingham University , UK .", "label": "", "metadata": {}, "score": "65.82364"}
{"text": "At present , this is concentrating on the use of semantics and inference to detect inconsistent and redundant content in document collections .Brief History Before joining PARC in December 1998 , I was a lecturer ( i.e. assistant professor in U.S. terminology ) in the Department of Computer Science at Nottingham University , UK .", "label": "", "metadata": {}, "score": "65.82364"}
{"text": "Control rules are induced using a novel ILP algorithm which handles difficult issues arising in the induction of search - control heuristics .Both the control - rule framework and the induction algorithm are crucial to CHILL 's success .The main advantage of CHILL over propositional counterparts is its flexibility in handling varied representations .", "label": "", "metadata": {}, "score": "65.83646"}
{"text": "In logical form language , the statement would be : .( THE x : ( DOG1 x ) ( BARKS1 x ) ) .Modal operators are used to represent the meaning of intentional verbs such as believe and want , to represent tense , and for other uses .", "label": "", "metadata": {}, "score": "65.83884"}
{"text": "ML ID : 68 .Learning to Parse Database Queries using Inductive Logic Programming [ Details ] [ PDF ] John M. Zelle and Raymond J. Mooney In AAAI / IAAI , 1050 - 1055 , Portland , OR , August 1996 .", "label": "", "metadata": {}, "score": "65.87546"}
{"text": "It may be segmented either automatically or with human assistance .If the source document is segmented automatically , the segmentation method is selected by the system automatically .To select the appropriate segmentation method , the system may use information about the type , style , or genre of the document .", "label": "", "metadata": {}, "score": "65.98761"}
{"text": "ML ID : 57 .Lexical Acquisition : A Novel Machine Learning Problem [ Details ] [ PDF ] Cynthia A. Thompson and Raymond J. Mooney Technical Report , Artificial Intelligence Lab , University of Texas at Austin , January 1996 .", "label": "", "metadata": {}, "score": "65.99979"}
{"text": "Rules connected with a certain class are used for all its children .In a child class there is a possibility to re - define inherited rules : add new rules , change the order of application , forbid inherited rules , etc . .", "label": "", "metadata": {}, "score": "66.03974"}
{"text": "This view is rightly taken to be absurd .Fortunately , nobody has ever held this position .So what then is the AoS ?First , a negative thesis : syntax is not reducible to operations of the interface systems .", "label": "", "metadata": {}, "score": "66.05124"}
{"text": "Most of these have very restricted domains , that is , they can only handle conversations about limited topics .Suffice it to say that with respect to a natural language processing system that can converse with a human about any topic likely to come up in conversation , we are not there yet .", "label": "", "metadata": {}, "score": "66.056046"}
{"text": "A top - down parser would \" think\"along the following lines : \" To find a sentence meaning S : vp np , find a noun phrase meaning np to the left of a verb phrase meaning vp . \" Bottom - up would be \" If you find a noun phrase meaning np to the left of a verb phrase meaning vp , make them into a sentence meaning S : vp np .", "label": "", "metadata": {}, "score": "66.10483"}
{"text": "Tree least general generalizations ( TLGGs ) of the representations of input sentences are performed to assist in determining the representations of individual words in the sentences .The best guess for a meaning of a word is the TLGG which overlaps with the highest percentage of sentence representations in which that word appears .", "label": "", "metadata": {}, "score": "66.12776"}
{"text": "For example , Richard ( 1990 ) , Crimmins and Perry ( 1989 ) and Crimmins ( 1992 ) .Introduction to Natural Language Processing .Introduction .In this paper I present a general introduction to natural language processing .This is primarily a discussion of how one might go about getting a computer to process a natural language .", "label": "", "metadata": {}, "score": "66.163445"}
{"text": "The OK - KeJia robot prototype is implemented and evaluated , with special attention to two tests on 11,615 user tasks and 467 user desires .The experiments show that the overall performance . ...e semantics .For this purpose , a lexicon with semantically annotated lexemes and a collection of augmented syntax rules ( as - rules , for short ) are hand crafted in our current implementation .", "label": "", "metadata": {}, "score": "66.19819"}
{"text": "CV.pdf ] Selected Papers .( Richard Crouch , Cleo Conodoravdi , Reinhard Stolle , Tracy King , Valeria de Paiva , John Everett & Daniel Bobrow ) Proceedings of Workshop on Scalability in Natural Language Understanding ( ScaNaLU ) , Heidelberg .", "label": "", "metadata": {}, "score": "66.21941"}
{"text": "CV.pdf ] Selected Papers .( Richard Crouch , Cleo Conodoravdi , Reinhard Stolle , Tracy King , Valeria de Paiva , John Everett & Daniel Bobrow ) Proceedings of Workshop on Scalability in Natural Language Understanding ( ScaNaLU ) , Heidelberg .", "label": "", "metadata": {}, "score": "66.21941"}
{"text": "To be able to converse with other humans , even if restricted to textual interaction rather than speech , a computer would probably need not only to process natural language sentences but also possess knowledge of the world .A decent conversation would involve interpretation and generation of natural language sentences , and presumably responding to comments and questions would require some common - sense knowledge .", "label": "", "metadata": {}, "score": "66.342384"}
{"text": "Learning Language from Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen December 2009 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .Most current natural language processing ( NLP ) systems are built using statistical learning algorithms trained on large annotated corpora which can be expensive and time - consuming to collect .", "label": "", "metadata": {}, "score": "66.495964"}
{"text": "Specifically , I will present two probabilistic generative models for learning such correspondences .The models are applied to two publicly available datasets in two different domains , sportscasting and navigation , and compared with previous work on the same data .", "label": "", "metadata": {}, "score": "66.50786"}
{"text": "[ 0033 ] FIG .9 is a diagram illustrating semantic descriptions according to one exemplary embodiment of the NLC method .[ 0034 ] FIG .10 is a diagram illustrating lexical descriptions according to one exemplary embodiment of the NLC method .", "label": "", "metadata": {}, "score": "66.63484"}
{"text": "For future work , I am proposing to solve the more complex task of learning how to give and receive navigation instructions in a virtual environment .In this setting , each instruction corresponds to a navigation plan that is not directly observable .", "label": "", "metadata": {}, "score": "66.75154"}
{"text": "0154 ] The building 1240 of the graph of the generalized constituents is performed .The graph 1202 of generalized constituents which describes all possible syntactic structures of the entire sentence is built by linking and assembling the generalized constituents 1222 to each other .", "label": "", "metadata": {}, "score": "66.76136"}
{"text": "The need for NLIs has become more pronounced given the widespread access to complex databases now available through the Internet .However , such systems are difficult to build and must be tailored to each application .A current research topic involves using machine learning methods to automate the development of NLI 's .", "label": "", "metadata": {}, "score": "66.76544"}
{"text": "[0185 ] As shown in FIG .14 , when the graph of precise constituents 1430 , which covers the sentence , was built , one or more syntactic trees can be generated at the step of generating 1460 during the precise syntactic analysis 540 .", "label": "", "metadata": {}, "score": "66.92209"}
{"text": "Sound structure ( phonological and phonetic ) studies of focus are not as numerous , as relational language phenomena tend to be of greater interest to syntacticians and semanticists .The precise usages of focus in natural language are still uncertain .", "label": "", "metadata": {}, "score": "66.94739"}
{"text": "But secondly , there is the grammar I construct in my natural language processor .These two grammars are not the same , or perhaps they are not the same uses of the term \" grammar . \"Grammar in the first sense defines the language , and in this sense of the term \" grammar \" it makes no sense to say that the grammar analyzes the sentence correctly or incorrectly ; grammar in this sense does n't analyze anything .", "label": "", "metadata": {}, "score": "66.95094"}
{"text": "But efforts met with no real success .For example , from the mid - fifties came the following translation of \" In recent times , Boolean algebra has been successfully employed in the analysis of relay networks of the series - parallel type . \"", "label": "", "metadata": {}, "score": "67.2391"}
{"text": "Integrating Top - down and Bottom - up Approaches in Inductive Logic Programming : Applications in Natural Language Processing and Relational Data Mining [ Details ] [ PDF ] Lappoon R. Tang PhD Thesis , Department of Computer Sciences , University of Texas , Austin , TX , August 2003 .", "label": "", "metadata": {}, "score": "67.318954"}
{"text": "A natural language processor in the full sense should be able to not only interpret or understand natural language sentences , but also generate them and participate in a conversation ( a natural dialogue ) with another natural language processor , whether human or computer .", "label": "", "metadata": {}, "score": "67.42661"}
{"text": "One problem is that in the published writings we find appeals to a substitutivity principle about reference , but no analogous principle about sense .Another problem is that in the Grundlagen Frege announces his famous context principle , which on certain interpretations contradicts certain interpretations of compositionality ; cf .", "label": "", "metadata": {}, "score": "67.656715"}
{"text": "Finite - state grammars are not recursive and thus can stumble on long sentences thus extended , perhaps stuck on extensive backtracking .It seems to me that , given an infinitely fast computer with an infinite amount of storage space , and an infinite time to program the vocabulary , a state - machine parser would correctly interpret many sentences in the language by a sort of brute - force method .", "label": "", "metadata": {}, "score": "67.74603"}
{"text": "The system does not use any prior language knowledge and was able to learn to sportscast in both English and Korean .Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans .", "label": "", "metadata": {}, "score": "67.8291"}
{"text": "A generalized constituent model of a lexeme contains a generalized deep model and a generalized surface model .A generalized deep model of a lexeme includes the list of all of the deep slots which have the same lexical meaning for a lexeme , together with the descriptions of all the requirements for the fillers of the deep slots .", "label": "", "metadata": {}, "score": "67.85794"}
{"text": "The built - in reader can be used to build a Prolog natural language tokenizer that can tokenize strings that consist of valid Prolog terms .Using this Prolog reader , and a built - in \" operator \" predicate to define other operators that can connect nouns , for instance , an elementary natural language processor can be built that can parse simple sentences .", "label": "", "metadata": {}, "score": "67.88303"}
{"text": "Scripts can be described in terms of actions or states as goals , such as \" taking the train to Rochester \" or \" getting to Rochester , \" and these goals might be used by the system to locate the relevant script .", "label": "", "metadata": {}, "score": "67.93139"}
{"text": "Because there is no rule in ( 14 ) or ( 15 ) that licenses F - marking to the direct object from any other node , the direct object parrot must be accented as indicated in bold .Rule ( 15b ) allows F - marking to project from the direct object to the head verb adopted .", "label": "", "metadata": {}, "score": "67.93313"}
{"text": "[ iwcs.pdf ] .( Richard Crouch , Anette Frank & Josef van Genabith ) .In Bunt , Muskens & Thijsse ( eds )Computing Meaning , volume 2 , ( Studies in Linguistics and Philosophy , 77 ) , Kluwer .", "label": "", "metadata": {}, "score": "67.94495"}
{"text": "[ iwcs.pdf ] .( Richard Crouch , Anette Frank & Josef van Genabith ) .In Bunt , Muskens & Thijsse ( eds )Computing Meaning , volume 2 , ( Studies in Linguistics and Philosophy , 77 ) , Kluwer .", "label": "", "metadata": {}, "score": "67.94495"}
{"text": "For example , after checking with agreement rules , the mask of a pronoun can be empty such that any linking or pairing up between the controller and its proform can not be established .For example , in some cases , the gender of the controller and the pronoun may not agree ; in these cases , only limited numbers of proforms inserted .", "label": "", "metadata": {}, "score": "67.94721"}
{"text": "[0106 ]Different surface slots 815 may be in a strict and/or variable relationship in the syntform 812 .For example , parenthesis may be used to build the linear order expressions and describe strict linear order relationships between different surface slots 815 .", "label": "", "metadata": {}, "score": "67.97833"}
{"text": "The system of claim 26 , wherein the search reveals at least one matching translation .The method of system 27 , wherein the search is an exact search where the or each matching translation corresponds exactly to the document fragment .", "label": "", "metadata": {}, "score": "68.01245"}
{"text": "Active learning methods attempt to select for annotation and training only the most informative examples , and therefore are potentially very useful in natural language applications .However , existing results for active learning have only considered standard classification tasks .To reduce annotation effort while maintaining accuracy , we apply active learning to two non - classification tasks in natural language processing : semantic parsing and information extraction .", "label": "", "metadata": {}, "score": "68.08141"}
{"text": "ML ID : 229 .A Dependency - based Word Subsequence Kernel [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the conference on Empirical Methods in Natural Language Processing ( EMNLP-2008 ) , 400 - -409 , Waikiki , Honolulu , Hawaii , October 2008 .", "label": "", "metadata": {}, "score": "68.14488"}
{"text": "In this paper I 'll mostly ignore the topic of signal processing .Computers most often take text input directly , whether at the keyboard or read from a file or other source , rather than interpret spoken language .There are some sophisticated systems , and even some less costly ones anybody can buy , that process spoken words more or less successfully to translate them into text form .", "label": "", "metadata": {}, "score": "68.18057"}
{"text": "There are two major ILP approaches : top - down and bottom - up .The former searches the hypothesis space from general to specific while the latter the other way round .Integrating both approaches has been demonstrated to be more effective .", "label": "", "metadata": {}, "score": "68.219894"}
{"text": "The best known systems of this type are SYSTRAN and PROMPT .The known RBMT systems , however , usually possess restricted syntactic models and simplified dictionary descriptions where language ambiguities are artificially removed .[0007 ] Rule - based MT has evolved into Model - Based MT ( MBMT ) which is based on linguistic models .", "label": "", "metadata": {}, "score": "68.25132"}
{"text": "[0194 ]The rules of additional restrictions are checked during the stage 1460 to make sure whether a constituent meets the restrictions but also suggest the steps which should be taken in certain slots so that the constituent will meet the restrictions .", "label": "", "metadata": {}, "score": "68.33295"}
{"text": "A traversal of the tree from the top down is made , starting the rules which were postponed at the first stage .Once again , a traversal of the tree from the child constituents to the parent is made by starting the rest of the postponed rules .", "label": "", "metadata": {}, "score": "68.347176"}
{"text": "Social .Family .Addresses .Side Projects .Senior member of research staff Natural Language Theory and Technology Information Sciences and Technologies Laboratory ( ISTL ) Palo Alto Research Center 3333 Coyote Hill Rd .Palo Alto , CA 94304 phone : ( 650 ) 812 - 4746 fax : ( 650 ) 812 - 4374 Research Interests Principal interests in computational semantics and pragmatics , especially ambiguity management , context - dependency , the syntax - semantics interface , and natural language understanding / knowledge representation .", "label": "", "metadata": {}, "score": "68.428276"}
{"text": "If the ellipsis restoration 1260 is needed and called upon during the rough syntactic analysis 530 due to , for example , the presence of constituents left alone without any parent constituents being attached to , only these constituents are processed .", "label": "", "metadata": {}, "score": "68.42969"}
{"text": "Further possible applications of the presented approaches include summarized machine translation tasks and learning from real perception data assisted by computer vision and robotics .ML ID : 291 .Adapting Discriminative Reranking to Grounded Language Learning [ Details ] [ PDF ] [ Slides ] Joohyun Kim and Raymond J. Mooney In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL-2013 ) , 218 - -227 , Sofia , Bulgaria , August 2013 .", "label": "", "metadata": {}, "score": "68.4431"}
{"text": "Future work includes extending the algorithm and performing tests on a more realistic corpus .ML ID : 56 .Using Inductive Logic Programming to Automate the Construction of Natural Language Parsers [ Details ] [ PDF ] John M. Zelle PhD Thesis , Department of Computer Sciences , The University of Texas at Austin , Austin , TX , 1995 .", "label": "", "metadata": {}, "score": "68.49599"}
{"text": "Events are important in many theories because they provide a structure of organizing the interpretation of sentences .Actions are carried out by agents .Also important is the already mentioned notion of a situation .Just noting different senses of a word does not of course tell you which one is being used in a particular sentence , and so ambiguity is still a problem for semantic interpretation .", "label": "", "metadata": {}, "score": "68.505585"}
{"text": "[ . pdf ] .( Hiyan Alshawi and Richard Crouch )Proc . 30th ACL .[ . pdf ] .Teaching Material At various times I have found myself preparing notes for lecture courses .Here are some of them , without any guarantees as to their accuracy , usefulness , lack of plagiarism , completeness , or coherence : .", "label": "", "metadata": {}, "score": "68.575"}
{"text": "[ . pdf ] .( Hiyan Alshawi and Richard Crouch )Proc . 30th ACL .[ . pdf ] .Teaching Material At various times I have found myself preparing notes for lecture courses .Here are some of them , without any guarantees as to their accuracy , usefulness , lack of plagiarism , completeness , or coherence : .", "label": "", "metadata": {}, "score": "68.575"}
{"text": "Barbara Partee gave her first lecture today ( which was very interesting btw ) and discussed three versions of the autonomy of syntax thesis ( AoS ) that I would like to quickly comment on here .Non- generativists regularly advert to the AoS citing it as one of Generative Grammar 's more obvious absurdities ( e.g. see here ) .", "label": "", "metadata": {}, "score": "68.58595"}
{"text": "It is a bit hard to define in full generality what it is for an expression to be a constituent of another .( This problem does not arise if we require the syntactic algebra to be a term algebra . )", "label": "", "metadata": {}, "score": "68.622055"}
{"text": "[0158 ] The building 1240 of the graph of the generalized constituents can be impossible without ellipsis restoration 1260 .Ellipsis is a language phenomenon which is represented by the absence of core constituents .Ellipsis can also be related with coordination .", "label": "", "metadata": {}, "score": "68.65848"}
{"text": "I am developing will or will not be a good one if it makes the right judgments corresponding to accepted sentences defined by the language 's own grammar .Discussions of syntactic analysis distinguish among different types of grammar , meaning grammar in this second sense of the rules being followed in the natural language processor under construction .", "label": "", "metadata": {}, "score": "68.69222"}
{"text": "The restrictions used during the stage 1460 can be defined for any surface slot and the corresponding deep slot .On the basis of the specified restrictions , the difference in quality between the best and second - best tree for this surface slot is calculated .", "label": "", "metadata": {}, "score": "68.71471"}
{"text": "5B illustrates transforming of the source sentence 512 into the output sentence 514 through various structures according to an exemplary embodiment of the invention .[ 0086 ] As shown in FIGS .5A and 5B , the method 500 for translating a source sentence 512 in a source / input language into an output sentence 514 includes using linguistic descriptions adapted to perform various steps of analysis and synthesis .", "label": "", "metadata": {}, "score": "68.72148"}
{"text": "ML ID : 99 .Learning for Semantic Interpretation : Scaling Up Without Dumbing Down [ Details ] [ PDF ] Raymond J. Mooney In Workshop Notes for the Workshop on Learning Language in Logic , 7 - 15 , Bled , Slovenia , 2000 .", "label": "", "metadata": {}, "score": "68.87552"}
{"text": "We demonstrate its capabilities by developing a system that learns to sportscast simulated robot soccer games in both English and Korean without any language - specific prior knowledge .Training employs only ambiguous supervision consisting of a stream of descriptive textual comments and a sequence of events extracted from the simulation trace .", "label": "", "metadata": {}, "score": "68.89499"}
{"text": "Any constituent is formed by a lexeme - core which may have outgoing named arrows which denotes surface slots 815 filled by child constituents .An incoming arrow means attaching this constituent to a surface slot of another constituent .The graph 1300 is so complicated and has so many arrows , because it shows all relationships which can be established between constituents of the sentence \" This boy is smart , he 'll succeed in life . \"", "label": "", "metadata": {}, "score": "68.943634"}
{"text": "Proforms which were substituted during the rough syntactic analysis but have not received a controller can be deleted from the syntactic structure .[0206 ]During the stage 1470 , for every syntactic tree , a best syntactic structure with attached non - tree links can be generated , as a result .", "label": "", "metadata": {}, "score": "68.99968"}
{"text": "This paper reviews our recent work on applying inductive logic programming to the construction of natural language processing systems .We have developed a system , CHILL , that learns a parser from a training corpus of parsed sentences by inducing heuristics that control an initial overly - general shift - reduce parser .", "label": "", "metadata": {}, "score": "69.03"}
{"text": "Automating the construction of semantic grammars is a difficult and interesting problem for machine learning .This paper shows how the semantic - grammar acquisition problem can be viewed as the learning of search - control heuristics in a logic program .", "label": "", "metadata": {}, "score": "69.04649"}
{"text": "Some authors seem to think that this type of parser is based on a particular understanding of how humans produce sentences .Maybe it was originally , but I think that now one could build a state - machine parser for a particular application because it is useful and yet claim that humans actually build sentences in an entirely different way .", "label": "", "metadata": {}, "score": "69.082306"}
{"text": "ML ID : 269 .Learning to Interpret Natural Language Navigation Instructions from Observations [ Details ] [ PDF ] [ Slides ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th AAAI Conference on Artificial Intelligence ( AAAI-2011 ) , 859 - 865 , August 2011 .", "label": "", "metadata": {}, "score": "69.10214"}
{"text": "0182 ] Coordination is also processed when a child constituent attached during the stage 1450 .For slots filled by coordination , there exists a need to check that not only the apex of coordination can be attached but its other components as well .", "label": "", "metadata": {}, "score": "69.12846"}
{"text": "0222 ] FIG .21 illustrates an exemplary resulting semantic structure 1700 of the sentence \" This boy is smart , he 'll succeed in life .\"The deep constituents are represented by rectangles with a semantic class indicated inside , for example , DECLARATIVE_MAIN_CLAUSE , TO_SUCCEED , BOY , LIVE , etc .", "label": "", "metadata": {}, "score": "69.18533"}
{"text": "Since there may be many lexical meanings meeting the conditions of lexical selection 2220 , lexical meanings having a best rating are selected at first .There are cases , however , when the rules 2224 of lexical selection and structure correction have to be used .", "label": "", "metadata": {}, "score": "69.236336"}
{"text": "5A illustrates a flow diagram of the employing the NLC method which uses linguistic descriptions according to one embodiment of the invention .[ 0029 ] FIG .5B illustrates converting the source fragment into an output fragment through various linguistic structures employing the NLC method which uses linguistic descriptions according to one embodiment of the invention .", "label": "", "metadata": {}, "score": "69.243454"}
{"text": "James Allen has the second edition of what is considered the standard work here , Natural Language Understanding , and I draw from that source frequently .Before proceeding I should note , however , two other processes that have to occur for natural language processing : tokenization and machine level processing .", "label": "", "metadata": {}, "score": "69.27774"}
{"text": "Semantic hierarchy 910 may include semantic notions or semantic entities named semantic classes , arranged into hierarchical parent - child relationships .In general , a child semantic class inherits most properties of its direct parent and all ancestral semantic classes .", "label": "", "metadata": {}, "score": "69.2837"}
{"text": "The verb phrase is then broken down into the verb \" ran , \" the adverb \" quickly , \" and the noun phrase \" to the house .\" This noun phrase is further broken up into preposition and noun phrase , and the noun phrase then into article and noun .", "label": "", "metadata": {}, "score": "69.39134"}
{"text": "Experimental results show that the resulting system is able to cope up with ambiguities and learn accurate semantic parsers .ML ID : 200 .Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus [ Details ] [ PDF ] Yuk Wah Wong and Raymond J. Mooney In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics ( ACL-2007 ) , Prague , Czech Republic , June 2007 .", "label": "", "metadata": {}, "score": "69.413025"}
{"text": "In addition , the models 1232 of the generalized constituents can be used during the building 1450 of the graph of precise constituents .[0174 ]During the precise syntactic analysis 540 , the precise constituents are built recursively .Proper constituents are generated backwardly and recursively .", "label": "", "metadata": {}, "score": "69.605774"}
{"text": "Whatever we take the contribution of the left arrow to be , it is hard to accept that the meanings of both these traffic signs are determined compositionally .( As always , there are all sorts of maneuvers that could save compositionality .", "label": "", "metadata": {}, "score": "69.65401"}
{"text": "Restoring 2260 movements and determining the linear order is performed for the best surface structure .During this step referential and structural control is checked and movements are restored .The relations of control may be represented in the surface structure by means of non - tree links .", "label": "", "metadata": {}, "score": "69.71161"}
{"text": "Besides our representation of syntactic structure and logical form , then , we need a way of representing such background knowledge and reasoning .The new level of representation is knowledge representation .( KR ) , and the language we use for it will be a knowledge representation language ( KRL ) .", "label": "", "metadata": {}, "score": "69.74684"}
{"text": "0010 ] Most machine translation systems , both rule - based and statistics - based , concentrate on proper transfer of language information directly between a source sentence and an output sentence and usually do not require any full - fledged intermediary data structures to explicate the meaning of the sentence being translated .", "label": "", "metadata": {}, "score": "69.89577"}
{"text": "[ 0208 ] FIG .19 illustrates a best syntactic structure 1900 with semantic parents of lexical meanings and their grammemes generated for the sentence \" This boy is smart , he 'll succeed in life .\" during the precise syntactic analysis 540 .", "label": "", "metadata": {}, "score": "69.96823"}
{"text": "ML ID : 180 .A Statistical Semantic Parser that Integrates Syntax and Semantics [ Details ] [ PDF ] Ruifang Ge and Raymond J. Mooney In Proceedings of CoNLL-2005 , Ann Arbor , Michigan , June 2005 .We introduce a learning semantic parser , Scissor , that maps natural - language sentences to a detailed , formal , meaning - representation language .", "label": "", "metadata": {}, "score": "69.97031"}
{"text": "Additionally , the corrected translation variant is recorded in the translation database and will have the highest rating for this user in the future .At the end of step 230 , the source fragment , if found in the database , will be replaced in the document by the found translation 204 .", "label": "", "metadata": {}, "score": "69.9866"}
{"text": "Can computers understand natural languages yet ?Early efforts at NLP include the National Research Council attempt in the late forties or early fifties to develop a system that could translate among human languages .Full fluency was predicted within five years .", "label": "", "metadata": {}, "score": "70.056564"}
{"text": "One attempt to help with this is for the different senses can be organized into a set of classes of objects ; this representation is called an ontology .Aristotle noted classes of substance , quantity , quality , relation , place , time , position , state , action , and affection , and Allen notes we can add events , ideas , concepts , and plans .", "label": "", "metadata": {}, "score": "70.28245"}
{"text": "Precise Syntactic Analysis . [0165 ] FIG .14 illustrates in detail the precise syntactic analysis 540 performed to select the best syntactic structure 1402 according one or more embodiments of the invention .The precise syntactic analysis 540 is performed top - down from the higher levels to the bottom lower levels , from the node of the potential top of the graph 1202 of the generalized constituents down to its bottom - level child constituents .", "label": "", "metadata": {}, "score": "70.28552"}
{"text": "Learning for Semantic Parsing Using Statistical Syntactic Parsing Techniques [ Details ] [ PDF ] [ Slides ] Ruifang Ge PhD Thesis , Department of Computer Science , University of Texas at Austin , Austin , TX , May 2010 .165 pages .", "label": "", "metadata": {}, "score": "70.36453"}
{"text": "Experiments show the potential of the approach .ML ID : 301 .Grounded Language Learning Models for Ambiguous Supervision [ Details ] [ PDF ] [ Slides ] Joo Hyun Kim PhD Thesis , Department of Computer Science , University of Texas at Austin , December 2013 .", "label": "", "metadata": {}, "score": "70.43211"}
{"text": "We introduce a dialog agent for mobile robots that understands human instructions through semantic parsing , actively resolves ambiguities using a dialog manager , and incrementally learns from human - robot conversations by inducing training data from user paraphrases .Our dialog agent is implemented and tested both on a web interface with hundreds of users via Mechanical Turk and on a mobile robot over several days , tasked with understanding navigation and delivery requests through natural language in an office environment .", "label": "", "metadata": {}, "score": "70.485855"}
{"text": "4 is detailed illustration of step 120 of translating the untranslated fragments using the NLC system which employs linguistic descriptions and a semantic structure to represent the meaning of the source .The step includes the translation proper of the fragment 410 with the NLC system .", "label": "", "metadata": {}, "score": "70.606316"}
{"text": "The big question to answer in defining a conversational agent is , why should the agent ever speak ?What motivates it to say anything or to attempt to comprehend the utterances that are said to it ?A very simple NLP that engaged in conversation might do so because it was programmed to do so , in the manner of a database question - answering agent .", "label": "", "metadata": {}, "score": "70.6599"}
{"text": "Finally , we also plan to investigate ways to combine our semantic parser with some recently developed semantic parsers to form committees in order to get the best overall performance .ML ID : 181 .Learning for Semantic Parsing Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong 2005 .", "label": "", "metadata": {}, "score": "70.718765"}
{"text": "Experimental results are presented on learning to map English coaching instructions for Robocup soccer into an existing formal language for coaching simulated robotic agents .ML ID : 140 .Learning Semantic Parsers : An Important But Under - Studied Problem [ Details ] [ PDF ] Raymond J. Mooney In Papers from the AAAI 2004 Spring Symposium on Language Learning : An Interdisciplinary Perspective , 39 - -44 , Stanford , CA , March 2004 .", "label": "", "metadata": {}, "score": "70.85483"}
{"text": "The system of claim 28 , wherein said translating comprises substituting one matching translation for the document fragment .The method of claim 30 , or claim 31 , wherein the one matching translation is the matching translation in the case of a single matching translation or a selected matching translation from a set of translation variants in the case of more that one matching translation .", "label": "", "metadata": {}, "score": "70.872375"}
{"text": "ML ID : 171 .Learning to Transform Natural to Formal Languages [ Details ] [ PDF ] [ Slides ] Rohit J. Kate , Yuk Wah Wong and Raymond J. Mooney In Proceedings of the Twentieth National Conference on Artificial Intelligence ( AAAI-05 ) , 1062 - 1068 , Pittsburgh , PA , July 2005 .", "label": "", "metadata": {}, "score": "70.92057"}
{"text": "For example , the algorithm decides whether to examine the tokens from left to right or vice versa , whether to use a depth - first or breadth - first method , whether to proceed in a top - down or bottom - up method , etc .", "label": "", "metadata": {}, "score": "70.96802"}
{"text": "0115 ]Deep slots descriptions 920 are used to describe the properties of the deep slots 914 and reflect the semantic roles of child constituents in the deep models 912 .The deep slots descriptions 920 also contain grammatical and semantic restrictions on what could be the possible fillers of the deep slots 914 .", "label": "", "metadata": {}, "score": "71.08101"}
{"text": "\" One way to analyze this is to consider it as a complete verb phrase , with the verb \" put , \" the noun phrase \" the book , \" and the prepositional phrase \" on the table . \"Another way to analyze it is to consider \" the book on the table \" as itself the noun phrase , with no additional prepositional phrase .", "label": "", "metadata": {}, "score": "71.172646"}
{"text": "As a result of the rough syntactic analysis 530 , the graph 1202 of generalized constituents is built which represents the whole sentence .[ 0142 ]FIG .12 illustrates in further detail the rough syntactic analysis 530 according to one or more embodiments of the invention .", "label": "", "metadata": {}, "score": "71.2789"}
{"text": "We report experimental results on two real applications , an interpreter for coaching instructions in robotic soccer and a natural - language database interface .The results show that reranking can improve the performance on the coaching interpreter , but not on the database interface .", "label": "", "metadata": {}, "score": "71.3528"}
{"text": "Or one could use thematic roles , in which John has the role of agent , the window has the role of theme , and hammer has the role of instrument .Other situations might require the roles of \" from a location , \" to a location , \" and the \" path along a location , \" and even more roles can be symbolized .", "label": "", "metadata": {}, "score": "71.3582"}
{"text": "A non - tree link of type \" Anaphoric Model -- Subject \" 1810 is established from the constituent \" boy \" 1820 to the constituent \" he \" 1830 to identify the subjects of the two parts of the complex sentence .", "label": "", "metadata": {}, "score": "71.434845"}
{"text": "If the VP in ( 21a ) is the salient antecedent for the VP in ( 21b ) , then the VP in ( 21b ) counts as given .-type - shifed VP in ( 21a ) is shown in ( 22 ) .", "label": "", "metadata": {}, "score": "71.61067"}
{"text": "A predicate operator takes a predicate as an argument and produces a new predicate ; this is used to deal with plural forms , such as in \" the dogs bark .\" If DOG1 is a predicate true of any dog , then ( PLUR DOG1 ) is a predicate true of any set of dogs .", "label": "", "metadata": {}, "score": "71.70935"}
{"text": "What should we say about the fact that the meaning of one traffic sign can supplement the meaning of another ?In spelling out the meanings of traffic signs should we include indexicals - e.g. , ' No left turn here ' ?", "label": "", "metadata": {}, "score": "71.76329"}
{"text": "Besides the choice of strategy direction as top - down or bottom - up , there is also the aspect of whether to proceed depth - first or breadth - first .To understand the difference between these two strategies , it helps to have worked through searching algorithms in a data structures course , but I 'll try to explain the main idea .", "label": "", "metadata": {}, "score": "71.8197"}
{"text": "[ 0263 ] The invention is operational with numerous other general purpose or special purpose computing system environments or configurations .[0264 ] The invention may be described in the general context of computer - executable instructions , such as program modules , being executed by a computer .", "label": "", "metadata": {}, "score": "71.82536"}
{"text": "Thus , for example , the frame for a house may have slots of kitchen , living room , etc .The frame will also specify the relationships between slots and the object represented by the frame itself .The slot notation can be extended to show relations between the frame and other propositions or events , especially preconditions , effects , and decomposition ( the way an action is typically performed ) .", "label": "", "metadata": {}, "score": "71.909836"}
{"text": "[0223 ] FIG .22 illustrates one example of a method 2200 exemplifying process flow diagram of synthesis 560 of an output natural language sentence .The step is illustratively described below can be configured to generating a surface syntactic structure of a sentence in an output language from a language - independent semantic structure , such as a language - independent semantic structure generated after analyzing a source sentence in a source language .", "label": "", "metadata": {}, "score": "71.92557"}
{"text": "Generative theories have generally respected this version of the AoS as well , though there have been suggested principles that violate it ( at least in spirit ) .The Fox - Reinhart thesis is a contemporary example .It sanctions movement just in case the movement has an effect on meaning ( Chomsky 's version adds a strong feature to the derivation just in case it has an effect on interpretation ) .", "label": "", "metadata": {}, "score": "72.081795"}
{"text": "6 illustrates language descriptions 610 including morphological descriptions 501 , lexical descriptions 503 , syntactic descriptions 502 , and semantic descriptions 504 , and interrelationship between them .Among them , the morphological descriptions 501 , the lexical descriptions 503 , and the syntactic descriptions 502 are language - specific .", "label": "", "metadata": {}, "score": "72.13681"}
{"text": "Noise - disposal parsers .State - machine parsers ( finite - state machine parsers ) .Definite clause grammar parsers ( similar to phrase structure grammar parsers ) .This may be accurate , but the types seem mixed together .", "label": "", "metadata": {}, "score": "72.168564"}
{"text": "6 is a diagram illustrating language descriptions according to one exemplary embodiment of the NLC method .[0031 ] FIG .7 is a diagram illustrating morphological descriptions according to one exemplary embodiment of the NLC method .[ 0032 ] FIG .", "label": "", "metadata": {}, "score": "72.32918"}
{"text": "If the controlled proform is related to the subject , both the variants are possible , otherwise only a relative clause is possible .An attempt to use a participial clause in order to realize a verb attribute of a noun phrase in the control rule fails , and thus such a variant is discarded .", "label": "", "metadata": {}, "score": "72.40929"}
{"text": "Learning for Semantic Parsing [ Details ] [ PDF ] Raymond J. Mooney In A. Gelbukh , editors , Computational Linguistics and Intelligent Text Processing : Proceedings of the 8th International Conference ( CICLing 2007 ) , 311 - -324 , Mexico City , Mexico , February 2007 .", "label": "", "metadata": {}, "score": "72.47883"}
{"text": "But of course , Allen notes , this type of simple agent would n't be considered very intelligent or conversational .This type of agent would have no chance of passing the Turing test , for example , because it would n't be flexible and would n't seem at all able to generate an independent response or initiate a line of dialogue .", "label": "", "metadata": {}, "score": "72.51851"}
{"text": "But yet if the phrase is included in the longer sentence \" Put the book on the table in your pocket , \" then it invites the latter analysis , because it refers to a book already on the table .Depending on how the phrase it used in any particular sentence , grammar alone might not decide how to correctly analyze this phrase syntactically .", "label": "", "metadata": {}, "score": "72.5206"}
{"text": "In view of this controversy over whether digital computers of the type under consideration can ever understand anything , use of the phrase \" natural language understanding \" seems to slant the issue unless one qualifies the use of the phrase \" understanding .", "label": "", "metadata": {}, "score": "72.64078"}
{"text": "The dispatcher 1290 can be a device , system , or algorithm , which keeps all the information about the constituents that have been modified .A constituent is considered modified if changes have been introduced to any of its properties which describe the sub - tree , including boundaries and the set of pre - child constituents .", "label": "", "metadata": {}, "score": "72.65511"}
{"text": "The generalized constituents 1222 are used to build the graph 1430 of precise constituents for generating one or more trees of precise constituents .For each generalized constituent , its possible boundaries and its child constituents are marked .[ 0175 ] The stage 1460 for generating the syntactic trees is performed to generate the best syntactic tree 1420 .", "label": "", "metadata": {}, "score": "72.70378"}
{"text": "Human evaluations of the generated commentaries indicate they are of reasonable quality compared to human commentaries .ML ID : 219 .Learning for Semantic Parsing with Kernels under Various Forms of Supervision [ Details ] [ PDF ] [ Slides ] Rohit J. Kate PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .", "label": "", "metadata": {}, "score": "72.78447"}
{"text": "The computer is going to act in a deterministic fashion in accordance with its program , so that it must be programmed when to initiate a conversation , for example .It 's not going to be all that far off , then , from the simple database program alluded to earlier .", "label": "", "metadata": {}, "score": "72.968735"}
{"text": "27 is a block diagram of a translation system and its interaction with other applications in accordance with one embodiment of the invention .DETAILED DESCRIPTION .[0052 ] Embodiments of the invention provide a hybrid method and computer systems configured to efficiently and completely translate a document in an input language into an output language .", "label": "", "metadata": {}, "score": "72.9695"}
{"text": "Thus in \" the man kept the dog in the house , \" the interpretation is that \" in the house \" applies to \" kept \" rather than \" dog .\" Right association ( late closure ) : all other things being equal , interpret new constituents as part of the current constituent under construction , rather than part of some constituent higher in the parse tree .", "label": "", "metadata": {}, "score": "73.22966"}
{"text": "[ 0100 ] The surface models 810 are represented as aggregates of one or more syntactic forms ( \" syntforms \" 812 ) in order to describe possible syntactic structures of sentences in a given language .[ 0102 ] The surface slots descriptions 820 as a part of syntactic descriptions 502 are used to describe the general properties of the surface slots 815 that are used in the surface models 810 of various lexical meanings in the source language .", "label": "", "metadata": {}, "score": "73.4477"}
{"text": "Second , adopting a syntax - based approach allows us to directly leverage the enormous progress made in statistical syntactic parsing .The first semantic parser , SCISSOR , adopts an integrated syntactic - semantic parsing approach , in which a statistical syntactic parser is augmented with semantic parameters to produce a semantically - augmented parse tree ( SAPT ) .", "label": "", "metadata": {}, "score": "73.592804"}
{"text": "In 1966 , after spending $ 20 million , the NRC 's Automated Language Processing Advisory Committee recommended no further funding for the project .Instead , they thought , the focus of funding should shift to the study of language understanding .", "label": "", "metadata": {}, "score": "73.62288"}
{"text": "People act to achieve goals .A way to model this is use the concepts of perceptions ( of the world ) , which include : . beliefs ( about the world ) , . desires and wants ( positive or negative responses to states of the world , enabling comparison of the desirability of these states ) , .", "label": "", "metadata": {}, "score": "73.85884"}
{"text": "There is also usually associated the technical goal of getting a computer to process natural language sentences .Humans are of course able to process and understand natural languages , but the real interest in natural language processing here is in whether a computer can or will be able to do it .", "label": "", "metadata": {}, "score": "73.885315"}
{"text": "ML ID : 92 .Semantic Lexicon Acquisition for Learning Natural Language Interfaces [ Details ] [ PDF ] Cynthia Ann Thompson PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , December 1998 .", "label": "", "metadata": {}, "score": "73.93982"}
{"text": "We compare a number of semantic parsing approaches on the highly noisy training data collected from ordinary users , and find that loosely synchronous systems perform best .ML ID : 317 .Intelligent robots frequently need to understand requests from naive users through natural language .", "label": "", "metadata": {}, "score": "74.070404"}
{"text": "For example , even when a machine receives text from the keyboard , the text enters the machine as stream of ASCII characters , which must be classified into individual units , such as words or letter / number characters .6 The computer does n't know how to consider the ASCII characters types into it unless it is told to expect characters , integers , floating point numbers , a string , etc .", "label": "", "metadata": {}, "score": "74.09991"}
{"text": "One can indeed say that English contains the sentences ' I have one kumquat ' , ' I have two kumquats ' , ' I have three kumquats ' , ... but I do n't think we could continue this series ad infinitum without recourse to elaborate mathematical notation .", "label": "", "metadata": {}, "score": "74.47792"}
{"text": "Here are some other important distinctions relating to knowledge representation .Relations of entailment must be distinguished from relations of implication .When a formula P must be true given the formulas in a knowledge base , the KB entails P. Implications , on the other hand , are conclusions that might typically be derived from a sentence but that could be denied in specific circumstances .", "label": "", "metadata": {}, "score": "74.48171"}
{"text": "[ 0236 ] FIG .23 is a diagram schematically illustrating the idea of a surface structure 2300 of a synthesized sentence according to one or more embodiments of the invention .In FIG .23 , constituents of the surface structure 2204 are shown as rectangles , arrows show filled surface slots .", "label": "", "metadata": {}, "score": "74.52546"}
{"text": "Inductive Logic Programming for Natural Language Processing [ Details ] [ PDF ] Raymond J. Mooney In Stephen Muggleton , editors , Inductive Logic Programming : Selected papers from the 6th International Workshop , 3 - 22 , Berlin , 1996 .", "label": "", "metadata": {}, "score": "74.563065"}
{"text": "The performance of semantic parsing can be potentially improved by using discriminative reranking , which explores arbitrary global features .In this paper , we investigate discriminative reranking upon a baseline semantic parser , SCISSOR , where the composition of meaning representations is guided by syntax .", "label": "", "metadata": {}, "score": "74.846016"}
{"text": "The term \" processing \" is perhaps preferable to \" understanding \" in this context , but \" understanding \" has a history here and I am not advocating we discontinue use of the term .Certainly in this paper if I use the terms \" understanding \" or \" knowledge \" metaphorically with reference to computers , I imply nothing about whether they can or will ever really understand or know in any philosophically interesting sense .", "label": "", "metadata": {}, "score": "74.87558"}
{"text": "The method of claim 9 , further comprising performing one of creating and selecting the terminology dictionary for a given subject domain .The method of claim 9 , further comprising performing one of creating and selecting the translation dictionary for a given subject domain .", "label": "", "metadata": {}, "score": "75.06215"}
{"text": "Consequently , every lexical meaning connected with a proform may have its referential control rule .[ 0251 ] The non - tree links on the surface ( syntactic ) structure for the Russian sentence which is obtained as result of translating the above mentioned English sentence \" This boy is smart , he 'll succeed in life . \" according to one embodiment of the invention are shown on FIG .", "label": "", "metadata": {}, "score": "75.14644"}
{"text": "Two new integrated ILP systems for these tasks that overcome limitations of existing methods will be presented .Cocktail is a new ILP algorithm for inducing semantic parsers .For this task , two features of a parse state , functional structure and context , provide important information for disambiguation .", "label": "", "metadata": {}, "score": "75.21434"}
{"text": "While at SRI I worked on the Core Language Engine , and was also a member of the LRE project Frameworks for Computational Semantics ( FraCaS ) .I have served on the editorial boards of Computational Linguistics and Personal Technologies .", "label": "", "metadata": {}, "score": "75.37065"}
{"text": "While at SRI I worked on the Core Language Engine , and was also a member of the LRE project Frameworks for Computational Semantics ( FraCaS ) .I have served on the editorial boards of Computational Linguistics and Personal Technologies .", "label": "", "metadata": {}, "score": "75.37065"}
{"text": "During coordination processing 1250 , the linear order and multiple filling possibility of the surface slot are determined .If the attachment is possible , a proform which refers to the common child constituent is created and attached .As shown in FIG .", "label": "", "metadata": {}, "score": "75.395996"}
{"text": "Programs that could check for grammar and writing techniques in a word processing document .A computer that could read a human language could read whole books to stock its database with data .This would surely be easier than what Doug Lenat is trying to do with CYC .", "label": "", "metadata": {}, "score": "75.43163"}
{"text": "A word with different senses is said to have lexical ambiguity .At the semantic level one must also note the possibility of structural ambiguity .\" Every boy loves a dog \" is ambiguous between many dogs or one dog .", "label": "", "metadata": {}, "score": "75.54221"}
{"text": "An example of an elliptical English sentence is \" The president signed the agreement and the secretary [ signed ] the protocol . \"As discussed above , the ellipsis restoration 1260 can be used to generate the new request and new constituent pairs .", "label": "", "metadata": {}, "score": "75.588745"}
{"text": "As another example , \" each of all of us \" can be normalized to \" each of us \" .As still another example , \" He can do it , ca n't he ? \" can be normalized to \" He can do it . \" ; since the deep slot of TagQuestion is filled and saved in the semantic structure , the constituents \" ca n't he \" are removed .", "label": "", "metadata": {}, "score": "75.600716"}
{"text": "Proceedings of Int .Conference on Formal Ontologies in Information Systems , Maine .[ . pdf ] .( Richard Crouch , Anette Frank & Josef van Genabith ) .Proceedings 4th International Workshop on Computational Semantics , Tilburg .Revised version to appear in Bunt & Muskens ( eds )", "label": "", "metadata": {}, "score": "75.63461"}
{"text": "Proceedings of Int .Conference on Formal Ontologies in Information Systems , Maine .[ . pdf ] .( Richard Crouch , Anette Frank & Josef van Genabith ) .Proceedings 4th International Workshop on Computational Semantics , Tilburg .Revised version to appear in Bunt & Muskens ( eds )", "label": "", "metadata": {}, "score": "75.63461"}
{"text": "Some of the semantemes calculating rules 862 may be used cyclically as long as their conditions are met .Use of semantemes calculating rules 862 leads , in particular , to substitution of language - dependent characteristics , grammemes , with universal characteristics -- semantemes .", "label": "", "metadata": {}, "score": "75.64237"}
{"text": "The Algebraic notation is the standard system for describing chess games .Its essentials go back to the Arabs of the 9 th century .The example and the discussion is a slightly modified version of Szab\u00f3 ( 2000a ) : 77 - 78 .", "label": "", "metadata": {}, "score": "75.64615"}
{"text": "[ 32 ] For example , the result of -type - shifting the VP in ( 17 ) is ( 18 ) : .Note that ( 18 ) is a full proposition .The existential F - closure in ( 16b ) refers to the operation of replacing the highest F - marked node with an existentially closed variable .", "label": "", "metadata": {}, "score": "75.66501"}
{"text": "Once you 've gotten the meaning , you can forget the words .Where can I find a man who has forgotten words so I can talk with him ? \" -- The Writings of Chuang Tzu , 4th century B.C. ( Original text in Chinese ) .", "label": "", "metadata": {}, "score": "75.79674"}
{"text": "A translation database 2570 and dictionaries 2580 may be located in a storage device 2540 .[ 0265 ] FIG .26 illustrates another example of a system 2600 in accordance with one embodiment of the invention .The system 2600 may include a processing unit , such as a processor 2610 , a memory 2620 and a network interface 2670 .", "label": "", "metadata": {}, "score": "75.806915"}
{"text": "This is why tokenization on the part of the natural language processor might be seen as the first step in parsing .As an aside , we point out that Prolog , like any other programming language , has a built - in tokenizer that allows it to recognize valid data types that exist in Prolog .", "label": "", "metadata": {}, "score": "75.93489"}
{"text": "For example , the focus pattern in ( 3 ) would be infelicitous if the question was ' Did you see a grey dog or a black dog ? 'In ( 3 ) and ( 4 ) , the pitch accent is marked in bold .", "label": "", "metadata": {}, "score": "75.963554"}
{"text": "17 is a best syntactic tree for the exemplary sentence extracted from the graph of generalized constituents from FIG .13 .[ 0042 ] FIG .18 is an exemplary best syntactic structure for the exemplary sentence with non - tree links generated on the basis of a syntactic tree shown on FIG .", "label": "", "metadata": {}, "score": "76.03178"}
{"text": "Sometimes for a full and unambiguous determining a grammatical meaning , control rules have to be taken into account .For example , there is not enough information in the surface structure 2204 to generate sentences \" I met Mary with her daughters .", "label": "", "metadata": {}, "score": "76.15301"}
{"text": "Integrating Statistical and Relational Learning for Semantic Parsing : Applications to Learning Natural Language Interfaces for Databases [ Details ] [ PDF ] Lappoon R. Tang May 2000 .Ph.D. proposal , Department of Computer Sciences , University of Texas at Austin .", "label": "", "metadata": {}, "score": "76.31401"}
{"text": "By only observing how humans follow navigation instructions , the system was able to infer the corresponding hidden navigation plans and parse previously unseen instructions in new environments for both English and Chinese data .With the rise in popularity of crowdsourcing , we also present results on collecting additional training data using Amazon 's Mechanical Turk .", "label": "", "metadata": {}, "score": "76.52041"}
{"text": "( e is simple iff it is not the value of any syntactic operation . )For an alternative abstract characterization of constituency , see Hodges ( 2012 ) , 251 - 2 .Note that Frege 's conclusion appears to be the building principle .", "label": "", "metadata": {}, "score": "76.6102"}
{"text": "It is such an ambitious task that it sometimes is referred to as an AI - complete problem , implying that its difficulty is equivalent to solving the central artificial intelligence problem -- making computers as intelligent as people .Despite its complexity , natural language understanding continues to be a fundamental problem in natural language processing in terms of its theoretical and empirical importance .", "label": "", "metadata": {}, "score": "76.69992"}
{"text": "To say that a parser is a state - machine is to classify it on the way it works , not on the grammar it uses .To say a parser is a definite clause grammar parser is to classify it on the basis of the type of grammar it uses .", "label": "", "metadata": {}, "score": "76.70875"}
{"text": "If none of the lexical meanings of child constituent meets the deep restrictions of this deep slot , attachment to this deep slot is impossible .Then , the possibility of attachment to the other deep slots is checked .A deep slot which has the maximal value of the deep rating is selected .", "label": "", "metadata": {}, "score": "76.81156"}
{"text": "( Ash Asudeh & Richard Crouch ) Proceedings 21stWest Coast Conference on Formal Linguistics ( WCCFL ) , Santa Cruz .[draft.pdf ] .( John Everett , Daniel Bobrow , Reinhard Stolle , Richard Crouch , Valeria de Paiva , Cleo Condoravdi , Martin van den Berg , & Livia Polanyi ) .", "label": "", "metadata": {}, "score": "76.932556"}
{"text": "( Ash Asudeh & Richard Crouch ) Proceedings 21stWest Coast Conference on Formal Linguistics ( WCCFL ) , Santa Cruz .[draft.pdf ] .( John Everett , Daniel Bobrow , Reinhard Stolle , Richard Crouch , Valeria de Paiva , Cleo Condoravdi , Martin van den Berg , & Livia Polanyi ) .", "label": "", "metadata": {}, "score": "76.932556"}
{"text": "( Some types of ambiguity that could not be settled except by reference to the larger context would not be resolved .This deals with pragmatics ) .Of course , my machine is not that fast or large , and I do n't have that much time .", "label": "", "metadata": {}, "score": "76.96947"}
{"text": "Hogan , James P. , Mind Matters ( New York : Ballantine , 1997 ) .Lazarev , Gregory L. , Why Prolog ?( Englewood Cliffs : Prentice - Hall , 1989 ) .Marcus , Claudia , Prolog Programming ( Reading : Addison - Wesley , 1986 ) .", "label": "", "metadata": {}, "score": "77.08287"}
{"text": "Finally , we also show that ensembles of different semantic parser learning systems can obtain the best overall performance .ML ID : 215 .Learning for Semantic Parsing and Natural Language Generation Using Statistical Machine Translation Techniques [ Details ] [ PDF ] Yuk Wah Wong PhD Thesis , Department of Computer Sciences , University of Texas at Austin , Austin , TX , August 2007 .", "label": "", "metadata": {}, "score": "77.191086"}
{"text": "This paper reviews our prior work on this topic and discusses directions for future research .ML ID : 196 .Association for Computational Linguistics .We present a new approach for mapping natural language sentences to their formal meaning representations using string - kernel - based classifiers .", "label": "", "metadata": {}, "score": "77.34779"}
{"text": "For a precise formulation of the weaker compositionality principle , see Pagin and Pelletier ( 2007 ) .In section 1.3 I will introduce a weaker compositionality principle , ( C coll ) , that is a generalization of the weak principle .", "label": "", "metadata": {}, "score": "77.501755"}
{"text": "Teft , Lee , Programming in Turbo Prolog ( Englewood Cliffs : Prentice - Hall , 1989 ) .Townsend , Carl , Advanced Techniques in Turbo Prolog ( San Francisco : Sybex , 1987 )Tools . by David L. Chen , Joohyun Kim , Raymond J. Mooney - Journal of Artificial Intelligence Research , 2010 . \" ...", "label": "", "metadata": {}, "score": "77.765686"}
{"text": "The system of claim 33 , wherein said selecting is performed by a machine .The system of claim 33 , wherein said selecting is performed with assistance from a human operator .The computer storage medium of claim 36 , wherein steps a ) and b ) are performed automatically .", "label": "", "metadata": {}, "score": "77.88318"}
{"text": "FIG .11 is a lexical - morphological structure for an exemplary sentence \" This boy is smart , he 'll succeed in life . \" according to one embodiment of the NLC method .[ 0036 ] FIG .12 is a process flow diagram illustrating rough syntactic analysis according to one or more embodiments of the NLC method .", "label": "", "metadata": {}, "score": "77.95203"}
{"text": "[ 0011 ] Thus , even though some linguistic approaches have been proposed , most of them have not resulted in any useful algorithms or industrial applications because of poor performance in translating complete sentences .It is especially difficult to translate or generate complex sentences , such as those found in technical texts , documentation , internet articles , journals , and the like and is yet to be done .", "label": "", "metadata": {}, "score": "78.08376"}
{"text": "One can now see the advantage of using Prolog in this type of application .In fact one author states that context - free grammars and definite clause grammars are in effect Prolog programs .We have been trying to distinguish between the definite clause grammar part of the definite clause grammar parser and the phrase structure grammar parsing algorithm part of the definite clause grammar parser .", "label": "", "metadata": {}, "score": "78.12969"}
{"text": "Did the clerk put the bananas on the shelf ?Yes .The ice cream in the refrigerator ?The pattern of the last sentence can be matched with the earlier pattern , with ice cream mapping to bananas , and refrigerator to shelf .", "label": "", "metadata": {}, "score": "78.184875"}
{"text": "The program interface 2760 , the user interface 2720 , and the network interface 2786 , etc . , are used to provide communication between the translation module 2700 and its users via a LAN or WAN , such as the Internet .", "label": "", "metadata": {}, "score": "78.49902"}
{"text": "[ 31 ] [ 32 ] However , both Selkirk and Schwarzschild predict that in the narrow focus context , an accent will occur at most on the preposition in ( 27 ) as shown in ( 28 ) : .( 28 ) Paul took down their tent that they [ play their game [ in f t f ] foc ] .", "label": "", "metadata": {}, "score": "78.59592"}
{"text": "Personal Married to Valeria Paiva , and father of Anna and Eric .Patent application title : METHOD FOR TRANSLATING DOCUMENTS FROM ONE LANGUAGE INTO ANOTHER USING A DATABASE OF TRANSLATIONS , A TERMINOLOGY DICTIONARY , A TRANSLATION DICTIONARY , AND A MACHINE TRANSLATION SYSTEM .", "label": "", "metadata": {}, "score": "78.72566"}
{"text": "The method of claim 6 , wherein said translating comprises substituting one matching translation for the document fragment .The method of claim 8 , or claim 9 , wherein the one matching translation is the matching translation in the case of a single matching translation or a selected matching translation from a set of translation variants in the case of more that one matching translation .", "label": "", "metadata": {}, "score": "78.77031"}
{"text": "( BELIEVE SUE1 ( HAPPY JACK1 ) ) .We can also use modal operators to capture tense information .Modal tense operators include PAST , PRES , and FUT . \"John sees Fido , \" \" John saw Fido , \" and \" John will see Fido \" are thus rendered : .", "label": "", "metadata": {}, "score": "78.786804"}
{"text": "FIG .18 is one example of a syntactic structure 1402 , which is obtained near the end of the stage 1470 for the sentence \" This boy is smart , he 'll succeed in life .\" with non - tree links generated on the basis of the best syntactic tree which is shown on FIG .", "label": "", "metadata": {}, "score": "78.80397"}
{"text": "As another example , square brackets may be used to describe variable linear order relationships between different surface slots 815 of the syntform 812 in the linear order expressions .As such , [ SurfaceSlot1 SurfaceSlot2 ] indicates that any linear order of surface slots denoted by the variables SurfaceSlot1 and SurfaceSlot2 is possible .", "label": "", "metadata": {}, "score": "78.85389"}
{"text": "The invention may also be practiced in distributed computing environments .In a distributed computing environment , program modules may be located in both local and remote computer storage media including memory storage devices .In one embodiment , various program applications , program modules , etc . , such as a translation application 2530 are loaded into the memory 2520 and run by the processor 2510 .", "label": "", "metadata": {}, "score": "79.02858"}
{"text": "20 is an exemplary process flow diagram illustrating the semantic analysis 550 according to one or more embodiments of the invention .During semantic analysis 550 a semantic structure 2002 of the source sentence 512 is build .The resulting semantic structure 2002 of the source sentence 512 is built from the best syntactic structure 1402 according to various applicable analysis rules .", "label": "", "metadata": {}, "score": "79.054825"}
{"text": "By using a learned lexicon to refine inferred plans and a supervised learner to induce a semantic parser , the system is able to automatically learn to correctly interpret a reasonable fraction of the complex instructions in this corpus .ML ID : 264 .", "label": "", "metadata": {}, "score": "79.065216"}
{"text": "Let 's take a step back and note some actual parsing methods discussed in many AI books .We already mentioned that books commonly discuss three types of parsers used in natural language processors : .Noise - disposal parsers .State - machine parsers ( finite - state machine parsers ) .", "label": "", "metadata": {}, "score": "79.21491"}
{"text": "BRIEF DESCRIPTION OF THE DRAWINGS .It is to be noted , however , that the appended drawings illustrate only typical embodiments of this invention and are therefore not to be considered limiting of its scope , for the invention may admit to other equally effective embodiments .", "label": "", "metadata": {}, "score": "79.31843"}
{"text": "Most of the other parsing and generation algorithms presented in this thesis are extensions of WASP or its inverse .We demonstrate the effectiveness of our parsing and generation algorithms by performing experiments in two real - world , restricted domains .", "label": "", "metadata": {}, "score": "79.32517"}
{"text": "For example , a linear order description for the sentence , \" Boys play football .\" may be represented as \" Subject Core Object_Direct \" , where \" Subject , Object_Direct \" are names of surface slots 815 corresponding to the word order .", "label": "", "metadata": {}, "score": "79.36106"}
{"text": "Unfortunately there is some confusion in the use of terms , and we need to get straight on this before proceeding .Hence one writer states that \" human languages allow anomalies that natural languages can not allow . \" 2 There may be a need for such a language , but a natural language restricted in this way is artificial , not natural .", "label": "", "metadata": {}, "score": "79.72424"}
{"text": "ML ID : 272 .Learning Language from Ambiguous Perceptual Context [ Details ] [ PDF ] [ Slides ] David L. Chen PhD Thesis , Department of Computer Science , University of Texas at Austin , May 2012 .Building a computer system that can understand human languages has been one of the long - standing goals of artificial intelligence .", "label": "", "metadata": {}, "score": "80.071465"}
{"text": "We demonstrate its capabilities by developing a system that learns to sportscast simulated robot soccer games in both English and Korean without any language - specific prior know ... \" .We present a novel framework for learning to interpret and generate language using only perceptual context as supervision .", "label": "", "metadata": {}, "score": "80.18408"}
{"text": "Another goal is to get a computer to process natural languages , and of course in this attempt to build a natural language processor fulfilling the first goal of understanding how a processor works could be useful .Another way to distinguish these two goals is to note that in seeking to develop a computational model of natural language processing ( or understanding ) , one must distinguish between the scientific goal and the technical goal .", "label": "", "metadata": {}, "score": "80.195114"}
{"text": "Finally , we will investigate the impact of different statistical syntactic parsers on semantic parsing using the automated SAPT - generation process .ML ID : 184 .A Kernel - based Approach to Learning Semantic Parsers [ Details ] [ PDF ] [ Slides ] Rohit J. Kate 2005 .", "label": "", "metadata": {}, "score": "80.40431"}
{"text": "But it seems to me a few reasonably competent philosophers could quickly find common sense knowledge not encoded into the database .What we need , it seems to me , is a way for the computer to learn common sense knowledge the way we do , by experiencing the world .", "label": "", "metadata": {}, "score": "80.410706"}
{"text": "These results support the claim that ILP techniques as implemented in CHILL represent a viable alternative with significant potential advantages over neural - network , propositional , and probablistic approaches to empirical parser construction .ML ID : 48 .This paper presents results from recent experiments with CHILL , a corpus - based parser acquisition system .", "label": "", "metadata": {}, "score": "80.63269"}
{"text": "The selected translation variant may be offered to the user for editing 430 ( optional ) .If the user makes corrections to the translation variant , these corrections may be applied by the system ( at step 440 ) to all the occurrences of this fragment in the current document .", "label": "", "metadata": {}, "score": "80.868835"}
{"text": "0249 ] The other example of sentence which may be generated from the language - independent semantic structure formally following the English language rules is \" I 've met a boy my sister likes [ whom].\" This sentence may be transformed into more usable variant \" I 've met a boy whom my sister likes . \" by movement of \" whom \" .", "label": "", "metadata": {}, "score": "81.08501"}
{"text": "Ferge ( 1884 ) , section 60 .The translation in the standard English edition is misleading ; the translation here is mine .The second restriction is debatable .I tend to think that ' Vanda ordered a palacsinta ' is a meaningful sentence even though ' ordered ' is not a word of Hungarian and ' palacsinta ' is not a word of English , and consequently , the sentence is neither in English nor in Hungarian .", "label": "", "metadata": {}, "score": "81.10567"}
{"text": "Description : .CROSS -REFERENCE TO RELATED APPLICATIONS .[ 0001 ] This application is a continuation - in - part of co - pending U.S. patent application Ser .No . 11/548,214 , filed Oct. 10 , 2006 , and U.S. patent application Ser .", "label": "", "metadata": {}, "score": "81.171814"}
{"text": "Of course , the converse is also true ; the properties of the interpretive systems ( meaning and \" sound \" ) are not reducible to properties of the syntax .There are systematic interconnections , but no reduction .The classic illustration of this comes from thinking about the sentence \" colorless green ideas sleep furiously \" and comparing it to \" green sleep colorless furiously ideas . \"", "label": "", "metadata": {}, "score": "81.46829"}
{"text": "The method of claim 11 , wherein said selecting is performed by a machine .The method of claim 11 , wherein said selecting is performed with assistance from a human operator .The method of claim 12 , further comprising allowing a human to edit the selected translation variant .", "label": "", "metadata": {}, "score": "81.51793"}
{"text": "Natural language processing \" here refers to the use and ability of systems to process sentences in a natural language such as English , rather than in a specialized artificial computer language such as C++ .The systems of real interest here are digital computers of the type we think of as personal computers and mainframes ( and not digital computers in the sense in which \" we are all digital computers , \" if this is even true ) .", "label": "", "metadata": {}, "score": "81.60842"}
{"text": "Selkirk [ 14 ] [ 15 ] assumes the subject Judy is accented if F - marked as indicated in bold .[ 32 ] .Schwarzschild [ 16 ] points out weaknesses in Selkirk 's [ 14 ] [ 15 ] ability to predict accent placement based on facts about the discourse .", "label": "", "metadata": {}, "score": "81.64882"}
{"text": "The method of claim 3 , further comprising performing the search .The method of claim 4 , wherein the search reveals at least one matching translation .The method of claim 5 , wherein the search is an exact search where the or each matching translation corresponds exactly to the document fragment .", "label": "", "metadata": {}, "score": "81.71863"}
{"text": "Searle , for example , claims that digital computers such as PCs and mainframes , as we currently know them , can not understanding anything at all , and no future such digital computer will ever be able to understand anything by virtue of computation alone .", "label": "", "metadata": {}, "score": "81.73163"}
{"text": "FIG .27 is an example of a translation module 2700 according to one embodiment of the invention .The translation module 2700 may include a search module 2710 and a NLC module 2720 .The translation module 2700 may also interface with a program interface 2760 and a user interface 2770 to interact with other programs and a user , respectively .", "label": "", "metadata": {}, "score": "81.77744"}
{"text": "\" , or \" I met the Smith couple with their daughters .\" In these examples the gender or number of a possessive pronoun is determined by a controller ( controlling element ) therefore only control rules , which are included into referential and structural control description 856 , can determine values of these categories .", "label": "", "metadata": {}, "score": "81.78845"}
{"text": "Also appears as Technical Report AI07 - 343 , Artificial Intelligence Lab , University of Texas at Austin , August 2007 .One of the main goals of natural language processing ( NLP ) is to build automated systems that can understand and generate human languages .", "label": "", "metadata": {}, "score": "81.985435"}
{"text": "For example , the sentence \" John is a good boy and it seems that John loves Mary .\" may be generated , but \" John is a good boy and seems to love Mary .\" is more real and spoken , and the later may be generated through movement of \" John \" because of a co - ordination .", "label": "", "metadata": {}, "score": "82.24531"}
{"text": "The dogs bark \" is : .( THE x : ( ( PLUR DOG1 ) x ) ( BARKS1 x ) ) .So you can see that the logical form language really does bear a resemblance to FOPC , with certain additions needed to capture the richness of a natural language that is often ignored by FOPC .", "label": "", "metadata": {}, "score": "82.4581"}
{"text": "The difference between these syntactic trees lies in their structures , filled surface slots for some constituents , and/or the morphological paradigms for some constituents .For example , during the precise syntactic analysis 540 of the above mentioned sentence \" This boy is smart , he 'll succeed in life .", "label": "", "metadata": {}, "score": "82.479095"}
{"text": "For above mentioned example , the result of translating the English sentence \" This boy is smart , he 'll succeed in life . \" according to one embodiment of the invention into Russian is the sentence \" MaK coopa3TeeH , OH npeycneeT B 3H. [ 0257 ]", "label": "", "metadata": {}, "score": "82.68415"}
{"text": "In discussions of natural language processing by computers , it is just presupposed that machine level processing is going on as the language processing occurs , and it is not considered as a topic in natural language processing per se .It seems to me that it could turn out that how the computer actually works at the lowest level may be a relevant issue for natural language processing after all .", "label": "", "metadata": {}, "score": "82.71486"}
{"text": "The system 2600 may operate in a networked environment using logical connections to one or more remote computers .The remote computer may be a personal computer , a hand - held device , a server , a router , a network PC , a peer device or other common network node , and typically includes many or all of the elements described above relative to the system 2600 .", "label": "", "metadata": {}, "score": "82.82837"}
{"text": "Would all the chatty words that appear on many US traffic signs but not on their European equivalents count as constituents ?Is the size of the traffic sign a constituent ?( Note that the minimum size of the No - Left - Turn sign in the US is 24\u00d724 inches . )", "label": "", "metadata": {}, "score": "82.93783"}
{"text": "( Stefan Riezler , John Maxwell , Tracy King , Ronald Kaplan , Richard Crouch & Mark Johnson ) .Proceedings 40th Meeting Association for Computational Linguistics , Philadelphia .[ . pdf ] .2002 ( Richard Crouch , Ronald Kaplan , Tracy King & Stefan Riezler ) Beyond PARSEVAL workshop at 3rd Int .", "label": "", "metadata": {}, "score": "83.14202"}
{"text": "( Stefan Riezler , John Maxwell , Tracy King , Ronald Kaplan , Richard Crouch & Mark Johnson ) .Proceedings 40th Meeting Association for Computational Linguistics , Philadelphia .[ . pdf ] .2002 ( Richard Crouch , Ronald Kaplan , Tracy King & Stefan Riezler ) Beyond PARSEVAL workshop at 3rd Int .", "label": "", "metadata": {}, "score": "83.14202"}
{"text": "ML ID : 107 .The development of natural language interfaces ( NLI 's ) for databases has been a challenging problem in natural language processing ( NLP ) since the 1970 's .The need for NLI 's has become more pronounced due to the widespread access to complex databases now available through the Internet .", "label": "", "metadata": {}, "score": "83.327194"}
{"text": "In the area of program optimization , a prototype system , DOLPHIN , is able to transform some intractable specifications into polynomial - time algorithms , and outperforms competing approaches in several benchmark speedup domains .A prototype language acquisition system , CHILL , is also described .", "label": "", "metadata": {}, "score": "83.38545"}
{"text": "26 can include , for example , a local area network ( LAN ) 2690 or a wide area network ( WAN ) , such as the Internet 2680 .Such networking environments are commonplace in offices , enterprise - wide computer networks , intranets , and the Internet .", "label": "", "metadata": {}, "score": "83.60735"}
{"text": "As a result , the complement \" smart \" 1850 fills the surface slot \" Modifier_Attributive \" 1860 of the controller \" child \" 1820 by means of a link of type \" Control - Complement \" 1870 .[0203 ]", "label": "", "metadata": {}, "score": "83.766136"}
{"text": "[0274 ] The translation module 2700 may interact via the program interface 2760 with other applications .For example , the translation module 2700 may receive a source sentence from a speech recognition application 2782 after converting the source sentence into a text after speech recognition .", "label": "", "metadata": {}, "score": "83.828094"}
{"text": "Imagine different ways of breaking down the number sixteen into sixteen individual ones .Suppose we try to break this down by constructing a tree structure , with the number sixteen at the top .Under this we write two eights .", "label": "", "metadata": {}, "score": "84.06105"}
{"text": "The same point can be made by considering unacceptable sentences like \" The girl seems sleeping .\" This sentence has a perfectly clear meaning ( viz .\" the girl seems to be sleeping \" and not \" the girl seems sleepy \" ) even though the sentence is syntactically odd .", "label": "", "metadata": {}, "score": "84.52045"}
{"text": "ML ID : 223 .Transforming Meaning Representation Grammars to Improve Semantic Parsing [ Details ] [ PDF ] Rohit J. Kate In Proceedings of the Twelfth Conference on Computational Natural Language Learning ( CoNLL-2008 ) , 33 - -40 , Manchester , UK , August 2008 .", "label": "", "metadata": {}, "score": "84.58379"}
{"text": "ML ID : 222 .Learning to Sportscast : A Test of Grounded Language Acquisition [ Details ] [ PDF ] [ Slides ] [ Video ] David L. Chen and Raymond J. Mooney In Proceedings of the 25th International Conference on Machine Learning ( ICML ) , Helsinki , Finland , July 2008 .", "label": "", "metadata": {}, "score": "84.75852"}
{"text": "( You can not understand an ironical remark without recognizing the irony , but this is not required for understanding the expression uttered . )On any conception of reference , a sentence like ' He is asleep ' refers only relative to a context of utterance .", "label": "", "metadata": {}, "score": "85.045654"}
{"text": "As shown in FIG .12 , the ellipsis processor 1280 or other algorithms , devices , and computer subsystems can be adapted to perform the ellipsis restoration 1260 .In addition , the ellipsis descriptions 852 which contain proform models can be adapted to aid the ellipsis processor 1280 and process core ellipsis to build the graph 1202 of generalized constituents .", "label": "", "metadata": {}, "score": "85.212685"}
{"text": "Any other removable / non - removable , volatile / nonvolatile computer storage media can be used .[ 0268 ] A user may enter commands and information into the system 2600 through input devices 2650 , such as a keyboard 2658 , a microphone 2656 , a scanner 2654 and a pointing device , such as a mouse , trackball or touch pad .", "label": "", "metadata": {}, "score": "85.46271"}
{"text": "PT - Thinker has a limited ability to handle English sentences , so I will comment briefly on how its parser appears to operate .I doubt that PT - Thinker has much in the way of general world knowledge , but it does have the ability to sort out elementary English sentences .", "label": "", "metadata": {}, "score": "85.60422"}
{"text": "Proc .7th EACL .[ . pdf ] .( Richard Crouch )Proc .9th Amsterdam Colloquium .[ . pdf ] .( Richard Crouch and Stephen Pulman ) , Artificial Intelligence 63 .pp265 - 304 .( Reprinted in Pereira and Grosz , eds , Natural Language Processing , MIT Press , 1994 ) .", "label": "", "metadata": {}, "score": "85.69784"}
{"text": "Proc .7th EACL .[ . pdf ] .( Richard Crouch )Proc .9th Amsterdam Colloquium .[ . pdf ] .( Richard Crouch and Stephen Pulman ) , Artificial Intelligence 63 .pp265 - 304 .( Reprinted in Pereira and Grosz , eds , Natural Language Processing , MIT Press , 1994 ) .", "label": "", "metadata": {}, "score": "85.69784"}
{"text": "These ambiguities can be resolved later when additional information from the rest of the sentence and more context information become available .Some authors treat the language that captures this ambiguity encoding as quasi - logical form .As an example of this ability to capture ambiguity ( without resolving it ) , consider the word \" ball , which may be a round object or a social event .", "label": "", "metadata": {}, "score": "85.95642"}
{"text": "Perhaps the next oft - cited step in the other aspects of natural language processing was ELIZA , developed by Joseph Weizenbaum in the sixties .This program could give the appearance of doing natural language processing , but its syntactic , semantic , and pragmatic analyses were primitive or virtually non - existent , so it was really just a clever party game , which seems to have been close to Weizenbaum 's original intent anyway .", "label": "", "metadata": {}, "score": "86.27423"}
{"text": "Personal Married to Valeria Paiva , and father of Anna and Eric .Social .Family .Addresses .Side Projects .Senior member of research staff Natural Language Theory and Technology Information Sciences and Technologies Laboratory ( ISTL ) Palo Alto Research Center 3333 Coyote Hill Rd .", "label": "", "metadata": {}, "score": "86.3127"}
{"text": "[0247 ] FIG .24 is an exemplary best surface ( syntactic ) structure of the Russian sentence which is obtained as result of translating the English sentence \" This boy is smart , he 'll succeed in life . \" according to one embodiment of the invention on the basis of the semantic structure which is shown on FIG .", "label": "", "metadata": {}, "score": "86.31665"}
{"text": "The requests can be processed by a subsystem , such as a dispatcher 1290 .If attachment to the selected surface slot is performed or found impossible , the request is removed from the queue of active request of the dispatcher 1290 .", "label": "", "metadata": {}, "score": "86.5377"}
{"text": "The basic idea here is that a single word such as \" break \" might have different senses in .John broke the window with the hammer .The hammer broke the window .The window broke .These uses of \" break \" have different arity ( the first is ternary between John , the hammer , and the windows , while the others are binary and unary , respectively ) .", "label": "", "metadata": {}, "score": "86.986885"}
{"text": "For example , consider the following sentences : .I read a story about evolution in ten minutes .I read a story about evolution in the last million years .Obviously , the prepositional phrase ending the first sentence refers to the time it took to read the story , while the prepositional phrase ending the second sentence refers to the period of evolution itself .", "label": "", "metadata": {}, "score": "87.05856"}
{"text": "[ 0129 ] FIG .11 illustrates an example of the lexical - morphological structure for the sentence \" This boy is smart , he 'll succeed in life . \" according to one embodiment of the invention .The lexical - morphological structure has a complete set of pairs of \" lexical meaning - grammatical value \" for each unit of this sentence .", "label": "", "metadata": {}, "score": "87.11196"}
{"text": "ILP , which investigates the learning of relational ( first - order ) rules , provides an empirical method for acquiring knowledge within traditional , symbolic parsing frameworks .This dissertation details the architecture , implementation and evaluation of CHILL a computer system for acquiring natural language parsers by training over corpora of parsed text .", "label": "", "metadata": {}, "score": "87.247986"}
{"text": "By allowing both approaches to induce program clauses and choosing the best combination of their results , Cocktail learns more effective parsers .Experimental results on learning natural - language interfaces for two databases demonstrate that it learns more accurate parsers than Chillin , the previous best method for this task .", "label": "", "metadata": {}, "score": "87.54346"}
{"text": "To capture this , Allen can use generalized quantifiers , which have the form : .( quantifier variable : restriction - proposition body - proposition ) .\" Most dogs bark \" is interpreted as having the logical form : .", "label": "", "metadata": {}, "score": "87.69978"}
{"text": "[ iwcs.pdf ] .Notes for introductory course given with Josef van Genabith at ESSLLI-00 , Birmingham .[ . pdf ] .( Richard Crouch and Josef van Genabith ) , in Semantics and Syntax in Lexical Functional Grammar : The Resource Logic Approach .", "label": "", "metadata": {}, "score": "87.9355"}
{"text": "[ iwcs.pdf ] .Notes for introductory course given with Josef van Genabith at ESSLLI-00 , Birmingham .[ . pdf ] .( Richard Crouch and Josef van Genabith ) , in Semantics and Syntax in Lexical Functional Grammar : The Resource Logic Approach .", "label": "", "metadata": {}, "score": "87.9355"}
{"text": "For example , the lexical meaning \" cow \" in English may be associated not only with the lexeme \" cow \" , but with \" bull \" and \" calf \" , among others .The required lexeme may be selected according to the value of grammatical category \" Gender \" , and additionally , according to the presence of semanteme \" Baby \" .", "label": "", "metadata": {}, "score": "87.95314"}
{"text": "FIG .13 is an exemplary graph of generalized constituents for the sentence \" This boy is smart , he 'll succeed in life . \" according to one embodiment of the NLC method .[0038 ]FIG .14 is a process flow diagram illustrating precise syntactic analysis according to one or more embodiments of the NLC method .", "label": "", "metadata": {}, "score": "87.9904"}
{"text": "[0075 ]Suppose we have the following sentence : \" The two boys are playing tennis , \" but , only the sentence \" The two girls are playing tennis \" has been found in the translation database .In this case , \" boys \" is a \" differing part . \" which may be translated by means of a translation dictionary or a terminology dictionary .", "label": "", "metadata": {}, "score": "88.46308"}
{"text": "[ 0262 ] The system 2500 may generally include a variety of computer readable media .Computer readable media can be any available media that can be accessed by the system 2500 and includes both volatile and nonvolatile media , removable and non - removable media .", "label": "", "metadata": {}, "score": "88.579346"}
{"text": "Now what do we do ?We can take the first four and break that into two twos .This would be a depth - first strategy because we try to go deep before going wide .Or we can take the second eight and break this into two fours .", "label": "", "metadata": {}, "score": "88.8279"}
{"text": "To see the effects of focus on meaning , consider the following examples : .( 6 ) John only introduced Bill to SUE .In ( 6 ) , accent is placed on Sue .There are two readings of ( 6 ) - broad focus shown in ( 7 ) and narrow focus shown in ( 8) : .", "label": "", "metadata": {}, "score": "89.39107"}
{"text": "The conversation temporarily veers off into a discussion of the new car the driver had recently purchased .Then the listener breaks in with \" By the way , did you get her to the plane on time ?\" Obviously , \" her \" refers not to a possible salesperson that sold the driver the new car but the person being driven to the airport .", "label": "", "metadata": {}, "score": "89.43683"}
{"text": "As the order of the grammemes synthesis rules 2242 applying may be determined by presence not only some semantemes , but grammemes too , so , not only semantemes but , additionally , grammemes may be included in the condition of a rule applying .", "label": "", "metadata": {}, "score": "90.134384"}
{"text": "Common sense is needed to know that humans eat lamb but not washing machines .I 'm not going to discuss all the possible uses of a computer that could process a natural language , but I 'll mention some here .", "label": "", "metadata": {}, "score": "90.368034"}
{"text": "Later followed a variety of variants by students of these guys , including FRUMP , which was used to summarize news stories by UPI .Still , adequate consistent translation was lacking , as when FRUMP read a story about how a political assassination had shaken America and summarized the story as about an earthquake .", "label": "", "metadata": {}, "score": "90.46895"}
{"text": "In ( 4 ) , the pitch accent is also placed on dog but only the noun dog is under focus .In ( 5 ) , pitch accent is placed on grey and only the adjective grey is under focus .", "label": "", "metadata": {}, "score": "90.50488"}
{"text": "The method of claim 15 , wherein said segmenting is performed by a machine .The method of claim 16 , further comprising allowing human operator to edit the document fragments generated by said segmenting .The method of claim 15 , wherein said segmenting is performed with human assistance .", "label": "", "metadata": {}, "score": "90.62875"}
{"text": "When you type a letter on the keyboard , for example , the effect is to transmit an ASCII character code for the particular letter typed . \"A , \" for example , is 41 ( this would be transmitted in binary ) .", "label": "", "metadata": {}, "score": "91.13226"}
{"text": "When used in a WAN networking environment , the system 2600 may additionally include a modem or other means for establishing communications over the WAN , such as the Internet .It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the systems and computers may be used . [", "label": "", "metadata": {}, "score": "91.21205"}
{"text": "Experimental results show the improvements obtained over the purely supervised parser , particularly when the annotated training set is small .ML ID : 198 .This paper explores the use of statistical machine translation ( SMT ) methods for tactical natural language generation .", "label": "", "metadata": {}, "score": "91.65602"}
{"text": "To adapt an example from Ginsberg , consider : .A business plan will involve much more than a marketing plan .Although development of a marketing plan has been a major topic in this course , other important areas are involved in this broader plan .", "label": "", "metadata": {}, "score": "92.11871"}
{"text": "He found a bottle of milk in the dairy section , paid for it and left .The noun phrase most recent to the use of \" it \" is dairy section , but knowledge base information could tell us that people do n't pay for dairy sections , so we should look for another referent .", "label": "", "metadata": {}, "score": "92.127945"}
{"text": "For example , RAM may contain the operating system , various application programs , such as the translation application 2630 , other program modules , and program data .[ 0267 ] A translation database and dictionaries may be located in a storage devices 2640 .", "label": "", "metadata": {}, "score": "92.58969"}
{"text": "23 is a diagram exemplifying various components of a syntactic structure of synthesized sentence according to one or more embodiments of the NLC method .[0048 ] FIG .24 is an exemplary surface ( syntactic ) structure for a synthesized Russian sentence which correspond to English sentence \" This boy is smart , he 'll succeed in life . \" according to one embodiment of the NLC method .", "label": "", "metadata": {}, "score": "92.92749"}
{"text": "Precise constituents are nodes of the graph 1430 and one or more trees of precise constituents are generated on the basis of the graph 1430 of precise constituents .[0177 ]The graph 1430 of precise constituents is an intermediate representation between the graph 1202 of generalized constituents and syntactic trees .", "label": "", "metadata": {}, "score": "93.152054"}
{"text": "We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision , and shows better robustness to variations in task complexity and word order .ML ID : 187 .", "label": "", "metadata": {}, "score": "94.574844"}
{"text": "[draft.pdf ] .( Josef van Genabith and Richard Crouch ) , in Semantics and Syntax in Lexical Functional Grammar : The Resource Logic Approach .( edited by Mary Dalrymple ) MIT Press .[draft.pdf ] .( Josef van Genabith and Richard Crouch )", "label": "", "metadata": {}, "score": "94.8526"}
{"text": "[draft.pdf ] .( Josef van Genabith and Richard Crouch ) , in Semantics and Syntax in Lexical Functional Grammar : The Resource Logic Approach .( edited by Mary Dalrymple ) MIT Press .[draft.pdf ] .( Josef van Genabith and Richard Crouch )", "label": "", "metadata": {}, "score": "94.8526"}
{"text": "The translation application 2630 may be , for example , a machine translation program for translating a sentence from an input language into an output language .[ 0266 ] The memory 2620 may also include computer storage media in the form of volatile and/or nonvolatile memory such as read only memory ( ROM ) and random access memory ( RAM ) .", "label": "", "metadata": {}, "score": "95.70694"}
{"text": "I know what a pain in the neck it is to comment a program after it is done , and John Barker has commented some of the early parts of the program .He is under no obligation to comment it or even show it to anybody , so he really is being a good sport in letting me see the parser code .", "label": "", "metadata": {}, "score": "96.35679"}
{"text": "To reduce annotation effort while maintaining accuracy , we apply active learning to semantic lexicons .We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance .ML ID : 121 .", "label": "", "metadata": {}, "score": "96.3776"}
{"text": "In ( 13 ) we note that the verb make is not given by the sentence in ( 12 ) .It is discourse new .Therefore , it is available for accentuation .However , toast in ( 13 ) is given in ( 12 ) .", "label": "", "metadata": {}, "score": "96.46724"}
{"text": "FIG .15 is an exemplary schematic representation of a syntactic tree according to one embodiment of the NLC method .[ 0040 ] FIG .16 is an exemplary syntactic tree of the above mentioned sentence \" This boy is smart , he 'll succeed in life .", "label": "", "metadata": {}, "score": "96.469025"}
{"text": "He went to his desk and took out a gun \" we reason that David has some plan to use the gun to commit a crime and get some money , even though this is not explicitly stated .Or when we ask a ticket agent \" Do you know when the next train leaves ?", "label": "", "metadata": {}, "score": "96.67681"}
{"text": "For example , \" the fox runs through the woods \" treats \" fox \" as a noun , whereas \" the fox runs through the woods were easy for the hounds to follow \" uses it as an adjective .You do n't know how \" fox \" is used until you read the entire sentence .", "label": "", "metadata": {}, "score": "96.80707"}
{"text": "We can represent this sentence using a single logical form that captures both senses of ball : .We mentioned that a sentence such as \" Every boy loves a dog \" is ambiguous about whether there is one dog or many .", "label": "", "metadata": {}, "score": "97.39206"}
{"text": "A monitor , a display 2662 , or other type of display device is also connected to the system bus 2612 via an interface , such as a video interface .In addition to the display 2662 , the system 2600 may also include other peripheral output devices , such as speakers 2666 and printers 2664 , which may be connected through an output peripheral interface .", "label": "", "metadata": {}, "score": "97.595795"}
{"text": "Did you see a grey dog or a black dog ?I saw a [ GREY ] f dog .The question / answer paradigm shown in ( 3)-(5 ) has been utilized by a variety of theorists [ 13 ] [ 17 ] to illustrate the range of contexts a sentence containing focus can be used felicitously .", "label": "", "metadata": {}, "score": "97.84617"}
{"text": "I think the answer is negative .Consider the following minimal pair : .The meaning of the first is something like ' No left turn ! ' ; the meaning of the second is roughly ' Left turn ; recommended speed 30 mph or less . '", "label": "", "metadata": {}, "score": "98.93591"}
{"text": "( 10 ) John introduced Bill to [ SUE ] f .( 11 ) John only introduced [ BILL ] f to [ SUE ] f .Specifically , the structured meaning of ( 10 ) is : . where introd is the denotation of introduce , j John , b Bill and s Sue .", "label": "", "metadata": {}, "score": "99.70607"}
{"text": "\" Fido is a dog \" translates as \" ( DOG1 FIDO1 ) \" using the term FIDO1 and the predicate constant DOG1 .There can be unary predicates ( one argument ) , binary predicates ( two arguments ) , and n - ary predicates . \" Sue loves Jack \" is ( LOVES1 SUE1 JACK1 ) .", "label": "", "metadata": {}, "score": "101.858604"}
{"text": "The steel ships are transporting is expensive .The old man the boats .At first you stumble over the first sentence until you realize that the main noun in the subject is \" steel .\" You may have taken the sentence to be about steel ships and then , when the rest of the sentence failed to parse correctly , you backtracked and recategorized \" steel \" from an adjective to a noun .", "label": "", "metadata": {}, "score": "102.11385"}
{"text": "Jack lost his wallet in his car .He looked for it for several hours .( pronoun \" it \" referring to \" wallet \" in earlier sentence ) Jack forgot his wallet .Sam did too .( verb ellipsis referring to forgetting of wallet in previous sentence ) .", "label": "", "metadata": {}, "score": "102.17653"}
{"text": "Another way to represent a sentence analyzed in accordance with a context free grammar is in a list structure .In a list notation , Allen 's example of \" John ate the cat \" is .( S ( NP ( NAME John ) ) ( VP ( V ate ) ( NP ( ART the ) ( N cat ) ) ) ) .", "label": "", "metadata": {}, "score": "102.95221"}
{"text": "[ 0261 ]The system 2500 may be a general purpose computing device in the form of a computer .Components of the system 2500 may include , but are not limited to , a processing unit , such as a processor 2510 , a system memory 2520 , and a system bus 2512 that couples various system components including the system memory 2520 to the processing unit 2510 .", "label": "", "metadata": {}, "score": "103.0888"}
{"text": "For example , consider : .Jack took out a match .He lit a candle .Because we assume the discourse is coherent , the \" he \" must refer to Jack , \" lit \" must mean \" lighting \" rather than \" illuminating \" the candle , and the instrument used to light the candle must be the match .", "label": "", "metadata": {}, "score": "103.3292"}
{"text": "RAM typically contains data and/or program modules that are immediately accessible to and/or presently being operated on by the processor 2610 .These data and/or program modules are located in the memory 2620 or is loaded into memory when a program is called upon .", "label": "", "metadata": {}, "score": "103.36718"}
{"text": "25 illustrates an example of a suitable computing system environment on which the invention may be implemented .A system 2500 is provided and is only one example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention .", "label": "", "metadata": {}, "score": "103.94101"}
{"text": "S NP VP NAME VP John VP John V NP John are NP John are ART N John ate the N John ate the cat .In a bottom - up strategy , one starts with the words of the sentence and used the rewrite rules backward to reduce the sentence symbols until one is left with S. .", "label": "", "metadata": {}, "score": "109.59456"}
{"text": "In ( 9 ) , the set of alternatives is said to contrast with the ordinary semantic meaning of because the speaker indicates that the ordinary semantic meaning is true while every alternative is false .For example in ( 9 ) , Mary likes Sue is true while Mary likes Bill and Mary likes Lisa are both false .", "label": "", "metadata": {}, "score": "113.42799"}
{"text": "( 3 )Did you see a grey dog or a cat ?I saw [ a grey DOG ] f .( 4 )Did you see a grey dog or a grey cat ?I saw a grey [ DOG ] f .", "label": "", "metadata": {}, "score": "113.620514"}
{"text": "( LOVES1 ) .This takes the place of two separate possibilities : .( EVERY b1 : ( BOY1 b1 ) ( A d1 : ( DOG1 d1 ) ( LOVES1 b1 d1 ) ) )( A d1 : ( DOG1 d1 ) ( EVERY b1 : ( BOY1 b1 ) ( LOVES b1 d1 ) ) ) .", "label": "", "metadata": {}, "score": "114.865524"}
{"text": "( Undergraduate course at Nottingham University ) [ notes.pdf][slides.pdf ] .( MPhil course at Cambridge University ) [ slides.pdf ] .[ slides.pdf ] See also the homepage of a more extended course given at Stanford .( Course at ESSLLI-00 ) [ notes.pdf][slides.ps ] .", "label": "", "metadata": {}, "score": "115.11286"}
{"text": "( Undergraduate course at Nottingham University ) [ notes.pdf][slides.pdf ] .( MPhil course at Cambridge University ) [ slides.pdf ] .[ slides.pdf ] See also the homepage of a more extended course given at Stanford .( Course at ESSLLI-00 ) [ notes.pdf][slides.ps ] .", "label": "", "metadata": {}, "score": "115.11286"}
{"text": "( 8) John only introduced Bill to [ SUE ] f .The meaning of ( 7 ) can be summarized as the only thing John did was introduce Bill to Sue .The meaning of ( 8) can be summarized as the only person to whom John introduced Bill is Sue .", "label": "", "metadata": {}, "score": "117.66947"}
{"text": "\" The fish trap exists because of the fish .Once you 've gotten the fish you can forget the trap .The rabbit snare exists because of the rabbit .Once you 've gotten the rabbit , you can forget the snare .", "label": "", "metadata": {}, "score": "118.00749"}
{"text": "Proc . 1stLFG Conference .( Extended and much improved version in Crouch and van Genabith 1999 , above . )[ . pdf ] .( Josef van Genabith and Richard Crouch )Proc . 1stLFG Conference .[ . pdf ] .", "label": "", "metadata": {}, "score": "120.509125"}
{"text": "Proc . 1stLFG Conference .( Extended and much improved version in Crouch and van Genabith 1999 , above . )[ . pdf ] .( Josef van Genabith and Richard Crouch )Proc . 1stLFG Conference .[ . pdf ] .", "label": "", "metadata": {}, "score": "120.509125"}
{"text": "draft.pdf ] .( Josef van Genabith and Richard Crouch )Proc .35th ACL / 8th European ACL .[ . pdf ] .( Josef van Genabith and Richard Crouch )Proc .COLING-96 . [ . pdf ] .", "label": "", "metadata": {}, "score": "122.15936"}
{"text": "draft.pdf ] .( Josef van Genabith and Richard Crouch )Proc .35th ACL / 8th European ACL .[ . pdf ] .( Josef van Genabith and Richard Crouch )Proc .COLING-96 . [ . pdf ] .", "label": "", "metadata": {}, "score": "122.15936"}
{"text": "Time flies like an arrow Fruit flies like a banana .There may still be ambiguities lurking in these sentences , but we use general knowledge about time and fruit flies to probably interpret \" flies \" differently in these sentences .", "label": "", "metadata": {}, "score": "127.34439"}
