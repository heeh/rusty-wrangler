{"text": "More generally , we consider problems involving multiple dependent output variables , structured output spaces , and classification problems with class attributes .In order to accomplish this , we propose to appropriately generalize the well - known notion of a separation margin and derive a corresponding maximum - margin formulation .", "label": "", "metadata": {}, "score": "32.033455"}
{"text": "To address this challenge , many QA systems have incorporated semantic resources for answer ranking in a single language .However , there has been little research on a generalized probabilistic framework that models the correctness and correlation of answer candidates for multiple languages .", "label": "", "metadata": {}, "score": "33.23426"}
{"text": "However , considering all available evidence on ECS together provides a stronger constraint than individual lines of evidence .Bayesian methods can be used to incorporate multiple lines of evidence to sharpen the posterior distribution of ECS , as in Annan and Hargreaves ( 2006 ) and Hegerl et al .", "label": "", "metadata": {}, "score": "33.241646"}
{"text": "This framework also provides a Bayesian solution to the problems of image denoising and filling in of missing pixels .We demonstrate that the results obtained by applying the learned bases to these problems are improved over those obtained with traditional techniques .", "label": "", "metadata": {}, "score": "34.21803"}
{"text": "This paper presents a language - independent probabilistic answer ranking framework for question answering .The framework estimates the probability of an individual answer candidate given the degree of answer relevance and the amount of supporting evidence provided in the set of answer candidates for the question .", "label": "", "metadata": {}, "score": "34.541817"}
{"text": "This paper presents a language - independent probabilistic answer ranking framework for question answering .The framework estimates the probability of an individual answer candidate given the degree of answer relevance and the amount of supporting evidence provided in the set of answer candidates for the question .", "label": "", "metadata": {}, "score": "34.541817"}
{"text": "We also describe other improvements to standard ICA , such as temporal pre - whitening and variance normafisation of timeseries , the latter being particularly useful in the context of dimensionality reduction when weak activation is present .We discuss the use of prior information about the spatiotemporal nature of the source processes , and an alternative - hypothesis testing approach for inference , using Gaussian mixture models .", "label": "", "metadata": {}, "score": "35.81089"}
{"text": "In [ 1 ] , we proposed a methodology in which we do not make any a priori dependency assumptions .Rather , we give data a complete ( but controlled ) freedom to dictate the appropriate dependencies .In other words , we learn the dependencies between ( hidden and observable ) variables from data .", "label": "", "metadata": {}, "score": "36.2884"}
{"text": "In [ 1 ] , we proposed a methodology in which we do not make any a priori dependency assumptions .Rather , we give data a complete ( but controlled ) freedom to dictate the appropriate dependencies .In other words , we learn the dependencies between ( hidden and observable ) variables from data .", "label": "", "metadata": {}, "score": "36.2884"}
{"text": "In additional experiments we train overcomplete energy - based models to extract features from various standard data - sets containing speech , natural images , hand - written digits and faces . \" ...This paper presents a language - independent probabilistic answer ranking framework for question answering .", "label": "", "metadata": {}, "score": "36.561165"}
{"text": "Collins ( 2000 ) uses a technique based on boosting algorithms for machine learning that reranks n - best output from model 2 in t .. \" ...The problem of combining preferences arises in several applications , such as combining the results of different search engines .", "label": "", "metadata": {}, "score": "36.750923"}
{"text": "We use these models to study Gaussian process regression for processes with multiple outputs and latent processes ( i.e. , processes that are not directly observed and predicted but interrelate the output quantities ) .Our results demonstrate the effectiveness of the approach on both synthetic and realistic data sets .", "label": "", "metadata": {}, "score": "36.888687"}
{"text": "This paper presents a novel practical framework for Bayesian model averaging and model selection in probabilistic graphical models .Our approach approximates full posterior distributions over model parameters and structures , as well as latent variables , in an analytical manner .", "label": "", "metadata": {}, "score": "37.071503"}
{"text": "This paper presents a novel practical framework for Bayesian model averaging and model selection in probabilistic graphical models .Our approach approximates full posterior distributions over model parameters and structures , as well as latent variables , in an analytical manner .", "label": "", "metadata": {}, "score": "37.071503"}
{"text": "This factorization provides conceptual simplicity , straightforward opportunities for separately improving the component models , and a level of performance comparable to similar , non - factored models .This pruning is done for efficiency ; the question is whether it is hurting accuracy .", "label": "", "metadata": {}, "score": "37.243332"}
{"text": "This paper proposes a method to improve shift - reduce constituency parsing by using lexical dependencies .The lexical dependency information is obtained from a large amount of auto - parsed data that is generated by a baseline shift - reduce parser on unlabeled data .", "label": "", "metadata": {}, "score": "37.84292"}
{"text": "This paper proposes a method to improve shift - reduce constituency parsing by using lexical dependencies .The lexical dependency information is obtained from a large amount of auto - parsed data that is generated by a baseline shift - reduce parser on unlabeled data .", "label": "", "metadata": {}, "score": "37.84292"}
{"text": "We present a novel generative model for natural language tree structures in which semantic ( lexical dependency ) and syntactic ( PCFG ) structures are scored with separate models .This factorization provides conceptual simplicity , straightforward opportunities for separately improving the component mod ... \" .", "label": "", "metadata": {}, "score": "38.16583"}
{"text": "This view leads to a single algorithmic framework for the three problems .We prove worst case loss bounds for various algorithms for both the realizable case and the non - realizable case .The end result is new algorithms and accompanying loss bounds for hinge - loss regression and uniclass .", "label": "", "metadata": {}, "score": "38.20499"}
{"text": "Our approach approximates full posterior distributions over model parameters and structures , as well as latent variables , in an analytical manner .These posteriors ... \" .This paper presents a novel practical framework for Bayesian model averaging and model selection in probabilistic graphical models .", "label": "", "metadata": {}, "score": "39.36132"}
{"text": "( b ) Let the parameter posterior q ( ) fall out of free - form optimization , as before . \" ...Current methods for learning graphical models with latent variables and a fixed structure estimate optimal values for the model parameters .", "label": "", "metadata": {}, "score": "40.086586"}
{"text": "Second , the EDF that we used in model selection is an estimate based on the training data .For degenerate sites , the estimate should be accurate with even small training samples ; whereas for conserved sites a larger training sample might reveal additional bases and change the EDF .", "label": "", "metadata": {}, "score": "40.12793"}
{"text": "Estimation of the number of intrinsic sources not only enables us to carry out probabilistic modelling , but also achieves an asymptotically unique decomposition of the data .This reduces problems of interpretation , as each final independent component is now much more likely to be due to only one physical or physiological process .", "label": "", "metadata": {}, "score": "40.25274"}
{"text": "This assumption results in marginal dependencies among the features , but conditional independence of the features given the inputs .By assigning energies to the features a probability distribution over the input states is defined through the Boltzmann distribution .Free parameters of this model are trained using the contrastive divergence objective ( Hinton , 2002 ) .", "label": "", "metadata": {}, "score": "40.588097"}
{"text": "This assumption results in marginal dependencies among the features , but conditional independence of the features given the inputs .By assigning energies to the features a probability distribution over the input states is defined through the Boltzmann distribution .Free parameters of this model are trained using the contrastive divergence objective ( Hinton , 2002 ) .", "label": "", "metadata": {}, "score": "40.588097"}
{"text": "The theory of the method is discussed in a companion paper .Simulations with artificial and natural data demonstrate the feasibility and good performance of the ... \" .In this paper , we present experimental results on a nonlinear independent component analysis approach based on Bayesian ensemble learning .", "label": "", "metadata": {}, "score": "40.76812"}
{"text": "The theory of the method is discussed in a companion paper .Simulations with artificial and natural data demonstrate the feasibility and good performance of the ... \" .In this paper , we present experimental results on a nonlinear independent component analysis approach based on Bayesian ensemble learning .", "label": "", "metadata": {}, "score": "40.76812"}
{"text": "The proposed methodology can be extended in various ways .In the present implementation , we chose to discard an explicit source model from the estimation stages and use the Gaussian mixture model on ... . \" ...A Bayesian ensemble learning method is introduced for unsupervised extraction of dynamic processes from noisy data .", "label": "", "metadata": {}, "score": "40.82938"}
{"text": "Overall , several lines of evidence strengthen confidence in present estimates of ECS , and new results based on objective analyses make it possible to assign probabilities to ranges of climate sensitivity previously assessed from expert opinion alone .This represents a significant advance .", "label": "", "metadata": {}, "score": "40.911545"}
{"text": "Moreover , learning the structure of models with latent variables , for which the Bayesian approach is crucial , is yet a harder problem .In this paper I present the Variational Bayes framework , which provides a solution to these problems .", "label": "", "metadata": {}, "score": "41.39846"}
{"text": "This view leads to a single algorithmic framework for the three problems .We prove worst case loss bounds for various algorithms for both the realizable case and the non - realizable case .The end result is new alg ... \" .", "label": "", "metadata": {}, "score": "41.569862"}
{"text": "use a more global discriminative model to rerank those candidates .However , these methods fail when the correct output is pruned away in the first pass .Closest to our proposal are gradient - descent methods that adjust the parameters of all of the local classifiers ... . ... ns , or quotation marks ) and have the same label 15 as a constituent in the treebank parse .", "label": "", "metadata": {}, "score": "41.824577"}
{"text": "The resulting algorithm generalizes the standard Expectation Maximization a .. matrices , as well as the source distributions , from noisy data .However , in realistic cases the observed data is generated by an unknown number of sources m. Here we exploit the VB approach ... . \" ...", "label": "", "metadata": {}, "score": "42.081314"}
{"text": "Whereas this approach usually produces overfitting and suboptimal generalization performance , carrying out the Bayesian program of computing the full posterior ... \" .Current methods for learning graphical models with latent variables and a fixed structure estimate optimal values for the model parameters .", "label": "", "metadata": {}, "score": "42.598846"}
{"text": "Furthermore , our approach is technically very attractive because all the computational eort is made in the training phase . ... epends only on the current hidden variable .There is , however , a fundamental question regarding these dependency assumptions : are they realistic hypothesis for any kind of speech recognition task ?", "label": "", "metadata": {}, "score": "42.68824"}
{"text": "Furthermore , our approach is technically very attractive because all the computational eort is made in the training phase . ... epends only on the current hidden variable .There is , however , a fundamental question regarding these dependency assumptions : are they realistic hypothesis for any kind of speech recognition task ?", "label": "", "metadata": {}, "score": "42.68824"}
{"text": "The system has been used to parse many well known corpora in order to produce data for lexical acquisition efforts ; it has also been used as a component in an open - domain question answering project .The performance of the system is competitive with that of statistical parsers using highly lexicalised parse selection models .", "label": "", "metadata": {}, "score": "42.818142"}
{"text": "We apply a Bayesian method for inferring an optimal basis to the problem of finding efficient image codes for natural scenes .The basis functions learned by the algorithm are oriented and localized in both space and frequency , bearing a resemblance to two - dimensional Gabor functions , and increasing ... \" .", "label": "", "metadata": {}, "score": "42.86971"}
{"text": "We discuss the use of prior information about the spatiotemporal nature of the source processes , and an alternative - hypothesis testing approach for inference , using Gaussian mixture models .The performance of our approach is illustrated and evaluated on real and complex artificial FMRI data , and compared to the spatio - temporal accuracy of restfits obtaine ... .", "label": "", "metadata": {}, "score": "42.87252"}
{"text": "3 ) Manual Filtering Other than the features mentioned above , we manually created many rules for numeric and temporal questions to filter out invalid answers .For example , when the question is looki ... . \" ...Data - driven function tag assignment has been studied for English using Penn Treebank data .", "label": "", "metadata": {}, "score": "43.07621"}
{"text": "First , the chi - square test that partitions motif positions into those with dependencies and those without dependencies will , like any statistical test , make mistakes , and its statistical power to detect dependencies will suffer with small training samples .", "label": "", "metadata": {}, "score": "43.303833"}
{"text": "In this paper I present the Variational Bayes framework , which provides a solution to these problems .This approach approximates full posterior distributions over model parameters and structures , as well as latent variables , in an analytical manner without resorting to sampling methods .", "label": "", "metadata": {}, "score": "43.404984"}
{"text": "Reduction of the data to this ' true ' subspace before the ICA decomposition automatically results in an estimate of the noise , leading to the ability to assign significance to voxels in ICA spatial maps .Estimation of the number of intrinsic sources not only enables us to carry out probabilistic modelling , but also achieves an asymptotically unique decomposition of the data .", "label": "", "metadata": {}, "score": "43.67158"}
{"text": "The basis functions learned by the algorithm are oriented and localized in both space and frequency , bearing a resemblance to two - dimensional Gabor functions , and increasing ... \" .We apply a Bayesian method for inferring an optimal basis to the problem of finding efficient image codes for natural scenes .", "label": "", "metadata": {}, "score": "43.99373"}
{"text": "i . ... aches have been proposed for extending the range of dependencies modelled by both generative and discriminative statistical models .For discriminative models , latent - variable extensions such as ... . \" ...Currently , most approaches to speech recognition are frame - based in that they represent speech as a temporal sequence of feature vectors .", "label": "", "metadata": {}, "score": "44.30777"}
{"text": "Taking the dependency layer as the parsing unit , the proposed parser has a lower computational complexity than graph - based models which search for a whole dependency graph and alleviates the error propagation that transition - based models suffer from to some extent .", "label": "", "metadata": {}, "score": "44.416496"}
{"text": "Moreover , this paper shows that many advanced models for speech recognition and language processing can also be simply described by a graph , including many at the acoustic- , pronunciation- , and language - modeling levels .A number of speech recognition techniques born directly out of the graphical - models paradigm are also surveyed .", "label": "", "metadata": {}, "score": "44.450287"}
{"text": "Moreover , this paper shows that many advanced models for speech recognition and language processing can also be simply described by a graph , including many at the acoustic- , pronunciation- , and language - modeling levels .A number of speech recognition techniques born directly out of the graphical - models paradigm are also surveyed .", "label": "", "metadata": {}, "score": "44.450287"}
{"text": "Precisely , our strategy is to conceive ASR systems for which robustness relies on : the fidelity and the flexibility in speech modelling rather . ... aximal dependency structure and hence to make a tradeoff between modelling accuracy and model complexity .", "label": "", "metadata": {}, "score": "44.55688"}
{"text": "Precisely , our strategy is to conceive ASR systems for which robustness relies on : the fidelity and the flexibility in speech modelling rather . ... aximal dependency structure and hence to make a tradeoff between modelling accuracy and model complexity .", "label": "", "metadata": {}, "score": "44.55688"}
{"text": "After motivating the need for explicit predicate argument structure labels , we briefly discuss the theoretical considerations of predicate argument structure and the need to maintain consistency across syntactic alternations .The issues of consistency of argument structure across both polysemous and synonymous verbs are also discussed and we present our actual guidelines for these types of phenomena , along with numerous examples of tagged sentences and verb frames .", "label": "", "metadata": {}, "score": "44.654514"}
{"text": "In the present implementation , we chose to discard an explicit source model from the estimation stages and use the Gaussian mixture model on ... . \" ...A Bayesian ensemble learning method is introduced for unsupervised extraction of dynamic processes from noisy data .", "label": "", "metadata": {}, "score": "44.731148"}
{"text": "The authors find a similar constraint using five lines of evidence under more conservative assumptions about uncertainties ( adding cooling during the Little Ice Age and studies based on varying model parameters to match climatological means , see Box 10.2 ) .", "label": "", "metadata": {}, "score": "44.93283"}
{"text": "The dataset consists of a training set ( containing of data ) and a testing set ( the remainder ) , which were previously used to assess the performance of NNSplice [ 33 ] .We used the same partitions for training and testing in the following comparisons .", "label": "", "metadata": {}, "score": "45.251507"}
{"text": "We first give a formal framework for the problem .We then describe and analyze a new boosting ... \" .The problem of combining preferences arises in several applications , such as combining the results of different search engines .This work describes an efficient algorithm for combining multiple preferences .", "label": "", "metadata": {}, "score": "45.322224"}
{"text": "The probabilistic framework provides a method for comparing the coding efficiency of different bases objectively by calculating their probability given the observed data or by measuring the entropy of the basis function coefficients .The learned bases are shown to have better coding efficiency than traditional Fourier and wavelet bases .", "label": "", "metadata": {}, "score": "45.373386"}
{"text": "There is , however , a fundamental question regarding these dependency assumptions : are they realistic hypothesis for any kind of speech recognition task ?Rather , we give data a complete ( but controlled ) freedom to dictate the appropriate dependencies .", "label": "", "metadata": {}, "score": "45.409233"}
{"text": "There is , however , a fundamental question regarding these dependency assumptions : are they realistic hypothesis for any kind of speech recognition task ?Rather , we give data a complete ( but controlled ) freedom to dictate the appropriate dependencies .", "label": "", "metadata": {}, "score": "45.409233"}
{"text": "Additionally , we used smaller training sets to access the performance of these methods on the same testing set .Smaller training sets , in sizes ranging from 15 to 150 , were independently sampled ( without replacement ) from the original 150 sites for training .", "label": "", "metadata": {}, "score": "45.522648"}
{"text": "Model selection .Many different mixtures of Markov models can be formed from the combination of different Markov chains .It is essential to choose the model that minimizes prediction error .In model selection , we first fit each model using maximum likelihood smoothed by a Dirichlet prior [ see Additional file 1 ] , then compute either the Akaike information criterion ( AIC ) [ 27 ] or the Bayesian information criterion ( BIC ) [ 28 ] .", "label": "", "metadata": {}, "score": "45.559074"}
{"text": "We show how the algorithms can be efficiently applied to exponential sized representations of parse trees , such as the \" all subtrees \" ( DOP ) representation described by ( Bod 98 ) , or a representation tracking all sub - fragments of a tagged sentence .", "label": "", "metadata": {}, "score": "45.605545"}
{"text": "The basis functions learned by the algorithm are oriented and localized in both space and frequency , bearing a resemblance to two - dimensional Gabor functions , and increasing the number of basis functions results in a greater sampling density in position , orientation , and scale .", "label": "", "metadata": {}, "score": "45.682922"}
{"text": "We approach this by introducing a temporal constraint into the well known technique of Principal Component Analysis .On this subspace , we attempt a parametric modelling of the trajectory , and compute a distance metric to perform classification of diphones .", "label": "", "metadata": {}, "score": "45.907444"}
{"text": "These assumptions include ( i ) the choice of prior distribution for each of the model parameters ( Section 9.6.1 and Supplementary Material , Appendix 9 .Neglecting important sources of uncertainty in these estimates will result in overly narrow ranges that overstate the certainty with which the ECS or TCR is known .", "label": "", "metadata": {}, "score": "45.932472"}
{"text": "The observation process can be represented as a factor analysis model or a linear discriminant analysis model .General HMMs and schemes proposed to improve their performance such as STC can be regarded as special cases in this framework . \" ...", "label": "", "metadata": {}, "score": "46.09844"}
{"text": "Currently , most approaches to speech recognition are frame - based in that they represent speech as a temporal sequence of feature vectors .Although these approaches have been successful , they can not easily incorporate complex modeling strategies that may further improve speech recognition performance .", "label": "", "metadata": {}, "score": "46.32823"}
{"text": "Without sufficient training data , it is difficult to accurately estimate all model parameters , even using more robust methods ( e.g . interpolated Markov chains [ 43 , 44 ] ) .As a result , lack of sufficient training data often makes it impractical to train a higher order Markov model .", "label": "", "metadata": {}, "score": "46.655197"}
{"text": "This report describes an attempt at capturing segmental transition information for speech recognition tasks .The slowly varying dynamics of spectral trajectories carries much discriminant information that is very crudely modelled by traditional approaches such as HMMs .In approaches such as recurrent neural networks there is the hope , but not the convincing demonstration , that such transitional information could be captured .", "label": "", "metadata": {}, "score": "46.73663"}
{"text": "In contrast to the causal generative extensions of ICA which maintain marginal independence of sources , we define features as deterministic ( linear ) functions of the inputs .This assumption resul ... \" .We present a new way of extending independent components analysis ( ICA ) to overcomplete representations .", "label": "", "metadata": {}, "score": "46.897453"}
{"text": "In contrast to the causal generative extensions of ICA which maintain marginal independence of sources , we define features as deterministic ( linear ) functions of the inputs .This assumption resul ... \" .We present a new way of extending independent components analysis ( ICA ) to overcomplete representations .", "label": "", "metadata": {}, "score": "46.897453"}
{"text": "We fitted a set of 0-k mixture models , in which the k th order chains are either linear or circular and k ranges from 0 to 3 , with the training data .We subsequently applied the fitted models to predict splice sites in testing data .", "label": "", "metadata": {}, "score": "47.0269"}
{"text": "Unlike in large sample approximations , the posteriors are generally nonGaussian and no Hessian needs to be computed .Predictive quantities are obtained analytically .The resulting algorithm generalizes the standard Expectation Maximization algorithm , and its convergence is guaranteed .We demonstrate that this approach can be applied to a large class of models in several domains , including mixture models and source separation .", "label": "", "metadata": {}, "score": "47.02901"}
{"text": "One example is in atmospheric dynamics where pressure and wind speed are driven by geostrophic assumptions ( wind /x pressure ) .In this study we develop both analytical and numerical auto - covariance and cross - covariance models that are consistent with physical constraints or can incorporate automatically sensible assumptions about the process that generated the data .", "label": "", "metadata": {}, "score": "48.006966"}
{"text": "The dynamics of the factors are modeled using a nonlinear statespace model .The nonlinear map ... \" .A Bayesian ensemble learning method is introduced for unsupervised extraction of dynamic processes from noisy data .The data are assumed to be generated by an unknown nonlinear mapping from unknown factors .", "label": "", "metadata": {}, "score": "48.091213"}
{"text": "The dynamics of the factors are modeled using a nonlinear statespace model .The nonlinear map ... \" .A Bayesian ensemble learning method is introduced for unsupervised extraction of dynamic processes from noisy data .The data are assumed to be generated by an unknown nonlinear mapping from unknown factors .", "label": "", "metadata": {}, "score": "48.091213"}
{"text": "This approach guaranties to improve model ... \" .We present a new continuous automatic speech recognition system where no a priori assumptions on the dependencies between the observed and the hidden speech processes are made .Rather , dependencies are learned form data using the Bayesian networks formalism .", "label": "", "metadata": {}, "score": "48.096138"}
{"text": "This approach guaranties to improve model ... \" .We present a new continuous automatic speech recognition system where no a priori assumptions on the dependencies between the observed and the hidden speech processes are made .Rather , dependencies are learned form data using the Bayesian networks formalism .", "label": "", "metadata": {}, "score": "48.096138"}
{"text": "This paper first provides a brief overview of graphical models and their uses as statistical models .Moreover , this paper shows that many advanced models for speech recognition and language processing can also be simply described by a graph , including many at the acoustic- , pronunciation- , and language - modeling levels .", "label": "", "metadata": {}, "score": "48.107925"}
{"text": "The optimized position order of its 3 rd order chain was : .We can see that this model is consistent with the above evidence ( a ) and ( b ) .In addition , it is well supported by experimentally verified position dependencies of position 4 on the positions -1 , -2 , 3 and 5 [ 37 ] , and the computationally confirmed dependency of position -3 on position -2 due to the adjacent base - pair effect [ 2 ] .", "label": "", "metadata": {}, "score": "48.12225"}
{"text": "Structural uncertainties in the models , for example , in the representation of cloud feedback processes ( Chapter 8 ) or the physics of ocean mixing , will affect results for climate sensitivity and are very difficult to quantify .The use of a single value for the ECS further assumes that it is constant in time .", "label": "", "metadata": {}, "score": "48.299744"}
{"text": "Both have theoretical support [ 27 , 28 ] .In our application , neither criterion worked well when using the DF ( results not shown ) ; but both , particularly AIC , performed well when using EDF .We found that models selected by AIC using EDF were consistent with models selected by cross - validation and by ROC analysis .", "label": "", "metadata": {}, "score": "48.41998"}
{"text": "An overall analysis and a detailed module - by - module analysis are presented . ...S - MSRSeg [ 23].We also performed NE tagging using BBN 's Identifinder [ 6 ] , and merged with NE tags produced by S - MSRSeg .", "label": "", "metadata": {}, "score": "48.48806"}
{"text": "There is no clear better choice between AIC and BIC for model selection .In our test on 61 different TFBS datasets , whose sample sizes range from 20 to 130 , we preferred AIC to BIC for picking an appropriate model .", "label": "", "metadata": {}, "score": "48.647644"}
{"text": "Current methods for learning graphical models with latent variables and a fixed structure estimate optimal values for the model parameters .Whereas this approach usually produces overfitting and suboptimal generalization performance , carrying out the Bayesian program of computing the full posterior distributions over the parameters remains a difficult problem .", "label": "", "metadata": {}, "score": "48.660744"}
{"text": "While recent progress in machine learning has mainly focused on designing flexible and powerful input representations , this paper addresses the complementary ... \" .Learning general functional dependencies between arbitrary input and output spaces is one of the key challenges in computational intelligence .", "label": "", "metadata": {}, "score": "48.745586"}
{"text": "Empirical results from testing on NT - CIR factoid questions show a 40 % performance improvement in Chinese answer selection and a 45 % improvement in Japanese answer selection . ... nce between an answer candidate and question keywords , segmentation was done with linguistic tools .", "label": "", "metadata": {}, "score": "48.947678"}
{"text": "Several other time - series models have been proposed recently especially in the segment model framework to address the inter - frame correlation problem such as Gauss - Markov and dynamical system segment models .The lack of intra - frame correlation has been compensated for with transform schemes such as semi - tied full covariance matrices ( STC ) .", "label": "", "metadata": {}, "score": "49.02272"}
{"text": "Recent work has focused on the use of dynamic Bayesian networks ( DBNs ) framework to construct new acoustic models to overcome the limitations of HMM based systems .In this line of research we proposed a methodology to learn the conditional independence assertions of acoustic models based on structural learning of DBNs .", "label": "", "metadata": {}, "score": "49.180687"}
{"text": "Recent work has focused on the use of dynamic Bayesian networks ( DBNs ) framework to construct new acoustic models to overcome the limitations of HMM based systems .In this line of research we proposed a methodology to learn the conditional independence assertions of acoustic models based on structural learning of DBNs .", "label": "", "metadata": {}, "score": "49.180687"}
{"text": "The optimization for the 2 nd order linear chains was slightly worse than that for the 1 st order linear chains , partially because the DNJ method relies only on the pairwise dependencies between two single positions .Nevertheless , most of the DNJ optimized models were still close to the best [ see Additional file 1 Figure 1a ] .", "label": "", "metadata": {}, "score": "49.23041"}
{"text": "On the other hand , using less than all available information will yield results that are less constrained than they could be under optimal use of available data .While a variety of important uncertainties ( e.g. , radiative forcing , mixing of heat into the ocean ) have been taken into account in most studies ( Table 9.3 ) , some caveats remain .", "label": "", "metadata": {}, "score": "49.31289"}
{"text": "Experimental results indicate that the proposed approach offers desirable accuracies and especially a fast parsing speed . ... mplementations in projective case .The Classifier Splitting heuristic strategy and SVM speeding up methods ( Goldberg and Elhadad , 2008 ) are gold choi ... . \" ...", "label": "", "metadata": {}, "score": "49.3292"}
{"text": "Based on pairwise dependencies , motif positions are grouped into independent sets , each forming a Markov chain .The outline of our procedure for grouping motif positions is described in the following steps .Calculate base frequencies for each position , and find highly conserved positions where the observed frequency of a certain base ( almost ) equals 1 .", "label": "", "metadata": {}, "score": "49.592194"}
{"text": "We present an integrated approach to Probabilistic ICA for FMRI data that allows for non - square mixing in the presence of Gaussian noise .We employ an objective estimation of the amount of Gaussian noise through Bayesian analysis of the true dimensionality of the data , i.e. the number of activation and non - Gaussian noise sources .", "label": "", "metadata": {}, "score": "49.67297"}
{"text": "On the other hand , a higher order Markov model is necessary for detecting subtle dependency signals that can be essential for distinguishing true motifs from false ones .Motif dissection .To apply the mixture of Markov models to a motif , the first step is to dissect the motif into several independent sub - motifs , each of which is modeled as a Markov chain .", "label": "", "metadata": {}, "score": "49.699497"}
{"text": "These are primarily reasons that OMiMa showed superior performance , in terms of prediction accuracy , required size of training data or computational time , over other leading - methods in our results .With any model selection procedure , the possibility of choosing a model that drastically over- or underfits is a concern .", "label": "", "metadata": {}, "score": "50.003548"}
{"text": "Linear Gaussian models ( LGM ) are popular as many forms may be trained efficiently using the expectation maximisation algorithm .In this paper , several LGMs and generalised LGMs are reviewed .The models can be roughly categorised into four combinations according to two different state evolution and two different observation processes .", "label": "", "metadata": {}, "score": "50.073612"}
{"text": "The application of such ' model - free ' methods , however , has been somewhat restricted both by the view that results can be uninterpretable and by the lack of ... \" .Independent Component Analysis is becoming a popular exploratory method for analysing complex data such as that from FMRI experiments .", "label": "", "metadata": {}, "score": "50.094727"}
{"text": "Joining the first position to the last position in the vector forms a circular chain .A linear chain could be further optimized by forming a circular chain first from the final vector , then breaking the circular chain between positions with the weakest dependency , e.g . , between positions i and j where p i , j is the largest or the log - likelihood of the corresponding linear chain model is maximized .", "label": "", "metadata": {}, "score": "50.110073"}
{"text": "These posteriors fall out of a free - form optimization procedure , which naturally incorporates conjugate priors .Unlike in large sample approximations , the posteriors are generally nonGaussian and no Hessian needs to be computed .Predictive quantities are obtained analytically .", "label": "", "metadata": {}, "score": "50.152863"}
{"text": "An exhaustive search is not always possible in practice , however , as the search space can be very large .The number of possible Markov chains is the factorial of the length of the Markov chain and dramatically increases as the length of chain increases .", "label": "", "metadata": {}, "score": "50.22246"}
{"text": "Also , we extended the traditional linear chain Markov model to the circular chain Markov model , which can better represent position dependencies within a motif in some cases .We presented a novel method , DNJ , for efficiently optimizing position arrangement of a non 0 th order Markov chain to incorporate most dependencies .", "label": "", "metadata": {}, "score": "50.60506"}
{"text": "We randomly split both the true sites and false sites into 10 roughly equal - sized parts , and used a 10-fold cross validation to compare the performance of OMiMa 's 0 - 1 mixture model with the others .", "label": "", "metadata": {}, "score": "50.699833"}
{"text": "Generally , only a subset of bases from B appears in a particular position of a set of biological motifs .The more conserved a position , the fewer bases are in the subset .The EDF for a model is related to the observed bases in training samples .", "label": "", "metadata": {}, "score": "50.8799"}
{"text": "We show how a kernel over trees can be applied to parsing using the voted perceptron algorithm , and we give experimental results on the ATIS corpus of parse trees . ... ion from ranking problems to a margin - based classification problem in [ 8].", "label": "", "metadata": {}, "score": "51.364502"}
{"text": "So a decoy site can have the exactly same sequence as a real site .We applied this original training and testing sets to assess performance of OMiMa , where we used only log - likelihood ratio scoring .In addition , we ran a 3-fold cross - validation , in which the number of sites in new training and testing sets are roughly the same as those in the original ones [ see Additional file 1 Table 2 ] .", "label": "", "metadata": {}, "score": "51.56497"}
{"text": "The evolution of the state vector may be viewed as a ... \" ...We present conditional random fields , a framework for building probabilistic models to segment and label sequence data .Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks , including the ability to relax strong independence assumptions ... \" .", "label": "", "metadata": {}, "score": "51.592766"}
{"text": "Each potential threshold yields an estimated true positive rate and a false positive rate .The plot of true positive rates against false positive rates generates a Receiver Operating Characteristic ( ROC ) curve , which can be used for comparing and selecting the best model .", "label": "", "metadata": {}, "score": "51.642292"}
{"text": "In the 3-fold cross validation , the sample sizes for both training and testing sets are approximately equal to those of the original partition by Yeo and Burge .Biological explanation .To compare OMiMa 's fitted donor site models to biological knowledge about dependencies among positions , we examined the best donor models for the first donor dataset ( Reese data ) and for the second donor dataset ( Yeo data ) .", "label": "", "metadata": {}, "score": "51.762276"}
{"text": "Rather , dependencies are learned form data using the Bayesian networks formalism .This approach guaranties to impr ... \" .ABSTRACT We present a new continuous automatic speech recognition system where no a priori assumptions on the dependencies between the observed and the hidden speech processes are made .", "label": "", "metadata": {}, "score": "52.03255"}
{"text": "Rather , dependencies are learned form data using the Bayesian networks formalism .This approach guaranties to impr ... \" .ABSTRACT We present a new continuous automatic speech recognition system where no a priori assumptions on the dependencies between the observed and the hidden speech processes are made .", "label": "", "metadata": {}, "score": "52.03255"}
{"text": "The nonlinear mappings in the model are represented using multilayer perceptron networks .The proposed method is computationally demanding , but it allows the use of higher dimensional nonlinear latent variable models than other existing approaches .Experiments with chaotic data show that the new method is able to blindly estimate the factors and the dynamic process which have generated the data .", "label": "", "metadata": {}, "score": "52.196075"}
{"text": "The nonlinear mappings in the model are represented using multilayer perceptron networks .The proposed method is computationally demanding , but it allows the use of higher dimensional nonlinear latent variable models than other existing approaches .Experiments with chaotic data show that the new method is able to blindly estimate the factors and the dynamic process which have generated the data .", "label": "", "metadata": {}, "score": "52.196075"}
{"text": "We formulate the modelling problem in the dynamic Bayesian networks DBNs formalism .As a subset of PGMs , DBNs are able to encode complex independence assertions for dynamic processes .We developed a methodology in which we do not make any a priori dependence assumptions between the observed and hidden processes in speech .", "label": "", "metadata": {}, "score": "52.33645"}
{"text": "We formulate the modelling problem in the dynamic Bayesian networks DBNs formalism .As a subset of PGMs , DBNs are able to encode complex independence assertions for dynamic processes .We developed a methodology in which we do not make any a priori dependence assumptions between the observed and hidden processes in speech .", "label": "", "metadata": {}, "score": "52.33645"}
{"text": "For our mixture of Markov models , the EDF is defined as the number of parameters that are direct estimates of the observed bases in a training motif set .Let b i be the base set observed in a position i of a training set of motifs .", "label": "", "metadata": {}, "score": "52.345676"}
{"text": "We present a new probabilistic model based on the lexical PCFG model , which can easily utilize the Chinese character information to solve the lexical information sparseness in lexical PCFG model .We discuss in particular some important features that can improve the parsing performance , and describe the strategy of modifying original label structure to reduce the label ambiguities .", "label": "", "metadata": {}, "score": "52.47967"}
{"text": ".. learning in similar problems using slightly di#erent assumptions and methods ( Choudrey et al . , 2000 ; Miskin and MacKay , 2000 ; Miskin and MacKay , 2001 ; Roberts and Everson , 2001 ) .In ( Attias , 2000 ) , this type of methods h .. by Jeffrey A. Bilmes - Mathematical Foundations of Speech and Language Processing , 2003 . \" ...", "label": "", "metadata": {}, "score": "52.516388"}
{"text": ".. learning in similar problems using slightly di#erent assumptions and methods ( Choudrey et al . , 2000 ; Miskin and MacKay , 2000 ; Miskin and MacKay , 2001 ; Roberts and Everson , 2001 ) .In ( Attias , 2000 ) , this type of methods h .. by Jeffrey A. Bilmes - Mathematical Foundations of Speech and Language Processing , 2003 . \" ...", "label": "", "metadata": {}, "score": "52.516388"}
{"text": "The prediction accuracy of a probabilistic model is largely determined by the effectiveness of the model in characterizing a biological motif .Since there is large variation of the signals embedded in biological motifs , an effective model can be as simple as a consensus sequence or as complex as a fully connected network model .", "label": "", "metadata": {}, "score": "52.516792"}
{"text": "However , the exponentially increased number of parameters of these models makes them impractical due to insufficient training data .To address the weaknesses of WAM in incorporating long - range interactions , Burge and Karlin [ 2 ] proposed the Maximal Dependence Decomposition ( MDD ) model , which has a binary tree structure formed by a set of conditional WAMs .", "label": "", "metadata": {}, "score": "52.59625"}
{"text": "A novel feature of t ... \" .\" Segmental hidden Markov models \" ( SHMMs ) are intended to overcome important speech - modelling limitations of the conventional - HMM approach by representing sequences ( or segments ) of features and incorporating the concept of trajectories to describe how features change over time .", "label": "", "metadata": {}, "score": "52.66849"}
{"text": "We describe a robust accurate domain - independent approach to statistical parsing incorporated into the new release of the ANLT toolkit , and publicly available as a research tool .The system has been used to parse many well known corpora in order to produce data for lexical acquisition efforts ; it ha ... \" .", "label": "", "metadata": {}, "score": "52.67301"}
{"text": "These properties also resemble the spatial receptive fields of neurons in the primary visual cortex of mammals , suggesting that the receptive - field structure of these neurons can be accounted for by a general efficient coding principle .The probabilistic framework provides a method for comparing the coding efficiency of different bases objectively by calculating their probability given the observed data or by measuring the entropy of the basis function coefficients .", "label": "", "metadata": {}, "score": "52.85545"}
{"text": "Any methods that employ chi - square techniques to test for dependent sites face similar limitations .Nevertheless , OMiMa with its relatively small parameter space should adapt to small training datasets better than many competitors .Of course , any motif finding algorithm would do better with larger training samples .", "label": "", "metadata": {}, "score": "53.0907"}
{"text": "Previous attempts to construct acoustic models that remove this assumption have suffered from a significant increase in the number of parameters to train .Another weakness ... \" .The HMM assumption of conditional independence of observations causes a variety of problems for speech - recognition applications .", "label": "", "metadata": {}, "score": "53.11345"}
{"text": "It also includes an example where a graph can be used to represent language model smoothing constraints .As will be seen , the space of models describable by a graph is quite large .A thorough exploration of this space should yield techniques that ultimately will supersede the hidden Markov model . .", "label": "", "metadata": {}, "score": "53.163956"}
{"text": "It also includes an example where a graph can be used to represent language model smoothing constraints .As will be seen , the space of models describable by a graph is quite large .A thorough exploration of this space should yield techniques that ultimately will supersede the hidden Markov model . .", "label": "", "metadata": {}, "score": "53.163956"}
{"text": "The application of such ' model - free ' methods , however , has been somewhat restricted both by the view that results can be uninterpretable and by the lack of ability to quantify statistical significance .We present an integrated approach to Probabilistic ICA for FMRI data that allows for non - square mixing in the presence of Gaussian noise .", "label": "", "metadata": {}, "score": "53.331333"}
{"text": "On the right , the remaining positions that closely depend on each other form a circular chain of the 2 nd order Markov model .The graphic representation of the 0-k mixture model for TFBS .The simple mixture of Markov models for TFBS .", "label": "", "metadata": {}, "score": "53.341717"}
{"text": "Unlike in the Laplace approximation , these posteriors are generally non - Gaussian and no Hessian needs to be computed .The resulting algorithm generalizes the standard Expectation Maximization a .. matrices , as well as the source distributions , from noisy data .", "label": "", "metadata": {}, "score": "53.544773"}
{"text": "The proposed method has important applications in areas such as computational biology , natural language processing , information retrieval / extraction , and optical character recognition .Experiments from various domains involving different types of output spaces emphasize the breadth and generality of our approach . by Koby Crammer , Ofer Dekel , Shai Shalev - Shwartz , Yoram Singer - JMLR , 2006 . \" ...", "label": "", "metadata": {}, "score": "53.551277"}
{"text": "The remaining positions in M are further grouped into subsets by iterating the following rules : .( c )For each remaining position , check if it significantly depends on any position in C s .If it does , then move it from M into C s .", "label": "", "metadata": {}, "score": "53.808643"}
{"text": "The probability of a motif sequence is given by equation ( 1 ) for a linear chain and equation ( 2 ) for a circular chain , respectively .Compared to a linear Markov chain , a circular Markov chain incorporates additional dependencies that may contain subtle signals that allow the model to distinguish true motifs from false ones , especially when false motifs are similar to true motifs .", "label": "", "metadata": {}, "score": "53.8518"}
{"text": "In the latter case , a variable might indicate a condition such as noise level or qua ... . \" ...We present a new continuous automatic speech recognition system where no a priori assumptions on the dependencies between the observed and the hidden speech processes are made .", "label": "", "metadata": {}, "score": "54.071945"}
{"text": "In the latter case , a variable might indicate a condition such as noise level or qua ... . \" ...We present a new continuous automatic speech recognition system where no a priori assumptions on the dependencies between the observed and the hidden speech processes are made .", "label": "", "metadata": {}, "score": "54.071945"}
{"text": "This paper first provides a brief overview of graphical models and their uses as statistical models .It is then shown that the statistical assumptions behind many pattern recog ... \" .Graphical models provide a promising paradigm to study both existing and novel techniques for automatic speech recognition .", "label": "", "metadata": {}, "score": "54.17967"}
{"text": "This paper first provides a brief overview of graphical models and their uses as statistical models .It is then shown that the statistical assumptions behind many pattern recog ... \" .Graphical models provide a promising paradigm to study both existing and novel techniques for automatic speech recognition .", "label": "", "metadata": {}, "score": "54.17967"}
{"text": "Given a training dataset , ML estimates a single optimal value f .. spirit of [ 8].( b ) Let the parameter posterior q ( ) fall out of free - form optimization , as before . \" ...", "label": "", "metadata": {}, "score": "54.199036"}
{"text": "The recent explosive growth of online , accessible corpora of spoken language interactions opens up new opportunities for the development of high accuracy parsing approaches to the analysis of spoken language .The availability of high accuracy parsers will in turn provide a platform for development of a wide range of new applications , as well as for advanced research on the nature of conversational interactions .", "label": "", "metadata": {}, "score": "54.333313"}
{"text": "For many biological motifs , however , the number of known ( experimentally determined ) sites is small .This limits the usage of complex models , such as higher order Markov models , Bayesian trees , network models or MEM , even though these models in some cases can perform better than the simpler models given enough training data .", "label": "", "metadata": {}, "score": "54.43373"}
{"text": "Inside the layer the dependency graphs are searched exhaustively while between the layers the parser state transfers deterministically .Taking the ... \" .Abstract .In this paper , a layer - based projective dependency parsing approach is presented .This novel approach works layer by layer from the bottom up .", "label": "", "metadata": {}, "score": "54.543785"}
{"text": "Since results from instrumental data and the last millennium are dominated primarily by decadal- to centennial - scale changes , they will therefore only represent climate sensitivity at an equilibrium that is not too far from the present climate .Despite these uncertainties , which are accounted for to differing degrees in the various studies , confidence is increased by the similarities between individual ECS estimates ( Figure 9.20 ) .", "label": "", "metadata": {}, "score": "54.653534"}
{"text": "17 ] and the Weight Array Model ( WAM ) [ 18 ] , can incorporate dependencies between adjacent positions .To incorporate further dependencies of non - adjacent positions , Ponomarenko et al .[19 ] extended DWMM by introducing the Oligonucleotide Weight Matrix model , which includes a comprehensive set of oliogonucleotide matrices classified into 5 biological function categories .", "label": "", "metadata": {}, "score": "54.745083"}
{"text": "The inability of the PWM to capture such dependencies is a limitation as the PWM model often produces a large number of false positives in a genome - wide scan [ 16 ] .Many models have been developed to incorporate position dependencies .", "label": "", "metadata": {}, "score": "54.79458"}
{"text": "So far , we have concentrated on the way to exploit the information contained in the statistical data to build acoustic models .We formulate the modelling problem in the dynamic Bayesian networks DBNs formalism .As a subset of PGMs , DBNs are able to encode complex independenc ... \" . ing robust ASR systems .", "label": "", "metadata": {}, "score": "54.801994"}
{"text": "So far , we have concentrated on the way to exploit the information contained in the statistical data to build acoustic models .We formulate the modelling problem in the dynamic Bayesian networks DBNs formalism .As a subset of PGMs , DBNs are able to encode complex independenc ... \" . ing robust ASR systems .", "label": "", "metadata": {}, "score": "54.801994"}
{"text": "Minimizing AIC is the same as choosing the model with the minimum prediction error or loss , while minimizing BIC is equivalent to choosing the model with the largest posterior probability .Nonetheless , AIC and BIC have a similar form : . -2 \u00b7 loglik + \u03bb \u00b7 DF .", "label": "", "metadata": {}, "score": "54.945114"}
{"text": "Modeling TFBS V$AP1_Q4_01 .The performance of the optimized model of TFBS V$AP1_Q4_01 .The histogram is the log - likelihood score distribution of 1,000 randomly permuted mixture models .The red reference line indicates the relative performance of the DNJ optimized model ( a ) 0 - 1 mixture linear model ( b ) 0 - 1 mixture circular model .", "label": "", "metadata": {}, "score": "55.21718"}
{"text": "Another weakness of current acoustic models is that they do not account for the origin of derived features ( estimated derivatives ) .We show how to both remove the independence assumption and properly account for derived features , with little or no increase in the number of parameters to train , by applying the principle of maximum entropy .", "label": "", "metadata": {}, "score": "55.614037"}
{"text": "In addition , we compared the maximum accuracy ( Ac ) and the maximum Matthews correlation efficient ( Mc ) achieved by each model ( data not shown ) .The best models were 0 - 1 mixture models ( Figure 8 ) .", "label": "", "metadata": {}, "score": "55.969856"}
{"text": "Sets C s are different .The position arrangement for each set C s needs to be optimized so that the Markov model can account for most dependencies while minimizing the Markov order .The neighbor - joining ( NJ ) method proposed by Saitou and Nei [ 26 ] is a well - known distance method for phylogenetic tree reconstruction .", "label": "", "metadata": {}, "score": "56.188652"}
{"text": "We then calculated the empirical p_value of the DNJ - optimized model as follows : . where \u03b4 is an indicator function with value 1 if condition is true , and 0 otherwise .Fifty - three human transcription factors , whose binding sites contain at least four dependent positions by the \u03c7 2 test given by equation ( 3 ) , are selected for this evaluation ( Table 1 ) .", "label": "", "metadata": {}, "score": "56.251034"}
{"text": "We also showed that the optimized Markov model can be an excellent motif predictor .Moreover , it is also computationally efficient due to its simplicity .Model complexity , measured by parameter number , is an important issue in motif modeling .", "label": "", "metadata": {}, "score": "56.353287"}
{"text": "he model in non - discrete uncountable ways , something that can not be exactly flattened into a countable ( or even finite ) state space .Efficient and provably optimal structure learning methods exist in certain case ... . \" ...", "label": "", "metadata": {}, "score": "56.35611"}
{"text": "he model in non - discrete uncountable ways , something that can not be exactly flattened into a countable ( or even finite ) state space .Efficient and provably optimal structure learning methods exist in certain case ... . \" ...", "label": "", "metadata": {}, "score": "56.35611"}
{"text": "where M s is the signal model trained by true motif sites , and M b is the background model or false signal model trained by background sequences or false motif sites .A sequence x is predicted as a positive site if the score of x is larger than a certain threshold .", "label": "", "metadata": {}, "score": "56.452774"}
{"text": "Our DNJ method is based on the exactly same principle .The only major difference is that DNJ needs to consider the direction in joining two nearest neighbors to form a new node while NJ does not .Instead of producing a phylogenetic tree as the NJ method does , DNJ method creates a chain structure , which arranges closely dependent positions as the nearest neighbors .", "label": "", "metadata": {}, "score": "56.46505"}
{"text": "Independent Component Analysis is becoming a popular exploratory method for analysing complex data such as that from FMRI experiments .The application of such ' model - free ' methods , however , has been somewhat restricted both by the view that results can be uninterpretable and by the lack of ... \" .", "label": "", "metadata": {}, "score": "56.56367"}
{"text": "For both TFBS , OMiMa was also able to arrange the positions of each dependent pair to be the nearest neighbors in their 0 - 1 mixture models : ( See table 7 ) .Table 2 : .Simulation of two palindromic TFBS .", "label": "", "metadata": {}, "score": "56.670746"}
{"text": "Experimental results are reported on DARPA 's speakerindependent Resource Management corpus .INTRODUCTION In earlier work , the Stochastic Segment Model ( SSM ) [ 1 , 2 ] has been shown to be a viable alternative to the Hidden Markov Model ( HMM ) for representing variable - duration phones .", "label": "", "metadata": {}, "score": "56.674232"}
{"text": "A thorough exploration of this space should yield techniques that ultimately will supersede the hidden Markov model . ... recognition is to start with the HMM graph given in Figure 16 , and extend it with either additional edges or additional variables .", "label": "", "metadata": {}, "score": "56.694473"}
{"text": "A thorough exploration of this space should yield techniques that ultimately will supersede the hidden Markov model . ... recognition is to start with the HMM graph given in Figure 16 , and extend it with either additional edges or additional variables .", "label": "", "metadata": {}, "score": "56.694473"}
{"text": "Evaluation of our maxent model on a simple problem cuts an already - low error rate in half compared to an equivalent HMM with the same number of parameters . ... ry itself may be non - parametric [ 17 ] , [ 16 ] , [ 18 ] or a low - order polynomial [ 19 ] , [ 20 ] , [ 23 ] , [ 15 ] , with constant and linear trajectories having received the most attention .", "label": "", "metadata": {}, "score": "56.843597"}
{"text": "That is why the positions 5 and 8 were arranged together in the model for TFBS A , and positions 6 and 10 were together for TFBS B. We compared the prediction results of OMiMa 's 0 - 1 mixture model with those of PWM , 1stMM and the 1 st order PVLMM ( with depth 1 ) .", "label": "", "metadata": {}, "score": "57.021534"}
{"text": "Results In this section we will first discuss our NTC ... .by Ping Jian , Chengqing Zong - Proceedings of the 23rd Pacific Asia Conference on Language , Information and Computation ( PACLIC , 2009 . \" ... Abstract .In this paper , a layer - based projective dependency parsing approach is presented .", "label": "", "metadata": {}, "score": "57.253387"}
{"text": "We then describe and analyze a new boosting algorithm for combining preferences called RankBoost .We also describe an efficient implementation of the algorithm for certain natural cases .We discuss two experiments we carried out to assess the performance of RankBoost .", "label": "", "metadata": {}, "score": "57.333275"}
{"text": "In this paper we evaluate our approach for a more complex task : continuous phoneme recognition .For this purpose , we propose a new decoding algorithm based on dynamic programming .The proposed algorithm decreases the computational complexity of decoding and hence enables the application of the approach to complex speech recognition tasks . \" ...", "label": "", "metadata": {}, "score": "57.4524"}
{"text": "In this paper we evaluate our approach for a more complex task : continuous phoneme recognition .For this purpose , we propose a new decoding algorithm based on dynamic programming .The proposed algorithm decreases the computational complexity of decoding and hence enables the application of the approach to complex speech recognition tasks . \" ...", "label": "", "metadata": {}, "score": "57.4524"}
{"text": "The 3 rd and 4 th columns are simulation parameters , which specify the probabilities of forming a complementary base pair .The last 2 columns are the p - values of OMiMa 's pairwise \u03c7 2 tests of position dependency for the simulated data .", "label": "", "metadata": {}, "score": "57.910473"}
{"text": "Our primary goal is the labeling of syntactic nodes with specific argument labels that preserve the similarity of roles such as the window in ... \" .This paper describes our approach to the development of a Proposition Bank , which involves the addition of semantic information to the Penn English Treebank .", "label": "", "metadata": {}, "score": "57.93438"}
{"text": "We investigate the issues that are involved in trade - offs between trajectory and mixture modeling in segment - based word re ... \" .This paper presents a mechanism for implementing mixtures at a phone - subsegment ( microsegment ) level for continuous word recognition based on the Stochastic Segment Model ( SSM ) .", "label": "", "metadata": {}, "score": "58.006126"}
{"text": "For example , a high sensitivity is difficult to rule out because a high aerosol forcing could nearly cancel greenhouse gas forcing over the 20th century .In addition , nonlinearities in the response to transient forcing make it more difficult to constrain the upper limit on ECS based on observed transient forcing responses ( Frame et al . , 2005 ) .", "label": "", "metadata": {}, "score": "58.209362"}
{"text": "A commonly used model for motif identification is the Weight Matrix Model ( WMM ) proposed by Staden [ 7 ] , also called the Position Weight Matrix ( PWM ) or Mononucleotide Weight Matrix ( MWM ) .A PWM is usually generated from a set of aligned instances of known motif sequences , using the observed position - specific base frequencies and/or prior information .", "label": "", "metadata": {}, "score": "58.282116"}
{"text": "If only base A is observed in the position , then one needs to estimate only the frequency of A , the remaining parameters , i.e . , the frequencies of C , G , T , can be derived from any prior information .", "label": "", "metadata": {}, "score": "58.306313"}
{"text": "Table 1 .The optimized 1 st order Markov chains for TFBS .The optimized arrangement of dependent positions within TFBS for the 1 st order Markov model .N and N D are total number of motif positions and the number of positions significantly dependent , respectively .", "label": "", "metadata": {}, "score": "58.457054"}
{"text": "Since the k th order Markov chain of ' a 0-k mixture model ' can be either linear or circular , we also use terms ' a 0-k mixture linear model ' and ' a 0-k mixture circular model ' to distinguish them .", "label": "", "metadata": {}, "score": "58.735985"}
{"text": "Affiliated with .Abstract .Background .Identifying functional elements , such as transcriptional factor binding sites , is a fundamental step in reconstructing gene regulatory networks and remains a challenging issue , largely due to limited availability of training samples .", "label": "", "metadata": {}, "score": "58.810787"}
{"text": "Conclusion .Our optimized mixture of Markov models represents an alternative to the existing methods for modeling dependent structures within a biological motif .Unlike existing methods , our model is conceptually simple and effective , which has advantages in a large scale motif prediction .", "label": "", "metadata": {}, "score": "58.867027"}
{"text": "We simulated two imperfect palindromic TFBS ( named A and B ) of length 12 bases .For each TFBS , the bases in each position were generated from the uniform distribution ( the frequency of each base is 0.25 ) .", "label": "", "metadata": {}, "score": "59.13755"}
{"text": "The sub - motif formed by independent positions is modeled by a 0 th order Markov order model .The sub - motif forming by the remaining positions is modeled by either a 1 st or 2 nd order Markov chain , which can be either linear ( break at dotted arrows ) or circular .", "label": "", "metadata": {}, "score": "59.24504"}
{"text": "This approach has the advantage to guaranty that the resulting model represents speech with higher fidelity than HMMs .Moreover , a control is given to the user to make a trade - off between modeling accuracy and model complexity .In addition , the approach is technically very attractive because all the computational effort is made in the training phase . .", "label": "", "metadata": {}, "score": "59.312897"}
{"text": "This approach has the advantage to guaranty that the resulting model represents speech with higher fidelity than HMMs .Moreover , a control is given to the user to make a trade - off between modeling accuracy and model complexity .In addition , the approach is technically very attractive because all the computational effort is made in the training phase . .", "label": "", "metadata": {}, "score": "59.312897"}
{"text": "Indeed , the observations are assumed to be governed by a hidden ( unobserved ) dynamic process .The associated independence assumptions state that the hidden process is first - order Markov , and each observation depends only on the current hidden variable .", "label": "", "metadata": {}, "score": "59.433556"}
{"text": "Indeed , the observations are assumed to be governed by a hidden ( unobserved ) dynamic process .The associated independence assumptions state that the hidden process is first - order Markov , and each observation depends only on the current hidden variable .", "label": "", "metadata": {}, "score": "59.433556"}
{"text": "Graphical models provide a promising paradigm to study both existing and novel techniques for automatic speech recognition .This paper first provides a brief overview of graphical models and their uses as statistical models .It is then shown that the statistical assumptions behind many pattern recog ... \" .", "label": "", "metadata": {}, "score": "59.43511"}
{"text": "The problem of dimensionality reduction arises in many fields of information processing , including machine learning , data compression , scientific visualization , pattern recognition , and neural computation . by Hagai Attias - In Advances in Neural Information Processing Systems 12 , 2000 . \" ...", "label": "", "metadata": {}, "score": "59.655006"}
{"text": "How to further enrich feature representations for better shift - reduce constituency parsing becomes a very challenging problem .In this paper , we solve this issue by using the ... . \" ... question answering To my family for love and support . iv Question answering ( QA ) aims at finding exact answers to a user 's natural language question from a large collection of documents .", "label": "", "metadata": {}, "score": "60.043133"}
{"text": "For this task , we compare the performance of RankBoost to the individual search strategies .The second experiment is a collaborative - filtering task for making movie recommendations .Here , we present results comparing RankBoost to nearest - neighbor and regression algorithms . by Ioannis Tsochantaridis , Thorsten Joachims , Thomas Hofmann , Yasemin Altun - JOURNAL OF MACHINE LEARNING RESEARCH , 2005 . \" ...", "label": "", "metadata": {}, "score": "60.62215"}
{"text": "Comparison with MEM and PVLMM .Given enough training data , we can use more complicated models than the 0 - 1 mixture model to improve prediction accuracy .In this evaluation , we test whether 0-k mixture models can compete with the MEM on a much larger dataset .", "label": "", "metadata": {}, "score": "60.91966"}
{"text": "question answering To my family for love and support . iv Question answering ( QA ) aims at finding exact answers to a user 's natural language question from a large collection of documents .Most QA systems combine information retrieval with extraction techniques to identify a set of likely candidates and then utilize some selection strategy to generate the final answers .", "label": "", "metadata": {}, "score": "60.93052"}
{"text": "( PDF 312 KB ) .Authors ' contributions .W. Huang provided the principal contributions to the conception and design of this study as well as to its analysis . D. M. Umbach and L. Li contributed to the design of the study and the interpretation of results .", "label": "", "metadata": {}, "score": "60.95677"}
{"text": "Despite significant advances in syntactic parsing of written text , the application of these techniques to spontaneous spoken language has received more limited attention .The recent explosive growth of online , a ... \" .Automatic analysis of syntax is one of the core problems in natural language processing .", "label": "", "metadata": {}, "score": "61.24735"}
{"text": "PWM has been used by many motif identification programs , e.g . , Matlnspector [ 9 ] and Match [ 10 ] , and performs reasonably well for motif identification .While a PWM can capture both nucleotide preferences at each position and different levels of position specificity , it does not account for functional dependencies between positions .", "label": "", "metadata": {}, "score": "61.330513"}
{"text": "Markov chain optimization .The next step is to arrange the positions in each subset into a Markov chain .Since the positions in sets H and I are independent of each other , they can be arranged in their natural order to form a 0 th order Markov chain .", "label": "", "metadata": {}, "score": "61.446583"}
{"text": "Motif positions involved in the same role can be highly dependent , whereas those involved unrelated roles are likely independent .A mixture of Markov models seems an ideal fit by modeling different signals with different sub - models .A 0 th order Markov chain can effectively model strong signals such as those embedded in highly conserved positions where the probability of a certain base occurring is almost one .", "label": "", "metadata": {}, "score": "61.47763"}
{"text": "The distance of x to other remaining vector y is defined by : .Go back to step 3 if the number of vectors in C s is larger than 2 , otherwise join the last two vectors according to Algorithm 1 .", "label": "", "metadata": {}, "score": "61.533722"}
{"text": "Illustration of the DNJ method for Markov chain optimization .An example of the DNJ method to optimize the 2 nd order Markov chain .For a given set C s , put each position in the set into a different vector .", "label": "", "metadata": {}, "score": "61.595577"}
{"text": "In additional experiments we train overcomplete energy - based models to extract features from various standard data - sets containing speech , natural images , hand - written digits and faces .Tools . by Lawrence K. Saul , Sam T. Roweis , Yoram Singer - Journal of Machine Learning Research , 2003 . \" ...", "label": "", "metadata": {}, "score": "61.689983"}
{"text": "The lower bound is consistent with the view that the sum of all atmospheric feedbacks affecting climate sensitivity is positive .Although upper limits can be obtained by combining multiple lines of evidence , remaining uncertainties that are not accounted for in individual estimates ( such as structural model uncertainties ) and possible dependencies between individual lines of evidence make the upper 95 % limit of ECS uncertain at present .", "label": "", "metadata": {}, "score": "61.90758"}
{"text": "E ( x i , x j ) is the product of observed base frequencies x i and x j .Based on the above \u03c7 2 tests , find all positions that show little dependence on any other positions in M , and move them to the set I , as defined by .", "label": "", "metadata": {}, "score": "61.958305"}
{"text": "Based on the Area Under Curve ( AUC ) criterion , the figure indicates that : ( a )For training data , the best models were 3-L-1 and 3-C-1 while the worst model is 0-L-1 ( same as 0-C-1 ) .", "label": "", "metadata": {}, "score": "61.9868"}
{"text": "Typically , the model assumes that segme ... . ... istic mapping specifies which region corresponds to each observation vector .Initial experiments with contextindependent ( CI ) phone classification suggested that microsegment models provided a significant gain over the standard SSM ... . \" ...", "label": "", "metadata": {}, "score": "61.9923"}
{"text": "Some of the work has been published previously in conference proceedings [ 66,69 ] , two journal articles [ 36,68 ] , two workshop papers [ 35,67 ] and a tech - nical report [ 65].The length of this thesis including appendices , bibliography , footnotes , tables and equations is approximately 60,000 words .", "label": "", "metadata": {}, "score": "62.233093"}
{"text": "The promising results on this simple task encouraged us to consider a more complicated application and we validated our result ... . ... ilistic modelling approaches for analysis and decision making under uncertainty are gaining more popularity than deterministic methods in today 's world .", "label": "", "metadata": {}, "score": "62.272217"}
{"text": "The promising results on this simple task encouraged us to consider a more complicated application and we validated our result ... . ... ilistic modelling approaches for analysis and decision making under uncertainty are gaining more popularity than deterministic methods in today 's world .", "label": "", "metadata": {}, "score": "62.272217"}
{"text": "The best models picked by ROC analysis are consistent with those selected by OMiMa ( AIC criterion ) .The selected models were further confirmed by a six - fold cross validation .Comparison of different 0-k mixture models for donor splice site prediction .", "label": "", "metadata": {}, "score": "62.357056"}
{"text": "Except for its order and depth parameters , PVLMM was run under its default settings in all comparisons .Simulated TFBS prediction .Many TFBS are palindromic sites bound by heterodimers / homodimers ( e.g . , : Jun - Fos , Myc - Max , Max - Max and p50-p50 ) .", "label": "", "metadata": {}, "score": "62.358852"}
{"text": "The optimized mixture of Markov models we presented here tries to inherit advantages of these existing models while avoiding their disadvantages .In OMiMa , we replace VLMM with a mixture of several lower order Markov models , which are subsequently optimized to account for long - range dependencies .", "label": "", "metadata": {}, "score": "62.439476"}
{"text": "For convenience , we use notation \" P : k - d \" to denote a PVLMM of order k and depth d .We adopt notation in [ 23 ] for sub - models of MEM .One advantage of OMiMa over MEM is that , for the models with similar performance , OMiMa 's models generally have fewer parameters and thus require fewer training samples .", "label": "", "metadata": {}, "score": "62.492725"}
{"text": "Since both OMiMa and NNSplice used the same training and testing data , their prediction results can be directly compared .We compared OMiMa 's 1-L-1 and 1-C-1 models with the first order PVLMM ( with depth 1 ) as all have similar model complexity .", "label": "", "metadata": {}, "score": "62.648743"}
{"text": "Graphical models provide a promising paradigm to study both existing and novel techniques for automatic speech recognition .This paper first provides a brief overview of graphical models and their uses as statistical models .Moreover , this paper shows that many advanced models for speech recognition and language processing can also be simply described by a graph , including many at the acoustic- , pronunciation- , and language - modeling levels .", "label": "", "metadata": {}, "score": "62.70852"}
{"text": "View Article PubMed .Staden R : Computer methods to locate signals in nucleic acid sequences .Nucl Acids Res 1984 , 12 : 505 - 519 .View Article PubMed .Stormo GD , Fields DS : Specificity , free energy and information content in protein - DNA interactions .", "label": "", "metadata": {}, "score": "62.856556"}
{"text": "For Japanese , Chasen 4 was used .6.2.2 Answer Similarity Features As Chinese and Japanese factoid questions require short text phrases as answers , the similarity between two answer candidates can be calculated with string distance ... . \" ...This paper presents a language - independent probabilistic answer ranking framework for question answering .", "label": "", "metadata": {}, "score": "63.24057"}
{"text": "Empirical results from testing on NT - CIR factoid questions show a 40 % performance improvement in Chinese answer selection and a 45 % improvement in Japanese answer selection . by Teruko Mitamura , Frank Lin , Hideki Shima , Mengqiu Wang , Jeongwoo Ko , Justin Betteridge , Matthew Bilotti , Andrew Schlaikjer , Eric Nyberg - In Proceedings of the 6th NTCIR Workshop , 2007 . \" ...", "label": "", "metadata": {}, "score": "63.282295"}
{"text": "We investigated a supervised sequence learning method to automatically recognize function tags , which achieves an F - score of 0.938 on gold - standard POS ( Part - of - Speech ) tagged Chinese text - a statistically significant improvement over existing Chinese function label assignment systems .", "label": "", "metadata": {}, "score": "63.38263"}
{"text": "State space models are based on a hidden continuous state evolution process and an observation process wh ... . \" ...This report describes an attempt at capturing segmental transition information for speech recognition tasks .The slowly varying dynamics of spectral trajectories carries much discriminant information that is very crudely modelled by traditional approaches such as HMMs .", "label": "", "metadata": {}, "score": "63.39999"}
{"text": "In parsing we would have training examples fs i ; t i g where each s i is a sentence and each t i is the cor ... . by Paul Kingsbury , Martha Palmer - In Language Resources and Evaluation , 2002 . \" ...", "label": "", "metadata": {}, "score": "63.520535"}
{"text": "For testing data , the best models were 1-L-1 and 1-C-1 while the worst models are 3-L-1 and 3-C-1 .Using the best model selected above , we then compared OMiMa with NNSplice and PVLMM .", "label": "", "metadata": {}, "score": "63.53778"}
{"text": "Several motif models and methods have been developed to address this issue .One of these models is the variable length Markov model ( VLMM ) , whose Markov orders ( also called context lengths ) can vary among different positions .", "label": "", "metadata": {}, "score": "63.5833"}
{"text": "Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks , including the ability to relax strong independence assumptions made in those models .Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models ( MEMMs ) and other discriminative Markov models based on directed graphical models , which can be biased towards states with few successor states .", "label": "", "metadata": {}, "score": "63.6867"}
{"text": "The performance comparison of different methods for predicting the simulated palindromic TFBS A. The x - axis shows the number of motif sequences used for training .The y - axis is the Matthews correlation coefficient of each method in predicting the same testing dataset ( 150 false and 150 true sites , respectively ) .", "label": "", "metadata": {}, "score": "63.80551"}
{"text": "As an integrated part of OMiMa , we also introduce the Directed Neighbor - Joining ( DNJ ) method to optimally rearrange positions to minimize Markov order .We then describe and discuss the methods for selecting the best model .We implement our model into the OMiMa system that is freely available to the public .", "label": "", "metadata": {}, "score": "63.810547"}
{"text": "VLMM , however , is not the best choice to incorporate long - range dependencies .The position optimized Markov model ( POMM ) [ 21 ] is able to incorporate important distant dependencies without increasing Markov chain order .However , the effectiveness of this model largely depends on the optimization routine .", "label": "", "metadata": {}, "score": "63.912918"}
{"text": "For example , the total EDF for the special 0-k mixture model equals to the EDF sum of the 0 th and the k th order chains .Performance assessment .We test the effectiveness of our method on TFBS data and the donor splice sites , where training data for OMiMa are a set of sequences of a motif .", "label": "", "metadata": {}, "score": "63.93118"}
{"text": "State space models are based on a continuous state vector evolving through time according to a state evo- .... mance , mathematically this technique conflicts with the independence assumption .This independence assumption is widely thought to be the major drawback of the use of HMMs for speech recognition ( eg .", "label": "", "metadata": {}, "score": "64.104996"}
{"text": "Although all approaches try to circumvent the frame independence assumption within a segment and repo ... . by Ashvin Kannan , Mari Ostendorf - in Proc .Int&apos;l .Conf . on Acoust . , Speech and Signal Proc , 1993 . \" ...", "label": "", "metadata": {}, "score": "64.34039"}
{"text": "For the pre - instrumental part of the last millennium , uncertainties in temperature and forcing reconstructions , and the nonlinear connection between ECS and the response to volcanism , prohibit tighter constraints .In addition , the number of studies providing estimates of PDFs from palaeoclimatic data , using independent approaches and complementary sources of proxy data , are limited .", "label": "", "metadata": {}, "score": "64.36885"}
{"text": "The Markov model is the simplest yet can be very powerful when it is optimized .Our results showed that the optimized Markov models performed better than the neural network model and PVLMM , and comparably with MEM for splice site prediction .", "label": "", "metadata": {}, "score": "64.46069"}
{"text": "In other word ... . \" ...State - of - the - art automatic speech recognition systems are based on probabilistic modelling of the speech signal using Hidden Markov Models ( HMMs ) .Recent work has focused on the use of dynamic Bayesian networks ( DBNs ) framework to construct new acoustic models to overcome the limitations of HMM b ... \" .", "label": "", "metadata": {}, "score": "64.47485"}
{"text": "In other word ... . \" ...State - of - the - art automatic speech recognition systems are based on probabilistic modelling of the speech signal using Hidden Markov Models ( HMMs ) .Recent work has focused on the use of dynamic Bayesian networks ( DBNs ) framework to construct new acoustic models to overcome the limitations of HMM b ... \" .", "label": "", "metadata": {}, "score": "64.47485"}
{"text": "Currently the most popular acoustic model for speech recognition is the hidden Markov model ( HMM ) .However , HMMs are based on a series of assumptions some of which are known to be poor .In particular , the assumption that successive speech frames are conditionally independent given the discrete state that generated them is not a good assumption for speech recognition .", "label": "", "metadata": {}, "score": "64.677086"}
{"text": "For the transcription factor V$AP1_Q4_01 , we found that for the 0 - 1 mixture model of either linear or circular structure , DNJ optimized models are better than any models from 1,000 random permutations ( Figure 5 ) .The performance of the DNJ optimized 0 - 1 mixture models .", "label": "", "metadata": {}, "score": "64.69046"}
{"text": "Initially , each vector has only one position .Convert the distance matrix d to the transformed distance matrix D , whose elements are D ( u , v ) , by the following conversion function ( see [ 26 ] ): .", "label": "", "metadata": {}, "score": "65.12235"}
{"text": "View Article PubMed .Zhang MQ , Marr TG : A weight array method for splicing signal analysis .Comput Appl Biosci 1993 , 9 ( 5 ) : 499 - 509 .PubMed .Ponomarenko MP , Ponomarenko JV , Frolov AS , Podkolodnaya OA , Vorobyev DG , Kolchanov NA , Overton GC : Oligonucleotide frequency matrices addressed to recognizing functional DNA sites .", "label": "", "metadata": {}, "score": "65.261444"}
{"text": "First , based on 1,116 real donor sites in the Reese original training data , the 0 - 1 mixture model was selected as the best model with the following 1 st order chain .Interestingly , the model also arranged non - conserved positions ( -4 , -5 , -6 , -7 , 6 , 7 ) together as it did for the other more conserved positions .", "label": "", "metadata": {}, "score": "65.31741"}
{"text": "The features can help to disambiguate action conflicts during decoding .Experimental results show that the new features achieve absolute improvements over a strong baseline by 0.9 % and 1.1 % on English and Chinese respectively .Moreover , the improved parser outperforms all previously reported shift - reduce constituency parsers . .", "label": "", "metadata": {}, "score": "65.352844"}
{"text": "Table 3 .Performance evaluation using simulated palindromic TFBS .Performance comparison of OMiMa ( 1-L-0 ) with PWM , 1stMM , and PVLMM ( order 1 and depth 1 ) for predicting two simulated TFBS A and B. The performance was measured as the maximum Mc achieved by each model .", "label": "", "metadata": {}, "score": "65.63806"}
{"text": "Kel AE , G\u00f6ssling E , Reuter I , Cheremushkin E , Kel - Margoulis OV , Wingender E : MATCH :A tool for searching transcription factor binding sites in DNA sequences .Nucleic Acids Res 2003 , 31 ( 13 ) : 3576 - 3579 .", "label": "", "metadata": {}, "score": "65.71617"}
{"text": "It has not been submitted in whole or in part for a degree at any other university .Some of the work has been published previously in conference proceedings [ 66,69 ] , two ... \" .Declaration This dissertation is the result of my own work and includes nothing that is the outcome of work done in collaboration .", "label": "", "metadata": {}, "score": "65.71889"}
{"text": "PubMed .Barash Y , Elidan G , Friedman N , Kaplan T : Modeling dependencies in protein - DNA binding sites .RECOMB ' 03 : Proceedings of the seventh annual international conference on Computational molecular biology New York , NY , USA : ACM Press 2003 , 28 - 37 .", "label": "", "metadata": {}, "score": "65.74788"}
{"text": "Authors ' Affiliations .Biostatistics Branch , The National Institute of Environmental Health Sciences , National Institutes of Health .Institute for Genome Sciences & Policy , Duke University Medical Center .References .Burge C , Karlin S : Prediction of complete gene structures in human genomic DNA .", "label": "", "metadata": {}, "score": "65.76638"}
{"text": "Gaussian random field ; Spatial uncertainty ; Model calibration ; Spatial statistics Tools . by Lawrence K. Saul , Sam T. Roweis , Yoram Singer - Journal of Machine Learning Research , 2003 . \" ...The problem of dimensionality reduction arises in many fields of information processing , including machine learning , data compression , scientific visualization , pattern recognition , and neural computation .", "label": "", "metadata": {}, "score": "65.83841"}
{"text": "We describe the application of kernel methods to Natural Language Processing ( NLP ) problems .In many NLP tasks the objects being modeled are strings , trees , graphs or other discrete structures which require some mechanism to convert them into feature vectors .", "label": "", "metadata": {}, "score": "65.839424"}
{"text": "We describe the application of kernel methods to Natural Language Processing ( NLP ) problems .In many NLP tasks the objects being modeled are strings , trees , graphs or other discrete structures which require some mechanism to convert them into feature vectors .", "label": "", "metadata": {}, "score": "65.839424"}
{"text": "In addition to simply extend previous method from English to Chinese , we also proposed an ... \" .Data - driven function tag assignment has been studied for English using Penn Treebank data .In this paper , we address the question of whether such method can be applied to other languages and Treebank resources .", "label": "", "metadata": {}, "score": "65.96913"}
{"text": "We used two independent datasets of human donor sites to assess the performance of OMiMa in comparison with leading competitors .Comparison with NNSplice and PVLMM .The test dataset of human donor splice sites ( Reese data ) was from [ 38 ] .", "label": "", "metadata": {}, "score": "65.97251"}
{"text": "Therefore , there are only pairwise position dependencies in the simulated TFBS .The position pair 0 - 11 has the strongest dependency , whereas the pair 5 - 6 has the weakest dependency ( they are independent ) .Overall , motif A has stronger position dependencies than motif B. The false sites of TFBS were simulated from the uniform distribution of four nucleotides without any constraints of base pairing between the two half sites .", "label": "", "metadata": {}, "score": "66.07887"}
{"text": "Tools . by Jeffrey A. Bilmes - Mathematical Foundations of Speech and Language Processing , 2003 . \" ...Graphical models provide a promising paradigm to study both existing and novel techniques for automatic speech recognition .This paper first provides a brief overview of graphical models and their uses as statistical models .", "label": "", "metadata": {}, "score": "66.08426"}
{"text": "Bioinformatics 2004 , 20 ( 6 ) : 909 - 916 .View Article PubMed .Saitou N , Nei M : The neighbor - joining method : a new method for reconstructing phylogenetic trees .Mol Biol Evol 1987 , 4 ( 4 ) : 406 - 425 . PubMed .", "label": "", "metadata": {}, "score": "66.182144"}
{"text": "The extra - segmental component of the model is represented in terms of variability in the trajectory parameters , and these models are therefore referred to as \" probabilistic - trajectory segmental HMMs \" ( PTSHMMs ) .This paper presents the theory of PTSHMMs using a linear trajectory description characterized by slope and mid - point parameters , and presents theoretical and experimental comparisons between different types of PTSHMMs , simpler SHMMs and conventional HMMs .", "label": "", "metadata": {}, "score": "66.696915"}
{"text": "These models lead to the best recognition performances in ideal \" lab \" conditions or for easy tasks .However , in real word conditions of speech proc ... \" .State - of - the - art automatic speech recognition ( ASR ) systems are based on probabilistic modelling of the speech signal using Hidden Markov Models ( HMM ) .", "label": "", "metadata": {}, "score": "66.7764"}
{"text": "These models lead to the best recognition performances in ideal \" lab \" conditions or for easy tasks .However , in real word conditions of speech proc ... \" .State - of - the - art automatic speech recognition ( ASR ) systems are based on probabilistic modelling of the speech signal using Hidden Markov Models ( HMM ) .", "label": "", "metadata": {}, "score": "66.7764"}
{"text": "An initial approach to parsing another language in CHILDES would involve repeating the procedure for parsing English described throughout this dissertation .The first ... . \" ...We present a new probabilistic model based on the lexical PCFG model , which can easily utilize the Chinese character information to solve the lexical information sparseness in lexical PCFG model .", "label": "", "metadata": {}, "score": "66.86633"}
{"text": "This approach guaranties to improve modelling fidelity as compared to HMMs .Furthermore , our approach is technically very attractive because all the computational effort is made in the training phase .1 INTRODUCTION First order Hidden Markov Models ( HMM ) are the most commonly used stochastic models in speech recognition .", "label": "", "metadata": {}, "score": "67.50806"}
{"text": "This approach guaranties to improve modelling fidelity as compared to HMMs .Furthermore , our approach is technically very attractive because all the computational effort is made in the training phase .1 INTRODUCTION First order Hidden Markov Models ( HMM ) are the most commonly used stochastic models in speech recognition .", "label": "", "metadata": {}, "score": "67.50806"}
{"text": "We tested whether OMiMa can capture such dependency and optimize the Markov model accordingly .Next , we tested our method on real motif data for AP1 .In both examples , we compared OMiMa performance to PWM , PVLMM , and the 1 st order Markov model ( 1stMM ) with its motif positions in the natural order .", "label": "", "metadata": {}, "score": "67.61546"}
{"text": "Additionally , this paper includes a novel graphical analysis regarding why derivative ( or delta ) features improve hidden Markov model - based speech recognition by improving structural discriminability .It also includes an example where a graph can be used to represent language model smoothing constraints .", "label": "", "metadata": {}, "score": "67.66672"}
{"text": "Additionally , this paper includes a novel graphical analysis regarding why derivative ( or delta ) features improve hidden Markov model - based speech recognition by improving structural discriminability .It also includes an example where a graph can be used to represent language model smoothing constraints .", "label": "", "metadata": {}, "score": "67.66672"}
{"text": "However , in real word conditions of speech processing , the performances of HMM - based ASR systems can decrease drastically and their use becomes very limited .For this reason , the conception of robust and viable ASR systems has been a tremendous scientific and technological challenge in the field of ASR for the last decades .", "label": "", "metadata": {}, "score": "67.800995"}
{"text": "However , in real word conditions of speech processing , the performances of HMM - based ASR systems can decrease drastically and their use becomes very limited .For this reason , the conception of robust and viable ASR systems has been a tremendous scientific and technological challenge in the field of ASR for the last decades .", "label": "", "metadata": {}, "score": "67.800995"}
{"text": "Effectiveness of DNJ method for optimization .To assess the ability of our DNJ method for optimizing a Markov chain , we compared the DNJ method with random permutation method .For each TFBS , we first fitted a 0-k mixture model ( denoted as M DNJ ) with its k th order Markov chain optimized by the DNJ method .", "label": "", "metadata": {}, "score": "67.88587"}
{"text": "This paper addresses the time - series modelling of high dimensional data .Currently , the hidden Markov model ( HMM ) is the most popular and successful model especially in speech recognition .However , there are well known shortcomings in HMMs particularly in the modelling of the correlation between successive observation vectors ; that is , inter - frame correlation .", "label": "", "metadata": {}, "score": "68.009766"}
{"text": "Find the minimum D ( u , v ) in D .Then a new vector x is formed by joining vector u and v according to Algorithm 1 [ see Additional file 1 ] for a k th order Markov chain .", "label": "", "metadata": {}, "score": "68.04768"}
{"text": "Agarwal P , Bafna V : Detecting non - adjoining correlations with signals in DNA .RECOMB ' 98 : Proceedings of the second annual international conference on Computational molecular biology New York , NY , USA : ACM Press 1998 , 2 - 8 .", "label": "", "metadata": {}, "score": "68.10309"}
{"text": "That is , the DF increases exponentially as the order of Markov chain increases .Tested on 61 human regulatory motifs from the Transfac database ( ver . 7.4 ) [ 29 ] , we found that both AIC and BIC selected the 0 th order Markov models for all 61 DNA regulatory motifs when using the DF .", "label": "", "metadata": {}, "score": "69.33452"}
{"text": "For a biological motif with position dependencies , these models can show improvement in prediction accuracy over the models that assume independence .Incorporating position dependencies can also improve the accuracy of de novo motif discovery [ 25 ] .In this paper , we present a new and flexible motif model , the OMiMa , to incorporate position dependencies within a motif .", "label": "", "metadata": {}, "score": "69.54411"}
{"text": "However , the DNJ method did not perform well in optimizing the 2 nd order circular Markov chains [ see Additional file 1 Figure 1b ] .We used AP1 ( activating protein 1 ) transcription factor binding sites ( Transfac ID V$AP1_Q4_01 ) as an example of how DNJ optimization can improve performance of a 0 - 1 or 0 - 2 mixture model .", "label": "", "metadata": {}, "score": "69.56619"}
{"text": "1471 - 2105 - 7 - 279-S1.pdf Additional file 1 : The supplement includes the mathematical formulas for computing the probability of a motif site given a Markov model , the algorithmic pseudo - code for the DNJ method , and the description of the parameter estimation for our model .", "label": "", "metadata": {}, "score": "69.60219"}
{"text": "Bioinformatics 1999 , 15 ( 5 ) : 362 - 369 .View Article PubMed .Crooks GE , Hon G , Chandonia JM , Brenner SE : WebLogo : A Sequence Logo Generator .Genome Res 2004 , 14 ( 6 ) : 1188 - 1190 .", "label": "", "metadata": {}, "score": "69.60287"}
{"text": "The graphic representation of a mixture of Markov models .A graphic representation of a mixture of Markov models .On the top is a motif of length 14 bases .On the left , 6 positions , which are independent of each other and all other positions , form a 0 th order Markov chain .", "label": "", "metadata": {}, "score": "69.82973"}
{"text": "Simulations with artificial and natural data demonstrate the feasibility and good performance of the proposed approach .We also discuss the relationships of the method to other existing methods . by Yee Whye Teh , Max Welling , Simon Osindero , Geoffrey E. Hinton , Te - won Lee , Jean - fran\u00e7ois Cardoso , Erkki Oja , Shun - ichi Amari - Journal of Machine Learning Research , 2003 . \" ...", "label": "", "metadata": {}, "score": "69.90524"}
{"text": "Simulations with artificial and natural data demonstrate the feasibility and good performance of the proposed approach .We also discuss the relationships of the method to other existing methods . by Yee Whye Teh , Max Welling , Simon Osindero , Geoffrey E. Hinton , Te - won Lee , Jean - fran\u00e7ois Cardoso , Erkki Oja , Shun - ichi Amari - Journal of Machine Learning Research , 2003 . \" ...", "label": "", "metadata": {}, "score": "69.90524"}
{"text": "Rissanen J : Complexity of strings in the class of Markov sources .IEEE Trans Inform Theory 1986 , 32 ( 4 ) : 526 - 532 .View Article .B\u00fchlmann P , Wyner AJ : Variable length Markov chains .", "label": "", "metadata": {}, "score": "69.91481"}
{"text": "[ 24 ] described the PVLMM in an attempt to combine advantages of both VLMM and POMM .The disadvantage of PVLMM is that the number of possible permutations is the factorial of motif length , which makes it more computationally expensive .", "label": "", "metadata": {}, "score": "70.2762"}
{"text": "View Article PubMed .Wray GA , Hahn MW , Abouheif E , Balhoff JP , Pizer M , Rockman MV , Romano LA : The Evolution of Transcriptional Regulation in Eukaryotes .Mol Biol Evol 2003 , 20 ( 9 ) : 1377 - 1419 .", "label": "", "metadata": {}, "score": "71.20715"}
{"text": "Our DNJ method can deal with such long motifs because of its computational efficiency .TFBS identification .One interesting application of our mixture model is TFBS identification .In this assessment , we used a couple of examples to show how OMiMa can improve prediction accuracy when there are position dependencies within a TFBS .", "label": "", "metadata": {}, "score": "71.25893"}
{"text": "The optimized mixture of Markov models is implemented in our computational tool OMiMa , which can use a variety of mixture models for motif prediction .OMiMa , in which most parameters are configurable , is freely available to all users .", "label": "", "metadata": {}, "score": "71.285706"}
{"text": "We implemented these methods in our motif finding OMiMa system , which is freely available .Finally , we demonstrated from different aspects in several examples that OMiMa can improve motif prediction accuracy in biological sequences .The interaction of biological macromolecules , such as transcription factors bound to DNA sites , usually involves several highly dependent positions functioning as a unit .", "label": "", "metadata": {}, "score": "71.44481"}
{"text": "Table 6 : .Comparison of OMiMa PVLMM and MEM for donor site prediction .Comparing OMiMa with PVLMM and MEM for donor splice site prediction .The table shows Matthews correlation efficients ( Mc ) of top 4 models from each model class .", "label": "", "metadata": {}, "score": "71.57025"}
{"text": "In other words , we learn the dependencies from data .All rights reserved .the structure learning approach in Bayesian networks .Our approach has the advantage to guaranty that the resulting model represents speech with higher fidelity than HMMs .", "label": "", "metadata": {}, "score": "71.575195"}
{"text": "In other words , we learn the dependencies from data .All rights reserved .the structure learning approach in Bayesian networks .Our approach has the advantage to guaranty that the resulting model represents speech with higher fidelity than HMMs .", "label": "", "metadata": {}, "score": "71.575195"}
{"text": "We demonstrate that this approach can be applied to a large class of models in several domains , including mixture models and source separation .1 Introduction A standard method to learn a graphical model 1 from data is maximum likelihood ( ML ) .", "label": "", "metadata": {}, "score": "71.62312"}
{"text": "View Article PubMed .Quandt K , Freeh K , Karas H , Wingender E , Werner T : Matlnd and Matlnspector : new fast and versatile tools for detection of consensus matches in nucleotide sequence data .Nucl Acids Res 1995 , 23 ( 23 ) : 4878 - 4884 .", "label": "", "metadata": {}, "score": "71.81831"}
{"text": "Brief Bioinform 2000 , 1 ( 4 ) : 343 - 356 .View Article PubMed .Carmel I , Tal S , Vig I , Ast G : Comparative analysis detects dependencies among the 5 ' splice - site positions .", "label": "", "metadata": {}, "score": "72.64309"}
{"text": "An example of OMiMa is illustrated in Figure 1 .However , for short motifs such as transcription factor binding sites , we can use a simple mixture of Markov models consisting of only one 0 th order and one k th order chain ( Figure 2 ) .", "label": "", "metadata": {}, "score": "73.5954"}
{"text": "Our OMiMa system , to our knowledge , is the only motif finding tool that incorporates automatic selection of the best model .OMiMa is freely available at [ 1 ] .Conclusion .Our optimized mixture of Markov models represents an alternative to the existing methods for modeling dependent structures within a biological motif .", "label": "", "metadata": {}, "score": "73.601105"}
{"text": "PubMed .Krivan W , Wasserman WW : A Predictive Model for Regulatory Sequences Directing Liver - Specific Transcription .Genome Res 2001 , GR1806R. Schneider TD , Stormo GD , Gold L , Ehrenfeucht A : Information content of binding sites on nucleotide sequences .", "label": "", "metadata": {}, "score": "73.64979"}
{"text": "J Comput Biol 2004 , 11 ( 2 - 3 ) : 377 - 394 .View Article PubMed .Zhao X , Huang H , Speed TP : Finding short DNA motifs using permuted markov models .RECOMB ' 04 : Proceedings of the eighth annual international conference on Computational molecular biology New York , NY , USA : ACM Press 2004 , 68 - 75 .", "label": "", "metadata": {}, "score": "73.710045"}
{"text": "The larger the genome evaluated , the more false positives are likely to be declared .Although OMiMa 's prediction accuracy will help , other approaches to reducing false positives will be needed .Cross - species comparisons and relative location compared to transcription start sites have been used to reduce false positives and could be used with OMiMa too .", "label": "", "metadata": {}, "score": "73.82475"}
{"text": "Results also showed the first order PVLMM did not perform better than 1stMM and PWM .We found that the first order PVLMM arranged the position pair 5 - 6 , which showed the strong dependency , differently from OMiMa and 1stMM .", "label": "", "metadata": {}, "score": "74.061516"}
{"text": "Kellis M , Patterson N , Endrizzi M , Birren B , Lander ES : Sequencing and comparison of yeast species to identify genes and regulatory elements .Nature 2003 , 423 ( 6937 ) : 241 - 254 .View Article PubMed .", "label": "", "metadata": {}, "score": "74.215"}
{"text": "Nucl Acids Res 2001 , 29 ( 12 ) : 2471 - 2478 .View Article PubMed .Benos PV , Lapedes AS , Fields DS , Stormo GD : SAMIE : statistical algorithm for modeling interaction energies .Pac Symp Biocomput 2001 , 115 - 26 .", "label": "", "metadata": {}, "score": "74.386826"}
{"text": "Figure 5 shows the result of parsing with our combined model , using ... . \" ...This paper introduces new learning algorithms for natural language processing based on the perceptron algorithm .We show how the algorithms can be efficiently applied to exponential sized representations of parse trees , such as the \" all subtrees \" ( DOP ) representation described by ( Bod 9 ... \" .", "label": "", "metadata": {}, "score": "74.80594"}
{"text": "View Article PubMed .Salzberg S , Delcher A , Kasif S , White O : Microbial gene identification using interpolated Markov models .Nucl Acids Res 1998 , 26 ( 2 ) : 544 - 548 .View Article PubMed .", "label": "", "metadata": {}, "score": "74.96689"}
{"text": "Genome Res 2005 , 15 ( 5 ) : 692 - 700 .View Article PubMed .Xie X , Lu J , Kulbokas EJ , Golub TR , Mootha V , Lindblad - Toh K , Lander ES , Kellis M : Systematic discovery of regulatory motifs in human promoters and 3 ' UTRs by comparison of several mammals .", "label": "", "metadata": {}, "score": "75.12683"}
{"text": "Nucl Acids Res 2002 , 30 ( 5 ) : 1255 - 1261 .View Article PubMed .Roulet E , Busso S , Camargo AA , Simpson AJG , Mermod N , Bucher P : High - throughput SELEX SAGE method for quantitative modeling of transcription - factor binding sites .", "label": "", "metadata": {}, "score": "75.22215"}
{"text": "4.5 Error Analysis In the ... Languages Main page Arabic Chinese French Russian Spanish IPCC web pages IPCC Home Working Group I Working Group II Working Group III TFI / NGGIP Distribution Centre .9.6.4 Summary of Observational Constraints for Climate Sensitivity .", "label": "", "metadata": {}, "score": "75.43407"}
{"text": "We introduce a novel and flexible model , the O ptimized Mi xture Ma rkov model ( OMiMa ) , and related methods to allow adjustment of model complexity for different motifs .In comparison with other leading methods , OMiMa can incorporate more than the NNSplice 's pairwise dependencies ; OMiMa avoids model over - fitting better than the Permuted Variable Length Markov Model ( PVLMM ) ; and OMiMa requires smaller training samples than the Maximum Entropy Model ( MEM ) .", "label": "", "metadata": {}, "score": "75.49335"}
{"text": "Nucleic Acids Res 2000 , 28 : 316 - 319 .View Article PubMed .Matthews B : Comparison of the predicted and observed secondary structure of T4 phage lysozyme .Biochim Biophys Acta 1975 , 405 ( 2 ) : 442 - 451 .", "label": "", "metadata": {}, "score": "75.78873"}
{"text": "This is one possible reason why PVLMM performed slightly worse .The sequence logos of AP1 TFBS and the donor site .Sequence logos of the AP1 TFBS and the donor splice site .The height of bases represents the information content at each position of a sequence motif .", "label": "", "metadata": {}, "score": "75.95392"}
{"text": "Performance benefits have been demonstrated from incorporating a linear trajectory description and additionally from modelling variability in the mid - point parameter . \" ...This paper addresses the time - series modelling of high dimensional data .Currently , the hidden Markov model ( HMM ) is the most popular and successful model especially in speech recognition .", "label": "", "metadata": {}, "score": "76.181625"}
{"text": "Constraints on the upper end of the likely range of climate sensitivities are also important , particularly for probabilistic forecasts of future climate with constant radiative forcing .The upper 95 % limit for ECS ranges from 5 \u00b0 C to 10 \u00b0 C , or greater in different studies depending upon the approach taken , the number of uncertainties included and specific details of the prior distribution that was used .", "label": "", "metadata": {}, "score": "76.357994"}
{"text": "However , difficulties in segmentbased recognition have impeded the realization of potential advantages in modeling .This thesis . \" ...Currently the most popular acoustic model for speech recognition is the hidden Markov model ( HMM ) .However , HMMs are based on a series of assumptions some of which are known to be poor .", "label": "", "metadata": {}, "score": "76.576324"}
{"text": "TFBS V$AP1_Q4_01 prediction .Comparison of OMiMa ( 1-L-0/1-C-0 ) , PWM , 1stMM , and PVLMM ( order 1 and depth 1 ) for AP1 TFBS prediction .The performance results are the average values of 10-fold cross validation .", "label": "", "metadata": {}, "score": "76.82516"}
{"text": "X 3 X 4 X 5 Figure 7 .Multi - level ICA Further generalizations of PCA / FA / ICA can be obtained simply by using different implementations of the basic graph given in Figure 6 .Moreover , a multi - level factor analysis algorithm , shown in Figure 7 , can easily be described where the middle hidden layer is ... . by Harri Lappalainen , Xavier Giannakopoulos , Antti Honkela , Juha Karhunen , 2000 . \" ...", "label": "", "metadata": {}, "score": "77.01442"}
{"text": "X 3 X 4 X 5 Figure 7 .Multi - level ICA Further generalizations of PCA / FA / ICA can be obtained simply by using different implementations of the basic graph given in Figure 6 .Moreover , a multi - level factor analysis algorithm , shown in Figure 7 , can easily be described where the middle hidden layer is ... . by Harri Lappalainen , Xavier Giannakopoulos , Antti Honkela , Juha Karhunen , 2000 . \" ...", "label": "", "metadata": {}, "score": "77.01442"}
{"text": "IEEE Trans Automat Control 1974 , 19 ( 6 ) : 716 - 723 .View Article .Schwarz G : Estimating the dimension of a model .Ann Stat 1978 , 6 ( 2 ) : 461 - 464 .View Article .", "label": "", "metadata": {}, "score": "77.06679"}
{"text": "The dataset , extracted from 1821 non - redundant human transcripts , has 8,415 real and 179,438 decoy sites in the training set , and 4,208 real and 89,717 in decoy sites in the testing set .Each real site has length 9 bases from -3 to +6 around the conserved ' GT ' of donor splice sites recognized by U-2 type spliceosome .", "label": "", "metadata": {}, "score": "77.31383"}
{"text": "The y - axis is 1- p_value measuring performance of the DNJ optimized models relative to the randomly permuted models .The values on x - axis are the ID numbers of 53 TFBS in the first column of Table 1 .", "label": "", "metadata": {}, "score": "78.2888"}
{"text": "Mixed Markov models .Let X i be the discrete random variable associated with position i in a biological motif X of length w .X i follows a multinomial distribution .If one uses the k th order Markov model ( M k ) , the probability of observing a motif sequence x is just the product of conditional / transition probabilities .", "label": "", "metadata": {}, "score": "78.333565"}
{"text": "Acknowledgements .We thank Drs Bruce Weir and Jeffrey Thorne for critically reading the manuscript , and Drs Clarice Weinberg and Joseph Nevins for helpful comments .This research was supported by Intramural Research Programs of the NIH , National Institute of Environmental Health Sciences .", "label": "", "metadata": {}, "score": "78.53146"}
{"text": "We found that OMiMa had comparable prediction accuracy to NNSplice and PVLMM ( Table 5 ) .In addition , OMiMa is much more computationally efficient than NNSplice and PVLMM [ see Additional file 1 ] .Table 5 .Comparison OMiMa with NNSplice and PVLMM for donor site prediction .", "label": "", "metadata": {}, "score": "82.52316"}
{"text": "Note that the positions 4 and 6 of AP1 TFBS are not perfectly conserved .( b ) the logo of donor splice site .The positions 0 and 1 are perfectly conserved .The logo plot was created by WebLogo [ 45 ] .", "label": "", "metadata": {}, "score": "83.45868"}
{"text": "View Article .Reese MG , Eeckman FH , Kulp D , Haussler D : Improved splice site detection in Genie .J Comput Biol 1997 , 4 ( 3 ) : 311 - 323 .View Article PubMed .Ketterling RP , Drost JB , Scaringe WA , Liao DZ , Liu JZ , Kasper CK , Sommer SS : Reported in vivo splice - site mutations in the factor IX gene : severity of splicing defects and a hypothesis for predicting deleterious splice donor mutations .", "label": "", "metadata": {}, "score": "83.749664"}
{"text": "Electronic supplementary material .The online version of this article ( doi : 10 .1186/\u200b1471 - 2105 - 7 - 279 ) contains supplementary material , which is available to authorized users .Background .Biological sequences , including DNA , RNA and proteins , contain functionally important motifs , such as transcription factor binding sites ( TFBS ) , RNA splice sites , and protein domains .", "label": "", "metadata": {}, "score": "84.29376"}
{"text": "AP1 TFBS prediction .We chose human AP1 TFBS ( see Figure 7a ) for this evaluation because of its relatively large number of known sites .In total , we had 119 true sites and 5950 false sites .The true sites were extracted from Transfac database ( Transfac ID V$AP1_Q4_01 ) , and false sites were randomly sampled from the non - coding regions of the human genome .", "label": "", "metadata": {}, "score": "85.00686"}
{"text": "View Article PubMed .Cai D , Delcher A , Kao B , Kasif S : Modeling splice sites with Bayes networks .Bioinformatics 2000 , 16 ( 2 ) : 152 - 158 .View Article PubMed .Ellrott K , Yang C , Sladek FM , Jiang T : Identifying transcription factor binding sites through Markov chain optimization .", "label": "", "metadata": {}, "score": "85.18569"}
{"text": "View Article PubMed .Staley JP , Guthrie C : An RNA switch at the 5 ' splice site requires ATP and the DEAD box protein Prp28p .Mol Cell 1999 , 3 : 55 - 64 .View Article PubMed .", "label": "", "metadata": {}, "score": "88.443985"}
{"text": "We demonstrate that the results obtained by applying the learned bases to these problems are improved over those obtained with traditional techniques .\u00a9 1999 Optical Society of America [ S0740 - 3232(99)03107 - 5 ] OCIS codes : 000.5490 , 100.2960 , 100.3010 . \" ...", "label": "", "metadata": {}, "score": "89.500244"}
{"text": "Copyright .\u00a9 Huang et al .2006 .This article is published under license to BioMed Central Ltd.To address this difficulty , we turn to covariance function models that take a form consistent in some sense with physical laws that govern the underlying simulated pro- cess .", "label": "", "metadata": {}, "score": "89.83882"}
{"text": "View Article PubMed .Nelson K , Green M : Mechanism for Cryptic Splice Site Activation During Pre - mRNA Splicing .PNAS 1990 , 87 ( 16 ) : 6253 - 6257 .View Article PubMed .Nandabalan K , Price L , Roeder GS : Mutations in U1 snRNA bypass the requirement for a cell type - specific RNA splicing factor .", "label": "", "metadata": {}, "score": "91.54925"}
{"text": "In the NTCIR6 CLQA2 evaluation , our system achieved 19 % and 13 % accuracy in the Engl ... \" .In this paper , we describe the JAVELIN Cross Language Question Answering system , which includes modules for question analysis , keyword translation , document retrieval , information extraction and answer generation .", "label": "", "metadata": {}, "score": "93.11916"}
{"text": "The transcription of most higher eukaryotic genes involves RNA splicing , in which primary transcripts become mature mRNA by removing introns .The donor or 5 ' splice sites and the acceptor or 3 ' splice sites on the boundaries of exons and introns provides critical signals for precise splicing .", "label": "", "metadata": {}, "score": "105.25969"}
{"text": "The splicing process starts with U1 snRNP binding to the donor site via base - pairing of U1 snRNA .The base pairing between U1 snRNA and the donor site , however , need not be perfectly complementary in all positions [ 34 , 35 ] .", "label": "", "metadata": {}, "score": "117.0703"}
