{"text": "For example , we argue that multi - time resolution processing - in the context of which segmentation occurs concurrently on segmental and syllabic time scales - relates closely to the ' landmarks ' approach advocated by Stevens ( 2002 ) .", "label": "", "metadata": {}, "score": "39.190063"}
{"text": "In the speech recognition system described here , the input speech is pre - processed using an algorithm for speech enhancement .A number of different methods for the enhancement of speech , combined with the auditory front - end of Li et al .", "label": "", "metadata": {}, "score": "45.080826"}
{"text": "The constraints are based on the significant properties known to be employed by the human auditory system .A preliminary version of a speech recognizer incorporating the above ideas will be presented where bundles of overlapping articulatory features are used as the basis for describing the phonological structure of speech .", "label": "", "metadata": {}, "score": "45.116142"}
{"text": "A speech recognizer is run on each utterance to generate a word lattice .The lattice is pruned relative to the correct path .The forward - backward algorithm is used to align each path in the lattice against the speech input and compute observation counts .", "label": "", "metadata": {}, "score": "46.04126"}
{"text": "A speech recognizer is run on each utterance to generate a word lattice .The lattice is pruned relative to the correct path .The forward - backward algorithm is used to align each path in the lattice against the speech input and compute observation counts .", "label": "", "metadata": {}, "score": "46.04126"}
{"text": "Intermediate attributes of speech can be linguistically motivated or derived automatically from the data .Both of these types of attributes are explored in this work with more emphasis on automatically - derived attributes .All of the proposed elements of this system are aimed at the goal of improving the robustness of a speech recognizer to unseen noise conditions , i.e. , environmental conditions for which the recognizer was not trained .", "label": "", "metadata": {}, "score": "46.83007"}
{"text": "Whereas there are studies exploiting signal - processing techniques to highlight the contributions of higher- or lower - modulation frequencies ( Drullman et al .1994 a , b ) , the interaction between temporal information on different scales has been taken for granted ( i.e. it is an implicit presupposition that segmental and syllabic information are ' congruent ' in some sense , permitting successful comprehension ) .", "label": "", "metadata": {}, "score": "46.83564"}
{"text": "A second source of evidence from the speech domain comes from studies on audiovisual ( AV ) integration .Several studies have replicated the following surprising finding ( Massaro et al .1996 ; Munhall et al .1996 ; Grant et al .", "label": "", "metadata": {}, "score": "47.68622"}
{"text": "( 2005 ) interpret these findings in the following way : the visual speech input , which typically precedes the auditory signal , elicits a ( broad class of ) internal abstract representations ( the hypothesis space ) .These internal representations predict the possible audio targets .", "label": "", "metadata": {}, "score": "47.79545"}
{"text": "We find the convergence to a multiresolution analysis on two time scales of approximately the same size particularly intriguing and very much worth pursuing as one of the fundamental principles for speech recognition .For a related multi - tier framework on speech that also engages the multiple time scale , spectral integration and representational challenges to recognition , see Greenberg ( 2005 ) .", "label": "", "metadata": {}, "score": "47.82303"}
{"text": "After Agarwal and Cheng [ 25 ] , the next best performance across the board is obtained using Ephraim and Malah [ 20 ] , and Westerlund et al .[ 22 ] .This suggests that the choice of speech enhancement algorithm for best speech recognition performance is somewhat independent of the choice of front - end ( though this would have to be validated by further testing with other front ends ) .", "label": "", "metadata": {}, "score": "47.949127"}
{"text": "2000 ; Norris & Wise 2000 ; Poeppel et al .The fact that imaging studies show bilateral activation does , of course , not imply that the computations executed in left and right core auditory cortices are identical - there are , presumably , important differences in local computation .", "label": "", "metadata": {}, "score": "48.122772"}
{"text": "Comput .Sci . , MIT , Cambridge , MA 02139 .The conventional design of speech recognizers tends to treat the ' ' front end ' ' ( signal representation of speech ) and the ' ' back end ' ' ( lexical representation plus signal modeling and pattern matching ) as separate modules .", "label": "", "metadata": {}, "score": "48.144714"}
{"text": "That is , the integration is in abstract , amodal articulation space .Lexical representation and Distinctive Features .We adopt the idea ( probably first expressed in Bell ( 1867 ) ; cited in Halle 2002 , pp .3 - 4 , see also pp .", "label": "", "metadata": {}, "score": "48.25168"}
{"text": "( I ) and Li et al .( II ) , is to allow for a closer comparison with the ETSI basic front - end [ 6 ] and the ETSI advanced front - end [ 7 ] respectively .In all cases training was carried out using clean data , so that the effect of the speech enhancement in removing mismatch could be examined .", "label": "", "metadata": {}, "score": "48.507183"}
{"text": "Figure 1 .MFCC feature extraction .Auditory modelling as an alternative front - end .Many computational auditory models have been proposed for use in speech recognition systems , often with excellent results , particularly in the presence of noise .", "label": "", "metadata": {}, "score": "48.69032"}
{"text": "The feature vectors produced by the auditory model are transmitted over a channel that is subject to packet burst loss and packet loss mitigation to compensate for missing features is investigated .Conclusions are presented in Section 5 .Distributed speech recognition systems .", "label": "", "metadata": {}, "score": "48.861412"}
{"text": "The recognition error rate is signifi - cantly reduced with incorporation of additional dynamic fea - tures , semi - continuous hidden Markov models , and speaker clustering .For the June 1990 ( RM2 ) evaluation test set , the error rates of our current system are 4.3 % and 19.9 % for word - pair grammar and no grammar respectively . .", "label": "", "metadata": {}, "score": "49.06301"}
{"text": "The recognition error rate is signifi - cantly reduced with incorporation of additional dynamic fea - tures , semi - continuous hidden Markov models , and speaker clustering .For the June 1990 ( RM2 ) evaluation test set , the error rates of our current system are 4.3 % and 19.9 % for word - pair grammar and no grammar respectively . .", "label": "", "metadata": {}, "score": "49.06301"}
{"text": "2004 ; van Wassenhove et al .Does the information carried on these two time scales interact in perceptually relevant ways ?If an auditory signal is indeed analysed concurrently on two time scales , is there a binding of information that modulates speech perception ?", "label": "", "metadata": {}, "score": "49.11417"}
{"text": "One alternative is to make use of automatic speech recognition ( ASR ) systems that act on speech input from the user .An ASR system has two main elements .The first element is a front - end processor that extracts parameters , or features , that represent the speech signal .", "label": "", "metadata": {}, "score": "49.213646"}
{"text": "If distinct auditory cortical fields are found to be differentially sensitive to temporal information , such data would support the model that different time scales are processed in parallel .In a recent fMRI study , Boemio et al .( 2005 ) tested this hypothesis using non - speech signals that were constructed to closely match certain properties of speech signals .", "label": "", "metadata": {}, "score": "49.367065"}
{"text": "( 2005 ) ; Schonwiesner et al .( 2005 ) and others .If this type of multi - time resolution model is on the right track , evidence is owed for the model 's constituent claims .Evidence for temporal integration on the short time scale is relatively abundant and will not be discussed further here ( see Poeppel 2003 ; Wang et al .", "label": "", "metadata": {}, "score": "49.54341"}
{"text": "Following Jakobson et al .( 1952 ; see also Halle 2002 , pp .108 - 110 ) , the features have dual definitions and provide the fundamental connection between action ( articulation ) and perception ( audition ) .Each feature is defined by its effective motoric gesture(s ) , and also by the auditory patterns that trigger its detection .", "label": "", "metadata": {}, "score": "49.882683"}
{"text": "This concept is very similar to Stevens ' notion of looking for informative landmarks and then verifying and testing the information around these landmarks to specify the speech information at that time point in the waveform .Secondly , once one has such featural hypotheses , one can generate internal guesses that can then guide further perceptual processing .", "label": "", "metadata": {}, "score": "49.921062"}
{"text": "( 2005 ) conducted a combined psychophysical and ERP study to investigate this issue .In a three - alternative forced choice test , subjects had to categorize what they perceived ; concurrently , ERPs were recorded .Based on the multisensory literature , which derives primarily from single - unit studies ( Stein & Meredith 1993 ) or haemodynamic imaging studies ( Calvert 2001 ) , the most straightforward prediction was to observe supra - additivity on one of the major auditory evoked responses .", "label": "", "metadata": {}, "score": "50.424118"}
{"text": "M. Kleinschmidt and D. Gelbart , \" Spectro - Temporal Gabor Features as a Front End for Automatic Speech Recognition , \" Int .Conf .Spoken Language Processing , Denver , CO , September 2002 .Prosody - based Automatic Detection of Annoyance and Frustration in Human - Computer Dialog .", "label": "", "metadata": {}, "score": "50.581047"}
{"text": "Because today 's state - of - the - art recognizers are not designed to be situated naturally in an error feedback loop , they are ill - positioned for inclusion in multi - modal interfaces , multi - media databases , and other interesting applications .", "label": "", "metadata": {}, "score": "50.61256"}
{"text": "Speech recognition system .The classifier used for the recognition experiments in the work presented in this chapter is the HMM - based recogniser architecture specified for use with the Aurora 2 database [ 16 ] , and implemented with the widely - used HTK package [ 19 ] .", "label": "", "metadata": {}, "score": "50.7237"}
{"text": "The method used to measure the performance of a speech recognition system is dependent on the type of utterance that is to be recognised , i.e. isolated word or continuous speech .There are three error types associated with the recogniser in a continuous speech recognition system : .", "label": "", "metadata": {}, "score": "50.818535"}
{"text": "The more informative the facial information is , the more specific the prediction can be , and the more temporal savings is observed .Cumulatively , these data are most consistent with an analysis - by - synthesis model , an internal forward model in which perceptual analysis is guided by the predictions made based on the internally synthesized candidates that are compared against input signals .", "label": "", "metadata": {}, "score": "51.190666"}
{"text": "Major contextual variations in speech are modeled as a natural result of overlapping the ' ' intrinsic ' ' values of one or more of these features across adjacent phonemic units .Knowledge from speech production and speech perception are utilized to limit the allowable feature overlaps .", "label": "", "metadata": {}, "score": "51.65647"}
{"text": "Multi - band processing takes its inspiration from the way humans exploit redundant cues found in multiple frequency regions to maintain robust recognition .Classification of intermediate speech attributes is motivated by studies that show how people can discern certain speech attributes , like voicing and nasality , despite confounding noise .", "label": "", "metadata": {}, "score": "51.67736"}
{"text": "[ 22 ] , for which the overall recognition results are quite close .For Li et al .( I ) , Li et al .( II ) , the ETSI basic front - end and the ETSI advanced front - end , the best overall recognition accuracy is obtained for speech enhancement using the algorithm proposed by Agarwal and Cheng [ 25 ] .", "label": "", "metadata": {}, "score": "51.684692"}
{"text": "Using this chip , we designed a multi - chip system that serves as a front - end for an auditory scene analysis system , computing multiple auditory representations from an analog signal input .We performed a study on using this multi - chip system as a front - end for speaker - independent , isolated - word speech recognition , which was published in our 1997 article in Analog Integrated Circuits and Signal Processing .", "label": "", "metadata": {}, "score": "51.794777"}
{"text": "Using this chip , we designed a multi - chip system that serves as a front - end for an auditory scene analysis system , computing multiple auditory representations from an analog signal input .We performed a study on using this multi - chip system as a front - end for speaker - independent , isolated - word speech recognition , which was published in our 1997 article in Analog Integrated Circuits and Signal Processing .", "label": "", "metadata": {}, "score": "51.794777"}
{"text": "Applications to rescoring of lattices from a large vocabulary continuous speech recognizer are also presented .SPEECH RECOGNITION BASED ON .The segments and landmarks ( defined by boundary locations ) are then analyzed for phonemes using Gaussian Mixture Models ( GMMs ) or multi - layer perceptrons .", "label": "", "metadata": {}, "score": "51.981068"}
{"text": "Therefore , one goal has to be to begin to specify what the computational contribution of each cortical field might be .Imaging studies show very convincingly that the processing of speech at the initial stages is robustly bilateral , at least at the level of core and surrounding STG ( Mummery et al .", "label": "", "metadata": {}, "score": "52.19987"}
{"text": "For isolated word recognition with known and limited vocabulary , the landmark sequences are constrained using a manner class pronunciation graph .Probabilistic decisions on place and voicing phonetic features are then made using a separate set of APs extracted using the landmarks .", "label": "", "metadata": {}, "score": "52.242516"}
{"text": "We are attempting to improve the robustness of automatic speech recognition systems by using a set of two - dimensional Gabor filters with varying extents in time and frequency and varying ripple rates to analyze a spectrogram [ 1].These filters have some characteristics in common with the responses of neurons in the auditory cortex of primates , and can also be seen as two - dimensional frequency analyzers .", "label": "", "metadata": {}, "score": "52.275444"}
{"text": "In a fully embedded ASR system [ 1 ] , the feature extraction and the speech classification are carried out on the mobile device .However , due to the computational complexity of high - performance speech recognition systems , such an embedded architecture can be impractical on mobile hand - held terminals due to limitations in processing and memory resources .", "label": "", "metadata": {}, "score": "52.27809"}
{"text": "The initial cortical analysis of speech occurs bilaterally in core and surrounding superior auditory areas ( see Hackett et al .( 2001 ) for relevant human auditory cortex anatomy ) .( 2004 ) for arguments and imaging evidence that speech is bilaterally mediated ) .", "label": "", "metadata": {}, "score": "52.350754"}
{"text": "It is this ' forward ' synthesis of candidate representations that is the central property of the approach and makes it a completely active process .Hypothesize - and - test models for perception were discussed in the 1950s and 1960s , for example , by Miller et al .", "label": "", "metadata": {}, "score": "52.405968"}
{"text": "Multiresolution processing is widely observed in other systems ( e.g. vision ) and can , we suggest , be used profitably in engineering approaches to speech recognition .Second , at the algorithmic level of description , the central algorithm we invoke is analysis - by - synthesis .", "label": "", "metadata": {}, "score": "52.538208"}
{"text": "( PDF ) .Y. Zhang and J. Glass , \" Unsupervised Spoken Keyword Spotting via Segmental DTW on Gaussian Posteriorgrams , \" Proc .ASRU , 398 - 403 , Merano , Dec. 2009 .( PDF ) .K. Saenko , K. Livescu , J. Glass , and T. Darrell , \" Multistream Articulatory Feature - Based Models for Visual Speech Recognition , \" IEEE Trans .", "label": "", "metadata": {}, "score": "52.53849"}
{"text": "In summary , the experiments and results outlined in this chapter show the benefit of combining speech enhancement and packet loss mitigation to combat both noise and packet loss .Furthermore , the performance of the auditory model of Li et al . was generally shown to be superior to that of the standard ETSI advanced front - end .", "label": "", "metadata": {}, "score": "52.543877"}
{"text": "Both more anterior parts of the STS ( Scott et al .2000 ) and more posterior parts of the STG / STS ( Binder et al .2000 ) as well as MTG ( Indefrey & Levelt 2004 ) have been implicated in speech - sound processing .", "label": "", "metadata": {}, "score": "52.673023"}
{"text": "Given the explicit feature specification for each node in the overall speech space , a general set of acoustic / auditory measurements can be assigned specifically into the individual nodes based on the understanding of the acoustic / auditory correlates to the features .", "label": "", "metadata": {}, "score": "52.782352"}
{"text": "2005 ; Meyer et al .2005 ; Schonwiesner et al .Analysis - by - synthesis - internal forward models .Models of speech perception and lexical access tend to come in two types .Either the processing is rather strictly bottom - up ( e.g. Norris et al .", "label": "", "metadata": {}, "score": "53.082283"}
{"text": "The current DARPA databases suffer from the described difficulties which suggests that new CSR databases are needed if we are to further advance the state - of - the - art . ... tabase .Implications for Vocabulary Independence The above suggests that any training methods that average over a number of contexts and/or use discriminative techniques include the true source language mod ... . \" ... hidden Markov model ( HMM ) based continuous speech recognition system typically used in a speaker - indepen - dent manner .", "label": "", "metadata": {}, "score": "53.27156"}
{"text": "The current DARPA databases suffer from the described difficulties which suggests that new CSR databases are needed if we are to further advance the state - of - the - art . ... tabase .Implications for Vocabulary Independence The above suggests that any training methods that average over a number of contexts and/or use discriminative techniques include the true source language mod ... . \" ... hidden Markov model ( HMM ) based continuous speech recognition system typically used in a speaker - indepen - dent manner .", "label": "", "metadata": {}, "score": "53.27156"}
{"text": "The speech recognizer 's functionality is extended to include con dence annotations , which are \\meta - level \" markings that indicate how certain the recognizer is that it has decoded its input correctly .This is accomplished by feeding externally de ned error conditions back to the recognizer .", "label": "", "metadata": {}, "score": "53.561237"}
{"text": "The speech recognizer 's functionality is extended to include con dence annotations , which are \\meta - level \" markings that indicate how certain the recognizer is that it has decoded its input correctly .This is accomplished by feeding externally de ned error conditions back to the recognizer .", "label": "", "metadata": {}, "score": "53.561237"}
{"text": "In the non - speech case , three clear examples of processing on this time scale are provided by the psychophysical order threshold ( Hirsh & Sherrick 1961 ) , by frequency modulation ( FM ) direction discrimination ( Gordon & Poeppel 2002 ; Luo et al .", "label": "", "metadata": {}, "score": "53.70343"}
{"text": "( PDF ) .Y. Zhang , E. Chuangsuwanich , and J. Glass , \" Extracting Deep Neural Network Bottleneck Features using Low - Rank Matrix Factorization , \" Proc .ICASSP , Florence , 2014 .( PDF ) .X. Feng , Y. Zhang , and J. Glass , \" Speech Feature Denoising and Dereverberation via Deep Autoencoders for Noisy Reverberant Speech Recognition , \" Proc .", "label": "", "metadata": {}, "score": "53.705803"}
{"text": "In this paper , we compare a Probabilistic Landmark - Based speech recognition System ( LBS ) which uses Knowledge - based Acoustic Parameters ( APs ) as the front - end with an HMMbased recognition system that uses the Mel - Frequency Cepstral Coefficients as its front end .", "label": "", "metadata": {}, "score": "53.814804"}
{"text": "In this paper , we compare a Probabilistic Landmark - Based speech recognition System ( LBS ) which uses Knowledge - based Acoustic Parameters ( APs ) as the front - end with an HMMbased recognition system that uses the Mel - Frequency Cepstral Coefficients as its front end .", "label": "", "metadata": {}, "score": "53.814804"}
{"text": "One approach that can be used to improve the robustness of ASR systems is to enhance the speech signal itself before feature extraction .Speech enhancement can be particularly useful in cases where a significant mismatch exists between training and testing conditions , such as where a recognition system is trained with clean speech and then used in noisy conditions .", "label": "", "metadata": {}, "score": "53.957397"}
{"text": "Index Terms : landmark , speech recognition , acoustic parameters , phonetic features . ... complete hierarchy ) such that only the relevant APs for the feature at that node serve as input to the classifier .Probabilistic decisions obtained from the outputs of SVMs are combined with class dependent duration probability densities to obtain one or more segmentations of the speech signal into the broad cl ...", "label": "", "metadata": {}, "score": "53.975002"}
{"text": "But listeners also pay attention to the location of individual tokens in the acoustic ' clouds ' defined by the categories ( or types ) .That is , they detect , know and remember something about the speaker 's speech , as compared with the listener 's statistical summary of the acoustic variation in the categories that they have already encountered ( Goldinger et al .", "label": "", "metadata": {}, "score": "54.044647"}
{"text": "In DSR , the terminal ( the mobile device ) includes a local front - end processor that extracts , directly from the speech , the features to be sent to the remote server ( back - end ) where recognition is performed .", "label": "", "metadata": {}, "score": "54.079918"}
{"text": "( II ) undergo post - processing in the cepstral domain by means of cepstral mean subtraction ( CMS ) .The recognition results for Li et al .( II ) , for each speech enhancement algorithm , are detailed in Table 3 and the recognition results for the ETSI advanced front - end are detailed in Table 4 .", "label": "", "metadata": {}, "score": "54.128895"}
{"text": "The implementation of noise reduction in the ETSI advanced front - end is summarised in [ 12 ] .Tests and results .This section presents recognition results from tests on the Aurora 2 database [ 16 ] , using the combination of the speech enhancement algorithms described previously and the auditory model proposed by Li et al .", "label": "", "metadata": {}, "score": "54.24279"}
{"text": "It is , in our view , not a sufficient answer to state that a word has been recognized without specifying rather explicitly what the format of the representation is .More colloquially , if the neural code for lexical representation is written in , say , Brain++ , speech perception must transform the input signal , a continuously varying waveform , into Brain++ objects .", "label": "", "metadata": {}, "score": "54.315247"}
{"text": "ICRA , Anchorage , 2010 .( PDF ) .Y. Zhang and J. Glass , \" Towards Speaker - Independent Unsupervised Speech Pattern Discovery , \" Proc .ICASSP , 4366 - 4369 , Dallas , 2010 .( PDF ) . A. Correa , M. Walter , L. Fletcher , J. Glass , S. Teller , and R. Davis , \" Multimodal Interaction with an Autonomous Forklift , \" Proc .", "label": "", "metadata": {}, "score": "54.632973"}
{"text": "These three problems are , of course , closely related and constitute irritating stumbling blocks for automatic speech recognition research as well as accounts of human speech perception .We are in no position to provide answers to these foundational challenges , and the paper is not focused on segmentation and invariance .", "label": "", "metadata": {}, "score": "54.749535"}
{"text": "This mapping may - as suggested in figure 1 c -or may not involve further intermediate representations .Note that it is controversial as to what extent the processing steps can feedback to previous stages ( cf .Norris et al .", "label": "", "metadata": {}, "score": "54.810944"}
{"text": "We hypothesize that the internal model is updated approximately every 30 ms , i.e. with each new sample that is available .Segmental and syllabic - level analyses of the signal are concurrent ( multi - time resolution ) .Spectro - temporal analysis and the construction of a high - resolution auditory representation that is performed in the afferent pathway and core auditory cortex .", "label": "", "metadata": {}, "score": "54.970695"}
{"text": "A Multi - Band Approach to Robust Speech Recognition Using Graphical Models for Intermediate Classification .Barry Chen ( Professor Nelson H. Morgan ) DARPA : EARS Novel Approaches .This work further explores the multi - band approach to automatic speech recognition ( ASR ) using probabilistic graphical models ( PGM ) to classify a set of intermediate speech attributes .", "label": "", "metadata": {}, "score": "55.2235"}
{"text": "14 ] , are evaluated for the purpose of robust connected digit recognition .The ETSI basic [ 6 ] and advanced [ 7 ] front - ends proposed for distributed speech recognition are used as a baseline for comparison .Speech enhancement overview .", "label": "", "metadata": {}, "score": "55.27942"}
{"text": "This paper reports results on an experiment to use corrective training techniques for rapid acoustic speaker adaptation in a semi - continuous speech recognition system .Decoder output is used to adjust HMM acoustic models to improve discrimination between correct words and near misses .", "label": "", "metadata": {}, "score": "55.35196"}
{"text": "This paper reports results on an experiment to use corrective training techniques for rapid acoustic speaker adaptation in a semi - continuous speech recognition system .Decoder output is used to adjust HMM acoustic models to improve discrimination between correct words and near misses .", "label": "", "metadata": {}, "score": "55.35196"}
{"text": "This paper reports results on an experiment to use corrective training techniques for rapid acoustic speaker adaptation in a semi - continuous speech recognition system .Decoder output is used to adjust HMM acoustic models to improve discrimination between correct words and near misses .", "label": "", "metadata": {}, "score": "55.35196"}
{"text": "This paper reports results on an experiment to use corrective training techniques for rapid acoustic speaker adaptation in a semi - continuous speech recognition system .Decoder output is used to adjust HMM acoustic models to improve discrimination between correct words and near misses .", "label": "", "metadata": {}, "score": "55.35196"}
{"text": "( Note that our own work often focuses on these issues , i.e. we are not just sympathetic to auditory neuroscience and auditory theory , we are also practitioners ; e.g. Hickok & Poeppel 2000 , 2004 ) .These domains of investigation provide critical knowledge about the construction of the representations that constitute speech .", "label": "", "metadata": {}, "score": "55.44011"}
{"text": "Anticipating somewhat the discussion of distinctive features from \u00a7 5 , we see analysis - by - synthesis employed as a general computational architecture common to the whole recognition process .Acoustic measurements yield guesses about distinctive feature values in the string . '", "label": "", "metadata": {}, "score": "55.44669"}
{"text": "2003 ) and is argued to be necessary to maintain parity between input- and output - based speech tasks .Furthermore , aspects of Broca 's area ( Brodmann areas 44 and 45 ) are also regularly implicated in speech processing ( see Burton ( 2001 ) for review ) .", "label": "", "metadata": {}, "score": "55.452446"}
{"text": "( 2000 ) were the first to show that anterior STS plays a crucial role in speech intelligibility .Note that it is not at all clear which aspect of the so - called what pathway in auditory processing is responsible for lexical access .", "label": "", "metadata": {}, "score": "55.476284"}
{"text": "These enhancements include function - phrase modeling , between - word coarticulation modeling , and corrective training .On the DARPA resource management task , SPHINX attained a speaker - independent word accuracy of 96 % wit ... \" .This paper describes recent improvements in the SPHINX Speech Recognition System .", "label": "", "metadata": {}, "score": "55.592796"}
{"text": "These enhancements include function - phrase modeling , between - word coarticulation modeling , and corrective training .On the DARPA resource management task , SPHINX attained a speaker - independent word accuracy of 96 % wit ... \" .This paper describes recent improvements in the SPHINX Speech Recognition System .", "label": "", "metadata": {}, "score": "55.592796"}
{"text": "The layout of the chapter is as follows .Section 2 discusses the DSR architecture and standards in more detail .This is followed by an overview of the auditory model used in this chapter as an alternative front - end to those published in the DSR standards .", "label": "", "metadata": {}, "score": "55.648605"}
{"text": "Typically , these multi - band systems involve processing speech independently on multiple frequency channels , or sub - bands , training classifiers on sub - band features to learn phone probabilities , and using these probabilities to form the best word hypothesis .", "label": "", "metadata": {}, "score": "55.69211"}
{"text": "First , at the implementational level of description , speech perception is a multi - time resolution process , with signal analysis occurring concurrently on ( at least ) two time scales relevant to speech , syllabic - level ( approx .", "label": "", "metadata": {}, "score": "55.70455"}
{"text": "DARPA Speech and Natural language Workshop , 1990 . \" ...This paper reports recent efforts to further improve the perfor - mance of the Sphinx system for speaker - independent contin - uous speech recognition .The recognition error rate is signifi - cantly reduced with incorporation of additional dynamic fea - tures , semi - continuous hidden Markov models , and speake ... \" .", "label": "", "metadata": {}, "score": "55.766422"}
{"text": "DARPA Speech and Natural language Workshop , 1990 . \" ...This paper reports recent efforts to further improve the perfor - mance of the Sphinx system for speaker - independent contin - uous speech recognition .The recognition error rate is signifi - cantly reduced with incorporation of additional dynamic fea - tures , semi - continuous hidden Markov models , and speake ... \" .", "label": "", "metadata": {}, "score": "55.766422"}
{"text": "The afferent auditory pathway analyses the input signal in time and frequency .A neural ' analogue ' of the spectrogram is generated to highlight both spectral and temporal variations in the signal .( cf .STRFs in auditory cortex . )", "label": "", "metadata": {}, "score": "55.809944"}
{"text": "K. Schutte and J. Glass , \" Speech Recognition with Localized Time - Frequency Pattern Detectors , \" Proc .ASRU , 341 - 344 , Kyoto , December 2007 .( PDF ) .G. Choueiter , S. Seneff , and J. Glass , \" New Word Acquisition Using SubWord Modeling , \" , Proc .", "label": "", "metadata": {}, "score": "55.85314"}
{"text": "To d .. \" ...This thesis explores the use of discriminative training to improve acoustic modeling in a segment - based speech recognizer .In contrast with the more commonly used Maximum Likelihood training , discriminative training considers the likelihoods of competing classes when determining the parameters for a ... \" .", "label": "", "metadata": {}, "score": "55.86181"}
{"text": "We investigate some of the major di#erences between native and n .. d recognizer , and then hypothesizing groupings of frames which dene possible segments .In th ... . \" ...Segment model ( SM ) is a family of methods by using segmental distribution rather than frame - based features ( e.g. HMM ) to represent the underlying characteristics of observation sequence .", "label": "", "metadata": {}, "score": "55.89325"}
{"text": "The third component , the decoder , consists of a highly pruned ( and therefore irregular ) search through all possible utterances .Thus , the primary focus of our current effort is on this portion of the speech system .Our initial implementation consists of a small vocabulary system .", "label": "", "metadata": {}, "score": "55.97139"}
{"text": "J. Chang and J. Glass , \" Segmentation and Modeling in Segment - Based Recognition , \" Proc .Eurospeech , 1199 - 1202 , Rhodes , Sept. 1997 .( PDF ) . A. Halberstadt and J. Glass , \" Heterogeneous Acoustic Measurements for Phonetic Classification , \" Proc .", "label": "", "metadata": {}, "score": "55.995193"}
{"text": "( PDF ) .G. Choueiter and J. Glass , \" A wavelet and filter bank framework for phonetic classification , \" Proc .ICASSP , Philadelphia , PA , March 2005 .( PDF ) .K. Saenko , K. Livescu , J. Glass , and T. Darrell , \" Production domain modeling of pronunciation for visual speech recognition , \" Proc .", "label": "", "metadata": {}, "score": "56.0845"}
{"text": "Functional anatomic background .Several recent reviews develop large - scale models of the cortical basis of speech perception and , despite some disagreement on various details , there is also considerable convergence among these proposals ( Binder et al .2000 ; Hickok & Poeppel 2000 , 2004 ; Scott & Johnsrude 2003 ; Boatman 2004 ; Indefrey & Levelt 2004 ; Poeppel & Hackl 2007 ) .", "label": "", "metadata": {}, "score": "56.136974"}
{"text": "Conclusions .This chapter has examined the speech recognition performance of both a speech enhancement algorithm combined with the auditory model front - end proposed by Li et al .[14 ] , and the ETSI advanced front - end [ 7 ] , in the presence of both environmental noise and packet loss .", "label": "", "metadata": {}, "score": "56.180347"}
{"text": "Interspeech , Dresden , 2015 .( PDF ) .C. Lee , T. O'Donnell , and J. Glass , \" Unsupervised Lexicon Discovery from Acoustic Input , \" Trans .ACL , 3 , 2015 .( PDF ) .L. Lee , J. Glass , H. Lee , and C. Chan , \" Spoken Content Retrieval -- Beyond Cascading Speech Recognition with Text Retrieval , \" IEEE Trans .", "label": "", "metadata": {}, "score": "56.19414"}
{"text": "This thesis is about modeling , analyzing , and predicting errorful behavior in large vocabulary continuous speech recognition systems .Because today 's state - of - the - art recognizers are not designed to be situated naturally in an error feedback loop , they are ill - positioned for inclusion in multi - modal interfaces , multi - media databases , and other interesting applications .", "label": "", "metadata": {}, "score": "56.207836"}
{"text": "J. Glass , \" A Probabilistic Framework for Segment - Based Speech Recognition , \" Computer Speech and Language , 17 , 137 - 152 , 2003 .( PDF ) .S. Sakai and J. Glass , \" Fundamental frequency modeling for corpus - based speech synthesis based on a statistical learning technique , \" Proc .", "label": "", "metadata": {}, "score": "56.288"}
{"text": "We are currently adapting the workstation - based ASR system used at ICSI to run efficiently on these architectures .Two out of the three major components of ICSI 's speech system , the acoustic front - end and the phoneme probability estimator , contain computational kernels that are very regular ( FFT and matrix - matrix multiply , respectively ) .", "label": "", "metadata": {}, "score": "56.308952"}
{"text": "As decades of research show , phonological generalizations are stated over features ( neither holistic phonemes nor a fortiori ' epiphones ' ) , reflecting their epistemological primacy .The fact that the elements of phonological organization can be interpreted as articulatory gestures with distinct acoustic consequences suggests a tight and efficient architectural organization of the speech system in which speech production and perception are intimately connected through the unifying concept of distinctive features .", "label": "", "metadata": {}, "score": "56.331024"}
{"text": "2001 ) and human ( A. Boemio 2002 , unpublished dissertation ) studies show that response properties change at precisely that perceptual boundary , possibly associated with a transition from temporal to rate coding schemes .A compelling example from speech perception comes from the work of Saberi & Perrott ( 1999 ) , who took spoken sentences , cut them into time slices and locally reversed the direction of each time window .", "label": "", "metadata": {}, "score": "56.355656"}
{"text": "Crucial is that something must mediate the mapping from spectro - temporal signal configurations to lexical entries ( on our view of lexical representation ) .Such an intermediate ( and fleeting ) multi - time resolution representation will retain acoustic properties , but they will differ depending on whether one is looking at the shorter ( segmental ) or longer ( syllabic ) temporal primitive .", "label": "", "metadata": {}, "score": "56.36728"}
{"text": "( PDF ) .I. Saleh , S. Joty , L. Marquez , S. Cyphers , J. Glass , A. Moschitti , and P. Nakov , \" A Study of using Syntactic and Semantic Structures for Concept Segmentation and Labeling , \" Proc .", "label": "", "metadata": {}, "score": "56.412804"}
{"text": "( II ) when compared with the ETSI advanced front - end [ 7 ] .The other results in Tables 1 to 4 show that enhancement of the speech prior to feature extraction significantly improves the overall recognition performance .This improvement in recognition accuracy is observed for both the ETSI basic [ 6 ] and advanced [ 7 ] front - ends and the front - end proposed by Li et al .", "label": "", "metadata": {}, "score": "56.425568"}
{"text": "Analysis is carried out in the frequency domain and the signal spectrum is estimated using an FFT .Westerlund et al .[ 22 ] present a speech enhancement technique in which the input signal is first divided into a number of sub - bands .", "label": "", "metadata": {}, "score": "56.63453"}
{"text": "DECIPHER is a speaker - independent continuous speech recognition system based on hidden Markov model ( HMM ) technology .We show signific ... \" .This paper describes improvements to DECIPHER , the speech recog - nition component in SKI 's Air Travel Information Systems ( ATIS ) and Resource Management systems .", "label": "", "metadata": {}, "score": "56.638084"}
{"text": "DECIPHER is a speaker - independent continuous speech recognition system based on hidden Markov model ( HMM ) technology .We show signific ... \" .This paper describes improvements to DECIPHER , the speech recog - nition component in SKI 's Air Travel Information Systems ( ATIS ) and Resource Management systems .", "label": "", "metadata": {}, "score": "56.638084"}
{"text": "However , in a centralised ASR system the recognition accuracy can be compromised as a result of the speech signal being distorted by low bit - rate encoding at the codec and a poor quality transmission channel [ 2 , 3 ] .", "label": "", "metadata": {}, "score": "56.7119"}
{"text": "( PDF ) . H. Chang and J. Glass , \" Multi - level Context - Dependent Acoustic Modeling for Automatic Speech Recognition , \" Proc .ASRU , Waikolao , 2011 .( PDF ) .I. Badr , I. McGraw , and J. Glass , \" Pronunciation Learning from Continuous Speech , \" Proc .", "label": "", "metadata": {}, "score": "56.723846"}
{"text": "A block interleaver of degree d changes the order of transmission of a d x d block of input vectors .Figure 4 .Tests and results .The primary purpose of this section is to investigate the performance of the auditory model proposed by Li et al .", "label": "", "metadata": {}, "score": "56.780136"}
{"text": "This observation argues for the view that information extracted and analysed on two time scales interacts synergistically and in a perceptually relevant manner , supporting the hypothesis of multi - time resolution processing .A final point concerns the hypothesis that processing on different time scales is actually associated with different cortical areas and possibly lateralized .", "label": "", "metadata": {}, "score": "56.78302"}
{"text": "I. Malioutov , A. Park , R. Barzilay , and J. Glass , \" Making Sense of Sound : Unsupervised Topic Segmentation Over Acoustic Input , \" Proc .ACL , 504 - 511 , Prague , June 2007 .( PDF ) .", "label": "", "metadata": {}, "score": "56.90885"}
{"text": "Finally we show improvement using parallel male- and female - trained models in DECIPHER .The word - error rate when all three improvements were combined was 3.7 % on DARPA 's February 1989 speaker - independent test set using the standard perplexity 60 wordpair grammar .", "label": "", "metadata": {}, "score": "56.92534"}
{"text": "Finally we show improvement using parallel male- and female - trained models in DECIPHER .The word - error rate when all three improvements were combined was 3.7 % on DARPA 's February 1989 speaker - independent test set using the standard perplexity 60 wordpair grammar .", "label": "", "metadata": {}, "score": "56.92534"}
{"text": "( PDF ) . E. Chuangsuwanich and J. Glass , \" Robust Voice Activity Detector for Real World Applications Using Harmonicity and Modulation Frequency , \" Proc .Interspeech , Florence , 2011 .( PDF ) .C. Lee and J. Glass , \" A Transcription Task for Crowdsourcing with Automatic Quality Control , \" Proc .", "label": "", "metadata": {}, "score": "56.937473"}
{"text": "Work is ongoing in the use of this approach for larger - vocabulary recognition tasks , and in the use of the Gabor filters in a multi - stream , multi - classifier architecture .[ 1 ] .M. Kleinschmidt , \" Improving Word Accuracy with Gabor Feature Extraction , \" Forum Acusticum , Seville , Spain , September 2002 .", "label": "", "metadata": {}, "score": "56.93805"}
{"text": "Minimally , speech perception must yield representations that smoothly and rapidly interface with stored lexical items .Adopting the perspective of Marr , we argue and provide neurobiological and psychophysical evidence for the following research programme .First , at the implementational level , speech perception is a multi - time resolution process , with perceptual analyses occurring concurrently on at least two time scales ( approx .", "label": "", "metadata": {}, "score": "57.073006"}
{"text": "Psychophysical and electrophysiological experiments on the processing of click trains also highlight the relevance of processing on this time scale , in both humans and non - human primates ( Lu et al .2001 ; A. Boemio 2002 , unpublished dissertation ) .", "label": "", "metadata": {}, "score": "57.11032"}
{"text": "That is , therefore , some features must be detected within the segmental time frame ( approx .20 - 80 ms ) .However , in addition , there is also abundant phonological evidence for syllable - level generalizations in phonology ( a recent survey of such effects is F\u00e9ry & van de Vijver ( 2004 ) ) .", "label": "", "metadata": {}, "score": "57.17041"}
{"text": "Third , at the computational level of description , we commit to a specific representational theory , that of distinctive features as the primitives for lexical representation and phonological computation .Our proposal contrasts with views that argue for strictly episodic ( acoustic ) representations - although we are sympathetic to the fact that the rich evidence for episodic effects must be accommodated , and we articulate a proposal in \u00a7 5 .", "label": "", "metadata": {}, "score": "57.20733"}
{"text": "Design of a feature - based speech recognizer aiming at integration of auditory processing , signal modeling , and phonological structure of speech .Dept .Elec .Eng . , Univ .Waterloo , Waterloo , ON N2L 3G1 , Canada .", "label": "", "metadata": {}, "score": "57.210224"}
{"text": "Matching procedures between the synthesized candidate targets and the input signal ultimately select the best match ; in other words , the analysis is guided by internally synthesized candidate representations .In the terminology of contemporary cognitive neuroscience , analysis - by - synthesis as we develop it here is closely related to the concept of internal forward models .", "label": "", "metadata": {}, "score": "57.267216"}
{"text": "In this acoustic - phonetic approach , the speech recognition problem is hypothesized as a maximization of the joint posterior probability of a set of pho ... \" .A probabilistic and statistical framework is presented for automatic speech recognition based on a phonetic feature representation of speech sounds .", "label": "", "metadata": {}, "score": "57.329857"}
{"text": "The stages involved in feature extraction based on MFCCs are shown in Figure 1 .The speech signal first undergoes pre - emphasis in order to compensate for the unequal sensitivity of human hearing across frequency .Following pre - emphasis , a short - term power spectrum is obtained by applying a fast Fourier transform ( FFT ) to a frame of Hamming windowed speech .", "label": "", "metadata": {}, "score": "57.423763"}
{"text": "C. Lee , Y. Zhang , and J. Glass , \" Joint Learning of Phonetic Units and Word Pronunciations for ASR , \" Proc .EMNLP , Seattle , 2013 .( PDF ) .W. Li , J. Glass , N. Roy , and S. Teller , \" Probabilistic Dialogue Modeling for Speech - Enabled Assistive Technology , \" Proc .", "label": "", "metadata": {}, "score": "57.48467"}
{"text": "Beyond this initial analysis of sounds that is robustly bilateral and may involve all the steps involved in the acoustic - to - phonetic mapping , there is wide agreement that speech perception is lateralized .The right STG and STS have been shown to play a critical role in the analysis of voice information ( Belin et al .", "label": "", "metadata": {}, "score": "57.55728"}
{"text": "As it turns out , over a time interval of 200 ms or more of desynchronization , listeners reliably perceive the fused syllable /ta/. This evidence is of course consistent with the claim that there is a temporal integration window of roughly 250 ms in AV speech ( van Wassenhove et al .", "label": "", "metadata": {}, "score": "57.59095"}
{"text": "( PDF ) .S. Shum , N. Dehak , and J. Glass , \" Unsupervised Methods for Speaker Diarization : An Integrated and Iterative Approach , \" Trans .ASLP , 21(10 ) , 2015 - -2028 , 2013 .( PDF ) . A. Lee , Y. Zhang , and J. Glass , \" Mispronunciation Detection via Dynamic Time Warping on Deep Belief Network - Based Posteriorgrams , \" Proc .", "label": "", "metadata": {}, "score": "57.6018"}
{"text": "14 ] .For the task of connected digit recognition using the Aurora 2 database , the front - end proposed by Li et al .gave the best overall recognition results of all the auditory models examined , and with an overall reduction in recognition error compared to the ETSI basic front - end [ 6 ] which was used as a baseline for comparison .", "label": "", "metadata": {}, "score": "57.606125"}
{"text": "( PDF ) .K. Saenko , T. Darrell , and J. Glass , \" Articulatory features for robust visual speech recognition , \" Proc .ICMI , State College , October 2004 .( PDF ) .T. Hazen , K. Saenko , C. La and J. Glass , \" A segment - based audio - visual speech recognizer : Data collection , development and initial experiments , \" Proc .", "label": "", "metadata": {}, "score": "57.67948"}
{"text": "EMNLP , Lisbon , 2015 .( PDF ) .P. Cardinal , N. Dehak , Y. Zhang , and J. Glass , \" Speaker Adaptation Using the I - Vector Technique for Bottleneck Features , \" Proc .Interspeech , Dresden , 2015 .", "label": "", "metadata": {}, "score": "57.812515"}
{"text": "However , the evaluation here is looking primarily at the effect of speech enhancement or noise reduction alone on the connected digit recognition accuracy .Therefore , the waveform processing block in the ETSI advanced front - end was disabled .In addition , the ETSI advanced front - end carries out post - processing in the cepstral domain in the form of blind equalisation as described in [ 13 ] .", "label": "", "metadata": {}, "score": "57.873356"}
{"text": "( PDF ) .I. Bazzi and J. Glass , \" Heterogeneous lexical units for automatic speech recognition : Preliminary investigations \" Proc .ICASSP , Istanbul , June 2000 .K. Livescu and J. Glass , \" Lexical modeling of non - native speech for automatic speech recognition , \" Proc .", "label": "", "metadata": {}, "score": "57.95381"}
{"text": "G. Choueiter and J. Glass , \" An Implementation of Rational Wavelets and Filter Design for Phonetic Classification , \" Trans .ASLP , 15(3 ) , 939 - 948 , 2007 .( PDF ) . A. Park and J. Glass , \" Towards Unsupervised Pattern Discovery in Speech , \" Proc .", "label": "", "metadata": {}, "score": "58.139137"}
{"text": "( PDF ) .K. Schutte and J. Glass , \" Robust Detection of Sonorant Landmarks , \" Proc .Interspeech , 1005 - 1008 , Lisbon , September 2005 .( PDF ) . A. Park , T. Hazen , and J. Glass , \" Automatic processing of audio lectures for information retrieval : Vocabulary selection and language modeling , \" Proc .", "label": "", "metadata": {}, "score": "58.158356"}
{"text": "( PDF ) .X. Fang , N. Dehak , and J. Glass , \" Bayesian Distance Metric Learning on i - vector for Speaker Verification , \" Proc .Interspeech , Lyon , 2013 .( PDF ) . A. Lee and J. Glass , \" Pronunciation Assessment via a Comparison - based System , \" Proc .", "label": "", "metadata": {}, "score": "58.189903"}
{"text": "This poses a problem for many speech recognition systems , which need to handle both native and non - native speech .The problem is further complicat ... \" .The performance of automatic speech recognizers has been observed to be dramatically worse for speakers with non - native accents than for native speakers .", "label": "", "metadata": {}, "score": "58.228783"}
{"text": "( PDF ) .K. Livescu and J. Glass , \" Segment - based recognition on the Phonebook task : Initial results and observations on duration modeling , \" Proc .Eurospeech , Aalborg , September 2001 .( PDF ) .", "label": "", "metadata": {}, "score": "58.275818"}
{"text": "What is the purpose of such a proposed temporal quantization of the input waveform ?We hypothesize that this sampling serves as a logistical or administrative device to generate auditory representations of the appropriate granularity to interface with higher - order , abstract representations .", "label": "", "metadata": {}, "score": "58.32674"}
{"text": "N. Dehak , R. Dehak , J. Glass , D. Reynolds , and P. Kenny , \" Cosine Similarity Scoring without Score Normalization Techniques , \" Proc .Odyssey Speaker and Language Recognition Workshop , Brno , 2010 .( PDF ) .", "label": "", "metadata": {}, "score": "58.401005"}
{"text": "17 , pp .82 - 90 , Jan. 1999 .2 - D. Pearce , \" Enabling new speech driven services for mobile devices : an overview of the ETSI standards activities for distributed speech recognition front - ends \" , in Proc .", "label": "", "metadata": {}, "score": "58.453262"}
{"text": "Alternatively , perhaps the representations of speech that are motivated by linguistic considerations are in fact active in the analysis process itself and therefore active throughout the subroutines that make up the speech perception process .Unsurprisingly , we adopt the latter view .", "label": "", "metadata": {}, "score": "58.52626"}
{"text": "( PDF ) .P. Nakov , L. Marquez , W. Magdy , A. Moschitti , J. Glass , and B. Randeree , \" SemEval-2015 Task 3 : Answer Selection in Community Question Answering , \" Proc .Int .Workshop on Semantic Evaluation , Denver , 2015 .", "label": "", "metadata": {}, "score": "58.642666"}
{"text": "Furthermore , processes of vowel - consonant assimilation ( such as nasalization of vowels and rounding or palatalization of consonants ) serve to further ' smear ' featural information into the syllabic time scale .Thus for speakers to use segments to produce speech requires the segments to be decomposed into features in order to adequately account for rules of pronunciation , and listeners also construct representations using the same features , as shown by various psycholinguistic and neurolinguistic tests .", "label": "", "metadata": {}, "score": "58.658302"}
{"text": "This webpage was written shortly after the research ended .In January 2007 , I did some light editing on these pages , to remove dead links and better specify the timeline of the research .Why Model Audition ?Many engineering systems that process sound , such as speech recognition systems , pitch detectors , and psychoacoustic audio compressors , include simple models of human audition in their processing .", "label": "", "metadata": {}, "score": "58.709545"}
{"text": "On the DARPA resource management task , SPHINX attained a speaker - independent word accuracy of 96 % with a grammar ( perplexity 60 ) , and 82 % without grammar ( perplexity 997 ) .by H. Niemann , E. N\u00f6th , E.G. Schukat - Talamazzini , A. Kie\u00dfling , R. Kompe , T. Kuhn , S. Rieck - MODERN MODES OF MAN - MACHINE COMMUNICATION , 1994 . \" ...", "label": "", "metadata": {}, "score": "58.758762"}
{"text": "On the DARPA resource management task , SPHINX attained a speaker - independent word accuracy of 96 % with a grammar ( perplexity 60 ) , and 82 % without grammar ( perplexity 997 ) .by H. Niemann , E. N\u00f6th , E.G. Schukat - Talamazzini , A. Kie\u00dfling , R. Kompe , T. Kuhn , S. Rieck - MODERN MODES OF MAN - MACHINE COMMUNICATION , 1994 . \" ...", "label": "", "metadata": {}, "score": "58.758762"}
{"text": "( For a discussion of the related concept auditory primal sketch , see Todd ( 1994 ) . )For example , calling it ' phonological ' implies a categorical representation , but the extent to which the information in each of the two windows is categorical is unclear because it is untested .", "label": "", "metadata": {}, "score": "58.910725"}
{"text": "It is not yet worked out in what way a PPS relates to the representations stipulated by models , such as TRACE , NAM , shortlist or distributed cohort .Because such models do not make explicit reference to multi - time resolution processing , it is not obvious whether short , segmental or long , syllabic temporal primitives can be accommodated best within such theories .", "label": "", "metadata": {}, "score": "58.91771"}
{"text": "The idea that time windows of different sizes are relevant for speech analysis and perception derives from several phenomena .In particular , acoustic as well as articulatory - phonetic phenomena occur on different time scales .Investigation of a waveform and spectrogram of a spoken sentence reveal that at the scale of roughly 20 - 80 ms , segmental and subsegmental cues are reflected , as well as local segmental order ( i.e. the difference between ' pe st ' and ' pe ts ' ) .", "label": "", "metadata": {}, "score": "58.993042"}
{"text": "The performance of Li et al .( II ) was compared with the performance of the ETSI advanced front - end .The ETSI advanced front - end includes a SNR - dependent waveform processing block that is applied after noise reduction and before feature extraction .", "label": "", "metadata": {}, "score": "59.11753"}
{"text": "The analysis of prosodic features of speech has also been suggested to be lateralized to right STG .The processing of speech per se , i.e. that aspect of processing that permits lexical access and further speech - based computation , however , is lateralized to left temporal , parietal and frontal cortices ( Binder et al .", "label": "", "metadata": {}, "score": "59.145653"}
{"text": "( PDF ) .S. Lee , and J. Glass , \" Real - time probabilistic segmentation for segment - based speech recogntion , \" Proc .ICSLP , Sydney , November 1998 .( PDF ) .C. Pao , P. Schmid , and J. Glass , \" Confidence scoring for speech understanding systems , \" Proc .", "label": "", "metadata": {}, "score": "59.1566"}
{"text": "Experiments performed on the TIMIT phoneme classification task demonstrate the benefits of classification in frequency subbands : the subband classifier outperforms the cepstral classifiers in the presence of noise for signal - to - noise ratio ( SNR ) below 12dB. Index Terms - Robustness , speech recognition , acoustic waveforms , subbands , support vector machines .", "label": "", "metadata": {}, "score": "59.21154"}
{"text": "Performance ranking of enhancement algorithms .Discussion .Ignoring speech enhancement , and comparing Tables 1 and 2 , the performance of Li et al .( I ) exceeds the baseline ETSI front - end [ 6 ] by 2.08 % overall .", "label": "", "metadata": {}, "score": "59.215454"}
{"text": "( PDF ) . H. Shu , I. Lee Hetherington , and J. Glass , \" Baum - Welch training for segment - based speech recognition , \" Proc .ASRU , St. Thomas , December 2003 , 43 - 48 .", "label": "", "metadata": {}, "score": "59.416115"}
{"text": "14 ] in combination with speech enhancement in the presence of noise and packet loss .As a baseline for comparison , results are also presented for the ETSI advanced front - end [ 7 ] .In all cases , training was carried out using clean data .", "label": "", "metadata": {}, "score": "59.488632"}
{"text": "The baseline recognition results for the two front - ends , without vector quantisation and with no packet loss but with noise , are detailed in Table 7 .The word accuracies in the following tables are calculated as described in Section 2.4 .", "label": "", "metadata": {}, "score": "59.68631"}
{"text": "The bottom tier incorporates distinct levels of representation in the mapping from sound to word ( spectral analysis - segmental analysis - lexical hypotheses ) .The intermediate tier shows possible representations and computations that interact with the bottom and top ( analysis - by - synthesis ) levels to generate the correct mappings .", "label": "", "metadata": {}, "score": "59.695503"}
{"text": "( b )Functional lateralization as a consequence of temporal integration .From asymmetric temporal integration of this type , it follows that different auditory tasks will recruit the two populations differentially owing to sensitivity differences and lead to hemispheric asymmetry .", "label": "", "metadata": {}, "score": "59.74488"}
{"text": "Following initial testing with no packet loss compensation , a number of existing packet loss mitigation techniques were investigated , namely nearest neighbour repetition and interpolation .Results show that the best recognition performance was obtained using nearest neighbour repetition to reconstruct missing features .", "label": "", "metadata": {}, "score": "59.800377"}
{"text": "The advantage of this is that there is no impact on the computational complexity of the feature extraction or the recognition processes as the enhancement is independent of both , and the speech enhancement can be implemented as an add - on without significantly affecting existing parts of the system .", "label": "", "metadata": {}, "score": "59.844563"}
{"text": "In January 2007 , I did some light editing on these pages , to remove dead links and better specify the timeline of the research .Why Model Audition ?Many engineering systems that process sound , such as speech recognition systems , pitch detectors , and psychoacoustic audio compressors , include simple models of human audition in their processing .", "label": "", "metadata": {}, "score": "59.9625"}
{"text": "Modeling of words by segmental units should be supported by suprasegmental units since valuable information is r ... \" .In order to cope with the problems of spontaneous speech ( including , for example , hesitations and non - words ) it is necessary to extract from the speech signal all information it contains .", "label": "", "metadata": {}, "score": "60.027508"}
{"text": "Modeling of words by segmental units should be supported by suprasegmental units since valuable information is r ... \" .In order to cope with the problems of spontaneous speech ( including , for example , hesitations and non - words ) it is necessary to extract from the speech signal all information it contains .", "label": "", "metadata": {}, "score": "60.027508"}
{"text": "The information carried in these different channels is not identical - different spatial frequencies are associated with differential abilities to convey emotional information ( low spatial frequencies ) versus image details ( high spatial frequencies ; e.g. Vuilleumier et al .An alternative way to conceptualize this distinction is to think of it as the tension between global versus local information .", "label": "", "metadata": {}, "score": "60.10203"}
{"text": "The front - end of Li et al . performs marginally better overall than the ETSI advanced front - end for channels A , B and C ; however , for channel D , the overall recognition performance of the ETSI advanced front - end is better than that of Li et al .", "label": "", "metadata": {}, "score": "60.25447"}
{"text": "We now turn to the three hypothesized attributes of speech perception introduced above and , when possible , relate them to the sketch of the anatomy outlined here .Multi - time resolution processing .It is an intuitively straightforward observation that visual signals are processed on multiple spatial scales .", "label": "", "metadata": {}, "score": "60.27355"}
{"text": "The overall word accuracies in Table 9 , with vector quantization , compare well with the baseline accuracies , without vector quantization , in Table 7 .Table 8 .Table 9 .Recognition results with VQ codebooks designed using implementation of the GLA .", "label": "", "metadata": {}, "score": "60.292976"}
{"text": "One way to reconcile the tension between local ( fast modulation frequency ) and global ( slower modulation frequency ) information is to assume hierarchical processing such that higher - order , longer representations are constructed on the basis of smaller units .", "label": "", "metadata": {}, "score": "60.332607"}
{"text": "Certainly this is no solution to invariance , but it does provide one new perspective on how to approach this highly important and vexing issue in the perception of spoken language .Figure 1 schematizes the operative representations in speech perception in the context of the present proposal .", "label": "", "metadata": {}, "score": "60.364296"}
{"text": "This interaction has implications for vocabulary independent modeling , testing methodologies , discriminative training , and the adequacy of our current databases for continuo ... \" .An interaction has been found between the true source language model , training language model , and the testing language model .", "label": "", "metadata": {}, "score": "60.416355"}
{"text": "This interaction has implications for vocabulary independent modeling , testing methodologies , discriminative training , and the adequacy of our current databases for continuo ... \" .An interaction has been found between the true source language model , training language model , and the testing language model .", "label": "", "metadata": {}, "score": "60.416355"}
{"text": "For example , the field is very comfortable talking about how acoustic signals can be characterized by spectro - temporal receptive fields ( STRFs ) of auditory cortical neurons ( e.g. Shamma 2001 ) .This is a terrific set of results - but such a characterization tells us nothing about how such a ( neuronal ) representation allows for further computation with that token .", "label": "", "metadata": {}, "score": "60.465675"}
{"text": "( PDF ) . A. Lee and J. Glass , \" Context - dependent Pronunciation Error Pattern Discovery with Limited Annotations , \" Proc .Interspeech , Singapore , 2014 .( PDF ) .D. Harwath and J. Glass , \" Speech Recognition without a Lexicon - Bridging the Gap between Graphemic and Phonetic Systems , \" Proc .", "label": "", "metadata": {}, "score": "60.502808"}
{"text": "Both psychophysical and neurobiological evidence suggest that physically continuous information is broken apart and processed in temporal windows .The claim that there is temporal integration is rather uncontroversial .More controversial is the hypothesis that there is not just integration but discretization ( Saberi & Perrott 1999 ; VanRullen & Koch 2003 ) .", "label": "", "metadata": {}, "score": "60.541355"}
{"text": "Frequency information is encoded throughout the system , so that the search can proceed on a ' best - first ' basis , with more probable parses assigned greater weight in the system .This primal sketch gives a neighbourhood of words matching the detected landmark sequence .", "label": "", "metadata": {}, "score": "60.583725"}
{"text": "The core acoustic operation has essentially remained the same for decades : a single feature vector ( derived from the power spectral envelope over a ... \" .State - of - the - art automatic speech recognition ( ASR ) systems continue to improve , and yet there remain many tasks for which the technology is inadequate .", "label": "", "metadata": {}, "score": "60.63582"}
{"text": "These concepts are not mutually exclusive - rather , knowledge about language is built upon knowledge of language .A related way to address this tension comes from the cognitive psychology of concepts .In particular , the concepts literature has struggled with the tension between a range of well - documented surface effects ( typically perceptual similarity effects ) and the necessary and sufficient conditions that are definitional of the ' classical ' accounts of concepts ( see for review Murphy 2002 ) .", "label": "", "metadata": {}, "score": "60.659256"}
{"text": "Moreover , much work in automatic speech recognition has a Bayesian orientation through the use of inverse - probability techniques such as hidden Markov models .However , much of the work in perception , signal analysis and speech recognition is of the empirical Bayes variety , using non - informative priors .", "label": "", "metadata": {}, "score": "60.68011"}
{"text": "( 1979 ) in a study on trilingual Flemish students .Thus , accommodation is not a mechanical exemplar - driven process but is rather mediated by the attitude of the listener to the speaker .That is , the speaker 's knowledge OF language ( in the sense of Chomsky ( 1986 ) ) serves as the basis for the collection of knowledge ABOUT language .", "label": "", "metadata": {}, "score": "60.6999"}
{"text": "We present an approach to flexible and efficient modeling of speech by segmental units and describe extraction and use of suprasegmental information . ...This dissertation is the result of my own work and includes nothing which is the outcome of work done in collaboration , except where stated .", "label": "", "metadata": {}, "score": "60.713608"}
{"text": "We present an approach to flexible and efficient modeling of speech by segmental units and describe extraction and use of suprasegmental information . ...This dissertation is the result of my own work and includes nothing which is the outcome of work done in collaboration , except where stated .", "label": "", "metadata": {}, "score": "60.713608"}
{"text": "The ETSI advanced front - end includes a SNR - dependent waveform processing block that is applied after noise reduction and before feature extraction .The waveform processing block in the ETSI advanced front - end is also implemented in the front - end of Li et al .", "label": "", "metadata": {}, "score": "60.77169"}
{"text": "Ephraim and Malah [ 20 ] present a minimum mean - square error short - time spectral amplitude ( MMSE STSA ) estimator .The estimator is based on modelling speech and noise spectral components as statistically independent Gaussian random variables .", "label": "", "metadata": {}, "score": "60.838802"}
{"text": "Feature vectors are extracted from the output of this waveform processing block .A detailed description of the waveform processing block can be found in [ 26 ] .The ETSI advanced front - end carries out post - processing in the cepstral domain in the form of blind equalization as described by [ 13 ] .", "label": "", "metadata": {}, "score": "60.863396"}
{"text": "A significant amount of research has been carried out on speech enhancement , and a number of approaches have been well documented in the literature .A survey of a number of approaches to speech enhancement using a single microphone is presented in [ 5 ] .", "label": "", "metadata": {}, "score": "60.872337"}
{"text": "N. Dehak , Z. Karam , D. Reynolds , R. Dehak , W. Campbell , and J. Glass , \" A Channel - Blind System for Speaker Verification , \" Proc .ICASSP , Prague , 2011 .( PDF ) .", "label": "", "metadata": {}, "score": "60.98686"}
{"text": "There are three different test sets defined for recognition testing , with the test utterances taken from the testing part of the TIDigits database .Test Set A ( 28028 utterances ) employs the same four noises as used for the multi - condition training .", "label": "", "metadata": {}, "score": "61.00679"}
{"text": "The primal sketch includes enough information to broadly classify certain prosodic characteristics as well ( such as the approximate number of moras or syllables in the word ) .Of course , the various feature detectors are fallible and return probabilistic information , which can then be inverted using Bayes 's rule .", "label": "", "metadata": {}, "score": "61.04449"}
{"text": "They will completely eliminate task - specific training , and will enable rapid configuration of speech recognizers for new vocabularies .Our initial results using generalized triphones as VIi models show that with more training data and more detailed modeling , the error rate of VI models can be reduced substantially .", "label": "", "metadata": {}, "score": "61.11206"}
{"text": "They will completely eliminate task - specific training , and will enable rapid configuration of speech recognizers for new vocabularies .Our initial results using generalized triphones as VIi models show that with more training data and more detailed modeling , the error rate of VI models can be reduced substantially .", "label": "", "metadata": {}, "score": "61.11206"}
{"text": "This debate on concepts in cognitive psychology seems to us quite analogous to the conflict between abstractionist versus episodic models of speech perception and lexical representation .We advocated an abstractionist model ( distinctive features as the representational primitives for phonology and lexicon ) that , we argued , can be linked in principled ways to acoustic implementation and also holds hope for developing spectro - temporal primitives ( Stevens 2002 ) .", "label": "", "metadata": {}, "score": "61.130463"}
{"text": "The front - ends investigated were perceptual linear prediction ( PLP ) proposed by Hermansky [ 17 ] , the PEMO algorithm proposed by Tchorz and Kollmeier [ 18 ] , and the front - end processor proposed by Li et al .", "label": "", "metadata": {}, "score": "61.13649"}
{"text": "Based on this perspective , we outline a research programme on speech perception that is strongly influenced by Marr 's ( 1982 ) approach to understanding visual perception .Marr 's suggestion to distinguish between computational , algorithmic and implementational levels of description when investigating computational systems in cognitive neuroscience seems to be very helpful to us in fractionating the problem and organizing the set of questions one faces in the study of speech perception .", "label": "", "metadata": {}, "score": "61.1702"}
{"text": "One important goal of the research programme is to develop linking hypotheses between putative neurobiological primitives ( e.g. temporal primitives ) and those primitives derived from linguistic inquiry , to arrive ultimately at a biologically sensible and theoretically satisfying model of representation and computation in speech .", "label": "", "metadata": {}, "score": "61.258987"}
{"text": "Speech enhancement algorithms give a trade - off between noise reduction and signal distortion .A reduction in noise can lead to an improvement in the subjective quality of the speech but a decrease in the measured speech intelligibility [ 5 ] .", "label": "", "metadata": {}, "score": "61.412178"}
{"text": "In the mapping from input to lexical representation , the initial steps are bilateral , mediated by various cortical fields on the STG ; subsequent computation is typically left lateralized and extends over many left per - Sylvian areas .IFG , inferior frontal gyrus ; SPT , Sylvian parieto - temporal area ; MTG , middle temporal gyrus ; ITG , inferior temporal gyrus ; STG , superior temporal gyrus .", "label": "", "metadata": {}, "score": "61.467606"}
{"text": "An intermediate representation may be necessary to map from a spectro - temporal representation of the acoustic input signal to the putative abstract representation of the word .The intermediate representation may be a PPS , built on temporal primitives ( temporal windows of specific sizes ) and spectral primitives .", "label": "", "metadata": {}, "score": "61.53199"}
{"text": "We hypothesize that the STRFs of neurons in bilateral core auditory cortex generate high - resolution neuronal representations of the input signal ( which of course is already highly pre - processed in subcortical areas , say , the inferior colliculus ) .", "label": "", "metadata": {}, "score": "61.57207"}
{"text": "Gabor Filter Analysis for Automatic Speech Recognition .David Gelbart and Michael Kleinschmidt 1 ( Professor Nelson H. Morgan )Deutsche Forschungsgemeinschaft , Natural Sciences and Engineering Research Council of Canada , and German Ministry for Education and Research .Auditory researchers believe that the human auditory system computes many different representations of sound , reflecting different time and frequency resolutions .", "label": "", "metadata": {}, "score": "61.62542"}
{"text": "Introduction .We take speech perception to be the set of computations that entail as their ' endgame ' and optimal result the identification of words , either presented in isolation or in spoken discourse .In short , it is a critical requirement that the output of the processes that constitute speech perception are representations that permit using and manipulating these representations in specific ways .", "label": "", "metadata": {}, "score": "61.67216"}
{"text": "[14 ] is used .The choice of this auditory front - end is motivated by previous work carried out by the authors [ 15 ] where a number of auditory front - ends were investigated in a comparative study of robust speech recognition with the widely - used Aurora 2 database [ 16 ] .", "label": "", "metadata": {}, "score": "61.69883"}
{"text": "The approach to the speech perception that we advocate here differs from many current proposals in explicitly ( re)incorporating linguistic and psycholinguistic considerations , particularly considerations of lexical and phonological representations .While we are sympathetic to what can be learned from such a research programme , we are convinced that one can not do without the constraints derived from linguistics , and particularly phonology .", "label": "", "metadata": {}, "score": "61.73814"}
{"text": "ASLP , 16(1 ) , 186 - 197 , 2008 .( PDF ) .J. Ming , T. Hazen , and J. Glass , \" Combining Missing - Feature Theory , Speech Enhancement , and Speaker - Dependent/-Independent Modeling for Speech Separation , \" Computer , Speech , and Language , ( DOI ) , 2007 .", "label": "", "metadata": {}, "score": "61.793446"}
{"text": "The speech database is derived from utterances of isolated digits and connected digit sequences spoken by US - American adults originally included in the well - known TIDigits database .The speech in the TIDigits database is sampled at 20 kHz and is down - sampled to 8 kHz in the Aurora database .", "label": "", "metadata": {}, "score": "61.854378"}
{"text": "In the previous section , the benefit of speech enhancement prior to feature extraction in a speech recognition system was demonstrated .However , in a DSR system , transmission errors can still have a significant impact on recognition performance .Such transmission errors in the form of bit errors , random packet loss and packet burst loss need to be taken into consideration .", "label": "", "metadata": {}, "score": "61.962296"}
{"text": "Server - based methods include feature reconstruction , by means of repetition or interpolation , and error correction in the ASR - decoding stage .Reference [ 4 ] provides a survey of robustness issues related to network degradations and presents a number of analyses and experiments with a focus on transmission error robustness .", "label": "", "metadata": {}, "score": "62.100662"}
{"text": "As has been argued recently , for example by Price et al .( 2005 ) , all the cortical machinery that is used for speech is also used for other tasks .It seems like a reasonable proposition that in the difficult case of having to analyse complex signals extremely rapidly , you use whatever is available to you .", "label": "", "metadata": {}, "score": "62.195374"}
{"text": "However , DSR systems generally operate in high levels of background noise ( particularly in mobile environments ) .For mobile users in noisy environments ( airports , cars , restaurants etc . ) the speech recognition accuracy can be reduced dramatically as a consequence of additive background noise .", "label": "", "metadata": {}, "score": "62.255833"}
{"text": "A DSR system is designed as a compromise between local and centralised recognition , in order to alleviate the issues associated with these approaches [ 2 , 3 ] .In DSR , the speech recognition task is split between the terminal or client , where the front - end feature extraction is performed , and the network or server , where the back - end recognition is performed .", "label": "", "metadata": {}, "score": "62.27063"}
{"text": "Speech quality is a subjective measure and is dependent on the individual preferences of listeners .It is a measure of how comfortable a listener is when listening to the speech under evaluation .The intelligibility of the speech can be regarded as an objective measure , and is calculated based on the number or percentage of words that can be correctly recognised by listeners .", "label": "", "metadata": {}, "score": "62.352943"}
{"text": "Their view converges with that of Poeppel ( 2001 , 2003 ) , where it is suggested that the spectral versus temporal right - left asymmetry is a consequence of the size of the temporal integration windows of the neuronal ensembles in these areas .", "label": "", "metadata": {}, "score": "62.377922"}
{"text": "Eds .Cambridge , MA : MIT Press .Remarks on analysis by synthesis and distinctive features .In Models for the perception of speech and visual form : proceedings of a symposium Wathen - Dunn W 1967 pp . 88 - 102 .", "label": "", "metadata": {}, "score": "62.42079"}
{"text": "The computational needs of auditory models are especially troubling when considering the use of such system in battery - operated portable devices .Digital - signal - processors ( DSPs ) are the traditional solution to speeding up computationally - intensive audio algorithms .", "label": "", "metadata": {}, "score": "62.488358"}
{"text": "The computational needs of auditory models are especially troubling when considering the use of such system in battery - operated portable devices .Digital - signal - processors ( DSPs ) are the traditional solution to speeding up computationally - intensive audio algorithms .", "label": "", "metadata": {}, "score": "62.488358"}
{"text": "Accuracy increases when discriminating only \" frustrated \" from other utterances , and when using only those utterances on which labelers originally agreed .Furthermore , prosodic model accuracy degrades only slightly when using recognized versus true words .Language model features , even if based on true words , are relatively poor predictors of frustration .", "label": "", "metadata": {}, "score": "62.57069"}
{"text": "The probabilistic framework makes the acoustic - phonetic approach to speech recognition suitable for practical recognition tasks as well as compatible with probabilistic pronunciation and language models .Support vector machines ( SVMs ) are applied for the binary classification tasks because of their two favorable properties- good generalization and the ability to learn from a relatively small amount of high dimensional data .", "label": "", "metadata": {}, "score": "62.62494"}
{"text": "( PDF ) . H. Chang and J. Glass , \" A Back - off Discriminative Acoustic Model for Automatic Speech Recognition , \" Proc .Interspeech , 232 - 235 , Brighton , Sept. 2009 .( PDF ) .J. Baker , L. Deng , S. Khudanpur , C. Lee , J. Glass , N. Morgan , and D. O'Shaughnessy , \" Updated MINDS Report on Speech Recognition and Understanding , Part 2 , \" IEEE Signal Processing Magazine , 78 - 85 , July 2009 .", "label": "", "metadata": {}, "score": "62.694027"}
{"text": "2001 ; A. Boemio 2002 , unpublished dissertation ) .Experiments testing the minimum stimulus onset asynchrony ( SOA ) at which the order of two concurrently presented signals can be reliably indicated show that , across sensory modalities , approximately 20 - 30 ms are the relevant time scale ( Hirsh & Sherrick 1961 ) .", "label": "", "metadata": {}, "score": "62.747334"}
{"text": "( PDF ) .S. Shum , N. Dehak , E. Chuangsuwanich , D. Reynolds , and J. Glass , \" Exploiting Intra - Conversation Variability for Speaker Diarization , \" Proc .Interspeech , Florence 2011 .( PDF ) .", "label": "", "metadata": {}, "score": "62.797256"}
{"text": "B. Zhu , T. Hazen , and J. Glass , \" Multimodal Speech Recognition with Ultrasonic Sensors , \" Proc .Interspeech , 662 - 665 , Antwerp , August 2007 .( PDF ) .J. Ming , T. Hazen , J. Glass , and D. Reynolds , \" Robust Speaker Recognition in Unknown Noisy Conditions , \" Trans .", "label": "", "metadata": {}, "score": "62.855183"}
{"text": "D. Harwath , T. Hazen , and J. Glass , \" Zero Resource Spoken Audio Corpus Analysis , \" Proc .ICASSP , Vancouver , 2013 .( PDF ) .I. McGraw , I. Badr , and J. Glass , \" Learning Lexicons from Speech using a Pronunciation Mixture Model , \" Trans .", "label": "", "metadata": {}, "score": "62.87804"}
{"text": "More intriguingly , however , languages seem to organize their features so as to minimize the number of features used in the language to distinguish among both consonants and vowels ( see especially the discussion of combinatorial specification in Archangeli & Pulleyblank ( 1994 ) ) .", "label": "", "metadata": {}, "score": "62.915085"}
{"text": "y recognized speaker .Hidden Markov Models are normally trained according to a maximum likelihood criterion ; parameters are adjusted to maximize the probability of the training set .This process does not directly minimiz ...", "label": "", "metadata": {}, "score": "62.924103"}
{"text": "I. Bazzi and J. Glass , \" A multi - class approach for modelling out - of - vocabulary words , \" Proc .ICSLP , Denver , 1613 - 1616 , September 2002 .J. Yi and J. Glass , \" Information - theoretic criteria for unit selection synthesis , \" Proc .", "label": "", "metadata": {}, "score": "63.125816"}
{"text": "S. Shum , N. Dehak , and J. Glass , \" Limited Labels for Unlimited Data : Active Learning for Speaker Recognition , \" Proc .Interspeech , Singapore , 2014 .( PDF ) . H. Lee , Y. Zhang , E. Chuangsuwanich , and J. Glass , \" Graph - based Re - ranking using Acoustic Feature Similarity between Search Results for Spoken Term Detection on Low - resource Languages , \" Proc .", "label": "", "metadata": {}, "score": "63.14686"}
{"text": "NCC 2 - 1256 , and ( NSF ) IRI-9619921 .We investigate the use of prosody for the detection of frustration and annoyance in natural human - computer dialog .In addition to prosodic features , we examine the contribution of language model information and speaking \" style .", "label": "", "metadata": {}, "score": "63.188717"}
{"text": "27 - C. Pel\u00e1ez - Moreno , G. Gallardo - Antol\u00edn and F. D\u00edaz - de - Mar\u00eda , \" Recognizing voice over IP : A robust front - end for speech recognition on the world wide web \" , IEEE Trans .", "label": "", "metadata": {}, "score": "63.30068"}
{"text": "Tools . \" ...This thesis is about modeling , analyzing , and predicting errorful behavior in large vocabulary continuous speech recognition systems .Because today 's state - of - the - art recognizers are not designed to be situated naturally in an error feedback loop , they are ill - positioned for inclusion in multi- ... \" .", "label": "", "metadata": {}, "score": "63.32269"}
{"text": "NAACL - HLT , Denver , 2015 .( PDF ) .C. Cai , P. Guo , J. Glass , and R. Miller , \" Wait - Learning : Leveraging Wait Time for Second Language Education , \" Proc .CHI , Seoul , 2015 .", "label": "", "metadata": {}, "score": "63.341328"}
{"text": "Speech enhancement algorithms .In this section , the various speech enhancement algorithms that were examined are briefly described .The algorithms range from well - established algorithms like that of Ephraim and Malah [ 20 ] , to more recently proposed ones like that of Rangachari and Loizou [ 21 ] .", "label": "", "metadata": {}, "score": "63.413536"}
{"text": "In comparison , the visual /pa/ , which is almost always correctly identified , was associated with much greater temporal facilitation ( up to 25 ms at the P2 ) .In other words , the rate of correct identification of the visual - alone signal predicted the degree of temporal savings of the auditory N1 and P2 components .", "label": "", "metadata": {}, "score": "63.45929"}
{"text": "1996 ; Munhall et al .1996 ; Grant et al .2004 ; van Wassenhove et al .When subjects are presented with AV syllables in which either the audio or the video signals lead or lag by up to 200 ms , subjects apparently integrate the desynchronized signal successfully and interpret the AV signal as coherent and bound .", "label": "", "metadata": {}, "score": "63.47129"}
{"text": "For exceptions , permission may be sought for such use through Elsevier 's permissions site at : .A further issue is that a given training database will obviously consist of more frames than phonetic segments , hence the training of the segmental model is more vulnerable with respect to variance ... . \" ...", "label": "", "metadata": {}, "score": "63.538902"}
{"text": "X. Feng , B. Richardson , S. Amman , and J. Glass , \" On Using Heterogeneous Data for Vehicle - Based Speech Recognition : A DNN - Based Approach , \" Proc .ICASSP , Brisbane , 2015 .( PDF ) .", "label": "", "metadata": {}, "score": "63.55389"}
{"text": "( PDF ) .G. Choueiter , M. Ohannessian , S. Seneff , and J. Glass , \" A Turbo - Style Algorithm For Lexical Baseforms Estimation , \" Proc .ICASSP , 4313 - 4316 , Las Vegas , April 2008 .", "label": "", "metadata": {}, "score": "63.64862"}
{"text": "3 , pp .209 - 218 , June 2001 .29 - J. Van Sciver , J. Z. Ma , F. Vanpoucke and H. Van Hamme , \" Investigation of speech recognition over IP channels \" , in Proc . of IEEE International Conference on Acoustics , Speech and Signal Processing ( ICASSP ) , May 2002 , pp .", "label": "", "metadata": {}, "score": "63.73733"}
{"text": "K. Livescu , J. Glass , and J. Bilmes , \" Hidden feature models for speech recognition using dynamic Bayesian networks , \" Proc .Eurospeech Geneva , 2529 - 2532 , September 2003 .( PDF ) .J. Glass and S. Seneff , \" Flexible and personalizable mixed - initiative dialogue systems , \" Proc .", "label": "", "metadata": {}, "score": "63.75708"}
{"text": "J. Baker , L. Deng , J. Glass , S. Khudanpur , C. Lee , N. Morgan , and D. O'Shaughnessy , \" Research Developments and Directions in Speech Recognition and Understanding , Part 1 , \" IEEE Signal Processing Magazine , 75 - 80 , May 2009 .", "label": "", "metadata": {}, "score": "63.798264"}
{"text": "hidden Markov model ( HMM ) based continuous speech recognition system typically used in a speaker - indepen - dent manner .Initially we review the DECIPHER sys - tem , then we show that DECIPHER 's speaker - independent performance improved by 20 % when the standard 3990-sentence speaker - independent test set was augmented with training data from the 7200-sentence re - source management speaker - dependent training sentences .", "label": "", "metadata": {}, "score": "63.92596"}
{"text": "hidden Markov model ( HMM ) based continuous speech recognition system typically used in a speaker - indepen - dent manner .Initially we review the DECIPHER sys - tem , then we show that DECIPHER 's speaker - independent performance improved by 20 % when the standard 3990-sentence speaker - independent test set was augmented with training data from the 7200-sentence re - source management speaker - dependent training sentences .", "label": "", "metadata": {}, "score": "63.92596"}
{"text": "26 - D. Macho and Y. M. Cheng , \" SNR - dependent waveform processing for improving the robustness of ASR front - end \" , in Proc . of IEEE International Conference on Acoustics , Speech and Signal Processing ( ICASSP ) , May 2001 , pp .", "label": "", "metadata": {}, "score": "63.964783"}
{"text": "As stated above , the auditory signal up to primary auditory cortex is processed in a predominantly symmetric manner ( although there are notable asymmetries at the subcortical level ) .The STRFs in core auditory cortex permit the construction of a relatively high - fidelity representation of the signal .", "label": "", "metadata": {}, "score": "64.02609"}
{"text": "For example , the detection of [ labial ] or [ coronal ] place is different within nasals in English ( which lacks a velar nasal phoneme ) than it is for stops ( which contrast all three categories ) .Figure 4 shows some of the hypothesized set of computations , adapted and extended from Klatt ( 1979 ) , to make clear where the synthesis process sits within the larger architecture .", "label": "", "metadata": {}, "score": "64.04546"}
{"text": "K. Livescu , B. Zhu , and J. Glass , \" On the Phonetic Information in Ultrasonic Microphone Signals , \" Proc .ICASSP , 4621 - 4624 , Taipei , April 2009 .( PDF ) .Y. Zhang and J. Glass , \" Speech Rhythm Guided Syllable Nuclei Detection , \" Proc .", "label": "", "metadata": {}, "score": "64.06984"}
{"text": "Thus , in our view , distinctive features are the sort of representational primitives that allow us to talk both about action and perception and about the connection between action and perception in a principled manner .We can do this because distinctive features are stated in both articulatory ( i.e. as gestures performed in a motor coordinate system ) and acoustic / auditory terms ( i.e. as events statable in an acoustic coordinate system ) .", "label": "", "metadata": {}, "score": "64.13097"}
{"text": "However , the high complexity prevents these models from p ... \" .Segment model ( SM ) is a family of methods by using segmental distribution rather than frame - based features ( e.g. HMM ) to represent the underlying characteristics of observation sequence .", "label": "", "metadata": {}, "score": "64.1612"}
{"text": "1992 ) , it does not follow that categorical - type abstract representations do not exist .Instead , we believe that we can learn from the concepts literature and accommodate both types of effects .How can the disagreement be resolved ?", "label": "", "metadata": {}, "score": "64.37999"}
{"text": "Based on the experimental measurements , a set of packet loss characteristics was defined in [ 33 ] and these are used to analyse recognition performance for different network conditions .The parameters in Table 6 are taken from this defined set of packet loss characteristics .", "label": "", "metadata": {}, "score": "64.398285"}
{"text": "Interspeech , Florence , 2011 .( PDF ) .S. Roberts , B. Mehler , J. Orszulak , B. Reimer , J. Glass , and J. Coughlin , \" An Evaluation of Age , Gender , and Technology Experience in User Performance and Impressions of a Multimodal Human - Machine Interface , \" Ind. Eng .", "label": "", "metadata": {}, "score": "64.41618"}
{"text": "J. Ming , T. Hazen , and J. Glass , \" Combining Missing - Feature Theory , Speech Enhancement , and Speaker - Dependent - Independent Modeling for Speech Separation , \" Computer , Speech , and Language , 24(1 ) , 67 - 76 , 2010 .", "label": "", "metadata": {}, "score": "64.44414"}
{"text": "Enhancement of noisy speech signals is normally used to improve the perception of the speech by human listeners however , it may also have benefits in enhancing robustness in ASR systems .Speech enhancement can be particularly useful in cases where a significant mismatch exists between training and testing conditions , such as where a recognition system is trained with clean speech and then used in noisy conditions , as inclusion of speech enhancement can help to reduce the mismatch .", "label": "", "metadata": {}, "score": "64.48819"}
{"text": "one - per - syllable ) phenomena , such as stress , tone and vowel harmony ( Archangeli & Pulleyblank 1994 ) .The importance of the syllable in speech perception has also been emphasized by many researchers ( e.g. Greenberg ( 2005 ) for an important perspective ) .", "label": "", "metadata": {}, "score": "64.54085"}
{"text": "For the purpose of training the speech recogniser , two modes are defined .The first mode is training on clean data and the second mode is multi - condition training on noisy data .The same 8440 utterances , taken from the training part of the TIDigits , are used for both modes .", "label": "", "metadata": {}, "score": "64.56427"}
{"text": "IMUX , Toronto , May 2007 .( PDF ) .T. Hori , L. Hetherington , T. Hazen , and J. Glass , \" Open - Vocabulary Spoken Utterance Retrieval Using Confusion Networks , \" Proc .ICASSP , 73 - 76 , Honolulu , April 2007 .", "label": "", "metadata": {}, "score": "64.582855"}
{"text": "In particular , analysis - by - synthesis , or perception driven by predictive coding based on internal forward models , is a decidedly active stance towards perception that has been characterized as a ' hypothesize - and - test ' approach .", "label": "", "metadata": {}, "score": "64.7666"}
{"text": "The algorithm makes use of the parameters from the front - end feature extraction algorithm of the ETSI advanced front - end .The purpose of the algorithm is to reduce the number of bits needed to represent each front - end feature vector and so reduce the bit rate required over the communications channel .", "label": "", "metadata": {}, "score": "64.81076"}
{"text": "Table 14 .Discussion .The results in Table 7 show that the front - end proposed by Li et al .[14 ] , when combined with the speech enhancement algorithm proposed by [ 25 ] , reduces the overall word error rate of the ETSI advanced front - end [ 7 ] by 8 % .", "label": "", "metadata": {}, "score": "64.81233"}
{"text": "To connect with that aspect of processing , the representations in play must be in the same ' code ' , a rather straightforward conjecture .Now , if we assume ( for us , uncontroversially ; for some , shockingly ) that there are abstract internal representations that form the basis for linguistic representation and processing , there must be some stage at which auditory signals are translated into such representations .", "label": "", "metadata": {}, "score": "64.857666"}
{"text": "The minimum tracking method requires a bias compensation since the minimum power spectral density of the noisy signal is smaller than the average value .In [ 24 ] , Martin further developed the noise estimation algorithm by using a time- and frequency - dependent smoothing parameter when calculating the smoothed power spectral density .", "label": "", "metadata": {}, "score": "64.86221"}
{"text": "ISSCC , San Francisco , 2014 .( PDF ) .J. Liu , P. Pasupat , Y. Wang , S. Cyphers , and J. Glass , \" Query Understanding Enhanced by Hierarchical Parsing Structures , \" Proc .ASRU , Olomouc , 2013 .", "label": "", "metadata": {}, "score": "64.86247"}
{"text": "( PDF ) .I. Badr , R. Zbib , and J. Glass , \" Segmentation for English - to - Arabic Statistical Machine Translation , \" Proc .ACL , 153 - 156 , Columbus , 2008 .( PDF ) . A. Gruenstein , B. Hsu , J. Glass , S. Seneff , I. Hetherington , S. Cyphers , I. Badr , C. Wang , and S. Liu , \" A Multimodal Home Entertainment Interface via a Mobile Device , \" Proc .", "label": "", "metadata": {}, "score": "64.86874"}
{"text": "Rangachari and Loizou [ 21 ] proposed an algorithm for the estimation of noise in highly non - stationary environments .The noisy speech power spectrum is averaged using time and frequency dependent smoothing factors .This new averaged value is then used to update the noise estimate .", "label": "", "metadata": {}, "score": "64.91876"}
{"text": "Representations and transformations from input signal to lexical representation .Solid arrows represent logically required steps and dotted arrows reflect hypothesized top - down mappings .( a )At the auditory periphery , the listener has to encode a continuously varying acoustic waveform ( x -axis , time ; y -axis , amplitude ) .", "label": "", "metadata": {}, "score": "64.919556"}
{"text": "The four different packet loss channels investigated are defined in Table 6 .Recognition tests , in the presence of packet loss , were carried out for each of the following conditions : .Tests were first carried out for packet loss with no steps taken to recover the missing features or to minimise the loss burst length .", "label": "", "metadata": {}, "score": "64.94873"}
{"text": "Temporal integration in auditory and speech analysis .( a ) Temporal integration and multi - time resolution analysis : quantization and lateralization .Both left and right auditory cortices have populations of neurons ( wired as neuronal ensembles ) that have preferred integration constants of two types .", "label": "", "metadata": {}, "score": "64.98595"}
{"text": "We explore the latter possibility here .In particular , we discuss the hypothesis that there are two principal time windows within which a given auditory signal ( speech or non - speech ) is processed , with the mean durations as above .", "label": "", "metadata": {}, "score": "65.022934"}
{"text": "( PDF ) .C. Lee , J. Glass , and O. Ghitza , \" An Efferent - Inspired Auditory Model Front - End for Speech Recognition , \" Proc .Interspeech , Florence , 2011 .( PDF ) .I. McGraw , J. Glass , and S. Seneff , \" Growing a Spoken Language Interface on Amazon Mechanical Turk , \" Proc .", "label": "", "metadata": {}, "score": "65.06424"}
{"text": "( PDF ) . E. Weinstein , K. Steele , A. Agarwal and J. Glass , \" Loud : A 1020-Node Microphone Array and Acoustic Beamformer , \" Proc .ICSV , 571 - 578 , Cairns , July 2007 .", "label": "", "metadata": {}, "score": "65.08153"}
{"text": "Moreover , if task - specific training data were available , we can interpolate them with VI models .Our prelimenary results show that this interpolation can lead to an 18 % error rate reduction over task - specific models . by Kai - fu Lee , Hsiao - wuen Hon , Mei - yuh Hwang - Proceedings of the DARPA Speech and Natural Language Workshop , 1989 . \" ...", "label": "", "metadata": {}, "score": "65.14958"}
{"text": "Moreover , if task - specific training data were available , we can interpolate them with VI models .Our prelimenary results show that this interpolation can lead to an 18 % error rate reduction over task - specific models . by Kai - fu Lee , Hsiao - wuen Hon , Mei - yuh Hwang - Proceedings of the DARPA Speech and Natural Language Workshop , 1989 . \" ...", "label": "", "metadata": {}, "score": "65.14958"}
{"text": "Consistent with previous work ( Drullman et al .1994 a ) , low - modulation frequency signals , despite being extremely impoverished relative to a normal speech signal , allow for surprisingly good comprehension , with subjects showing intelligibility scores of well over 40 % despite a severely degraded signal .", "label": "", "metadata": {}, "score": "65.19508"}
{"text": "( PDF ) .J. Yi and J. Glass , \" Natural - sounding speech synthesis using variable - length units , \" Proc .ICSLP , Sydney , November 1998 .( PDF ) .J. Polifroni , S. Seneff , J. Glass , and T.J. Hazen , \" Evaluation methodology for a telephone - based conversational system , \" Proc .", "label": "", "metadata": {}, "score": "65.228836"}
{"text": "The peak latency of the N1 and the P2 responses varied systematically as a function of the correctly identified viseme .In this study , subjects were asked to identify , based only on the visual signal , spoken syllables .For bilabials , correct identification was , predictably , very high ( more than 90 % ) ; for alveolars , identification was at an intermediate level ( approx .", "label": "", "metadata": {}, "score": "65.26976"}
{"text": "38 - B. P. Milner and A. B. James , \" Robust speech recognition over mobile and IP networks in burst - like packet loss \" , in IEEE Trans .on Audio , Speech and Language Processing vol .14 , ed , Jan. 2006 , pp .", "label": "", "metadata": {}, "score": "65.312035"}
{"text": "Error - robustness techniques are categorised in [ 4 ] under the headings client - based error recovery , and server - based error concealment .Client - based techniques include retransmission , interleaving and forward error correction ( FEC ) .", "label": "", "metadata": {}, "score": "65.39412"}
{"text": "As mentioned above , a critical requirement of lexical representation is that the representations enter into subsequent computation , for example of the morphological or syntactic flavour .One could imagine that lexical roots share properties with the mental / neural representations of non - linguistic sounds , but some formal attribute of the representations must be such that they can participate in formal operations ranging from pluralization to compound generation to phrase structure construction .", "label": "", "metadata": {}, "score": "65.53026"}
{"text": "Such findings have ( i ) challenged the view that Broca 's area is principally responsible for production tasks or syntactic tasks and ( ii ) reinvigorated the discussion of a ' motor ' contribution to speech perception .In part , these discussions are reflected in the debates surrounding mirror neurons and the renewed interest in the motor theory of speech perception .", "label": "", "metadata": {}, "score": "65.71501"}
{"text": "The channel characteristics used are G.712 and modified intermediate reference system ( MIRS ) .The down - sampled , filtered speech corresponds to \" clean \" data in the Aurora database .The Aurora database also contains \" noisy \" data .", "label": "", "metadata": {}, "score": "65.87698"}
{"text": "( submitted ) tests the idea directly .They created signals in which either low - modulation frequency information was maintained across the spectrum ( 0 - 4 Hz , corresponding to long temporal window analysis ) or higher - modulation frequency information was selectively retained ( 22 - 40 Hz , corresponding to the shorter integration constants ) .", "label": "", "metadata": {}, "score": "65.96858"}
{"text": "9 - \" Speech Processing , Transmission and Quality Aspects ( STQ ) ; Distributed speech recognition ; Extended advanced front - end feature extraction algorithm ; Compression algorithms ; Back - end speech reconstruction algorithm \" , in ETSI ES 202 212 , Ver .", "label": "", "metadata": {}, "score": "66.03348"}
{"text": "150 - 300 ms ) , commensurate with ( sub)segmental and syllabic analyses , respectively .Second , at the algorithmic level , we suggest that perception proceeds on the basis of internal forward models , or uses an ' analysis - by - synthesis ' approach .", "label": "", "metadata": {}, "score": "66.09224"}
{"text": "Twenty - five FFT - Mel filters spanning 100 to 6400 hz are used to derive 12 Mel - cepstra coefficients every 10-rns frame .Four features are derived every frame from this cepstra sequence .The resulting four - feature - per - frame vector is used as input to the DECIPHER HMM - based speech recognition system .", "label": "", "metadata": {}, "score": "66.24284"}
{"text": "Twenty - five FFT - Mel filters spanning 100 to 6400 hz are used to derive 12 Mel - cepstra coefficients every 10-rns frame .Four features are derived every frame from this cepstra sequence .The resulting four - feature - per - frame vector is used as input to the DECIPHER HMM - based speech recognition system .", "label": "", "metadata": {}, "score": "66.24284"}
{"text": "Either way , we see no logical reason why episodic and abstractionist models are mutually exclusive since they , for the most part , are designed to account for very different sets of phenomena .Acknowledgments .Supported by NIH DC 05660 to D.P. and a Canada - US Fulbright Program award to W.J.I. We thank Norbert Hornstein for numerous insightful and provocative comments on these issues .", "label": "", "metadata": {}, "score": "66.25457"}
{"text": "The ETSI advanced front - end [ 7 ] specifies that where missing feature vectors occur due to transmission errors , they should be substituted with the nearest correctly received feature vector in the receiver .The speech vector includes the 12 static cepstral coefficients C 1 - C 12 , the zeroth cepstral coefficient C 0 and the log energy term , and all are replaced together .", "label": "", "metadata": {}, "score": "66.30649"}
{"text": "ISCA ITRW ASR-2000 , Paris , France , Sept. 2000 , pp .181 - 188 .20 - Y. Ephraim and D. Malah , \" Speech enhancement using a minimum mean - square error short - time spectral amplitude estimator \" , IEEE Trans . on Acoustics , Speech and Signal Processing , vol .", "label": "", "metadata": {}, "score": "66.31799"}
{"text": "( PDF ) .Y. Zhang , E. Chuangsuwanich , and J. Glass , \" Language ID - based training of multilingual stacked bottleneck features , \" Proc .Interspeech , Singapore , 2014 .( PDF ) .T. Al Hanai and J. Glass , \" Lexical Modeling for Arabic ASR : A Systematic Approach , \" Proc .", "label": "", "metadata": {}, "score": "66.48689"}
{"text": "( PDF ) .T. Hazen and J. Glass , \" A Comparison of Novel Techniques for Instantaneous Speaker Adaptation , \" Proc .Eurospeech , 2047 - 2050 , Rhodes , Sept. 1997 .( PDF ) .Some Older Publications .", "label": "", "metadata": {}, "score": "66.52728"}
{"text": "Zatorre and colleagues have argued on the basis of neuropsychological and neuroimaging data that right hemisphere superior temporal areas are specialized for the analysis of spectral properties of signals , in particular spectral change , and the analysis of pitch , specifically pitch change .", "label": "", "metadata": {}, "score": "66.57477"}
{"text": "auditory model are shown in Figure 2 .Speech is sampled at 8 kHz and blocked into frames of 240 samples .Frame overlap is 66.7 % and a Hamming window is used prior to taking a FFT .An outer / middle ear transfer function that models pressure gain in the outer and middle ears is applied to the spectrum magnitude .", "label": "", "metadata": {}, "score": "66.63171"}
{"text": "Future work includes running a large vocabulary system on these architectures .This involves picking a search order that will maximize reuse of state from previous searches ( e.g. , if the word \" architecture \" has already been processed , most of the work can be reused for the word \" architectural \" ) .", "label": "", "metadata": {}, "score": "66.78744"}
{"text": "In the analysis , two versions of the Li et al .front - end are used .The first , referred to as Li et al .( I ) , generates a feature vector consisting of 13 coefficients made up of the frame log - energy measure and the cepstral coefficients C 1 to C 12 .", "label": "", "metadata": {}, "score": "66.808586"}
{"text": "The final step is the application of a discrete cosine transform ( DCT ) to generate the MFCCs .In the ETSI DSR front - ends , speech , sampled at 8 kHz , is blocked into frames of 200 samples with an overlap of 60 % .", "label": "", "metadata": {}, "score": "66.83614"}
{"text": "High SNR values indicate the presence of speech and the sub - band signal is amplified .Low SNR values indicate the presence of noise only and the sub - band signal remains unchanged .Martin [ 23 ] presented an algorithm for the enhancement of noisy speech signals by means of spectral subtraction , in particular through a method for estimation of the noise power on a sub - band basis .", "label": "", "metadata": {}, "score": "66.87979"}
{"text": "The advantage of interleaving can be seen by a comparison of Table 14 with Table 13 , where overall recognition results are improved for both front - ends when interleaving is introduced .Looking at Table 14 it is seen that Li et al .", "label": "", "metadata": {}, "score": "66.915985"}
{"text": "Proc .HLT / NAACL , Boston , May 2004 .( PDF ) .J. Glass , T. Hazen , L. Hetherington and C. Wang , \" Analysis and processing of lecture audio data : Preliminary investigations \" , In Proceedings of the HLT - NAACL 2004 Workshop on Interdisciplinary Approaches to Speech Indexing and Retrieval , 9 - 12 , Boston , May 2004 .", "label": "", "metadata": {}, "score": "67.22428"}
{"text": "( PDF ) .B. Lake , C. Lee , J. Glass , and J. Tenenbaum , \" One - Shot Learning of Generative Speech Concepts , \" Proc .CogSci , 803 - -808 , Quebec City , 2014 .( PDF ) . H. Bahari , N. Dehak , H. Van hamme , L. Burget , A. Ali , and J. Glass , \" Non - Negative Factor Analysis for Gaussian Mixture Model Weight Adaptation for Language and Dialect Recognition , \" Trans .", "label": "", "metadata": {}, "score": "67.31004"}
{"text": "For these applications , an alternative approach to DSPs is to use a special - purpose analog to digital converter , that computes auditory model representations directly on the analog signal before digitization .Auditory Models in Analog VLSI .The 1985 - 1995 time period was a time of continual improvement in analog circuit models of biological audition .", "label": "", "metadata": {}, "score": "67.36014"}
{"text": "For these applications , an alternative approach to DSPs is to use a special - purpose analog to digital converter , that computes auditory model representations directly on the analog signal before digitization .Auditory Models in Analog VLSI .The 1985 - 1995 time period was a time of continual improvement in analog circuit models of biological audition .", "label": "", "metadata": {}, "score": "67.36014"}
{"text": "The PPS is then specified by identifying the articulator - bound features within the detected landmarks .That is , the 2 - 1/two - dimensional analogue is constructed using probabilistic information about features such as [ labial ] , [ coronal ] , etc .", "label": "", "metadata": {}, "score": "67.51409"}
{"text": "- 2620 , September 2002 .( PDF ) .I. Bazzi and J. Glass , \" Learning units for domain - independent out - of - vocabulary word modelling , \" Proc .Eurospeech , Aalborg , September 2001 .( PDF ) .", "label": "", "metadata": {}, "score": "67.56804"}
{"text": "This results in higher noise robustness when compared with using a magnitude spectrum estimate as used in the ETSI basic front - end [ 12 ] .The two front - ends both generate a feature vector consisting of 14 coefficients made up of the frame log - energy measure ( determined prior to pre - emphasis ) and cepstral coefficients C 0 to C 12 .", "label": "", "metadata": {}, "score": "67.65167"}
{"text": "A non - linearity in the form of a logarithm followed by a DCT is applied to the filter outputs to generate the cepstral coefficients .The recognition experiments use vectors that include energy and 12 cepstral coefficients ( C 1 to C 12 ) along with velocity and acceleration coefficients .", "label": "", "metadata": {}, "score": "67.71895"}
{"text": "In the case of the basic front - end , pre - emphasis is carried out using a filter coefficient equal to 0.97 while the advanced front - end uses a value of 0.9 .A Hamming window is used in both the ETSI basic and advanced front - ends prior to taking an FFT .", "label": "", "metadata": {}, "score": "67.72474"}
{"text": "( PDF ) .P. Cardinal , A. Ali , N. Dehak , Y. Zhang , T. Al Hanai , Y. Zhang , J. Glass , and S. Vogel , \" Recent Advances in ASR Applied to an Arabic Transcription System for Al - Jazeera , \" Proc .", "label": "", "metadata": {}, "score": "67.75485"}
{"text": "14 ] .A comparison of Table 1 with Table 2 shows that Li et al .( I ) outperforms the ETSI basic front - end for all of the speech enhancement techniques evaluated .Furthermore , from Tables 3 and 4 , it is seen that Li et al .", "label": "", "metadata": {}, "score": "67.89552"}
{"text": "R. Rifkin , K. Schutte , M. Saad , J. Bouvrie , and J. Glass , \" Noise Robust Phonetic Classification with Linear Regularized Least Squares and Second - Order Features , \" Proc .ICASSP , 881 - 884 , Honolulu , April 2007 .", "label": "", "metadata": {}, "score": "68.04331"}
{"text": "15 - R. Flynn and E. Jones , \" A comparative study of auditory - based front - ends for robust speech recognition using the Aurora 2 database \" , in Proc .IET Irish Signals and Systems Conference , Dublin , Ireland , 28 - 30 June 2006 , pp . 111 - 116 .", "label": "", "metadata": {}, "score": "68.0455"}
{"text": "An attribute that tends to be common among such models is that the analysis is relatively ' passive ' .That is to say , features percolate up the processing hierarchy in bottom - up models , or activation spreads in interactive models .", "label": "", "metadata": {}, "score": "68.07556"}
{"text": "3820 - 3823 .31 - P. Mayorga , L. Besacier , R. Lamy and J. F. Serignat , \" Audio packet loss over IP and speech recognition \" , in Proc . of IEEE Workshop on Automatic Speech Recognition and Understanding ( ASRU ) , Nov. 2003 , pp .", "label": "", "metadata": {}, "score": "68.17757"}
{"text": "When one presents listeners with AV syllables and desynchronizes the audio and video tracks , one might expect severe perceptual disturbances given that one has disrupted the temporal alignment of the auditory and the visual information .Surprisingly , listeners tolerate enormous temporal asynchronies when viewing asynchronous AV speech .", "label": "", "metadata": {}, "score": "68.30463"}
{"text": "front - end .The Li et al .front - end , combined with speech enhancement , still outperforms the ETSI advanced front - end in the presence of vector quantisation although the improvement in overall word error rate is reduced from 8 % ( without vector quantisation ) to 5.3 % .", "label": "", "metadata": {}, "score": "68.336945"}
{"text": "The adjusted counts are normalized to generate new observation probabilities for the models .The parameters being adjusted are the mixture weights for the semi - continuous HMMs .The technique reduced word error for a test subject by 37 % relative . .", "label": "", "metadata": {}, "score": "68.7169"}
{"text": "The adjusted counts are normalized to generate new observation probabilities for the models .The parameters being adjusted are the mixture weights for the semi - continuous HMMs .The technique reduced word error for a test subject by 37 % relative . .", "label": "", "metadata": {}, "score": "68.71693"}
{"text": "Therefore , an implementation of the Generalized Lloyd Algorithm ( GLA ) , described by [ 39 ] , was used to design the VQ codebooks for both the ETSI advanced front - end and the front - end of Li et al .", "label": "", "metadata": {}, "score": "68.81378"}
{"text": "Additionally , interleaving , a technique used to reduce feature vector loss burst lengths ( with a penalty of additional delay ) , is also briefly discussed .Interleaving is carried out on the client side of a DSR system , with de - interleaving on the server side .", "label": "", "metadata": {}, "score": "68.96984"}
{"text": "These chips receive analog input , and perform several stages on analog computation on the signal , using circuit techniques from silicon audition .The output of these chips are a digital encoding of the final auditory representation , suitable for direct processing by computing systems .", "label": "", "metadata": {}, "score": "68.97333"}
{"text": "These chips receive analog input , and perform several stages on analog computation on the signal , using circuit techniques from silicon audition .The output of these chips are a digital encoding of the final auditory representation , suitable for direct processing by computing systems .", "label": "", "metadata": {}, "score": "68.97333"}
{"text": "6 - \" Speech Processing , Transmission and Quality Aspects ( STQ ) ; Distributed speech recognition ; Front - end feature extraction algorithm ; Compression algorithms \" , in ETSI ES 201 108 , Ver .1.1.3 , Sept. 2003 .", "label": "", "metadata": {}, "score": "69.066284"}
{"text": "J. Yi , J. Glass and L. Hetherington , \" A flexible , scalable finite - state transducer architecture for corpus - based concatenative speech synthesis , \" Proc .ICSLP , Beijing , October 2000 .( PDF ) .V. Zue and J. Glass , \" Conversational Interfaces : Advances and Challenges \" Proc .", "label": "", "metadata": {}, "score": "69.11484"}
{"text": "One contribution of 13 to a Theme Issue ' The perception of speech : from sound to meaning ' .The study of prelexical and lexical processes in comprehension : psycholinguistics and functional neuroimaging .In The new cognitive neurosciences Gazzaniga M 2000 pp .", "label": "", "metadata": {}, "score": "69.123276"}
{"text": "Binary classifiers of the manner phonetic features- syllabic , sonorant and continuant- are applied for the probabilistic detection of speech landmarks .The landmarks include stop bursts , vowel onsets , syllabic peaks , syllabic dips , fricative onsets and offsets , and sonorant consonant onsets and offsets .", "label": "", "metadata": {}, "score": "69.37778"}
{"text": "y recognized speaker .Hidden Markov Models are normally trained according to a maximum likelihood criterion ; parameters are adjusted to maximize the probability of the training set .This process does not directly minimiz ...Tools . \" ...This thesis is about modeling , analyzing , and predicting errorful behavior in large vocabulary continuous speech recognition systems .", "label": "", "metadata": {}, "score": "69.4039"}
{"text": "ICASSP , Prague , 2011 .( PDF ) .S. Liu , S. Seneff , and J. Glass , \" A Collective Data Generation Method for Speech Language Models , \" Proc .IEEE Workshop on Spoken Language Technology , 211 - 216 , Berkeley , 2010 .", "label": "", "metadata": {}, "score": "69.41132"}
{"text": "Such observations suggest that a tolerance for visual leads is not only preferable but also natural in AV speech perception .Unclear , however , is the issue of whether the information associated with the visual signal plays any specific role in auditory speech perception .", "label": "", "metadata": {}, "score": "69.48041"}
{"text": "Lexical representations are sui generis : they may share properties with other cognitive representations , but they have a number of extremely specialized properties that seem to be restricted to the representation of lexical items in the human brain .So , for example , lexical items do not , at least to our knowledge , look like the internal representations of jingling keys , faces , melodies or odours .", "label": "", "metadata": {}, "score": "69.481094"}
{"text": "Beginning in the STG , research in the last few years has identified the emergence of two processing streams .The idea of segregated and parallel pathways is closely related to vision research , where the concept of a ' what ' versus a ' where'/'how ' pathway is very firmly established ( Ungerleider & Mishkin 1982 ) .", "label": "", "metadata": {}, "score": "69.48807"}
{"text": "( PDF ) . A. Gruenstein , J. Orszulak , S. Liu , S. Roberts , J. Zabel , B. Reimer , B. Mehler , S. Seneff , J. Glass , J. Coughlin , \" City Browser : Developing a Conversational Automotive HMI , \" Proc .", "label": "", "metadata": {}, "score": "69.489944"}
{"text": "For segment durations of up to 50 ms , intelligibility was not significantly affected , supporting the notion of the special nature of integration , and perhaps even discretization , on this time scale .Evidence for temporal integration on a longer , 150 - 300 ms time scale also comes from physiological and psychophysical studies .", "label": "", "metadata": {}, "score": "69.72391"}
{"text": "( II ) , generates a feature vector that contains the cepstral coefficients C 1 to C 12 along with a weighted combination of cepstral coefficient C 0 and the frame log - energy measure .The reason for investigating two versions of the Li et al .", "label": "", "metadata": {}, "score": "69.73296"}
{"text": "Section 3 addresses the problem of robustness of speech recognition systems in the presence of additive noise , in particular , by examining in detail the use of speech enhancement techniques to reduce the effects of noise on the speech signal .", "label": "", "metadata": {}, "score": "69.84169"}
{"text": "It is not a ' subtle interplay ' of feed - forward and feedback steps that we have in mind , though , but a rather unromantic , mechanical ( forward ) calculation of perceptual candidates based on very precisely guided synthesis steps .", "label": "", "metadata": {}, "score": "70.0199"}
{"text": "( PDF ) .( PDF ) .Y. Belinkov , M. Mohtarami , S. Cyphers , and J. Glass , \" VectorSLU : A Continuous Word Vector Approach to Answer Selection in Community Question Answering Systems , \" Proc .Int .", "label": "", "metadata": {}, "score": "70.052895"}
{"text": "( PDF ) .I. Badr , R. Zbib , and J. Glass , \" Syntactic Phrase Reordering for English - to - Arabic Statistical Machine Translation , \" Proc .EACL , 86 - 93 , Athens , April 2009 .", "label": "", "metadata": {}, "score": "70.205765"}
{"text": "Speech perception consists of a set of computations that take continuously varying acoustic waveforms as input and generate discrete representations that make contact with the lexical representations stored in long - term memory as output .Because the perceptual objects that are recognized by the speech perception enter into subsequent linguistic computation , the format that is used for lexical representation and processing fundamentally constrains the speech perceptual processes .", "label": "", "metadata": {}, "score": "70.228714"}
{"text": "1.1.5 , Jan. 2007 . 8 - \" Speech Processing , Transmission and Quality Aspects ( STQ ) ; Distributed speech recognition ; Extended front - end feature extraction algorithm ; Compression algorithms ; Back - end speech reconstruction algorithm \" , in ETSI ES 202 211 , Ver .", "label": "", "metadata": {}, "score": "70.51969"}
{"text": "In contrast with the more commonly used Maximum Likelihood training , discriminative training considers the likelihoods of competing classes when determining the parameters for a given class 's model .Thus , discriminative training works directly to minimize the number of errors made in the recognition of the training data . \" ...", "label": "", "metadata": {}, "score": "70.54824"}
{"text": "32 - J. Vicente - Pe\u00f1a , G. Gallardo - Antol\u00edn , C. Pel\u00e1ez - Moreno and F. D\u00edaz - de - Mar\u00eda , \" Band - pass filtering of the time sequences of spectral parameters for robust wireless speech recognition \" , Speech Communication , vol .", "label": "", "metadata": {}, "score": "70.60479"}
{"text": ".. ated based on a simple shift in the ( discrete ) output probabilities for each state , so that within - state vectors are more likely .Chou [ 22 , 23 ] implements a similar scheme , but aims at minimising the recogn ... . by Douglas B. Pault , James K. Baker : f , Janet M. Baker , E Psubeatmsubcat . \" ...", "label": "", "metadata": {}, "score": "70.6778"}
{"text": ".. ated based on a simple shift in the ( discrete ) output probabilities for each state , so that within - state vectors are more likely .Chou [ 22 , 23 ] implements a similar scheme , but aims at minimising the recogn ... . by Douglas B. Pault , James K. Baker : f , Janet M. Baker , E Psubeatmsubcat . \" ...", "label": "", "metadata": {}, "score": "70.6778"}
{"text": "When plotting electrophysiological response peak latency as a function of correct identification of the visual signal , significant temporal facilitation of the auditory evoked responses ( N1 and P2 ) was observed as a function of how informative the face was for the listeners .", "label": "", "metadata": {}, "score": "70.74791"}
{"text": "A Telephone - Based Conversational Interface for Weather Information , \" Trans .SAP , 8(1 ) , 85 - 96 , 2000 .J. Glass , \" Challenges for spoken dialogue systems , \" Proc .ASRU , Keystone , December 1999 .", "label": "", "metadata": {}, "score": "70.805084"}
{"text": "For many inferential psychological processes ( say , deductive reasoning ) , a categorical perspective on concepts has been more successful ; in contrast , many other processing effects have been best described by gradient , non - categorical representations of some type .", "label": "", "metadata": {}, "score": "70.88761"}
{"text": "Speech enhancement , Hermite interpolation .When interleaving is introduced , the receive side perceives that the average loss burst length is reduced [ 37 ] .Table 14 shows the recognition results obtained when interleaving , with an interleaving depth of 4 , is used in conjunction with Hermite interpolation .", "label": "", "metadata": {}, "score": "70.964584"}
{"text": "853 - 856 .35 - A. B. James and B. P. Milner , \" Towards improving the robustness of distributed speech recognition in packet loss \" , in Proc .Second COST278 and ISCA Tutorial and Research Workshop ( ITRW ) on Robustness Issues in Conversational Interaction , University of East Anglia , U.K. , Aug. 2004 , p. paper", "label": "", "metadata": {}, "score": "71.07837"}
{"text": "Baseline recognition results .In order to implement split vector quantization it is necessary to design VQ codebooks for each of the seven coefficient pairs .ETSI has made available script files for the ETSI advanced front - end and included with these are the VQ codebooks for the coefficient pairs .", "label": "", "metadata": {}, "score": "71.21697"}
{"text": "( Naturally , it can be weighted to what extent core versus periphery are more important for various tasks using that concept . )The kind of phenomena that motivated this relatively complex view of concepts include experiments in which it must be the case that both kinds of information are consulted .", "label": "", "metadata": {}, "score": "71.32665"}
{"text": "Finally we describe our performance in the February 1991 DARPA Resource Management evaluation ( 4.8 percent word error ) and in the February 1991 DARPA - ATIS speech and SLS evaluations ( 95 sentences correct , 15 wrong of 140 ) .", "label": "", "metadata": {}, "score": "71.41742"}
{"text": "Finally we describe our performance in the February 1991 DARPA Resource Management evaluation ( 4.8 percent word error ) and in the February 1991 DARPA - ATIS speech and SLS evaluations ( 95 sentences correct , 15 wrong of 140 ) .", "label": "", "metadata": {}, "score": "71.41742"}
{"text": "IEEE Workshop on Spoken Language Technology , Berkeley , 2010 .( PDF ) .I. Badr , I. McGraw , and J. Glass , \" Learning New Word Pronunciations from Spoken Examples , \" Proc .Interspeech , 2294 - 2297 , Makuhari , 2010 .", "label": "", "metadata": {}, "score": "71.46441"}
{"text": "Electrophysiological mismatch negativity studies testing temporal integration of non - speech signals also point to 150 - 300 ms as the relevant time scale ( Yabe et al .1997 , 2001 a , b ) .There are two observations from the domain of speech that we consider critical in this context .", "label": "", "metadata": {}, "score": "71.47125"}
{"text": "DSR avoids both the speech encoding and decoding stages associated with centralised recognition and so eliminates the degradations that originate from the speech compression algorithms .The bandwidth required to transmit the extracted features to the server is much less than what is required to send the encoded speech signal .", "label": "", "metadata": {}, "score": "71.59183"}
{"text": "S. Seneff , J. Glass , T.J. Hazen , Y. Minami , J. Polifroni , and V. Zue , \" Mokusei : A Japanese spoken dialogue system in the weather domain , \" NTT R&D Vol .49 , No . 7 , 2000 .", "label": "", "metadata": {}, "score": "71.59838"}
{"text": "1109 - 1121 , Dec. 1984 .25 - A. Agarwal and Y.M. Cheng , \" Two - stage mel - warped wiener filter for robust speech recognition \" , in Proceedings of Automatic Speech Recognition and Understanding Workshop , Keystone , Colorado , USA , 1999 , pp .", "label": "", "metadata": {}, "score": "71.646164"}
{"text": "In the comparison of Li et al .( I ) and the ETSI basic front - end , there was no post - processing of the feature vectors carried out .The recognition results using the Aurora 2 database for Li et al .", "label": "", "metadata": {}, "score": "71.710785"}
{"text": "Nevertheless , there is consensus that the STG from rostral to caudal fields and the STS constitute the neural tissue in which many of the critical computations for speech recognition are executed .In analogy to the visual what / where distinction , evidence from auditory anatomy and neurophysiology ( e.g. Romanski et al .", "label": "", "metadata": {}, "score": "71.76547"}
{"text": ".. ng the right thing and that the language model should be relied upon instead .For more detail on how we can sort through these different cases in a more automated fashion , see Chapter 9 . 4.5 Summary We have seen that by looking closely at what is going on frame by frame in th ... . by", "label": "", "metadata": {}, "score": "72.441505"}
{"text": ".. ng the right thing and that the language model should be relied upon instead .For more detail on how we can sort through these different cases in a more automated fashion , see Chapter 9 . 4.5 Summary We have seen that by looking closely at what is going on frame by frame in th ... . by", "label": "", "metadata": {}, "score": "72.441505"}
{"text": "In both Test Sets A and B , the frequency characteristic used in the filtering of the speech and noise is the same as that used in the training sets , namely G.712 .The frequency characteristic of the filter used in Test Set C ( 14014 utterances ) is the MIRS , and is different from that used in the training sets .", "label": "", "metadata": {}, "score": "72.60388"}
{"text": "That is , the initial pass defines a neighbourhood on broad - class and manner features ( e.g. stop - fricative - nasal - approximant ; the term ' approximant ' covers both glides and vowels ) .These initial guesses are based on minimal spectro - temporal information ( say , two or three analysis windows ) and can be stepwise refined in small time increments ( approx .", "label": "", "metadata": {}, "score": "72.72609"}
{"text": "Right hemisphere ( non - primary ) cortex houses neuronal ensembles , a large proportion of which have longer ( 150 - 300 ms ) integration windows , and therefore are better suited to analyse spectral change .These ideas are discussed in more detail below , but they build on a long history and literature that investigates hemispheric asymmetry in the auditory cortex related to spectral versus temporal processing ( Schwartz & Tallal 1980 ; Robin et al .", "label": "", "metadata": {}, "score": "72.73151"}
{"text": "N. Str\u00f6m , L. Hetherington , T.J. Hazen , E. Sandness and J. Glass , \" Acoustic modeling improvements in a segment - based speech recognizer , \" Proc .ASRU , Keystone , December 1999 .( PDF ) .J. Glass , T.J. Hazen and L. Hetherington , \" Real - time telephone - based speech recognition in the Jupiter domain , \" Proc .", "label": "", "metadata": {}, "score": "72.87174"}
{"text": "It is not obvious whether very much can be learned by focusing on whether or not there is this kind of extreme specialization .Presumably , what everybody is actually interested in is to try to understand how speech recognition works .", "label": "", "metadata": {}, "score": "72.8947"}
{"text": "The benefit of speech enhancement in the presence of packet loss , without any missing feature reconstruction , can be seen by comparing Table 10 and Table 11 .With speech enhancement and no packet loss compensation , Table 11 shows that Li et al .", "label": "", "metadata": {}, "score": "72.928894"}
{"text": "( PDF ) .C. Cai , P. Guo , J. Glass , and R. Miller , \" Wait Learning : Leveraging Conversational Dead Time for Second Language Education , \" Proc .CHI , Toronto , 2014 .( PDF ) .", "label": "", "metadata": {}, "score": "72.955414"}
{"text": "Signal presence is determined by computing the ratio of the noisy speech power spectrum to its local minimum , which is updated continuously by averaging past values of the noisy speech power spectra with a look - ahead factor .The results in [ 21 ] indicate that the local minimum estimation algorithm adapts very quickly to highly non - stationary noise environments .", "label": "", "metadata": {}, "score": "73.03723"}
{"text": "In electrophysiological studies , such integration windows may be reflected as activity in the gamma and theta bands , respectively .The evidence for a rightward asymmetry of slow integration is growing and the evidence for a leftward asymmetry of rapid integration is unsettled .", "label": "", "metadata": {}, "score": "73.33298"}
{"text": "( PDF ) .M. Korpusik , N. Schmidt , J. Drexler , S. Cyphers , and J. Glass , \" Data Collection and Language Understanding of Food Descriptions , \" IEEE SLT Workshop , South Lake Tahoe , 2014 .( PDF ) . A. Ali , Y. Zhang , P. Cardinal , N. Dahak , S. Vogel , and J. Glass , \" A Complete Kaldi Recipe For Building Arabic Speech Recognition Systems , \" IEEE SLT Workshop , South Lake Tahoe , 2014 .", "label": "", "metadata": {}, "score": "73.35564"}
{"text": "( PDF ) .J. Glass and T.J. Hazen , \" Telephone - based conversational speech recognition in the Jupiter domain , \" Proc .ICSLP , Sydney , November 1998 .( PDF ) . A. Halberstadt and J. Glass , \" Heterogeneous measurements and multiple classifiers for speech recognition , \" Proc .", "label": "", "metadata": {}, "score": "73.44423"}
{"text": "The top - down forward model signals feed to temporal lobe from all connected areas , with a strong contribution from frontal articulatory cortical fields .( Adapted and extended from Klatt ( 1979 ) . )One source of evidence for internal forward models of this type comes from studies on AV integration in speech .", "label": "", "metadata": {}, "score": "73.52029"}
{"text": "V. Zue , S. Seneff , J. Polifroni , M. Phillips , C. Pao , D. Goodine , D. Goddeau , and J. Glass , \" Pegasus : A Spoken Dialogue Interface for Online Travel Planning , \" Speech Communication , 15 , 331 - 340 , 1994 .", "label": "", "metadata": {}, "score": "73.62489"}
{"text": "B. Hsu and J. Glass , \" N - gram Weighting : Reducing Training Data Mismatch in Cross - Domain Language Model Estimation , \" Proc .EMNLP , 828 - 837 , Honolulu , 2008 .( PDF ) .B. Hsu and J. Glass , \" Iterative Language Model Estimation : Efficient Data Structure & Algorithms , \" Proc .", "label": "", "metadata": {}, "score": "73.72763"}
{"text": "Neuroimaging evidence for the psychological reality of these sets has been provided by Phillips et al .( 2000 ) , who found mismatch negativity responses in English subjects between the set of voiced stops /b d g/ and the set of voiceless stops /p t k/.", "label": "", "metadata": {}, "score": "74.19715"}
{"text": "The first filtering stage coarsely reduces the noise and whitens any residual noise while the second stage attempts to remove the residual noise .Filtering is based on the Wiener filter concept and filter optimisation is carried out in the mel - frequency domain .", "label": "", "metadata": {}, "score": "74.23238"}
{"text": "Efficient digital communication protocols .The address - event protocol ( AER ) is a digital communication system optimized for communicating neural representations between chips .In collaboration with researchers from Caltech , we developed auditory chips that used AER for point - to - point communications ; we later extended AER to support multi - chip systems .", "label": "", "metadata": {}, "score": "74.63899"}
{"text": "Efficient digital communication protocols .The address - event protocol ( AER ) is a digital communication system optimized for communicating neural representations between chips .In collaboration with researchers from Caltech , we developed auditory chips that used AER for point - to - point communications ; we later extended AER to support multi - chip systems .", "label": "", "metadata": {}, "score": "74.63899"}
{"text": "ICASSP , 4481 - 4484 , Taipei , April 2009 .( PDF ) .B. Hsu and J. Glass , \" Language Model Parameter Estimation Using User Transcriptions , \" Proc .ICASSP , 4805 - 4808 , Taipei , April 2009 .", "label": "", "metadata": {}, "score": "74.670654"}
{"text": "ASRU , 272 - 275 , Kyoto , December 2007 .( PDF ) .G. Choueiter , S. Seneff , and J. Glass , \" Automatic Lexical Pronunciations Generation and Update , \" Proc .ASRU , 225 - 228 , Kyoto , December 2007 .", "label": "", "metadata": {}, "score": "74.688095"}
{"text": "Whereas in the visual case the image can be fractionated into different spatial scales , in the auditory case both frequency and time can be thought of as dimensions along which one could fractionate the signal .We pursue the hypothesis that auditory signals are processed in time windows of different sizes , or durations .", "label": "", "metadata": {}, "score": "74.70697"}
{"text": "The ETSI basic front - end [ 6 ] was developed for implementation over circuit - switched channels and this implementation is also considered in the other three standards .The advanced front - end [ 7 ] produces superior performance to the basic front - end , and was designed to increase robustness in background noise .", "label": "", "metadata": {}, "score": "74.716675"}
{"text": "Comparing Table 9 with Table 11 , a significant reduction in recognition performance is observed in the presence of packet loss , in particular for channels C and D where the probability of packet loss is 50 % .When nearest neighbour repetition is used to reconstruct missing features , Table 12 shows that there is a significant increase in recognition performance across all channels when compared to the results presented in Table 11 .", "label": "", "metadata": {}, "score": "74.89976"}
{"text": "The word accuracies for each of the Aurora test sets presented throughout this chapter are calculated according to [ 16 ] , which defines the performance measure for a test set as the word accuracy averaged over all noises and over all SNRs between 0 dB and 20dB.", "label": "", "metadata": {}, "score": "75.00829"}
{"text": "Speech enhancement .Additive noise from interfering noise sources , and convolutional noise arising from transmission channel characteristics both contribute to a degradation of performance in automatic speech recognition systems .This section addresses the problem of robustness of speech recognition systems in the first of these conditions , namely additive noise .", "label": "", "metadata": {}, "score": "75.02835"}
{"text": "Feature vectors were extracted directly from the enhanced speech with no intermediate processing .The recognition experiments used vectors that include 13 static coefficients along with velocity and acceleration coefficients .This results in vectors with an overall dimension equal to 39 .", "label": "", "metadata": {}, "score": "75.07649"}
{"text": "With the emergence of high - performance speaker - independent systems , a great barrier to man - machine interface has been overcome .This work describes our next step to improve the usability of speech recognizers --- the use of vocabulary - independent ( VI ) models .", "label": "", "metadata": {}, "score": "75.20143"}
{"text": "With the emergence of high - performance speaker - independent systems , a great barrier to man - machine interface has been overcome .This work describes our next step to improve the usability of speech recognizers --- the use of vocabulary - independent ( VI ) models .", "label": "", "metadata": {}, "score": "75.20143"}
{"text": "11 - \" RTP Payload Formats for European Telecommunications Standards Institute ( ETSI ) European Standard ES 202 050 , ES 202 211 , and 202 212 Distributed Speech Recognition Encoding \" , in RFC 4060 , May 2005 .14 - Q. Li , F. K. Soong and O. Siohan , \" A high - performance auditory feature for robust speech recognition \" , in Proc . of 6th International Conference on Spoken Language Processing ( ICSLP ) , Beijing , China , Oct. 2000 , pp .", "label": "", "metadata": {}, "score": "75.25167"}
{"text": "The result is to generate a new vector sequence Y i that is related to X i by .In order for the interleaver to carry out the reordering of the feature vectors , it is necessary to buffer the vectors , which introduces a delay .", "label": "", "metadata": {}, "score": "75.37987"}
{"text": "These same four channels are used here to determine the effect of packet loss on speech recognition performance .The parameter values for the four channels are detailed in Table 6 .These parameters result from work in [ 33 ] on IP and wireless networks .", "label": "", "metadata": {}, "score": "75.43482"}
{"text": "Odyssey Speaker and Language Recognition Workshop , Brno , 2010 .( PDF ) .I. McGraw , C.Y. Lee , L. Hetherington , S. Seneff and J. Glass , \" Collecting Voices from the Cloud , \" Proc .International Conference on Language Resources and Evaluation , 1576 - 1583 , Malta , 2010 .", "label": "", "metadata": {}, "score": "75.46245"}
{"text": "Recent comparative studies have shown the superior performance of DSR to codec - based ASR [ 4 ] .However , in a DSR system , transmission errors in the form of random packet loss and packet burst loss still need to be taken into consideration .", "label": "", "metadata": {}, "score": "75.860176"}
{"text": "r method produced any improvement .Finally , we investigated corrective training for semicontinuous models .We found that this method is effective if top- 1 ( or discrete HMM ) decoding is used .However , if the recognition algorithm considers top N codewords , while the corrective t .. ...", "label": "", "metadata": {}, "score": "75.95926"}
{"text": "r method produced any improvement .Finally , we investigated corrective training for semicontinuous models .We found that this method is effective if top- 1 ( or discrete HMM ) decoding is used .However , if the recognition algorithm considers top N codewords , while the corrective t .. ...", "label": "", "metadata": {}, "score": "75.95926"}
{"text": "Subsequent to the initial hypotheses triggered by the construction of the PPS , a cohort - type selection is elicited from the articulator - bound ( place ) features .In this way , we try to have our cake and eat it too - trying to capture both ( gross ) neighbourhood and ( gross ) cohort - model effects .", "label": "", "metadata": {}, "score": "76.283554"}
{"text": "Silicon audition prototypes typically used off - chip potentiometers for parameter control .In collaboration with Alan Kramer we developed an on - chip , non - volatile analog memory architecture , which can be programmed via a microprocessor - compatible asynchronous bus .", "label": "", "metadata": {}, "score": "76.370445"}
{"text": "Silicon audition prototypes typically used off - chip potentiometers for parameter control .In collaboration with Alan Kramer we developed an on - chip , non - volatile analog memory architecture , which can be programmed via a microprocessor - compatible asynchronous bus .", "label": "", "metadata": {}, "score": "76.370445"}
{"text": "Experiments using the Aurora connected - digit recognition framework [ 16 ] found that the best performance was obtained using the method of Agarwal and Chang [ 25 ] .The test results also suggest that the choice of speech enhancement algorithm for best speech recognition performance is independent of the choice of front - end .", "label": "", "metadata": {}, "score": "76.39552"}
{"text": "Pulse coding is an important part of many silicon auditory models ; we developed microwatt versions of popular spiking circuits . . .We combined these technologies to produce several generations of analog - to - digital converter chips .An early generation device was featured in our article in June 1994 edition of IEEE Micro .", "label": "", "metadata": {}, "score": "76.512886"}
{"text": "Pulse coding is an important part of many silicon auditory models ; we developed microwatt versions of popular spiking circuits . . .We combined these technologies to produce several generations of analog - to - digital converter chips .An early generation device was featured in our article in June 1994 edition of IEEE Micro .", "label": "", "metadata": {}, "score": "76.512886"}
{"text": "The primary issues of kernel design for subband components of acoustic waveforms and combination of the individual subband classifiers using stacked generalization are addressed .Ex ... \" .A subband acoustic waveform front - end for robust speech recognition using support vector machines ( SVMs ) is developed .", "label": "", "metadata": {}, "score": "76.607216"}
{"text": "( PDF ) .K. Livescu and J. Glass , \" Feature - based pronunciation modeling with trainable asynchrony probabilities .\"Proc .ICSLP , Jeju , October 2004 .( PDF ) .K. Livescu and J. Glass , \" Feature - based pronunciation modeling for speech recognition .", "label": "", "metadata": {}, "score": "76.65724"}
{"text": "The problem is further complicated by the large number of non - native accents , which makes modeling separate accents di#cult , as well as the small amount of non - native speech that is often available for training .Previous work has attempted to address this issue by building accent - specific acoustic and pronunciation models or by adapting acoustic models to a particular non - native speaker .", "label": "", "metadata": {}, "score": "76.71268"}
{"text": "A comparison of Table 10 with Table 11 illustrates the benefit of using speech enhancement in improving recognition performance .Comparing Table 11 with Table 9 ( no packet loss ) it is seen that packet loss has a significant impact on the recognition results , in particular for channels C and D where the probability of packet loss is 50 % .", "label": "", "metadata": {}, "score": "77.22306"}
{"text": "The following four parameters define the model , and from these parameters the transition probabilities of the 3-state model can be determined : .The authors in [ 33 ] suggest that an alternative to performing speech recognition tests using simulated channels is to define a set of packet loss characteristics , thus enabling recognition performance to be analysed across a range of different packet loss conditions .", "label": "", "metadata": {}, "score": "77.270355"}
{"text": "Eurospeech , Aalborg , September 2001 .( PDF ) .M. Nakano , T. Minami , S. Seneff , T. J. Hazen , D. Scott Cyphers , J. Glass , J. Polifroni , V. Zue , \" Mokusei : A telephone - based Japanese conversational system in the weather domain , \" Proc .", "label": "", "metadata": {}, "score": "77.42879"}
{"text": "This section examines the performance of a DSR system in the presence of both background noise and packet loss .Channel models and loss compensation .A DSR client and server may be interconnected over either a circuit - switched channel or a packet - switched channel .", "label": "", "metadata": {}, "score": "77.622025"}
{"text": "It is further suggested in [ 38 ] that , for a DSR application , it is more beneficial to trade delay for accuracy rather than trading bit - rate for accuracy as in forward error correction schemes .Reference [ 35 ] combines block interleaving to reduce burst lengths on the client side with packet loss compensation at the server side .", "label": "", "metadata": {}, "score": "77.809906"}
{"text": "In particular , with feature reconstruction channel C shows improvements in recognition accuracy greater than 55 % for both front - ends .Channel D also shows good improvement .Nearest neighbour repetition gives a slightly higher performance compared to Hermite interpolation .", "label": "", "metadata": {}, "score": "77.94214"}
{"text": "However , the high complexity prevents these models from practical system .In this paper we present a framework to reduce the computational complexity of segment model by fixing the number of the basic unit in the segment to share the intermediate computation results .", "label": "", "metadata": {}, "score": "77.96431"}
{"text": "Whereas visual leads are tolerated very well in perceptual experiments , auditory leads are more detrimental .Is such a result plausible from a more ecological perspective ?We believe such a psychophysical result follows from the fact that movement of the articulators naturally precedes auditory speech output .", "label": "", "metadata": {}, "score": "78.08211"}
{"text": "In contrast to the supra - additivity prediction , the experiment showed that the auditory - evoked N1 and P2 responses were actually reduced in amplitude in the AV case .The amplitude reduction of both the N1 and the P2 were independent of the stimulus .", "label": "", "metadata": {}, "score": "78.12564"}
{"text": "We are , therefore , not at all hostile to all episodic effects in models of speech perception .However , we are against episodic models insofar as they are not just episodic but also explicitly anti - abstractionist .It seems to us an unnecessary consequence to discard abstraction because there is evidence for episodic encoding .", "label": "", "metadata": {}, "score": "78.16847"}
{"text": "( student paper award ) ( PDF ) .J. Liu , P. Pasupat , S. Cyphers , and J. Glass , \" Asgard : A Portable Architecture for Multilingual Dialogue Systems , \" Proc .ICASSP , Vancouver , 2013 .", "label": "", "metadata": {}, "score": "78.321655"}
{"text": "The dorsal pathway implicated in auditory tasks includes temporo - parietal , parietal and frontal areas .The specific computational contribution of each area is not yet understood for either where / how tasks in hearing or speech perception tasks .However , there is evidence , from the domain of speech processing , that a temporo - parietal area plays an important role in the ( hypothesized ) coordinate transformation from auditory to motor coordinates .", "label": "", "metadata": {}, "score": "78.537766"}
{"text": "The coefficients .a . a . a . 2 and .a .3 in ( 6 ) are determined from the two correctly received feature vectors either side of the loss burst , .x .b and .x .", "label": "", "metadata": {}, "score": "78.74957"}
{"text": "undergo post - processing in the cepstral domain by means of cepstral mean subtraction ( CMS ) .As defined by the ETSI advanced front - end [ 7 ] , each packet transmitted over the communication channel carries two feature vectors .", "label": "", "metadata": {}, "score": "79.00725"}
{"text": "20 Hz ) temporal analyses .Naturally , multiresolution processing is but one of many relevant implementational issues , but it has received recent empirical support in both human and animal studies ( Boemio et al .2005 ; Narayan et al .", "label": "", "metadata": {}, "score": "79.361946"}
{"text": "The use of the Internet for accessing information has expanded dramatically over the past few years , while the availability and use of mobile hand - held devices for communication and Internet access has greatly increased in parallel .Industry has reacted to this trend for information access by developing services and applications that can be accessed by users on the move .", "label": "", "metadata": {}, "score": "79.413956"}
{"text": "But , crucially , what happens when both signals are presented at the same time ( dichotically ) ?Many patterns could be obtained .The two signals could destructively interfere with each other , yielding low - intelligibility scores ; the signals could be processed independently , yielding no net gain overall ; the two signals could interact and yield an additive or even a supra - additive effect .", "label": "", "metadata": {}, "score": "79.55409"}
{"text": "The FFT magnitude coefficients are grouped into the appropriate critical bands and then weighted by the triangular filters .The energies in each band are summed , creating a filter bank vector of spectral energies on the mel scale .The size of this vector of spectral energies is equal to the number of triangular filters used .", "label": "", "metadata": {}, "score": "79.90323"}
{"text": "( PDF ) .J. Glass , T. Hazen , S. Cyphers , I. Malioutov , D. Huynh , and R. Barzilay , \" Recent Progress in the MIT Spoken Lecture Processing Project , \" Proc .Interspeech , 2553 - 2556 , Antwerp , August 2007 .", "label": "", "metadata": {}, "score": "80.03003"}
{"text": "As a fairly clear example , the feature [ + round ] defines the connection between the motor gesture of lip rounding ( the enervation of the orbicularis oris muscle ) and the perceptual pattern of a down sweep in frequencies across the whole spectral range .", "label": "", "metadata": {}, "score": "80.0518"}
{"text": "Cambridge , MA : MIT Press .Abstracts for Nelson H. Morgan .The EECS Research Summary for 2003 .Large Vocabulary Automatic Speech Recognition on Emerging Architectures .Adam Janin ( Professor Nelson H. Morgan ) ( NSF ) IIS-0121396 and Swiss Research Network IM2 .", "label": "", "metadata": {}, "score": "80.37013"}
{"text": "Engineering research into creating comprehensive auditory models , and applying them to practical problems , flourished in the 1980s and 1990s .Examples from that era include : .Why Silicon Audition ?Engineering systems based on auditory models require substantial computational resources , especially when judged by the state of the art of computing in the early 1990s .", "label": "", "metadata": {}, "score": "80.43687"}
{"text": "Engineering research into creating comprehensive auditory models , and applying them to practical problems , flourished in the 1980s and 1990s .Examples from that era include : .Why Silicon Audition ?Engineering systems based on auditory models require substantial computational resources , especially when judged by the state of the art of computing in the early 1990s .", "label": "", "metadata": {}, "score": "80.43687"}
{"text": "With Hermite interpolation , Table 13 shows that the front - end of Li et al .outperforms the ETSI advanced front - end for the packet loss conditions of channels A and B , however , for channel C the reverse is the case .", "label": "", "metadata": {}, "score": "80.45888"}
{"text": "In this section , the 3-state model proposed in [ 33 ] is used to simulate packet loss and loss bursts .To compensate for missing packets , two error - concealment methods are examined , namely nearest neighbour repetition and interpolation .", "label": "", "metadata": {}, "score": "80.66058"}
{"text": "Packet loss parameters .Packet loss mitigation .Two error concealment methods are examined , namely nearest neighbour repetition and interpolation .These methods attempt to reconstruct the feature vector stream when packet loss is detected .Missing feature vectors are estimated solely from correctly received feature vectors .", "label": "", "metadata": {}, "score": "80.67273"}
{"text": "In particular , Bourhis & Giles ( 1977 ) were able to produce accent divergence by Welsh speakers to an English - speaking authority figure by having the authority figure profess derogatory attitudes towards the Welsh language and culture .The speech of the Welsh speakers showed more Welsh characteristics after demeaning questions than after neutral questions .", "label": "", "metadata": {}, "score": "81.21219"}
{"text": "1379 - 1398 , Oct. 2006 .33 - B.P. Milner and A.B. James , \" An analysis of packet loss models for distributed speech recognition \" , in Proc . of 8th International Conference on Spoken Language Processing ( ICSLP ) , Jeju Island , Korea , Oct. 2004 , pp . 1549 - 1552 .", "label": "", "metadata": {}, "score": "81.49393"}
{"text": "The first of these [ 10 ] specifies the real - time transport protocol ( RTP ) payload format for the basic front - end while the second [ 11 ] specifies the RTP payload format for the advanced front - end .", "label": "", "metadata": {}, "score": "81.62566"}
{"text": "Deletions ( D ) - A word in the original sentence is missed .Insertions ( I ) - A new word is inserted between two words of the original sentence .The performance measure used throughout the work presented here , and also used in [ 16 ] , is the word accuracy as defined by ( 1 ): .", "label": "", "metadata": {}, "score": "81.733154"}
{"text": "Figure 2 .Aurora 2 database .The recognition problem examined in this work is connected digit recognition using the Aurora 2 database [ 16 ] .The motivation behind the creation of the Aurora database was to provide a framework that allowed for the evaluation and comparison of speech recognition algorithms in noisy conditions , thus providing a good basis for comparison between researchers .", "label": "", "metadata": {}, "score": "82.23091"}
{"text": "Robust Distributed Speech Recognition Using Auditory Modelling .[ 1 ] School of Engineering , Athlone Institute of Technology , Athlone , , Ireland .[ 2 ] College of Engineering and Informatics , National University of Ireland , Galway , , Ireland .", "label": "", "metadata": {}, "score": "82.41998"}
{"text": "To allow for close comparison between the ETSI advanced front end and the front - end proposed by Li et al . , the VQ codebooks for Li et al . should be determined in the same manner as the VQ codebooks for the ETSI advanced front - end .", "label": "", "metadata": {}, "score": "82.6134"}
{"text": "This allows an efficient , regular implementation .On IRAM , we arrange batches of words with total length equal to the vector length .On Imagine , we batch words such that the total length will fit in the cluster memory .", "label": "", "metadata": {}, "score": "82.97401"}
{"text": "The Gilbert model was found in [ 3 ] to be inadequate for simulating a GSM channel and instead a two - fold stochastic model is used in which there are two processes , namely shadowing and Rayleigh fading .This same model was used by [ 32 ] , again to model a GSM network .", "label": "", "metadata": {}, "score": "83.68676"}
{"text": "Speech enhancement , no error mitigation .Two methods , nearest neighbour repetition and Hermite interpolation , are used to reconstruct the feature vector stream as a result of missing features due to packet loss .Table 12 details the recognition results obtained when using nearest neighbour repetition while Table 13 details the results obtained when Hermite interpolation is implemented ( speech enhancement is used in both cases ) .", "label": "", "metadata": {}, "score": "83.689735"}
{"text": "What is now owed is a set of linking hypotheses from auditory - based representations of that type to whatever machinery or representational structure underlies further , language - based processing .Why ?Because the recognized item typically enters into phonological and morphological operations ( say , pluralization ) as well as syntactic ones ( say , subject - predicate agreement , viz . '", "label": "", "metadata": {}, "score": "84.40965"}
{"text": "These algorithms do speed up SM greatly but they are still far slower than HMM , since the computation of these algorithms is based on segment while HMM is based on frame .In our study , we propose a ... . \" ...", "label": "", "metadata": {}, "score": "84.82834"}
{"text": "The importance of reducing the average burst length of lost feature vectors rather than reducing the overall packet loss rate is central to the work in these papers .By minimising the average burst length , the estimation of lost feature vectors is more effective .", "label": "", "metadata": {}, "score": "84.88803"}
{"text": "The models are a 2-state Markov chain , the Gilbert - Elliot model and a 3-state Markov chain .The 2-state Markov chain in [ 33 ] uses State 1 to model a correctly received packet and State 2 to model a lost packet .", "label": "", "metadata": {}, "score": "84.93187"}
{"text": "However , large vocabulary , robust ASR requires hardware resources far beyond those available on current PDAs .Emerging architectures , such as Vector IRAM at UC Berkeley , and Imagine at Stanford , provide a partial solution by delivering very high performance for relatively little expenditure of power .", "label": "", "metadata": {}, "score": "85.00892"}
{"text": "The hypothesized representation of the word cat in the mind / brain of the speaker / listener .Each of the three segments of this consonant - vowel - consonant word is built from distinctive features that as a bundle are definitional of the segment .", "label": "", "metadata": {}, "score": "85.20473"}
{"text": "EuroSpeech 89 , 1989 . \" ...With the emergence of high - performance speaker - independent systems , a great barrier to man - machine interface has been overcome .This work describes our next step to improve the usability of speech recognizers --- the use of vocabulary - independent ( VI ) models .", "label": "", "metadata": {}, "score": "85.379295"}
{"text": "EuroSpeech 89 , 1989 . \" ...With the emergence of high - performance speaker - independent systems , a great barrier to man - machine interface has been overcome .This work describes our next step to improve the usability of speech recognizers --- the use of vocabulary - independent ( VI ) models .", "label": "", "metadata": {}, "score": "85.379295"}
{"text": "ICSLP , Beijing , October 2000 .( PDF ) .J. Glass , J. Polifroni , S. Seneff and V. Zue , \" Data collection and performance evaluation of spoken dialogue systems : The MIT experience , \" Proc .ICSLP , Beijing , October 2000 .", "label": "", "metadata": {}, "score": "85.60027"}
{"text": "The results suggest that for packet loss compensation , the decoder - based strategy is best .This is especially true in the presence of large bursts of losses as the accuracy of reconstruction methods falls off rapidly as burst length increases .", "label": "", "metadata": {}, "score": "85.65539"}
{"text": "Interleaving .Research has shown that by minimising the average burst length of lost vectors the estimation of lost feature vectors is more effective [ 34 ] .The aim of interleaving is to break a long loss burst into smaller loss bursts by distributing them over time and so making it appear that the errors are more randomly distributed .", "label": "", "metadata": {}, "score": "85.694565"}
{"text": "The \" sil \" model has 3 states and each state has 6 mixtures .The \" sp \" model has a single state .The Baum - Welch re - estimation algorithm is applied in the training of the word models .", "label": "", "metadata": {}, "score": "85.78279"}
{"text": "We also investigated creating complete audio signal processing systems that operation in the micropower regime .This research was in collaboration with Richard Lippmann , MIT Lincoln Labs .This paper describes a power management architecture for DSP systems that uses micropower analog processing .", "label": "", "metadata": {}, "score": "85.965614"}
{"text": "We also investigated creating complete audio signal processing systems that operation in the micropower regime .This research was in collaboration with Richard Lippmann , MIT Lincoln Labs .This paper describes a power management architecture for DSP systems that uses micropower analog processing .", "label": "", "metadata": {}, "score": "85.965614"}
{"text": "The three models in [ 33 ] are all validated for GSM and wireless local area network ( WLAN ) channels .Results indicate that the 3-state Markov model gives the best results overall and this model is used in the work described here ; the model is described in more detail later in this chapter .", "label": "", "metadata": {}, "score": "86.699005"}
{"text": "The first makes use of physical layer models that simulate transmission phenomena that occur on the physical channel .The second category involves the use of statistical models that model unconditional packet loss probability and conditional packet loss burst lengths .This is the approach used in this chapter .", "label": "", "metadata": {}, "score": "87.05101"}
{"text": "Such periods of low speech energy occur between words or syllables in an utterance and during speech pauses .The energy of the signal during these periods reflects the noise power level .Martin 's minimum statistics noise estimation method tracks the short - term power spectral density estimate of the noisy speech signal in each frequency bin separately .", "label": "", "metadata": {}, "score": "87.11763"}
{"text": "Several generations of improved designs followed , including work by : .Lloyd Watts .Rahul Sarpeshkar .Andreas Andreou .Andre van Schaik .Neal A. Bhadkamkar .Shihab Shamma .Mohammed Ismail .Chris Toumazou . and their respective collaborators .", "label": "", "metadata": {}, "score": "87.321884"}
{"text": "Several generations of improved designs followed , including work by : .Lloyd Watts .Rahul Sarpeshkar .Andreas Andreou .Andre van Schaik .Neal A. Bhadkamkar .Shihab Shamma .Mohammed Ismail .Chris Toumazou . and their respective collaborators .", "label": "", "metadata": {}, "score": "87.321884"}
{"text": "n . 1 , and their first derivatives , .x .b and .x .b .n .Equation ( 6 ) can be rewritten as .x .^ .b .n .x .b .", "label": "", "metadata": {}, "score": "87.35576"}
{"text": "The noise signals added are chosen to reflect environments in which telecommunication terminals are used .In total there are eight different noise types : subway , babble , car , exhibition hall , restaurant , street , airport and train station .", "label": "", "metadata": {}, "score": "88.42047"}
{"text": "There are eleven whole word HMMs each with 16 states ; each state has 3 Gaussian mixtures .The topology of the models is left - to - right without any skips over states .This topology is suitable for modelling the sequential nature of speech and the consecutive states represent the consecutive speech states in a particular utterance .", "label": "", "metadata": {}, "score": "89.08394"}
{"text": "The length of this thesis including footnotes and appendices is approximately ... \" .This dissertation is the result of my own work and includes nothing which is the outcome of work done in collaboration , except where stated .It has not been submitted in whole or part for a degree at any other university .", "label": "", "metadata": {}, "score": "89.34662"}
{"text": "The length of this thesis including footnotes and appendices is approximately ... \" .This dissertation is the result of my own work and includes nothing which is the outcome of work done in collaboration , except where stated .It has not been submitted in whole or part for a degree at any other university .", "label": "", "metadata": {}, "score": "89.34662"}
{"text": "The sum of these two delays is known as the latency of the interleaving / de - interleaving process .The spread S of an interleaver is a metric that indicates how good an interleaver is at breaking up error bursts .", "label": "", "metadata": {}, "score": "90.06705"}
{"text": "J. Glass , E. Weinstein , S. Cyphers , J. Polifroni , G. Chung , and M. Nakano , \" A Framework for Developing Conversational User Interfaces , \" Proc .CADUI , Madeira , 354 - 365 , Portugal , January 2004 .", "label": "", "metadata": {}, "score": "90.31886"}
{"text": "The research programme we have outlined has implications for some of issues in speech perception research that tend to elicit high blood pressure .We briefly mention some of the consequences of our proposal for two major issues here .First , there have been many discussions on the question of whether speech is ' special ' .", "label": "", "metadata": {}, "score": "90.35118"}
{"text": "In [ 27 - 29 ] , a voice over IP ( VoIP ) channel is simulated using such a model .References [ 30 , 31 ] simulate IP channels and use a 2-state Gilbert model to simulate burst type packet loss on the channel .", "label": "", "metadata": {}, "score": "90.35768"}
{"text": "Packet loss can arise in wireless and packet switched ( IP ) networks , both networks over which a DSR system would normally be expected to operate .Packet loss , in particular packet burst loss , can have a serious impact on recognition performance and needs to be considered in the design of a DSR system .", "label": "", "metadata": {}, "score": "90.77675"}
{"text": "Interpolation .The disadvantage of stationary periods that arise with nearest neighbour repetition can be alleviated somewhat by polynomial interpolation between the correctly received feature vectors either side of a loss burst .Reference [ 34 ] found that non - linear interpolation using cubic Hermite polynomials gives the best estimates for missing feature vectors .", "label": "", "metadata": {}, "score": "90.86862"}
{"text": "John Lazzaro 's graduate work at Caltech , in collaboration with Carver Mead and Richard Lyon , focused on circuit models beyond cochlear mechanics , as did contemporaneous work by Andre van Schaik and collaborators , and by Richard Lyon .Silicon Audition at UC Berkeley .", "label": "", "metadata": {}, "score": "92.16007"}
{"text": "John Lazzaro 's graduate work at Caltech , in collaboration with Carver Mead and Richard Lyon , focused on circuit models beyond cochlear mechanics , as did contemporaneous work by Andre van Schaik and collaborators , and by Richard Lyon .Silicon Audition at UC Berkeley .", "label": "", "metadata": {}, "score": "92.16007"}
{"text": "That is , rules of pronunciation traffic in natural classes of sounds rather than individual sounds .Likewise , in word - final position Korean neutralizes all coronal obstruents /t t h c c h s s'/ to the plain coronal stop /t/ ( Martin 1951 ) .", "label": "", "metadata": {}, "score": "92.20134"}
{"text": "The 14 coefficients ( C 1 to C 12 , C 0 & lnE ) are grouped into pairs , and each pair is quantized using its own vector quantisation ( VQ ) codebook .The resulting set of index values is then used to represent the feature vector .", "label": "", "metadata": {}, "score": "92.27414"}
{"text": "Packet loss framework .Packet loss model .The packet loss model used in this work is the 3-state Markov chain proposed by [ 33 ] .This 3-state model was found to be more effective at simulating different packet loss conditions in comparison with a 2-state Markov chain and the Gilbert - Elliot model .", "label": "", "metadata": {}, "score": "93.15351"}
{"text": "From 1991 to 1997 , we focused on creating technology that would bring silicon audition to commercial viability .In this section , we review some highlights of this research ; see this annotated bibliography and this concise bibliography for a complete listing of the results of the project .", "label": "", "metadata": {}, "score": "93.180466"}
{"text": "From 1991 to 1997 , we focused on creating technology that would bring silicon audition to commercial viability .In this section , we review some highlights of this research ; see this annotated bibliography and this concise bibliography for a complete listing of the results of the project .", "label": "", "metadata": {}, "score": "93.180466"}
{"text": "by Nelson Morgan , Qifeng Zhu , Andreas Stolcke , Kemal S\u00f6nmez , Sunil Sivadas , Mari Ostendorf , Pratibha Jain , Hynek Hermansky , Dan Ellis , Barry Chen , \u00d6zgur \u00c7etin , Herv\u00e9 Bourlard , Marios Athineos . \" ...", "label": "", "metadata": {}, "score": "94.54062"}
{"text": "Long periods of fading in a wireless network can result in bursts of packet loss .The authors in [ 33 ] measured the characteristics of an IP network and a WLAN , and the results showed the packet loss rate ( \u03b1 ) and the burst length ( \u03b2 ) to be highly variable .", "label": "", "metadata": {}, "score": "97.42479"}
{"text": "First , we compared the complexity of SM with HMM and proposed a fast SM framework based on the comparison .Second we use two examples to illustrate this framework .The fast SMs have better performance than the system based on HMM , and at the mean time , we successfully keep the computation complexity of SM at the same level of HMM . ...", "label": "", "metadata": {}, "score": "97.857216"}
{"text": "Occupancy of states 1 and 3 indicate no packet loss while occupancy of state 2 indicates packet loss .In Figure 3 , Q , q and Q ' are the self - loop probabilities of states 1 , 2 and 3 respectively .", "label": "", "metadata": {}, "score": "103.75668"}
{"text": "t .x .b .t .t .x .b .t .t .t .x .b .t .t .n . where .t .n .It was found in [ 34 ] that performance was better when the derivative components in ( 7 ) are set to zero .", "label": "", "metadata": {}, "score": "107.35553"}
{"text": "In an IP network , packet loss arises primarily due to congestion at the routers within the network , due to high levels of IP traffic .The nature of IP traffic is that it can be described as being ' bursty ' in nature with the result that packet loss occurs in bursts .", "label": "", "metadata": {}, "score": "108.426"}
