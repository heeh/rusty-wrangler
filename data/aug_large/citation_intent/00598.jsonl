{"text": "The use of an SVM classifier decreases the number of failed s - probing iterations by a factor two , and increases the percent- age of successful s - probing iterations from 8 % to 15 % .These improvements come at essentially no cost .", "label": "", "metadata": {}, "score": "34.604664"}
{"text": "Details on the choice of xiand S are given in Section 3 .This probing algorithm potentially requires a significant amount of CPU time .To limit this drawback , we use a Support Vector Machine ( SVM ) classifier [ 7 ] before performing a Branch - and - Bound search , to predict the success or fail- ure of the search .", "label": "", "metadata": {}, "score": "39.524582"}
{"text": "Thus L1 , L2-regularized / loss linear binary SVM solver , LR and Multi - class classification , and cross validation for model selection will be included into my proposal .-One and One - vs .-Others schemes .", "label": "", "metadata": {}, "score": "39.965073"}
{"text": "In each class , the same proportion is present in each random partition to divide instances into m parts .In training and validation , k - fold Cross - Validations ( CVs ) were applied to the m-1 parts of instance vectors .", "label": "", "metadata": {}, "score": "41.464962"}
{"text": "Additionally , we exclude points ( 0,0,yi ) from the data set D on which the model is trained ; this yields an additional advantage that will be discussed in Section 5 . 5 Computational experiments We implemented Aggressive Probing within Couenne , an open - source Branch- and - Bound solver for nonconvex MINLPs [ 11].", "label": "", "metadata": {}, "score": "42.21168"}
{"text": "We used a superset of the test problems described in Section 5.1 , including some additional problems from MINLPLib as well as problems from [ 19 ] with less than 1,000 variables , giving a .Page 10 .A probing algorithm for MINLP 9 Without SVM Probing + FBBT + Conv .", "label": "", "metadata": {}, "score": "42.221947"}
{"text": "Each parameter was considered only when appropriate ; e.g. , d was used for the polynomial kernel only .Overall , we tested 1,057 combinations of input parameters .In our first set of experiments pertaining to the training of an SVM on D , we performed 3-fold cross validation .", "label": "", "metadata": {}, "score": "42.81327"}
{"text": "Along with their corresponding labels of expression levels , 652 instance vectors were used on training and validation by 10-fold CVs .By using three 1vs1 classifiers , the prediction class of an instance vector was determined by a majority voting .", "label": "", "metadata": {}, "score": "43.219704"}
{"text": "Similar to flatSVM , 652 instance vectors with 87 features were applied to 10-fold CVs on training and validation of the first classifier .However , for the first classifier , instance vectors labelled with soluble and insoluble were treated as one class .", "label": "", "metadata": {}, "score": "44.09889"}
{"text": "Besides , cross validation for model selection also can take advantage of such coarse - grained parallelism .3.3.1 Multi - class Classification based on MapReduce Framework In SVM , multi - class classification can be decomposed as a set of binary classifiers , and the classifiers are independent to each other , in this sense , the multi - classification can take advantage of MapReduce framework .", "label": "", "metadata": {}, "score": "44.678974"}
{"text": "Now let 's apply some kernel to the SVM .The complete code can be found here .The resulting clusters are shown in the figure below .In this example , we will use the option enforcing n - fold cross validation in svmtrain , which is simply put the ' -v n ' in the parameter section , where n denote n - fold cross validation .", "label": "", "metadata": {}, "score": "45.553658"}
{"text": "# of classes : 2 # of data : 20,242 / 677,399 ( testing ) # of features : 47,236 Files : rcv1_train .These latest accuracy values on 20 newsgroups seem waaay too high .In my experience getting 99.9 % right on any real problem has always implied that I have introduced a target leak .", "label": "", "metadata": {}, "score": "45.89946"}
{"text": "In this code we want to illustrate how to perform classification using n - fold cross validation , which is a common methodology to use when the data set does not have explicit training and test set separately .Such data sets usually come as a single set and we will need to separate them into n equal parts / folds .", "label": "", "metadata": {}, "score": "46.04963"}
{"text": "hierSVM .For our third method , class labels were considered as attribute vectors instead of arbitrary numbers and involved the concept of hierarchical classification method [ 32 ] .Because of resource availability constraints , we did not implement the entire algorithm .", "label": "", "metadata": {}, "score": "46.111023"}
{"text": "( libsvm : get - svr - probability model ) 1d0 .( destructuring - bind ( l y x ) l - problem-3 - 7 .( dotimes ( i l ) .( multiple - value - bind ( v e ) .", "label": "", "metadata": {}, "score": "46.281578"}
{"text": "So far , all functionalities almost be done except parallel parameter selection .For the case in Liblinear , which needs all training samples in each training process , it 's difficult to leverage the MapReduce framework to improve the performance , include the multi - class classification and parameter selection .", "label": "", "metadata": {}, "score": "46.92397"}
{"text": "I will introduce them separately . 3.1 Data Handler Due to all the packages Mahout Core are based on high performance Vector ( DenseVector or SparseVector ) , the data handler is also based on them .The dataset ( Vectors ) can be stored on personal computer or on Hadoop cluster .", "label": "", "metadata": {}, "score": "46.94618"}
{"text": "In this data set , continuous features are discretized into quantiles , and each quantile is represented by a binary feature .Also , a categorical feature with m categories is converted to m binary features .Details on how each feature is converted can be found in the beginning of each file from this page .", "label": "", "metadata": {}, "score": "47.050056"}
{"text": "Then libsvm does not need the original .training / testing sets .Assume there are L training instances x1 , ... , xL and .Let K(x , y ) be the kernel .value of two instances x and y.", "label": "", "metadata": {}, "score": "47.123596"}
{"text": "Can I use weka in java to classify one sample ... .I 'm currently trying to preprocess my training data ready for a multi - layered perceptron .The data I downloaded consists of 20,000 instances and 16 attributes , all of which are coordinate values of ... .", "label": "", "metadata": {}, "score": "47.22735"}
{"text": "Can I use weka in java to classify one sample ... .I 'm currently trying to preprocess my training data ready for a multi - layered perceptron .The data I downloaded consists of 20,000 instances and 16 attributes , all of which are coordinate values of ... .", "label": "", "metadata": {}, "score": "47.22735"}
{"text": "The procedure of training and testing was repeated for n times .Finally , performance results of these n repeats were averaged and their corresponding SDs were measured .flatSVM .According to the hierarchical structure as shown in Figure 1 , we treated this binary - tree taxonomy as a flat one .", "label": "", "metadata": {}, "score": "47.395977"}
{"text": "( 2 ) Write a .m files in the current directory as follows , and run . global preprocess ; . %Normalize the data . %Evaluation Method : 0 : Train - Test .Split ; 1 : Cross Validation .", "label": "", "metadata": {}, "score": "47.3973"}
{"text": "For a perfect case , all instance vectors of soluble and insoluble used in first step were promoted to train the second classifier .Hence , 207 soluble cases and 212 insoluble cases were used for 10-fold CVs for training and validation .", "label": "", "metadata": {}, "score": "47.493534"}
{"text": "For unigram , the number of features is 254 .Contact us if you need scripts to obtain the data from the original documents .Note that the trigram version contains only 680,715 nonzero feature columns .Is it possible to get a Z - score from sklearn 's svm implementation ?", "label": "", "metadata": {}, "score": "47.564964"}
{"text": "Those are then wrapped in a Runnable which ... .I am using InputMappedClassifer in weka to replace all the missing attribute values by a missing value ( \" ? \" ) but for some reason I still get the Value not defined for given nominal attribute exception ... .", "label": "", "metadata": {}, "score": "47.66819"}
{"text": "Those are then wrapped in a Runnable which ... .I am using InputMappedClassifer in weka to replace all the missing attribute values by a missing value ( \" ? \" ) but for some reason I still get the Value not defined for given nominal attribute exception ... .", "label": "", "metadata": {}, "score": "47.66819"}
{"text": "We report the percentage of optimality gap closed at the end of the optimization process , the number of nodes , and the total CPU time .When Ag- gressive Probing is used , we additionally report the optimality gap closed by probing at the root ( after recomputing the convexification ) and the corresponding CPU time .", "label": "", "metadata": {}, "score": "47.74406"}
{"text": "I have a SVM model consisting of 6 classes and 19 features .It works well , 95 % accuracy .I 'm evaluating , how to get the last 5 % .My idea is to create other models with other features , train instances .", "label": "", "metadata": {}, "score": "47.810024"}
{"text": "I have 100 instances and each instance has 400 attributes most of which have a single value .However some attributes have multiple values as ... .Within a university course I have some features of images ( as text files ) .", "label": "", "metadata": {}, "score": "47.888214"}
{"text": "I have 100 instances and each instance has 400 attributes most of which have a single value .However some attributes have multiple values as ... .Within a university course I have some features of images ( as text files ) .", "label": "", "metadata": {}, "score": "47.888214"}
{"text": "Similar techniques have been applied to MINLPs as well [ 5].In this paper , we propose a probing technique based on truncated Branch - and-Bound searches .Let \u00af z be the objective value of the best solution of the original problem found so far .", "label": "", "metadata": {}, "score": "47.89183"}
{"text": "In summary , on all but one test instance , Aggressive Probing is able to provide better variable bounds compared to traditional bound - tightening techniques ( FBBT followed by OBBT ) .This comes at a large computational cost , but may be worth the effort for some difficult instances that can not be solved otherwise , or when parallel computing resources provide a large amount of CPU power .", "label": "", "metadata": {}, "score": "47.916718"}
{"text": "Finally , 617 features for each instance vector were generated ( cf .Table 2 ) .617 features were extracted from an entire recombinant fusion protein .They were divided into two groups with respect to nucleotide or protein levels .", "label": "", "metadata": {}, "score": "48.181"}
{"text": "Reducer then calls a binary SVM classifier to train a model for this category and emits the model as Reducer 's output .3.3.2 Parallel Model Selection Similar to Multi - Class Classification , SVM Model selection is stacked with a set of binary classifier .", "label": "", "metadata": {}, "score": "48.465202"}
{"text": "This page contains many classification , regression , multi - label and string data sets stored in LIBSVM format .Many are from UCI , Statlog , StatLib and other collections .We thank their efforts .For most sets , we linearly scale each attribute to [ -1,1 ] or [ 0,1].", "label": "", "metadata": {}, "score": "48.773468"}
{"text": "In its simplest form , the associated optimization problem can be written as : min s.t . ?h ?Page 8 .The mapping is implicit because we do not need explicit knowledge of the feature space .In the optimization problem ( SVM ) , we express the separating hyperplane in terms of the training points zi(see", "label": "", "metadata": {}, "score": "48.84928"}
{"text": "I will introduce them separately .2.1 Data Handler The dataset can be stored on personal computer or on Hadoop cluster .This framework provides high performance Random Loader , Sequential Loader for accessing large - scale data .Besides , cross validation for model selection also can take advantage of such coarse - grained parallelism .", "label": "", "metadata": {}, "score": "48.86415"}
{"text": "Additionally , we excluded the instances for which Aggressive Probing was able to find the optimal solution and provide an optimality certificate in less than 2 hours .These are easy instances that can be quickly solved by default Couenne , therefore there is no need for expensive bound - tightening methods .", "label": "", "metadata": {}, "score": "48.903793"}
{"text": "Apparently , the functionalities of Pegasos package on Mahout and LIBLINEAR are quite similar to each other .The whole picture of interfaces is illustrated in Figure 1 : .The unified interface has two main parts : 1 ) Dataset loader , 2 ) Algorithms .", "label": "", "metadata": {}, "score": "48.955574"}
{"text": "All the functionalities suppose to be implemented except probability estimates and weights for unbalanced data ( If time permitting , I would like to do so ) .-One and One - vs .-Others schemes .Apparently , the functionalities of Pegasos package on Mahout and LIBLINEAR are quite similar to each other .", "label": "", "metadata": {}, "score": "49.008022"}
{"text": "2 ) Performance improvement .For example : news20 , the original c / c++ implementation spends 9.4s , our method uses 33.1s by using L2-R L2-Loss SVM .Further improvement will be conducted in coming weeks . 3 )", "label": "", "metadata": {}, "score": "49.29372"}
{"text": "Example 5 .Classify the data in example.data using the Diverse Density algorithm and evaluate it using leave_ont_out scheme .The DD algorithm uses 20 random starting points and combines the results of the 20 runs by averaging .MIL_run('classify -t example.data -- leave_one_out -- DD -NumRuns 20 -Aggregate avg ' ) ; .", "label": "", "metadata": {}, "score": "49.355774"}
{"text": "Given such an SVM model , we proceed as follows .Page 9 . 8 Nannicini et al . probing iteration as if the s - probing iteration failed .If wj ?Note that we could apply the SVM classifier even on points of the form ( 0,0 ) .", "label": "", "metadata": {}, "score": "49.44211"}
{"text": "Each data point .has one label ( the color ) which must be 1 , 2 , or 3 and two . attributes ( x - axis and y - axis values ) in [ 0,1].Type ' make ' in respective directories to build them .", "label": "", "metadata": {}, "score": "49.574104"}
{"text": "I suppose I need to select best attributes for better accuracy .I tried to select attributes using InfoGainAttributeEval and Ranker method ... .Quite a simple question : I am a beginner in using Weka , but I just wanted to know the percentiles ( for example quartiles , quantiles etc ) for one of my numeric attributes .", "label": "", "metadata": {}, "score": "49.699757"}
{"text": "I suppose I need to select best attributes for better accuracy .I tried to select attributes using InfoGainAttributeEval and Ranker method ... .Quite a simple question : I am a beginner in using Weka , but I just wanted to know the percentiles ( for example quartiles , quantiles etc ) for one of my numeric attributes .", "label": "", "metadata": {}, "score": "49.699757"}
{"text": "A full description of FBBT can be found in [ 12,13].The other aspects of the Branch - and - Bound algorithm are similar to those of any Branch - and - Bound for solving MILPs ; see [ 5 ] for more details .", "label": "", "metadata": {}, "score": "49.752228"}
{"text": "( : return - type nil )( : library svm - so ) ) .( ffi : def - call - out svm_predict_values2 ( : name \" svm_predict_values \" ) .( : arguments ( model model ) ( x ( c - array - ptr node ) ) .", "label": "", "metadata": {}, "score": "49.935364"}
{"text": "By using an SVM classifier , we predict success or failure of each iteration of Aggressive Probing , where the prediction is based on features of the algorithm 's input .Skipping the probing iterations likely to fail saves on average 30 % of the com- puting time .", "label": "", "metadata": {}, "score": "50.040695"}
{"text": "As this approach is computationally expensive , we use a Support - Vector - Machine classifier to infer whether or not the probing algorithm should be used .Computational experiments demonstrate that the use of this classifier saves a substantial amount of CPU time at the cost of a marginally weaker bound tightening .", "label": "", "metadata": {}, "score": "50.20895"}
{"text": "For debugging ... .I am using opencv249 and Visual Studio 2013 .I would like to extract features of rectangle regions(25x25 ) of an image .Then , I would like to train them with two classes .I implemented those stuff in ... .", "label": "", "metadata": {}, "score": "50.24209"}
{"text": "Finally , SVM is a parameterized method allowing better control of the trade - off between Precision and Recall of the classifier ( see below for details ) than simpler methods .Because we are interested in a classifier with high Precision and good Recall , the ability to tune the classifier is an advantage .", "label": "", "metadata": {}, "score": "50.336723"}
{"text": "Page 3 . 2 Nannicini et al .with tighter bounds resulting generally in a tighter convexification .As such , bound tightening is an important part of any MINLP solver .Probing is a bound - tightening technique often applied to Mixed Integer Lin- ear Programs(MILPs ) [ 6].", "label": "", "metadata": {}, "score": "50.420166"}
{"text": "We found that if we remove those less important features from our feature set , it will result in a lower accuracy .For instance , after doing feature selection and keeping 37 the most important features , the testing accuracy will dramatically decrease from 87.84 % to 45.95 % in one of the best cross - validation model in flatSVM .", "label": "", "metadata": {}, "score": "50.424156"}
{"text": "The rest 530 features were retrieved from protein sequences .Three SVM - based methods for classification .Support Vector Machines ( SVMs ) are one type of machine learning techniques used for classification and regression originally developed by Vapnik based on the statistical learning theory [ 19 ] .", "label": "", "metadata": {}, "score": "50.845154"}
{"text": "In the page is metioned ... .I 'm trying to use libsvm via its Python binding with a precomputed gram matrix ( numpy array ) .I 'm using 10-fold cross - validation to compute accuracies .", "label": "", "metadata": {}, "score": "51.015545"}
{"text": "Libsvm is a simple , easy - to - use , and efficient software for SVM . classification and regression .It solves C - SVM classification , nu - SVM . classification , one - class - SVM , epsilon - SVM regression , and nu - SVM . regression .", "label": "", "metadata": {}, "score": "51.093647"}
{"text": "Preprocessing : Instance - wise normalization to mean zero and variance one .Then feature - wise normalization to mean zero and variance one .The original dataset consists of 49 instances .Five are removed since the classification results using immunohistochemistry and protein immunoblotting assay confilcted .", "label": "", "metadata": {}, "score": "51.1086"}
{"text": "It is known that SVM is very sensitive to its algorithm settings , hence a grid search on a set of input parameters is typically applied in order to find the values that yield the best performance on the input data .", "label": "", "metadata": {}, "score": "51.13553"}
{"text": "The algorithm was described as follows .Here , the first three digits in attribute vectors were associated to the original labels in the order of soluble , insoluble , and non - expression .The last digit in attribute vectors represented the common parent node of labels between soluble and insoluble proteins in class taxonomy .", "label": "", "metadata": {}, "score": "51.20374"}
{"text": "In particular , we are able to solve a difficult MINLPLib instance , waterz , for the first time , and we obtain better lower bounds ( or a smaller enumeration tree ) for other instances .Page 17 . 16Nannicini et al .", "label": "", "metadata": {}, "score": "51.232765"}
{"text": "The code divides the data into 2 parts % train : 1 to 200 % test : 201:270 % Then plot the results vs their true class .In order to visualize the high % dimensional data , we apply MDS to the 13D data and reduce the dimension % to 2D .", "label": "", "metadata": {}, "score": "51.443455"}
{"text": "[HFY11a ] .Preprocessing : The file \" url_original.tar .bz2 \" contains a directory 121 days , in which the file \" FeatureTypes \" gives indices of real - valued features ( other features are 0/1 ) .The file \" url_combined .", "label": "", "metadata": {}, "score": "51.552"}
{"text": "The resulting model consisted of 4,500 to 5,000 support vectors .Such a large number of support vectors would yield a slow classifier and may indicate overfitting .To obtain a model with fewer support vectors , we first attempted \u03bd - classification [ 14 ] , without success .", "label": "", "metadata": {}, "score": "51.58592"}
{"text": "for class -1 .Do five - fold cross validation for the classifier using . model output_file .Obtain a model with probability information and predict test data with .probability estimates .Precomputed Kernels .Users may precompute kernel values and input them as training and .", "label": "", "metadata": {}, "score": "51.699905"}
{"text": "In : Proceedings of CPAIOR 2010 .Volume 6140 of Lecture Notes in Computer Science .Springer ( 2010 ) 186 - 202 9 .Mark \u00b4 ot , M.C. , Schichl , H. : Comparison and automated selection of local optimiza- tion solvers for interval global optimization methods .", "label": "", "metadata": {}, "score": "51.705345"}
{"text": "By cooperating with kernel functions , SVMs map original data that are non - linearly separable in input space into a high - dimensional feature space .In this paper , expression level prediction of recombinant fusion proteins was formulated as a three - class classification problem ; i.e. , soluble , insoluble , and non - expression .", "label": "", "metadata": {}, "score": "51.845352"}
{"text": "This set of cases is used in both training and evaluation of our models .We evaluate three different models based on the support vector machines ( SVM ) and their ensembles .Unlike many previous works , these models consider the sequence of the target protein as well as the sequence of the whole fusion vector as the features .", "label": "", "metadata": {}, "score": "51.88712"}
{"text": "Therefore , bound - tightening techniques aim to deduce improved variable bounds implied by the constraint structure of the subproblem , and are widely used by existing software , such as Baron [ 10 ] and Couenne [ 11 ] , for the solution of MINLPs .", "label": "", "metadata": {}, "score": "51.913754"}
{"text": "The value of z(P ) for each instance was obtained from the MINLPLib website .Results are reported in Table 1 .The fraction of tightened variables is relative to the number of original variables for \" Probing \" .For \" Probing + FBBT + Conv . \" , it is relative to the total number of variables , because auxiliary variables can also be tightened after bound propagation through FBBT .", "label": "", "metadata": {}, "score": "51.959152"}
{"text": "Note that in each line the numbers must be separated by comma ; blanks and tabs can be added for better separation .An example data file is given below , where the first ( negative ) bag has two instances and the second ( positive ) one has three instances .", "label": "", "metadata": {}, "score": "52.017906"}
{"text": "The data are shuffled and normalized to [ 0,1 ] before classification .MIL_run('classify -t example.data -sf 1 -n 1 -- cross_validate -t 5 -- DD -NumRuns 10 -Aggregate avg ' ) ; .You might need to run \" clear global preprocess ; \" before classification to clean the global variable \" preprocess \" .", "label": "", "metadata": {}, "score": "52.10444"}
{"text": "The . java - files appear in the project , but I get a lot of error messages because ... .I am using WEKA for text classification .When I use the J48 algorithm for creating the classifier , it runs on test set with no problem .", "label": "", "metadata": {}, "score": "52.10858"}
{"text": "The . java - files appear in the project , but I get a lot of error messages because ... .I am using WEKA for text classification .When I use the J48 algorithm for creating the classifier , it runs on test set with no problem .", "label": "", "metadata": {}, "score": "52.10858"}
{"text": "I am wondering how can I encode an output model of M5Rules into a C program that could be embedded in an energy consumption simulator .The complete model is ... .I have my dataset split into two parts - training and testing ( 70/30 split ) .", "label": "", "metadata": {}, "score": "52.1481"}
{"text": "I am wondering how can I encode an output model of M5Rules into a C program that could be embedded in an energy consumption simulator .The complete model is ... .I have my dataset split into two parts - training and testing ( 70/30 split ) .", "label": "", "metadata": {}, "score": "52.1481"}
{"text": "The List is 1000 Vectors long and Vector length is of 10.000 double values each .100 vectors represent one class ( 100 samples per class ) so ... .So I tried using the snowfall package for parallel execution in R , using all my cpu cores .", "label": "", "metadata": {}, "score": "52.320576"}
{"text": "The List is 1000 Vectors long and Vector length is of 10.000 double values each .100 vectors represent one class ( 100 samples per class ) so ... .So I tried using the snowfall package for parallel execution in R , using all my cpu cores .", "label": "", "metadata": {}, "score": "52.320576"}
{"text": "clisp / modules / libsvm test.tst , NONE , 1.1 svm.xml , NONE , 1.1 .svm.h , NONE , 1.1 svm.cpp , NONE , 1.1 link.sh , NONE , 1.1 .libsvm.lisp,NONE , 1.1 README , NONE , 1.1 Makefile , NONE , 1.1 .", "label": "", "metadata": {}, "score": "52.53038"}
{"text": "By repeating the same procedure of training and testing in ten times , an average and SD were calculated for these ten CV results .All programs were implemented and associated with LIBSVM package [ 30 ] .nestSVM .Following the procedure of transcribing and translating a recombinant fusion protein in E. coli , the hierarchical structure was divided into two steps .", "label": "", "metadata": {}, "score": "52.551823"}
{"text": "Shuffle the data before classification .Use 10-fold cross - validation to evaluate the performance .MIL_run('classify -t example.data -sf 1 -- cross_validate -t 10 -- kNN -RefNum 5 -CiterRank 5 ' ) ; .Example 3 .Classify the data in example.data using the bag - level SVM variant for MIL .", "label": "", "metadata": {}, "score": "52.57187"}
{"text": "For an one - class model , +1 or -1 is . returned .This function conducts cross validation .Data are separated to .nr_fold folds .Under given parameters , sequentially each fold is . validated using the model from training the remaining .", "label": "", "metadata": {}, "score": "52.670906"}
{"text": "Variables are processed in the order in which they are stored in Couenne .Note that Couenne uses a standardized representation of the problem where extra variables , called auxiliary variables , are typically .Page 14 .A probing algorithm for MINLP 13 added to represent expressions in the original problem formulation [ 5].", "label": "", "metadata": {}, "score": "52.74185"}
{"text": "I have some texts and i would like to mine these by implementing Machine Learning methods in Java using Weka libraries .For that purpose , i 've already did something so far but since whole code is too ... .", "label": "", "metadata": {}, "score": "52.77681"}
{"text": "I have some texts and i would like to mine these by implementing Machine Learning methods in Java using Weka libraries .For that purpose , i 've already did something so far but since whole code is too ... .", "label": "", "metadata": {}, "score": "52.77681"}
{"text": "Sch\u00a8 olkopf , B. , Smola , A.J. : Learning with Kernels : Support Vector Machines , Regularization , Optimization , and Beyond .MIT Press , Cambridge , MA ( 2002 ) 16 .Achterberg , T. , Koch , T. , Martin , A. : Branching rules revisited .", "label": "", "metadata": {}, "score": "52.78106"}
{"text": "In fact , we can just use the original codes ( svmtrain and svmpredict ) from the libsvm package to do the job by making a \" wrapper code \" to call the original code one pair at a time .The good news is that libsvm tutorial page provides a wrapper code to do so already .", "label": "", "metadata": {}, "score": "52.822945"}
{"text": "plying our probing technique to difficult instances P to improve a Branch - and-Bound search ; thus , in our implementation Aggressive Probing reuses as much previously computed information as possible .The branching strategy of Couenne was set to Strong Branching [ 5,16 ] in all experiments .", "label": "", "metadata": {}, "score": "52.87755"}
{"text": "For the case in Liblinear , which needs all training samples in each training process , it 's difficult to leverage the MapReduce framework to improve the performance , include the multi - class classification and parameter selection .Although I 've done a parallel classifier for multi - class problem using the same framework with Pegasos ( Mahout-232 ) , I believe parallel liblinear could be useless within such framework .", "label": "", "metadata": {}, "score": "52.97744"}
{"text": "Finally , for training and validation , two positive cases and two negative cases were used .For testing , 6 pairs of subtractions between attribute vectors of labels were applied to predict and averaged to decide the final prediction label .", "label": "", "metadata": {}, "score": "52.999584"}
{"text": "one method .Thus L1 . , L2-regularized / loss linear binary SVM solver , LR and Multi - class classification , and cross validation for model selection will be included into my proposal .-One and One - vs .", "label": "", "metadata": {}, "score": "53.002632"}
{"text": "Page 11 .10 Nannicini et al . total of 84 instances .We applied Aggressive Probing on all variables , with a time limit of 30 seconds for each s - probing iteration , 1 minute for each variable bound , and 2 hours per problem instance .", "label": "", "metadata": {}, "score": "53.006084"}
{"text": "In this way , 726 scenarios , 121 target genes with six different fusion vectors , were obtained .There were 231 , 236 , and 259 cases for soluble fraction , inclusion fraction , and non - expression , respectively ( cf .", "label": "", "metadata": {}, "score": "53.133904"}
{"text": "Currently , this package supports reading data from disk instead of loading all samples in Memory .-----------------------------------------------------------------------------------------------------------Data Set : Rcv1_train .zhao zhendong added a comment - 29/Jul/10 15:53 Three major revisions : 1 ) Fix a bug , previous accuracies are in - correct .", "label": "", "metadata": {}, "score": "53.161476"}
{"text": "Page 7 . 6 Nannicini et al .Supported by this observation , we use the following strategy .In the remainder of this section we discuss our choice of the bound reduction measure and the decision method .4.1 Measuring the effect of FBBT Several bound - reduction measures are possible .", "label": "", "metadata": {}, "score": "53.23394"}
{"text": "I have two data sets which are the same in layout and attribute names but the values ... .I am trying to use SVM classifier in Weka .I downloaded weka-3 - 7 - 13 version .When i click on the classifier tab , SVM is not in the list .", "label": "", "metadata": {}, "score": "53.250954"}
{"text": "I have two data sets which are the same in layout and attribute names but the values ... .I am trying to use SVM classifier in Weka .I downloaded weka-3 - 7 - 13 version .When i click on the classifier tab , SVM is not in the list .", "label": "", "metadata": {}, "score": "53.250954"}
{"text": "Here , three SVM - based methods were proposed to deal with the three - class classification problem .With respect to different aspects of considering the hierarchical structure formed by expression levels of recombinant fusion proteins , instance vectors were treated as flat , nested , or hierarchical ones .", "label": "", "metadata": {}, "score": "53.306557"}
{"text": "Results and discussion .Predictive performance of our proposed SVM - based methods .In order to investigate expression levels of target proteins cloned into individual fusion vectors , six three - class classifiers were trained and assessed by applying flatSVM .", "label": "", "metadata": {}, "score": "53.576183"}
{"text": "In only two cases ( nsv24 and tln6 ) , using SVM for failure prediction results in an overall longer probing time , but the increase is negligible .Summarizing , using an SVM model to predict likely failures of the Aggressive Probing algorithm leads to CPU time savings that depend on the problem instance at hand and are sometimes very large , sometimes moderate , while variable bounds are tightened by almost the same amount .", "label": "", "metadata": {}, "score": "53.660313"}
{"text": "( function - documentation , set - function - documentation ) : do not fallthrough on subr .Index : NEWS .RCS file : /cvsroot / clisp / clisp / src / NEWS , v . retrieving revision 1.340 . retrieving revision 1.341 .", "label": "", "metadata": {}, "score": "53.735695"}
{"text": "Some training data are further separated to \" training \" ( tr ) and \" validation \" ( val ) sets .Details can be found in the description of each data set .To read data via MATLAB , you can use \" libsvmread \" in LIBSVM package .", "label": "", "metadata": {}, "score": "53.738388"}
{"text": "( let ( ( nodes ( aref x i ) ) ) .( terpri out ) ) ) .( provide \" libsvm \" ) .Take Surveys .Earn Cash .Influence the Future of IT .Join SourceForge.net 's Techsay panel and you 'll get the chance to share your .", "label": "", "metadata": {}, "score": "53.80586"}
{"text": "We also plot the decision values in the feature space just to give an idea how the decision boundary looks like . demo_libsvm_test6 .m . multiclass , OVR .no , manually . leave - one - out n - fold cross validation . default .", "label": "", "metadata": {}, "score": "53.89622"}
{"text": "Model ensemble of proposed methods .To investigate the diversity of our proposed methods , we calculated Yule 's Q - statistic between pairs of proposed methods .The results in Table 6 indicate that each method permit to train a classifier in a partial un - correlation .", "label": "", "metadata": {}, "score": "53.910637"}
{"text": "As shown in Figure 1 , three expression levels of recombinant proteins in SDS - PAGE experiments were soluble fraction , inclusion fraction , and non - expression .Hence , after screening solubility of 121 target proteins in six different fusion vectors , the model of expression and solubility of entire recombinant proteins , including given genes and fusion vectors , was formulated as a three - class classification problem .", "label": "", "metadata": {}, "score": "54.088413"}
{"text": "The observations with identical run number will be grouped together into a fold .It is a preference to have observations from all the classes within a certain fold .In fact , assigning the run number to each observation randomly is fine as well . demo_libsvm_test7 .", "label": "", "metadata": {}, "score": "54.31781"}
{"text": "I have 26 classes in total but I am not able to classify using SVM in R. I can classify the images ... .My colleague and I are trying to wrap our heads around the difference between logistic regression and an SVM .", "label": "", "metadata": {}, "score": "54.399017"}
{"text": "According to their previously observed sequence - dependent features in protein levels , Idicula - Thomas et al . provided a SVM - based approach to achieve 72 % in prediction accuracy [ 21 , 22 ] .Additionally , Smialowski et al .", "label": "", "metadata": {}, "score": "54.417137"}
{"text": "Although I 've done a parallel classifier for multi - class problem using the same framework with Pegasos ( Mahout-232 ) , I believe parallel Liblinear could be useless within such framework .In this sense , it 's almost impossible can be applied to large - scale data .", "label": "", "metadata": {}, "score": "54.427048"}
{"text": "Although I 've done a parallel classifier for multi - class problem using the same framework with Pegasos ( Mahout-232 ) , I believe parallel Liblinear could be useless within such framework .In this sense , it 's almost impossible can be applied to large - scale data .", "label": "", "metadata": {}, "score": "54.427048"}
{"text": "Naturally , SVM is a binary classification model , how can we use SVM in the multi - class scenario ?In this example , we will show you how to do multi - class classification using libsvm .A simple strategy is to do binary classification 1 pair at a time .", "label": "", "metadata": {}, "score": "54.445213"}
{"text": "a file for later use .Once an SVM model is available , you can use it . to classify new data .This function constructs and returns an SVM model according to .the given training data and parameters . struct svm_problem describes the problem : . struct svm_problem . int l ; . where ' l ' is the number of training data , and ' y ' is an array containing .", "label": "", "metadata": {}, "score": "54.48208"}
{"text": "One interesting paper has been published by Libsvm(liblinear ) group , which listed in my last post .zhao zhendong added a comment - 02/Aug/10 13:53 - edited Could we load the data set into HBase for further randomly accessing ?", "label": "", "metadata": {}, "score": "54.48952"}
{"text": "i am runing NaiveBayes on a cluster of 16 machines first by parallelizing the data , and then performing the learning process .it runs as i expected to .Now the problem that i am facing is trying to ... .", "label": "", "metadata": {}, "score": "54.583786"}
{"text": "For one - class SVM , it 's . not used so can be any number .Except using precomputed kernels .( attribute ) value . is a real number .Indices must be in an ASCENDING order .Labels in the .", "label": "", "metadata": {}, "score": "54.70292"}
{"text": "Inst_MI_SVM .Desc : The mi - SVM as an instance - level SVM variant for MIL [ Andrews et al . , 2002].This classifier is built on the LibSVM package .Options : . -Kernel ( def 2 ) : Type of kernel used in SVM . 0 for linear , 1 for polynomial , 2 for RBF , 3 for sigmoid .", "label": "", "metadata": {}, "score": "54.70601"}
{"text": "The process of training and testing were used to 121 target genes for each vector to train a three - class classifier .All target genes were divided into five parts .Four out of five parts were used to train a classifier by 5-fold CVs .", "label": "", "metadata": {}, "score": "54.793697"}
{"text": "The complete code can be found here .For parameter selection using cross validation , we use the code below to calculate the average accuracy cv .You can just add ' -t x ' to the code .Classification : the ' -t x ' is included in the variable model already , so you do n't need to specify ' -t x ' again when classifying .", "label": "", "metadata": {}, "score": "54.872627"}
{"text": "To the best of our knowledge , an optimality certificate for the solutions to the .Page 16 .A probing algorithm for MINLP 15 Without Aggr .Probing Final Instance Gap % water4 100.00 1751046 20252.1 waterx 30.31 waterz 77.78 11088079 86399.6 Table 3 .", "label": "", "metadata": {}, "score": "54.887833"}
{"text": "First , while considering a proper number of mutation sites in biological laboratories , we limited the maximum steps of mutation sites to five .Meanwhile , to effectively reduce the search space , we employed a beam search for narrowing down the search to the top five potential candidates to be soluble forms , which were predicted by our classifier .", "label": "", "metadata": {}, "score": "54.955334"}
{"text": "For testing the performance of nestSVM , 74 unseen instance vectors were used to predict protein expression by the first binary classifier .In the second binary classifier , it was applied to instances that were labelled as expression in the first step to predict their protein solubility .", "label": "", "metadata": {}, "score": "54.975853"}
{"text": "multi - scale automatic , quite perfect .leave - one - out n - fold cross validation . default and specific kernel are fine here .4-class ring .The code is developed based on _ test12 .The only difference is that this code use n - fold cross validation when classifying the \" single \" data set , i.e. , the data set where both train and test set are combine together -- often found when the number of observations is limited .", "label": "", "metadata": {}, "score": "54.99672"}
{"text": "In order to reduce a hierarchical SVM classification into a binary classification , subtractions between pairs of attribute vectors were taken to implement the idea .For example , when considering an instance vector with its label as soluble , two new attribute vectors of positive cases were produced by subtracting attribute vectors of insoluble and non - expression from attribute vector of soluble , respectively .", "label": "", "metadata": {}, "score": "55.15409"}
{"text": "It looked ... .I am trying to perform cross - validation on my models with multiple classification classes but I am getting errors when trying to update my classperf on each fold .I am getting this error \" Index vector ... .", "label": "", "metadata": {}, "score": "55.200523"}
{"text": "In this section , we report Branch - and - Bound ex- periments with and without Aggressive Probing on a few selected instances .Table 1 indicates that the probing algorithm proposed in this paper may be effective on the three water instances .", "label": "", "metadata": {}, "score": "55.249016"}
{"text": "The svm_rank is running for 3 days and the iteration is over 5000 is this reasonable ?I am trying to perform cross - validation on images for my SVM , where I have 3 categories of labels for the classification , \" Good \" , \" Ok \" and \" Bad \" .", "label": "", "metadata": {}, "score": "55.380142"}
{"text": "My research has involved the large - scale SVM classifier .I have taken part in setting up and maintaining a Hadoop cluster with around 70 nodes in our group .5 References [ 1 ] Rong - En Fan , Kai - Wei Chang , Cho - Jui Hsieh , Xiang - Rui Wang , and Chih - Jen Lin .", "label": "", "metadata": {}, "score": "55.408203"}
{"text": "Top 10 algorithms in data mining .Knowl .Inf .Syst . , 14(1):1 - 37 , 2007 .This proposal will port one of the most famous linear SVM solvers , LIBLINEAR [ 1 ] to mahout with unified interface with Pegasos [ 2 ] on mahout , which is another linear SVM solver and almost finished by myself ( Mahout-232 ) .", "label": "", "metadata": {}, "score": "55.42728"}
{"text": "result contains the overall prediction statistics for the test set , including the classification accuracy of bag labels , and classification accuracy of instances if the algorithm is able to classify instances .Processing Filename : example.data .Classifier : DD -NumRuns 10 -Aggregate avg .", "label": "", "metadata": {}, "score": "55.465702"}
{"text": "In this case , because the interval size is increased in a geometric fashion , in a few it- erations we will reach the scale that is needed for the probing interval to be \" not trivially infeasible \" .This avoids investing all of the CPU time in the first probing iteration in cases where the initial interval - size guess is too large .", "label": "", "metadata": {}, "score": "55.468822"}
{"text": "The sparse format is especially helpful ( actually , necessary ) in application such as text categorization , where each instance ( say , a document or a passage ) is indexed by a term vector which can be of thousands of or even more dimensions .", "label": "", "metadata": {}, "score": "55.503845"}
{"text": "The SVM training procedure is pretty slow , however , especially on the case with large - scale dataset .Nowadays , several literatures propose SVM solvers with linear kernel that can handle large - scale learning problem , for instance , LIBLINEAR [ 1 ] and Pegasos [ 2 ] .", "label": "", "metadata": {}, "score": "55.5609"}
{"text": "The SVM training procedure is pretty slow , however , especially on the case with large - scale dataset .Nowadays , several literatures propose SVM solvers with linear kernel that can handle large - scale learning problem , for instance , LIBLINEAR [ 1 ] and Pegasos [ 2 ] .", "label": "", "metadata": {}, "score": "55.5609"}
{"text": "The SVM training procedure is pretty slow , however , especially on the case with large - scale dataset .Nowadays , several literatures propose SVM solvers with linear kernel that can handle large - scale learning problem , for instance , LIBLINEAR [ 1 ] and Pegasos [ 2 ] .", "label": "", "metadata": {}, "score": "55.5609"}
{"text": "Cai L , Hofmann T : Hierarchical document categorization with support vector machines .Kuncheva LI , Whitaker CJ : Measures of Diversity in Classifier Ensembles and Their Relationship with the Ensemble Accuracy .Mach Learn 2003 , 51 ( 2 ) : 181 - 207 .", "label": "", "metadata": {}, "score": "55.573048"}
{"text": "Chang , C.C. , Lin , C.J. : LIBSVM : a library for support vector machines .Bussieck , M.R. , Drud , A.S. , Meeraus , A. : MINLPLib - a collection of test mod- els for Mixed - Integer Nonlinear Programming .", "label": "", "metadata": {}, "score": "55.591705"}
{"text": "But the results were not better than a simpler method that seems to work well : the initial value of s is chosen to be a small , fixed value size , depending on the variable type .The good performance of the update strategy and the initial choice for the value of s lies in the dynamic and geometric adjustment of the interval length during Aggressive Probing .", "label": "", "metadata": {}, "score": "55.621696"}
{"text": "Machine learning methods have been used in the OR community for various tasks , such as parameter tun- ing [ 8 ] and solver selection [ 9].In this paper , machine learning is used to predict failures of an algorithm based on characteristics of its input data .", "label": "", "metadata": {}, "score": "55.665688"}
{"text": "Reporting a results using n - fold cross validation : In case you have only 1 data set ( i.e. , there is no explicit train or test set ) , n - fold cross validation is a conventional way to assess a classifier .", "label": "", "metadata": {}, "score": "55.72506"}
{"text": "data ' , preprocess.root ) ; .This example will do exactly the same thing as the command line does .Input Formats .The input file containing the training examples can be in two formats : .( 1 ) Normal format ( for instances with non - zero values on most of features ) .", "label": "", "metadata": {}, "score": "55.82899"}
{"text": "-b probability_estimates : whether to train an SVC or SVR model for probability estimates , 0 or 1 ( default 0 ) .-v n : n - fold cross validation mode .The k in the -g option means the number of attributes in the input data .", "label": "", "metadata": {}, "score": "55.898346"}
{"text": "Computational tests demonstrate that our Aggressive Probing algorithm is able to tighten the variable bounds on many instances , even after other bound - tightening techniques have been applied .Because Aggressive Probing can easily be carried out in parallel , it is well- suited for leveraging parallel environments to solve difficult MINLPs .", "label": "", "metadata": {}, "score": "55.994286"}
{"text": "( equalp v - parameter .( ffi : foreign - value ( setq f - parameter ( libsvm : make - parameter .: v v - parameter ) ) ) ) .T . ; ; create an artificial problem : . ; ; predict the remainder of dividion by k from n - digits .", "label": "", "metadata": {}, "score": "56.11467"}
{"text": "For integer variables , we round the probing interval endpoints appropriately .Define a positive number B. Two details of the algorithm still need to be specified : the exit condition and the initial choice of s. We use two exit conditions : a maximum CPU time for the application of Aggressive Probing , and a maximum number of consecutive failed s - probing iterations .", "label": "", "metadata": {}, "score": "56.13945"}
{"text": "We provide preliminary computational results to assess the practical effi- ciency of the approach .The experiments show that the proposed probing algo- rithm is very effective in tightening the variable bounds , and it is helpful for solving MINLPs with Branch - and - Bound .", "label": "", "metadata": {}, "score": "56.24198"}
{"text": "T ) T . ---NEW FILE : Makefile --- .# Makefile for CLISP module set libsvm .all : libsvm.fas svm.so .svm.so : svm.cpp svm.h .$ ( C++ ) $ ( CPPFLAGS ) $ ( MYCFLAGS ) -I$(INCLUDES ) \\ .", "label": "", "metadata": {}, "score": "56.263092"}
{"text": "You can use LIBLINEAR with option -s 3 ( i.e. , l2-regularized l1-loss SVM ) to get auPRC of 0.5773 , similar to 0.5775 reported in Table 2 of Sonnenburg and Franc ( 2010 ) .If you do n't have enough RAM to run LIBLINEAR , you can use the following code at LIBSVM tools and see our experimental log here .", "label": "", "metadata": {}, "score": "56.290382"}
{"text": "Table 1 .Data distribution of three expression levels in six fusion vectors .726 cases comprised 121 genes fused into six fusion vectors generated from HTP systems .Six fusion vectors used in HTP systems .Cloning and expression regions of the six expression vectors and corresponding insertion locations of target proteins were used in this work .", "label": "", "metadata": {}, "score": "56.296272"}
{"text": "MIL_run('classify -t example.data -sf 1 -n 0 -- iterdiscrim_APR ' ) ; .Example 2 .Classify example.data using the Citation - kNN approach for MIL , using min - Hausdorff distance and 3 references and rank-5 citers for each data point .", "label": "", "metadata": {}, "score": "56.383194"}
{"text": "Option : -t ( def -2 ) : Indicate the training - testing splitting boundary as the number of bags from the beginning of the input file .If this option is set to a negative value x , the first 1/(-x ) portion of the data is used for training and the rest are used for testing ( E.g. , -2 means the first half the data for training ) . \u00b7", "label": "", "metadata": {}, "score": "56.383984"}
{"text": "The observations are separated into n folds equally , the code use n-1 folds to train the svm model which will be used to classify the remaining 1 fold according to standard OVR .The code can be found here .Using multiclass ovr - svm with kerne l : So far I have n't shown the usage of ovr - svm with kernel specific ( ' -t x ' ) .", "label": "", "metadata": {}, "score": "56.41602"}
{"text": "[ Andrews et al . , 2002 ] S. Andrews , . I. Tsochantaridis , T. Hofmann .Support Vector Machines for Multiple - Instance Learning .NIPS 2002 .[ Dietterich et al . , 1997 ] T. G. Dietterich , R. H. Lathrop , T. Lozano - Perez .", "label": "", "metadata": {}, "score": "56.41938"}
{"text": "a file , \" run \" button to obtain an SVM model , and \" clear \" . button to clear the window .You can enter options in the bottom of the window , the syntax of . options is the same as ' svm - train ' .", "label": "", "metadata": {}, "score": "56.71956"}
{"text": "This function should be called . before calling svm_get_svr_probability and . svm_predict_probability .This function saves a model to a file ; returns 0 on success , or -1 . if an error occurs .This function returns a pointer to the model read from the file , . or a null pointer if the model could not be loaded .", "label": "", "metadata": {}, "score": "56.73786"}
{"text": "The experiments were conducted on a 2.6 GHz AMD Opteron 852 machine with 64 GB of RAM , running Linux .5.1 Test instances The test instances are a subset of MINLPLib [ 18 ] , a freely available collection of convex and nonconvex MINLPs .", "label": "", "metadata": {}, "score": "56.75496"}
{"text": "For example , . implies that the kernel matrix is .Library Usage .These functions and structures are declared in the header file ' svm.h ' .You need to # include \" svm.h \" in your C / C++ source files and link your . program with ' svm.cpp ' .", "label": "", "metadata": {}, "score": "56.792778"}
{"text": "Tght . %Red .Performance of Aggressive Probing , with and without failure prediction by SVM .We report , after probing ( columns \" Probing \" ) and after applying FBBT and recomputing the convexification ( columns \" Probing + FBBT + Conv . \" ) : the fraction of tightened variables with finite bounds , and the average bound reduction .", "label": "", "metadata": {}, "score": "56.797363"}
{"text": "More information about parameter selection can be found in .tools / README .Installation .On Unix systems , type ' make ' to build the ' svm - train ' and ' svm - predict ' .programs .Run them without arguments to show the usages of them .", "label": "", "metadata": {}, "score": "56.817917"}
{"text": "Tips on practical use . - Examples . -Precomputed Kernels . -Library Usage .- Java Version .- Building Windows Binaries .-Additional Tools : Model Selection , Sub - sampling , etc . .-Python Interface . -", "label": "", "metadata": {}, "score": "56.831425"}
{"text": "Desc : The cross - validation method based on n even partitions of the data .Options : -t ( def 3 ) : The number of folders for cross - validation . \u00b7leave_one_out .Desc : Each time train on all the data except one data item ( bag ) , and test it on the remaining bag .", "label": "", "metadata": {}, "score": "56.860428"}
{"text": "Additionally , based on the undertaking of structural genomics projects , Bertone et al . have applied machine learning techniques such as decision trees and Support Vector Machines ( SVMs ) to discover other informative features based on 562 proteins from Methanobacterium thermoautotrophicum .", "label": "", "metadata": {}, "score": "56.914986"}
{"text": "Options : -m ( def ' ' ) : The input model file .The base classifier options . \u00b7DD .Desc : The diverse density algorithm [ Maron and Lozano - Perez , 1998 ] .Options : . -Scaling ( def 1 ) : Whether to scale different dimensions of the feature space , i.e. , weighting the feature dimensions .", "label": "", "metadata": {}, "score": "56.959824"}
{"text": "If the model is not for svr or does not contain required .information , 0 is returned .This function gives decision values on a test vector x given a . model .For a classification model with nr_class classes , this function .", "label": "", "metadata": {}, "score": "57.03534"}
{"text": "In this model , each class is assumed to be normally distributed , and a 2-dimensional Gaussian model is fit to each class using maximum - likelihood estimation .Then , we classify points in the corresponding test set by computing the probability that they are generated by the two normal distributions and by picking the class that maximizes this probability .", "label": "", "metadata": {}, "score": "57.08003"}
{"text": "Assume the original training data has three four - feature . instances and testing data has one instance : .If the linear kernel is used , we have the following new .training / testing sets : . can be any value .", "label": "", "metadata": {}, "score": "57.08631"}
{"text": "The dataset ( Vectors ) can be stored on personal computer or on Hadoop cluster .This framework provides high performance Random Loader , Sequential Loader for accessing large - scale data .Besides , cross validation for model selection also can take advantage of such coarse - grained parallelism .", "label": "", "metadata": {}, "score": "57.135582"}
{"text": "For the first part , there are two cases predicted by our classifier to change their expression level to soluble forms after one and five steps , respectively .As shown in Figure 5 , this case was originally in the non - expression level , but was predicted as a soluble from after mutating five bases .", "label": "", "metadata": {}, "score": "57.28923"}
{"text": "Hierarchical structure comprising three expression levels in SDS - PAGE .The hierarchical structure consists of three expression levels ; i.e. , soluble fraction , inclusion fraction , and non - expression , in SDS - PAGE .Methods .Data preparation and formulation .", "label": "", "metadata": {}, "score": "57.29733"}
{"text": "c ' and ' svm - predict .c ' .for examples showing how to use them .Before you classify test data , you need to construct an SVM model .( ' svm_model ' ) using training data .", "label": "", "metadata": {}, "score": "57.31431"}
{"text": "Page 5 .Otherwise , it is a failure .In both The Aggressive Probing algorithm for variable xi(see Algorithm 1 ) has an initial value for s as input and runs an s - probing iteration .While an exit condition is not met , if the s - probing iteration is successful , the value of s is doubled and a new s - probing iteration is executed .", "label": "", "metadata": {}, "score": "57.34401"}
{"text": "The reason for excluding s - probing iterations per- formed with less than 20 seconds of CPU time left is that they are likely to fail simply because they are not given enough time to complete , regardless of the difficulty of the s - probing subproblem .", "label": "", "metadata": {}, "score": "57.435665"}
{"text": "( setf ( get : documentation ( sys::%record - ref x 0 ) ) new - value ) ) ) ) .Index : ChangeLog .RCS file : /cvsroot / clisp / clisp / src / ChangeLog , v . retrieving revision 1.5401 . retrieving revision 1.5402 .", "label": "", "metadata": {}, "score": "57.474052"}
{"text": "2 Background A function is factorable if it can be computed in a finite number of simple steps , starting with model variables and real constants , using elementary unary and .Page 4 .A probing algorithm for MINLP3 binary operators .", "label": "", "metadata": {}, "score": "57.492996"}
{"text": "Each sample will be emit N times with different categories ' label , where N is the number of categories in dataset .The class label will be emitted as the key of Mappers ' output .After sorting , all the samples with same class label will be sank into a same Reducer .", "label": "", "metadata": {}, "score": "57.58105"}
{"text": "While using weka SVM , the error is receiving \" libsvm is not in classpath ' .I set the classpath through environmental variables , But the error still remains .I was using the weka svm for one year for ... .", "label": "", "metadata": {}, "score": "57.581837"}
{"text": "While using weka SVM , the error is receiving \" libsvm is not in classpath ' .I set the classpath through environmental variables , But the error still remains .I was using the weka svm for one year for ... .", "label": "", "metadata": {}, "score": "57.581837"}
{"text": "How to obtain the SVM weight vector w : Please see the example code and discussion from StackOverflow .classification separated / n - fold . kernel .data set .description .demo_libsvm_test1 .m . binary .no , manually . separated . default ( RBF ) .", "label": "", "metadata": {}, "score": "57.618755"}
{"text": "The RCV1 numbers are similarly surprising .Can you say a little bit more about where these data sets came from and how they were pre - processed ?Which 20newsgroup dataset ?Which header fields were suppressed ?How was it processed ?", "label": "", "metadata": {}, "score": "57.64987"}
{"text": "L - PROBLEM-2 - 7 .( multiple - value - bind ( p maxindex ) ( libsvm : load - problem \" svm - problem \" ) .( setf ( ffi : slot ( ffi : foreign - value f - parameter ) ' libsvm::gamma ) .", "label": "", "metadata": {}, "score": "57.804405"}
{"text": "( 1 )In Matlab command line , type .MIL_run('classify -t input_file [ options ] [ -- EvaluationMethod [ options ] ] -- BaseClassifier [ options ] ' ) ; .For example , the following command line uses the Diverse Density ( DD ) method to classify the data in train.data , using 10 random starting points and aggregating the results from the 10 runs by average .", "label": "", "metadata": {}, "score": "57.848038"}
{"text": "The average bound reduction is close to 50 % .The amount of optimality gap closed by adding convexification inequalities after tightening the bound is largely problem dependent as well .The new convexification is much stronger for the water , nvs and csched2 instances , but for the remaining instances , the optimality gap is unchanged .", "label": "", "metadata": {}, "score": "57.85118"}
{"text": "Table 3 .Performance evaluation of six individual classifiers with respect to six vectors .For F 1 measure , each individual classifier must correctly identify each instance into its real class .Instead of taking experimental data separately to train six classifiers with respect to each vector , all data were considered together in the following experiments .", "label": "", "metadata": {}, "score": "57.880543"}
{"text": "( integers in classification , real numbers in . regression ) ' x ' is an array of pointers , each of which points to a sparse . representation ( array of svm_node ) of one training vector .For example , if we have the following training data : . LABELATTR1ATTR2ATTR3ATTR4ATTR5 .", "label": "", "metadata": {}, "score": "57.918625"}
{"text": "( : arguments ( model model ) ) .( : return - type double - float ) ) .( ffi : def - call - out svm_predict_values1 ( : name \" svm_predict_values \" ) .( : arguments ( model model ) ( x ( c - array - ptr node ) ) .", "label": "", "metadata": {}, "score": "57.936333"}
{"text": "( print ( list ( aref y i ) ( if e ( princ - to - string e ) v ) ) ) ) ) ) .NIL .( libsvm : destroy - model model ) NIL .( ffi : validp f - problem-3 - 7 ) T .", "label": "", "metadata": {}, "score": "57.962486"}
{"text": "Savelsbergh , M.W.P.:Preprocessing and probing techniques for mixed integer programming problems .ORSA Journal on Computing 6(4 ) ( 1994 ) 445 - 455 7 .Cortes , C. , Vapnik , V. : Support - vector networks .Machine Learning 20 ( 1995 ) 273 - 297 8 .", "label": "", "metadata": {}, "score": "58.24859"}
{"text": "While it could be argued that SVM is not really required for classifying our 2-dimensional data , we use SVM for three reasons .First , in our experiments SVM performs better than a predictor based on a simple Gaussian model for the data , see Section 5.2 .", "label": "", "metadata": {}, "score": "58.27838"}
{"text": "Page 15 .14Nannicini et al .# s - prob . iter .Success Failure 1600 18131 1634 Without SVM With SVM 8998 Table 2 .Number of successful and failed s - probing iterations recorded by applying Aggressive Probing on the full test set of Table 1 . tightening is only slightly weaker .", "label": "", "metadata": {}, "score": "58.327885"}
{"text": "For each test instance , we first apply FBBT and OBBT .Then , for each variable , we apply Aggressive Probing to tighten both the lower and upper bounds , with a time limit of 60 seconds per variable , and 36 hours per instance .", "label": "", "metadata": {}, "score": "58.336304"}
{"text": "The kernel function can be interpreted as the dot - product in the higher - dimensional space .The separation hyperplane in the feature space translates into a nonlinear separation surface in the original space Rp .Further- more , SVM handles data that is not separable in the feature space by using a soft margin , i.e. , allowing the optimal separation hyperplane to misclassify some points , imposing a penalty for each misclassification .", "label": "", "metadata": {}, "score": "58.41388"}
{"text": "my database is YMU database , how should ... .I need to minimize the following equation to implement a c - svm Objective function to be minimized I know that I am supposed to implement stochastic sub - gradient descent algorithm to minimize the above ... .", "label": "", "metadata": {}, "score": "58.618477"}
{"text": "where TP , FP , and FN represent true positive , false positive , and false negative , respectively .Alternatively , the well - known representation of F score for a binary classification is associated with precision and recall , which are denoted as p and r , respectively .", "label": "", "metadata": {}, "score": "58.624966"}
{"text": "The rest data are further splited into training ( 38 ) , and validation ( 4 ) .[SKS03a ] .Preprocessing : The raw data set ( epsilon_train ) is instance - wisely scaled to unit length and split into two parts : 4/5 for training and 1/5 for testing .", "label": "", "metadata": {}, "score": "58.64341"}
{"text": "( setf ( documentation ( find - package \" LIBSVM \" ) ' sys::impnotes ) \" libsvm \" ) .( default - foreign - language : stdc ) .( defconstant svm - so .; ; ; types and constants .", "label": "", "metadata": {}, "score": "58.653454"}
{"text": "In the example below , I will show the nested cross validation .First , we search for the optimal parameters ( c and gamma ) in the big scale , then the searching space is narrowed down until satisfied .The results are compared with the first experiment which does not use the optimal parameters .", "label": "", "metadata": {}, "score": "58.668"}
{"text": "The prons and cons are listed as follows : Prons : All classifiers in Liblinear are quite stable .Whenever training a data set with one certain classifier , we always got extract same object value and accuracy .Cons : Requirement for whole data set could limit the usability of Liblinear , especially , while we need to train a classifier on an extremely large scale data set .", "label": "", "metadata": {}, "score": "58.780724"}
{"text": "The prons and cons are listed as follows : Prons : All classifiers in Liblinear are quite stable .Whenever training a data set with one certain classifier , we always got extract same object value and accuracy .Cons : Requirement for whole data set could limit the usability of Liblinear , especially , while we need to train a classifier on an extremely large scale data set .", "label": "", "metadata": {}, "score": "58.780724"}
{"text": "( : return - type int ) ) .( ffi : def - call - out svm_get_labels ( : library svm - so ) .( : arguments ( model model ) ( label c - pointer ) ) .( : return - type nil ) ) .", "label": "", "metadata": {}, "score": "58.79067"}
{"text": "Each point represents the average values of Precision and Recall corresponding to a set of parameter values .When producing the figure , we eliminated points for which the standard deviation of either Precision or Recall was more than 1/4 of its mean , because these points correspond to experiments with unreliable results .", "label": "", "metadata": {}, "score": "58.859985"}
{"text": "Each code is built for some specific application , which might be useful to the reader to download and tweak just to save your developing time .Big picture : In this scenario , I compiled an easy example to illustrate how to use svm in full process .", "label": "", "metadata": {}, "score": "58.87966"}
{"text": "( T T ) .( let ( ( vec ( libsvm : cross - validation f - problem-2 - 7 v - parameter 3 ) ) ) .( list ( length vec ) ( count 1d0 vec ) ( count -1d0 vec ) ) ) .", "label": "", "metadata": {}, "score": "58.969997"}
{"text": "The format of svm_prob is same as that for svm_train ( ) .This function gives svm_type of the model .Possible values of .svm_type are defined in svm.h .For a classification model , this function gives the number of . classes .", "label": "", "metadata": {}, "score": "59.096264"}
{"text": "So far I 've trained the images using svm.train ( ) method .However , I fail at testing the images .So far My Code for Testing the Images : ... .I labeled some pixels of a picture as foreground and the rest of them are unlabeled yet .", "label": "", "metadata": {}, "score": "59.140118"}
{"text": "Right now , we got almost accuracy as same as original implementation does .2 ) Performance improvement .For example : news20 , the original c / c++ implementation spends 9.4s , our method uses 33.1s by using L2-R L2-Loss SVM .", "label": "", "metadata": {}, "score": "59.15107"}
{"text": "Train a classifier using instance - level SVM from the data in example.data without testing it .Store the model file in model.txt .Use polynomial kernel of 2 degree .MIL_run('classify -t example.data -- train_only -m model.txt -- inst_MI_SVM -Kernel 1 -KernelParam 2 ' ) ; .", "label": "", "metadata": {}, "score": "59.25452"}
{"text": "Inst3,Bag2,1,0.7,0.9 . Inst4,Bag2,0,0.1,0.5 .Inst5,Bag2,1,0.3,0.2 .m file that calls MILL .But this can be skipped since it is the default .( 2 ) Sparse format ( for instances with zero values on most of features ) .Only non - zero features must be presented , while zero - valued features can be skipped .", "label": "", "metadata": {}, "score": "59.49631"}
{"text": "Bound algorithm of Couenne on these instances with a time limit of 24 hours , using the variable bounds obtained after applying FBBT and OBBT at the root node .Then we perform the same experiment using the variable bounds provided by Aggressive Probing with SVM for failure prediction .", "label": "", "metadata": {}, "score": "59.536316"}
{"text": "After calculation , the range of Q varies from -1 to 1 .For statistically independent classifiers , the calculation will be equal to zero .On one hand , the positive value of Q indicates that classifiers tend to identify the same instances correctly .", "label": "", "metadata": {}, "score": "59.54931"}
{"text": "( with - foreign - object ( label ' ( c - array int , ( get - nr - class model ) ) ) .( svm_get_labels model label ) .( foreign - value label ) ) ) .( def - call - out get - svr - probability ( : library svm - so ) .", "label": "", "metadata": {}, "score": "59.570175"}
{"text": "( def - c - type problem ( c - struct list .( l int ) ; number of records .( y ( c - array - ptr double - float ) ) ; of length l ( targets ) .", "label": "", "metadata": {}, "score": "59.858356"}
{"text": "Log Message : . tweak docs .Index : svm.xml .RCS file : /cvsroot / clisp / clisp / modules / libsvm / svm . xml , v . retrieving revision 1.1 . retrieving revision 1.2 .diff -u -d -r1.1 -r1.2 . --- svm.xml4 Oct 2006 00:53:35 -00001.1 .", "label": "", "metadata": {}, "score": "59.870434"}
{"text": "Please help me to overcome this ... .How do I free memory in Java ?I trie using system.gc , but its still take huge memory , when the aplication write in csv its increase and take about 0,6 gb per csv , dokumen contains 1000 ArrayList try ... .", "label": "", "metadata": {}, "score": "59.872543"}
{"text": "Please help me to overcome this ... .How do I free memory in Java ?I trie using system.gc , but its still take huge memory , when the aplication write in csv its increase and take about 0,6 gb per csv , dokumen contains 1000 ArrayList try ... .", "label": "", "metadata": {}, "score": "59.872543"}
{"text": "However , as reported by Hsu et al . , 1vsAll strategy may get a comparable performance as 1vs1 strategy , but it takes much more time on training [ 31 ] .Therefore , considering the cost of training time , we decided to use 1vs1 strategy instead of 1vsAll strategy in this work .", "label": "", "metadata": {}, "score": "59.880493"}
{"text": "( : return - type nil ) ) .( defun cross - validation ( problem param nr_fold ) .( with - foreign - object ( target ' ( c - array double - float . , ( slot ( foreign - value problem ) ' l ) ) ) .", "label": "", "metadata": {}, "score": "59.88298"}
{"text": "To the best of our knowledge , this is the first attempt to consider the entire cloning and expression regions as a whole than focusing only on the sequences of the desired protein as in previous works .The entire cloning and expression regions usually consist of affinity tags and desired proteins for over - expression in recombinant protein production systems .", "label": "", "metadata": {}, "score": "59.92496"}
{"text": "NONE , 1.1 README , NONE , 1.1 Makefile , NONE , 1.1 COPYRIGHT , NONE , 1.1 .To : clisp - cvs@ ... .Update of /cvsroot / clisp / clisp / modules / libsvm .In directory sc8-pr - cvs4 . sourceforge.net:/tmp/cvs-serv19582/modules/libsvm .", "label": "", "metadata": {}, "score": "60.04991"}
{"text": "The rest of this paper is organized as follows .In Section 2 , we introduce the necessary background .In Section 3 , we describe the probing algorithm .In Section 4 , we discuss how we can integrate a machine learning method in our algorithm to save CPU time .", "label": "", "metadata": {}, "score": "60.10234"}
{"text": "( : arguments ( model model ) ( x ( c - array - ptr node ) ) ) .( : return - type double - float ) ) .( ffi : def - call - out svm_predict_probability ( : library svm - so ) .", "label": "", "metadata": {}, "score": "60.15344"}
{"text": "All authors conceived the project and design .YS and PL prepared the data .WC implemented the algorithms , performed the computational experiments , and analyzed the results .UY partly initiated the design of computational analyses .WC , WL , and CH wrote the paper .", "label": "", "metadata": {}, "score": "60.201855"}
{"text": "L - PROBLEM-3 - 7 .( progn .( setf f - parameter ( libsvm : make - parameter : v v - parameter ' LIBSVM::nu 5d-1 . 'LIBSVM::svm_type libsvm : NU_SVR ) .v - parameter ( ffi : foreign - value f - parameter ) ) .", "label": "", "metadata": {}, "score": "60.234432"}
{"text": "I am trying to use SVM classifier in Weka .I downloaded weka-3 - 7 - 13 version .When i click on the classifier tab , SVM is not in the list .How to use SVM in this tool ?", "label": "", "metadata": {}, "score": "60.23936"}
{"text": "+ and makes Support Vector Machines available in CLISP .+ DOCUMENTATION on built - in functions was broken on some platforms .[1569234 ] .Index : ChangeLog .RCS file : /cvsroot / clisp / clisp / src / ChangeLog , v . retrieving revision 1.5402 . retrieving revision 1.5403 .", "label": "", "metadata": {}, "score": "60.29649"}
{"text": "The standard deviation of Precision and Recall for all models achieving a Pareto optimum is fairly small , typically less than 2 .Therefore , we can assume that the performance of the SVM model does not depend heavily on the particular subset of D that is used for training .", "label": "", "metadata": {}, "score": "60.412613"}
{"text": "S olving the multiple - instance problem : a lazy learning approach .Proc .17th Int'l Conf . on Machine Learning , pp .1119 - 1125 , 2000 .[ Zhang and Goldman , 2001 ] Q. Zhang and S. A. Goldman .", "label": "", "metadata": {}, "score": "60.47735"}
{"text": "Bag_MI_SVM .Desc : The MI - SVM as an bag - level SVM variant for MIL [ Andrews et al . , 2002].This classifier is built on the LibSVM package .Options : Same as the options for inst_SVM .", "label": "", "metadata": {}, "score": "60.487747"}
{"text": "The library is in the \" libsvm \" package .Building Windows Binaries .Windows binaries are in the directory ' windows ' .To build them via .Visual C++ , use the following steps : .Open a dos command box and change to libsvm directory .", "label": "", "metadata": {}, "score": "60.507187"}
{"text": "( ( cache_size cache_size ) ( if v - p ( svref v 5 ) 1d2 ) ) .( ( eps eps ) ( if v - p ( svref v 6 ) 1d-3 ) ) .( ( C C ) ( if v - p ( svref v 7 ) 1d0 ) ) .", "label": "", "metadata": {}, "score": "60.538666"}
{"text": "PubMed View Article .Chang CC , Lin CJ : LIBSVM : a library for support vector machines .Hsu CW , Lin CJ : A comparison of methods for multiclass support vector machines .IEEE Trans Neural Netw 2002 , 13 ( 2 ) : 415 - 25 .", "label": "", "metadata": {}, "score": "60.610577"}
{"text": "Genome Res 2004 , 14 ( 10B ) : 2102 - 10 .PubMed View Article .Vapnik VN : The nature of statistical learning theory .New York : Springer ; 1995 .Scholkopf B , Smola AJ : Learning with kernels : support vector machines , regularization , optimization , and beyond .", "label": "", "metadata": {}, "score": "60.825665"}
{"text": "As elucidated in Table 3 , the best performance occurred in the classifiers based on GST vector for the average F 1 measure .The result showed that the classifier of GST vector outperformed other five classifiers trained with respect to other vectors on classifying instances into three expression levels correctly .", "label": "", "metadata": {}, "score": "60.89853"}
{"text": "The first such study was conducted by Wilkinson and Harrison [ 13 ] with a regression model analysis .They concluded five amino acid - dependent factors are discriminative features that correlate to inclusion bodies formation .There were charge average approximation ( Asp , Glu , Lys and Arg ) , turn - forming residue fraction ( Asn , Gly , Pro and Ser ) , cysteine and proline fractions , hydrophilicity and molecular weight .", "label": "", "metadata": {}, "score": "60.910378"}
{"text": "Examples .Scale each feature of the training data to be in [ -1,1].Scaling .factors are stored in the file range and then used for scaling the . test data . tolerance 0.00001 . in the loss function .", "label": "", "metadata": {}, "score": "61.0195"}
{"text": "This performance is comparable to a particular choice of parameters of SVM to obtain high Recall and low Precision .Computational experiments ( not reported in detail ) demonstrate that using the Gaussian model leads to weaker bound tightening compared to SVM , with no saving of CPU time on average .", "label": "", "metadata": {}, "score": "61.047882"}
{"text": "Example 7 .Do 3-folder cross - validate using instance - level SVM on a sparse data set in sparse_example . data .Using linear kernel for the SVM .Enforce the label distribution on the testing data to be the same as in the training data .", "label": "", "metadata": {}, "score": "61.137215"}
{"text": "The samples in one Reducer should with \" -1 \" and \" +1 \" label right now , where \" +1 \" denotes the sample within a certain category while \" -1 \" represents all other samples belong to rest of categories .", "label": "", "metadata": {}, "score": "61.14093"}
{"text": "Rice P , Longden I , Bleasby A : EMBOSS : the European Molecular Biology Open Software Suite .Trends Genet 2000 , 16 ( 6 ) : 276 - 7 .PubMed View Article .Plewczynski D , Tkacz A , Wyrwicz LS , Rychlewski L : AutoMotif server : prediction of single residue post - translational modifications in proteins .", "label": "", "metadata": {}, "score": "61.152256"}
{"text": "2 , where \u03bb , \u03b2 and d are input parameters .Problem - specific kernel functions can be devised as well .The ratio \u03c9 can be adjusted to handle unbalanced data sets where one class is much more frequent than the other .", "label": "", "metadata": {}, "score": "61.154205"}
{"text": "Mathematical Programming 99 ( 2004 ) 563 - 591 5 .Belotti , P. , Lee , J. , Liberti , L. , Margot , F. , W\u00a8 achter , A. : Branching and bounds tightening techniques for non - convex MINLP .", "label": "", "metadata": {}, "score": "61.166016"}
{"text": "Such a classifier is of limited value for our purpose .We are more interested in the region with roughly 80 % Precision and 60 % Recall : approximately 60 % of the unsuccessful probing iterations in the test set are predicted correctly , while keeping good Precision .", "label": "", "metadata": {}, "score": "61.305595"}
{"text": "OutputFlag ) .-dir ( def ' ' ) : The working directory , which is $ MILLRoot .( preprocess .WorkingDir ) .-distrib ( def 0 ) : Enforce the same distribution of bag labels or not , 1 for enforce .", "label": "", "metadata": {}, "score": "61.344204"}
{"text": "Unlike normal kNN , it not only considers the data points considered as neighbors of the current point in question ( references ) , but also those that consider the current point as neighbors ( citers ) , in order to be more robust in prediction .", "label": "", "metadata": {}, "score": "61.34435"}
{"text": "By inputting these synthesized nucleotide sequences into our classifiers , we want to investigate whether any changes in expression levels will occur .In our data set , there are totally 259 scenarios , including a given gene and its corresponding vector , resulted in a non - expression level .", "label": "", "metadata": {}, "score": "61.39"}
{"text": "See more details in this page .Preprocessing : We consider the subset used in the Pascal Large Scale Learning Challenge .According to Soeren Sonnenburg , all positive examples were taken and the negative examples were created by randomly traversing the Internet starting at well known ( e.g. news ) web - sites .", "label": "", "metadata": {}, "score": "61.4121"}
{"text": "libsvm.fas : libsvm.lisp .$ ( CLISP ) -c libsvm.lisp .# Make a module .clisp - module : all .# Make a module distribution into $ ( distribdir ) .clisp - module - distrib : clisp - module force .", "label": "", "metadata": {}, "score": "61.43175"}
{"text": "Python Interface .See the README file in python directory .Additional Information .If you find LIBSVM helpful , please cite it as .Chih - Chung Chang and Chih - Jen Lin , LIBSVM : a library for .support vector machines , 2001 .", "label": "", "metadata": {}, "score": "61.454018"}
{"text": "In this work , each SVM - based classifier was used as a three - class classifier to predict expression levels of recombinant fusion proteins in E. coli .Hence , the performance of three proposed SVM - based classifiers were compared to each other by F 1 measure .", "label": "", "metadata": {}, "score": "61.46367"}
{"text": "# The idea I have in mind is to feed a k - means classifier with the ... .I am trying to use libsvm via Weka API .I have added weka - dev-3.7.6.jar and libsvm.jar to my eclipse build path .", "label": "", "metadata": {}, "score": "61.525158"}
{"text": "# The idea I have in mind is to feed a k - means classifier with the ... .I am trying to use libsvm via Weka API .I have added weka - dev-3.7.6.jar and libsvm.jar to my eclipse build path .", "label": "", "metadata": {}, "score": "61.525158"}
{"text": "Overall , for each set of training parameters , we have 10 values for Precision and 10 values for Recall .We compute the average and the standard deviation of these values , and use them to choose the best set of parameters .", "label": "", "metadata": {}, "score": "61.582077"}
{"text": "This package will includes two distinct schemes : ( 1 )One versus One ( One - vs .-One ) ; ( 2 )One versus Others ( One - vs .-Others ) .We will explain the later scheme due to it is a bit easier to understand .", "label": "", "metadata": {}, "score": "61.588562"}
{"text": "are : .New training instance for xi : .New testing instance for any x : . 1:K(x , x1 ) ...L : K(x , xL ) .That is , in the training file the first column must be the \" ID \" of .", "label": "", "metadata": {}, "score": "61.65944"}
{"text": "( and name ( setf ( get : documentation name ) new - value ) ) ) ) .+ ( ( setq name ( sys::subr - info x ) ) ; subr .+ ( setf ( get : documentation name ) new - value ) ) .", "label": "", "metadata": {}, "score": "61.714577"}
{"text": "This code shows the simple ( perhaps simplest ) usage of the svmlib package to train and classify .Very easy to understand .This code just simply run the SVM on the example data set \" heart_scale \" , which is scaled properly .", "label": "", "metadata": {}, "score": "61.783714"}
{"text": "This is a ... .I am working on a music data set where I have to classify the music data in to genres .I have both test and train data sets .I have linked the datasets for you to check here .", "label": "", "metadata": {}, "score": "61.811558"}
{"text": "( libsvm : make - problem : l repeat :x x : y y ) ) ) .PROBLEM .( defparameter f - problem-2 - 7 ( problem 1000 2 7 ) )F - PROBLEM-2 - 7 .( libsvm : save - problem \" svm - problem \" f - problem-2 - 7 ) NIL .", "label": "", "metadata": {}, "score": "61.84594"}
{"text": "Infinite variable bounds are tightened to a finite value only for the three water instances , independent of whether SVM is used .First , we discuss the effect of Aggressive Probing alone .Table 1 shows that the effect of probing is problem - dependent ; for example , for lop97icx , no variable is tightened by our algorithm , and for nvs23 and nvs24 , more than 90 % of the variables are tightened .", "label": "", "metadata": {}, "score": "62.09438"}
{"text": "Options : . -Scaling : as in DD .- NumRuns : as in DD .- Aggregate : as in DD .- Threshold : as in DD . - IterTolerance ( def 0.1 ) : The minimum change of objective function as the termination criterion for each optimization ( each M - step ) . \u00b7 kNN .", "label": "", "metadata": {}, "score": "62.101093"}
{"text": "If they . are unknown , just fill the first column with any numbers .A sample classification data included in this package is ' heart_scale ' .Type ' svm - train heart_scale ' , and the program will read the training . data and output the model file ' heart_scale . model ' .", "label": "", "metadata": {}, "score": "62.215145"}
{"text": "Some numerical results will be presented to illustrate the behavior of the methods under NLP subproblem inexactness .Send clisp - cvs mailing list submissions to clisp - cvs@ ...To subscribe or unsubscribe via the World Wide Web , visit https://lists.sourceforge.net/lists/listinfo/clisp-cvs .", "label": "", "metadata": {}, "score": "62.271004"}
{"text": "We propose three SVM - based methods to tackle a three - class classification problem according to the expression levels in SDS - PAGE experiments .These three classes consist of soluble fraction , inclusion fraction , and non - expression , as show in Figure 1 .", "label": "", "metadata": {}, "score": "62.2924"}
{"text": "The next scope of liblinear on Mahout suppose is to focus on Sequential Learning with Large - scale data sets .One interesting paper has been published by Libsvm(liblinear ) group , which listed in my last post .zhao zhendong added a comment - 09/Aug/10 08:38 Add parallel Multi - class classifier to this package .", "label": "", "metadata": {}, "score": "62.30381"}
{"text": "Options and Classifiers .The basic grammar for MILL command is as follows .Note that \" -- \" is used to separate different parts of the input commands .Spaces MUST be added before and after the \" -- \" , otherwise MILL can not parse the command correctly .", "label": "", "metadata": {}, "score": "62.33015"}
{"text": "An example data file in sparse format is given below , where each instance is represented by a 10-d feature vector .Inst1,Bag1,0,1:0.4,6:0.1,10:0.7 . Inst2,Bag1,0,3:0.2 .Inst3,Bag2,1,1:0.8,2:0.7,8:0.2,9:0.1 . Inst4,Bag2,0,2:0.1,4:0.3,7:0.7 .Inst5,Bag2,1 , 5:0.4,8:0.1 .m file that calls MILL .", "label": "", "metadata": {}, "score": "62.375"}
{"text": "utilized random forest and decision - tree based methods on about 27 , 000 protein targets in TargetDB [ 16 ] to conclude that the most significant protein feature was serine percentage composition [ 17 ] .Furthermore , Luan et al .", "label": "", "metadata": {}, "score": "62.464825"}
{"text": "( foreign - value prob_estimates ) ) ) ) .; ; can not use ( setf ( validp model ) nil ) because .; ; must not invalidate the sole FFI session pointer .( def - call - out destroy - model ( : library svm - so ) ( : name \" svm_destroy_model \" ) .", "label": "", "metadata": {}, "score": "62.49257"}
{"text": "set called heart_scale .t , then type ' svm - predict heart_scale . t .heart_scale . model output ' to see the prediction accuracy .The ' output ' .file contains the predicted class labels .There are some other useful programs in this package .", "label": "", "metadata": {}, "score": "62.50534"}
{"text": "Koggalage , R. , Halgamuge , S. : Reducing the number of training samples for fast support vector machine classification .Neural Information Processing - Letters 2(3 ) ( 2004 ) 57 - 65 .Data provided are for informational purposes only .", "label": "", "metadata": {}, "score": "62.52333"}
{"text": "As you can see in Figure 2 , the Mappers act as Emit Controller .Each sample will be emit N times with different categories ' label , where N is the number of categories in dataset .The class label will be emitted as the key of Mappers ' output .", "label": "", "metadata": {}, "score": "62.532234"}
{"text": "However , the model shows good performance on examples not included in the training set .5.3Testing the probing algorithm In this section , we discuss the effect of applying Aggressive Probing on a set of difficult MINLPs .In addition to FBBT , we also use Optimality - Based Bound Tightening ( OBBT ) [ 12].", "label": "", "metadata": {}, "score": "62.548386"}
{"text": "; ; ; foreign functions and small wrappers .( def - call - out check - parameter ( : library svm - so ) ( : name \" svm_check_parameter \" ) .( : arguments ( problem ( c - ptr problem ) ) ( param ( c - ptr parameter ) ) ) .", "label": "", "metadata": {}, "score": "62.585648"}
{"text": "Top 10 algorithms in data mining .Knowl .Inf .Syst . , 14(1):1 - 37 , 2007 .Robin Anil added a comment - 08/Feb/11 14:43 I will take a look at this weekend to clean this up and propose a patch .", "label": "", "metadata": {}, "score": "62.654224"}
{"text": "( t ( get : documentation ( sys::%record - ref x 0 ) ) ) ) ) .; ; ; documentation .( : method ( ( x slot - definition ) ( doc - type ( eql ' t ) ) ) .", "label": "", "metadata": {}, "score": "62.79015"}
{"text": "For F 1 measure , each individual classifier must correctly identify each instance into its real class .In contrast , F score just focuses on measuring the rate of correctly identifying soluble fraction instances from non - soluble ones , i.e. the class of soluble fraction versus the other two classes .", "label": "", "metadata": {}, "score": "62.83252"}
{"text": "multi - scale automatic , quite perfect .separated . default and specific kernel are fine here .4-class spiral .The code is developed based on _ test11 .I figure that the function svmtrain and svmpredict , originally implemented in libsvm , support multiclass pair - wise SVM .", "label": "", "metadata": {}, "score": "62.99601"}
{"text": "+ + + ChangeLog4 Oct 2006 00:40:48 -00001.5402 .+ fixed bug # [ 1569234 ] : on some platforms SUBR is not a record .+ ( set - function - documentation ) : do not fallthrough on subr .-(gnu - distrib ) : pass --use - agent to gpg .", "label": "", "metadata": {}, "score": "63.014282"}
{"text": "( foreign - free parameter ) .( setf ( validp parameter ) nil ) ) ) .; ; the defaults are the same as those in svm_train ( see README ) .( defun make - parameter ( & key ( v # ( ) v - p ) .", "label": "", "metadata": {}, "score": "63.34258"}
{"text": "Can you say a little bit more about where these data sets came from and how they were pre - processed ?Which 20newsgroup dataset ?Which header fields were suppressed ?Ted Dunning added a comment - 14/Jul/10 16:57 These latest accuracy values on 20 newsgroups seem waaay too high .", "label": "", "metadata": {}, "score": "63.346657"}
{"text": "I have worked with Hadoop and Map Reduce since one year ago , and I have dedicated lots of my spare time to Sequential SVM ( Pegasos ) based on Mahout .I have taken part in setting up and maintaining a Hadoop cluster with around 75 nodes in our group .", "label": "", "metadata": {}, "score": "63.356712"}
{"text": "The codes ovrtrain and ovrpredict are the wrapper .You can also do the cross validation from the demo code below , where get_cv_ac is again the wrapper code .The one - vs - rest multiclass SVM results .So , parameter selection is really important ! ! ! !", "label": "", "metadata": {}, "score": "63.362522"}
{"text": "multi - scale automatic , quite perfect .separated . default and specific are fine here .10-class spiral .This code is developed based on _ test5 .What we add are : . better automatic cross validation routine than _", "label": "", "metadata": {}, "score": "63.427536"}
{"text": "6 References [ 1 ] Rong - En Fan , Kai - Wei Chang , Cho - Jui Hsieh , Xiang - Rui Wang , and Chih - Jen Lin .J. Mach .Learn .Res . , 9:1871 - 1874 , 2008 .", "label": "", "metadata": {}, "score": "63.439312"}
{"text": "lisp , v . retrieving revision 1.26 . retrieving revision 1.27 .diff -u -d -r1.26 -r1.27 .--- documentation.lisp1 Oct 2006 14:48:19 -00001.26 .+ + + documentation.lisp4 Oct 2006 00:40:48 -00001.27 .( in - package \" CLOS \" ) .", "label": "", "metadata": {}, "score": "63.589027"}
{"text": "Can someone explain to me the steps for including new package in Weka API using the package manager .I am able to install new packages to Weka using the GUI .I am confused how to do so in the API .", "label": "", "metadata": {}, "score": "63.652626"}
{"text": "Can someone explain to me the steps for including new package in Weka API using the package manager .I am able to install new packages to Weka using the GUI .I am confused how to do so in the API .", "label": "", "metadata": {}, "score": "63.652626"}
{"text": "There are two major output files , the prediction file and the result file , which can be specified -p and -o respectively in the command line mode , or by specifying proprocess.pred_file and proprocess.output_file in the .m file .By default , their names are set to $ ( input_file ) .", "label": "", "metadata": {}, "score": "63.707115"}
{"text": "The labels of the bags are provided , but the labels of instances in the bags are unknown .However , a bag is labeled positive if at least one instance in the bag is positive , and a bag is negative if all the instances in it are negative .", "label": "", "metadata": {}, "score": "63.73169"}
{"text": "A probing algorithm for MINLP5 Algorithm 1 The Aggressive Probing algorithm .We would like to avoid wasting time in trying to tighten the bounds of a variable for which there is little hope of success .Note that FBBT is the first step of the Branch - and - Bound algorithm used in Aggressive Probing , so this does not require additional work .", "label": "", "metadata": {}, "score": "63.81352"}
{"text": "This proposal will port one of the most famous linear SVM solvers , LIBLINEAR [ 1 ] to mahout with unified interface with Pegasos [ 2 ] on mahout , which is another linear SVM solver and almost finished by myself ( Mahout-232 ) .", "label": "", "metadata": {}, "score": "63.814972"}
{"text": "Biegler , L. , Grossmann , I. , Westerberg , A. : Systematic Methods of Chemical Pro- cess Design .Prentice Hall , Upper Saddle River ( NJ ) ( 1997 ) 2 .Floudas , C. : Global optimization in design and control of chemical process systems .", "label": "", "metadata": {}, "score": "63.880272"}
{"text": "Multiple sequence alignment for one mutation case .The result of Multiple Sequence Alignment ( MSA ) for one case which was predicted as a soluble form after mutating 5 nucleotides was presented .Conclusion .In this study , we developed three SVM - based methods of predicting three expression levels based on SDS - PAGE experiments for a target protein in a corresponding vector in E. coli .", "label": "", "metadata": {}, "score": "63.954742"}
{"text": "( with - open - file ( in file ) .( when log .load - problem file ( file - length in ) ) .( force - output log ) ) .( incf len ) .( multiple - value - bind ( target pos ) ( read - from - string line ) .", "label": "", "metadata": {}, "score": "64.02619"}
{"text": "In this code , we also make a routine to determine the optimal parameters automatically .The user can guess an initial parameter , the routine will keep improving it .Here we also modify the original train and classify function a bit : .", "label": "", "metadata": {}, "score": "64.039024"}
{"text": "We found that having kernel - specific is much slower than using the default ( without ' -t x ' ) .At this point , I prefer using the default kernel .10-class spiral .The code is developed based on _ test7 .", "label": "", "metadata": {}, "score": "64.04133"}
{"text": "HFY10c ] .Preprocessing : KDD Cup 2010 is an educational data mining competition .The data comes from Carnigie Learning and DataShop .This is the training set of the second problem : bridge_to_algebra_2008_2009 .We provide a transformed version used by the winner ( National Taiwan Univ ) .", "label": "", "metadata": {}, "score": "64.04355"}
{"text": "After Aggressive Probing has been applied to all of the original variables or the global time limit is reached , we record the fraction of tightened variables \u03b7 , and the average bound reduction \u03c1 , as described in Section 4.1 .", "label": "", "metadata": {}, "score": "64.11855"}
{"text": "( : return - type nil ) ) .; ; not needed ! ; ; ( def - call - out destroy - param ( : library svm - so ) ( : name \" svm_destroy_param \" ) .( def - call - out check - probability - model ( : library svm - so ) .", "label": "", "metadata": {}, "score": "64.17232"}
{"text": "input data or with asymmetric misclassification cost .nr_weight is the number of elements in the array weight_label and . weight .Each weight[i ] corresponds to weight_label[i ] , meaning that .the penalty of class weight_label[i ] is scaled by a factor of weight[i].", "label": "", "metadata": {}, "score": "64.20626"}
{"text": "ChangeLog4 Oct 2006 00:40:48 -00001.5402 .+ + + ChangeLog4 Oct 2006 00:53:31 -00001.5403 . fixed bug # [ 1569234 ] : on some platforms SUBR is not a record .( set - function - documentation ) : do not fallthrough on subr .", "label": "", "metadata": {}, "score": "64.20896"}
{"text": "23 ] .By submitting each recombinant fusion proteins to their provided web servers , calculated results were acquired .As illustrated in Figure 3 for PRC , each point in the plot was an average of 10 repeats of test cases for all methods .", "label": "", "metadata": {}, "score": "64.28531"}
{"text": "MODEL .( ffi : enum - from - value ' libsvm : svm_type ( libsvm : get - svm - type model ) ) libsvm : C_SVC .( libsvm : get - nr - class model ) 2 .( libsvm : get - labels model ) # ( -1 1 ) .", "label": "", "metadata": {}, "score": "64.34"}
{"text": "Note that the following examples can be ran by simply copying the command line into the Matlab command window .The example data files used in these examples are actually available in the MILL directory .Example 1 .Classify the data in example.data using iterdiscrim_APR method , using a 50%-50 % training - testing split ( default ) .", "label": "", "metadata": {}, "score": "64.341286"}
{"text": "Data Set : Rcv1_train .zhao zhendong added a comment - 30/May/10 17:19 Libsvm Format convertor .Labels in Libsvm data sets will be separated to files with suffix \" . labels \" .zhao zhendong added a comment - 30/May/10 17:17 Libsvm Format convertor .", "label": "", "metadata": {}, "score": "64.34214"}
{"text": "( : return - type nil )( : library svm - so ) ) .( defun predict - values ( model x ) .( case ( get - svm - type model ) .( ( ONE_CLASS EPSILON_SVR NU_SVR ) .", "label": "", "metadata": {}, "score": "64.35983"}
{"text": "( foreign - value target ) ) ) .( def - call - out save - model ( : library svm - so ) ( : name \" svm_save_model \" ) .( : arguments ( model_file_name c - string ) ( model model ) ) .", "label": "", "metadata": {}, "score": "64.374725"}
{"text": "Smith , E. : On the Optimal Design of Continuous Processes .PhD thesis , Imperial College of Science , Technology and Medicine , University of London ( October 1996 ) 14 .Cristianini , N. , Shawe - Taylor , J. : An Introduction to Support Vector Machines and Other Kernel - based Learning Methods .", "label": "", "metadata": {}, "score": "64.40985"}
{"text": "Krogh A , Larsson B , von Heijne G , Sonnhammer EL : Predicting transmembrane protein topology with a hidden Markov model : application to complete genomes .J Mol Biol 2001 , 305 ( 3 ) : 567 - 80 .", "label": "", "metadata": {}, "score": "64.41533"}
{"text": "Let Y be a binary variable .If we use logistic regression for modeling , then we can use cv.glm for cross validation and there we can specify the cost function in the cost argument .By specifying the ... .I 'm currently using a support vector machine to predict which item a user will buy given demographic data .", "label": "", "metadata": {}, "score": "64.504105"}
{"text": "For a classification model , this function outputs the name of .labels into an array called label .For regression and one - class . models , label is unchanged .For a regression model with probability information , this function .", "label": "", "metadata": {}, "score": "64.52106"}
{"text": "diff -u -d -r1.463 -r1.464 . --- impext.xml7 Sep 2006 01:06:08 -00001.463 .+ + + impext.xml4 Oct 2006 00:53:35 -00001.464 . by & hin;.+ from & clisp;;.Index : Makefile .RCS file : /cvsroot / clisp / clisp / doc / Makefile , v . retrieving revision 1.87 . retrieving revision 1.88 .", "label": "", "metadata": {}, "score": "64.52438"}
{"text": "As this ap- proach is computationally expensive , we use a Support - Vector - Machine classifier to infer whether or not the probing algorithm should be used .Computational experiments demonstrate that the use of this classifier saves a substantial amount of CPU time at the cost of a marginally weaker bound tightening . 1 Introduction A Mixed Integer Nonlinear Program ( MINLP ) is a mathematical program with continuous nonlinear objective and constraints , where some of the variables are required to take integer values .", "label": "", "metadata": {}, "score": "64.59154"}
{"text": "PubMed View Article .Chen L , Oughtred R , Berman HM , Westbrook J : TargetDB : a target registration database for structural genomics projects .Bioinformatics 2004 , 20 ( 16 ) : 2860 - 2 .PubMed View Article .", "label": "", "metadata": {}, "score": "64.60742"}
{"text": "C is the cost of constraints violation .( we usually use 1 to 1000 ) .eps is the stopping criterion .( we usually use 0.00001 in nu - SVC , . 0.001 in others ) .nu is the parameter in nu - SVM , nu - SVR , and .", "label": "", "metadata": {}, "score": "64.6219"}
{"text": "I am trying to solve this homework , but am receiving the above mentioned error ...The code is working for the linear kernel and radial kernel , ... .Recently I started toying with Neural Network .I was trying to implement an ANDgate with tensorflow .", "label": "", "metadata": {}, "score": "64.622696"}
{"text": "Currently I only have a few numbers of classes limited by the training data .However , in the future , I may get data ... .I am new to SVM .I used to do object detection using HAAR Cascading .", "label": "", "metadata": {}, "score": "64.658936"}
{"text": "While others have focused on improving the folding probabilities regarding enhancement of mRNA stability , over - expression of rare - codon tRNA , selection of efficient vectors and host strains , and co - expression with solubility - enhanced proteins [ 3 ] .", "label": "", "metadata": {}, "score": "64.66107"}
{"text": "Artificial Intelligence Journal , 89 , 1997 .[ Maron and Lozano - Perez , 1998 ] Oded Maron , Tom\u00e1s Lozano - P\u00e9rez , A framework for multiple - instance learning , Proc . of the 1997 Conf . on Advances in Neural Information Processing Systems 10 , p.570 - 576 , 1998 .", "label": "", "metadata": {}, "score": "64.76465"}
{"text": "Building Windows binaries ' in this file ) or use the pre - built . binaries ( Windows binaries are in the directory ' windows ' ) .The format of training and testing data file is : .( multi - class is supported ) .", "label": "", "metadata": {}, "score": "64.83322"}
{"text": "The system of HTP and parallel approaches in protein expression included six different fusion protein expression vectors and two universal restriction sites in E. coli .The expression results consisted of three levels after the treatment of denaturing SDS - PAGE .", "label": "", "metadata": {}, "score": "64.852715"}
{"text": "View Article .Pryor KD , Leiting B : High - level expression of soluble protein in Escherichia coli using a His6-tag and maltose - binding - protein double - affinity fusion system .Protein Expr Purif 1997 , 10 ( 3 ) : 309 - 19 .", "label": "", "metadata": {}, "score": "64.977264"}
{"text": "With this regard , I make another version of parameter selection routine using cross validation : . which call the n - fold cross validation classification routine : .svmNFoldCrossValidation.m .I would say this is the best so - far code to run on separated data set as it provides parameter selection routine and the train and classification routines .", "label": "", "metadata": {}, "score": "65.06348"}
{"text": "( defun destroy - problem ( problem ) .( when ( validp problem ) .( foreign - free problem ) .( setf ( validp problem ) nil ) ) ) .; ; load the ' problem ' object from a standard libsvm / svmlight problem file : . ; ; target index1:value1 index2:value2 ... .", "label": "", "metadata": {}, "score": "65.09044"}
{"text": "The function is .This code is an excellent example complete code for classification on strain - test_separated data set and automatic parameters selection .The code is developed based on _ test8 and _ test9 .This code is developed based on -test10 , except that the code is made to work for any kernel .", "label": "", "metadata": {}, "score": "65.18733"}
{"text": "Lastly , we briefly present two methods to use the trained model in the design of the recombinant protein production systems to improve the chance of high soluble protein production .Conclusion .In this paper , we show that a machine learning approach to the prediction of the efficacy of a vector for a target protein in a recombinant protein production system is promising and may compliment traditional knowledge - driven study of the efficacy .", "label": "", "metadata": {}, "score": "65.29546"}
{"text": "-ssvm_type : set type of SVM ( default 0 ) . 0 -- C - SVC . 1 -- nu - SVC .2 -- one - class SVM . 3 -- epsilon - SVR .4 -- nu - SVR .", "label": "", "metadata": {}, "score": "65.32112"}
{"text": "svm_train ( ) .It returns NULL if the parameters are feasible , . otherwise an error message is returned .This function checks whether the model contains required .information to do probability estimates .If so , it returns .", "label": "", "metadata": {}, "score": "65.41519"}
{"text": "Furthermore , based on our experimental data of over - expression of given genes in different fusion vectors in E. coli , we considered entire sequences of recombinant expressed proteins instead of only sequences of target protein in previous works .Altogether , these three SVM - based methods , i.e. flatSVM , nestSVM , and hierSVM , predict each scenario , including a given gene and corresponding fusion vector , as one of the expression levels in SDS - PAGE experiments .", "label": "", "metadata": {}, "score": "65.42602"}
{"text": "( prob_estimates c - pointer ) ) .( : return - type double - float ) ) .( defun predict - probability ( model x ) .( with - foreign - object ( prob_estimates ' ( c - array int , ( get - nr - class model ) ) ) .", "label": "", "metadata": {}, "score": "65.50602"}
{"text": "Then plot the results vs their true class .In order to visualize the high dimensional data , we apply MDS to the 13D data and reduce the dimension to 2D .demo_libsvm_test2 . m . binary .no , manually . separated .", "label": "", "metadata": {}, "score": "65.537125"}
{"text": "For one - class model , label[0 ] is +1 or .This function does classification or regression on a test vector x .given a model with probability information .For a classification model with probability information , this .function gives nr_class probability estimates in the array . prob_estimates .", "label": "", "metadata": {}, "score": "65.61786"}
{"text": "svm_get_nr_class .The class with the highest probability is . returned .For all other situations , the array prob_estimates is . unchanged and the returned value is the same as that of . svm_predict .This function checks whether the parameters are within the feasible . range of the problem .", "label": "", "metadata": {}, "score": "65.725624"}
{"text": "We are interested in the set of Pareto op- tima with respect to these two criteria .Most Pareto optima are obtained with a polynomial kernel , and the remaining with a radial - basis kernel .The linear .Page 13 .", "label": "", "metadata": {}, "score": "65.81419"}
{"text": "( with - foreign - object ( dec - values ' ( c - array double - float , len ) ) .( svm_predict_values2 model x dec - values ) .( foreign - value dec - values ) ) ) ) ) ) .", "label": "", "metadata": {}, "score": "65.89836"}
{"text": "( def 0.05 ) : Kernel parameter , which represents the degree of polynomial kernel , or gamma for RBF kernel .-CostFactor ( def 1 ) : Cost factor that balances the margin width with the ratio of correct classification .", "label": "", "metadata": {}, "score": "65.95923"}
{"text": "MODEL .( ffi : enum - from - value ' libsvm : svm_type ( libsvm : get - svm - type model ) ) libsvm : NU_SVR .( libsvm : get - nr - class model ) 3 .( libsvm : get - labels model ) # ( 1 -1 ) .", "label": "", "metadata": {}, "score": "65.970924"}
{"text": "test_file is the test data you want to predict .svm - predict will produce output in the output_file .Tips on Practical Use .For example , scale each attribute to [ 0,1 ] or [ -1,+1]. errors and support vectors .", "label": "", "metadata": {}, "score": "66.005295"}
{"text": "LIBSVM [ 30 ] were used to implement all core algorithms in this research .According to the characteristics of features , the radial basis function ( RBF ) kernel implemented in LIBSVM was used because of its advantages on dealing with the most cases of numerical data .", "label": "", "metadata": {}, "score": "66.028435"}
{"text": "Evaluation measurement .Given a multi - class classifier , F 1 measure is the proper parameter of its performance .F 1 measure is calculated as .where J is the total number of classes , A j is the number of instances correctly predicted as class j , B j is the number of instances incorrectly assigned to class j , and C j is the number of class j instances assigned to other classes .", "label": "", "metadata": {}, "score": "66.05062"}
{"text": "The target genes cover a wide variety of species from virus , bacteria , mouse to human .The lengths of target genes varied from 144 to 3162 .That is , the lengths of final translation proteins after being cleaved from recombinant fusion proteins varied from 48 to 1054 .", "label": "", "metadata": {}, "score": "66.06"}
{"text": "HFY10c ] .Preprocessing : The data set is also available at UCI .Because the labels of testing set are not available , here we use the validation set ( madelon_valid .data and madelon_valid .labels ) as the testing set .", "label": "", "metadata": {}, "score": "66.15712"}
{"text": "We give the component corresponding to each option in the bracket after the description after each option .-sf ( def 0 ) : Shuffle the data or not , 0 for no shuffle ( preprocess .Shuffled ) .-n ( def 1 ) : Normalize the data or not , 1 for normalize ( preprocess .", "label": "", "metadata": {}, "score": "66.22099"}
{"text": "int index ; . struct svm_parameter describes the parameters of an SVM model : . structsvm_parameter . int svm_type ; . int kernel_type ; .svm_type can be one of C_SVC , NU_SVC , ONE_CLASS , EPSILON_SVR , NU_SVR .C_SVC : C - SVM classification .", "label": "", "metadata": {}, "score": "66.29376"}
{"text": "Note that this only works in cases where the algorithms that output meaningful probabilities ( bag probability is set to the maximum instance probability from the bag ) .The evaluation methods .The default method is to split the input file equally into training and testing sets . \u00b7 train_test_validate ( default ) .", "label": "", "metadata": {}, "score": "66.333824"}
{"text": "Using the scaling factors of the training part , the testing part is processed in a similar way .These train and testing data sets are used in [ GXY11a ] .Preprocessing : The data set is also available at UCI .", "label": "", "metadata": {}, "score": "66.40863"}
{"text": "Update of /cvsroot / clisp / clisp / src .In directory sc8-pr - cvs4 . sourceforge.net:/tmp/cvs-serv19582/src .Modified Files : .NEWS ChangeLog .Log Message : . and makes Support Vector Machines available in CLISP .", "label": "", "metadata": {}, "score": "66.40878"}
{"text": "y ) .( push .( let ( ( ret ( ) ) ) .( loop : with index : and value .( multiple - value - setq ( index pos ) .( parse - integer line : start pos : end colon ) ) .", "label": "", "metadata": {}, "score": "66.813034"}
{"text": "Quick Start .If you are new to SVM and if the data is not large , please go to . 'tools ' directory and use easy.py after installation .It does .everything automatic -- from data scaling to parameter selection .", "label": "", "metadata": {}, "score": "66.9346"}
{"text": "( def - c - enum svm_type C_SVC NU_SVC ONE_CLASS EPSILON_SVR NU_SVR ) .( def - c - enum kernel_type LINEAR POLY RBF SIGMOID PRECOMPUTED ) .( def - c - type parameter ( c - struct vector .( svm_type int ) .", "label": "", "metadata": {}, "score": "67.04331"}
{"text": "I have to measure the performance of SVM classifier in Matlab .Confusion matrix must be used as the performance measure .However , in the examples in Matlab , only loss value can be calculated .I could ... .I 'm studing SVM and I found an interesting example here .", "label": "", "metadata": {}, "score": "67.055824"}
{"text": "To measure performance , we use Precision and .Page 12 .A probing algorithm for MINLP11 0 20 40 60 80 100 0 20 40 60 80 100 Recall % Precision % polynomial linear radial basis chosen model Fig.1 .Average values of Precision and Recall for all tested combinations of training input parameters .", "label": "", "metadata": {}, "score": "67.0594"}
{"text": "clisp - cvs - request@ ... .You can reach the person managing the list at .clisp - cvs - owner@ ... .When replying , please edit your Subject line so it is more specific . than \" Re : Contents of clisp - cvs digest ... \" .", "label": "", "metadata": {}, "score": "67.13569"}
{"text": "clisp - cvs - request@ ... .You can reach the person managing the list at .clisp - cvs - owner@ ... .When replying , please edit your Subject line so it is more specific . than \" Re : Contents of clisp - cvs digest ... \" .", "label": "", "metadata": {}, "score": "67.13569"}
{"text": "In Neural Information Processing Systems 14 , 2001 .Description .Student Degree : Master Student Graduation : NUS'10 Organization : Hadoop . 0Abstract Linear Support Vector Machine ( SVM ) is pretty useful in some applications with large - scale datasets or datasets with high dimension features .", "label": "", "metadata": {}, "score": "67.217865"}
{"text": "( ( kernel_type kernel_type ) ( if v - p ( svref v 1 ) RBF ) ) .( ( degree degree ) ( if v - p ( svref v 2 ) 3 ) ) .( ( gamma gamma ) ( if v - p ( svref v 3 ) 0d0 ) ) ; 1/maxindex .", "label": "", "metadata": {}, "score": "67.47061"}
{"text": "MINLPs naturally arise in numerous applied problems , see e.g. [ 1,2].In this paper , we address nonconvex MINLPs where neither the objective function nor the constraints are required to be convex - a class of problems typically difficult to solve in practice .", "label": "", "metadata": {}, "score": "67.60376"}
{"text": "I am trying to use tri - axial accelerometer data collected from a smartphone for activity recognition .I have seen some of the UCI repositories for accelerometer - based activity recognition , and they ... .I have a program designed to run lots of weka experiments in parallel .", "label": "", "metadata": {}, "score": "67.68587"}
{"text": "I am trying to use tri - axial accelerometer data collected from a smartphone for activity recognition .I have seen some of the UCI repositories for accelerometer - based activity recognition , and they ... .I have a program designed to run lots of weka experiments in parallel .", "label": "", "metadata": {}, "score": "67.68587"}
{"text": "Is an SVM as simple as saying ... .Most classification algorithms are developed to improve the training speed .However , is there any classifier or algorithm focusing on the decision making speed(low computation complexity and simple ... .I am new to matlab .", "label": "", "metadata": {}, "score": "67.714645"}
{"text": "Moreover , the run time is not good either .We found a better way using multiclass pair - wise SVM , which is the default multiclass SVM approach in the libsvm package .In the next version ( _ test12 ) , we will test the pair - wise SVM . demo_libsvm_test12 .", "label": "", "metadata": {}, "score": "67.767784"}
{"text": "( def - call - out svm_train( : library svm - so ) .( : arguments ( problem ( c - ptr problem ) ) ( param ( c - ptr parameter ) ) ) .( : return - type model ) ) .", "label": "", "metadata": {}, "score": "67.826004"}
{"text": "C - SVM classification .This document explains the use of libsvm .Please read the COPYRIGHT file before using libsvm .Table of Contents . - Quick Start .-Installation . - ' svm - train ' Usage . - ' svm - predict ' Usage .", "label": "", "metadata": {}, "score": "67.83425"}
{"text": "flatSVM method performed significantly better than nestSVM method with a p - value less than 0.05 .Comparisons with solubility prediction methods .To compare our proposed methods with other previously published predictors , our methods were reduced to a binary classifier of predicting solubility of proteins from non - soluble ones , which included insoluble and non - expression .", "label": "", "metadata": {}, "score": "68.10948"}
{"text": "( let ( ( check ( check - parameter problem parameter ) ) ) .( svm_train problem parameter ) ) ) ) .( ffi : def - call - out svm_cross_validation ( : library svm - so ) .( : arguments ( problem ( c - ptr problem ) ) ( param ( c - ptr parameter ) ) .", "label": "", "metadata": {}, "score": "68.23117"}
{"text": "However , em- ploying Aggressive Probing yields a much better lower bound when the time limit is reached ( we close an additional 37 % of optimality gap ) .Finally , waterz is not solved by Branch - and - Bound unless Aggressive Probing is used .", "label": "", "metadata": {}, "score": "68.31967"}
{"text": "( : arguments ( model model ) ) .( : return - type int ) ) .( def - call - out get - nr - class ( : library svm - so ) ( : name \" svm_get_nr_class \" ) .", "label": "", "metadata": {}, "score": "68.331665"}
{"text": "Host cells were harvested and lysed in 96-well plates .After centrifugation , SDS - PAGE experiments were used to separate proteins to determine expression levels .In addition , Western blot was used to further verify expression results in SDS - PAGE experiment .", "label": "", "metadata": {}, "score": "68.355865"}
{"text": "In testing , ? can be any value .All kernel values including ZEROs must be explicitly provided .Any . permutation or random subsets of the training / testing files are also . valid ( see examples below ) .Note : the format is slightly different from the precomputed kernel . package released in libsvmtools earlier .", "label": "", "metadata": {}, "score": "68.38691"}
{"text": "Today 's Topics : . clisp Makefile.devel,1.154,1.155 ( Sam Steingold ) .clisp / src documentation.lisp , 1.26 , 1.27 NEWS , 1.340 , 1.341 .ChangeLog,1.5401 , 1.5402 ( Sam Steingold ) .clisp / doc impnotes.xml.in , 1.93 , 1.94 impext.xml , 1.463 , . 1.464", "label": "", "metadata": {}, "score": "68.421005"}
{"text": "Background .Acquiring large quantities of a desired protein in situ from original host cells is not trivial .Moreover , gene over - expression and purification of corresponding proteins in a soluble form are important for structural and functional proteomics .", "label": "", "metadata": {}, "score": "68.59308"}
{"text": "However , recent research has reported that recombinant proteins expressed as inclusion bodies still keep biological activity than previously appreciated [ 24 ] .Thus , it is still significant to distinguish inclusion bodies from the negative set in previous studies .", "label": "", "metadata": {}, "score": "68.70871"}
{"text": "( : shadowing - import - from \" EXPORTING \" # : def - c - enum # : def - c - struct .# : def - call - out # : def - c - type # : defun ) ) .", "label": "", "metadata": {}, "score": "68.73171"}
{"text": "I made this tutorial as a reminder for myself when I need to use it again .All the credits go for the libsvm developers .Here is how you can cite the libsvm .Just read the readme file in the package .", "label": "", "metadata": {}, "score": "68.75621"}
{"text": "-InstDistType ( def ' euclidean ' ) : The distance metric between two instances , as either \" euclidean \" or \" cosine \" .The latter is used for text categorization or similar applications .-RefNum ( def 2 ) : The number of reference nodes ( neighbors ) considered . -CiterRank ( def 4 ) : The rank deciding whether a data point is the citer of the current data point . \u00b7 iterdiscrim_APR [ Dietterich et al . , 1997 ] .", "label": "", "metadata": {}, "score": "68.75644"}
{"text": "A key step is the creation of an LP relaxation of the feasible region of a subproblem , which we refer to as convexification .This convexification is used to obtain a lower bound on the optimal objective value of the subproblem .", "label": "", "metadata": {}, "score": "68.92184"}
{"text": "Additionally , in biotechnology perspective , by mutating few nucleotides or by synthesizing optimal sequences according to the codon preference in E. coli , our prediction methods also provide effective ways to enhance the solubility of target proteins .Declarations .Acknowledgements .", "label": "", "metadata": {}, "score": "68.937515"}
{"text": "clean : force .a .distclean : clean . force : . ---NEW FILE : link.sh --- .if test -f libsvm.c ; then .fi .make clisp - module \\ . ---NEW FILE : svm.cpp --- .", "label": "", "metadata": {}, "score": "69.017586"}
{"text": "svm_modelproduced by svm_train ( ) .This function does classification or regression on a test vector x .given a model .For a classification model , the predicted class for x is returned .For a regression model , the function value of x calculated using .", "label": "", "metadata": {}, "score": "69.06671"}
{"text": "Identical to _ test1 except that it include a routine searching for good parameters c and gamma .demo_libsvm_test4 .m . multiclass , OVR . semi - automatic . separated . default .dna_scale .This code shows how to use the libsvm for the multiclass , more specifically one - vs - rest ( OVR ) , scenario .", "label": "", "metadata": {}, "score": "69.08867"}
{"text": "Learn .Res . , 9:1871 - 1874 , 2008 .[ 2 ] Shai Shalev - Shwartz , Yoram Singer , and Nathan Srebro .Pegasos : Primal estimated sub - gradient solver for svm .In ICML ' 07 : Proceedings of the 24th international conference on Machine learning , pages 807 - 814 , New York , NY , USA , 2007 .", "label": "", "metadata": {}, "score": "69.14011"}
{"text": "Message : 1 .Date : We d , 04 Oct 2006 00:03:27 +0000 .Subject : clisp Makefile.devel,1.154,1.155 .To : clisp - cvs@ ... .Update of /cvsroot / clisp / clisp .In directory sc8-pr - cvs4 . sourceforge.net:/tmp/cvs-serv31722 .", "label": "", "metadata": {}, "score": "69.25905"}
{"text": "A PARTICULAR PURPOSE ARE DISCLAIMED .IN NO EVENT SHALL THE REGENTS OR .CONTRIBUTORS BE LIABLE FOR ANY DIRECT , INDIRECT , INCIDENTAL , SPECIAL , .EXEMPLARY , OR CONSEQUENTIAL DAMAGES ( INCLUDING , BUT NOT LIMITED TO , .", "label": "", "metadata": {}, "score": "69.311066"}
{"text": "Type . nmake -f Makefile.win python .and then copy windows\\python\\svmc.dll to the python directory .Another way is to build them from Visual C++ environment .See details .in libsvm faq .Additional Tools : Model Selection , Sub - sampling , etc . .", "label": "", "metadata": {}, "score": "69.3506"}
{"text": "To access the raw data set , please check the above \" KDD CUP 2010 \" link .This data set is only to be used for research purposes .Users please acknowledge the data is from Carnigie Learning and DataShop .", "label": "", "metadata": {}, "score": "69.523544"}
{"text": "The applications of MIL include molecule activity prediction , text categorization , image classification and retrieval , etc . .The software is free for any scientific use .Please contact me , if you are planning to use the software for commercial purposes .", "label": "", "metadata": {}, "score": "69.535255"}
{"text": "Therefore , in the present work , predicted PTMs on entire recombinant fusion proteins were further considered .71 PTMs predicted by AutoMotif [29 ] were used to reveal critical steps of PTMs on recombinant fusion proteins to aid prediction of recombinant fusion protein solubility .", "label": "", "metadata": {}, "score": "69.53676"}
{"text": "Smith DB , Johnson KS : Single - step purification of polypeptides expressed in Escherichia coli as fusions with glutathione S - transferase .Gene 1988 , 67 : 31 - 40 .PubMed View Article .LaVallie ER , DiBlasio EA , Kovacic S , Grant KL , Schendel PF , McCoy JM : A thioredoxin gene fusion expression system that circumvents inclusion body formation in the E. coli cytoplasm .", "label": "", "metadata": {}, "score": "69.586136"}
{"text": "Because the only way to select a specific match between a target protein and an appropriate fusion partner that will lead to a soluble form is still a trial - and - error process ; a more systematic approach is required .", "label": "", "metadata": {}, "score": "69.93027"}
{"text": "EnforceDistrib ) .The -distrib option is used to enforce the distribution of the bag labels in the testing data the same as in the training data .This is done by ranking all the bags according to their probability ( of being positive ) , and label the top- K bags with the highest probability as positive while label the remaining as negative bags .", "label": "", "metadata": {}, "score": "69.98587"}
{"text": "Report the average performance . \u00b7 test_file_validate .Desc : Use the input file as the training set , and provide an additional file as the testing set . options : -t ( def ' ' ) : The additional testing file . \u00b7", "label": "", "metadata": {}, "score": "69.99435"}
{"text": "( let ( ( vec ( libsvm : cross - validation f - problem-3 - 7 v - parameter 3 ) ) ) .( list ( length vec ) ( count 1d0 vec ) ( count -1d0 vec ) ) ) NIL .", "label": "", "metadata": {}, "score": "70.12108"}
{"text": "( libsvm : get - svr - probability model ) 0d0 .( libsvm : save - model \" svm - model \" model ) 0 .( libsvm : destroy - model ( libsvm : load - model \" svm - model \" ) ) NIL .", "label": "", "metadata": {}, "score": "70.268585"}
{"text": "result .The file $ ( input_file ) .pred contains the prediction results for each bag in the testing data , including the probability ( of being positive ) , predicted label , and true label : .Index Probability Predict Truth .", "label": "", "metadata": {}, "score": "70.39914"}
{"text": "validation accuracy / mean squared error on them .svm - predict ' Usage .Usage : svm - predict [ options ] test_file model_file output_file . options : .-b probability_estimates : whether to predict probability estimates , 0 or 1 ( default 0 ) ; for one - class SVM only 0 is supported .", "label": "", "metadata": {}, "score": "70.68263"}
{"text": "4 Biography I am a graduating masters student in Multimedia Information Retrieval System from National University of Singapore .My research has involved the large - scale SVM classifier .I have worked with Hadoop and Map Reduce since one year ago , and I have dedicated lots of my spare time to Sequential SVM ( Pegasos ) based on Mahout .", "label": "", "metadata": {}, "score": "70.69015"}
{"text": "MILL ( MIL Library ) is an open - source toolkit for multiple instance learning algorithms written in Matlab .Multiple - instance learning ( MIL ) is a form of semi - supervised learning where there is only incomplete knowledge on the labels of the training data .", "label": "", "metadata": {}, "score": "70.77252"}
{"text": "The water4 instance is solved with and without Aggressive Probing ; Branch - and - Bound without probing is 30 % faster , but it explores 20 times as many nodes .Thus , probing is very effective in reducing the size of the enumer- ation tree .", "label": "", "metadata": {}, "score": "70.7793"}
{"text": "It has been issued as a Research Report for early dissemination of its contents .In view of the transfer of copyright to the outside publisher , its distribution outside of IBM prior to publication should be limited to peer communications and specific requests .", "label": "", "metadata": {}, "score": "70.8927"}
{"text": "& rawsock - file ; .& wildcard - file ; .& zlib - file ; .+ & svm - file ; .Message : 4 .Date : We d , 04 Oct 2006 00:53:37 +0000 .Subject : clisp / modules / libsvm test.tst , NONE , 1.1 svm.xml , NONE , 1.1 .", "label": "", "metadata": {}, "score": "70.900894"}
{"text": "Preliminary Experiments .Partially to fulfill the requirement of a course project , I 've done some preliminary experiments of MILL on three different tasks , namely drug activity prediction , text categorization , and image classification .Please find out the report on preliminary experiment results .", "label": "", "metadata": {}, "score": "70.91495"}
{"text": "However , a given protein usually yielded different expression levels by fusing different vectors .Note that different groups have discovered different crucial protein factors according to soluble target proteins acquired from their own experiments .It would be partly because their experimental data were conducted under different expression conditions , such as the focus of fusing different vectors in this work .", "label": "", "metadata": {}, "score": "70.92893"}
{"text": "Page 2 . cmu.edu 2Dept .Bound tightening is an important component of algorithms for solving nonconvex Mixed Integer Nonlinear Programs .A probing al- gorithm is a bound - tightening procedure that explores the consequences of restricting a variable to a subinterval with the goal of tightening its bounds .", "label": "", "metadata": {}, "score": "70.978455"}
{"text": "zhao zhendong added a comment - 17/Jul/10 08:11 Sorry for late reply .Yes , it 's bit surprising .At same time , we tested both datasets via standard liblinear , also get pretty good accuracy , say 97+% .", "label": "", "metadata": {}, "score": "71.007095"}
{"text": "ChangeLog,1.5401 , 1.5402 .To : clisp - cvs@ ... .Update of /cvsroot / clisp / clisp / src .In directory sc8-pr - cvs4 . sourceforge.net:/tmp/cvs-serv14215/src .Modified Files : . documentation.lisp NEWS ChangeLog .", "label": "", "metadata": {}, "score": "71.03253"}
{"text": "Iterdiscrim_APR is an iterative , discriminative variant which is empirically proved to outperforms all other variants .Options ( refer to the paper for details ) : . -KerelWidth ( def : 0.999 ) : The width of the Gaussian kernel used in the kernel density estimation at the expansion stage . -OutsideProb ( def : 0.01 ) : The cumulative probability falling outside the expanded APR given the density estimated by kernel density estimation .", "label": "", "metadata": {}, "score": "71.07651"}
{"text": "ovrtrain.m and .ovrpredict.m .respectively . demo_libsvm_test5 .m . multiclass , OVR .multi - scale automatic but not perfect .separated . default .10-class spiral .Here both the train and test set are generated from 10-class spiral made available here .", "label": "", "metadata": {}, "score": "71.14902"}
{"text": "The structures of six different fusion constructs were shown in Figure 2 .Fusion vectors were named by their corresponding fusion tags ; i.e. , CBP , GST , NusA , His , MBP , and Trx .To over - express highly soluble recombinant proteins , six different fusion constructs for each target gene were transformed into E. coli under the same standard experimental conditions , as well as in parallel .", "label": "", "metadata": {}, "score": "71.24689"}
{"text": "J. Mach .Learn .Res . , 9:1871 - 1874 , 2008 .[ 2 ] Shai Shalev - Shwartz , Yoram Singer , and Nathan Srebro .Pegasos : Primal estimated sub - gradient solver for svm .In ICML ' 07 : Proceedings of the 24th international conference on Machine learning , pages 807 - 814 , New York , NY , USA , 2007 .", "label": "", "metadata": {}, "score": "71.306175"}
{"text": "svm_get_nr_class .The order is label[0 ] vs. label[1 ] , ... , . label[0 ] vs. label[nr_class-1 ] , label[1 ] vs. label[2 ] , ... , .label[nr_class-2 ] vs. label[nr_class-1 ] , where label can be . obtained from the function svm_get_labels .", "label": "", "metadata": {}, "score": "71.406075"}
{"text": "( def - call - out load - model ( : library svm - so ) ( : name \" svm_load_model \" ) .( : arguments ( model_file_name c - string ) ) .( : return - type model ) ) .", "label": "", "metadata": {}, "score": "71.440094"}
{"text": "Date : We d , 04 Oct 2006 00:57:33 +0000 .Subject : clisp / modules / libsvm svm.xml,1.1,1.2 .To : clisp - cvs@ ... .Update of /cvsroot / clisp / clisp / modules / libsvm .In directory sc8-pr - cvs4 . sourceforge.net:/tmp/cvs-serv21177/modules/libsvm .", "label": "", "metadata": {}, "score": "71.44443"}
{"text": "( multiple - value - setq ( n r ) ( floor n base ) ) .( let ( ( value ( normalize r base ) ) ) .( unless ( zerop value ) ( push ( list index value ) ret ) ) ) ) ) ) ) .", "label": "", "metadata": {}, "score": "71.45897"}
{"text": "( values ( normalize ( rem num divisor ) divisor ) .( do ( ( n num ) r ( ret ( ) ) ( index 0 ( 1 + index ) ) ) .( ( zerop n ) .", "label": "", "metadata": {}, "score": "71.60815"}
{"text": "; ; some tests for libsvm . ; ; clisp -K full -E 1:1 -q -norc -i ./tests / tests -x ' ( run - test \" libsvm / test \" ) ' .( defparameter f - parameter ( libsvm : make - parameter ) ) .", "label": "", "metadata": {}, "score": "71.96611"}
{"text": "As we can see , there are three types of options , which are the general options , options on evaluation method , and options on base classifiers .We review these options as follows .The general options .If the user runs MILL by writing a .", "label": "", "metadata": {}, "score": "72.15698"}
{"text": "( coerce ( nreverse ( cons ( list -1 0d0 ) ret ) ) ' vector ) ) .x ) ) ) .( values ( make - problem : l len : y ( nreverse y ) :x ( nreverse x ) ) .", "label": "", "metadata": {}, "score": "72.209564"}
{"text": "ONE_CLASS : one - class - SVM .EPSILON_SVR : epsilon - SVM regression .NU_SVR : nu - SVM regression .kernel_type can be one of LINEAR , POLY , RBF , SIGMOID .PRECOMPUTED : kernel values in training_set_file .", "label": "", "metadata": {}, "score": "72.21186"}
{"text": "The data comes from Carnigie Learning and DataShop .This is the training set of the first problem : algebra_2008_2009 .We provide a transformed version used by the winner ( National Taiwan Univ ) .Because lables of the competition 's testing set are not available , the training data is split to two sets for training and validation .", "label": "", "metadata": {}, "score": "72.212524"}
{"text": "More details can be found here .Complete example for classification using train and test data set separately : This code works on the data set where the train and test set are separated , that is , train the model using train set and use the model to classify the test set .", "label": "", "metadata": {}, "score": "72.219345"}
{"text": "This way , two binary classifiers were trained with distinct sets of features to predict whether a recombinant fusion gene could be expressed and whether an expressed recombinant fusion protein would be soluble in E. coli .For protein expression , a binary classifier was trained to distinguish whether a recombinant fusion gene could be expressed as a protein in E. coli by focusing on features derived from nucleic acid sequences .", "label": "", "metadata": {}, "score": "72.23889"}
{"text": "( ( sys::closurep x ) ( sys::closure - documentation x ) ) . -( ( let ( ( name ( sys::subr - info x ) ) ) ; subr . -( and name ( get : documentation name ) ) ) ) .", "label": "", "metadata": {}, "score": "72.39392"}
{"text": "The validation set is called the testing set here .To access the raw data set , please check the above \" KDD CUP 2010 \" link .This data set is only to be used for research purposes .Users please acknowledge the data is from Carnigie Learning and DataShop .", "label": "", "metadata": {}, "score": "72.396484"}
{"text": "RCS file : /cvsroot / clisp / clisp / src / NEWS , v . retrieving revision 1.341 . retrieving revision 1.342 .diff -u -d -r1.341 -r1.342 . --- NEWS4 Oct 2006 00:40:48 -00001.341 .+ + + NEWS4 Oct 2006 00:53:31 -00001.342 .", "label": "", "metadata": {}, "score": "72.491745"}
{"text": "First , mRNA expression and stability for a recombinant fusion gene and codon preference in E. coli were the major factors .For second step , solubility related features to test whether an expressed protein could be folded correctly as a soluble one in E. coli were applied .", "label": "", "metadata": {}, "score": "72.50038"}
{"text": "By using F score , performance of our methods was compared with previous works under the same criterion .Moreover , the areas under Receiver Operating Characteristic ( ROC ) and Precision Recall Curves ( PRC ) were used to assess the performance of our methods with previous works .", "label": "", "metadata": {}, "score": "72.52138"}
{"text": "PubMed View Article .Bertone P , Kluger Y , Lan N , Zheng D , Christendat D , Yee A , Edwards AM , Arrowsmith CH , Montelione GT , Gerstein M : SPINE : an integrated tracking database and data mining approach for identifying feasible targets in high - throughput structural proteomics .", "label": "", "metadata": {}, "score": "72.56284"}
{"text": "J Mol Biol 2004 , 336 : 115 - 30 .PubMed View Article .Luan CH , Qiu S , Finley JB , Carson M , Gray RJ , Huang W , Johnson D , Tsao J , Reboul J , Vaglio P , et al .", "label": "", "metadata": {}, "score": "72.63513"}
{"text": "Idicula - Thomas S , Kulkarni AJ , Kulkarni BD , Jayaraman VK , Balaji PV : A support vector machine - based method for predicting the propensity of a protein to be soluble or to form inclusion body on overexpression in Escherichia coli .", "label": "", "metadata": {}, "score": "72.69511"}
{"text": "Moreover , according to the observation from our experimental data , a given protein could result in different expression levels when being over - expressed in different vectors in E. coli .Therefore , this work is the instance of encompassing the entire cloning and expression regions .", "label": "", "metadata": {}, "score": "72.72901"}
{"text": "As shown in Figure 3 for PRC , ensemble models between flatSVM and nestSVM resulted in a higher auPRC of 0.8093 .As shown in Figure 4 , ensemble models among all methods achieved 0.9045 in auROC .Yule 's Q - statistic was performed to proposed methods .", "label": "", "metadata": {}, "score": "72.94925"}
{"text": "This function frees the memory used by a parameter set .Java Version .The pre - compiled java class archive ' libsvm.jar ' and its source files are . in the java directory .To run the programs , use . java -classpath libsvm.jar svm_toy .", "label": "", "metadata": {}, "score": "72.960815"}
{"text": "p is the epsilon in epsilon - insensitive loss function . of epsilon - SVM regression .nr_weight , weight_label , and weight are used to change the penalty .for some classes ( If the weight for a class is not changed , it is . set to 1 ) .", "label": "", "metadata": {}, "score": "72.98041"}
{"text": "make - parameter nr_weight ( length weight ) ) .( let ( ( ret ( allocate - deep ' parameter .( vector svm_type kernel_type degree . gamma coef0 cache_size eps C .nr_weight weight_label weight .nu p shrinking probability ) ) ) ) .", "label": "", "metadata": {}, "score": "73.15163"}
{"text": "Tawarmalani , M. , Sahinidis , N. : Exact algorithms for global optimization of mixed- integer nonlinear programs .In Pardalos , P. , Romeijn , H. , eds .: Handbook of Global Optimization .Volume 2 .Kluwer Academic Publishers , Dordrecht ( 2002 ) 65 - 86 4 .", "label": "", "metadata": {}, "score": "73.247734"}
{"text": "-p epsilon : set the epsilon in loss function of epsilon - SVR ( default 0.1 ) .-m cachesize : set cache memory size in MB ( default 100 ) .-e epsilon : set tolerance of termination criterion ( default 0.001 ) .", "label": "", "metadata": {}, "score": "73.289345"}
{"text": "However , different results having been observed by using different fusion vectors were considered in this study .Instead of considering only target proteins , features in protein levels were derived from entire recombinant fusion proteins .It is known that PTMs rarely occur in E. coli .", "label": "", "metadata": {}, "score": "73.5484"}
{"text": "In naive byes classifier i want to find out the accuracy from my train and test .But my train set is like Happy : absolution abundance abundant accolade accompaniment accomplish accomplished achieve ...DOI : 10.1007/978 - 3 - 642 - 21311 - 3_15 Conference : Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems - 8th International Conference , CPAIOR 2011 , Berlin , Germany , May 23 - 27 , 2011 .", "label": "", "metadata": {}, "score": "73.5788"}
{"text": "We also showed the performance of AdaBoost as our baseline performance .Overall , flatSVM with high F 1 measure , F score , and accuracy seems to outperform other methods .Using Student 's t - test , we investigated the pair wise relationship of three proposed methods with respect to accuracy .", "label": "", "metadata": {}, "score": "73.589645"}
{"text": "Precision - Recall Curve ( PRC ) and Receiver Operating Characteristic ( ROC ) were used to compare performance of our methods to previous works .The following sections describe feature extraction and our three proposed methods in more detail .Feature generation .", "label": "", "metadata": {}, "score": "73.62566"}
{"text": "( libsvm : destroy - problem f - problem-2 - 7 ) NIL .( defparameter f - problem-3 - 7 ( problem 1000 3 7 ) )F - PROBLEM-3 - 7 .( libsvm : save - problem \" svm - problem \" f - problem-3 - 7 ) NIL .", "label": "", "metadata": {}, "score": "73.74923"}
{"text": "MIL_run('classify -t example.data -sf 0 -- train_test_validate -t 50 -- bag_MI_SVM -Kernel 2 -KernelParam 0.1 -CostFactor 10 ' ) ; .Example 4 .Train with the data in example.data and test on example2.data using EM - DD algorithm with default parameters .", "label": "", "metadata": {}, "score": "73.86568"}
{"text": "According to the claim of PROSO , correct evaluation occurred only when target proteins were without trans - membrane segment .Hence , after checking proteins in our dataset by TMHMM [ 34 ] , the bad performance of PROSO would be because of the existence of trans - membrane segments in recombinant fusion proteins that were not removed .", "label": "", "metadata": {}, "score": "73.90495"}
{"text": "Compared our three methods to others , the best result of our proposed method is flatSVM , which outperformed by achieving the auPRC and auROC of 0.8001 and 0.8891 , respectively .Comparative analysis with ROC curves .The ROC Curves of the comparative analysis of solubility prediction methods .", "label": "", "metadata": {}, "score": "74.13052"}
{"text": "heart_scale .Identical to _ test1 except that it shows how to specify the kernel ( e.g. , ' -t 4 ' ) in the code .demo_libsvm_test3 . m . binary . semi - automatic , but the code is still not compact . separated . default .", "label": "", "metadata": {}, "score": "74.16466"}
{"text": "PubMed View Article .Smialowski P , Martin - Galiano AJ , Mikolajka A , Girschick T , Holak TA , Frishman D : Protein solubility : sequence based prediction and experimental verification .Bioinformatics 2007 , 23 ( 19 ) : 2536 - 42 .", "label": "", "metadata": {}, "score": "74.20006"}
{"text": "-Aggregate ( def ' avg ' ) : The method of combining the classification results obtained using different starting points .-Threshold ( def 0.5 ) : The threshold on probability above which a bag / instance is classified positive . \u00b7 EMDD .", "label": "", "metadata": {}, "score": "74.20346"}
{"text": "( defparameter v - parameter ( ffi : foreign - value f - parameter ) ) .V - PARAMETER .( ffi : validp f - parameter ) T .( libsvm : destroy - parameter f - parameter ) NIL .", "label": "", "metadata": {}, "score": "74.34179"}
{"text": "Message : 3 .Date : We d , 04 Oct 2006 00:53:37 +0000 .Subject : clisp / doc impnotes.xml.in , 1.93 , 1.94 impext.xml , 1.463 , . 1.464Makefile , 1.87 , 1.88 .To : clisp - cvs@ ... .", "label": "", "metadata": {}, "score": "74.3682"}
{"text": "( : arguments ( model model ) ) .( : return - type int ) ) .; ; ; high - level helpers .( defun destroy - parameter ( parameter ) .( when ( validp parameter ) .", "label": "", "metadata": {}, "score": "74.38636"}
{"text": "PubMed View Article .Shih YP , Wu HC , Hu SM , Wang TF , Wang AH : Self - cleavage of fusion protein in vivo using TEV protease to yield native protein .Protein Sci 2005 , 14 ( 4 ) : 936 - 41 .", "label": "", "metadata": {}, "score": "74.424995"}
{"text": "Two major steps in recombinant protein productions in E. coli ; i.e. , transcribing messenger RNAs ( mRNAs ) of cloning and expression regions , and translating proteins of recombinant fusion vectors , were considered .The major factors were correlated to mRNA expression and stability , codon usage in E. coli , solubility of whole fusion vectors , and Post - Translational Modifications ( PTMs ) on recombinant proteins .", "label": "", "metadata": {}, "score": "74.46208"}
{"text": "If you use MILL in your scientific work , please cite as .System Requirement .You need Matlab and Perl to run MILL .You can run it in Windows or Linux / Unix .However , the two of the SVM - based MIL algorithms ( inst_MI_SVM and bag_MI_SVM ) need to call executables in LibSVM package , and these executables are complied in Windows .", "label": "", "metadata": {}, "score": "74.47945"}
{"text": "The unfilled markers represent data instance from the train set .The filled markers represent data instance from the test set , and filled color represents the class label assigned by SVM whereas the edge color represents the true ( ground - truth ) label .", "label": "", "metadata": {}, "score": "74.53123"}
{"text": "clisp - cvs@ ... https://lists.sourceforge.net/lists/listinfo/clisp-cvs .End of clisp - cvs Digest , Vol 6 , Issue 6 .Send clisp - cvs mailing list submissions to clisp - cvs@ ...To subscribe or unsubscribe via the World Wide Web , visit https://lists.sourceforge.net/lists/listinfo/clisp-cvs .", "label": "", "metadata": {}, "score": "74.576324"}
{"text": "PubMed .Christendat D , Yee A , Dharamsi A , Kluger Y , Gerstein M , Arrowsmith CH , Edwards AM : Structural proteomics : prospects for high throughput sample preparation .Prog Biophys Mol Biol 2000 , 73 ( 5 ) : 339 - 45 .", "label": "", "metadata": {}, "score": "74.71585"}
{"text": "Computational simulation of enhancing solubility by limit mutations or optimal codons .In biotechnology perspective , to improve the solubility of target proteins , some laboratory workers may mutate few nucleotides in target genes without affecting their corresponding translational proteins .Moreover , according to the codon preference in E. coli , they synthesize whole nucleotide sequences based on the amino acid sequences .", "label": "", "metadata": {}, "score": "74.86231"}
{"text": "( defun problem ( repeat divisor base ) .( let ( ( x ( make - array repeat ) )( y ( make - array repeat ) ) ) .( dotimes ( i repeat ) .( multiple - value - bind ( n v ) ( task i divisor base ) .", "label": "", "metadata": {}, "score": "74.94971"}
{"text": "In directory sc8-pr - cvs4 . sourceforge.net:/tmp/cvs-serv19582/doc .Modified Files : . impnotes.xml.in impext.xml Makefile .Log Message : . and makes Support Vector Machines available in CLISP .Index : impext.xml .RCS file : /cvsroot / clisp / clisp / doc / impext .", "label": "", "metadata": {}, "score": "75.08879"}
{"text": "-pf ( def 0 ) : The prediction format , either 0 or 1 ( preprocess .PredFormat ) .-if ( def 0 ) : The input format is normal or sparse , 1 for sparse ( preprocess .InputFormat ) . -oflag ( def ' a ' )", "label": "", "metadata": {}, "score": "75.13782"}
{"text": "Then we can decide the fate .Sean Owen added a comment - 26/Jan/11 15:01 Looks like there has been no activity on this for 6 months , since GSoC finished , from the student or sponsor .Ted suggests it 's not really committable or needed .", "label": "", "metadata": {}, "score": "75.39569"}
{"text": "Bug Reports .If you find bugs or you have problems with the code you can not solve by yourself , please contact me via email juny@cs.cmu.edu .Disclaimer .This software is free only for non - commercial use .It must not be modified and distributed without prior permission of the author .", "label": "", "metadata": {}, "score": "75.64679"}
{"text": "Copyright .\u00a9 Chan et al .2010 .This article is published under license to BioMed Central Ltd. libsvm is a great tool for SVM as it is very easy to use and is documented well .The libsvm package webpage is maintained by Chih - Chung Chang and Chih - Jen Lin of NTU .", "label": "", "metadata": {}, "score": "75.75105"}
{"text": "4 -- precomputed kernel ( kernel values in training_set_file ) .-d degree : set degree in kernel function ( default 3 ) .-g gamma : set gamma in kernel function ( default 1/k ) .-r coef0 : set coef0 in kernel function ( default 0 ) . -c cost : set the parameter C of C - SVC , epsilon - SVR , and nu - SVR ( default 1 ) .", "label": "", "metadata": {}, "score": "75.77838"}
{"text": "( nu double - float ) ; for NU_SVC , ONE_CLASS , and NU_SVR .( p double - float ) ; for EPSILON_SVR .( shrinking int ) ; use the shrinking heuristics .( probability int ) ) ) ; do probability estimates .", "label": "", "metadata": {}, "score": "76.138306"}
{"text": "( ( weight_label weight_label ) ( if v - p ( svref v 9 ) # ( ) ) ) .( ( weight weight ) ( if v - p ( svref v 10 ) # ( ) ) ) .", "label": "", "metadata": {}, "score": "76.15616"}
{"text": "Bound tightening is an important component of algorithms for solving nonconvex Mixed Integer Nonlinear Programs .A probing algorithm is a bound - tightening procedure that explores the consequences of restricting a variable to a subinterval with the goal of tightening its bounds .", "label": "", "metadata": {}, "score": "76.177536"}
{"text": "These over - expressed proteins in an insoluble form are termed as inclusion bodies .Since the refolding procedure of inclusion bodies to recover a soluble form of recombinant proteins is time - consuming , expression of insoluble protein aggregates is frequently a major obstacle in recombinant protein production .", "label": "", "metadata": {}, "score": "76.40253"}
{"text": "( ext : finalize ret # ' destroy - parameter ) .ret ) ) .( defun make - problem ( & key ( l 0 ) y x ) .; ; you must call ( destroy - problem ret ) yourself ! ; ; -- but remember that ' model ' returned by ' train ' uses ' problem ' , . ; ; so you can not free ' problem ' until you free all ' model 's .", "label": "", "metadata": {}, "score": "76.47631"}
{"text": "We should be clear that the end product is indeed going to be used , and then do the work to put it in .Worth thinking about as GSoC 2011 opens up .Ted Dunning added a comment - 19/Jan/11 08:13 It did n't sound real ready to me .", "label": "", "metadata": {}, "score": "76.76159"}
{"text": "( eps double - float ) ; stopping criteria .( C double - float ) ; for C_SVC , EPSILON_SVR and NU_SVR .( nr_weight int ) ; for C_SVC .( weight_label ( c - array - ptr int ) ) ; for C_SVC .", "label": "", "metadata": {}, "score": "76.792816"}
{"text": "Log Message : .( GPG ) : add -yes .Index : Makefile.devel .RCS file : /cvsroot / clisp / clisp / Makefile.devel , v . retrieving revision 1.154 . retrieving revision 1.155 .diff -u -d -r1.154 -r1.155 . --- Makefile.devel1 Oct 2006 19:05:43 -00001.154 .", "label": "", "metadata": {}, "score": "76.799706"}
{"text": "Idicula - Thomas S , Balaji PV : Understanding the relationship between the primary structure of proteins and its propensity to be soluble on overexpression in Escherichia coli .Protein Sci 2005 , 14 ( 3 ) : 582 - 92 .", "label": "", "metadata": {}, "score": "76.97664"}
{"text": "I searched online and got to know about the basics .I wanted to use libsvm ...I wanna classify Movielense users table demographic data but the result of J48 is weird , I classify my data with C5.0 and every thing was fine But I must work on this algorithm ( j48 ) structure of my ... .", "label": "", "metadata": {}, "score": "77.22165"}
{"text": "( ffi : validp f - problem-3 - 7 ) NIL .( ffi : validp f - parameter ) T .( libsvm : destroy - parameter f - parameter ) NIL .( ffi : validp f - parameter ) NIL .", "label": "", "metadata": {}, "score": "77.28758"}
{"text": "( degree int ) ; for poly .( gamma double - float ) ; for poly / rbf / sigmoid .( coef0 double - float ) ; for poly / sigmoid . ; ; these are for training only .", "label": "", "metadata": {}, "score": "77.426254"}
{"text": "Pegasos : Primal estimated sub - gradient solver for svm .In ICML ' 07 : Proceedings of the 24th international conference on Machine learning , pages 807 - 814 , New York , NY , USA , 2007 .ACM .", "label": "", "metadata": {}, "score": "77.45311"}
{"text": "Gonzalez - Montalban N , Garcia - Fruitos E , Villaverde A : Recombinant protein solubility - does more mean better ?Nat Biotechnol 2007 , 25 ( 7 ) : 718 - 20 .PubMed View Article .J Proteome Res 2005 , 4 ( 6 ) : 1942 - 51 .", "label": "", "metadata": {}, "score": "77.59627"}
{"text": "C:\\Program Files\\Microsoft Visual Studio .NET 2003\\Vc7\\bin\\vcvars32.bat \" .You may have to modify the above according which version of VC++or . where it is installed .Type . nmake -f Makefile.win clean all .( optional )To build python interface , download and install Python .", "label": "", "metadata": {}, "score": "78.38205"}
{"text": "Sahinidis , N. : Baron : Branch and reduce optimization navigator , user 's manual , version 4.0 .Belotti , P. : Couenne : a user 's manual .Technical report , Lehigh University ( 2009 ) 12 .Shectman , J. , Sahinidis , N. : A finite algorithm for global minimization of separable concave programs .", "label": "", "metadata": {}, "score": "78.38881"}
{"text": "Consequently , in this study , Codon Adaptation Index ( CAI ) has been calculated based on codon preference in E. coli K12 strain by EMBOSS package [ 28 ] .As described in previous works , 6 and 444 sequence - independent and non - redundant features used in [ 13 ] and [ 22 ] were extracted , respectively .", "label": "", "metadata": {}, "score": "78.39686"}
{"text": "Download & Installation .Install Matlab in your machine ( Skip this if it is already installed ) .Add the path $ MILLRoot in Matlab .It is ready to go .This section explains how to use the MILL software .", "label": "", "metadata": {}, "score": "78.68023"}
{"text": "gnu - distrib : $ ( SRC_DIST1 ) force .mkdir -p $ ( ARCHIVE ) . cp -f src / NEWS SUMMARY $ ( ARCHIVE ) .Message : 2 .Date : We d , 04 Oct 2006 00:40:55 +0000 .", "label": "", "metadata": {}, "score": "78.72967"}
{"text": "( ffi : slot ( ffi : foreign - value f - parameter ) ' libsvm::C ) 1d0 .( ffi : slot ( ffi : foreign - value f - parameter ) ' libsvm::kernel_type ) .libsvm::LINEAR .v - parameter ( ffi : foreign - value f - parameter ) ) .", "label": "", "metadata": {}, "score": "79.06468"}
{"text": "typedef float Qfloat ; . typedef signed char schar ; . # ifndef min .# endif .# ifndef max .# endif .[ ...3036 lines suppressed ... ] .free(label ) ; .free(count ) ; . free(label ) ; . ---", "label": "", "metadata": {}, "score": "79.1627"}
{"text": "You need GTK+ library to build the GTK version .We use Visual C++ to build the Windows version .The pre - built Windows binaries are in the windows directory .svm - train ' Usage .Usage : svm - train [ options ] training_set_file [ model_file ] .", "label": "", "metadata": {}, "score": "79.18881"}
{"text": "Wang HM , Shih YP , Hu SM , Lo WT , Lin HM , Ding SS , Liao HC , Liang PH : Parallel gene cloning and protein production in multiple expression systems .Biotechnol Prog 2009 .Makrides SC : Strategies for achieving high - level expression of genes in Escherichia coli .", "label": "", "metadata": {}, "score": "79.29242"}
{"text": "References .Baneyx F : Recombinant protein expression in Escherichia coli .Curr Opin Biotechnol 1999 , 10 ( 5 ) : 411 - 21 .PubMed View Article .Jonasson P , Liljeqvist S , Nygren PA , Stahl S : Genetic design for facilitated production and recovery of recombinant proteins in Escherichia coli .", "label": "", "metadata": {}, "score": "79.525085"}
{"text": "Guanine - cytosine content ( GC - content ) calculated from nucleic acid sequences of recombinant fusion genes were also taken into account .For protein expression , codon usage bias in E. coli could be a key factor of determining the efficiency of translation .", "label": "", "metadata": {}, "score": "79.527176"}
{"text": "# + FFI ( ( eq ( type - of x ) ' ffi::foreign - function ) .( setf ( getf ( sys::%record - ref x 5 ) : documentation ) new - value ) ) .( ( sys::closurep x ) ( sys::closure - set - documentation x new - value ) ) . -", "label": "", "metadata": {}, "score": "79.67672"}
{"text": "---NEW FILE : svm.h --- .# ifndef _ LIBSVM_H .# define _ LIBSVM_H .# ifdef _ _ cplusplus .# endif . struct svm_node .int index ; . struct svm_problem . int l ; . structsvm_parameter . int svm_type ; . int kernel_type ; . # endif . ---", "label": "", "metadata": {}, "score": "79.68029"}
{"text": "You can do it in both terminal and in MATLAB workspace .On Ubuntu machine , just to make sure you have gcc in your machine .If not , you need to install it using the command below : . %", "label": "", "metadata": {}, "score": "79.85759"}
{"text": "Ted Dunning added a comment - 08/Apr/10 21:29 There is little to say .This is an excellent proposal .You clearly have the background and the capability to succeed .A key limitation will be whether we have enough mentors .", "label": "", "metadata": {}, "score": "79.93533"}
{"text": "Funding :This work is supported in part by the National Research Program in Genomic Medicine ( NRPGM ) , NSC , Taiwan , under Grant No . NSC98 - 3112-B-001 - 026 ( Advanced Bioinformatics Core ) and NSC96 - 3112-B-001 - 013 ( Core Facility of Recombinant Protein Production ) , and in part under Grant No .", "label": "", "metadata": {}, "score": "80.042175"}
{"text": "Results .In this study , we applied machine learning to train prediction models to predict whether a pairing of vector - protein will express or not express in E. coli .For expressed cases , the models further predict whether the expressed proteins would be soluble .", "label": "", "metadata": {}, "score": "80.09151"}
{"text": "Knowl .Inf .Syst . , 14(1):1 - 37 , 2007 .Affiliated with .Affiliated with .Abstract .Background .Recombinant protein production is a useful biotechnology to produce a large quantity of highly soluble proteins .Currently , the most widely used production system is to fuse a target protein into different vectors in Escherichia coli ( E. coli ) .", "label": "", "metadata": {}, "score": "80.09947"}
{"text": "-(defun set - function - documentation ( x new - value ) .+ ( defun set - function - documentation ( x new - value & aux name ) .( setf ( std - gf - documentation x ) new - value ) ) .", "label": "", "metadata": {}, "score": "80.16788"}
{"text": "modification , are permitted provided that the following conditions .are met : .Redistributions of source code must retain the above copyright . notice , this list of conditions and the following disclaimer .Redistributions in binary form must reproduce the above copyright . notice , this list of conditions and the following disclaimer in the . documentation and/or other materials provided with the distribution .", "label": "", "metadata": {}, "score": "80.2968"}
{"text": "Elena SF , Whittam TS , Winkworth CL , Riley MA , Lenski RE : Genomic divergence of Escherichia coli strains : evidence for horizontal transfer and variation in mutation rates .Int Microbiol 2005 , 8 ( 4 ) : 271 - 8 .", "label": "", "metadata": {}, "score": "80.31566"}
{"text": "clisp - cvs mailing list .clisp - cvs@ ... https://lists.sourceforge.net/lists/listinfo/clisp-cvs .End of clisp - cvs Digest , Vol 6 , Issue 5 .I wanna classify Movielense users table demographic data but the result of J48 is weird , I classify my data with C5.0 and every thing was fine But I must work on this algorithm ( j48 ) structure of my ... .", "label": "", "metadata": {}, "score": "80.33841"}
{"text": "To date , Escherichia coli ( E. coli ) , one of Gram - negative bacteria , is still an approachable and favored host for cloning and expressing a given protein in many occasions [ 1 - 3 ] .In recent years , a variety of studies have developed well - established large - scale and high - throughput systems to obtain large quantities of soluble recombinant proteins [ 4 - 6 ] .", "label": "", "metadata": {}, "score": "80.53192"}
{"text": "Biotechnology ( N Y ) 1991 , 9 ( 5 ) : 443 - 448 .View Article .Davis GD , Elisee C , Newham DM , Harrison RG : New fusion protein systems designed to give soluble expression in Escherichia coli .", "label": "", "metadata": {}, "score": "80.662735"}
{"text": "Kapust RB , Waugh DS : Escherichia coli maltose - binding protein is uncommonly effective at promoting the solubility of polypeptides to which it is fused .Protein Sci 1999 , 8 ( 8) : 1668 - 74 .PubMed View Article .", "label": "", "metadata": {}, "score": "80.757416"}
{"text": "PROFITS ; OR BUSINESS INTERRUPTION ) HOWEVER CAUSED AND ON ANY THEORY OF .LIABILITY , WHETHER IN CONTRACT , STRICT LIABILITY , OR TORT ( INCLUDING .NEGLIGENCE OR OTHERWISE )ARISING IN ANY WAY OUT OF THE USE OF THIS .", "label": "", "metadata": {}, "score": "80.91083"}
{"text": "( makunbound ' v - parameter ) .( makunbound ' f - problem ) .( makunbound ' l - problem ) .( makunbound ' model ) .( makunbound ' maxindex ) .( delete - file \" svm - model \" ) .", "label": "", "metadata": {}, "score": "81.06401"}
{"text": "The training data ( gisette_train ) are feature - wisely scaled to [ -1,1].Then the testing data ( gisette_valid ) are scaled based on the same scaling factors for the training data .These two scaled data sets are used in [ GXY11a ] .", "label": "", "metadata": {}, "score": "81.17185"}
{"text": "Agarwal et al .( 2014 ) use the script to explicitly store all feature values .We apply the same script to the original data for generating training / test files : . fasta data / H_sapiens_acc_all_examples_plain_139 - 279_50000000 .fasta_down data / H_sapiens_acc_all_examples_plain_139 - 279_50000000 .", "label": "", "metadata": {}, "score": "81.17386"}
{"text": "( with - open - file ( out file : direction : output ) .( destructuring - bind ( size y x ) ( foreign - value problem ) .( when log .( force - output log ) ) .", "label": "", "metadata": {}, "score": "81.212006"}
{"text": "NEWS29 Sep 2006 01:16:46 -00001.340 .+ + + NEWS4 Oct 2006 00:40:48 -00001.341 .+ User visible changes .+ + DOCUMENTATION on built - in functions was broken on some platforms .+ [ 1569234 ] .Index : documentation.lisp .", "label": "", "metadata": {}, "score": "81.27934"}
{"text": "( read - from - string line t nil : start ( 1 + colon ) ) ) .( setq maxindex ( max maxindex index ) ) .( push ( list ( coerce index ' integer ) .( coerce value ' double - float ) ) .", "label": "", "metadata": {}, "score": "81.550964"}
{"text": "On the other hand , PRC consists of True Positive Rate ( TPR ) and Positive Predictive Value ( PPV ) as x and y - axes , respectively .The detail calculations were as follows .To investigate difference between pairs of our three methods , Student 's t - test and Yule 's Q - statistic [ 33 ] were conducted to demonstrate the relationship of diversity .", "label": "", "metadata": {}, "score": "81.59932"}
{"text": "Trial - and - error is still the common practice to find out the efficacy of a vector for a given target protein .Previous studies are limited in that they assumed that proteins would be over - expressed and focused only on the solubility of expressed proteins .", "label": "", "metadata": {}, "score": "82.67868"}
{"text": "In their study , the most prominent protein feature was GRAVY ( Grand Average of Hydropathicity , an indicator for average hydrophobicity of a protein ) [ 18 ] .To date , many studies have showed that Support Vector Machines ( SVMs ) combining with appropriate kernels frequently result in better performance for biological sequence classification than other methods based on statistical learning theory [ 19 , 20 ] .", "label": "", "metadata": {}, "score": "82.75996"}
{"text": "Desc : Use the input file for training only , and do no testing .Options : -m ( def ' ' ) : The output model file . \u00b7Test_only .Desc : Use the input file for testing only .", "label": "", "metadata": {}, "score": "82.823975"}
{"text": "cjlin@ ... .Acknowledgments : .This work was supported in part by the National Science .Council of Taiwan via the grant NSC 89 - 2213-E-002 - 013 .The authors thank their group members and users .for many helpful discussions and comments . ---", "label": "", "metadata": {}, "score": "82.8645"}
{"text": "[ 23 ] .The studies mentioned above have at least two basic postulations : 1 ) a given gene was thought to have been over - expressed and 2 ) the expression level of a target gene was the same whatever by fusing different vectors in E. coli .", "label": "", "metadata": {}, "score": "83.00639"}
{"text": "+ ( defun function - documentation ( x & aux name ) .( std - gf - documentation x ) ) .( ( eq ( type - of x ) ' FUNCTION ) ; interpreted function ?# + FFI ( ( eq ( type - of x ) ' ffi::foreign - function ) .", "label": "", "metadata": {}, "score": "83.31819"}
{"text": "+ for sample usage .Take Surveys .Earn Cash .Influence the Future of IT .Join SourceForge.net 's Techsay panel and you 'll get the chance to share your ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "84.231674"}
{"text": "Makefile16 Aug 2006 04:05:54 -00001.87 .+ + + Makefile4 Oct 2006 00:53:35 -00001.88 ./modules / dirkey / dirkey .xml\\ ./modules / fastcgi / fastcgi .xml\\ ./modules / i18n / i18n .xml\\ ./modules / libsvm / svm .", "label": "", "metadata": {}, "score": "84.86851"}
{"text": "PubMed View Article .Sorensen HP , Mortensen KK : Advanced genetic strategies for recombinant protein expression in Escherichia coli .J Biotechnol 2005 , 115 ( 2 ) : 113 - 28 .PubMed View Article .Shih YP , Kung WM , Chen JC , Yeh CH , Wang AH , Wang TF : High - throughput screening of soluble recombinant proteins .", "label": "", "metadata": {}, "score": "85.27991"}
{"text": "One versus One ( One - vs .-One ) ; ( 2 )One versus Others ( One - vs .-Others ) .We will explain the later scheme due to it is a bit easier to understand .An intuitive example will be introduced firstly .", "label": "", "metadata": {}, "score": "85.307816"}
{"text": "Today 's Topics : . clisp / src NEWS,1.341,1.342 ChangeLog,1.5402,1.5403 ( Sam Steingold ) .clisp / modules / libsvm svm.xml,1.1,1.2 ( Sam Steingold ) .Message : 1 .Date : We d , 04 Oct 2006 00:53:37 +0000 .Subject : clisp / src NEWS,1.341,1.342 ChangeLog,1.5402,1.5403 .", "label": "", "metadata": {}, "score": "85.67408"}
{"text": "NEW FILE : libsvm.lisp --- . ; ; ; LIBSVM interface .; ; ; Copyright ( C ) 2006 by Sam Steingold . ; ; ; This is Free Software , covered by the GNU GPL ( v2 ) .( defpackage \" LIBSVM \" .", "label": "", "metadata": {}, "score": "86.276"}
{"text": "Authors ' Affiliations .Institute of Biomedical Informatics , National Yang - Ming University .Bioinformatics Program , Taiwan International Graduate Program , Academia Sinica .Institute of Information Science , Academia Sinica .Institute of Biological Chemistry , Academia Sinica .", "label": "", "metadata": {}, "score": "86.92234"}
{"text": "3.3.2 Parallel Model Selection Similar to Multi - Class Classification , SVM Model selection is stacked with a set of binary classifier .Thus , we may leverage MapReduce framework to accelerate the process of model selection .4 Biography I am a graduating masters student in Multimedia Information Retrieval System from National University of Singapore .", "label": "", "metadata": {}, "score": "87.31115"}
{"text": "This is a tool for scaling input data file .svm - toy : .This is a simple graphical interface which shows how SVM . separate data in a plane .You can click in the window to . draw data points .", "label": "", "metadata": {}, "score": "87.35487"}
{"text": "Makefile COPYRIGHT .Log Message : . and makes Support Vector Machines available in CLISP . ---NEW FILE : COPYRIGHT --- .Copyright ( c ) 2000 - 2005 Chih - Chung Chang and Chih - Jen Lin .All rights reserved .", "label": "", "metadata": {}, "score": "89.248764"}
{"text": "This article has been published as part of BMC Bioinformatics Volume 11 Supplement 1 , 2010 : Selected articles from the Eighth Asia - Pacific Bioinformatics Conference ( APBC 2010 ) .Competing interests .The authors declare that they have no competing interests .", "label": "", "metadata": {}, "score": "90.00397"}
{"text": "/modules / matlab / matlab .xml\\ ./modules / netica / netica .xml\\ ./modules / oracle / oracle .xml\\ .Index : impnotes.xml.in .RCS file : /cvsroot / clisp / clisp / doc / impnotes . xml.in,v . retrieving revision 1.93 . retrieving revision 1.94 . diff -u -d -r1.93 -r1.94 . --- impnotes.xml.in25 Aug 2006 00:09:48 -00001.93 .", "label": "", "metadata": {}, "score": "90.64592"}
{"text": "may be used to endorse or promote products derived from this software .without specific prior written permission .THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS . ''AS IS ' ' AND ANY EXPRESS OR IMPLIED WARRANTIES , INCLUDING , BUT NOT .", "label": "", "metadata": {}, "score": "91.8076"}
{"text": "( ( p p ) ( if v - p ( svref v 12 ) 1d-1 ) ) .( ( shrinking shrinking ) ( if v - p ( svref v 13 ) 1 ) ) .( ( probability probability ) ( if v - p ( svref v 14 ) 0 ) ) ) .", "label": "", "metadata": {}, "score": "94.217865"}
{"text": "fasta_down data / H_sapiens_acc_all_examples_plain_139 - 279_5e7_test .fasta_up data / H_sapiens_acc_all_examples_plain_5e7_test .label .This set is higly skewed , so auPRC ( area under precision - recall curve ) is the suitable criterion .Using matlab statistics toolbox , you can obtain auPRC by .", "label": "", "metadata": {}, "score": "97.487305"}
{"text": "Red . %Tght . %Red . %Gap % 5822.00 5.05 253 12.1725.00 25310.4331.84 37146.9050.12 37146.9050.97 37151.7248.53 37149.6647.91 325 9.5224.80 46247.5149.45 46247.5149.57 46249.7250.20 46249.7248.85 46249.7248.26 4068.2016.81 1393 0.00 0.00 6490.0092.07 7690.9188.25 25319.1326.50 29054.8747.15 25317.3928.12 37159.3145.35 46256.3545.76 50217.1938.16 361 35.5035.67 8141.6733.33 10961.2228.33 14143.7525.60 1285 14.39 67.42 3592.78 100.00 31925.51 56.54 17414.0825.38 31915.3162.02 23.92 43.53 Time Tght . %", "label": "", "metadata": {}, "score": "100.16634"}
{"text": "You may need to increase maximum Java heap size .Library usages are similar to the C version .These functions are available : . public static svm_model svm_train(svm_problem prob , svm_parameter param ) ; . public static void svm_cross_validation(svm_problem prob , svm_parameter param , int nr_fold , double [ ] target ) ; . public static int svm_get_svm_type(svm_model model ) ; . public static int svm_get_nr_class(svm_model model ) ; . public static void svm_get_labels(svm_model model , int [ ] label ) ; . public static double svm_get_svr_probability(svm_model model ) ; . public static void svm_predict_values(svm_model model , svm_node [ ] x , double [ ] dec_values ) ; . public static double svm_predict(svm_model model , svm_node [ ] x ) ; . public static double svm_predict_probability(svm_model model , svm_node [ ] x , double [ ] prob_estimates ) ; . public static void svm_save_model(String model_file_name , svm_model model ) throws IOException . public static svm_model", "label": "", "metadata": {}, "score": "103.38489"}
{"text": "The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .Publisher conditions are provided by RoMEO .Differing provisions from the publisher 's actual policy or licence agreement may be applicable .", "label": "", "metadata": {}, "score": "109.40681"}
