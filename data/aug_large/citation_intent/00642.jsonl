{"text": "Metonymy resolution .Temporal information processing .Coreference resolution .Sentiment analysis .This list is expected to grow as the field progresses .Some tasks are closely related to each other .For instance , word sense disambiguation ( monolingual , multi - lingual and cross - lingual ) , word sense induction task , lexical substitution and evaluation of lexical resources are all related to word senses .", "label": "", "metadata": {}, "score": "32.055504"}
{"text": "The tasks in this area include lexical sample and all - word disambiguation , multi- and cross - lingual disambiguation , and lexical substitution .Given the difficulties of identifying word senses , other tasks relevant to this topic include word - sense induction , subcategorization acquisition , and evaluation of lexical resources .", "label": "", "metadata": {}, "score": "32.626976"}
{"text": "The tasks in this area include lexical sample and all - word disambiguation , multi- and cross - lingual disambiguation , and lexical substitution .Given the difficulties of identifying word senses , other tasks relevant to this topic include word - sense induction , subcategorization acquisition , and evaluation of lexical resources .", "label": "", "metadata": {}, "score": "32.626976"}
{"text": "The tasks in this area include lexical sample and all - word disambiguation , multi- and cross - lingual disambiguation , and lexical substitution .Given the difficulties of identifying word senses , other tasks relevant to this topic include word - sense induction , subcategorization acquisition , and evaluation of lexical resources .", "label": "", "metadata": {}, "score": "32.626976"}
{"text": "Currently , in this approach I am more concerned on the measurement which reflects the relation between the patterns of the two strings , rather than the meaning of the words .I implemented this algorithm when I was developing a tool to make the matching between XML schemas semi - automatic .", "label": "", "metadata": {}, "score": "33.353184"}
{"text": "This list is expected to grow as the field progresses .Some tasks are closely related to each other .For instance , word sense disambiguation ( monolingual , multi - lingual and cross - lingual ) , word sense induction task , lexical substitution , subcategorization acquisition and evaluation of lexical resources are all related to word senses .", "label": "", "metadata": {}, "score": "33.8524"}
{"text": "The task involves both finding the synonyms and disambiguating the context .It allows the use of any kind of lexical resource or technique , including word sense disambiguation and word sense induction .A cross - lingual task was also defined .", "label": "", "metadata": {}, "score": "35.436073"}
{"text": "We first describe an algorithm for converting the hierarchical structure of WordNet [ 13 ] ... \" .We discuss a method for augmenting and rearranging a structured lexicon in order to make it more suitable for a topic labeling task , by making use of lexical association information from a large text corpus .", "label": "", "metadata": {}, "score": "35.52676"}
{"text": "Some tasks are closely related to each other .For instance , word sense disambiguation ( monolingual , multi - lingual and cross - lingual ) , word sense induction task , lexical substitution and evaluation of lexical resources are all related to word senses .", "label": "", "metadata": {}, "score": "35.624615"}
{"text": "Some tasks are closely related to each other .For instance , word sense disambiguation ( monolingual , multi - lingual and cross - lingual ) , word sense induction task , lexical substitution and evaluation of lexical resources are all related to word senses .", "label": "", "metadata": {}, "score": "35.624615"}
{"text": "The former comprises disambiguating the occurrences of a small sample of target words which were previously selected , while in the latter all the words in a piece of running text need to be disambiguated .Tasks have been performed for many languages .", "label": "", "metadata": {}, "score": "35.8165"}
{"text": "The former comprises disambiguating the occurrences of a small sample of target words which were previously selected , while in the latter all the words in a piece of running text need to be disambiguated .Tasks have been performed for many languages .", "label": "", "metadata": {}, "score": "35.8165"}
{"text": "The former comprises disambiguating the occurrences of a small sample of target words which were previously selected , while in the latter all the words in a piece of running text need to be disambiguated .Tasks have been performed for many languages .", "label": "", "metadata": {}, "score": "35.8165"}
{"text": "With regard to semantic disambiguation , it should be appreciated that the present invention has wide ranging applications , for example in information retrieval , machine translation ; text summarisation , identifying sentiment and affect in text .Automatic retrieval and clustering of similar words .", "label": "", "metadata": {}, "score": "36.131565"}
{"text": "Tasks in this area include semantic role labeling , semantic relation analysis , and coreference resolution .Other tasks in this area look at more specialized issues of semantic analysis , such as temporal information processing , metonymy resolution , and sentiment analysis .", "label": "", "metadata": {}, "score": "36.154655"}
{"text": "The task is to identify the events described in a text and locate these in time , i.e. , identification of temporal referring expressions , events and temporal relations within a text .Coreference resolution : detection and resolution of coreferences .", "label": "", "metadata": {}, "score": "36.286964"}
{"text": "We describe and evaluate experimentally a method for clustering words according to their dis- tribution in particular syntactic contexts .Words are represented by the relative frequency distributions of contexts in which they appear , and relative entropy between those distributions is used as the si ... \" .", "label": "", "metadata": {}, "score": "36.62519"}
{"text": "In each of these potential applications , the contribution of the types of semantic analysis constitutes the most outstanding research issue .The former comprises disambiguating the occurrences of a small sample of target words which were previously selected , while in the latter all the words in a piece of running text need to be disambiguated .", "label": "", "metadata": {}, "score": "36.937096"}
{"text": "This task has expanded to inferring and developing new frames and frame elements , in individual sentences and in full running texts , with identification of intersentential links and coreference chains .The basic task began with attempts to replicate FrameNet data , specifically frame elements .", "label": "", "metadata": {}, "score": "36.976303"}
{"text": "A related task is cross - language information retrieval , where participants disambiguate in one language ( e.g. , with WordNet synsets ) and retrieve documents in another language ; standard information retrieval metrics are use to assess the quality of the disambiguation .", "label": "", "metadata": {}, "score": "37.07948"}
{"text": "A related task is cross - language information retrieval , where participants disambiguate in one language ( e.g. , with WordNet synsets ) and retrieve documents in another language ; standard information retrieval metrics are use to assess the quality of the disambiguation .", "label": "", "metadata": {}, "score": "37.07948"}
{"text": "A related task is cross - language information retrieval , where participants disambiguate in one language ( e.g. , with WordNet synsets ) and retrieve documents in another language ; standard information retrieval metrics are use to assess the quality of the disambiguation .", "label": "", "metadata": {}, "score": "37.07948"}
{"text": "A related task is cross - language information retrieval , where participants disambiguate in one language ( e.g. , with WordNet synsets ) and retrieve documents in another language ; standard information retrieval metrics are use to assess the quality of the disambiguation .", "label": "", "metadata": {}, "score": "37.07948"}
{"text": "The task involves both finding the synonyms and disambiguating the context .It allows the use of kind of lexical resource or technique , including word sense disambiguation and word sense induction .A cross - lingual task was also defined .", "label": "", "metadata": {}, "score": "38.042156"}
{"text": "The task involves both finding the synonyms and disambiguating the context .It allows the use of kind of lexical resource or technique , including word sense disambiguation and word sense induction .A cross - lingual task was also defined .", "label": "", "metadata": {}, "score": "38.042156"}
{"text": "In the language modeling task , a similarity - based model is used to improve probability estimates for unseen bigrams in a back - off language model .The similaritybased method yields a 20 % perplexity improvement in the prediction of unseen bigrams and statistically significant reductions in speech - recognition error .", "label": "", "metadata": {}, "score": "38.32409"}
{"text": "In fact , at this stage , the graph can be simply replaced with a table or array of n entries , associating each of the n points with their corresponding vertex .[0109 ] FIG .4 shows the main steps of a method 400 for semantic disambiguation ( by disambiguation engine 640 using the previously generator vector space 650 ) of a sentence .", "label": "", "metadata": {}, "score": "38.37488"}
{"text": "New tasks seek to measure the relational similarity between pairs of words , to extract drug - drug interactions from biomedical texts , and to develop methods in causal reasoning .Metonymy resolution : the figurative substitution of an attribute of a name for the thing specified .", "label": "", "metadata": {}, "score": "38.5621"}
{"text": "However , none of these approaches is able to clearly distinguish between word meanings and associate words in context except when dedicated to a very restricted vocabulary .[0006 ] WordNet is an ontology that is often used for word disambiguation .", "label": "", "metadata": {}, "score": "38.660835"}
{"text": "It combines a lexical taxonomy structure with corpus statistical information so that the semantic distance between nodes in the semantic space constructed by the taxonomy can be better quantifie ... \" .This paper presents a new approach for measuring semantic similarity / distance between words and concepts .", "label": "", "metadata": {}, "score": "38.75965"}
{"text": "A cross - lingual task was also defined .The task involves both finding the synonyms and disambiguating the context .It allows the use of . any . kind of lexical resource or technique , including word sense disambiguation and word sense induction .", "label": "", "metadata": {}, "score": "38.79868"}
{"text": "The basic task began with attempts to replicate FrameNet data , specifically frame elements .This task has expanded to inferring and developing new frames and frame elements , in individual sentences and in full running texts , with identification of intersentential links and coreference chains .", "label": "", "metadata": {}, "score": "39.227848"}
{"text": "The basic task began with attempts to replicate FrameNet data , specifically frame elements .This task has expanded to inferring and developing new frames and frame elements , in individual sentences and in full running texts , with identification of intersentential links and coreference chains .", "label": "", "metadata": {}, "score": "39.227848"}
{"text": "The basic task began with attempts to replicate FrameNet data , specifically frame elements .This task has expanded to inferring and developing new frames and frame elements , in individual sentences and in full running texts , with identification of intersentential links and coreference chains .", "label": "", "metadata": {}, "score": "39.227848"}
{"text": "The basic task began with attempts to replicate FrameNet data , specifically frame elements .This task has expanded to inferring and developing new frames and frame elements , in individual sentences and in full running texts , with identification of intersentential links and coreference chains .", "label": "", "metadata": {}, "score": "39.227848"}
{"text": "This latent relationship is a result of indirect links through other words .[ 0046 ] Embodiments of the method for determining a latent distance between a pair of vertice of a graph may be used to resolve distances between senses of words .", "label": "", "metadata": {}, "score": "39.46456"}
{"text": "Additional semantic links of constant weight between selected pairs of words are added to the graph , where such pairs of words have semantic overlap , or optionally with weights automatically calculated using the \" Modified Lesk \" similarity measure or another similarity measure .", "label": "", "metadata": {}, "score": "39.69266"}
{"text": "AAAI 2006 : 1419 - 1424 The WSD task provides texts with target words and requires identification of the appropriate translation .A related task is cross - language information retrieval , where participants disambiguate in one language ( e.g. , with WordNet synsets ) and retrieve documents in another language ; standard information retrieval metrics are use to assess the quality of the disambiguation .", "label": "", "metadata": {}, "score": "39.810112"}
{"text": "The task is to cluster corpus instances ( word uses , rather than word senses ) and to evaluate systems on how well they correspond to pre - existing sense inventories or to various sense mapping systems .Some tasks are closely related to each other .", "label": "", "metadata": {}, "score": "39.8944"}
{"text": "The step of linking said pair of sets determined to have a semantic overlap may be dependent on the calculated weight .For instance only pairs of sets having a weight above a predetermined threshold may be linked .[ 0035 ] Some embodiments relate to a computer implemented method of determining a latent distance between a pair of vertices of a graph , the method comprising : . [ 0036 ] providing a dataset comprising data points , wherein each of said data points is associated with at least one other of said data points , and a degree of association between respective pairs of said data points is represented by a weighted measure ; .", "label": "", "metadata": {}, "score": "40.327072"}
{"text": "We then use lexical cooccurrence statistics in combination with these categories to classify proper names , assign more specific senses to broadly defined terms , and classify new words into existing categories .We also describe how to use these statistics to assign schema - like information to the categories and show how the new categories improve a text - labeling algorithm .", "label": "", "metadata": {}, "score": "40.83949"}
{"text": "The second major area in semantic analysis is the understanding of how different sentence and textual elements fit together .Tasks in this area include semantic role labeling , semantic relation analysis , and coreference resolution .Other tasks in this area look at more specialized issues of semantic analysis , such as temporal information processing , metonymy resolution , and sentiment analysis .", "label": "", "metadata": {}, "score": "41.095787"}
{"text": "The second major area in semantic analysis is the understanding of how different sentence and textual elements fit together .Tasks in this area include semantic role labeling , semantic relation analysis , and coreference resolution .Other tasks in this area look at more specialized issues of semantic analysis , such as temporal information processing , metonymy resolution , and sentiment analysis .", "label": "", "metadata": {}, "score": "41.095787"}
{"text": "This topic also includes textual entailment and paraphrasing tasks .Evaluation of lexical resources : the task evaluates the submitted lexical resources indirectly , running a simple WSD based on topic signatures ( sets of words related to each target sense ) .", "label": "", "metadata": {}, "score": "41.13069"}
{"text": "Tasks have covered disambiguation of nouns , verbs , adjectives , and prepositions .The WSD task provides texts with target words and requires identification of the appropriate translation .A related task is cross - language information retrieval , where participants disambiguate in one language ( e.g. , with WordNet synsets ) and retrieve documents in another language ; standard information retrieval metrics are use to assess the quality of the disambiguation .", "label": "", "metadata": {}, "score": "41.314575"}
{"text": "Tasks have covered disambiguation of nouns , verbs , adjectives , and prepositions .The WSD task provides texts with target words and requires identification of the appropriate translation .A related task is cross - language information retrieval , where participants disambiguate in one language ( e.g. , with WordNet synsets ) and retrieve documents in another language ; standard information retrieval metrics are use to assess the quality of the disambiguation .", "label": "", "metadata": {}, "score": "41.314575"}
{"text": "While meaning is intuitive to humans , transferring those intuitions to computational analysis has proved elusive .This series of evaluations is providing a mechanism to characterize in more precise terms exactly what is necessary to compute in meaning .As such , the evaluations provide an emergent mechanism to identify the problems and solutions for computations with meaning .", "label": "", "metadata": {}, "score": "41.330112"}
{"text": "Compute the similarity between two words .The first method uses an edit - distance string matching algorithm : Levenshtein .The string edit distance is the total cost of transforming one string into another using a set of edit rules , each of which has an associated cost .", "label": "", "metadata": {}, "score": "41.53346"}
{"text": "Compute the similarity between two words .The first method uses an edit - distance string matching algorithm : Levenshtein .The string edit distance is the total cost of transforming one string into another using a set of edit rules , each of which has an associated cost .", "label": "", "metadata": {}, "score": "41.53346"}
{"text": "Compute the similarity between two words .The first method uses an edit - distance string matching algorithm : Levenshtein .The string edit distance is the total cost of transforming one string into another using a set of edit rules , each of which has an associated cost .", "label": "", "metadata": {}, "score": "41.53346"}
{"text": "The task is to identify the events described in a text and locate these in time , i.e. , identification of temporal referring expressions , events and temporal relations within a text .: detection and resolution of coreferences .The task is to detect full coreference chains , composed by named entities , pronouns , and full noun phrases and to resolve pronouns , i.e. , finding their antecedents .", "label": "", "metadata": {}, "score": "41.75422"}
{"text": "The task is to cluster corpus instances ( word uses , rather than word senses ) and to evaluate systems on how well they correspond to pre - existing sense inventories or to various sense mapping systems .The task involves both finding the synonyms and disambiguating the context .", "label": "", "metadata": {}, "score": "41.79178"}
{"text": "The task is to cluster corpus instances ( word uses , rather than word senses ) and to evaluate systems on how well they correspond to pre - existing sense inventories or to various sense mapping systems .The task involves both finding the synonyms and disambiguating the context .", "label": "", "metadata": {}, "score": "41.79178"}
{"text": "Specifically , the proposed measure is a combined approach that inherits the edge - based approach of the edge counting scheme , which is then enhanced by the node - based approach of the information content calculation .When tested on a common data set of word pair similarity ratings , the proposed approach outperforms other computational models .", "label": "", "metadata": {}, "score": "41.822227"}
{"text": "In this dissertation , I suggest that an answer to this question lies in the representation of conceptual . \" ... Introduction An impressive array of statistical methods have been developed for word sense identification .They range from dictionary - based approaches that rely on definitions ( Vronis and Ide 1990 ; Wilks et al .", "label": "", "metadata": {}, "score": "41.941566"}
{"text": "Metonymy resolution : the figurative substitution of an attribute of a name for the thing specified .A second task is to identify when the arguments of a specified predicate does not satisfy selectional restrictions , and if not , to identify both the type mismatch and the type shift ( coercion ) .", "label": "", "metadata": {}, "score": "42.000175"}
{"text": "The string similarity algorithm was developed to satisfy the following requirements : .A true reflection of lexical similarity - strings with small differences should be recognized as being similar .In particular , a significant sub - string overlap should point to a high level of similarity between the strings .", "label": "", "metadata": {}, "score": "42.016552"}
{"text": "The string similarity algorithm was developed to satisfy the following requirements : .A true reflection of lexical similarity - strings with small differences should be recognized as being similar .In particular , a significant sub - string overlap should point to a high level of similarity between the strings .", "label": "", "metadata": {}, "score": "42.016552"}
{"text": "HLT - NAACL 2009 : 19 - 27 .Hirst , Graeme and David St - Onge .Lexical chains as representations of context for the detection and correction of malapropisms .In Christiane Fellbaum , editor , WordNet : An Electronic Lexical Database .", "label": "", "metadata": {}, "score": "42.273235"}
{"text": "[ 0091 ] Next , for each pair of seed words , an edge is added between each of the synsets of the pair that have a semantic overlap .The semantic overlap is derived from the semantically tagged glosses of WordNet .", "label": "", "metadata": {}, "score": "42.772293"}
{"text": "0073 ]FIG .2 shows the output from a computer implemented method of determining a latent distance between a pair of vertices of a graph .[ 0074 ]FIG .3 shows the main steps of a first embodiment of an algorithm for semantic disambiguation of a pair of words .", "label": "", "metadata": {}, "score": "43.247192"}
{"text": "[ 0096 ] As a further optional step , the maximum number of \" associative \" links to a particular synset may be limited to a maximum value .The links that are discared are those with the lowest degree of semantic overlap according to whichever method was used at the time to determine the \" associative \" link weight .", "label": "", "metadata": {}, "score": "43.304413"}
{"text": "They began with apparently simple attempts to identify word senses computationally .They have evolved to investigate the interrelationships among the elements in a sentence ( e.g. , semantic role labeling ) , relations between sentences ( e.g. , coreference ) , and the nature of what we are saying ( semantic relations and sentiment analysis ) .", "label": "", "metadata": {}, "score": "43.573647"}
{"text": "They began with apparently simple attempts to identify word senses computationally .They have evolved to investigate the interrelationships among the elements in a sentence ( e.g. , semantic role labeling ) , relations between sentences ( e.g. , coreference ) , and the nature of what we are saying ( semantic relations and sentiment analysis ) .", "label": "", "metadata": {}, "score": "43.573647"}
{"text": "Associative links are given a constant weight which in general will be different from the weight given to the structural links .As mentioned earlier , this weight is determined heuristally .Optionally , for each pair of seed words , an edge can be added between each of the synsets of the pair , with a weight calculated from the \" Modified Lesk \" similarity measure for the two synsets .", "label": "", "metadata": {}, "score": "43.582138"}
{"text": "This series of evaluations is providing a mechanism to characterize in more precise terms exactly what is necessary to compute in meaning .As such , the evaluations provide an emergent mechanism to identify the problems and solutions for computations with meaning .", "label": "", "metadata": {}, "score": "43.853848"}
{"text": "In each of these potential applications , the contribution of the types of semantic analysis constitutes the most outstanding research issue .Tasks in Semantic Evaluation .The major tasks in semantic evaluation include : .Word sense disambiguation : WSD , lexical sample and all - words , the process of identifying which sense of a word ( i.e. meaning ) is used in a sentence , when the word has multiple meanings ( polysemy ) .", "label": "", "metadata": {}, "score": "44.016563"}
{"text": "In each of these potential applications , the contribution of the types of semantic analysis constitutes the most outstanding research issue .Tasks in Semantic Evaluation .The major tasks in semantic evaluation include : .Word sense disambiguation : WSD , lexical sample and all - words , the process of identifying which sense of a word ( i.e. meaning ) is used in a sentence , when the word has multiple meanings ( polysemy ) .", "label": "", "metadata": {}, "score": "44.016563"}
{"text": "However , the extent of the semantic relations afforded by WordNet is inadequate for some purposes .[0007 ] Many disambiguation schemes using similarity measures based on WordNet data have been tried .Most use some variation of path lengths between words and the information content of the words along the path .", "label": "", "metadata": {}, "score": "44.068356"}
{"text": "Deterministic annealing is used to find lowest distortion sets of clusters : as the an-nealing parameter increases , existing clusters become unstable and subdivide , yielding a hierarchi- cal \" soft \" clustering of the data .Clusters are used as the basis for class models of word coocurrence , and the models evaluated with respect to held - out test data . .", "label": "", "metadata": {}, "score": "44.085896"}
{"text": "Computing semantic similarity between words using the WordNet .The above section allows us to get the similarity score between patterns of strings .However , sometimes we need a semantic measurement .This problem leads us to find a semantic similarity .", "label": "", "metadata": {}, "score": "44.272987"}
{"text": "Computing semantic similarity between words using the WordNet .The above section allows us to get the similarity score between patterns of strings .However , sometimes we need a semantic measurement .This problem leads us to find a semantic similarity .", "label": "", "metadata": {}, "score": "44.272987"}
{"text": "Computing semantic similarity between words using the WordNet .The above section allows us to get the similarity score between patterns of strings .However , sometimes we need a semantic measurement .This problem leads us to find a semantic similarity .", "label": "", "metadata": {}, "score": "44.272987"}
{"text": "0075 ]FIG .4 shows the main steps of a first embodiment of an algorithm for semantic disambiguation of a sentence .[ 0076 ] FIG .5 shows a graphical representation of output from the algorithm shown in FIG .", "label": "", "metadata": {}, "score": "44.67358"}
{"text": "As such , the evaluations provide an emergent mechanism to identify the problems and solutions for computations with meaning .These exercises have evolved to articulate more of the dimensions that are involved in our use of language .They began with apparently simple attempts to identify word senses computationally .", "label": "", "metadata": {}, "score": "45.022034"}
{"text": "This task has expanded to inferring and developing new frames and frame elements , in individual sentences and in full running texts , with identification of intersentential links and coreference chains .The task , given a sample of semantic relation types , is to identify and classify semantic relations between nominals(i.e . , nouns and base noun phrases , excluding named entities ) ; a main purpose of this task is to assess different classification methods .", "label": "", "metadata": {}, "score": "45.17218"}
{"text": "This portal will be used to provide a comprehensive view of the issues involved in semantic evaluations .The SemEval exercises provide a mechanism for examining issues in semantic analysis of texts .The topics of interest fall short of the logical rigor that is found in formal computational semsntics , attempting to identify and characterize the kinds of issues relevant to human understanding of language .", "label": "", "metadata": {}, "score": "45.493313"}
{"text": "On the other hand , if one string is just a random anagram of the characters contained in the other , then it should ( usually ) be recognized as dissimilar .Language independence - the algorithm should work not only in English , but also in many different languages .", "label": "", "metadata": {}, "score": "45.662643"}
{"text": "On the other hand , if one string is just a random anagram of the characters contained in the other , then it should ( usually ) be recognized as dissimilar .Language independence - the algorithm should work not only in English , but also in many different languages .", "label": "", "metadata": {}, "score": "45.662643"}
{"text": "TECHNICAL FIELD .[ 0001 ] Embodiments generally concern a computer implemented method and system for determining word senses by latent semantic distance .Some embodiments concern a computer implemented method and system for semantic disambiguation of a pair of words .", "label": "", "metadata": {}, "score": "45.670288"}
{"text": "Words are represented by the relative frequency distributions of contexts in which they appear , and relative entropy between those distributions is used as the similarity measure for clustering .Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership .", "label": "", "metadata": {}, "score": "45.704983"}
{"text": "[ 0087 ] Two synsets are considered to be semantically overlapping if the gloss of one of the synsets contains the other synsets , or there is at least one third synset in WordNet , other than the two synsets , whose gloss contains both of the two synsets .", "label": "", "metadata": {}, "score": "45.75695"}
{"text": "[ 0019 ]The method may further comprise categorising at least some pairs of said sets according to semantic relationship using a semantic similarity measure .A semantic similarity measure attempts to estimate how close in meaning a pair of words ( or groups of words ) are in meaning .", "label": "", "metadata": {}, "score": "46.15435"}
{"text": "The detected similarities , or patterns , can then guide decision making , and be used to extrapolate , or project into the future , the effect of those decisions .For example , organisations typically collect large amounts of data on their customers .", "label": "", "metadata": {}, "score": "46.229095"}
{"text": "Using information content to evaluate semantic similarity .In Proceedings of the 14th International Joint Conference on Artificial Intelligence , pages 448 - 453 , Montreal , Canada , 1995 .Jarmasz , M. 2003 .Roget 's thesaurus as a Lexical Resource for Natural Language Processing .", "label": "", "metadata": {}, "score": "46.4197"}
{"text": "A cross - lingual task was also defined .or simplification . ' '' : find an alternative substitute word or phrase for a target word in context .The task involves both finding the synonyms and disambiguating the context .It allows the use of . any . kind of lexical resource or technique , including word sense disambiguation and word sense induction .", "label": "", "metadata": {}, "score": "46.4516"}
{"text": "Tasks have covered disambiguation of nouns , verbs , adjectives , and prepositions .The former comprises disambiguating the occurrences of a small sample of target words which were previously selected , while in the latter all the words in a piece of running text need to be disambiguated .", "label": "", "metadata": {}, "score": "46.47844"}
{"text": "Tasks have covered disambiguation of nouns , verbs , adjectives , and prepositions .The former comprises disambiguating the occurrences of a small sample of target words which were previously selected , while in the latter all the words in a piece of running text need to be disambiguated .", "label": "", "metadata": {}, "score": "46.47844"}
{"text": "Second order co - occurrence pmi for determining the semantic similarity of words .Proceedings of the International Conference on Language Resources and Evaluation ( LREC 2006 ) 1033 - 1038 .M. T. Pilehvar , D. Jurgens and R. Navigli .", "label": "", "metadata": {}, "score": "46.80642"}
{"text": "0017 ] outputting a meaning of said plurality of words based on said closest pair of said sets and at least one of said semantic relationships between said closest pair of said sets .[ 0018 ] The dataset of words may be sourced from a lexical database .", "label": "", "metadata": {}, "score": "46.861023"}
{"text": "Language independence - the algorithm should work not only in English , but also in many different languages .Solution .The similarity is calculated in three steps : .Partition each string into a list of tokens .Computing the similarity between tokens by using a string edit - distance algorithm ( extension feature : semantic similarity measurement using the WordNet library ) .", "label": "", "metadata": {}, "score": "46.87751"}
{"text": "[0065 ] Some embodiments relate to a system to enable disambiguation of word senses , the system comprising : . [ 0066 ] at least one processor ; and .[ 0069 ] wherein the vector space is usable to determine a latent distance between a pair of vertices in the graph by determining a distance between the pair of vertices in the vector space and the latent distance is usable for disambiguation of word senses .", "label": "", "metadata": {}, "score": "46.955254"}
{"text": "Statistical NLP methods determine the likelihood of a word combination from its frequency in a training corpus .However , the nature of language is such that many word combinations are infrequent and do not occur in any given corpus .In this work we propose a method for estimating the probability of such previously unseen word combinations using available information on \" most similar \" words .", "label": "", "metadata": {}, "score": "47.071503"}
{"text": "The similarity is calculated in three steps : .Partition each string into a list of tokens .Computing the similarity between tokens by using a string edit - distance algorithm ( extension feature : semantic similarity measurement using the WordNet library ) .", "label": "", "metadata": {}, "score": "47.104782"}
{"text": "The similarity is calculated in three steps : .Partition each string into a list of tokens .Computing the similarity between tokens by using a string edit - distance algorithm ( extension feature : semantic similarity measurement using the WordNet library ) .", "label": "", "metadata": {}, "score": "47.104782"}
{"text": "As one example , the seed pairs may be generated by taking all pairs of nouns in WordNet and selecting those that have any annotated gloss overlap .As another , the seed pairs may simply be a list of the most common noun colocations .", "label": "", "metadata": {}, "score": "47.327087"}
{"text": "In our experiments , we found that the automatic scoring of rules based on our novelty measure correlates with human judgments about as well as human judgments correlate with each other .In Proceedings of NAACL 2001 Workshop on WordNet and Other Lexical Resources : Applications , Extensions and Customizations , pp .", "label": "", "metadata": {}, "score": "47.38307"}
{"text": "We also conclude that events that occur only once in the training set have major impact on similarity - based estimates . by Marti A. Hearst , Hinrich Sch\u00fctze - Proc . of the Workshop on Extracting Lexical Knowledge , 1996 . \" ...", "label": "", "metadata": {}, "score": "47.87236"}
{"text": "Combining local context and WordNet similarity for word sense identification .In Christiane Fellbaum , editor , WordNet : An Electronic Lexical Database .The MIT Press , Cambridge , MA , pages 265 - 283 , 1998 .Combining local context and WordNet similarity for word sense identification .", "label": "", "metadata": {}, "score": "47.88757"}
{"text": "Given a multidimensional space upon which a node represents a 2unique concept consisting of a certain amount of information , and an edge represents a direct association between two concepts , ... .by Fernando Pereira , Naftali Tishby , Lillian Lee - In Proceedings of the 31st", "label": "", "metadata": {}, "score": "47.949364"}
{"text": "Word - sense induction : comparison of sense - induction and discrimination systems .The task is to cluster corpus instances ( word uses , rather than word senses ) and to evaluate systems on how well they correspond to pre - existing sense inventories or to various sense mapping systems .", "label": "", "metadata": {}, "score": "48.208065"}
{"text": "Word - sense induction : comparison of sense - induction and discrimination systems .The task is to cluster corpus instances ( word uses , rather than word senses ) and to evaluate systems on how well they correspond to pre - existing sense inventories or to various sense mapping systems .", "label": "", "metadata": {}, "score": "48.208065"}
{"text": "Word - sense induction : comparison of sense - induction and discrimination systems .The task is to cluster corpus instances ( word uses , rather than word senses ) and to evaluate systems on how well they correspond to pre - existing sense inventories or to various sense mapping systems .", "label": "", "metadata": {}, "score": "48.208065"}
{"text": "A degree of association between respective pairs of words is represented by a weighted value .The association is categorised as a \" is - a \" relationship , a \" is - part - of \" relationship or a \" is - semantically - similar - to \" relationship .", "label": "", "metadata": {}, "score": "48.3642"}
{"text": "Leacock , Claudia and Martin Chodorow .Combining local context and WordNet similarity for word sense identification .In Christiane Fellbaum , editor , WordNet : An Electronic Lexical Database .The MIT Press , Cambridge , MA , pages 265 - 283 , 1998 .", "label": "", "metadata": {}, "score": "48.37059"}
{"text": "The primary goal is to replicate human processing by means of computer systems .The tasks ( shown below ) are developed by individuals and groups to deal with identifiable issues , as they take on some concrete form .The first major area in semantic analysis is the identification of the intended meaning at the word level ( taken to include idiomatic expressions ) .", "label": "", "metadata": {}, "score": "48.373146"}
{"text": "[0058 ] accessing an electronic lexical database ; .[ 0059 ] sourcing data points representing seed words and seed pairs ; .[ 0061 ] generating a vector space based on the graph , wherein a distance between a pair of vertices in the vector space corresponds to a latent distance between the pair of vertices in the graph , and wherein the distance is usable for disambiguation of word senses .", "label": "", "metadata": {}, "score": "48.390266"}
{"text": "5 .The subsequent disambiguated output produces : There was a pipe_n -- 02 escape_n -- 07 in the apartment_n -- 01 .[0120 ]In order to build the graph , their Euclidean distances in the n - dimensional vector space were used to derive the graph edge weights between respective pairs of vertices .", "label": "", "metadata": {}, "score": "48.540207"}
{"text": "Landauer , T. K. ; L , T. K. ; Laham , D. ; Rehder , B. ; and Schreiner , M. E. 1997 .How well can passage meaning be derived without using word order ? a comparison of latent semantic analysis and humans .", "label": "", "metadata": {}, "score": "48.569607"}
{"text": "The semantic relationship between any pair of said data points may be categorised according to one or more categories of semantic relationship including a \" is - a \" relationship , a \" is - part - of \" relationship or a \" is - semantically - similar - to \" relationship .", "label": "", "metadata": {}, "score": "48.801395"}
{"text": "This system attempts to make use of aggregated customer data ( products browsed , products bought , products rated , etc . ) to showcase products to customers that are more likely to capture their interests , thus increasing the chance of making a sale .", "label": "", "metadata": {}, "score": "48.92588"}
{"text": "Introduction An impressive array of statistical methods have been developed for word sense identification .They range from dictionary - based approaches that rely on definitions ( Vronis and Ide 1990 ; Wilks et al .1993 ) to corpus - based approaches that use only word cooccurrence frequencies extracted from large textual corpora ( Schfitze 1995 ; Dagan and Itai 1994 ) .", "label": "", "metadata": {}, "score": "48.99344"}
{"text": "A lexical sample tagged with English WordNet senses was used for evaluation .Subcategorization acquistion : semantically similar verbs are similar in terms of subcategorization frames .The task is to use any available method for disambiguating verb senses , so that the results can then be fed into automatic methods used for acquiring subcategorization frames , with the hypothesis that the disambiguation will cluster the instances .", "label": "", "metadata": {}, "score": "49.13031"}
{"text": "A lexical sample tagged with English WordNet senses was used for evaluation .Subcategorization acquistion : semantically similar verbs are similar in terms of subcategorization frames .The task is to use any available method for disambiguating verb senses , so that the results can then be fed into automatic methods used for acquiring subcategorization frames , with the hypothesis that the disambiguation will cluster the instances .", "label": "", "metadata": {}, "score": "49.13031"}
{"text": "For instance , word sense disambiguation ( monolingual , multi - lingual and cross - lingual ) , word sense induction task , lexical substitution .SemEval ( Semantic Evaluation ) is an ongoing series of evaluations of computational semantic analysis systems ; it evolved from the Senseval Word sense evaluation series .", "label": "", "metadata": {}, "score": "49.359467"}
{"text": "[ 0028 ] A seed word may be represented in the form term.d or set.d where a term is a word and a set is in the WordNet format of term.pos.meaning_number , where pos is \" part of speech \" .[ 0029 ] Progressively locating said set as a vertex to the graph may further comprise the steps of : .", "label": "", "metadata": {}, "score": "49.38566"}
{"text": "Searching the connection between two words in WordNet is an expensive operation due to the large searching space .We define two restrictions in order to reduce the computational time .The first one is that only synonym relations are considered ( hyponym and hypernym will be considered later ) , since exhausting all the relations is too costly .", "label": "", "metadata": {}, "score": "49.66401"}
{"text": "Searching the connection between two words in WordNet is an expensive operation due to the large searching space .We define two restrictions in order to reduce the computational time .The first one is that only synonym relations are considered ( hyponym and hypernym will be considered later ) , since exhausting all the relations is too costly .", "label": "", "metadata": {}, "score": "49.66401"}
{"text": "Searching the connection between two words in WordNet is an expensive operation due to the large searching space .We define two restrictions in order to reduce the computational time .The first one is that only synonym relations are considered ( hyponym and hypernym will be considered later ) , since exhausting all the relations is too costly .", "label": "", "metadata": {}, "score": "49.66401"}
{"text": "A new task is evaluating phrasal semantics ( compositionality and semantic similarity of phrases ) .Multi - lingual or cross - lingual word - sense disambiguation : word senses are defined according to translation distinctions , e.g. , a polysemous word in Japanese is translated differently in a given context .", "label": "", "metadata": {}, "score": "50.095722"}
{"text": "The smaller number of distance [ n , m ] the more similar two strings are .There are several ways to compute the similarity value , may use some co - efficient .The idea of dynamic programming is quite simple .", "label": "", "metadata": {}, "score": "50.143173"}
{"text": "0010 ] Some embodiments relate to a computer implemented method of semantic disambiguation of a plurality of words , the method comprising : .[ 0011 ] providing a dataset of words associated by meaning into sets of synonyms ; . [ 0012 ] locating said sets at respective vertices of a graph , at least some pairs of said sets being spaced according to semantic similarity and categorised according to semantic relationship ; . [ 0013 ] transforming the graph into a Euclidean vector space comprising vectors indicative of respective locations of said sets in said vector space ; .", "label": "", "metadata": {}, "score": "50.31142"}
{"text": "Said degree of association between respective pairs of said data points may be dependent on the type of dataset utilised .The data points of said dataset may represent any of the following : ( a ) scientific data ; ( b ) financial data ; ( c ) lexical data ; ( d ) market research data and ( e ) bioinformatics data .", "label": "", "metadata": {}, "score": "50.370914"}
{"text": "Word sense disambiguation : WSD , lexical sample and all - words , the process of identifying which sense of a word ( i.e. meaning ) is used in a sentence , when the word has multiple meanings ( polysemy ) .", "label": "", "metadata": {}, "score": "50.56478"}
{"text": "The task is to use any available method for disambiguating verb senses , so that the results can then be fed into automatic methods used for acquiring subcategorization frames , with the hypothesis that the disambiguation will cluster the instances .The task is to use any available method for disambiguating verb senses , so that the results can then be fed into automatic methods used for acquiring subcategorization frames , with the hypothesis that the disambiguation will cluster the instances .", "label": "", "metadata": {}, "score": "50.74978"}
{"text": "The tasks ( shown below ) are developed by individuals and groups to deal with identifiable issues , as they take on some concrete form .The first major area in semantic analysis is the identification of the intended meaning at the word level ( taken to include idiomatic expressions ) .", "label": "", "metadata": {}, "score": "50.813114"}
{"text": "The tasks ( shown below ) are developed by individuals and groups to deal with identifiable issues , as they take on some concrete form .The first major area in semantic analysis is the identification of the intended meaning at the word level ( taken to include idiomatic expressions ) .", "label": "", "metadata": {}, "score": "50.813114"}
{"text": "[ 0049 ] locating said data points at respective vertices of a graph with said respective pairs of said data points spaced according to said weighted measures .[ 0050 ]The computer implemented method may further comprise determining those seed words that comprise a synset and for said seed words , adding respective synsets as data points to the graph .", "label": "", "metadata": {}, "score": "50.843056"}
{"text": "The MIT Press , Cambridge , MA , pages 265 - 283 , 1998 .Automatic retrieval and clustering of similar words .In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics ( COLING - ACL ' 98 ) , Montreal , Canada , pages 768 - 774 , 1998 .", "label": "", "metadata": {}, "score": "50.894928"}
{"text": "[ 0084 ] Within this specification the terms ' vertex ' and ' edge ' are standard terms employed in the fields of Graph Theory and Spectral Graph Theory .The term ' graph ' refers to a weighted , undirected graph .", "label": "", "metadata": {}, "score": "51.022266"}
{"text": "The automatic disambiguation of word senses has been an interest and concern since the earliest days of computer treatment of language in the 1950 's .Sense disambiguation is an \" intermediate task \" ( Wilks and Stevenson , 1996 ) which is not an end in itself , but rather is necessary at one level o ... \" .", "label": "", "metadata": {}, "score": "51.18291"}
{"text": "A true reflection of lexical similarity - strings with small differences should be recognized as being similar .In particular , a significant sub - string overlap should point to a high level of similarity between the strings .A robustness to changes of word order- two strings which contain the same words , but in a different order , should be recognized as being similar .", "label": "", "metadata": {}, "score": "51.247265"}
{"text": "In the context of the specification glosses mean either the semantically tagged definition gloss for a synset and/or usage example semantically annotated glosses .The graph is formed by vector space generator 630 as follows .[ 0088 ] Firstly , a list of pairs of seed words and/or a list of single seed words is supplied as input to the algorithm .", "label": "", "metadata": {}, "score": "51.349438"}
{"text": "I implemented this algorithm when I was developing a tool to make the matching between XML schemas semi - automatic .Preparing the ground .The Kuhn - Munkres algorithm ( also known as the Hungarian method)[2 ] .Without going \" deep into theory \" , if you want to understand these algorithms , please read about them in the algorithm books .", "label": "", "metadata": {}, "score": "51.43695"}
{"text": "I implemented this algorithm when I was developing a tool to make the matching between XML schemas semi - automatic .Preparing the ground .The Kuhn - Munkres algorithm ( also known as the Hungarian method)[2 ] .Without going \" deep into theory \" , if you want to understand these algorithms , please read about them in the algorithm books .", "label": "", "metadata": {}, "score": "51.43695"}
{"text": "[ 0015 ] identifying a second group of said sets comprising those of said sets that include a second of said pair of words ; .[ 0016 ] determining a closest pair in said vector space of said sets taken from said first and second groups of sets respectively ; and .", "label": "", "metadata": {}, "score": "51.457"}
{"text": "In Proceedings of the 15th International Conference on Machine Learning , Madison , WI , pages 296 - 304 , 1998 .Lin , Dekang .Automatic retrieval and clustering of similar words .In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics ( COLING - ACL ' 98 ) , Montreal , Canada , pages 768 - 774 , 1998 .", "label": "", "metadata": {}, "score": "51.54989"}
{"text": "[0052 ] The computer implemented method may further comprise determining those seed words that comprise a term , and for said seed words , deriving synsets for respective terms and adding said derived synsets as data points .[0053 ] The computer implemented method may further comprise for a pair of associated data points , calculating the weighted value using a Modified Lesk similarity measure , annotated gloss overlap , or an other semantic similarity measure .", "label": "", "metadata": {}, "score": "51.89262"}
{"text": "Temporal information processing : the temporal location and order of events in newspaper articles , narratives , and similar texts .The task is to identify the events described in a text and locate these in time , i.e. , identification of temporal referring expressions , events and temporal relations within a text .", "label": "", "metadata": {}, "score": "51.977745"}
{"text": "0062 ]The method may further comprise receiving disambiguation input comprising a word pair or a sentence as input and using the vector space to generate disambiguation output regarding the word pair or the sentence .[ 0063 ] Some embodiments also relate to use of the vector space generated by the described methods to generate disambiguation output in response to received disambiguation input .", "label": "", "metadata": {}, "score": "52.05474"}
{"text": "Due to the synonym consideration , first we use the following formula to calculate the semantic similarity of words score : .Where s and t : denote the source and target words being compared .SenseWeight : denotes a weight calculated according to the order of this sense and the count of total senses .", "label": "", "metadata": {}, "score": "52.081467"}
{"text": "Due to the synonym consideration , first we use the following formula to calculate the semantic similarity of words score : .Where s and t : denote the source and target words being compared .SenseWeight : denotes a weight calculated according to the order of this sense and the count of total senses .", "label": "", "metadata": {}, "score": "52.081467"}
{"text": "Due to the synonym consideration , first we use the following formula to calculate the semantic similarity of words score : .Where s and t : denote the source and target words being compared .SenseWeight : denotes a weight calculated according to the order of this sense and the count of total senses .", "label": "", "metadata": {}, "score": "52.081467"}
{"text": "[[ .Semantic relation identification . ]] : examining relations between lexical items in a sentence .The task , given a sample of semantic relation types , is to identify and classify semantic relations between nominals ( i.e. , nouns and base noun phrases , excluding named entities ) ; a main purpose of this task is to assess different classification methods .", "label": "", "metadata": {}, "score": "52.142868"}
{"text": "Sense disambiguation is an \" intermediate task \" ( Wilks and Stevenson , 1996 ) which is not an end in itself , but rather is necessary at one level or another to accomplish most natural language processing tasks .It is . by Lillian Lee , Fernando C. N. Pereira , Claire Cardie , Raymond Mooney - Machine Learning , 1999 . \" ... Abstract .", "label": "", "metadata": {}, "score": "52.577126"}
{"text": "Solid lines indicate the measured distances of links originally defined in the graph .Dotted lines indicate the measured distances in the six - dimensional vector space .[ 0102 ] FIG .3 shows the main steps of a method 300 for semantic disambiguation ( by disambiguation engine 640 using the previously generated vector space 650 ) of a pair of words .", "label": "", "metadata": {}, "score": "52.702324"}
{"text": "For example , a class - based approach has been proposed for use with the WordNet lexical database that was created at Princeton University .The one or more categories of semantic relationship may comprise a \" is - a \" relationship , a \" is - part - of \" relationship or a \" is - semantically - similar - to \" relationship .", "label": "", "metadata": {}, "score": "52.762188"}
{"text": "Multi - lingual or cross - lingual word - sense disambiguation : word senses are defined according to translation distinctions , e.g. , a polysemous word in Japanese is translated differently in a given context .The WSD task provides texts with target words and requires identification of the appropriate translation .", "label": "", "metadata": {}, "score": "53.004833"}
{"text": "Multi - lingual or cross - lingual word - sense disambiguation : word senses are defined according to translation distinctions , e.g. , a polysemous word in Japanese is translated differently in a given context .The WSD task provides texts with target words and requires identification of the appropriate translation .", "label": "", "metadata": {}, "score": "53.004833"}
{"text": "This code shows a dynamic implementation of the algorithm : . private int ComputeDistance ( string s , string t ) .s .Substring(i - 1 , 1 ) ?distance[i , j - 1 ] + 1 , .The similarity score .", "label": "", "metadata": {}, "score": "53.123314"}
{"text": "This code shows a dynamic implementation of the algorithm : . private int ComputeDistance ( string s , string t ) .s .Substring(i - 1 , 1 ) ?distance[i , j - 1 ] + 1 , .The similarity score .", "label": "", "metadata": {}, "score": "53.123314"}
{"text": "This code shows a dynamic implementation of the algorithm : . private int ComputeDistance ( string s , string t ) .s .Substring(i - 1 , 1 ) ?distance[i , j - 1 ] + 1 , .The similarity score .", "label": "", "metadata": {}, "score": "53.123314"}
{"text": "0070 ] The system may further comprise a disambiguation engine that has access to the vector space , the disambiguation engine being configured to use the vector space to provide disambiguation output in response to input of at least one of a word pair and a sentence .", "label": "", "metadata": {}, "score": "53.20594"}
{"text": "The similarity - based methods perform up to 40 % better on this particular task .We al ... \" .We compare four similarity - based estimation methods against back - off and maximum - likelihood estimation methods on a pseudo - word sense disambiguation task in which we controlled for both unigram and bigram frequency .", "label": "", "metadata": {}, "score": "53.52452"}
{"text": "This is to reduce the density of links in the graph .This maximum is determined heuristically .[ 0056 ] The computer implemented method may further comprise compacting said graph by recursively removing hypernyms that have only one hyponym and linking said hyponym to a hypernym of the removed hypernym .", "label": "", "metadata": {}, "score": "53.581955"}
{"text": "Then for each i in i max the vertex V i is identified from the graph in step 350 .In step 355 , the point E i in the Euclidean vector space corresponding to V i is retrieved .In the case that i and j are both the most frequent synset for their respective terms , their distance may optionally be shortened by a small amount that is determined heuristically .", "label": "", "metadata": {}, "score": "53.610283"}
{"text": "Similarity between two token lists .After splitting each string into token lists , we capture the similarity between two strings by computing the similarity of those two token lists , which is reduced to the bipartite graph matching problem .The problem can now be described as follows .", "label": "", "metadata": {}, "score": "53.881462"}
{"text": "Similarity between two token lists .After splitting each string into token lists , we capture the similarity between two strings by computing the similarity of those two token lists , which is reduced to the bipartite graph matching problem .The problem can now be described as follows .", "label": "", "metadata": {}, "score": "53.881462"}
{"text": "Similarity between two token lists .After splitting each string into token lists , we capture the similarity between two strings by computing the similarity of those two token lists , which is reduced to the bipartite graph matching problem .The problem can now be described as follows .", "label": "", "metadata": {}, "score": "53.881462"}
{"text": "SemEval on Wikipedia .On Wikipedia , a SemEval page had been created and it is calling for contributions and suggestions on how to improve the Wikipedia page and to further the understanding of computational semantics .The former comprises disambiguating the occurrences of a small sample of target words which were previously selected , while in the latter all the words in a piece of running text need to be disambiguated .", "label": "", "metadata": {}, "score": "54.181732"}
{"text": "It should be appreciated by those skilled in the art that a subgraph of a graph G , is a graph whose vertex set is a subset of that of G , and whose adjacency relation is a subset of that of G restricted to this subset .", "label": "", "metadata": {}, "score": "54.368187"}
{"text": "For example the words night , nighttime and dark constitute a single synset that has the following gloss : the time after sunset and before sunrise while it is dark outside .Synsets are connected to one another through explicit semantic relations .", "label": "", "metadata": {}, "score": "54.684433"}
{"text": "For example the words night , nighttime and dark constitute a single synset that has the following gloss : the time after sunset and before sunrise while it is dark outside .Synsets are connected to one another through explicit semantic relations .", "label": "", "metadata": {}, "score": "54.684433"}
{"text": "For example the words night , nighttime and dark constitute a single synset that has the following gloss : the time after sunset and before sunrise while it is dark outside .Synsets are connected to one another through explicit semantic relations .", "label": "", "metadata": {}, "score": "54.684433"}
{"text": "[0002 ] Progress in digital data acquisition and storage technology has resulted in the growth of huge repositories of data .Data mining , or knowledge discovery , refers to a multi - staged process of extracting unforseen knowledge from such repositories and applying the results to decision making .", "label": "", "metadata": {}, "score": "54.810486"}
{"text": "The task , given a sample of semantic relation types , is to identify and classify semantic relations between nominals(i.e . , nouns and base noun phrases , excluding named entities ) ; a main purpose of this task is to assess different classification methods .", "label": "", "metadata": {}, "score": "54.812386"}
{"text": "Base on WordNet and its .NET API ( that is provided by Troy Simpson ) ; I use synonym and hypernym relations to capture the semantic similarities of tokens .Given a pair of words , once a path that connects the two words is found , I determine their similarity based on two factors : the length of the path and the order of the sense involved in this path .", "label": "", "metadata": {}, "score": "54.82863"}
{"text": "Base on WordNet and its .NET API ( that is provided by Troy Simpson ) ; I use synonym and hypernym relations to capture the semantic similarities of tokens .Given a pair of words , once a path that connects the two words is found , I determine their similarity based on two factors : the length of the path and the order of the sense involved in this path .", "label": "", "metadata": {}, "score": "54.82863"}
{"text": "Base on WordNet and its .NET API ( that is provided by Troy Simpson ) ; I use synonym and hypernym relations to capture the semantic similarities of tokens .Given a pair of words , once a path that connects the two words is found , I determine their similarity based on two factors : the length of the path and the order of the sense involved in this path .", "label": "", "metadata": {}, "score": "54.82863"}
{"text": "See , for example , \" Extended Gloss Overlaps as a Measure of Semantic Relatedness \" ( 2003 ) Satanjeev Banerjee , Ted Pedersen , Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence .[0121 ] The described embodiments are capable of disambiguating pairs of words and sentences with a high degree of accuracy relative to existing algorithms such as those based on WordNet , statistical based algorithms and manual methods .", "label": "", "metadata": {}, "score": "54.948303"}
{"text": "Semantic relation identification : examining relations between lexical items in a sentence .The task , given a sample of semantic relation types , is to identify and classify semantic relations between nominals ( i.e. , nouns and base noun phrases , excluding named entities ) ; a main purpose of this task is to assess different classification methods .", "label": "", "metadata": {}, "score": "55.083572"}
{"text": "Y is the set of the second list of tokens .The task is to find a subset of node - disjoint edges that has the maximum total weight .The similarity of two strings is computed by the number of matched strings .", "label": "", "metadata": {}, "score": "55.106476"}
{"text": "Y is the set of the second list of tokens .The task is to find a subset of node - disjoint edges that has the maximum total weight .The similarity of two strings is computed by the number of matched strings .", "label": "", "metadata": {}, "score": "55.106476"}
{"text": "Y is the set of the second list of tokens .The task is to find a subset of node - disjoint edges that has the maximum total weight .The similarity of two strings is computed by the number of matched strings .", "label": "", "metadata": {}, "score": "55.106476"}
{"text": "Despite the persistence of this theory , however , there is widespread agreement about its empirical shortcomings ( McCawley , 1968 ; Fodor , 1977 ) .As an alternative , some critics of the Katz - Fodor theory ( e.g. ( Johnson - Laird , 1983 ) ) have abandoned the treatment of selectional constraints as semantic , instead treating them as indistinguishable from inferences made on the basis of factual knowledge .", "label": "", "metadata": {}, "score": "55.28282"}
{"text": "Lexical substitution or simplification : find an alternative substitute word or phrase for a target word in context .The task involves both finding the synonyms and disambiguating the context .It allows the use of any kind of lexical resource or technique , including word sense disambiguation and word sense induction .", "label": "", "metadata": {}, "score": "55.326496"}
{"text": "Subcategorization acquistion : semantically similar verbs are similar in terms of subcategorization frames .The task is to use any available method for disambiguating verb senses , so that the results can then be fed into automatic methods used for acquiring subcategorization frames , with the hypothesis that the disambiguation will cluster the instances .", "label": "", "metadata": {}, "score": "55.381756"}
{"text": "Another restriction is to limit the length of the searching path .If the searcher can not find a path that has been connected within a limited length , we stop searching and give the result as no path found .Hence , this case should have a substitution , the edit - distance instead .", "label": "", "metadata": {}, "score": "55.460827"}
{"text": "Another restriction is to limit the length of the searching path .If the searcher can not find a path that has been connected within a limited length , we stop searching and give the result as no path found .Hence , this case should have a substitution , the edit - distance instead .", "label": "", "metadata": {}, "score": "55.460827"}
{"text": "Another restriction is to limit the length of the searching path .If the searcher can not find a path that has been connected within a limited length , we stop searching and give the result as no path found .Hence , this case should have a substitution , the edit - distance instead .", "label": "", "metadata": {}, "score": "55.460827"}
{"text": "The method of claim 35 , wherein the dataset of words may be sourced from a lexical database .The method of claim 35 , further comprising categorising at least some pairs of said sets according to one or more semantic relationships using a semantic similarity measure .", "label": "", "metadata": {}, "score": "55.570396"}
{"text": "That is , .v i ) .( v j .v i ) ) .where \" .\" is the vector dot product .This results in a n\u00d7n matrix , L , where the distance , d ij , between two vertices i and j in the semantic space is given by : .", "label": "", "metadata": {}, "score": "55.791332"}
{"text": "However the success rate of Modified Lesk is limited by the terseness of the glosses .[0009] It is desired to address or ameliorate one or more shortcomings or disadvantages of prior techniques , or to at least provide a useful alternative thereto .", "label": "", "metadata": {}, "score": "56.045135"}
{"text": "0092 ] After the edges have been added , as an optional step , all the synsets that are \" part - of \" the current vertices in the graph can be added .In order to avoid saturating the number of links , these \" part - of \" links may only be added to synsets that have less than a maximum number of links .", "label": "", "metadata": {}, "score": "56.441475"}
{"text": "The system of claim 66 , further comprising a disambiguation engine that has access to the vector space , the disambiguation engine being configured to provide disambiguation output in response to input of at least one of a word pair and a sentence .", "label": "", "metadata": {}, "score": "56.447853"}
{"text": "The first three evaluations , Senseval-1 through Senseval-3 , were focused on word sense disambiguation , each time growing in the number of languages offered in the tasks and in the number of participating teams .Beginning with the 4th workshop , SemEval-2007 ( SemEval-1 ) , the nature of the tasks evolved to include semantic analysis tasks outside of word sense disambiguation .", "label": "", "metadata": {}, "score": "56.552235"}
{"text": "The first three evaluations , Senseval-1 through Senseval-3 , were focused on word sense disambiguation , each time growing in the number of languages offered in the tasks and in the number of participating teams .Beginning with the 4th workshop , SemEval-2007 ( SemEval-1 ) , the nature of the tasks evolved to include semantic analysis tasks outside of word sense disambiguation .", "label": "", "metadata": {}, "score": "56.552235"}
{"text": "Transformations are the one - step operations of ( single - phone ) insertion , deletion and substitution .In the simplest version substitutions cost about two units except when the source and target are identical , in which case the cost is zero .", "label": "", "metadata": {}, "score": "56.569008"}
{"text": "Transformations are the one - step operations of ( single - phone ) insertion , deletion and substitution .In the simplest version substitutions cost about two units except when the source and target are identical , in which case the cost is zero .", "label": "", "metadata": {}, "score": "56.569008"}
{"text": "Transformations are the one - step operations of ( single - phone ) insertion , deletion and substitution .In the simplest version substitutions cost about two units except when the source and target are identical , in which case the cost is zero .", "label": "", "metadata": {}, "score": "56.569008"}
{"text": "[ 0024 ] for each pair of seed words : .[ 0025 ] determining if the sets of said pair have a semantic overlap ; .[ 0026 ] linking a pair of sets determined to have a semantic overlap ; and .", "label": "", "metadata": {}, "score": "56.621643"}
{"text": "[ 0100 ] Other metrics for the distance such as : . sup .+ ij / ( L.sup .+ j j ) .may also be used .[ 0101 ] An example of a small six dimensional vector space with distances is shown diagrammatically in FIG .", "label": "", "metadata": {}, "score": "56.747982"}
{"text": "- Paula .I glad that you enjoyed it .As you can read in the article , here are three major steps : - Split up a sentence into word / token .( assuming that in most natural language , a sentence is a sequence of words and delimiters . ) - Compute the similarity of two words .", "label": "", "metadata": {}, "score": "56.842354"}
{"text": "A second task is to identify when the arguments of a specified predicate does not satisfy selectional restrictions , and if not , to identify both the type mismatch and the type shift ( coercion ) .A second task is to identify when the arguments of a specified predicate does not satisfy selectional restrictions , and if not , to identify both the type mismatch and the type shift ( coercion ) .", "label": "", "metadata": {}, "score": "56.891163"}
{"text": "The two traditions complement each other .Corpus - based approaches have the advantage of being generally applicable to new texts , domains , and corpora without needing costly and perhaps error - prone parsing or semantic analysis .They require only training corpora in which the sense distinctions have been marked , but therein lies their weakness .", "label": "", "metadata": {}, "score": "57.054165"}
{"text": "n tendencies into associations of words to certain hidden senses classes and associations between the classes themselves .More specifically , we model senses as probabilistic concepts or clusters c with corresponding clus ... . \" ...Selectional constraints are limitations on the applicability of predicates to arguments .", "label": "", "metadata": {}, "score": "57.21094"}
{"text": "The Krylov - Schur Algorithm is described in chapter 3 of the book titled \" Numerical Methods for General And Structured Eigenvalue Problems \" , Springer Berlin Heidelberg , 2005 , the contents of which are herein incorporated by reference .The result is a Euclidean vector semantic space of dimension n\u00d7n where n is the number of vertices and n is the number of derived eigenvectors .", "label": "", "metadata": {}, "score": "57.338455"}
{"text": "SIGLEX , the ACL Special Interest Group on the Lexicon is the umbrella organization for the SemEval semantic evaluations and the SENSEVAL word - sense evaluation exercises .SENSEVAL is the home page for SENSEVAL 1 - 3 .Each exercise is usually organized by two individuals , who make the call for tasks and handle the overall administration .", "label": "", "metadata": {}, "score": "57.63125"}
{"text": "SIGLEX , the ACL Special Interest Group on the Lexicon is the umbrella organization for the SemEval semantic evaluations and the SENSEVAL word - sense evaluation exercises .SENSEVAL is the home page for SENSEVAL 1 - 3 .Each exercise is usually organized by two individuals , who make the call for tasks and handle the overall administration .", "label": "", "metadata": {}, "score": "57.63125"}
{"text": "SIGLEX , the ACL Special Interest Group on the Lexicon is the umbrella organization for the SemEval semantic evaluations and the SENSEVAL word - sense evaluation exercises .SENSEVAL is the home page for SENSEVAL 1 - 3 .Each exercise is usually organized by two individuals , who make the call for tasks and handle the overall administration .", "label": "", "metadata": {}, "score": "57.63125"}
{"text": "Bibtex : .Sign up to receive free email alerts when patent applications with chosen keywords are published SIGN UP .Abstract : .The invention relates to methods and systems for semantic disambiguation of a plurality of words .Claims : .", "label": "", "metadata": {}, "score": "57.751106"}
{"text": "[ 0071 ] Further features of the embodiments are set forth in the following description , given by way of example only and with reference to the accompanying drawings .[ 0072 ] FIG .1 shows a computer system configured to perform described disambiguation methods .", "label": "", "metadata": {}, "score": "58.04802"}
{"text": "A lexical sample tagged with English WordNet senses was used for evaluation .A lexical sample tagged with English WordNet senses was used for evaluation .The task is to use any available method for disambiguating verb senses , so that the results can then be fed into automatic methods used for acquiring subcategorization frames , with the hypothesis that the disambiguation will cluster the instances .", "label": "", "metadata": {}, "score": "58.07945"}
{"text": "A lexical sample tagged with English WordNet senses was used for evaluation .A lexical sample tagged with English WordNet senses was used for evaluation .The task is to use any available method for disambiguating verb senses , so that the results can then be fed into automatic methods used for acquiring subcategorization frames , with the hypothesis that the disambiguation will cluster the instances .", "label": "", "metadata": {}, "score": "58.07945"}
{"text": "Let you imagine the representation of problems on a hierarchical tree .A parent node is bigger problem , and a smaller is child node .To compute the solution for the parent node you do not need to look at its descendant just need to care its children .", "label": "", "metadata": {}, "score": "58.09432"}
{"text": "The similaritybased methods perform up to 40 % better on this particular task . ...Sections 2.3.1 and 2.3.2 discuss two related information - theoretic functions , the KL divergence and the Jensen - Shannon divergence .Section 2.3.3 describes the L 1 norm , ... . by Ido Dagan , Lillian Lee , Fernando Pereira - In Proceedings of the Association for Computational Linguistics , 1997 . \" ...", "label": "", "metadata": {}, "score": "58.257072"}
{"text": "distance[i , j - 1 ] + 1 , // if we base the problem [ i , j - 1 ] we need to delete one character .for example : from ABCD to ABC we need to delete \" D \" .", "label": "", "metadata": {}, "score": "58.30845"}
{"text": "The purpose of the SemEval exercises and SENSEVAL is to evaluate semantic analysis systems .The first three evaluations , Senseval-1 through Senseval-3 , were focused on word sense disambiguation , each time growing in the number of languages offered in the tasks and in the number of participating teams .", "label": "", "metadata": {}, "score": "58.500786"}
{"text": "This link is referred to as a \" structural \" link and is given a constant weight .In the case of synsets that are instances of other synsets , these instance synsets may not have a hypernym path to the root vertex .", "label": "", "metadata": {}, "score": "58.590546"}
{"text": "The method of claim 48 , wherein transforming the graph into a Euclidean vector space comprises deriving an un - normalised Graph Laplacian matrix .The method of claim 48 , wherein semantic relationships between any pair of said data points are categorised according to one or more categories of semantic relationship , including a \" is - a \" relationship , a \" is - part - of \" relationship or a \" is - semantically - similar - to \" relationship .", "label": "", "metadata": {}, "score": "58.598503"}
{"text": "Such weights are usually real numbers , but may be further limited to rational or even to positive numbers , depending on the algorithms that are applied to them .It is further understood that an ' undirected graph ' refers to a graph with all bi - directional edges .", "label": "", "metadata": {}, "score": "58.819603"}
{"text": "The Kuhn - Munkres algorithm ( also known as the Hungarian method)[2 ] .Without going \" deep into theory \" , if you want to understand these algorithms , please read about them in the algorithm books .Other information about them can be reached at : . Problem .", "label": "", "metadata": {}, "score": "58.999046"}
{"text": "[ 0095 ] As a father optional step , the weight of \" structural \" links of hyponyms of a particular synset may be reduced if the number of hyponyms exceeds a minimum number and these hyponyms are leaves of the graph .", "label": "", "metadata": {}, "score": "59.317955"}
{"text": "[ 0039 ] using said vector space to determine said latent distance between said pair of vertices , said latent distance being a distance between said pair of vertices in said vector space .[ 0040 ] The transforming may be performed by deriving eigenvectors and eigenvalues or by taking the pseudo - inverse of the graph to create the vector space , for example .", "label": "", "metadata": {}, "score": "59.45083"}
{"text": "The method of claim 55 , further comprising , for each seed word , recursively adding hypernyms of said seed word as data points , where said seed word is associated with each respective hypernym and represented by the same weighted measure .", "label": "", "metadata": {}, "score": "60.218464"}
{"text": "The tree represents different relations ( such as \" is a \" or hypernyms , \" is a specialized form of \" or hyponyms , \" is a part of \" or meronyms , an so on ) .WordNet records some semantic relations between these synonym sets .", "label": "", "metadata": {}, "score": "60.35965"}
{"text": "Mr , Levenstein has done it . private int ComputeDistance ( string s , string t ) .That means the cheapest cost to transform a string of length \" i \" to a empty string is the total steps of using the delete operation .", "label": "", "metadata": {}, "score": "60.455803"}
{"text": "The SemEval exercises provide a mechanism for examining issues in semantic analysis of texts .The topics of interest are concerned with identifying and characterizing the kinds of issues relevant to human understanding of language ; the topics are generally different from the concerns of the logic - based approach of formal computational semantics .", "label": "", "metadata": {}, "score": "60.501785"}
{"text": "[ 0031 ] locating said hypernym as a vertex V h to the graph ; and .[ 0032 ] linking vertices V h and V s and assigning a weight to said link .[ 0033 ] The weight assigned to the pair of vertices V h and V s may be a constant weight .", "label": "", "metadata": {}, "score": "60.51142"}
{"text": "The method of claim 40 , wherein linking said pair of sets determined to have a semantic overlap is dependent on the calculated weight .The method of claim 48 , wherein the transforming comprises deriving eigenvectors and eigenvalues .The method of claim 48 , wherein the transforming comprises taking the pseudo - inverse of the graph .", "label": "", "metadata": {}, "score": "60.840164"}
{"text": "[ 0077 ] FIG .6 is a block diagram of a disambiguation system according to some embodiments .DETAILED DESCRIPTION .[0079 ] Referring to FIGS . 1 and 6 , a computer system is shown in the exemplary form of a computer 20 , which forms an element of a disambiguation system 600 .", "label": "", "metadata": {}, "score": "60.987522"}
{"text": "Thad Hughes , Daniel Ramage : Lexical Semantic Relatedness with Random Graph Walks .EMNLP - CoNLL 2007 : 581 - 589 .Jiang , Jay J. and David W. Conrath .Semantic similarity based on corpus statistics and lexical taxonomy .", "label": "", "metadata": {}, "score": "61.040916"}
{"text": "Comments and Discussions .General News Suggestion Question Bug Answer Joke Praise Rant Admin .Use Ctrl+Left / Right to switch messages , Ctrl+Up / Down to switch threads , Ctrl+Shift+Left / Right to switch pages .We present a novel application of WordNet to estimating the interestingness of rules discovered by data - mining methods .", "label": "", "metadata": {}, "score": "61.13669"}
{"text": "The method of claim 55 , further comprising compacting said graph by recursively removing hypernyms that have only one hyponym and linking said hyponym to a hypernym of the removed hypernym .The method of claim 63 , further comprising receiving disambiguation input comprising a word pair or a sentence as input and using the vector space to generate disambiguation output regarding the word pair or the sentence .", "label": "", "metadata": {}, "score": "61.162506"}
{"text": "Introduction .This article describes a way of capturing the similarity between two strings ( or words ) .String similarity is a confidence score that reflects the relation between the meanings of two strings , which usually consists of multiple words or acronyms .", "label": "", "metadata": {}, "score": "61.16826"}
{"text": "Introduction .This article describes a way of capturing the similarity between two strings ( or words ) .String similarity is a confidence score that reflects the relation between the meanings of two strings , which usually consists of multiple words or acronyms .", "label": "", "metadata": {}, "score": "61.16826"}
{"text": "A user may enter commands and information , such as disambiguation input 642 , into the computer 20 through input devices such as a keyboard 40 and a pointing device 42 .Input devices are often connected to the processing unit 21 through a serial port interface 46 that is coupled to the system bus .", "label": "", "metadata": {}, "score": "61.266804"}
{"text": "Some embodiments relate to a disambiguation engine comprising , or having access to , the vector space generated by the described methods and configured to use the vector space to generate disambiguation output in response to received disambiguation input .[ 0064 ] Some embodiments relate to computer systems or computing devices comprising means to perform the described methods .", "label": "", "metadata": {}, "score": "61.293907"}
{"text": "It includes the word , its explanation , and the synonyms of its meaning .The specific meaning of one word under one type of POS is called a sense .Each sense of a word is in a different synset .", "label": "", "metadata": {}, "score": "61.42736"}
{"text": "It includes the word , its explanation , and the synonyms of its meaning .The specific meaning of one word under one type of POS is called a sense .Each sense of a word is in a different synset .", "label": "", "metadata": {}, "score": "61.42736"}
{"text": "It includes the word , its explanation , and the synonyms of its meaning .The specific meaning of one word under one type of POS is called a sense .Each sense of a word is in a different synset .", "label": "", "metadata": {}, "score": "61.42736"}
{"text": "The predefined minimum weight is determined heuristically .These links are referred to as \" Lesk \" links .Normally , only such links between seed pairs of vertices , rather than between all vertices , are added since the computational expense of the calculation grows according to the number of vertices to be linked .", "label": "", "metadata": {}, "score": "61.907265"}
{"text": "However , if a global depth is not provided the global depth is set to a default value of zero .[ 0089 ] Secondly , for each seed word that is a synset , that synset is added as a vertex to the graph .", "label": "", "metadata": {}, "score": "62.22522"}
{"text": "The vector space 650 can be stored within the same memory and/or system as disambiguation engine 640 or stored separately , so long as the disambiguation engine 640 has access to vector space 650 .[ 0083 ]In order to determine a latent distance between a pair of vertices of a graph , a dataset of data points is required .", "label": "", "metadata": {}, "score": "62.367126"}
{"text": "This \" instance \" link may be given a constant weight that is different from that of a \" structural \" link .Each child is linked to its parent with a structural link .Likewise for instance synsets .If the seed word is the root word for WordNet and the depth is equal or greater to the maximum dept of the WordNet ontology tree , then the whole WordNet will be added to the graph .", "label": "", "metadata": {}, "score": "62.451942"}
{"text": "n is incremented by 1 at step 455 .The links to the start and end vertices are a framework in order to provide a single starting and ending point for the path calculation .Any weight may be used as long as it is consistent for every link that originates at the starting point and every link terminating at the end vertex .", "label": "", "metadata": {}, "score": "62.62532"}
{"text": "The results of GetSimilarity function are used to compute the weight of edges .Connecting the edges to maximize the total weight .We use the Hungarian method to solve the maximum total weight of bipartite matching problem .The class used to implement this algorithm is MatchsMaker.cs .", "label": "", "metadata": {}, "score": "62.87422"}
{"text": "The results of GetSimilarity function are used to compute the weight of edges .Connecting the edges to maximize the total weight .We use the Hungarian method to solve the maximum total weight of bipartite matching problem .The class used to implement this algorithm is MatchsMaker.cs .", "label": "", "metadata": {}, "score": "62.87422"}
{"text": "The results of GetSimilarity function are used to compute the weight of edges .Connecting the edges to maximize the total weight .We use the Hungarian method to solve the maximum total weight of bipartite matching problem .The class used to implement this algorithm is MatchsMaker.cs .", "label": "", "metadata": {}, "score": "62.87422"}
{"text": "The \" part - of \" links may be given a constant weight different from \" structural \" links .[0093 ] To ensure that the graph is connected , all unconnected subgraphs are identified and connected to the largest subgraph with structural links .", "label": "", "metadata": {}, "score": "63.067223"}
{"text": "[ 0094 ] As a further optional step , the graph may be compacted by recursively removing any hypemyms that have only one hyponym ( child ) and linking that hyponym to the hypernym of the removed hypernym .Hypernyms are identified by their relationship in WordNet .", "label": "", "metadata": {}, "score": "63.22843"}
{"text": "SemEval ( Semantic Evaluation ) is an ongoing series of evaluations of computational semantic analysis systems ; it evolved from the Senseval Word sense evaluation series .The evaluations are intended to explore the nature of meaning in language .While meaning is intuitive to humans , transferring those intuitions to computational analysis has proved elusive .", "label": "", "metadata": {}, "score": "63.43694"}
{"text": "[0122 ] It will be appreciated by persons skilled in the art that some variations and/or modifications may be made to the described embodiments without departing from the scope of the invention as broadly described .The present embodiments are , therefore , to be considered in all respects as illustrative and not restrictive .", "label": "", "metadata": {}, "score": "63.519352"}
{"text": "In Proceedings of the 14th International Joint Conference on Artificial Intelligence , pages 448 - 453 , Montreal , Canada , 1995 .Using information content to evaluate semantic similarity .In Proceedings of the 14th International Joint Conference on Artificial Intelligence , pages 448 - 453 , Montreal , Canada , 1995 .", "label": "", "metadata": {}, "score": "63.57811"}
{"text": "The description of Dijkstra 's algorithm in this book is incorporated herein by this reference .[ 0119 ] In step 485 , each word in the original sentence is replaced with its synset that is on the shortest path and in step 490 the result is output .", "label": "", "metadata": {}, "score": "63.613403"}
{"text": "For a seed word having a plurality of hypernyms , the respective vertices V h may be linked to vertex V s by the same weight .[ 0034 ] Optionally , the step of assigning a weight to said linked pair may comprise calculating a similarity measure for said pair of sets .", "label": "", "metadata": {}, "score": "63.828697"}
{"text": "[ 0103 ] For each j in S i the vertex V j is identified from the graph in step 325 .The point in the Euclidean vector space corresponding to V j is retrieved in step 330 and saved in step 335 to memory .", "label": "", "metadata": {}, "score": "64.042305"}
{"text": "The method of claim 41 , wherein , for a seed word having a plurality of hypernyms , the respective vertices V h are linked to vertex V s by the same weight .The method of claim 41 , wherein assigning a weight to said linked pair comprises calculating a similarity measure for said pair of sets .", "label": "", "metadata": {}, "score": "64.28073"}
{"text": "Comments and Discussions .Was a good read and thoroughly enjoyed going through it .Although i have to admit did n't understand most of the coding in the program , being an englishs ' student at uni myself , but managed to get in running in the end somehow by my brothers help .", "label": "", "metadata": {}, "score": "64.893776"}
{"text": "[ 0021 ] Locating said sets at respective vertices of a graph may comprise : .[ 0022 ] for each seed word that corresponds to an entry in a set , progressively locating said set as a vertex ( V s ) to said graph ; .", "label": "", "metadata": {}, "score": "64.97978"}
{"text": "The synsets that make up the shortest path are determined to be the correct meanings for each word .[ 0111 ]For illustration purposes .The sentence selected for disambiguation is \" There was a pipe leak in the flat \" .", "label": "", "metadata": {}, "score": "64.99846"}
{"text": "The task is to detect full coreference chains , composed by named entities , pronouns , and full noun phrases and to resolve pronouns , i.e. , finding their antecedents .Sentiment analysis : emotion annotation , polarity orientation labeling .The task is to classify the titles of newspaper articles with the appropriate emotion label and/or with a valence indication ( positive / negative ) , given a set of predefined six emotion labels ( i.e. , Anger , Disgust , Fear , Joy , Sadness , Surprise ) .", "label": "", "metadata": {}, "score": "65.33117"}
{"text": "[0097 ] When the graph is complete , it is then transformed by vector space generator 630 as follows , into a Euclidean vector space 650 comprising vectors indicative of respective locations of said vertices in said vector space .[ 0098 ] The un - normalized Graph Laplacian matrix ( n\u00d7n ) for the graph is derived .", "label": "", "metadata": {}, "score": "65.58501"}
{"text": "In this example three words are extracted , each of which belong to the noun category , the first word being \" pipe \" , the second word being \" leak \" and the third word being \" flat \" .n max is set to the maximum number of words , in this case three .", "label": "", "metadata": {}, "score": "65.88451"}
{"text": "[ 0116 ] The shortest path from V start to V end is then calculated using Dijkstra 's algorithm in step 475 and the associated synsets associated with the shortest path are returned at step 480 ; namely : . [ 0117 ] \" pipe \" : returns pipe.n.02 : a long tube made of metal or plastic that is used to carry water or oil or gas etc . \" leak \" : returns escape.n.07 : the discharge of a fluid from some container . \" flat \" : returns apartment.n.01 ; a suite of rooms usually on one floor of an apartment house .", "label": "", "metadata": {}, "score": "65.932655"}
{"text": "0054 ]The computer implemented method may further comprise adjusting the weighted measure according to the number of hyponyms of a particular data point .[ 0055 ] The computer implemented method may further comprise limiting the number of weighted measures to a particular data point such that the number of links to the data point does not exceed a preset maximum .", "label": "", "metadata": {}, "score": "66.08796"}
{"text": "firstly I want to explain little bit about string edit distance problem .Let give a simple game : given two words .and you have three operators to do with a word : replace , insert , delete .If you can find out the least number of steps to transform the first word to the second one , you win .", "label": "", "metadata": {}, "score": "66.119125"}
{"text": "The method of claim 35 , wherein the dataset of words may comprise single seed words and pairs of seed words .The method of claim 41 , wherein the weight assigned to the pair of vertices V h and V s is a constant weight .", "label": "", "metadata": {}, "score": "66.381035"}
{"text": "The method of claim 55 , further comprising for a pair of associated data points , calculating the weighted value using a semantic similarity measure .The method of claim 55 , further comprising adjusting the weighted measure of hyponyms according to the number of hyponyms of a particular data point .", "label": "", "metadata": {}, "score": "66.57242"}
{"text": "Each V i is linked to V 0 and a unit weight is assigned to respective links in step 430 .n is incremented by 1 .The weight that is assigned to the link between two synsets is equal to the distance between the vertices representing those synsets in the n - dimensional Euclidean vector space .", "label": "", "metadata": {}, "score": "66.81749"}
{"text": "Tokenization .A string is a list of words or abbreviations , it may be composed to follow the Camel or Pascal casing without separator characters .Take an example : ' fileName ' is being tokenized as \" file \" and \" Name \" .", "label": "", "metadata": {}, "score": "66.92169"}
{"text": "Tokenization .A string is a list of words or abbreviations , it may be composed to follow the Camel or Pascal casing without separator characters .Take an example : ' fileName ' is being tokenized as \" file \" and \" Name \" .", "label": "", "metadata": {}, "score": "66.92169"}
{"text": "Tokenization .A string is a list of words or abbreviations , it may be composed to follow the Camel or Pascal casing without separator characters .Take an example : ' fileName ' is being tokenized as \" file \" and \" Name \" .", "label": "", "metadata": {}, "score": "66.92169"}
{"text": "The WordNet .WordNet is a lexical database which is available online and provides a large repository of English lexical items .The WordNet was designed to establish connections between four types of POS ( Parts of Speech ) , noun , verb , adjective , and adverb .", "label": "", "metadata": {}, "score": "67.20598"}
{"text": "The WordNet .WordNet is a lexical database which is available online and provides a large repository of English lexical items .The WordNet was designed to establish connections between four types of POS ( Parts of Speech ) , noun , verb , adjective , and adverb .", "label": "", "metadata": {}, "score": "67.20598"}
{"text": "The WordNet .WordNet is a lexical database which is available online and provides a large repository of English lexical items .The WordNet was designed to establish connections between four types of POS ( Parts of Speech ) , noun , verb , adjective , and adverb .", "label": "", "metadata": {}, "score": "67.20598"}
{"text": "0081 ] The computer 20 may comprise code modules to configure it to act as a server and may operate in a networked environment using logical connections to one or more remote computers , such as a remote computer 49 .The logical connections depicted include a local area network ( LAN ) 51 and a wide area network ( WAN ) 52 , which may include the Internet .", "label": "", "metadata": {}, "score": "67.499344"}
{"text": "This pair is considered to , be semantically , ' most similar ' .[0105 ] For the pair of terms \" pipe \" and \" leak \" Table 1 shows the partial returned lists of each of the synsets S i and S j .", "label": "", "metadata": {}, "score": "67.64713"}
{"text": "I will be back to say about maximize bipartite matching algorithm .( I am currently sinking into research paper ) .General News Suggestion Question Bug Answer Joke Praise Rant Admin .Use Ctrl+Left / Right to switch messages , Ctrl+Up / Down to switch threads , Ctrl+Shift+Left / Right to switch pages .", "label": "", "metadata": {}, "score": "67.79325"}
{"text": "SemEval on Wikipedia .On Wikipedia , a SemEval page had been created and it is calling for contributions and suggestions on how to improve the Wikipedia page and to further the understanding of computational semantics .Introduction .This article describes a way of capturing the similarity between two strings ( or words ) .", "label": "", "metadata": {}, "score": "67.904175"}
{"text": "According to the influential theo ... \" .Selectional constraints are limitations on the applicability of predicates to arguments .For example , the statement \" The number two is blue \" may be syntactically well formed , but at some level it is anomalous - BLUE is not a predicate that can be applied to numbers .", "label": "", "metadata": {}, "score": "68.00161"}
{"text": "General News Suggestion Question Bug Answer Joke Praise Rant Admin .Use Ctrl+Left / Right to switch messages , Ctrl+Up / Down to switch threads , Ctrl+Shift+Left / Right to switch pages .Tools . by Jay J. Jiang , David W. Conrath - Proc of 10th International Conference on Research in Computational Linguistics , ROCLING'97 , 1997 . \" ...", "label": "", "metadata": {}, "score": "68.80234"}
{"text": "The task is to classify the titles of newspaper articles with the appropriate emotion label and/or with a valence indication ( positive / negative ) , given a set of predefined six emotion labels ( i.e. , Anger , Disgust , Fear , Joy , Sadness , Surprise ) .", "label": "", "metadata": {}, "score": "69.021484"}
{"text": "( This work is an experiment and is not available in this version , it will soon be released . )Using the code .Add the similarity project to your workspace .Create a method like the following : . public Test ( ) .", "label": "", "metadata": {}, "score": "69.49312"}
{"text": "( This work is an experiment and is not available in this version , it will soon be released . )Using the code .Add the similarity project to your workspace .Create a method like the following : . public Test ( ) .", "label": "", "metadata": {}, "score": "69.49312"}
{"text": "( This work is an experiment and is not available in this version , it will soon be released . )Using the code .Add the similarity project to your workspace .Create a method like the following : . public Test ( ) .", "label": "", "metadata": {}, "score": "69.49312"}
{"text": "Repeat step 4 until reach the problem size NxM .Step 4 : Compute the solution for problem of size [ i , j ] bases on previous smaller problem : [ i-1 , j ] , [ i , j-1 ] , [ i-1 , j-1 ] .", "label": "", "metadata": {}, "score": "69.54567"}
{"text": "Step 3 : Finding the solution for the problem of size [ i , j ] .The idea behind this code is bottom - up dynamic programming technique .For each element [ i , j ] we compute the solution for problem of [ i , j ] bases on the previous smaller problem .", "label": "", "metadata": {}, "score": "69.58382"}
{"text": "WordNet uses the terms hypernym and hyponym to express the \" is - a \" relationship .For example if we have that \" kitten \" is a \" cat \" then \" kitten \" is the hyponym of \" cat \" and \" cat \" is the hypernym of \" kitten \" .", "label": "", "metadata": {}, "score": "69.860115"}
{"text": "Sentiment analysis : emotion annotation , polarity orientation labeling .The task is to classify the titles of newspaper articles with the appropriate emotion label and/or with a valence indication ( positive / negative ) , given a set of predefined six emotion labels ( i.e. , Anger , Disgust , Fear , Joy , Sadness , Surprise ) .", "label": "", "metadata": {}, "score": "71.07455"}
{"text": "Herbert Rubenstein and John B. Goodenough .Contextual correlates of synonymy .Communications of the ACM , 8(10):627 - 633 , 1965 .Samer Hassan , Rada Mihalcea : Semantic Relatedness Using Salient Semantic Analysis .AAAI 2011 .Lin , Dekang .", "label": "", "metadata": {}, "score": "71.12098"}
{"text": "SemEval on Wikipedia .On Wikipedia , a SemEval page had been created and it is calling for contributions and suggestions on how to improve the Wikipedia page and to further the understanding of computational semantics .The SemEval exercises provide a mechanism for examining issues in semantic analysis of texts .", "label": "", "metadata": {}, "score": "72.260284"}
{"text": "Contents .SemEval ( Semantic Evaluation ) is an ongoing series of evaluations of computational semantic analysis systems ; it evolved from the Senseval Word sense evaluation series .The evaluations are intended to explore the nature of meaning in language .", "label": "", "metadata": {}, "score": "72.78276"}
{"text": "0004 ]A further example is that of natural language processing , in particular the application of automated expression disambiguation , especially for document retrieval .Take the word ' pipe ' for example .The word ' pipe ' has many meanings , for instance a pipe for smoking tobacco , a tube for directing the flow of fluids or gases , and an organ - pipe .", "label": "", "metadata": {}, "score": "72.92726"}
{"text": "Proc . of the 51st Annual Meeting of the Association for Computational Linguistics ( ACL 2013 ) , Sofia , Bulgaria , August 4 - 9 , 2013 , pp .1341 - 1351 .Michael Strube , Simone Paolo Ponzetto : WikiRelate !", "label": "", "metadata": {}, "score": "73.09575"}
{"text": "To a human , the combination \" pipe leak \" has a clear meaning and refers to a hole in a pipe from which a liquid or gas is escaping .However , to a computer the meaning is not clear .", "label": "", "metadata": {}, "score": "75.51424"}
{"text": "A first list of all the synsets of the first word \" pipe \" are compiled S i in step 310 and a second list of all the synsets of the first word \" leak \" are compiled S j in step 315 .", "label": "", "metadata": {}, "score": "76.754715"}
{"text": "Share .About the Author .I 'm still alive ... but temporarily moved to work on mobile & web stuffs(j2me / brew / php / flash ... something not M$ ) .things have just been very busy , and probably will continue ... so do n't have chance to maintain & respond .", "label": "", "metadata": {}, "score": "77.944435"}
{"text": "Share .About the Author .I 'm still alive ... but temporarily moved to work on mobile & web stuffs(j2me / brew / php / flash ... something not M$ ) .things have just been very busy , and probably will continue ... so do n't have chance to maintain & respond .", "label": "", "metadata": {}, "score": "77.944435"}
{"text": "Share .About the Author .I 'm still alive ... but temporarily moved to work on mobile & web stuffs(j2me / brew / php / flash ... something not M$ ) .things have just been very busy , and probably will continue ... so do n't have chance to maintain & respond .", "label": "", "metadata": {}, "score": "77.944435"}
{"text": "The match .Score is the similarity score of the two strings .In this example , the score is 0.94 .References .License .This article has no explicit license attached to it but may contain usage terms in the article text or the download files themselves .", "label": "", "metadata": {}, "score": "79.2431"}
{"text": "The match .Score is the similarity score of the two strings .In this example , the score is 0.94 .References .License .This article has no explicit license attached to it but may contain usage terms in the article text or the download files themselves .", "label": "", "metadata": {}, "score": "79.2431"}
{"text": "The match .Score is the similarity score of the two strings .In this example , the score is 0.94 .References .License .This article has no explicit license attached to it but may contain usage terms in the article text or the download files themselves .", "label": "", "metadata": {}, "score": "79.2431"}
{"text": "The drives and their associated computer - readable media provide non - volatile storage of computer readable instructions , data structures , program modules and other data for the computer 20 .Such application programs 36 include a vector space generator 630 and a disambiguation engine 640 , as shown in FIG .", "label": "", "metadata": {}, "score": "79.79879"}
{"text": "To escape : the cylindrical discharge of a shape fluid from some container .Pipe.n.04 a tubular wind instrument Organ_Pipe .n.01 the flues and stops on a pipe organ . [0106 ] The partial output of the calculated distances is shown below in Table 2 .", "label": "", "metadata": {}, "score": "83.433975"}
{"text": "n.01 to escape.n.07 0.45705944 pipe.n.03 to leak.n.02 28.6794190 pipe.n.01 to leak.n.02 28.6798460 pipe.n.02 to leak.n.02 28.6801110 organ_pipe .n.01 to leak.n.02 28.6897180 pipe.n.04 to leak.n.03 41.6200600 . \" Pipe leak : A long tube made of metal or plastic that is used to carry water or oil or gas etc , the discharge of a fluid from some container .", "label": "", "metadata": {}, "score": "85.08262"}
{"text": "[0044 ] Advantageously , embodiments can be used to determine latent relationships , as well as emergent behaviours in large data sets .[0045 ] The term latent ( indirect ) refers to the relationship between data points .For example , in the context of language , and referring to the sentence \" the robin flew down from the tree and ate the worm \" , there is a direct relationship formed between robin , flew , and worm because they have all appeared together .", "label": "", "metadata": {}, "score": "85.276596"}
{"text": "For example , a speech recognizer may need to determine which of the two word combinations \" eat a peach \" and \" eat a beach \" is more likely .Statistical NLP met ... \" .Abstract .In many applications of natural language processing ( NLP ) it is necessary to determine the likelihood of a given word combination .", "label": "", "metadata": {}, "score": "88.51474"}
{"text": "For example , tree is a kind of plant , tree is a hyponym of plant and plant is hypernym of tree .Analogously trunk is a part of tree and we have that trunk is meronym of tree and tree is holonym of trunk .", "label": "", "metadata": {}, "score": "88.534515"}
{"text": "For example , tree is a kind of plant , tree is a hyponym of plant and plant is hypernym of tree .Analogously trunk is a part of tree and we have that trunk is meronym of tree and tree is holonym of trunk .", "label": "", "metadata": {}, "score": "88.534515"}
{"text": "For example , tree is a kind of plant , tree is a hyponym of plant and plant is hypernym of tree .Analogously trunk is a part of tree and we have that trunk is meronym of tree and tree is holonym of trunk .", "label": "", "metadata": {}, "score": "88.534515"}
{"text": "Computer 20 may be any form of computing device or system capable of performing the functions described herein .The computer 20 further includes a hard disk drive 27 for reading from and writing to a hard disk 60 and an optical disk drive 30 for reading from or writing to a removable optical disk 31 .", "label": "", "metadata": {}, "score": "94.1988"}
{"text": "When used in a LAN networking environment , the computer 20 is connected to the local network 51 through a network interface or adapter 53 .When used in a WAN networking environment , the computer 20 typically includes a modem 54 for establishing communications over the WAN 52 .", "label": "", "metadata": {}, "score": "96.85281"}
