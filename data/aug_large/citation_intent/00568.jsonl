{"text": "Church and Hanks made use of mutual information ( MI ) to evaluate the correlation between a pair of words .They take a window size of five words for co - occurrence and conduct experiments based on a corpus .They were able to extract interesting pairs of related words such as doctors and nurses doctors and treating .", "label": "", "metadata": {}, "score": "33.60253"}
{"text": "Both works attempted to automatically acquire true collocations from corpora .Our work builds on Choueka 's , and has been developed contemporarily to Church 's .Choueka , Klein , and Neuwitz ( 1983 ) pro ... . \" ...One of the main challenges in question - answering is the potential mismatch between the expressions in questions and the expressions in texts .", "label": "", "metadata": {}, "score": "40.16594"}
{"text": "Several approaches have been proposed to retrieve various types of collocations from the analysis of large samples of textual data .These techniques automatically produce large numbers of collocations along with statistical figures intended to reflect the relevance of the associations .", "label": "", "metadata": {}, "score": "40.538887"}
{"text": "Also , the results produced often contained improper word associations reflecting some spurious aspect of the training corpus that did not stand for true collocations .In this paper , we describe a set of techniques based on statistical methods for retrieving and identifying collocations from large textual corpora .", "label": "", "metadata": {}, "score": "41.939896"}
{"text": "People , words , and objects do . by Kenneth Church , William Gale , Patrick Hanks , Donald Hindle - In Proceedings of the International Workshop on Parsing Technologies , 1989 . \" ...There are a number of coUocational constraints in natural languages that ought to play a more important role in natural language parsers .", "label": "", "metadata": {}, "score": "43.61537"}
{"text": "( The standard method of obtaining word association norms , testing a few thousand subjects on a few hundred words , is both costly and unreliable . )The proposed measure , the association ratio , estimates word association norms directly from computer readable corpora , making it possible to estimate norms for tens of thousands of words . by Kenneth Church , William Gale , Patrick Hanks , Donald Hindle - Lexical Acquisition : Exploiting On - Line Resources to Build a Lexicon , 1991 . \" ...", "label": "", "metadata": {}, "score": "44.934677"}
{"text": "Word collocation measures the likelihood that two words co - occur within a given distance of each other .The strength of word collocation can also be measured by the frequency of a word pair F(x , y ) in a corpus of fixed size .", "label": "", "metadata": {}, "score": "45.424717"}
{"text": "However , it should be noted that the word \" term \" has a different meaning in information retrieval , where it refers to words and phrases .There are more and more interest in collocations and co - occurrences partly because this area has been undervalued in the structural linguistic traditions that follow Saussure and Chomsky .", "label": "", "metadata": {}, "score": "45.55993"}
{"text": "Moreover , the extracted collocations or co - occurrences are always stored in a dictionary , which only contains a limited number of entries with limited information for each one .Finally , the collocation dictionary normally does not differentiate the strength of various collocations .", "label": "", "metadata": {}, "score": "45.618317"}
{"text": "Ken Church and Bill Gale ( et al ) used this statistic over a decade ago and published papers on its use .Annoyingly ( in this new cyber world ) I routinely refer people to .Church , K.W. , W.Gale , P.W.Hanks , D. Hindle \" Using Statistics in Lexical Analysis \" in Uri Zernik ( ed . )", "label": "", "metadata": {}, "score": "47.12539"}
{"text": "The promotion of correct choices at various locations within a sentence influences the promotion of word decisions elsewhere .This effectively improves on a strictly local analysis by allowing for strong collocations to reinforce weak ( but related ) collocations .Hereinafter is shown an experimental analysis in which the process is applied to improving text recognition results that are less than 60 % correct .", "label": "", "metadata": {}, "score": "47.917274"}
{"text": "Thus , in the above example , 80 % of the time the correct word would remain in the top position , 10 % of the time it would be moved into the second position , and so on .The eight noise models shown in Table 4 were used to generate neighborhoods for the running text of the five test articles .", "label": "", "metadata": {}, "score": "47.97332"}
{"text": "However , a sufficiently large tagged corpus is not available .To acquire an adequate database of collocations , the full 85-million WSJ corpus is needed .It is necessary to infer the nature of combinations from indirect corpus - based statistics as shown below .", "label": "", "metadata": {}, "score": "48.50538"}
{"text": "Each neighborhood has one or more adjacent neighborhoods .Each neighborhood is ranked by its first to last choice of candidates .The computer accesses from its word collocation data base collocation data for each word candidate .Collocation data may be the likelihood of the word candidate appearing with its adjacent word candidate .", "label": "", "metadata": {}, "score": "48.81378"}
{"text": "Page 12 .12 Guodong Zhou et al . 1stReading Table 2 .Examples of N - best collocations ( Here , the collocations are sorted according to EPMI first and then EAMI . )No .Table 3 gives some of them .", "label": "", "metadata": {}, "score": "48.97954"}
{"text": "These sets do not contain translations of the individual words \" make \" , \" use \" and \" of \" so that a large number of possibly irrelevant senses of the constituent terms of the collocation \" make use of \" are eliminated .", "label": "", "metadata": {}, "score": "49.32843"}
{"text": "[ 7 ] D. Hindle and M. Rooth , Structural ambiguity and lexical relations , Computational Linguistics , 19(1 ) , 1993 , 102 - 119 .[ 8 ] J. S. Justeson and S. M. Katz , Technical terminology : Some linguistic properties and an algorithm for identification in text , Natural Language Engineering , 1(1 ) , 1995 , 9 - 27 .", "label": "", "metadata": {}, "score": "49.50882"}
{"text": "This paper will propose an objective measure based on the information theoretic notion of mutual information , for estimating word association norms from computer readable corpora .( The standard method of obtaining word association norms , testing a few thousand subjects on a few hundred words , is b ... \" .", "label": "", "metadata": {}, "score": "49.598938"}
{"text": "In the specific example described hereinbefore , the glosser was required to identify only a single continuous collocation in addition to the individual words of the source language query .However , the glosser disclosed in EP 0 813 160 and GB 2 314 183 is also capable of identifying non - continuous collocations .", "label": "", "metadata": {}, "score": "49.65035"}
{"text": "In accordance with the present invention , a method is provided for performing part of speech tagging for content - word pairs in a natural language text processing system .Content - word pairs are first identified in a large corpus of text used for training purposes .", "label": "", "metadata": {}, "score": "49.956787"}
{"text": "For each word position , the word recognition program provides a neighborhood of word candidates .Each word candidate has an initial probability of correctness .The word candidates are selected from a dictionary stored in a data base .Each word position has at least two word candidates and as many as ten or more .", "label": "", "metadata": {}, "score": "50.473434"}
{"text": "This is done by finding two optimal classes in the collocation net and mapping the less - frequently occurring word and feature bigrams to them through the word- clustering mechanism provided in the collocation net as follows : . indd 711/29/2007 2:52:46 PM .", "label": "", "metadata": {}, "score": "50.88801"}
{"text": "The second and third columns present the collocation and its frequency .The fourth and fifth column present the stemmed collocation and its frequency .The sixth column presents the mutual information score ( MIS ) .The MIS is calculated by dividing the number of occurrences of the collocation by the number of times each individual word in the collocation occurs alone .", "label": "", "metadata": {}, "score": "51.100544"}
{"text": "Word collocation refers to the likelihood that two words co - occur within a fixed distance of one another ....A word recognizer system 10 has a probabilistic relaxation process that improves the performance of an image text recognition technique by propagating the influence of word collocation statistics .", "label": "", "metadata": {}, "score": "51.373314"}
{"text": "Through the collocation net , the data sparseness problem is resolved by providing a clustering mechanism and the collocation relationship between any two words can be easily determined and measured from the collocation net .Here , the collocation relationship is calculated using novel estimated pair - wise mutual information ( EPMI ) and estimated average mutual information ( EAMI ) .", "label": "", "metadata": {}, "score": "51.59024"}
{"text": "This paper will concentrate on \" collocation \" rather than \" co - occurrence \" although there is much overlap between these two terms .There is also considerable overlap between the concept of \" collocation \" and notions like \" term \" , \" technical term \" and \" terminological phrase \" .", "label": "", "metadata": {}, "score": "51.844322"}
{"text": "Our algorithm is based on an extended version of Harris ' Distributional Hypothesis , which states that words that occurred in the same contexts tend to be similar .Instead of using this hypothesis on words , we apply it to paths in the dependency trees of a parsed corpus .", "label": "", "metadata": {}, "score": "51.858753"}
{"text": "Search for a word ( phrase ) within a set span ( e.g. 4 words ) .The program lists all the collocations containing the searchword and provides frequency and/or statistical information ( Log Likelihood , Mutual Information , t - score ) .", "label": "", "metadata": {}, "score": "52.090103"}
{"text": "Try the different measures : you 'll soon see the difference .If a collocate appears in the top of both MI and t - score lists it is clearly a humdinger of a collocate , rock - solid , typical , frequent , strongly associated with its node word , recurrent , reliable , etc etc etc .", "label": "", "metadata": {}, "score": "52.26777"}
{"text": "Page 3 .Building a Collocation Net 3 1stReading 1.1 .Statistics - based methods The methods in this category are normally used to extract the word co - occurrence relationship , the phenomena where words are likely to occur in the same context , from the raw unparsed corpus .", "label": "", "metadata": {}, "score": "52.27498"}
{"text": "In the more advanced lexicographic organizations , there are concordancing programs ( see figure below ) , which are basically KWIC ( key word in context ( Aho et al . , 1988 , p. 122 ) , ( Salton , 198 ... \" .", "label": "", "metadata": {}, "score": "52.530613"}
{"text": "However , this would require perfect knowledge about which collocation is correct .Actual performance will be less than this because of other words in the neighborhood that have collocations in the training data and the interactions of those words and their recognition confidence values during iterations of the relaxation algorithm .", "label": "", "metadata": {}, "score": "52.70339"}
{"text": "( d ) generating a ranking of candidates for each word based upon a likelihood of correctness of each candidate , each ranking having a top choice indicating the initial most likely correct candidate for the word ; .( e ) grouping ranked word candidates into neighborhoods , each neighborhood comprising two or more word candidates and each neighborhood being adjacent to at least one other neighborhood ; .", "label": "", "metadata": {}, "score": "52.74076"}
{"text": "The word recognizer 10 receives groups of visually similar decisions ( called neighborhoods ) for words in a running text .The position of decisions within the neighborhoods are modified based on how often they co - occur with decisions in the neighborhoods of other nearby words .", "label": "", "metadata": {}, "score": "52.811943"}
{"text": "[14 ] F. Smadja , Retrieving collocations from text : Xtract , Computational Linguistics , 19(1 ) , 1993 , 143 - 177 .[15 ] G. W. Snedecor and G. C. William , Statistical Methods , Iowa State University Press , Ames , Iowa , 1989 , p. 127 .", "label": "", "metadata": {}, "score": "53.240402"}
{"text": "A method of determining the similarity of nouns on the basis of a metric derived from the distribution of subject , verb and object in a large text corpus is described .The resulting quasi - semantic classification of nouns demonstrates the plausibility of the distributional hypothesis , and has potential application to a variety of tasks , including automatic indexing , resolving nominal compounds , and determining the scope of modification . \" ...", "label": "", "metadata": {}, "score": "53.35829"}
{"text": "Keywords : .With specific reference to bilingual lexicography , one only finds trivial statements , with no solutions whatsoever .For instance , all that is said by Gauton ( 2008 : 112 ) on ideophones is : \" Languages ... . \" ...", "label": "", "metadata": {}, "score": "53.422646"}
{"text": "First of all , frequency - based method [ 12 , 8 , 18 ] uses the frequencies of the word pairs with the optional help of part - of - speech filter , stop word list and/or acceptable patterns .Secondly , mean and variance - based method [ 14 ] computes the mean and variance of the offsets between the words in the corpus , and the word pairs , which have low variances , are regarded as word co - occurrences .", "label": "", "metadata": {}, "score": "53.503956"}
{"text": "This paper will attempt to show that many of these types of concerns can be addressed with syntactic methods ( symbol pushing ) , and need not require explicit semantic interpretation .We have found that it is possible to identify many of these interesting co - occurrence relations by computing simple summary statistics over millions of words of text .", "label": "", "metadata": {}, "score": "53.52344"}
{"text": "Such a process aids the selection of sensible translations because there are fewer possible translations of a collocation than of its separate constituent words .For example , the collocation \" make use of \" has only a few translations into target languages whereas the frequently used terms \" make \" , \" use \" and \" of \" give rise to a large number of translation terms .", "label": "", "metadata": {}, "score": "53.751938"}
{"text": "If that pattern of distance is relatively predictable then we have evidence for a collocation of variable phrases like cement ... relations .Hypothesis Testing .Hypothesis testing is used to check whether two words co - occur more often than a chance .", "label": "", "metadata": {}, "score": "53.77991"}
{"text": "These techniques often post - process the results of a word recognition process that provides various alternatives for the identity of each word that are called its neighborhood .The objective of the language model is to choose the alternatives for words that make sense in the context of the rest of the text .", "label": "", "metadata": {}, "score": "53.856407"}
{"text": "It should be noted that these results were calculated from the entire training database , including the test articles .Since , as shown earlier , about 2 % to 3 % of the words in the test data do not occur in the training data , the performance obtained by re - ranking using frequency could be up to 2 % to 3 % lower .", "label": "", "metadata": {}, "score": "53.95718"}
{"text": "Collocation or lexical collocation means two or more words co - occur in a sentence more frequently than by chance .A collocation is an expression that forms a specific meaning .It may be noun phrase like large house , verbal phrase like pick up , idioms , cliches or technical terms .", "label": "", "metadata": {}, "score": "54.048195"}
{"text": "In step four , for each word in each neighborhood the computer 20 computes the collocation score for the word candidate .After the collocation scores for all the word candidates are computed in accordance with expression 2.0 , the neighborhoods are resorted by their new collocation scores .", "label": "", "metadata": {}, "score": "54.072052"}
{"text": "Relations to other theories , phenomena , and problems are sketched . ... 5 Given the transform used , this result is similar to what would be obtained by a mutual information analysis , a method for capturing word dependencies often used in computational linguistics ( e.g .. Because of the transform , this poor result is still better than that obtained by a gross correlation over raw co - occurrence frequencies , a statistic often assumed to be the way statistical extracti ... . \" ...", "label": "", "metadata": {}, "score": "54.240196"}
{"text": "Thus , although known techniques for cross - linguistic information retrieval may be used , the efficacy of such information retrieval can only be checked by searchers who have sufficient familiarity with the target language not to need to use such techniques .", "label": "", "metadata": {}, "score": "54.243546"}
{"text": "Page 10 .In this way , we have a large set of collocation candidates with their frequencies .( 4 ) Examine whether the collocation net is to be re - built .For example , whether the average probability ratio between the best parsed tree hypothesis and the second best parsed tree hypothesis for each sentence converges or begins to dropd .", "label": "", "metadata": {}, "score": "54.353104"}
{"text": "Fourthly , mutual information - based method [ 13 , 17 , 19 , 20 ] tells the change of information when two words co - occur .The scores used by t - test and chi - square are difficult to interpret while mutual information - based method is the worst for the low frequently occurred words .", "label": "", "metadata": {}, "score": "54.369934"}
{"text": "[ 2 ] K. W. Church and A. G. William , A comparison of the enhanced good turing and deleted estimation methods for estimating probabilities of English bigrams , Computer , Speech and Language , 5(1 ) , 1991 , 19 - 54 .", "label": "", "metadata": {}, "score": "54.660027"}
{"text": "This was done by calculating the percentage of words in the test articles that also appear in the training data .This is relevant since if a word does not occur in the training data there will be no collocations stored for it and the algorithm may not select it .", "label": "", "metadata": {}, "score": "54.66047"}
{"text": "Note that here verbs precede propositions .Calzolari and Bindi uses mutual information for extracting lexical information from an Italian corpus .They used a measure , dispersion , to show how the second word is distributed within the window under consideration .", "label": "", "metadata": {}, "score": "54.7063"}
{"text": "( h ) sorting word candidates by their collocation score ; .( i ) comparing changes between the word candidates of the initial neighborhoods and the word candidates in the sorted neighborhood ; .( j ) counting the number of changes for the neighborhoods ; and .", "label": "", "metadata": {}, "score": "54.83721"}
{"text": "These results show that about 60 % of the words occur adjacent to the same words in both the test data and the training data .About 32 % of the words are adjacent only to either the word before or the word after and 4 % to 8 % of the words have no collocations in the training database .", "label": "", "metadata": {}, "score": "54.918827"}
{"text": "[ 4 ] M. Collins , Head - driven statistical models for natural language parsing , Ph.D. Dissertation , University of Pennsylvania , 1999 .[5 ] T. Dunning , Accurate methods for the statistics of surprise and coincidence , Computational Linguistics , 19(1 ) , 1993 , 61 - 74 .", "label": "", "metadata": {}, "score": "54.928688"}
{"text": "Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , a \u00d8 2 -test ( CHI ) , and term strength ( TS ) .", "label": "", "metadata": {}, "score": "54.973495"}
{"text": "However , when tested on a real corpus , ( i.e. , Wall Street Journal ( WSJ ) news stories ) , this mechanism collapses .For a typical well - behaved 33-word sentence it produces hundreds of candidate interpretations .", "label": "", "metadata": {}, "score": "55.01435"}
{"text": "Before testing the process , a baseline for performance comparison was determined .The accuracy rate in each position in the top 10 candidate list was calculated by re - ranking using word frequency , i.e. , the a - priori probability of the word ( see Table 5 ) .", "label": "", "metadata": {}, "score": "55.219162"}
{"text": "Word collocation refers to the likelihood that two words co - occur within a fixed distance of one another .For example , it is highly likely that if the word \" boat \" occurs , the word \" river \" will also occur somewhere in ten words on either side of \" boat . \" Previous work using word collocation data to post - process word recognition results has shown the usefulness of this data .", "label": "", "metadata": {}, "score": "55.292725"}
{"text": "65 - 73 , Columbus , Ohio , 1993 .This technique used local collocation data about words that co - occur next to each other to improve recognition performance .A disadvantage of this approach was that it did not allow for successful results off : one word to influence the results on another word .", "label": "", "metadata": {}, "score": "55.571632"}
{"text": "This method of calculating the score for \u03c9 ij at time k+1 is an improvement over a previous approach that did not incorporate recognition confidence .This measure uses the top - ranked choice of adjacent words to adjust the ranking in each neighborhood .", "label": "", "metadata": {}, "score": "55.632156"}
{"text": "The method attains an accuracy of 82.8 % on the full test set , but the accuracy rises above 95 % when the algorithm is allowed to abstain from classifying mild words . \" ...This paper presents a simple unsupervised learning algorithm for recognizing synonyms , based on statistical data acquired by querying a Web search engine .", "label": "", "metadata": {}, "score": "55.774483"}
{"text": "This paper presents a simple unsupervised learning algorithm for recognizing synonyms , based on statistical data acquired by querying a Web search engine .The algorithm , called PMI - IR , uses Pointwise Mutual Information ( PMI ) and Information Retrieval ( IR ) to measure the similarity of pairs of words .", "label": "", "metadata": {}, "score": "55.88035"}
{"text": "The focus is on aggressive dimensionality reduction .Five methods were evaluated , including term selection based on document frequency ( DF ) , information gain ( IG ) , mutual information ( MI ) , ... \" .This paper is a comparative study of feature selection methods in statistical learning of text categorization .", "label": "", "metadata": {}, "score": "55.96751"}
{"text": "Recent work in lexicography indicates that collocations are pervasive in English ; apparently , they are common in all types of wri ... \" .Natural languages are full of collocations , recurrent combinations of words that co - occur more often than expected by chance and that correspond to arbitrary word usages .", "label": "", "metadata": {}, "score": "55.991264"}
{"text": "However , since there are no explicit meaning priorities for these word - forms established in the Ministry 's guidelines , it is hypothesized that the Ministry 's prescribed list will not effect a principled implementation of the word - forms or a systematic treatment which includes their most common meanings and uses .", "label": "", "metadata": {}, "score": "56.098198"}
{"text": "There has been described a relaxation process that used word collocation information to improve text recognition results .The experimental results showed that the correct rate at the top choice of a word recognition algorithm could be improved from 56 % to 83 % correct .", "label": "", "metadata": {}, "score": "56.33066"}
{"text": "Thus , only 2 % to 3 % of the words in a typical document are not found .The potential upper bound in performance is also illustrated by the results shown in Table 3 .These give the number of times each word in the test articles appear adjacent to the same word or words in the training data .", "label": "", "metadata": {}, "score": "56.456993"}
{"text": "This suggests the data sparseness problem in building a collocation net and proper handling can improve the performance .For clarity , Table 5 lists the effect of the best full parsing re - ranking system using the collocation net .It shows that the use of the collocation net can increase the F - measure by 1.9 in F - measure .", "label": "", "metadata": {}, "score": "56.48587"}
{"text": "For example , one effect of this may be that , because information retrieval systems are often statistical in nature , more common terms may be allowed to contribute fewer documents to a retrieval system so as to leave more room for other terms to contribute documents .", "label": "", "metadata": {}, "score": "56.488434"}
{"text": "Frequencies of each variant in the WSJ corpus are shown .For example , joint venture takes 3 variants totaling 4300 instances , out of which 4288 are concentrated in 2 patterns , which in effect ( stripping the plural \" S \" suffix ) , are a single pattern .", "label": "", "metadata": {}, "score": "56.57347"}
{"text": "Compared with the traditional collocation dictionary , the collocation net provides a much more powerful facility since it can determine and measure the collocation relationship between any two words quantitatively .The layout of this paper is as follows : Section 2 describes the novel structure of collocation net .", "label": "", "metadata": {}, "score": "56.578053"}
{"text": "Also , alternative translations may be ranked according to a criterion indicating the likelihood of each translation being correct .Thus , the number of translations actually used in target - language query formulation may be adjusted to the requirements of a searcher .", "label": "", "metadata": {}, "score": "56.666817"}
{"text": "The present algorithm tags both light cases as a noun .The example below illustrates the use of a fixed and a variable collocation in context , and motivates the need for thematic analysis .In this small sample , 8 out of 35 cases ( the ones marked \" - \" ) can not be resolved reliably by using local context only .", "label": "", "metadata": {}, "score": "56.67518"}
{"text": "There are many approaches to find collocations in a text corpus .The important ones are : .Frequency 2 .Mean and Variance 3 .Hypothesis Testing 4 .Mutual Information .Frequency .Frequency is the simplest method for finding collocations in a text corpus .", "label": "", "metadata": {}, "score": "56.680695"}
{"text": "In the specific example , the first two documents are clearly relevant as they contain the preferred glossing translations of the terms of the source language query .However , by using a limited number of less - preferred translations , the chances of missing a relevant document are reduced whereas the number of irrelevant documents located is also reduced .", "label": "", "metadata": {}, "score": "56.93972"}
{"text": "Table 2 gives some of the examples .It shows that our method can not only extract the collocations that occur frequently in the corpus but also extract the collocations that seldom occur in the corpus .Another advantage is that our method can determine the collocation relationship between any two words and measure its strength degree .", "label": "", "metadata": {}, "score": "56.970093"}
{"text": "That signal is then converted into digital pixel data signals for segmentation and word recognition .Moreover , while the above examples have used the top choices of two adjacent neighbors , those skilled in the art will realize that one could use a single neighbor top choice for collocation .", "label": "", "metadata": {}, "score": "56.977634"}
{"text": "When deciding on a strategy for formulating target language queries , it may be necessary to consider the actual form of the multilingual resource .For example , machine translation systems may generate target language query terms which are quite rare whereas glossers might generate more common terms .", "label": "", "metadata": {}, "score": "57.245632"}
{"text": "A key insight gained by computational methods in language analysis is undoubtedly the importance of lexical co - occurrence and usage patterns for the description of lexical meaning .Corpus analysis and new methods in the analysis of pragmatic components of meaning have also yielded significant results in areas such as the treatment of semantic prosody .", "label": "", "metadata": {}, "score": "57.500114"}
{"text": "The performance gap between the results achieved when the collocation data includes the test data and when it does not suggests that word collocation data should be collected from larger and more balanced English corpora .Analysis of the remaining errors showed that many of them could be corrected by using a larger window size and special strategies for processing proper nouns .", "label": "", "metadata": {}, "score": "57.535095"}
{"text": "In step seven , if the number of changes of word candidates within the neighborhoods is at or below a threshold number , the iterative process beginning at step three is repeated .On the other hand , if the number of changes are less than the threshold , then the top choices of each neighborhood are output as the most likely correct choices of the word recognizer 10 .", "label": "", "metadata": {}, "score": "57.65055"}
{"text": "A span of up to 12 words is allowed , but the only statistical score in spans larger than 2 is Mutual Information .The search string can be based on or include part - of - speech tags , assuming that the corpus is tagged .", "label": "", "metadata": {}, "score": "57.83113"}
{"text": "The results which are returned and which contain \" most likely \" query term translations may be placed higher in a ranked list of results than those containing a target language query term generated from a less likely translation alternative .A specific example illustrating such re - ranking is described hereinafter .", "label": "", "metadata": {}, "score": "58.11341"}
{"text": "words co - occurring next to each other .In practice , a substantial number of collocations in real languages are non - continuous .For example , the collocation \" make use of \" may occur in natural language documents as \" make good use of \" , spanning the word \" good \" so as to be a non - continuous collocation .", "label": "", "metadata": {}, "score": "58.416695"}
{"text": "International Journal of Computer Processing of Oriental Languages Vol . a - star .edu.sg This paper presents an approach to build a novel two - level collocation net , which enables calculation of the collocation relationship between any two words , from a large raw corpus .", "label": "", "metadata": {}, "score": "58.619267"}
{"text": "Each neighborhood ( e.g. snow , slow , show ) is a group of visually similar words .The neighborhoods are initially ranked by the confidence values provided by a word recognition program in a manner well known in the art .", "label": "", "metadata": {}, "score": "58.64306"}
{"text": "In this case , the words \" making use of \" constitute a non - continuous collocation spanning the word \" good \" .By detecting such non - continuous collocations , it is possible to improve the precision of translating the query into the target language .", "label": "", "metadata": {}, "score": "58.665516"}
{"text": "Now if we were to list the collocates of \" post ' by raw frequency of co - occurrence we would order them according to j(x ) , as above .Of course , a full collocation listing of \" post \" in this form would have many other words with intermediate frequencies -- we are just focussing on these three words for the moment .", "label": "", "metadata": {}, "score": "58.6993"}
{"text": ", Loci of contextual effects on visual word recognition , in Attention and Performance V , edited by P. Rabbitt and S. Dornie .Academic Press , 1975 , pp .98 - 116 .[ 12 ] I. C. Ross and J. W. Tukey , Introduction to these volumes , in John Wilder Tukey ( ed . ) , Index to Statistics and Probability , R&D Press , Los Altos , 1975 , pp . iv - x .", "label": "", "metadata": {}, "score": "58.718758"}
{"text": "Neighborhood Generation .Neighborhoods were generated for each of the 70,000 unique words in the combined corpus of testing and training data by the following procedure .Digital images of the words were generated from their ASCII equivalents by first converting them to an 11 pt .", "label": "", "metadata": {}, "score": "58.848892"}
{"text": "Semantic Collocations : They are lexically restricted word pairs , for which only a subset of the synonym of the collocator can be used in the same lexical context .Collocations are also categorized into compounds and flexible word pairs .Compounds : Compounds include word pairs that occur consecutively in language and typically are immutable in function .", "label": "", "metadata": {}, "score": "58.970013"}
{"text": "In our experimentation , only six most frequently occurring collocation relation types are considered .Table 1 shows them with their occurrence frequencies in the Reuters corpus .Table 1 .Six most frequently occurring collocation relation types ( in predicate + argument/ adjunct or head noun + modifier format ) .", "label": "", "metadata": {}, "score": "58.971474"}
{"text": "WO 97/08604 discloses an information retrieval system which is based on translating queries and documents .However , this technique makes use of a language - independent conceptual representation of each query and of each document which is available for searching .", "label": "", "metadata": {}, "score": "59.146286"}
{"text": "However , both of these approaches have disadvantages .Selecting all possible translations of source language query terms may lead to the retrieval of many documents which are not relevant to the query .This is because source language words have different meanings in different contexts and , based on these , have different preferred translations .", "label": "", "metadata": {}, "score": "59.189487"}
{"text": "Building a Collocation Net 11 1stReading from Tij ; CC is the number of collocation candidates extracted from Tij and EPMI(CCi ) is the estimated pair - wise mutual information , which measures the change of information when the collocation candidate CCi is collocated .", "label": "", "metadata": {}, "score": "59.27687"}
{"text": "It is believed that such a technique may not result in too many relevant documents being retrieved because the fact that the term is common is a clue to the information retrieval system that its value in distinguishing relevant documents from non - relevant ones is probably quite low .", "label": "", "metadata": {}, "score": "59.452103"}
{"text": "The method of claim 1 wherein said high variability factors exceed 0.75 and said low variability factors are less than or equal to 0.75 .The method of claim 1 comprising the additional step of using local context analysis to tag collocation content word pairs before using said collocation database .", "label": "", "metadata": {}, "score": "59.524216"}
{"text": "The problem takes many forms ; learning vocabulary from text is an especially dramatic and convenient case for research .A new general theory of acquired similarity and knowledge representation , latent semantic analysis ( LS ... \" .How do people know as much as they do with as little information as they get ?", "label": "", "metadata": {}, "score": "60.060883"}
{"text": "Queries are similarly processed and searching is performed by matching the conceptual representations .SUMMARY OF THE INVENTION .A multilingual resource is any system which is capable of converting a term ( word or collocation ) in the source language into one or more equivalent terms in the target language .", "label": "", "metadata": {}, "score": "60.06349"}
{"text": "In the k - means clustering algorithm , k is fine - tuned to 1000 to achieve proper granity and the frequency distributions of C FDCC are mapped to each class in C2 of the two - level collocation net using cross- validation in this paper .", "label": "", "metadata": {}, "score": "60.18741"}
{"text": "The algorithm achieves an average accuracy of 74 % when evaluated on 410 reviews from Epinions , sampled from four different domains ( reviews of automobiles , banks , movies , and travel destinations ) .The accuracy ranges from 84 % for automobile reviews to 66 % for movie reviews . .", "label": "", "metadata": {}, "score": "60.295357"}
{"text": "An assumed correct rate in each , position in the neighborhood was given .For example , the top choice might be 80 % correct , the second choice 10 % correct , and so on .The noise model was applied to the text by calling a uniform random number generator for each word in the passage and scaling the result between zero and one .", "label": "", "metadata": {}, "score": "60.329617"}
{"text": "Table 5 .Application of the collocation net in parse tree re - ranking .P(%)R(%)F1 Before re - ranking After re - ranking 88.26 90.12 88.05 89.98 88.15 90.06 6 .Conclusion This paper proposes a novel structure of two - level collocation net and a method capable of automatically building the collocation net given a large raw corpus .", "label": "", "metadata": {}, "score": "60.417976"}
{"text": "These methods can extract linguistic related word collocations from the parsed trees and can differentiate between different types of linguistic relations .Normally these 00166 . indd 311/29/2007 2:52:45 PM .Page 4 . 4 Guodong Zhou et al . 1stReading methods are combined with the frequency - based method to reject the ones whose frequencies are below the predefined threshold [ 16].", "label": "", "metadata": {}, "score": "60.444702"}
{"text": "Compounds form a bridge between collocations and idioms as they are quite invariable but need not be semantically opaque .Flexible Word Pairs : Flexible word pairs include collocations between subject and verb , or verb and object .Any number of intervening words may occur between the words of the collocation .", "label": "", "metadata": {}, "score": "60.49579"}
{"text": "As an alternative , some critics of the Katz - Fodor theory ( e.g. ( Johnson - Laird , 1983 ) ) have abandoned the treatment of selectional constraints as semantic , instead treating them as indistinguishable from inferences made on the basis of factual knowledge .", "label": "", "metadata": {}, "score": "60.52228"}
{"text": "In contrast , Contextual Theory of Meaning that follows Firth , Halliday and Sinclair , emphasizes the importance of context : the context of social setting , the context of discourse and the context of surrounding words .Such detailed contextual information easily gets lost in structural linguistics .", "label": "", "metadata": {}, "score": "60.54879"}
{"text": "Thus , a searcher who is unfamiliar with the target language can determine with higher precision whether identified target language documents are indeed relevant to the query .The efficacy of cross - linguistic retrieval may therefore be substantially improved irrespective of whether a searcher is familiar with the target language .", "label": "", "metadata": {}, "score": "60.571022"}
{"text": "For example , where the multilingual resource is a bilingual dictionary , this default translation may be the preferred translation obtained from the dictionary .Where information has been obtained on the frequency of occurrence of a term , for example by analysing a large number of documents , the most common term may be selected as the default translation .", "label": "", "metadata": {}, "score": "60.59581"}
{"text": "This can be easily done through computing the EAMI and EPMI of all the collocation candidates extracted from the corpus , as described in Section 3 .Then all the collocation candidates whose EPMIs are larger than a threshold ( e.g. 0 ) are kept as collocations and sorted according to their EPMIs .", "label": "", "metadata": {}, "score": "60.611282"}
{"text": "Thus , when more than 90 % of the phrases are concentrated in a single pattern , it is classified as a fixed adjective - noun ( or noun - noun ) phrase .Otherwise , it is classified as a noun - verb ( or verb - noun ) thematic relation .", "label": "", "metadata": {}, "score": "60.68399"}
{"text": "A method for performing thematic part - of - speech tagging for collocations having content - word pairs in a natural language text processing system comprising the steps of : . identifying collocations of content - word pairs in a large corpus of text ; . calculating , for each of said collocation content - word pair identified , a variability factor which is a measure of variability of said collocation content - word pairs occurring in said text ; . storing said collocation content word pairs and associated variability factors in a collocation database ; and .", "label": "", "metadata": {}, "score": "60.777355"}
{"text": "The collocates are listed in descending order of significance .Let us work through some example data ( taken from a 20 m word corpus ) for the word \" post \" .It co - occurs with many words , among which are \" the \" , \" office \" and \" mortem \" .", "label": "", "metadata": {}, "score": "60.937862"}
{"text": "Thus , in practice , the number of iterations should be controlled by an estimate of the overall error rate in word recognition .If low confidences have been assigned to many words in a text passage , then this should indicate that the relaxation should be iterated until the order of the decisions in the neighborhoods ceases to change .", "label": "", "metadata": {}, "score": "60.965797"}
{"text": "The possibility to analyse vast amounts of linguistic data has brought about changes both in methodology as well as in the ways we perceive certain language phenomena .A key insight gained by computational methods in language analysis is undoubtedly the importance of lexical co - occurrence and usage ... \" .", "label": "", "metadata": {}, "score": "61.00673"}
{"text": "The at least part of each document may comprise a sentence containing terms which match the query in the target language .The multilingual resource may be a bilingual glosser .The glosser may be arranged to identify and translate each term of the source language query .", "label": "", "metadata": {}, "score": "61.17222"}
{"text": "Given the extra information available , this is not the desired behaviour .Using the extra information , the results are re - ranked based on the likelihood of the translation alternatives .In the simplest case , for example , the formula : \" number of occurrences of the terms in the document \" times \" likelihood of the term \" may be applied .", "label": "", "metadata": {}, "score": "61.33994"}
{"text": "16 ] J. Yang , Towards the automatic acquisition of lexical selection rules , MT Summit VII , Singapore , 1999 , pp .397 - 403 .[17 ] D. Yuret , Discovery of linguistic relations using lexical attraction , Ph .", "label": "", "metadata": {}, "score": "61.619728"}
{"text": "We use examples to show that our system discovers many inference rules easily missed by humans . ... unable to tell which SlotX filler occurred with which SlotY filler in the corpus .Mutual i .. \" ...A method of determining the similarity of nouns on the basis of a metric derived from the distribution of subject , verb and object in a large text corpus is described .", "label": "", "metadata": {}, "score": "61.62796"}
{"text": "The top three recognition choices are shown in each position .These three choices are the neighborhood for each word position .Only two of the seven words are correct in the first choice .After one iteration , six of the seven are correct and after two iterations all seven word decisions are correct .", "label": "", "metadata": {}, "score": "61.77133"}
{"text": "claim 4 , wherein the glosser identifies and translates terms which are collocations but does not translate the individual words of the collocations .A method according to .claim 4 , wherein , for each term having more than one translation , the glosser supplies more than one of the translations .", "label": "", "metadata": {}, "score": "61.958603"}
{"text": "[20 ] G. D. Zhou and K. T. Lua , Interpolation of N - gram and MI - based trigger pair language modeling in mandarin speech recognition , Computer , Speech and Language , 13(2 ) , 1999 , 123 - 135 . indd 1611/29/2007 2:52:48 PM .", "label": "", "metadata": {}, "score": "61.97343"}
{"text": "Also , many of the cases that were correct on the first iteration but that were placed in a lower position in the neighborhood on a subsequent iteration were short words such as \" one \" that were confused with function words such as \" the \" .", "label": "", "metadata": {}, "score": "61.984215"}
{"text": "In this dissertation , I suggest that an answer to this question lies in the representation of conceptual . ... act useful relationships between words . by Peter D. Turney , Michael L. Littman - ACM Transactions on Information Systems , 2003 . \" ...", "label": "", "metadata": {}, "score": "62.095203"}
{"text": "The source and target languages are preferably natural languages .The multilingual resource may be a bilingual glosser .The glosser may identify and translate each term of the source language query .The glosser may identify and translate terms which are collocations but may not translate the individual words of the collocations .", "label": "", "metadata": {}, "score": "62.16475"}
{"text": "A \" glosser \" enables an ( ordered ) plurality of source language words ( or collocations ) to be labelled with target language translations .Another disadvantage of known arrangements of the type described hereinbefore is that identified documents are presented to the searcher in the target language .", "label": "", "metadata": {}, "score": "62.19169"}
{"text": "821 - 826 , 1992 .The neighborhoods for each dictionary word were then calculated by computing the Euclidean distance between its feature vector and the feature vectors of all the other dictionary words and sorting the result .The ten words with the smallest distance values were stored with each dictionary word as its neighborhood .", "label": "", "metadata": {}, "score": "62.29729"}
{"text": "An apparatus according to . claim 11 , wherein the multilingual resource is a bilingual glosser .An apparatus according to . claim 13 , wherein the glosser is arranged to identify and translate each term of the source language query .", "label": "", "metadata": {}, "score": "62.425156"}
{"text": "In order to search documents in a different \" target \" language from the \" source \" language of the query , the dictionary - based approach looks up the query terms in a bilingual dictionary .All possible translations of each source language query term are used to form a query in the target language and the matching process is then performed in the target language .", "label": "", "metadata": {}, "score": "62.693832"}
{"text": "A method according to . claim 1 , wherein the source and target languages are natural languages .A method according to . claim 1 , wherein the multilingual resource is a bilingual glosser .A method according to .claim 3 , wherein the glosser identifies and translates each term of the source language query .", "label": "", "metadata": {}, "score": "62.861713"}
{"text": "68 - 73 .[ 10 ] C. D. Manning and H. Schutze , Foundations of Statistical Natural Language Processing , MIT Press , 1999 , p. 185 . indd 1511/29/2007 2:52:48 PM .Page 16 .16 Guodong Zhou et al . 1st", "label": "", "metadata": {}, "score": "63.23851"}
{"text": "In contrast , VF ( joint - venture ) is 1.00 .A list of the first 38 content - word pairs encountered in a test corpus is shown below .The frequency of each collocation P in the corpus relative to its stem frequency is shown .", "label": "", "metadata": {}, "score": "63.471893"}
{"text": "An example class ( \" finance / tax \" ) in the 2nd level of the collocation net . indd 13 11/29/2007 2:52:47 PM .Page 14 .14 Guodong Zhou et al . 1stReading Figure 1 compares the effect of different a 's in full parsing re - ranking .", "label": "", "metadata": {}, "score": "63.767857"}
{"text": "Collocate is a software program that can be used to identify or extract collocations , or terms , from a text or corpus .Collocations ( chunks , lexical bundles , prefabs etc . ) can not be precisely defined , but Collocate uses statistical analyses ( t - score , log likelihood , MI ) as well as frequency information in order to present a list of candidate collocations for inspection .", "label": "", "metadata": {}, "score": "63.796394"}
{"text": "The apparatus of claim 5 wherein the collocation score for each word candidate is computed by the following expression : # # EQU5 # # is the probabilistic score of the word candidate \u03c9 ij at time k+1 and n are the number of neighbors in a neighborhood .", "label": "", "metadata": {}, "score": "63.906036"}
{"text": "Building a Collocation Net Given a large raw corpus and a general - purpose full parser , a collocation net can be built iteratively as follows : ( 1 ) Parse all the sentences in the large raw corpus into parsed trees using a general - purpose full parser .", "label": "", "metadata": {}, "score": "64.09878"}
{"text": "Existing statistical taggers which rely on bigrams or trigram , but which do not employ thematic analysis of individual collocations fare poorly on this linguistic aspect .A database of collocations must be put in place in order to perform thematic analysis .", "label": "", "metadata": {}, "score": "64.55153"}
{"text": "Repeated applications of expression 2.0 effectively propagates results across a sentence .The process may require several iterations to converge on a stable state from which further iterations cause no significant changes in the rankings .Table 1 shows an example of how the process operates .", "label": "", "metadata": {}, "score": "64.58579"}
{"text": "But just selecting the most frequently occurring bigrams ( sequence of two adjacent words ) does not always yield the better results .Following are a few bigrams resulted from an experiment . of the in the to the as a has been New York is a for a .", "label": "", "metadata": {}, "score": "64.77356"}
{"text": "Accordingly , the method and the apparatus uses neighborhoods that comprise the top ranked choices for adjacent word candidates .Having summarized the invention , those skilled in the art are referred to the following detailed description of drawings .DRAWINGS .", "label": "", "metadata": {}, "score": "64.975464"}
{"text": "In contrast , systems using more rare terminology may be punished more heavily for mistakes in the translation process because the rarity of a resulting term may mean that it is given greater importance in the retrieval system and thus can contribute more potentially irrelevant documents to the result .", "label": "", "metadata": {}, "score": "65.2654"}
{"text": "This is true in general : ordering collocates by j(x ) simply places words like \" the \" , \" a \" , \" of \" , \" to \" at the top of every collocate list .What we would like to know is .", "label": "", "metadata": {}, "score": "65.35481"}
{"text": "Experimentation is given in Section 5 .Finally , some conclusions are drawn in Section 6 . indd 411/29/2007 2:52:45 PM .Page 5 .Building a Collocation Net 5 1stReading 2 .Collocation Net The collocation net is a kind of two - level structure , which stores rich information about the collocation candidates and others extracted from the linguistic analysis of a large raw corpus .", "label": "", "metadata": {}, "score": "65.387886"}
{"text": "For each term having more than one translation , the glosser may be arranged to supply more than one of the translations .The query forming means may be arranged to include in the target language query at least some of any terms in the source language query which can not be converted into the target language by the multilingual resource .", "label": "", "metadata": {}, "score": "65.50216"}
{"text": "Each word is associated with candidate parts of speech , and almost all words . are ambiguous .The tagger 's task is to resolve the ambiguity .A program can bring to bear 3 types of clues in resolving part - of - speech ambiguity .", "label": "", "metadata": {}, "score": "65.510666"}
{"text": "So too , ... \" .There are a number of coUocational constraints in natural languages that ought to play a more important role in natural language parsers .Thus , for example , it is hard for most parsers to take advantage of the fact that wine is typically drunk , produced , and sold , but ( probably ) not pruned .", "label": "", "metadata": {}, "score": "65.553894"}
{"text": "The focus of the present invention is on how to exploit the preferences encountered in corpus analysis using thematic analysis ( analysis of word relationships ) .Referring now to FIG .1 , there is shown a corpus of text 112 to be used for training .", "label": "", "metadata": {}, "score": "65.76373"}
{"text": "Extraction of collocations from the corpus as a whole ( using thresholds and either mutual information or the cost criterion ) .This text analysis software is easy to use and the statistics within the program are there simply to provide the user with different view of the corpus data .", "label": "", "metadata": {}, "score": "65.77275"}
{"text": "3 , a first step in the relaxation process is to read in word images and neighborhoods that have been computed from the text image by the computer 20 .Such input is well known in the art .A second step either prior or coincidental or subsequent to the first step is to read in word collocation data from a precompiled passage of ASCII coded text .", "label": "", "metadata": {}, "score": "65.81065"}
{"text": "Such terms may then be used in the target language query so that either : only documents containing such terms are retrieved ; or documents containing such terms and documents not containing such terms but fulfilling other search criteria are retrieved .", "label": "", "metadata": {}, "score": "65.95349"}
{"text": "Such a processor is trained to exploit properties of the corpus itself , highlights regularities , identifies thematic relations , and in general , feeds digested text into the unification parser .Consider the following WSJ , ( Aug. 19 , 1987 ) paragraph processed by a preprocessor : .", "label": "", "metadata": {}, "score": "66.498215"}
{"text": "I can assure you it will be a small number !It is : .Now you 'll see that even if \" egregious \" occurs just once in the vicinity of \" post \" the observed j(egregious ) will be 323 times more than the expected joint frequency , and the mutual information value will be high .", "label": "", "metadata": {}, "score": "66.82031"}
{"text": "Experiments were conducted to determine the performance of the proposed algorithm .The data used in the experiments were generated from the Brown Corpus and Penn Treebank databases .These corpora together contain over four million words of running text .The Brown corpus is divided into 500 samples of approximately 2000 words each . H. Kucera and W. N. Francis , Computational Analysis of Preset - day American English , Brown University Press , 1967 .", "label": "", "metadata": {}, "score": "66.83157"}
{"text": "The second is interference between coinciding collocations such as : market - experience and marketing - experience , or ship - agent and shipping - agent .Fortunately , these cases are very infrequent .Adjectives and nouns are difficult to distinguish in raw corpus ( unless they are marked as such lexically ) .", "label": "", "metadata": {}, "score": "67.09128"}
{"text": "This article introduces a method for inferring the semantic orientation of a word from its statistical association with a set of positive and negative paradigm words .Two instances of this approach are evaluated , based on two different statistical measures of word association : pointwise mutual information ( PMI ) and latent semantic analysis ( LSA ) .", "label": "", "metadata": {}, "score": "67.16243"}
{"text": "Page 6 . 6 Guodong Zhou et al . 1stReading related to Chi .That is , each word and feature bigram or class in the collocation net is represented by the distribution of its related collocation candidates .In this way , all the information extracted via the linguistic analysis is stored in the collocation net .", "label": "", "metadata": {}, "score": "67.35113"}
{"text": "In operating the relaxation process , the collocation score for each word candidate is computed by adding the probability of correctness of the word candidate to the products of the collocation data of each candidate and its top choice neighbors and probability of correctness for each top choice neighbor .", "label": "", "metadata": {}, "score": "67.35509"}
{"text": "In most cases the majority of the improvement in performance is obtained after three iterations .A drop in performance can be observed after the first iteration in cases where the initial correct rate is high .For example , when the first word has a 94 % correct rate , at the first iteration it is improved to 95 % and then it drops to 86 % after ten iterations .", "label": "", "metadata": {}, "score": "67.532364"}
{"text": "For example , the scanner may employ a charge coupled device ( CCD ) imager having an army of CCD cells of as many as one million or more .Such imagers are exposed , usually via a lens , to the entire document .", "label": "", "metadata": {}, "score": "67.64914"}
{"text": "Experimentation shows that the collocation net is efficient and effective in solving the data sparseness problem and determining the collocation relationship between any two words .Keywords : Collocation net ; Data sparseness problem ; Clustering .Introduction In any natural language , there always exist many highly associated relationships between words .", "label": "", "metadata": {}, "score": "67.67049"}
{"text": "A new general theory of acquired similarity and knowledge representation , latent semantic analysis ( LSA ) , is presented and used to successfully simulate such learning and several other psycholinguistic phenomena .By inducing global knowledge indirectly from local co - occurrence data in a large body of representative text , LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren .", "label": "", "metadata": {}, "score": "67.90515"}
{"text": "In this paper , a collocation candidate is represented as a 3tuple : a left side , a right side and a collocation relation type , which represents the collocation relationship between the left side and the right side .Both the left and right sides can be either a word and feature bigram or a class of word and feature bigrams . is the number of the collocation relation types in CR .", "label": "", "metadata": {}, "score": "68.23869"}
{"text": "Mutual Information Church and Hanks ( 1989 ) discussed the use of the mutual information statistic in order to identify a . ... forth .On the other hand , we find bank co - occurring with river , swim , boat , east ( and of course West and South , which have acquired special meanings of their own ) , on top of the , and of the Rhine .", "label": "", "metadata": {}, "score": "68.815704"}
{"text": "Page 9 .For example , parse tree re - ranking can be performed by considering the EPMI of the included collocation candidates in parse trees .Collocation relationship between any two words Given any two words wi and wj , the EPMI and EAMI between them are defined as the EPMI and EAMI of the optimal collocation candidate related to the two words .", "label": "", "metadata": {}, "score": "68.84117"}
{"text": "For example , the statement \" The number two is blue \" may be syntactically well formed , but at some level it is anomalous - BLUE is not a predicate that can be applied to numbers .According to the influential theory of ( Katz and Fodor , 1964 ) , a predicate associates a set of defining features with each argument , expressed within a restricted semantic vocabulary .", "label": "", "metadata": {}, "score": "68.9001"}
{"text": "Checking for the noun - verb case is symmetrical ( in step 2 .b ) .The threshold is different for each suffix and should be determined experimentally ( initial threshold can be taken as 0.75 .Notice that local - context rules override corpus preference .", "label": "", "metadata": {}, "score": "68.91868"}
{"text": "Upon completion of thematic analysis tagging , the text is in condition to be passed to parser 130 which performs parsing on the tagged text .The algorithm yields incorrect results in two problematic cases .The first is ambiguous thematic relations which are collocations that entertain both subject - verb and verb - object relations , i.e. , selling - companies ( as in \" the company sold its subsidiary . . .", "label": "", "metadata": {}, "score": "69.00102"}
{"text": "However , in 3 experiments , the authors show priming effects that free - association production probabilities can not easily predict .Instead , they argue that amount of priming depends on the familiarity of the prime and target as a compound , where the compound is formed by the simultaneous presence of the prime and target in short - term memory as a test item .", "label": "", "metadata": {}, "score": "69.00913"}
{"text": "TS compares favorably with the other methods with up to 50 % vocabulary redu ... . ... mputations has a time complexity of O(V m ) .If one considers the twoway contingency table of a term t and a category c , where A is the number of times t and c co - occur , B is the number of time the t occurs without c , C is number of times c oc ... . \" ...", "label": "", "metadata": {}, "score": "69.25523"}
{"text": "Use of only the preferred translation of each query term solves the problem of large numbers of documents .However , known machine translation systems are of limited accuracy and would frequently select an inappropriate translation as the preferred translation .Thus , whenever the translation system selects the wrong translation , the information retrieval system is not very likely to identify documents which are relevant to the subject matter which is sought .", "label": "", "metadata": {}, "score": "69.55697"}
{"text": "Collocate 1.0 allows the user to find collocates , collocations and n - grams in a corpus in several different ways .The Extract command allows the user to enter a word ( or phrase ) and specify a span ( e.g. , 2 words ) , as shown above .", "label": "", "metadata": {}, "score": "69.563446"}
{"text": "It shows that collocations play a key role in understanding sentences .Collocations are recursive so collocational phrase may contain more than two words .Types of Collocations .Grammatical Collocations : Contain prepositions , including paired syntactic categories , such as verb+preposition ( e.g come to , put on ) , adjective+preposition ( e.g. afraid that , fond of ) , and noun+preposition ( e.g by accident , witness to ) .", "label": "", "metadata": {}, "score": "69.57648"}
{"text": "IMPORTANT QUESTION : to what extent does the word \" post \" condition its lexical environment by selecting particular words with which it will co - occur ?We can compare the relative frequencies of what we observed with what we would expect under the null hypothesis : . which is .", "label": "", "metadata": {}, "score": "69.605995"}
{"text": "The technique we propose first identifies a set of collocations in one language and then attempts to translate them using the Hansards as waining data .To do this , we propose to use Xlract , a collocation compiler [ Smadja 92 ] , to identify collocations and to use mutual information statistics to Iranslate the collocations into the other language .", "label": "", "metadata": {}, "score": "70.088264"}
{"text": "Collocations are important for a number of applications : natural language generation , computational lexicography , parsing , proper noun discovery , corpus linguistic research , machine translation , information retrieval , etc .As an example , [ 7 ] showed how syntactic related collocation statistics can be used to improve the performance of the parser on sentences such as \" She wanted / placed / put the dress on the rack . \" , where lexical preferences are crucial to resolving the ambiguity of prepositional phrase attachment .", "label": "", "metadata": {}, "score": "70.10845"}
{"text": "BACKGROUND OF THE INVENTION .Sentences in a typical newspaper story include idioms , ellipses , and ungrammatical constructs .Since authentic language defies text - book grammar , the basic parsing paradigm must be tuned to the nature of the text under analysis .", "label": "", "metadata": {}, "score": "70.23652"}
{"text": "We will study more possibilities in the near future .indd 611/29/2007 2:52:46 PM .Page 7 .Building a Collocation Net 7 1stReading 3.1 .EAMI : Estimated Average Mutual Information Traditionally in information theory , average mutual information ( AMI ) measures the co - occurrence relationship between two words as follows : .", "label": "", "metadata": {}, "score": "70.261604"}
{"text": "A step 25 increments the parameter \" element \" by one and the steps 23 to 25 are repeated until all of the query terms have been translated .A step 26 sets a parameter i to a value of one and a step 27 tests whether i is less than or equal to N. If so , a step 28 sorts the target language translations stored in the set T i according to priority information obtained during the look up process performed in the step 24 .", "label": "", "metadata": {}, "score": "70.274155"}
{"text": "In order to search for documents containing information of relevance to a chosen topic , a query is formulated by the searcher .A typical query comprises a short item of text , such as a sentence , which indicates the subject matter to be located .", "label": "", "metadata": {}, "score": "70.38643"}
{"text": "However , where the set T i contains more than one possible translation , the translations are sorted in order of the likelihood of being correct .The parameter i is incremented by one in the step 29 and the steps 27 to 29 are repeated until all of the target language translations of the input source language query terms have been sorted .", "label": "", "metadata": {}, "score": "70.42401"}
{"text": "Similarly to AMI , the problem with the above equation is that it only works on frequently occurring word and feature bigrams .In order to resolve this problem , we also propose a modified version of PMI , called estimated pair - wise mutual information ( EPMI ) , to calculate the information change of a collocation candidate when one or two word and feature bigrams do not occur frequently .", "label": "", "metadata": {}, "score": "71.0186"}
{"text": "We will discuss this in more detail in Section 3 .Moreover , we also extend the EPMI and EAMI to determine and measure the collocation relationship between any two words .In this way , we can not only determine the most possible collocation relationship between any two words but also measure the strength of the collocation relationship between them .", "label": "", "metadata": {}, "score": "71.02374"}
{"text": "Description .BACKGROUND .This invention relates in general to a word recognition apparatus and method , and in particular , to a word recognition method an apparatus for recognizing one word in the context of adjacent words .The recognition of images of words of text is a difficult problem , especially when the image texts are degraded by noise such as that introduced by photocopying or facsimile transmission .", "label": "", "metadata": {}, "score": "71.26601"}
{"text": "Notice that fixed collocations are easily distinguishable from thematic relations .The smallest VF of a fixed collocation has a VF of 0.86 ( finance specialist ) ; the largest VF of a thematic relation is 0.56 ( produce concrete ) .", "label": "", "metadata": {}, "score": "71.3772"}
{"text": "These techniques have been implemented and resulted in a lexicographic tool , Xtract .The techniques are described and some results are presented on a 10 million - word corpus of stock market news reports .A lexicographic evaluation of Xtract as a collocation retrieval tool has been made , and the estimated precision of Xtract is 80 % . .", "label": "", "metadata": {}, "score": "71.40741"}
{"text": "According to a third aspect of the invention , there is provided a storage medium characterised by containing a program for controlling a data processor of such an apparatus .The glosser is preferably of the type disclosed in EP 0 813 160 and GB 2 314 183 , the contents of which are incorporated herein by reference .", "label": "", "metadata": {}, "score": "71.427444"}
{"text": "The computer segments the input pixel data signals into words , each word corresponding to a number of spatially related pixel data and compares the pixel data signals to data stored in its databases .The computer identifies candidates for word recognition based upon the likelihood that one or more word candidates stored in the databases is the correct word .", "label": "", "metadata": {}, "score": "71.57768"}
{"text": "In general , the comparison of observed j(x ) and expected j(x ) will be very unreliable when values of j(x ) are low ; this is common sense , too .Now here comes T - score .We can calculate a second - order statistic which is , crudely , this : . ------------------------------------------------------------------------", "label": "", "metadata": {}, "score": "71.64386"}
{"text": "The method of claim 1 wherein the collocation score : # # EQU4 # # is the probabilistic score of the word candidate \u03c9 ij at time k+1 and n are the number of neighbors in a neighborhood .The method of claim 1 wherein the collocation score includes a plurality of products of collocations between the word candidates and the top choices of two or more neighborhoods .", "label": "", "metadata": {}, "score": "71.752884"}
{"text": "We can improve these results by using heuristic : pass through the candidate phrases through a part - of - speech filter which only allows those patterns that are likely to be phrases .Juteson and Katz have introduced a part - of - speech filter that uses the patterns adjective - noun , noun - noun , etc to decide which pattern should be allowed to let through .", "label": "", "metadata": {}, "score": "71.79097"}
{"text": "This technique allows a collocation containing n words to be translated into a collocation of p words .The paper describes the proposed algorithm and shows how it is applied in the translation of the following three collocations : \" senior citizen , \" \" Madam Speaker , \" and \" election campaign .", "label": "", "metadata": {}, "score": "71.9097"}
{"text": "4 .The average correct rate at the top choice across all the passages tested is given for ten iterations of relaxation .Table 7 and FIG .5 shows the results obtained when the test passages are included in the training data .", "label": "", "metadata": {}, "score": "71.92515"}
{"text": "The initial score .P.sub .( \u03c9ij ) .sup .( 0 ) is the confidence ( between 0 and 1 ) provided by a word recognizer for the word candidate \u03c9 ij .The compatibility functions r.sub .( \u03c9i-1,1,\u03c9ij ) and r.sub .", "label": "", "metadata": {}, "score": "71.937065"}
{"text": "2 illustrates a method of retrieving information which may be performed by the apparatus shown in FIG .1 .A source language query , for example in English , is formulated at 11 , for instance , by being entered on a keyboard of the input interface 3 .", "label": "", "metadata": {}, "score": "71.96252"}
{"text": "This variability factor is a measure of the variability of the form that the particular word pair takes in the training text .A database of all of the content - word pairs and their associated variability factors is created for use by a program which performs tagging of a body of text .", "label": "", "metadata": {}, "score": "72.04982"}
{"text": "If no , re - build the collocation net by adjusting the probability of each PTH and going to Step ( 2 ) .( 13 ) dIn this paper , the threshold for the average probability ratio is set to 0.99 . indd 1011/29/2007 2:52:47 PM .", "label": "", "metadata": {}, "score": "72.250946"}
{"text": "The output you see will be in four columns .The first column lists each collocate .The second column shows the total independent frequency of that collocate in the corpus .The third column shows the frequency with which the node and the collocate appear together ( i.e. withing the specified span ) in the corpus .", "label": "", "metadata": {}, "score": "72.55263"}
{"text": "T. Hong & J. J. Hull , Text Recognition Enhancement With A Probabilistic Lattice Chart Parser , In Proceedings Of The Second International Conference On Document Analysis ( ICDAR93 ) , pp .222 225 , Oct. 1993 , Japan .", "label": "", "metadata": {}, "score": "72.67601"}
{"text": "The target language query may include at least some of any terms in the source language query which can not be converted into the target language by the multilingual resource .The at least part of each document may comprise a title of the document .", "label": "", "metadata": {}, "score": "72.67895"}
{"text": "T - score answers this question .It takes account of the size of j(x ) and weights its value accordingly .A high T - score says : it is safe ( very safe / pretty safe / extremely secure etc according to value ) to claim that there is some non - random association between these two words .", "label": "", "metadata": {}, "score": "72.692955"}
{"text": "The Japanese Ministry of Education includes a pr ... \" .There is broad agreement among scholars that EFL learners require the most common words of English as the basis for a usable competence and that evidence of large corpora of English texts can identify the most common words and their meanings and uses .", "label": "", "metadata": {}, "score": "72.78288"}
{"text": "Each class in both levels is represented by its collocation candidate distribution , extracted from the linguistic analysis of the raw training corpus , over possible collocation relation types .In this way , all the information extracted from the linguistic analysis is kept in the collocation net .", "label": "", "metadata": {}, "score": "72.95777"}
{"text": "The relaxation process would then be applied to the other words in the text .Since these will be the information - bearing words , the relaxation approach will be more likely to perform correctly .TABLE 6__________________________________________________________________________Correct rate at each iteration of relaxationInitial Iter . 1 Iter . 2 Iter . 3 Iter .", "label": "", "metadata": {}, "score": "73.52057"}
{"text": "Table 4 shows an example class \" finance / tax \" in the second level of the collocation net .In order to further evaluate the usefulness of the collocation net , we have used it in full parsing re - ranking using the standard PARSEVAL metrics .", "label": "", "metadata": {}, "score": "73.52511"}
{"text": "It is based on searching by character strings for useful documents or files and selecting the most appropriate translation environment ( such as a glosser or machine translation system ) for located documents on the basis of the character string .Any translation which occurs is performed exclusively on located documents by the most appropriate translation environment for the subject matter as identified by the character string .", "label": "", "metadata": {}, "score": "73.77063"}
{"text": "1 is a schematic representation of - a word recognition apparatus ; .FIG .2 is a drawing of the obscured text on a document ; .FIG .3 is a flow chart showing the process of operation of the apparatus shown in FIG .", "label": "", "metadata": {}, "score": "73.781364"}
{"text": "Documents containing the terms or logical combinations of the terms of each query are then made available to the apparatus , for instance by down - loading into the memory 5 .In order to provide sufficient memory capacity , the memory 5 may include disc drives of the magnetic or optical storage type .", "label": "", "metadata": {}, "score": "73.92914"}
{"text": "Specifically , the problem of tagging content - word pairs by part - of - speech is solved by using thematic analysis .A technique for injecting corpus - based preference into syntactic text parsing is provided .Specifically , the problem of tagging content - word pairs by part - of - speech is solved by using thematic analysis .", "label": "", "metadata": {}, "score": "73.97289"}
{"text": "Fortunately , only a small percent of the cases ( in newspaper stories ) depend on global reading .The third type of due is corpus analysis and is described in R. Beckwith , \" Wordnet : A Lexical Database Organized in Psycholinguistic Principles \" in Lexical Acquisition : Exploiting On - Line Dictionary to Build a Lexicon , Lawrence Erlbaum Assoc . , 1991 .", "label": "", "metadata": {}, "score": "74.09129"}
{"text": "PMI - IR has been empirically evaluated using 80 synonym test questions from the Test of English as a Foreign Language ( TOEFL ) , obtaining a score of 74 % ( Turney , 2001 ) .For comparison , Latent Semanti ... . \" ...", "label": "", "metadata": {}, "score": "74.25125"}
{"text": "An HTML document is pre processed by placing notional barriers around the HTML codes so as to preserve them .The remaining text and data outside these barriers are then translated to the desired language .Finally , the barriers are removed so that the pages retain their original format or appearance but all relevant text is translated into the desired language .", "label": "", "metadata": {}, "score": "74.29451"}
{"text": "According to spreading activation theories , the amount of activation that spreads between a prime and a target should be a function of the number of mediating links between the prime and ... \" .Spreading activation theories and compound cue theories have both been proposed as accounts of priming phenomena .", "label": "", "metadata": {}, "score": "74.378174"}
{"text": "Hence , further detail regarding the specific code itself has been omitted for the sake of brevity .The information management system 1 is of the type which contains machine - readable documents and which is arranged to access or search for such documents on the basis of queries .", "label": "", "metadata": {}, "score": "74.520996"}
{"text": "N N .Chief .Executive .A N .next . year .A N . real . estate .A N .Where A stands for adjective , N for noun and P for propositon .Note that the bigrams , last week and last year can not be regarded as non - compositional phrases .", "label": "", "metadata": {}, "score": "74.68039"}
{"text": "( b ) scanning the pixel areas with a light source and detecting the intensity of light from each pixel area to generate a plurality of pixel data signals , each pixel data signal being proportional to the intensity of light detected from its corresponding pixel area ; .", "label": "", "metadata": {}, "score": "74.95244"}
{"text": "For example , such terms may be carried over into the target language query only if they are identified as proper names .Thus , terms which are not identified as proper names are rejected and do not form part of the target language query .", "label": "", "metadata": {}, "score": "74.97616"}
{"text": "FIG .3 illustrates part of the method shown in FIG .2 in more detail .The use of the method will be described with reference to a specific but arbitrary source language query in English for accessing documents in Dutch .", "label": "", "metadata": {}, "score": "75.204056"}
{"text": "( Download the Collocate demo .The demo processes data in the same manner as the full version , but the results are limited to the top 5 items .The zip file includes the Collocate manual . )In the following screen shot the results are shown of a search for system ( with a span of 3 ) in a 46-million word corpus .", "label": "", "metadata": {}, "score": "75.22597"}
{"text": "In an alternate embodiment , a single charge coupled device array could instantly image all of the document onto a suitable array .Then the output of the array would be put onto signal line 15 .Either the scanner 12 or the computer 20 is suitably equipped with an A - to - D converter 16 .", "label": "", "metadata": {}, "score": "75.30057"}
{"text": "Once collocation database 116 is in place the actual tagging process may begin .An input device 122 is used for entering text to be tagged .The text is first processed by local context tagger 124 which uses local context rules to tag words .", "label": "", "metadata": {}, "score": "75.31839"}
{"text": "There are two words in between in the third sentence .Moreover the words between cement and relations may vary and the distance between the two words also can vary .But there is a regularity in the patterns so that we can determine that cement is the right verb to use for this situation .", "label": "", "metadata": {}, "score": "75.33664"}
{"text": "We actually observed j(the ) to be 1583 , which is rather higher , and we could simply express the difference as ratio ( of observed to expected joint frequency ) thus : .This is the Mutual Information score and it expresses the extent to which observed frequency of co - occurrence differs from expected ( where we mean \" expected under the null hypothesis \" ) .", "label": "", "metadata": {}, "score": "75.38425"}
{"text": "The invention will be further described , by way of example , with reference to the accompanying drawings , in which : .FIG .1 is a block schematic diagram of an apparatus for retrieving information constituting an embodiment of the invention ; .", "label": "", "metadata": {}, "score": "75.44104"}
{"text": "FIG .4 is a graph showing the correct rates of the subsequent iterations ; and .FIG .5 is similar to FIG .4 and includes test samples not included in FIG .4 ; . DETAILED DESCRIPTION .System Description .", "label": "", "metadata": {}, "score": "75.57825"}
{"text": "Using IG thresholding with a knearest neighbor classifier on the Reuters corpus , removal of up to 98 % removal of unique terms actually yielded an improved classification accuracy ( measured by average precision ) .DF thresholding performed similarly .Indeed we found strong correlations between the DF , IG and CHI values of a term .", "label": "", "metadata": {}, "score": "75.62825"}
{"text": "The changes in ranking of word candidates are compared .When the number of changes in a neighborhood is less than a predetermined threshold value , the computer displays the likelimost word candidates for the text .As an alternative , the computer may order the likelimost word candidates to be printed on a printer .", "label": "", "metadata": {}, "score": "76.498"}
{"text": "Findings suggest that the textbooks ' variable treatment of word - forms excludes their most Method of and apparatus for retrieving information and storage medium US 6360196 B1 .R\u00e9sum\u00e9 .A method for retrieving information from a plurality of documents in a target language using a query in a source language , including the steps of : . converting the query into the target language using a multilingual resource , . forming a query in the target language from the converted query and additional information on the target language , the additional information on the target language including information indicating a likelihood or probability of a converted query term in the target language being a correctly converted term , .", "label": "", "metadata": {}, "score": "76.50522"}
{"text": "The amount of activation should determine the amount of facilitation given by a prime to a target in lexical decision .To predict the amount of facilitation , it is necessary to measure the associative links between prime and target in memory .", "label": "", "metadata": {}, "score": "76.55411"}
{"text": "A method according to . claim 1 , wherein the at least part of each document comprises a title of the document .A method according to . claim 1 , wherein the at least part of each document comprises an abstract or abridgement of the document .", "label": "", "metadata": {}, "score": "76.76709"}
{"text": "The computer is also connected to a printer 40 .Accordingly , the recognized words may be output as data signals via line 41 to the printer 40 where the words will be printed on a document D1b .The computer 20 may also manipulate the recognized words in accordance with any standard word processing computer application .", "label": "", "metadata": {}, "score": "76.94472"}
{"text": "An apparatus according to . claim 14 , wherein , for each term having more than one translation , the glosser is arranged to supply more than one of the translations .An apparatus according to claims 11 , wherein the query forming means is arranged to include in the target language query at least some of any terms in the source language query which can not be converted into the target language by the multilingual resource .", "label": "", "metadata": {}, "score": "77.00854"}
{"text": "The URL that Gordon and Pam Cain referred to wo n't bring up the bit of text they were hoping to find .But I reproduce it here below in its entirety .It 's very short and it was written off the top of my head as an aid to people who use the CobuildDirect corpus facilities and who used to email me asking \" Er .... what are those MI and t - score numbers that appear on the screen when I ask for collocations ? \"", "label": "", "metadata": {}, "score": "77.164474"}
{"text": "1 , there is shown a word recognition apparatus 10 .A scanner 12 is coupled via a signal line 15 to a computer 20 .Computer 20 has output lines 31 , 41 coupled respectively to output display 30 and printer 40 .", "label": "", "metadata": {}, "score": "77.59801"}
{"text": "The classification of a review is predicted by the average semantic orientation of the phrases in the review that contain adjectives or adverbs .A ... \" .This paper presents a simple unsupervised learning algorithm for classifying reviews as recommended ( thumbs up ) or not recommended ( thumbs down ) .", "label": "", "metadata": {}, "score": "77.65375"}
{"text": "Then the words are available to an operator using keyboard 18 in accordance with the word processing program .The operator may make changes to the text by adding and deleting text or reformatting the words accordance with well known word processing techniques .", "label": "", "metadata": {}, "score": "78.25772"}
{"text": "On both tests , the algorithm obtains a score of 74 % .PMI - IR is contrasted with Latent Semantic Analysis ( LSA ) , which achieves a score of 64 % on the same 80 TOEFL questions .The paper discusses potential applications of the new unsupervised learning algorithm and some implications of the results for LSA and LSI ( Latent Semantic Indexing ) .", "label": "", "metadata": {}, "score": "78.40333"}
{"text": "For example , t - test [ 1 , 3 ] assumes normal distribution and looks at the difference between the observed and expected means , scaled by the variance of the sample data .Chi - square test [ 2 , 15 ] uses n - by - n table to show the dependence of occurrences between words and compares the observed frequencies in the table with the expected frequencies for independence .", "label": "", "metadata": {}, "score": "78.46048"}
{"text": "The information management system 16 performs a matching process .In particular , the system 16 searches the target language documents for matches between the target language query and the text of the documents .Whenever a match is found , the document is down - loaded as a target language result 17 .", "label": "", "metadata": {}, "score": "78.70779"}
{"text": "Abstract : The ideophone , a word class not unique to but highly characteristic of the Bantu languages , presents particular challenges in both monolingual and bilingual lexicography .Not only is this part of speech without a counterpart in most other languages , the meaning of ideophones is highly elusive .", "label": "", "metadata": {}, "score": "78.763504"}
{"text": "One of the main challenges in question - answering is the potential mismatch between the expressions in questions and the expressions in texts .While humans appear to use inference rules such as \" X writes Y \" implies \" X is the author of Y \" in answering questions , such rules are generally unavailable to question - answering systems due to the inherent difficulty in constructing them .", "label": "", "metadata": {}, "score": "78.89489"}
{"text": "Alternatives are related by the Boolean logic OR operator in the query .The query is applied to the target language information management system in a step 31 , which retrieves the search results in the form of documents in the target language .", "label": "", "metadata": {}, "score": "79.105804"}
{"text": "Five articles were randomly selected from the Brown Corpus as test samples .They are A06 , G02 , J42 , N01 and R07 .A06 is a collection of six short articles from the Newark Evening News , GO2 is from an article \" Toward a Concept of National Responsibility \" that appeared in The Yale Review .", "label": "", "metadata": {}, "score": "79.48015"}
{"text": "Page 15 .Building a Collocation Net 15 1stReading ( EPMI ) as the strength degree .Obviously , the two - level collocation net can be easily extended to more levels through cascading such a two - level structure .", "label": "", "metadata": {}, "score": "79.54913"}
{"text": "2 is a flow diagram illustrating a method of retrieving information constituting an embodiment of the invention ; and .FIG .3 is a more detailed flow diagram of a method similar to that illustrated in FIG .2 . DETAILED DESCRIPTION OF THE INVENTION .", "label": "", "metadata": {}, "score": "79.62744"}
{"text": "A typical digital signal may vary over 256 shades of gray ranging from absolute white to pure black .As such , the value associated with any particular pixel area will correspond to the amount of background and text image in the given pixel area .", "label": "", "metadata": {}, "score": "79.85176"}
{"text": "The top choice correct rate when the training data does not include the test passages is between 83 % and 86 % correct .The best performance possible , as shown in Table 7 , raises the correct rate at the top choice to between 91 % and 93 % .", "label": "", "metadata": {}, "score": "80.22551"}
{"text": "( a )If neither collocation is found , then do nothing .( b ) if only affix - stripped collocation is found , or . if VF ( variability factor ) is smaller than threshold , then tag first word a verb and the second word a noun ; .", "label": "", "metadata": {}, "score": "80.246155"}
{"text": "Parser 130 is standard text parsing software which accepts as input the marked up text as processed according to the method just described .If a word pair is a collocation ( e.g. , holding companies ) , and one of the two words is tagged \" ? ? \" then generate the S - stripped version ( i.e. , holding company ) , and the affix - stripped version ( i.e. , hold company ) .", "label": "", "metadata": {}, "score": "80.59104"}
{"text": "While specific embodiments of the invention have been illustrated and described herein , it is realized that modifications and changes will occur to those skilled in the art .It is therefore to be understood that the appended claims are intended to cover all such modifications and changes as fall within the true spirit and scope of the invention .", "label": "", "metadata": {}, "score": "80.71924"}
{"text": "An apparatus for retrieving information from a plurality of documents in a target language using a query in a source language , comprising : . a multilingual resource for converting the query into the target language , . means for applying the query in the target language to an information management system which identifies a plurality of documents in the target language based on the query , . means for using the additional information on the target language to re - rank the plurality of documents identified by the information management system according to a degree of relevance , . wherein the multilingual resource is arranged to convert at least part or all of at least one of the plurality of documents in the target language identified by the information management system into the source language .", "label": "", "metadata": {}, "score": "81.03101"}
{"text": "A program memory 7 in the form of a read only memory ( ROM ) contains a program for controlling operation of the data processor 2 .The apparatus further comprises a document glosser 8 which labels the terms ( words and collocations ) of the source language query with target language translations .", "label": "", "metadata": {}, "score": "81.19058"}
{"text": "The mass storage memory includes a dictionary of words and collocation data regarding the likelihood of one word being adjacent to another .A read only memory includes the operating system and dedicated application programs for the computer .The computer receives as its input a plurality of pixel data signals .", "label": "", "metadata": {}, "score": "81.27767"}
{"text": "Therefore , the new ranking is : .Veiligheid op kantoor : passen en beveiligingsbeambten .Een pas opent alle deuren .Het halen van voldoendes in school : zijn voldoendes echt voldoende ? which is more in line with the information about the likelihoods of the translation alternatives being correct .", "label": "", "metadata": {}, "score": "81.72217"}
{"text": "The light source 14 illuminates the document and a suitable detector such as a charge coupled device , not shown , records the reflection of the light source from the document .In this manner , the scanner 12 outputs signals representative of the varying intensity of the text image on document D1 from left to right and top to bottom as the light source 14 travels over the document D1 .", "label": "", "metadata": {}, "score": "81.79091"}
{"text": "Page 13 .Building a Collocation Net 13 1stReading Section 24 as development data and Section 23 as testing data ) while 20-best parse trees for each sentence are considered in re - ranking .This is done by building a collocation net on the golden parse trees in the training data and adjusting the probability of each parse tree candidate using the collocation net to achieve full parsing re - ranking , same as Equation ( 13 ) applied in Section 4 .", "label": "", "metadata": {}, "score": "81.84981"}
{"text": "For example , the statement \" The number two is blue \" may be syntactically well formed , but at some level it is anomalous - BLUE is not a predicate that can be applied to numbers .According to the influential theo ... \" .", "label": "", "metadata": {}, "score": "81.88779"}
{"text": "A word recognition apparatus comprising : . said computer comparing the light intensity pixel data signals to data signals stored in said memory holding alphanumeric characters and words in order to initially recognize word candidates from said pixel data signals ; . said computer generating a ranking of candidates for each word in proportion to the correspondence between the pixel data signals for a word candidate and the stored word data , each ranking having a top choice indicating the initial most likely correct candidate for the word ; . said computer grouping word candidates into neighborhoods , each neighborhood comprising two or more word candidates and each neighborhood being adjacent at least one other neighborhood ; . said computer reading from the word collocation database word collocation data for each word candidate ; . said arithmetic logic unit computing and storing a collocation score ; . said arithmetic logic unit sorting word candidates by their collocation score ; . said arithmetic logic unit comparing changes between the word candidates of the initial neighborhoods and the word candidates in the sorted neighborhood ; . said arithmetic logic unit counting the number of changes for the neighborhoods ; and . said computer outputting a list of likeliest word candidates when the number of changes is less than a predetermined threshold value .", "label": "", "metadata": {}, "score": "81.93164"}
{"text": "See , e.g. , A. Rosenfeld , R. A. Hummel and S. W. Zucker , \" Scene Labeling by Relaxation Operations , \" in IEEE Trans . on Sys .Man and Cyb , SMC-6(6):420 - 433 , 1976 .SUMMARY .", "label": "", "metadata": {}, "score": "82.17055"}
{"text": "Hillsdale : Lawrence Erlbaum , 1991 .and I routinely get a reply that goes like \" Oh , I ca n't seem to find this paper -- do you know anywhere else I can read up about this MI and t - score stuff ? \"", "label": "", "metadata": {}, "score": "82.173096"}
{"text": "The Full Extract command processes the whole corpus according to the specified parameters and produces a list of collocations .There are two basic commands .An n - gram command creates a bigram ( trigram , n - gram ) list for the corpus , along the lines of a simple word frequency list . \" ...", "label": "", "metadata": {}, "score": "82.32837"}
{"text": "Consider the following 2 cases where local context dominates : . the preferred stock raised .he expressed concern about .The words the and he dictate that preferred and expressed are adjective and verb respectively .This kind of inference , due to its local nature , is captured and propagated by the preprocessor .", "label": "", "metadata": {}, "score": "82.641464"}
{"text": "Also , the number of times a word is collocated only with either the word before .TABLE 2______________________________________Isolated word occurrence in the training datatest no . of no . inarticle words training data______________________________________A06 2213 2137 ( 97%)G02 2267 2201 ( 97%)J42 2269 2208 ( 97%)N01 2313 2271 ( 98%)R07 2340 2262 ( 97 % ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "82.76016"}
{"text": "Mutual Information .By the chain rule for entropy , .Therefore , . where H represents entropy and X and Y are random variables .This difference is called the mutual information between X and Y. It is the amount of information one random variable contains about another .", "label": "", "metadata": {}, "score": "82.78883"}
{"text": "\" N01 is a chapter from the adventure fiction \" The Killer Marshal .\" R07 is from the humor article \" Take It Off \" in The Arizona Quarterly .Each text has about 2000 words .There are totally 10,280 words in the testing samples .", "label": "", "metadata": {}, "score": "82.79985"}
{"text": "In another embodiment of the present invention , a mutual information score is used to control which word pairs occurring in the training text are to be stored in the database .BRIEF DESCRIPTION OF THE DRAWING .The sole FIGURE is a schematic diagram which shows the elements of the present invention .", "label": "", "metadata": {}, "score": "83.531975"}
{"text": "The invention is a word recognition method and apparatus that uses a relaxation - based process so that the results of word collocations reinforce each other in subsequent iterations of the relaxation method .The method is performed with the use of a special or general purpose computer having random access memory for holding input data and computed data .", "label": "", "metadata": {}, "score": "83.80993"}
{"text": "( in English : \" Getting pass marks in school : is a pass really good enough ? \" ) Veiligheid op kantoor : passen en beveiligingsbeambten .Now even though \" passen \" is by far the most likely query term translation , a document containing the least likely one has been ranked highest .", "label": "", "metadata": {}, "score": "83.962204"}
{"text": "Mean and Variance .Collocations are not always of fixed phrases .Consider the following sentences .Obama cemented relations with the East .Jill cemented his relations with Jack .John cemented Mark Taylor 's relations with Tom .While cement and relations occur together frequently cement does not follow relations immediately always .", "label": "", "metadata": {}, "score": "84.28723"}
{"text": "The relaxation process currently works as one part of a degraded text recognition system .There are two types of linguistic constraints used in the system .Visual global contextual information available inside a text page is also being considered for integration with the linguistic knowledge sources to further improve the performance of degraded text recognition .", "label": "", "metadata": {}, "score": "84.40148"}
{"text": "ADJ_ADJ(eligible ) can be measured as a collocation with EAMI of 1.01517e-05 and EPMI of 1.174579 although this collocation candidate does not exist in the corpus .The main reason is that the collocation net provides a word - clustering mechanism to resolve the problem of data sparseness .", "label": "", "metadata": {}, "score": "84.5641"}
{"text": "An apparatus according to . claim 11 , wherein the at least part of each document comprises an abstract or abridgement of the document .An apparatus according to . claim 11 , herein the at least part of each document comprises a sentence containing terms which match the query in the target language .", "label": "", "metadata": {}, "score": "84.92745"}
{"text": "From another perspective , pragmatics turns out to be an effective means of sense discrimination in works of lexical and lexicographic relevance , as will be shown in the continuation . \" ...Abstract : The ideophone , a word class not unique to but highly characteristic of the Bantu languages , presents particular challenges in both monolingual and bilingual lexicography .", "label": "", "metadata": {}, "score": "84.95305"}
{"text": "BUT BUT BUT ! there is Big Problem with Mutual Information : suppose the word \" egregious \" appears just once with \" post \" ( not an unreasonable event ) in the corpus .And \" egregious \" may have a very low overall freq : .", "label": "", "metadata": {}, "score": "84.96256"}
{"text": "Examples of word pairs and their frequencies are shown below ._ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the doctor 64a doctor 27doctor and 8doctor was 8doctor who 7his doctor 6doctor bills 4ward doctor 1 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "85.1987"}
{"text": "A storage medium containing a program for controlling a programmed data processor of an apparatus for retrieving information from a plurality of documents in a target language using a query in a source language , the apparatus comprising : . a multilingual resource for converting the query into the target language , . means for applying the query in the target language to an information management system which identifies a plurality of documents in the target language based on the query , . means for using the additional information on the target language to re - rank the plurality of documents identified by the information management system according to a degree of relevance , . wherein the multilingual resource is arranged to convert at least part or all of at least one of the plurality of documents in the target language identified by the information management system into the source language .", "label": "", "metadata": {}, "score": "85.31708"}
{"text": "( meaning \" untagged \" ) .When local context tagging is completed , the text is next processed by thematic analysis tagger 126 .Thematic analysis tagger 126 uses database 116 to tag the word - pairs left untagged by tagger 124 .", "label": "", "metadata": {}, "score": "85.951065"}
{"text": "Cheers .Jem Clear Electronic Development Director phone : +44 ( 0)121 - 414 - 3926 Collins Dictionaries fax : +44 ( 0)121 - 414 - 6203 Westmere , 50 Edgbaston Park Road email : jem@cobuild.collins.co.uk .The two statistical measures of significance which are used by the collocations feature of the CobuildDirect service are explained below in layman 's terms .", "label": "", "metadata": {}, "score": "86.04658"}
{"text": "[ 18 ] J. Zhao and C. N. Huang , Aquasi - dependency model for the structural analysis of Chinese BaseNPs , COLING - ACL'1998 , University de Montreal , Canada , 1998 , pp . 1 - 7 . [19 ] G. D. Zhou and K. T. Lua , Word association and MI - trigger - based language modeling , COLING - ACL'1998 , University of Montreal , Canada , 1998 , pp .", "label": "", "metadata": {}, "score": "86.30507"}
{"text": "For convenience , each word and feature bigram in the first level is also regarded as a class ( atomic class ) .That is to say , each first level atomic class contains only one bigram while each second level class contains one or more word and feature bigrams clustered from first level atomic classes .", "label": "", "metadata": {}, "score": "86.419846"}
{"text": "An example of the result of such a search is as follows : .Moderne behandelingen voor voetschimmel .Voetschimmel : nieuwe behandelingen voor een oude kwaal .Behandelingen voor aandoeningen van de atleet op basis van nieuwe medische vindingen .A step 32 then processes the search results based on sorting and priority information calculated in the step 28 and a specific example of this is described hereinafter .", "label": "", "metadata": {}, "score": "86.80461"}
{"text": "Although \" strong \" and \" powerful \" have similar syntax and semantics , there exist contexts where one is much more appropriate than the other [ 6].aPart of the work was done when the author was at the Institute for Infocomm Research , Singapore . indd 1 11/29/2007 2:52:45 PM .", "label": "", "metadata": {}, "score": "86.98964"}
{"text": "athlete . foot .athlete 's foot .A step 22 sets a parameter \" element \" to a value of 1 and a parameter N to the cardinality of the set S ie .a value equal to the number of elements of the set S which , in the specific example , is 5 .", "label": "", "metadata": {}, "score": "87.284836"}
{"text": "1 .In the example described hereinafter , the multilingual glosser 12 converts between English and Dutch terms and is of the type disclosed EP 0 813 160 and GB 2 314 183 .The glosser 12 converts the terms of the source language query into target language query terms as indicated at 13 .", "label": "", "metadata": {}, "score": "87.40059"}
{"text": "5 Iter .6 Iter . 7 Iter . 8 Iter . 9 Iter .TABLE 7__________________________________________________________________________Correct rate in relaxation when collocation includes test samplesInitial Iter . 1 Iter . 2 Iter . 3 Iter .4 Iter .5 Iter .", "label": "", "metadata": {}, "score": "87.49352"}
{"text": "Reading For example , we always say \" strong tea \" instead of \" strong computer \" and \" powerful computer \" instead of \" powerful tea \" .Psychological experiments [ 11 ] also indicated that human 's reaction to a highly associated word pair was stronger and faster than that to a poorly associated one .", "label": "", "metadata": {}, "score": "87.7246"}
{"text": "The query formulator 14 detects that there are various possible translations for the remaining terms of the source language query .In particular , the translations for the individual words \" athlete \" and \" foot \" would both have to be present in a relevant document but an alternative to this would be the presence of the translation for the term \" athlete 's foot \" .", "label": "", "metadata": {}, "score": "87.73331"}
{"text": "The target language query terms and the additional information are supplied to a query formulator 14 which converts the terms into a target language query 15 .The query formulator 14 uses the additional information , for instance to ignore each target language query term whose probability of being correct is less than a threshold .", "label": "", "metadata": {}, "score": "88.19336"}
{"text": "The constructs expressed concern and spokesman said must be tagged verb - object and noun - verb respectively .Preferred stock , on the other hand , must be identified and tagged as a fixed adjective - noun construct .The complex scope of the pre - processing task is best illustrated by the input to the preprocessor shown below .", "label": "", "metadata": {}, "score": "88.97548"}
{"text": "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 1 . and expressed / VB concern / NN about2 .", "label": "", "metadata": {}, "score": "89.28439"}
{"text": "The scanner uses a light source to scan the document .The scanner divides the document into two dimensional bit map area of pixel areas .Each pixel area is associated with a corresponding detected intensity of light .These pixel light intensity signals may be analog signals that are subsequently converted into digital signals , each digital signal being represented of the light intensity for a given pixel area .", "label": "", "metadata": {}, "score": "89.28987"}
{"text": "The information management system 16 is , in this example , a Dutch World Wide Web search engine .The source language query is \" treatments for athlete 's foot \" .In a step 21 , the glosser identifies the individual terms of the query , which terms may be words , non - continuous collocations and continuous collocations , and stores these terms in a set S. The specific query is converted into the set of terms : . treatments .", "label": "", "metadata": {}, "score": "89.38318"}
{"text": "Collocational windows are used to capture bigrams at a specific distance .Let us use a three word collocational window for the following sentence .Plane crashed as climate worsened .We get the following bigrams .Plane crashed plane as plane climate . crashed as crashed climate crashed worsened as climate as worsened . climate worsened .", "label": "", "metadata": {}, "score": "89.721985"}
{"text": "1 shows an apparatus for retrieving information using an information management system 1 , such as an Internet search engine .The apparatus is of the programmed data processor type , such as a computer , and comprises a programmable data processor 2 provided with an input interface 3 , such as a keyboard and mouse , and an output interface 4 , such as a display and printer .", "label": "", "metadata": {}, "score": "90.251076"}
{"text": "The company / nn adjourned / vb its annual / jj meeting / nn May 12 to allow / vb time / nn for negotiations and expressed / vb concern / nn ab out future / jj actions / nn by preferred / jj holders / nn .", "label": "", "metadata": {}, "score": "90.705536"}
{"text": "In the case of \" egregious \" we would get a very low t - score .In the case of \" the \" the t - score might be quite high , but not huge because \" the \" does n't have that strong an association with \" post \" . \" office \" gets a really high t - score because not only is the observed j(office ) way higher than expected , but we seen a goodly number of such co - occurrences , enough to be pretty damn sure that this ca n't be due to some freak of chance .", "label": "", "metadata": {}, "score": "91.022095"}
{"text": "A common example of this is where queries contain proper names .For example , it is unlikely that the multilingual resource would be able to translate proper names such as \" Dagmar Dwehus \" .However , such query terms may be very useful in retrieving relevant documents , for example where it is desired to retrieve only documents containing such a proper name .", "label": "", "metadata": {}, "score": "91.07759"}
{"text": "On the other hand , we find bank co - occurring with river , swim , boat , east ( and of course West and South , which have acquired special meanings of their own ) , on top of the , and of the Rhine . ' ' by Gail Mckoon , Roger Ratcliff - Journal of Experimental Psychology : Learning , Memory , and Cognition , 1992 . \" ...", "label": "", "metadata": {}, "score": "92.14615"}
{"text": "To illustrate the processing performed in the step 32 , a source language query \" introducing security passes \" is considered .The Dutch language translations of \" passes \" and their probabilities of being correct are given as : .A query generated from these alternatives ( and of course those of the other terms ) returns the following sets of results : .", "label": "", "metadata": {}, "score": "92.15958"}
{"text": "Positive semantic orientation indicates praise ( e.g. , \" honest \" , \" intrepid \" ) and negative semantic orientation indicates criticism ( e.g. , \" disturbing \" , \" superfluous \" ) .Semantic orientation varies in both direction ( positive or neg ... \" .", "label": "", "metadata": {}, "score": "92.65646"}
{"text": "TECHNICAL FIELD OF THE INVENTION .The present invention relates to a method of and an apparatus for retrieving information .The invention also relates to a storage medium containing a program for performing such a method .These techniques may be used in information management systems , such as information retrieval systems or \" search engines \" , information filtering applications also known as information routing systems , and information extraction applications .", "label": "", "metadata": {}, "score": "92.979065"}
{"text": "Global - sentence constraints are shown by the following two examples : . and preferred stock sold yesterday was . . . .2 .In case 1 , a main verb is found ( i.e. , was ) , and preferred is taken as an adjective ; in case 2 , a main verb is not found , and therefore expressed itself is taken as the main verb .", "label": "", "metadata": {}, "score": "93.1682"}
{"text": "Positive semantic orientation indicates praise ( e.g. , \" honest \" , \" intrepid \" ) and negative semantic orientation indicates criticism ( e.g. , \" disturbing \" , \" superfluous \" ) .Semantic orientation varies in both direction ( positive or negative ) and degree ( mild to strong ) .", "label": "", "metadata": {}, "score": "93.53315"}
{"text": "The output interface 4 may be used for displaying the results of searches and for providing information about operation of the apparatus .The data processor 2 has a \" working memory \" in the form of random access memory ( RAM ) 5 for temporarily storing data during data processing .", "label": "", "metadata": {}, "score": "94.57504"}
{"text": "For example , .He is known for his fair and square dealings and everybody trusts his work .Here fair and square means honest but if we take the individual words though the word fair gives somewhat closer meaning as it means just the word square confuses us .", "label": "", "metadata": {}, "score": "95.21225"}
{"text": "Although the glosser 8 is illustrated as an independent component of the apparatus , it may be embodied by the data processor 2 and the memories 5 to 7 .The program memory 7 contains the aforementioned program which is executed by the data processor 2 and/or the document glosser 8 included therein in order to carry out the various operations described herein .", "label": "", "metadata": {}, "score": "97.42238"}
{"text": "An example of a target language query is as follows : . behandelingen AND voor AND ( voetschimmel OR ( atleet AND ( voet OR basis ) ) ) .The query formulator 14 detects that the source language query terms \" treatments \" and \" for \" have single Dutch translations and must be present in any document of relevance .", "label": "", "metadata": {}, "score": "98.14498"}
{"text": "The input device 18 may be a keyboard or a mouse or both .The computer receives the input pixel data signals and operates on the pixel data signals to recognize the pixels as words .The computer uses a character recognition program to identify individual alphanumeric characters that correspond to the received pixel data signals .", "label": "", "metadata": {}, "score": "99.90082"}
{"text": "The postscript files were then converted into raster images with the ghostscript system .Neighborhoods were generated for each word by first calculating a feature vector for the word known as the stroke direction feature vector in a manner known in the art to which this invention is relevant .", "label": "", "metadata": {}, "score": "101.02026"}
{"text": "Next there will be described typical operation of the word recognition system 10 on a short passage of text .For example , the word recognition system 10 may operate on a document D1 as shown in FIG .2 .The document D 1 contains a poor facsimile of the phrase \" Please show me where Hong Kong is ! \"", "label": "", "metadata": {}, "score": "101.44897"}
{"text": "Thus , the target language search results given hereinbefore are translated by the glosser , which gives the following result : .Modern treatments for athlete 's foot .Athlete 's foot : new treatments for an old problem .Treatments for injuries of athletes based on new medical discoveries .", "label": "", "metadata": {}, "score": "101.964584"}
{"text": "A phrase has a positive semantic orientation when it has good associations ( e.g. , \" subtle nuances \" ) and a negative semantic orientation when it has bad associations ( e.g. , \" very cavalier \" ) .In this paper , the semantic orientation of a phrase is calculated as the mutual information between the given phrase and the word \" excellent \" minus the mutual information between the given phrase and the word \" poor \" .", "label": "", "metadata": {}, "score": "107.85262"}
{"text": "The advance in rank of a given word candidate depends not only upon its own probability , but also upon its collocation with the top choice of its neighbors .TABLE 1______________________________________An example of the relaxation process ( the sentence tobe recognized is \" Please show me where Hong Kong is ! \" position 1 2 3 4 5 6 7 8______________________________________Initial Word Neighborhoodstop1 Places snow me whale Kong Kong it !", "label": "", "metadata": {}, "score": "108.58798"}
{"text": "Here , Chm can be either C1i itself or any class in L2 while Cgn can be either C1j itself or any class in L2 .That is , C1i / C1j can be either mapped to itself when the word and feature bigram occurs frequently or mapped to any class in L2 when the word and feature bigram does not occur frequently .", "label": "", "metadata": {}, "score": "109.04007"}
{"text": "Although carefully collected , accuracy can not be guaranteed .The impact factor represents a rough estimation of the journal 's impact factor and does not reflect the actual current impact factor .Publisher conditions are provided by RoMEO .Differing provisions from the publisher 's actual policy or licence agreement may be applicable .", "label": "", "metadata": {}, "score": "115.853134"}
{"text": "The computer 20 has a central processing unit 21 which includes an arithmetic logic 22 for performing suitable calculations on data .A read only memory 23 stores operations and selected application programs for operating the computer 22 .Random access memory 24 stores input data as well as data arrived from operations performed upon the input data in accordance with the operating program of the computer 20 .", "label": "", "metadata": {}, "score": "118.465866"}
{"text": "top2 Please slow we whale Kong Hong ittop3 Pieces snow mo chore Hung Kung IsWord Neighborhoods After Iteration 2top1Please show me where Hong Kong is !top2 Places slow we whale Kong Hong ittop3 Pieces snow mo chore Hung Kung Is _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ .", "label": "", "metadata": {}, "score": "141.20276"}
