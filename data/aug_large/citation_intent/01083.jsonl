{"text": "The results provide strong support for the combined method and show that trigram LMs are appropriate for phrase linearization while on the clause level a richer representation is necessary to achieve comparable performance . ... ents to achieve the right order ( Kendall , 1938 ; Lapata , 2006 ) .", "label": "", "metadata": {}, "score": "32.172195"}
{"text": "Only then can they deal with such crucial generation issues as sentence planning , linearization and morphologization .Multilevel annotated corpora are increasingly available for multiple languages .We take advantage of them and propose a multilingual deep stochastic sentence realizer that mirrors the state - ofthe - art research in semantic parsing .", "label": "", "metadata": {}, "score": "33.394653"}
{"text": "In ( Chen , 2009 ) , we show that for a variety of language models belonging to the exponential family , the test set cross - entropy of a model can be accurately predicted from its training set cross - entropy and its parameter values .", "label": "", "metadata": {}, "score": "33.515778"}
{"text": "As opposed to past explanations , our interpretation can recover exactly the formulation of interpolated Kneser - Ney , and performs better than interpolated Kneser - Ney when a better inference procedure is used . \" ...In ( Chen , 2009 ) , we show that for a variety of language models belonging to the exponential family , the test set cross - entropy of a model can be accurately predicted from its training set cross - entropy and its parameter values .", "label": "", "metadata": {}, "score": "34.187096"}
{"text": "Our approach predicts liftings of edges in an unordered syntactic tree by means of a classifier , and uses a projective algorithm for tree linearization .We obtain statistically significant ... \" .We propose a technique to generate nonprojective word orders in an efficient statistical linearization system .", "label": "", "metadata": {}, "score": "34.21953"}
{"text": "In this paper we investigate the effects of applying such a technique to higherorder n - gram models trained on large corpora .We introduce a modi ... \" .In statistical language modeling , one technique to reduce the problematic effects of data sparsity is to partition the vocabulary into equivalence classes .", "label": "", "metadata": {}, "score": "34.4877"}
{"text": "However , with a neural network classifier and much higher dimensionality features , all feature sets perform similarly in terms of classification accuracy .As just illustrated , dimensionality reduction is not necessarily advantageous in terms of accuracy for classifiers trained with enough data and the \" right \" classifier .", "label": "", "metadata": {}, "score": "34.722492"}
{"text": "This motivates a Bayesian approach using a sparse prior to bias the estimator toward such a skewed distribution .We also point out the high variance in all of these estimators , and that they require many more iterations to approach conver - gence than usually thought .", "label": "", "metadata": {}, "score": "35.156315"}
{"text": "We use the first heuristic to develop a novel class - based language model that outperforms a baseline word trigram model by 28 % in perplexity and 1.9 % absolute in speech recognition word - error rate on Wall Street Journal data .", "label": "", "metadata": {}, "score": "35.196877"}
{"text": "In this paper we investigate the possibility of evaluating MT quality and fluency at the sentence level in the absence of reference translations .We measure the correlation between automatically - generated scores and human judgments , and we evaluate the performance of our system when used as a classifier for identifying highly dysfluent and illformed sentences .", "label": "", "metadata": {}, "score": "35.410904"}
{"text": "By using PCA projection , the basis of the feature space is orthogonalized .A Bayes classifier uses the transformed feature vectors to classify phoneme exemplars .The results show that the classification accuracy with PCA method surpasses the accuracy using only original features in most cases .", "label": "", "metadata": {}, "score": "35.545094"}
{"text": "Parsing algorithms that process the input from left to right and construct a single derivation have often been considered inadequate for natural language parsing because of the massive ambiguity typically found in natural language grammars .Nevertheless , it has been shown that such algorithms , combined with treebank - induced classifiers , can be used to build highly accurate disambiguating parsers , in particular for dependency - based syntactic representations .", "label": "", "metadata": {}, "score": "35.54862"}
{"text": "Finally , it should be recalled that while we have taken any expression of association for which even a single annotated instance exists as \" known \" , the performance at which many of these association can be extracted in practice may be limited .", "label": "", "metadata": {}, "score": "35.58429"}
{"text": "The LSP classifier successfully compensated for the inherent weakness of CRF , that is , its inability to use global information .Even simple NLP tasks such as tokenizing words and segmenting sentences can have their complexities .Punctuation characters could be used to segment sentences , but this requires the punctuation marks to be treated as separate tokens .", "label": "", "metadata": {}, "score": "35.788437"}
{"text": "The classifier uses linguistic features and has been trained to distinguish human translations from machine translations .We show that this approach also performs well in identifying dysfluent sentences . by Jakob Uszkoreit , Thorsten Brants - In ACL International Conference Proceedings , 2008 . \" ...", "label": "", "metadata": {}, "score": "35.84731"}
{"text": "This paper applies Principal Component Analysis ( PCA ... \" .Although isolated phoneme classification using features from time - domain phase space reconstruction has been investigated recently , the best representation of feature vectors for the discriminability over phoneme classes is still an open question .", "label": "", "metadata": {}, "score": "36.40024"}
{"text": "The approach below is based on the Supervised Classification : Sentence Segmentation example provided by Bird et al in Natural Language Processing with Python ( Chapter 6.2 , pp 233 - 4 ) .Note that the first edition ( print ) has a number of typographic errors in the code sample , so be sure to check the confirmed errata .", "label": "", "metadata": {}, "score": "36.410057"}
{"text": "In addition , we demonstrate that our method also improves performance when small amounts of training data are available , and can roughly halve the amount of supervised data required to reach a desired level of performance .The idea of combining word clusters with discriminative learning has been previously explored by Miller et al .", "label": "", "metadata": {}, "score": "36.700325"}
{"text": "We focus on the problem of lexical representation , introducing features that incorporate word clusters derived from a large unannotated corpus .We demonstrate the effectiveness of the approach in a series of dep ... \" .We present a simple and effective semisupervised method for training dependency parsers .", "label": "", "metadata": {}, "score": "36.939484"}
{"text": "The paper confirms the utility of including language model log probabilities as features in the model , which prior work on discriminative training with log linear models for HPSG realization had called into question .The perceptron model allows the combination of multiple n - gram models to be optimized and then augmented with both syntactic features and discriminative n - gram features .", "label": "", "metadata": {}, "score": "37.12525"}
{"text": "Thus , instead of instance - level extraction performance , we pay particular attention to not introducing overt bias e.g. toward particular forms of expression so as to be able to estimate relative frequencies of the associations in the full corpus .", "label": "", "metadata": {}, "score": "37.130657"}
{"text": "If the data are primarily clustered on curved subspaces embedded in high dimensionality feature spaces , linear transformations for feature dimensionality reduction are not well suited .For example , the data depicted in Figure 2 would be better approximated by its position with respect to a curved U - shape line rather the straight line obtained with linear PCA .", "label": "", "metadata": {}, "score": "37.885334"}
{"text": "For all discriminatively based transformations , either linear or nonlinear , an implicit assumption is that training data exists which has been labeled according to category .For the case of classification , such as the experiments just described , this labeled data is needed anyway , for both training and test data , to conduct classification experiments ; thus the need for category labeled data is not any extra burden .", "label": "", "metadata": {}, "score": "38.34133"}
{"text": "We investigate the extent to which alignment can be simulated using word sequences alone ( not syntactic structures ) .To this end , we interpolate a default language model with one calculated on the basis of a cached sentence .Experiments on sentences with the prepositional / double object alternation show that varying the weight given to the cache model varies the propensity to align .", "label": "", "metadata": {}, "score": "38.370583"}
{"text": "The first one is the widely used ' overgenerate and rank ' approach which relies exclusively on a trigram language model ( LM ) ; the second one combines language modeling with a maximum entropy cla ... \" .We compare two approaches to dependency tree linearization , a task which arises in many NLP applications .", "label": "", "metadata": {}, "score": "38.716328"}
{"text": "Finally , we interpreted the Equiv annotations identifying equivalent entity references in the data : any pair where entities are equivalent to those of at least one positive pair was marked positive ( see Figure 3 ) .Reinterpreting BioNLP Shared Task event structures as associated entity pairs .", "label": "", "metadata": {}, "score": "39.1597"}
{"text": "Alternatively , the neural network architecture and/or training constraints could be modified so that the nonlinearly transformed features are more suitable as input features for a Hidden Markov Model .References . 2 - S. B. Davis , P. Mermelstein , 1980 Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences , IEEE Trans . on Acoustics , Speech and Signal Processing , 28 357 366 .", "label": "", "metadata": {}, "score": "39.288246"}
{"text": "However , the recognition accuracy is often degraded .The more hidden nodes a network has , the more complex a decision surface can be formed , and thus better classification accuracy can be expected ( Meng , 2006 ) .Generally , the number of hidden nodes is empirically determined by a combination of accuracy and computational considerations , as applied to a particular application .", "label": "", "metadata": {}, "score": "39.326332"}
{"text": "If the underlying assumption of zero mean multivariate Gaussian random variables is satisfied , then this method of feature reduction generally performs very well .The principal components are also statistically independent for the Gaussian case .The principal components \" account for \" or explain the maximum amount of variance of the original data .", "label": "", "metadata": {}, "score": "39.514473"}
{"text": "Methods : A novel method of combining an LSP ( labeled sequential pattern ) classifier with a CRF ( conditional random field ) recognizer was devised .The LSP classifier filters out irrelevant sentences , while the CRF recognizer extracts follow - up and time phrases from candidate sentences presented by the LSP classifier .", "label": "", "metadata": {}, "score": "39.55123"}
{"text": "We find that : ( a ) , one- and two - stage classificationbased approaches can achieve almost 86 % accuracy in determining the absolute position of adverbials ; ( b ) a classifie ... \" .In this paper we compare three approaches to adverbial positioning using lexical , syntactic , semantic and sentence - level features . ... bial in a particular context , but other positions give output that is non - idiomatic or disfluent , ambiguous , or incoherent .", "label": "", "metadata": {}, "score": "39.628605"}
{"text": "This post uses a classification approach to create a parser that returns lists of sentences of tokenized words and punctuation .Splitting text into words and sentences seems like it should be the simplest NLP task .It probably is , but there are a still number of potential problems .", "label": "", "metadata": {}, "score": "39.658894"}
{"text": "This paper shows that discriminative reranking with an averaged perceptron model yields substantial improvements in realization quality with CCG .The paper confirms the utility of including language model log probabilities as features in the model , which prior work on discriminative training with lo ... \" .", "label": "", "metadata": {}, "score": "39.663944"}
{"text": "We use LVQ to map acoustic contextual data into context - independent phonemic form .The acoustic data is in the form of concatenated averages of successive short - time feature vectors .This mapping eliminates the need to employ context dependent phonemic , for example , triphone HMMs , and the difficulties associated therein .", "label": "", "metadata": {}, "score": "40.744072"}
{"text": "Moreover , the task of automatically generating or extracting semantic equivalences for the various units of language- words , phrases , and sentences - is an important part of natural language processing ( NLP ) and is being increasingly employed to improve the performance of several NLP applications .", "label": "", "metadata": {}, "score": "40.78277"}
{"text": "In this paper , we show how these results can be exploited to improve parsing accuracy by integrating a graph ... \" .Previous studies of data - driven dependency parsing have shown that the distribution of parsing errors are correlated with theoretical properties of the models used for learning and inference .", "label": "", "metadata": {}, "score": "40.91174"}
{"text": "We show that , in spite of similar performance overall , the two models produce different types of errors , in a w ... \" .We present a comparative error analysis of the two dominant approaches in datadriven dependency parsing : global , exhaustive , graph - based models , and local , greedy , transition - based models .", "label": "", "metadata": {}, "score": "40.913902"}
{"text": "In this paper we investigate the possibility of evaluating MT quality and fluency at the sentence level in the absence of reference translations .We measure the correlation between automatically - generated scores and human judgments , and we evaluate the performance of our system when used a ... \" .", "label": "", "metadata": {}, "score": "41.106613"}
{"text": "The effect of regularization is demonstrated for continuous speech recognition tasks by improving overfitted triphone models and by speaker adaptation with limited training data .1 Introduction One general problem when constructing statistical pattern recognition systems is to ensure the capability to generalize well , i.e. the system must be able ...", "label": "", "metadata": {}, "score": "41.243073"}
{"text": "Parser actions are determined by a classifier , based on features that represent the current state of the parser .We apply this pars ... \" .We present a data - driven variant of the LR algorithm for dependency parsing , and extend it with a best - first search for probabilistic generalized LR dependency parsing .", "label": "", "metadata": {}, "score": "41.258614"}
{"text": "This method requires a source - language dependency parser , target language word segmentation and an unsupervised word alignment component .We align a parallel corpus , project the source dependency parse onto the target sentence , extract dependency treelet translation pairs , and train a tree - based ordering model .", "label": "", "metadata": {}, "score": "41.376213"}
{"text": "Comparison of estimated coverage of previously known and newly identified words expressing gene / protein associations .Note truncated ranges .Discussion .In addition to event types , associations characterized as experimental outcomes and manipulations and static relations ( e.g. part - of ) were prominent among those not covered by the considered resources .", "label": "", "metadata": {}, "score": "41.40576"}
{"text": "As a consequence of a predominantly statistical approach to speech recognition problem , due to the numeric , feature vector - based , nature of rep - resentation , the classes inductively discovered from real data using decision - theoretic techniques have little meaning outside the statistical framework .", "label": "", "metadata": {}, "score": "41.525406"}
{"text": "There are newer versions of these methods such as Heteroscedastic Discriminant Analysis ( HDA ) ( Kumar & Andreou , 1998 ; Saon et al . , 2000 ) .However , in all cases certain assumptions are made about the statistical properties of the original data ( such as multivariate Gaussian ) ; even more fundamentally , the transformations are restricted to be linear .", "label": "", "metadata": {}, "score": "41.542995"}
{"text": "33 , CNIO , October 2009 .Sun , Xu , Yaozhong Zhang , Takuya Matsuzaki , Yoshimasa Tsuruoka and Jun'ichi Tsujii .A Discriminative Latent Variable Chinese Segmenter with Hybrid Word / Character Information .In the Proc . of NAACL - HLT'09 .", "label": "", "metadata": {}, "score": "41.60106"}
{"text": "These pass through the classifier , and are used in the final processing to collapse abbreviations into single word tokens .Each sentence is returned as a list of string word tokens .The final results are returned as a list of sentences .", "label": "", "metadata": {}, "score": "41.6331"}
{"text": "Articles .Okanohara , Daisuke and Jun'ichi Tsujii .Assigning Polarity Scores to Reviews Using Machine Learning Techniques .In Robert Dale , Kam - Fai Wong , Jian Su and Oi Yee Kwong ( Eds . ) , Natural Language Processing - IJCNLP 2005 .", "label": "", "metadata": {}, "score": "41.655674"}
{"text": "To evaluate the capability of the presented approach to identify new expressions of gene / protein associations , we next performed a manual study of candidate words for stating gene / protein associations using the E w ranking .Here , we take as known any word for which the normalized , lemmatized form ( using the NLM LVG norm normalizer [ 47 ] ) matches that of any word appearing as a trigger expression in the BioNLP ST training or development test data .", "label": "", "metadata": {}, "score": "41.755882"}
{"text": "Given a group of related sentences , we align their dependency trees and build a dependency graph .Using integer linear programming we compress this graph to a new tree , which we then linearize .We use GermaNet and Wikipedia for checking semantic compatibility of co - arguments .", "label": "", "metadata": {}, "score": "41.785583"}
{"text": "Ideally , the targets are uncorrelated , which enables quicker convergence of weight updates .The targets can also be viewed as multidimensional vectors , with a value of \" 1 \" for the target category and \" 0s \" for the non - target categories .", "label": "", "metadata": {}, "score": "41.938835"}
{"text": "We defer detailed description of the method to a later section ( Machine Learning ) , now simply assuming a way to assign to each path p an ( estimated ) probability P ( p ) that the path expresses an association between the entities it connects .", "label": "", "metadata": {}, "score": "41.98251"}
{"text": "In this chapter , some techniques are presented for reducing feature dimensionality while preserving category ( i.e. , phonetic for the case of speech ) discriminability .Since the techniques presented for reducing dimensionality are statistically based , these methods also are subject to \" curse of dimensionality \" issues .", "label": "", "metadata": {}, "score": "42.276443"}
{"text": "A novel method for classifying speech phonemes is presented 1 .Unlike traditional cepstral based methods , this approach uses histograms of reconstructed phase spaces .A Na\u00efve Bayes classifier uses the probability mass estimates for classification .The approach is verified using isolated fricative , v ... \" .", "label": "", "metadata": {}, "score": "42.295723"}
{"text": "In addition , a difficulty in neural network training is that the input data has a wide range of means and variances for each feature component .In order to avoid this , the input data of neural networks is often scaled so that all feature components have the same mean ( zero ) and variance ( so that range of values is approximately \u00b1 1 ) .", "label": "", "metadata": {}, "score": "42.560196"}
{"text": "The classifier is trained using the Treebank Corpus supplied with NLTK .The primary problem with this approach is that it can not distinguish between punctuation \" . \" characters and end of sentence markers ( full stops ) .The solution is to treat white space as a special \" space separator \" token .", "label": "", "metadata": {}, "score": "43.073845"}
{"text": "For this case , 2-D pseudo random data was created to lie along a U shaped curve , similar to the data depicted in Figure 2 .A neural network ( 2 - 5 - 1 - 5 - 2 ) was then trained as an identify map .", "label": "", "metadata": {}, "score": "43.23529"}
{"text": "We depend on a source - language dependency parser and a word - aligned parallel corpus .The only targe ... \" .done while at Microsoft Research We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .", "label": "", "metadata": {}, "score": "43.334194"}
{"text": "Note that unlike phonetic recognition experiments , for the case of classification , the timing labels in the database are explicitly used for both training and testing .Thus classification is \" easier \" than recognition , and accuracies typically higher , since phone boundaries are known in advance and used .", "label": "", "metadata": {}, "score": "43.51905"}
{"text": "With resources for static relation extraction this coverage can be further extended beyond event - type associations , for example applying static relations in support of event extraction as considered in the REL task of BioNLP Shared Task 2011 [52 ] .", "label": "", "metadata": {}, "score": "43.592678"}
{"text": "The explicit assumption for LDA is that the within class covariance of each category is the same , which is rarely true in practice .Nevertheless , for many practical classification problems , features reduced by LDA often are as effective or even advantageous to original higher dimensional features .", "label": "", "metadata": {}, "score": "43.599834"}
{"text": "However , it is also possible that one of the nonlinear methods for feature reduction is more effective , that is enable higher ASR accuracy , than any of the linear methods .The comparisons of these various methods can only be done experimentally .", "label": "", "metadata": {}, "score": "43.762093"}
{"text": "Most of the known stochastic sentence generators use syntactically annotated corpora , performing the projection to the surface in one stage .However , in full - fledged text generation , sentence realization usually starts from semantic ( predicate - argument ) structures .", "label": "", "metadata": {}, "score": "43.815216"}
{"text": "Most of the known stochastic sentence generators use syntactically annotated corpora , performing the projection to the surface in one stage .However , in full - fledged text generation , sentence realization usually starts from semantic ( predicate - argument ) structures .", "label": "", "metadata": {}, "score": "43.815216"}
{"text": "We apply our recent method to order constituents and , using the CMU toolkit ( Clarkson & Rosenfeld , 1997 ) , build a trigram language model from Wikipedia ( approx .1 GB plain ... . by Michael Strube - In Proceedings of Human Language Technologies : The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics , Companion Volume : Short Papers , 2009 . \" ...", "label": "", "metadata": {}, "score": "43.827225"}
{"text": "The only target language resource assumed is a word breaker .These are used to produce treelet ( \" phrase \" ) translation pairs as well as several models , including a channel model , an order model , and a target language model .", "label": "", "metadata": {}, "score": "43.836884"}
{"text": "Based on our experience with event annotation , we further expect that in a corpus of this size the great majority of association types that are expressed across multiple sentences in some statements will also appear within a single sentence in others .", "label": "", "metadata": {}, "score": "43.84675"}
{"text": "We applied the libSVM Support Vector Machine implementation using probabilistic outputs [ 45 ] .For training the classifier , we applied features derived only from the words and dependencies along the shortest path between any two entities .We first replaced each word marked as a gene / protein mention with a placeholder string and each other word with its part of speech tag , using the Penn tags included in TPS data ( Figure 4 ) .", "label": "", "metadata": {}, "score": "43.850075"}
{"text": "This is a Naive Bayes classifier , so it is quick to train ; but the complete trained classifier could be pickled for re - use instead of being created at the beginning of each application .At classification time , white space tokens are collapsed into single space character tokens .", "label": "", "metadata": {}, "score": "43.885284"}
{"text": "This issue of category labels is described in more detail in the following two subsections .Figure 12 .Classification accuracies of neural network ( top panel ) and MXL ( bottom panel ) classifiers using 10 % of group 2 training data for training classifier .", "label": "", "metadata": {}, "score": "43.95549"}
{"text": "The columns of B are also the same eigenvectors .Thus the \" forward \" and \" reverse \" transformations are transposes of each other .The components of Y are uncorrelated .Furthermore the expected value of this normalized mean square error between original and re - estimated X vectors can be shown to equal the ratio of the sum of \" unused \" eignevalues to the sum of all eigenvalues .", "label": "", "metadata": {}, "score": "44.02847"}
{"text": "View Article .Ding J , Berleant D , Xu J , Fulmer AW : Extracting Biochemical Interactions from MEDLINE Using a Link Grammar Parser .Proceedings of ICTAI'03 .Yakushiji A , Miyao Y , Tateisi Y , Tsujii J : Biomedical Information Extraction with Predicate - Argument Structure Patterns .", "label": "", "metadata": {}, "score": "44.071915"}
{"text": "We look at two strategies and provide convergence bounds for a particular mode of distributed structured perceptron training based on iterative parameter mixing ( or averaging ) .We present experiments on two structured prediction problems - namedentity recognition and dependency parsing - to highlight the efficiency of this method . ... converged models .", "label": "", "metadata": {}, "score": "44.149063"}
{"text": "Rinaldi F , Schneider G , Kaljurand K , Hess M , Romacker M : An environment for relation mining over richly annotated corpora : The case of GENIA .Proceedings of SMBM'06 .S\u00e6tre R , Sagae K , Tsujii J : Syntactic features for protein - protein interaction extraction .", "label": "", "metadata": {}, "score": "44.2332"}
{"text": "Ohta T , Kim JD , Pyysalo S , Wang Y , Tsujii J : Incorporating GENETAG - style annotation to GENIA corpus .Proceedings of BioNLP'09 .Tateisi Y , Yakushiji A , Ohta T , Tsujii J : Syntax Annotation for the GENIA corpus .", "label": "", "metadata": {}, "score": "44.316277"}
{"text": "We propose a novel interpretation of interpolated Kneser - Ney as approxima ... \" .Interpolated Kneser - Ney is one of the best smoothing methods for n - gram language models .Previous explanations for its superiority have been based on intuitive and empirical justifications of specific properties of the method .", "label": "", "metadata": {}, "score": "44.697784"}
{"text": "The number of hidden nodes in the second hidden layer was varied from 1 to 39 , according to the dimensionality being evaluated .For the case of NLDA2 , the network used for dimensionality reduction was also a classifier .For the sake of consistency , the outputs of the hidden nodes from the bottleneck neural network were used as features for a classifier , using either another neural network or the MXL classifier .", "label": "", "metadata": {}, "score": "44.85984"}
{"text": "Then a neural network ( 3 - 10 - 2 - 10 - 3 ) was trained as an identity map .After training , the outputs of the neural network are plotted in the right panel of Figure 6 .Clearly the neural network \" learned \" a 2-D internal representation , at the bottleneck layer , from which it could reconstruct the original data .", "label": "", "metadata": {}, "score": "44.919266"}
{"text": "For both the neural network and MXL classifiers , NLDA2 clearly performs much better than the other transformations or the original features .However , the advantage of NLDA2 decreases with an increasing number of features , and as the percentage of group 2 data increases ( not shown in figure ) .", "label": "", "metadata": {}, "score": "44.94729"}
{"text": "We obtain statistically significant improvements on six typologically different languages : English , . ...er is used to select the best surface realization ( Cahill et al . , 2007 ; White and Rajkumar , 2009 ) .They typically work by traversing the syntactic structure either bottom - up ( Filip929pova and S .. \" ...", "label": "", "metadata": {}, "score": "45.152714"}
{"text": "Nonlinear Dimensionality Reduction Methods for Use with Automatic Speech Recognition .Stephen A. Zahorian 1 and Hongbing Hu 1 .Introduction .For nearly a century , researchers have investigated and used mathematical techniques for reducing the dimensionality of vector valued data used to characterize categorical data with the goal of preserving \" information \" or discriminability of the different categories in the reduced dimensionality data .", "label": "", "metadata": {}, "score": "45.257362"}
{"text": "Conferences .Okanohara , Daisuke and Jun'ichi Tsujii .A discriminative language model with pseudo - negative samples .In the Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics .pp .73 - -80 , Association for Computational Linguistics , June 2007 .", "label": "", "metadata": {}, "score": "45.2909"}
{"text": "The classes would be well separated by a projection onto the first LDA basis vector , but poorly separated by a projection onto the first PCA basis vector .Figure 16 .Accuracies of NLDA1 and NLDA2 with various dimensionality reduced features based on 1-state ( top panel ) and 3-state HMMs ( bottom panel ) .", "label": "", "metadata": {}, "score": "45.466564"}
{"text": "Unlexicalized shortest path representation a ) Applied annotations with original sentence text .b ) Unlexicalized representation .c ) Shortest path connecting two gene / protein mentions .The resulting classifier is intentionally weak , being trained to recognize not the specific properties of positive examples in its training set but rather their general characteristics .", "label": "", "metadata": {}, "score": "45.480564"}
{"text": "We apply this parsing framework to both tracks of the CoNLL 2007 shared task , in each case taking advantage of multiple models trained with different learners .In the multilingual track , we train three LR models for each of the ten languages , and combine the analyses obtained with each individual model with a maximum spanning tree voting scheme .", "label": "", "metadata": {}, "score": "45.599632"}
{"text": "As another powerful approach , the softmax function takes all the nodes in a layer into account and calculates the output of a node as a posterior probability .When the outputs of the network are to be used as transformed features for the HMM recognition , a linear function or a softmax function is appropriate to generate the data with a more diverse distribution , such as one that would be well - modeled with a GMM .", "label": "", "metadata": {}, "score": "45.72975"}
{"text": "Since the original data is not multivariate Gaussian , the PCA basis vector is no longer a good way to approximate the data .In fact , since the data primarily follows a curved path in the 2-D space , no linear transform method , resulting in a straight line subspace , will be a good way to approximate the data with one dimension .", "label": "", "metadata": {}, "score": "45.929657"}
{"text": "The dependency parsing approach presented here extends the existing body of work mainly in four ways : 1 .Although stepwise 1 dependency parsing has commonly been performed using parsing algo1 Stepw ... . \" ...Perceptron training is widely applied in the natural language processing community for learning complex structured models .", "label": "", "metadata": {}, "score": "45.95761"}
{"text": "What about speech marks and apostrophes ?Many of these questions will depend on your specific application : for example , sometimes it is appropriate to treat speech as a sentence fragment , and sometimes it should be treated as a complete sentence .", "label": "", "metadata": {}, "score": "45.973965"}
{"text": "A wealth of approaches for distinguishing relevant paths from irrelevant ones have been proposed in the protein - protein interaction extraction literature , including rule - based , pattern - based ( hand - written and learned ) and supervised classification - based methods ( e.g. [ 31 , 32 , 34 - 38 ] ) .", "label": "", "metadata": {}, "score": "46.053352"}
{"text": "The first stage is based on the unlabeled dependency parsing models described by McDonald and Pereira ( 2006 ) augmented with morphological features for a subset of the languages .The second stage takes the ... \" .We present a two - stage multilingual dependency parser and evaluate it on 13 diverse languages .", "label": "", "metadata": {}, "score": "46.080658"}
{"text": "( Sentences not containing entities are not parsed as parsing was the most computationally intensive part of the automatic corpus annotation and the event extraction system could only extract events from sentences containing entities . )Parses were produced using the McClosky - Charniak parser [ 22 ] , a version of the Charniak - Johnson parser [ 23 ] adapted to the biomedical domain .", "label": "", "metadata": {}, "score": "46.140697"}
{"text": "Punctuation ( full stop , question mark , exclamation mark ) could be used to divide sentences .This quickly comes into problems when an abbreviation is processed .\" etc . \" would be interpreted as a sentence terminator , and \" U.N.E.S.C.O. \" would be interpreted as six individual sentences , when both should be treated as single word tokens .", "label": "", "metadata": {}, "score": "46.160645"}
{"text": "Table 5 .Example shortest paths for candidate gene / protein association - expressing word \" acylation \" .In total , 1200 candidate expressions were manually evaluated , proceeding from candidates ranked highest by E w to lower .While no stopping criterion was specified in advance , evaluation was stopped after reaching a point of diminishing returns where no positives had been identified in a run of over 100 examined candidates .", "label": "", "metadata": {}, "score": "46.26958"}
{"text": "Unlike traditional cepstral based methods , this approach uses histograms of reconstructed phase spaces .A Na\u00efve Bayes classifier uses the probability mass estimates for classification .The approach is verified using isolated fricative , vowel , and nasal phonemes from the TIMIT corpus .", "label": "", "metadata": {}, "score": "46.498943"}
{"text": "Theoretically , the nonlinear methods have the potential to be more \" efficient \" than linear methods , that is , give better representations with fewer dimensions .In addition , some examples are shown from experiments with Automatic Speech Recognition ( ASR ) where the nonlinear methods in fact perform better , resulting in higher ASR accuracy than obtained with either the original speech features , or linearly reduced feature sets .", "label": "", "metadata": {}, "score": "46.52776"}
{"text": "However , while statements of experimental results such as colocalize and coprecipitate do not directly state a biologically meaningful association between genes / proteins , they suggest a possible association and have been specifically included in a number of tasks targeting protein - protein interactions , including BioCreative challenges [ 17 ] .", "label": "", "metadata": {}, "score": "46.607502"}
{"text": "The second stage takes the output from the first and labels all the edges in the dependency graph with appropriate syntactic categories using a globally trained sequence classifier over components of the graph .We report results on the CoNLL - X shared task ( Buchholz et al . , 2006 ) data sets and present an error analysis . .", "label": "", "metadata": {}, "score": "46.83987"}
{"text": "Creating tokenizer . . . .Segmenting text into words and sentences . . . .Segmented sentences : .There we have it - text that has been tokenized and segmented ready for further processing such as classification , collocation detection , or POS tagging .", "label": "", "metadata": {}, "score": "46.85872"}
{"text": "The resulting clusterings are then used in training partially class - based language models .We show that combining them with wordbased n - gram models in the log - linear model of a state - of - the - art statistical machine translation system leads to improvements in translation quality as indicated by the BLEU score . ...", "label": "", "metadata": {}, "score": "46.904884"}
{"text": "Clearly , for this example , the two basis vectors are quite different , and clearly the projection of data onto the first LDA basis vector would be more effective for separating the two categories than data projected onto the first PCA basis vector .", "label": "", "metadata": {}, "score": "46.92446"}
{"text": "In the remaining part of this chapter , two versions of NLDA based on this strategy are described , followed by a series of experimental evaluations for the phonetic classification and recognition tasks .Nonlinear dimensionality reduction architecture .In a previous work ( Zahorian et al . , 2007 ) , NLPCA was applied to an isolated vowel classification task , and the nonlinear method based on neural networks was experimentally compared with linear methods for reducing the dimensionality of speech features .", "label": "", "metadata": {}, "score": "47.129436"}
{"text": "Of the examined candidates , 660 were judged as positive in total , confirming that the approach can identify expressions of entity associations not appearing in the reference annotated data .We next proceeded to manually cluster these by the type of association they would typically be expected to express .", "label": "", "metadata": {}, "score": "47.24398"}
{"text": "Proceedings of BioCreative II .Pyysalo S , Ohta T , Kim JD , Tsujii J : Static Relations : a Piece in the Biomedical Information Extraction Puzzle .Proceedings of BioNLP'09 .Bunescu RC , Mooney RJ : A shortest path dependency kernel for relation extraction .", "label": "", "metadata": {}, "score": "47.26025"}
{"text": "Figure 13 .Training target vectors of the neural network .State - level targets .Due to the nonstationarity of speech signals , a speech signal varies even in a very short time interval ( e.g. a phoneme ) .For speech recognition tasks , instead of phone level training targets , state ( as in hidden states of an HMM ) dependent targets could be advantageous in training a versatile network for more highly discriminative speech features .", "label": "", "metadata": {}, "score": "47.292694"}
{"text": "Variants of the Stanford Dependency representation .a ) Basic representation .b ) Collapsed , coordination - processed representation .Table 3 shows the words most frequently occurring on these paths .This list again suggests an increased focus on words relating to gene / protein associations : expression is the most frequent word on the paths , and binding appears in the top - ranked words .", "label": "", "metadata": {}, "score": "47.466713"}
{"text": "It is also shown that speech recognition accuracy can be as high as or even higher using reduced dimensionality features versus original features , with \" properly \" trained systems .Background .Both approaches are used .Thus , for good training of model parameters , increasing dimensionality from 40 to 50 , considered a modest increase , could easily increase the need for more data by a factor of 1000 or more .", "label": "", "metadata": {}, "score": "47.482506"}
{"text": "Standard and factored language models are analyzed in terms of applicability to the chord recognition task .Pitch class profile vectors that represent harmonic information are extracted from the given audio ... \" .This paper focuses on automatic extraction of acoustic chord sequences from a musical piece .", "label": "", "metadata": {}, "score": "47.505035"}
{"text": "Semi - automatically Developing Chinese HPSG Grammar from the Penn Chinese Treebank for Deep Parsing .In the Proceedings of COLING 2010 .Wu , Xianchao , Takuya Matsuzaki , Jun'ichi Tsujii .Fine - Grained Tree - to - String Translation Rule Extraction .", "label": "", "metadata": {}, "score": "47.767246"}
{"text": "In this paper , we describe how overly aggressive key - target resizing can sometimes prevent users from typing their desired text , violating basic user expectations about keyboard functionality .We propose an anchored key - target method which aims to provide an input method that is robust to errors while respecting usability principles .", "label": "", "metadata": {}, "score": "47.988503"}
{"text": "As the BioNLP ST data does not explicitly identify simple pairs of entities that are stated to be associated ( but rather event graphs ) , it was first necessary to derive a pairwise representation from the event representation .We applied a mapping similar to that introduced by [ 42 ] for deriving pairwise relations from the event - style annotations of the Biolnfer corpus [ 43 ] : for each co - occurring entity pair , we identified all paths through event structures connecting the two entities .", "label": "", "metadata": {}, "score": "48.06634"}
{"text": "For all cases , including original features , and all versions of the transformed features , a neural network classifier with 100 hidden nodes and 10 output nodes , trained with backpropagation , was used as the classifier .In addition , a Bayesian maximum likelihood Mahalanobis distance based Gaussian assumption classifier ( MXL ) was used for evaluation .", "label": "", "metadata": {}, "score": "48.162735"}
{"text": "With the availabi ... . \" ...The task of paraphrasing is inherently familiar to speakers of all languages .Moreover , the task of automatically generating or extracting semantic equivalences for the various units of language- words , phrases , and sentences - is an important part of natural language processing ( NLP ) and is being inc ... \" .", "label": "", "metadata": {}, "score": "48.62292"}
{"text": "View Article .Tanabe L , Xie N , Thom LH , Matten W , Wilbur WJ : GENETAG : A tagged corpus for gene / protein named entity recognition .BMC Bioinformatics .2005 , 6 ( Suppl . 1 ) : S3- View Article .", "label": "", "metadata": {}, "score": "48.6295"}
{"text": "Volume 3 , 2004 . \" ...This paper explores the issues involved in using symbolic metric algorithms for automatic speech recognition ( ASR ) , via a structural representation of speech .This representation is based on a set of phonological distinctive features which is a linguistically well - motivated alternative to the \" ... \" .", "label": "", "metadata": {}, "score": "48.64539"}
{"text": "For each pair of adjacent levels of annotation , a separate decoder is defined .So far , we evaluated the realizer for Chinese , English , German , and Spanish . ... riments on deep generation of Chinese , English , German and Spanish , starting from CoNLL ' 09 shared task corpora .", "label": "", "metadata": {}, "score": "48.734955"}
{"text": "Note that in this usage , \" outputs \" may be from the final outputs or from one of the internal hidden layers .Figure 7 .Overview of the NLDA transformation for speech recognition .The multilayer bottleneck neural network employed in NLDA contains an input layer , hidden layers including the bottleneck layer , and an output layer .", "label": "", "metadata": {}, "score": "48.79682"}
{"text": "Figure 5 shows precision / recall curves for each of the four rankings generated by the word frequency / expected value .The result supports the informal observations made through the top - ranked words in Tables 1 , 2 , 3 and 4 : the later approaches provide a much more relevant ranking for identifying words expressing associations .", "label": "", "metadata": {}, "score": "48.8444"}
{"text": "That is .Y .A .T .X , where X , Y are again column vectors as for PCA .The big difference is in how A is computed .For LDA , it has been shown that the columns of A correspond to the m largest eigenvalues of .", "label": "", "metadata": {}, "score": "48.966843"}
{"text": "Further , our estimate of overall association statement frequency ignored much of the \" long tail \" of the distribution , thus excluding rare expressions which may nevertheless add up to a not insignificant fraction of the total .These factors limit the reliability of the presented coverage estimates .", "label": "", "metadata": {}, "score": "48.983444"}
{"text": "To parse all the sentences in the PDT , one must use a non - projectiv ... .by Ryan McDonald , Kevin Lerman , Fernando Pereira - IN PROCEEDINGS OF THE CONFERENCE ON COMPUTATIONAL NATURAL LANGUAGE LEARNING ( CONLL , 2006 . \" ...", "label": "", "metadata": {}, "score": "49.110985"}
{"text": "By letting one model generate features for the other , we consistently improve accuracy for both models , resulting in a significant improvement of the state of the art when evaluated on data sets from the CoNLL - X shared task . ...", "label": "", "metadata": {}, "score": "49.22475"}
{"text": "The use of PCA improves accuracy on the order of 2 % to 10 % , depending on the conditions .In contrast , for NLDA2 , best performance was obtained with the nonlinearities used for both training and final transformations .", "label": "", "metadata": {}, "score": "49.22838"}
{"text": "View Article .Fundel K , Kuffner R , Zimmer R : RelEx - Relation extraction using dependency parse trees .Bioinformatics .10.1093/bioinformatics / btl616 .View Article .Miwa M , S\u00e6tre R , Miyao Y , Tsujii J : Protein - Protein Interaction Extraction by Leveraging Multiple Kernels and Parsers .", "label": "", "metadata": {}, "score": "49.2333"}
{"text": "Because of the later limitation it is doubtful that the gap between speech recognition and lin - guistic research can be bridged by the numeric representations .This thesis investigates an alternative , structural , approach to spoken language representation and categorisa- . \" ...", "label": "", "metadata": {}, "score": "49.36298"}
{"text": "class SentenceTokenizer ( ) : . # extract punctuation features from word list for position i .# Features are : this word ; previous word ( lower case ) ; . # is the next word capitalized ? ; previous word only one char long ? def punct_features ( self , tokens , i ) : . isupper ( ) , . ' prevword ' : tokens [ i - 1 ] . lower ( ) , . ' punct ' : tokens [ i ] , . '", "label": "", "metadata": {}, "score": "49.572655"}
{"text": "HDA suffers from two drawbacks .There is no known closed form solution for minimizing the objective function required to solve for the transformation - rather a complex numerically based gradient search is required .More fundamentally , with actual speech data , HDA alone was found to perform far worse than LDA .", "label": "", "metadata": {}, "score": "49.818596"}
{"text": "We then removed any path that did not meet this condition as not likely expressing an association , leaving 46437 unique unlexicalized paths ( 5.7 % of the total ) predicted to express gene / protein associations .Finally each occurrence of a word w on one of these paths is assigned the path probability P ( p ) .", "label": "", "metadata": {}, "score": "49.849037"}
{"text": "Our experiments confirm that the online algorithms are much faster than the batch algorithms in practice .We describe how the EG updates factor in a convenient way for structured prediction problems , allowing the algorithms to be . ... in McDonald et al .", "label": "", "metadata": {}, "score": "49.86847"}
{"text": "For the MXL classifier , NLDA2 features result in approximately 10 % higher classification accuracies as compared to all other features .For both the neural network and MXL classifiers , accuracy with NLPCA features was very similar to that obtained with linear PCA .", "label": "", "metadata": {}, "score": "50.05516"}
{"text": "Recent work done in manual and automatic construction of paraphrase corpora is also examined .We also discuss the strategies used for evaluating paraphrase generation techniques and briefly explore some future trends in paraphrase generation .this disparity could be that paraphrasing is not an application in and of itself .", "label": "", "metadata": {}, "score": "50.119843"}
{"text": "The features which were dimensionality reduced by PCA and LDA alone were also evaluated for the purpose of comparison .Figure 16 shows recognition accuracies of dimensionality reduced features using 1-state and 3-state HMMs with 3 mixtures per state .", "label": "", "metadata": {}, "score": "50.259933"}
{"text": "Across various encoding schemes , and for multiple language pairs , we show speed - ups of up to 50 times over single - pass decoding while improving BLEU score .Moreover , our entire decoding cascade for trigram language models is faster than the corresponding bigram pass alone of a bigram - to - trigram decoder . \" ... Interpolated Kneser - Ney is one of the best smoothing methods for n - gram language models .", "label": "", "metadata": {}, "score": "50.431602"}
{"text": "Calculating E w .E w , informally characterized as the expected number of times a word w occurs on a dependency path which is estimated to be likely to express a gene / protein association , is central to the applied probabilistic ranking .", "label": "", "metadata": {}, "score": "50.750225"}
{"text": "[ 2 ] - Most , but not all researchers , have used the recommended training and test sets .For all ASR experiments reported in this chapter , the SA sentences were removed , the recommended training and test sets were used , and the phone set was collapsed to the same 39 phones used in most ASR experiments with TIMIT .", "label": "", "metadata": {}, "score": "50.795113"}
{"text": "if tokens [ i ] in ' . ? ! ' ] self .NaiveBayesClassifier . train ( train_set ) .# Use the classifier to segment word tokens into sentences .# words is a list of ( word , bool ) tuples .", "label": "", "metadata": {}, "score": "50.82992"}
{"text": "Within the METIS - II project 1 , we have implemented a machine translation system which uses transfer and expander rules to build an AND / OR graph of partial translation hypotheses and a statistical ranker to find the best path through the graph .", "label": "", "metadata": {}, "score": "50.83055"}
{"text": "Within the METIS - II project 1 , we have implemented a machine translation system which uses transfer and expander rules to build an AND / OR graph of partial translation hypotheses and a statistical ranker to find the best path through the graph .", "label": "", "metadata": {}, "score": "50.83055"}
{"text": "# ( word , bool ) tuples for the tokesn .Word is used as above , but the bool .# flag ( whitespace separator ? ) is ignored .# This allows the same features to be extracted from tuples instead of .", "label": "", "metadata": {}, "score": "50.831635"}
{"text": "The aim of the second experiment is a more thorough evaluation of NLDA1 and NLDA2 using a varying number of states and mixtures in HMMs .The 78 DCTC / DCSCs ( computed as mentioned in previous section ) were reduced to 36 dimensions based on the results of the previous experiment .", "label": "", "metadata": {}, "score": "50.860893"}
{"text": "This analysis leads to new directions for parser development . ... otated corpus .The advantage of such models is that they are easily ported to any domain or language in which annotated resources exist .The first is what Buchholz and Marsi ( 2006 ) call the \" all - pairs \" approach , where every possible arc is considered in the ... . by Kenji Sagae - In Proceedings of the Eleventh Conference on Computational Natural Language Learning , 2007 . \" ...", "label": "", "metadata": {}, "score": "50.92746"}
{"text": "Columbus , OH , pp .46 - 54 , June 2008 .Matsuzaki , Takuya and Jun'ichi Tsujii .Comparative Parser Performance Analysis across Grammar Frameworks through Automatic Tree Conversion using Synchronous Grammars .In the Proceedings of the The 22nd International Conference on Computational Linguistics ( COLING-2008 ) .", "label": "", "metadata": {}, "score": "50.93244"}
{"text": "A .T .X .Let .X .^ .B .Y be an approximation to .X .Note that .X .Y and .X .^ can all be viewed as ( column ) vector - valued random variables .", "label": "", "metadata": {}, "score": "50.98707"}
{"text": "We present a novel unsupervised sentence fusion method which we apply to a corpus of biographies in German .Given a group of related sentences , we align their dependency trees and build a dependency graph .Using integer linear programming we compress this graph to a new tree , which we then linearize ... \" .", "label": "", "metadata": {}, "score": "51.020226"}
{"text": "This representation is based on a set of phonological distinctive features which is a linguistically well - motivated alternative to the \" beads - on - a - string \" view of speech that is standard in current ASR systems .We report the promising results of phoneme classification experiments conducted on a standard continuous speech task . by Jinjin Ye , Michael T. Johnson , Richard J. Povinelli - proceedings of ISCA Tutorial and Research Workshop on Non - linear Speech Processing ( NOLISP ) , Le Croisic , 2003 . \" ...", "label": "", "metadata": {}, "score": "51.03081"}
{"text": "Thus , in one sense , the recognizer is a hybrid neural network / Hidden Markov Model ( NN / HMM ) recognizer .However , the neural network step is used for the task of nonlinear dimensionality reduction and is independent of the HMM .", "label": "", "metadata": {}, "score": "51.294518"}
{"text": "Experiment 1 .In the first experiment , all training data were used to train the transformations including LDA , PCA , NLPCA , and NLDA2 , and the classifiers .Figure 11 shows the results based on the neural network and MXL classifiers for each transformation method in terms of classification accuracy , as the number of features varies from 1 to 39 .", "label": "", "metadata": {}, "score": "51.32289"}
{"text": "In contrast with NLDA1 where dimensionality reduction is assigned to PCA , for NLDA2 , since the dimensionality reduction can be accomplished with the neural network only , the linear PCA is used specifically for reducing the feature correlation .Figure 9 .", "label": "", "metadata": {}, "score": "51.475185"}
{"text": "Input and output plot of the 3-D Gaussian before ( left ) and after ( right ) using neural network for NLPCA .Nonlinear Discriminant Analysis ( NLDA ) .Fortunately , only a minor modification to NLPCA is needed to form NLDA .", "label": "", "metadata": {}, "score": "51.501354"}
{"text": "Classification accuracies of neural network ( top panel ) and MXL ( bottom panel ) classifiers with various types of features .The results obtained with the neural network and MXL classifiers using 10 % of the group 2 training data ( that is , 5 % of the overall training data ) are shown in Figure 12 .", "label": "", "metadata": {}, "score": "51.528168"}
{"text": "The difficulties and costs of adapting existing technology to new languages and application need to be assessed .Near term applications for LVCSR technology are likely to grow in somewhat limited domains such as spoken language systems for information retrieval , and limited domain dictation .", "label": "", "metadata": {}, "score": "51.60736"}
{"text": "E w is then the sum of these probabilities over the entire corpus .We note that this formulation does not include any normalization by the overall frequency of words .This implies that high - frequency irrelevant words ( such as \" gene \" ) are likely to receive higher E w values than rare relevant words ( such as \" biotinylation \" ) .", "label": "", "metadata": {}, "score": "51.60777"}
{"text": "To perform this , we need a word tokenizer that splits text into words , punctuation , and space tokens .Fortunately this is not too complicated .NLTK comes with its own word and punctuation tokenizer , WordPunctTokenizer .This uses the NLTK RegexpTokenizer ( defined in nltk.tokenize.regexp ) .", "label": "", "metadata": {}, "score": "51.742725"}
{"text": "We thus do not expect this practically motivated filtering to fundamentally alter the basic statistical properties of the data .Each path was then assigned the estimated probability P ( p ) using the probabilistic outputs of the SVM trained as described above .", "label": "", "metadata": {}, "score": "51.823223"}
{"text": "Kim JD , Wang Y , Takagi T , Yonezawa A : Overview of Genia Event Task in BioNLP Shared Task 2011 .Proceedings of BioNLP Shared Task 2011 Workshop .Mcintosh T , Curran JR : Reducing Semantic Drift with Bagging and Distributional Similarity .", "label": "", "metadata": {}, "score": "52.004627"}
{"text": "Let .X .[ .x .x .x .n . ]T be an n -dimensional ( column ) feature vector , and .Y .[ .y .y .y . m . ]T be an m -dimensional ( column ) feature vector , obtained as the linear transform of X , using the n by m transformation matrix A , i.e. .", "label": "", "metadata": {}, "score": "52.081512"}
{"text": "# Segment text into sentences and words .# returns a list of sentences , each sentence is a list of words .# punctuation chars are classed as word tokens ( except abbreviations ) .def segment_text ( self , full_text ) : . # Split ( tokenize ) text into words .", "label": "", "metadata": {}, "score": "52.09446"}
{"text": "Word is used as above , but the bool # flag ( whitespace separator ? ) isupper ( ) , ' prevword ' : tokens[i-1][0]. ? ! ' ] Count whitespace as # words . append ( ( word , True ) ) else : word_tuples .", "label": "", "metadata": {}, "score": "52.162376"}
{"text": "The features which are the direct outputs of the network without PCA processing were also evaluated .Figure 17 shows accuracies using 1-state and 3-state HMMs with a varying number of mixtures per state .NLDA2 performed better than NLDA1 for all conditions -- approximately 2 % higher accuracy .", "label": "", "metadata": {}, "score": "52.422714"}
{"text": "Conferences .Daisuke , Okanohara , Yusuke Miyao , Yoshimasa Tsuruoka and Jun'ichi Tsujii .Improving the Scalability of Semi - Markov Conditional Random Fields for Named Entity Recognition .In the Proceedings of ACL 2006 .Sydney , Australia , July 2006 .", "label": "", "metadata": {}, "score": "52.441277"}
{"text": "We first extracted all instances of shortest dependency paths connecting two genes / proteins .We then combined all paths sharing the same \" unlexicalized \" representation , giving a total of 6.8 million unique paths .To make storage and processing more feasible , we removed paths occurring only once in the entire corpus .", "label": "", "metadata": {}, "score": "52.49032"}
{"text": "We find in this listing only words that are regularly used to express gene / protein associations , suggesting that probabilistic ranking can allow clear focus on the targeted statements .Table 4 .Words ranked highest by E w , the expected number of times they occur on shortest paths likely to express a gene / protein association .", "label": "", "metadata": {}, "score": "52.539135"}
{"text": "For efforts aiming only to discover new expressions of entity associations without regard to their frequency , we expect incorporation of some form of correction by the overall frequency of words would be beneficial .Evaluation .We first evaluated each of the word rankings discussed in the section on Identification of Gene / Protein Associations by comparing the ranked lists of words against the set of single words marked as trigger expressions in the BioNLP ST development data .", "label": "", "metadata": {}, "score": "52.576656"}
{"text": "545 - 552 , 2008 .[ PDF ] .Sagae , Kenji , Yusuke Miyao , Takuya Matsuzaki , Jun'ichi Tsujii .Challenges in Mapping of Syntactic Representations for Framework - Independent Parser Evaluation .In the Proceedings of the Workshop on Automated Syntatic Annotations for Interoperable Language Resources at the First International Conference on Global Interoperability for Language Resources ( ICGL'08 ) .", "label": "", "metadata": {}, "score": "52.796185"}
{"text": "# Creating tokenizer .print sentence .The sample text is a few paragraphs of the Wikipedia article for \" Treebank \" as plain text .Here are the results ( only the first few sentences are shown for brevity ) : .", "label": "", "metadata": {}, "score": "52.86497"}
{"text": "We evaluate two decoding approaches , one inspired by dynamic programming and the . ... information for these probability distributions .We attempt to mine the source dependency tree for movement information .Ordering was an important component in their pipeline of operations : after having generated a set of surface nodes from an abstract r .. by Bernd Bohnet , Leo Wanner , Simon Mille , Alicia Burga - In Proceedings of the 23rd", "label": "", "metadata": {}, "score": "52.910965"}
{"text": "Hidden Markov Models ( HMMs ) .Left - to - right Markov models with no skip were used and a total of 48 monophone HMMs were created from the training data using the HTK toolbox ( Verion 3.4 ) ( Young et al . , 2006 ) .", "label": "", "metadata": {}, "score": "53.108627"}
{"text": "The specific definition of this entity type applied in this study is provided by the GENETAG corpus annotation [ 16 ] , as we make use of an automatic tagger trained on this resource for the recognition of genes / proteins .", "label": "", "metadata": {}, "score": "53.297432"}
{"text": "Deterministic shift - reduce parsing for unification - based grammars .Natural Language Engineering . pp .331 - 365 , Cambridge University Press , 2010 .S\u00e6tre , Rune , Kazuhiro Yoshida , Makoto Miwa , Takuya Matsuzaki , Yoshinobu Kano and Junichi Tsujii .", "label": "", "metadata": {}, "score": "53.327827"}
{"text": "We mapped a BioNLP ST entity to a TPS entity if their spans matched or the source entity was entirely contained within the span of the candidate target entity .Unmatched entities were removed from the data .This processing was applied to the BioNLP ST training set , creating a corpus of 6889 entity pairs of which 1119 ( 16 % ) were marked as expressing an association ( positive ) .", "label": "", "metadata": {}, "score": "53.506767"}
{"text": "The configuration of HMMs can be largely simplified by incorporating NLDA .Experiments with large network training .The results of the previous experiment showed large performance advantages for NLDA2 over NLDA1 and the original features , when using either a small number of features , or a \" small \" HMM .", "label": "", "metadata": {}, "score": "53.56379"}
{"text": "Pyysalo S , Ginter F , Heimonen J , Bj\u00f6rne J , Boberg J , J\u00e4rvinen J , Salakoski T : Biolnfer : A Corpus for Information Extraction in the Biomedical Domain .BMC Bioinformatics .View Article .Wang Y , Kim JD , S\u00e6tre R , Pyysalo S , Tsujii J : Investigating heterogeneous protein annotations toward cross - corpora utilization .", "label": "", "metadata": {}, "score": "53.585316"}
{"text": "I. . ... ntences ) are \" shibboleth \" sentences used to distinguish between dialects and are not used in here , leaving a total of 4040 sentences ( SX and SI sentences ) .Given a speech signal x , our task is to label each frame of that signalwith the appropriate ... . by Alexander Gutkin , Er Gutkin , Simon King - In : Proc .", "label": "", "metadata": {}, "score": "53.72088"}
{"text": "As illustrated in one of the experiments presented later , the state dependent targets were shown to perform better than phone level targets .The simpler approach of using fixed ratios for state boundaries was as good as using the Viterbi alignment approach .", "label": "", "metadata": {}, "score": "53.79976"}
{"text": "W .S .B , where S W is the within class covariance matrix and S B is the between class covariance matrix .Often S B is computed as the covariance of the category means ; alternatively , it is sometimes computed as the \" grand \" covariance matrix over all data , ignoring category labels , identical to the covariance matrix used to compute PCA basis vectors .", "label": "", "metadata": {}, "score": "53.804585"}
{"text": "Therefore , an arbitrary number of reduced dimensions can be obtained , independent of the input feature dimensions and the nature of the training targets .A lower dimensional representation of the input features is easily obtained by simply deploying fewer nodes in the middle layer than the input layer .", "label": "", "metadata": {}, "score": "53.839146"}
{"text": "Adverbial positioning has long been studied in linguistics ( e.g .. Affiliated with .Abstract .Background .Event extraction following the GENIA Event corpus and BioNLP shared task models has been a considerable focus of recent work in biomedical information extraction .", "label": "", "metadata": {}, "score": "53.87979"}
{"text": "All hidden nodes and output nodes had a bipolar sigmoidal activation function .After training with backpropagation , all data were transformed by the neural network .In Figure 5 , the original data is shown as blue symbols , and the transformed data is shown by red .", "label": "", "metadata": {}, "score": "53.884552"}
{"text": "else : . word_tuples . append ( ( word , False ) ) .# Create list of sentence using the classifier .for sent in self .classify_segment_sentences ( word_tuples ) : . # sent holds the next sentence list of tokens .", "label": "", "metadata": {}, "score": "53.893196"}
{"text": "# words .Keeping this information allows us to distinguish between .# abbreviations and sentence terminators . tokenizer . tokenize ( full_text ) .# Take tokenized words+spaces and create tuples of ( token , bool ) .# with the bool entry indicating if the token is whitespace .", "label": "", "metadata": {}, "score": "54.008373"}
{"text": "pp .1067 - 1072 , 2010 .Yao - zhong Zhang , Takuya Matsuzaki , Jun'ichi Tsujii .A Simple Approach for HPSG Supertagging Using Dependency Information .In the Proceedings of 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics ( NAACL - HLT'10 ) .", "label": "", "metadata": {}, "score": "54.034744"}
{"text": "The training of the neural network ( NLDA1 and NLDA2 ) requires category information for creating training targets .For the case of databases such as TIMIT , the data is labeled using 61 phone categories , and the starting point for training discriminative transformations would seem to be these phonetic labels .", "label": "", "metadata": {}, "score": "54.088257"}
{"text": "The intersection of tree transducer - based translation models with n - gram language models results in huge dynamic programs for machine translation decoding .We propose a multipass , coarse - to - fine approach in which the language model complexity is incrementally introduced .", "label": "", "metadata": {}, "score": "54.207542"}
{"text": "The intersection of tree transducer - based translation models with n - gram language models results in huge dynamic programs for machine translation decoding .We propose a multipass , coarse - to - fine approach in which the language model complexity is incrementally introduced .", "label": "", "metadata": {}, "score": "54.207542"}
{"text": "Bioinformatics .pp . i374-i381 , June 2010 .Yu , Kun , Yusuke Miyao , Takuya Matsuzaki , Xiangli Wang , Yaozhong Zhang , Kiyotaka Uchimoto , Junichi Tsujii .Comparison of Chinese Treebanks for Corpus - oriented HPSG Grammar Development .", "label": "", "metadata": {}, "score": "54.215157"}
{"text": "As a \" bottom - up \" approach is also more general in not relying on manually constructed resources , we chose to pursue such an approach in this work .Task definition .We term our extraction target gene / protein associations .", "label": "", "metadata": {}, "score": "54.45034"}
{"text": "This allows us to study the interaction of voice and word order alternations in realistic German corpus data .We show that with an appropriately underspecified input , a linguistically informed realisation model trained to regenerate strings from the underlying semantic representation achieves 91.5 % accuracy ( over a baseline of 82.5 % ) in the prediction of the original voice . ...", "label": "", "metadata": {}, "score": "54.507355"}
{"text": "The first experiment was conducted to evaluate the two NLDA versions with various dimensions in the reduced feature space with and without the use of PCA .As input features , 13 DCTCs , computed with 8 ms frames and 2 ms spacing , were represented with 6 DCSCs over a 500 ms block , for a total of 78 features ( 13 DCTCs x 6 DCSCs ) .", "label": "", "metadata": {}, "score": "54.55611"}
{"text": "As event extraction methods initially developed to target the set of events defined in the GENIA / BioNLP ST corpora are now being applied at PubMed scale , it makes sense to ask how much of the full spectrum of gene / protein associations found there they can maximally cover .", "label": "", "metadata": {}, "score": "54.569874"}
{"text": "These results show the NLDA methods based on the state level training targets are able to form highly discriminative features in a dimensionality reduced space .MFCC experiments .For comparison , 39-dimensional MFCC features ( 12 coefficients plus energy with the delta and acceleration terms ) were reduced to 36 dimensions with the same configurations and evaluated .", "label": "", "metadata": {}, "score": "54.574104"}
{"text": "Transactions on Computational Biology and Bioinformatics ( TCBB ) , BioCreative II.5 Special Issue . pp .46pp , IEEE / ACM , 2010 .Matsuzaki , Takuya , Yusuke Miyao , Jun'ichi Tsujii .Probabilistic Context - Free Grammars with Latent Annotations .", "label": "", "metadata": {}, "score": "54.58381"}
{"text": "E .X .X .^ . ) is minimized .That is , .X .^ should approximate X as well as possible , in a mean square error sense .As has been shown in several references ( for example , Duda et al . , 2001 ) , this seemingly intractable problem has a very straightforward solution , provided X is zero mean and multivariate Gaussian .", "label": "", "metadata": {}, "score": "54.584587"}
{"text": "Identification of gene / protein associations .In this section , we present our approach to identifying statements of gene / protein associations .We assume throughout that gene / protein associations are stated through specific words , analogously to the widely applied concepts of interaction words in protein - protein interaction extraction and trigger ( or text binding ) words in event extraction .", "label": "", "metadata": {}, "score": "54.598015"}
{"text": "s techniques , improved speech recognition accuracy may be achieved .Various signal - processing techniques have been proposed for phoneme recognition .Common features used are Linear Predictive Coding ( LPC ) and cepstral coefficients .Hybrid HMMs and neural networks have also be ... . \" ...", "label": "", "metadata": {}, "score": "54.723763"}
{"text": "pp .394 - 400 , Oxford University Press , February 2009 .Conferences .S\u00e6tre , Rune , Kazuhiro Yoshida , Makoto Miwa , Takuya Matsuzaki , Yoshinobu Kano and Jun'ichi Tsujii .AkaneRE Relation Extraction : Protein Interaction and Normalization in the BioCreAtIvE II.5 Challenge .", "label": "", "metadata": {}, "score": "54.987953"}
{"text": "Regularization is done by augmenting the EM training method by a penalty term that favors simple and smooth HMM systems .The penalty term is constructed as a mixture model of negative exponential distributions that is assumed to generate the state dependent emission probabilities of the HMMs .", "label": "", "metadata": {}, "score": "55.027187"}
{"text": "NLDA1 .In the first approach , which is referred to as NLDA1 , the transformed features are produced from the final output layer of the network .This approach is similar to the use of tandem neural networks used in some automatic speech recognition studies ( Hermansky & Sharma , 2000 ; Ellis et al . , 2001 ) .", "label": "", "metadata": {}, "score": "55.18178"}
{"text": "The database used for all experiments reported in the remainder of this chapter is TIMIT .The TIMIT database was developed in the early 1980 's for expediting acoustic - phonetic ASR research ( Garofolo et al . , 1993 ; Zue et al , 1990 ) .", "label": "", "metadata": {}, "score": "55.45907"}
{"text": "View Article .Ohta T , Pyysalo S , Miwa M , Kim JD , Tsujii J : Event Extraction for Post - Translational Modifications .Proceedings of BioNLP'10 .Pyysalo S , Ohta T , Cho HC , Sullivan D , Mao C , Sobral B , Tsujii J , Ananiadou S : Towards Event Extraction from Full Texts on Infectious Diseases .", "label": "", "metadata": {}, "score": "55.46295"}
{"text": "Experiment 2 .To simulate lack of training data , another experiment was conducted .In this experiment , the training data was separated into two groups , with about 50 % in each group .One group of data ( group 1 ) was used for \" training \" transformations while the other data ( group 2 ) was used for training classifiers .", "label": "", "metadata": {}, "score": "55.493813"}
{"text": "April 2010 .Wu , Xianchao , Takuya Matsuzaki , Jun'ichi Tsujii .Improve Syntax - based Translation Using Deep Syntactic Structures .Machine Translation ( Special Issue : Pushing the frontiers of SMT ) .pp .141 - 157 , Springer , 2010 .", "label": "", "metadata": {}, "score": "55.50338"}
{"text": "The neural network features also should be linearly transformed with a principal components transform in order to be effective for use by a Hidden Markov Model .For use with a multi - hidden - state Hidden Markov Model , the nonlinear transform should be trained with state - specific targets , but using \" do n't cares , \" to account for imprecise information about state boundaries .", "label": "", "metadata": {}, "score": "55.62551"}
{"text": "Much of this work draws on the GENIA Event corpus [ 2 ] , a resource of 1500 PubMed abstracts in the domain of transcription factors in human blood cells annotated for genes , proteins and related entities , events and syntax [ 3 - 5 ] .", "label": "", "metadata": {}, "score": "55.662613"}
{"text": "Models are trained and tested using data drawn from the TIMIT database .reserved by traditional speech analysis techniques , which could result in the improved speech recognition .The most common features are Mel Frequency Cepstral Coefficients ( MFCCs ) .", "label": "", "metadata": {}, "score": "55.725388"}
{"text": "Conferences .Matsuzaki , Takuya , Yusuke Miyao and Jun'ichi Tsujii .Probabilistic CFG with Latent Annotations .In the Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics .Michigan , USA , pp .75 - 82 , June 2005 .", "label": "", "metadata": {}, "score": "55.783295"}
{"text": "( 2007 ) , resulting in 2,500,554 features .The training data consists of 2,306 sentences ( 58,771 tokens ) .To evaluate validation error , we use 1,000 sentences ( 30,563 tokens ) and report accuracy ( rate of correct edges in a predicted parse t .. by Ryan Mcdonald - Proceedings of the Conference on Empirical Methods in Natural Language Processing and Natural Language Learning , 2007 . \" ...", "label": "", "metadata": {}, "score": "56.057518"}
{"text": "10.1016/j.tibtech.2010.04.005 .View Article .Kim JD , Ohta T , Tsujii J : Corpus annotation for mining biomedical events from literature .BMC Bioinformatics .View Article .Ohta T , Tateisi Y , Mima H , Tsujii J : GENIA Corpus : An Annotated Research Abstract Corpus in Molecular Biology Domain .", "label": "", "metadata": {}, "score": "56.185207"}
{"text": "However , as GO contains more than 20,000 biological process terms , purely manual identification of terms specifically relevant to frequent associations of entities of interest would require considerable effort .Organization of proposed new event classes into the GENIA ontology .", "label": "", "metadata": {}, "score": "56.44581"}
{"text": "BMC Bioinformatics .2008 , 9 ( Suppl . 3 ) : S6- View Article .Heimonen J , Pyysalo S , Ginter F , Salakoski T : Complex - to - pairwise mapping of biological relationships using a semantic network representation .", "label": "", "metadata": {}, "score": "56.45016"}
{"text": "Results obtained on 175 manually - labeled songs provided an increase in accuracy of about 2 % . by Carsten Brockmann , Jon Oberlander - In Proc . of the UM'05 Workshop on Adapting the Interaction , 2005 . \" ...For a successful and satisfying interaction , a dialogue participant may align their language to be more like that of their interlocutor .", "label": "", "metadata": {}, "score": "56.5214"}
{"text": "The classes would be well separated by a projection onto the first LDA basis vector , but poorly separated by a projection onto the first PCA basis vector .Heteroscedastic Discriminant Analysis ( HDA ) .Another linear transformation technique , related to linear discriminant analysis , but which accounts for the ( very common ) case where within class covariance matrices are not the same for all classes , is called Heterocscedastic Discriminant Analysis ( HDA ) ( Saon et al . , 2000 ) .", "label": "", "metadata": {}, "score": "56.55581"}
{"text": "In the Proceedings of the 5th International Joint Conference on Natural Language Processing ( IJCNLP-2011 ) .[ PDF ] .Articles .Ohta , Tomoko , Matsuzaki , Takuya , Okazaki , Naoaki , Miwa , Makoto , Saetre , Rune , Pyysalo , Sampo and Tsujii , Jun'ichi .", "label": "", "metadata": {}, "score": "56.611977"}
{"text": "Neural networks .In optimizing the design of a neural network , an important consideration is the number of hidden layers and an appropriate number of hidden nodes in each layer .A neural network with no hidden layers can form only simple decision regions , which is not suitable for highly nonlinear and complex speech features .", "label": "", "metadata": {}, "score": "56.614044"}
{"text": "In addition , we perform an experimental evaluation of all algorithms in combination with SVM classifiers for predicting the next parsing action , using data from thirteen languages .We show that all four algorithms give competitive accuracy , although the non - projective list - based algorithm generally outperforms the projective algorithms for languages with a non - negligible proportion of non - projective constructions .", "label": "", "metadata": {}, "score": "56.61904"}
{"text": "For a successful and satisfying interaction , a dialogue participant may align their language to be more like that of their interlocutor .In the first part of this paper , we examine the alignment phenomenon from the viewpoint of personalityrelated , linguistic , sociolinguistic and psycholinguistic research , concluding that some people are stronger aligners than others .", "label": "", "metadata": {}, "score": "56.66719"}
{"text": "Latent Variable Perceptron Algorithm for Structured Classification .In the Proceedings of International Joint Conferences on Artificial Intelligence ( IJCAI ) .Los Angeles , pp .1236 - 1242 , 2009 .[ PDF ] .Wu , Xianchao , Takuya Matsuzaki , Naoaki Okazaki , Yusuke Miyao , Jun'ichi Tsujii .", "label": "", "metadata": {}, "score": "56.741524"}
{"text": "Thus the method is patterned after LDA .In all cases , the dimensionality reduction is accomplished with a Neural Network ( NN ) , which internally encodes data with a reduced number of dimensions .The differences in the methods depend on error criteria used to train the network , the architecture of the network , and the extent to which the reduced dimensions are \" hidden \" in the neural network .", "label": "", "metadata": {}, "score": "56.88655"}
{"text": "Here , as we are interested in particular in texts describing associations between two or more gene / protein related entities , we apply a focused selection , picking only those individual sentences in which two or more mentions co - occur .", "label": "", "metadata": {}, "score": "57.01879"}
{"text": "BMC Bioinformatics .9(Suppl 3 ) .pp .S5 , BioMed Central , Apr 2008 .ISSN 1471 - 2105 .Conferences .Miyao , Yusuke , Rune S\u00e6tre , Kenji Sagae , Takuya Matsuzaki and Jun'ichi Tsujii .Task - Oriented Evaluation of Syntactic Parsers and Their Representations .", "label": "", "metadata": {}, "score": "57.069656"}
{"text": "Similar experiments , with all identical conditions except using either phone level targets , or state level targets without \" do n't cares \" resulted in about 2 % lower accuracies .These results imply that the use of \" do n't cares \" is able to reduce errors introduced by inaccurate determination of state boundaries .", "label": "", "metadata": {}, "score": "57.087975"}
{"text": "Table 1 shows the most frequent such words in PubMed .For this and other word statistics in this section , basic tokenization separating punctuation from words and lowercasing has been applied but stemming or lemmatization is not performed .The distribution suggests that medical topics dominate biomolecular ones overall , with e.g. the word \" patients \" occurring more than three times as often as the word \" protein \" .", "label": "", "metadata": {}, "score": "57.099987"}
{"text": "Recognition performance is further likely to vary by concept depending on the ambiguity and variability of typical forms of expression ( contrast e.g. protein phosphorylation with protein binding ) , leading to bias in frequency estimates .Finally , even given perfect recognition of concepts potentially expressing gene / protein associations it would remain necessary to determine which specific instances actually state such associations .", "label": "", "metadata": {}, "score": "57.130722"}
{"text": "Results .In the present study , our aim is to estimate the coverage of all statements of gene / protein associations in PubMed that existing resources for event extraction can provide .We base our analysis on a recently released corpus automatically annotated for gene / protein entities and syntactic analyses covering the entire PubMed , and use named entity co - occurrence , shortest dependency paths and an unlexicalized classifier to identify likely statements of gene / protein associations .", "label": "", "metadata": {}, "score": "57.181347"}
{"text": "Pitch class profile vectors that represent harmonic information are extracted from the given audio signal .The resulting chord sequence is obtained by running a Viterbi decoder on trained hidden Markov models and subsequent lattice rescoring , applying the language model weight .", "label": "", "metadata": {}, "score": "57.27314"}
{"text": "Latent Variable Perceptron Algorithm for Structured Classification .In the Proceedings of International Joint Conferences on Artificial Intelligence ( IJCAI ) .Los Angeles , pp .1236 - 1242 , 2009 .[ PDF ] .Articles .Oda , Kanae , Jin - Dong Kim , Tomoko Ohta , Daisuke Okanohara , Takuya Matsuzaki , Yuka Tateisi and Jun'ichi Tsujii .", "label": "", "metadata": {}, "score": "57.30964"}
{"text": "1998 ) discusses several theoretical methods for determining these curved subspaces ( manifolds ) within higher dimensionality spaces .Another general method , and the one illustrated and explored in more detail in this chapter , is based on a \" bottleneck \" neural network ( Kramer , 1991 ) .", "label": "", "metadata": {}, "score": "57.401337"}
{"text": "Gene / protein named entities were tagged in all sentences using the BANNER named entity recognition system [ 20 ] trained on the GENETAG corpus [ 16 ] and thus reflect its inclusive definition of gene / protein ( as discussed above ) .", "label": "", "metadata": {}, "score": "57.47303"}
{"text": "Conferences .Matsuzaki , Takuya , Yusuke Miyao and Jun'ichi Tsujii .An Efficient Clustering Algorithm for Class - based Language Models .In the Proceedings of the Seventh Conference on Natural Language Learning ( CoNLL ) at HLT - NAACL 2003 .", "label": "", "metadata": {}, "score": "57.551224"}
{"text": "Figure 10 .Illustrations of a linear activation function ( left ) , a unipolar sigmoid function ( middle ) and a bipolar sigmoid function ( right ) .The weights of the neural network are estimated using the backpropagation algorithm to minimize the distance between the scaled input features and target data .", "label": "", "metadata": {}, "score": "57.59285"}
{"text": "As shown in Figure 18 , both NLDA1 and NLDA2 using the expanded targets lead to a significant increase in accuracy .The NLDA2 accuracies are typically about 2 % higher than NLDA1 accuracies .The use of forced alignment for state boundaries resulted in the highest accuracy of 75.0 % with 64 mixtures .", "label": "", "metadata": {}, "score": "57.78152"}
{"text": "Perceptron training is widely applied in the natural language processing community for learning complex structured models .Like all structured prediction learning frameworks , the structured perceptron can be costly to train as training complexity is proportional to inference , which is frequently non - linear in example sequence length .", "label": "", "metadata": {}, "score": "57.844078"}
{"text": "This inclusiveness permits the identification of associations between more than only the strict gene and gene product entities included in e.g. BioNLP ST annotation [ 4 ] .The corpus annotation includes a specificity constraint that excludes generic , non - named entity references such as DNA sequence from annotation , which is appropriate for our goal to identify associations of specific genes and proteins .", "label": "", "metadata": {}, "score": "57.88571"}
{"text": "Cache models work by interpolating simple language models derived from the recent context with more elaborate , context - independent models .We use the SRILM toolkit [ 28 ] to compute n - gram langua ...Conferences .Andrade , D. , Matsuzaki , T. and Tsujii , J ..", "label": "", "metadata": {}, "score": "57.891487"}
{"text": "s132 J. Nivre et al .Matthias Trautner Kromann , Alberto Lavelli , Haitao Liu , Yuji Matsumoto , Ryan McDonald , Kemal Oflazer , Petya Osenova , Kiril Simov , Yannick Versley , ... . \" ...Parsing algorithms that process the input from left to right and construct a single derivation have often been considered inadequate for natural language parsing because of the massive ambiguity typically found in natural language grammars .", "label": "", "metadata": {}, "score": "57.932053"}
{"text": "Nonlinear Principal Components Analysis ( NLPCA ) .Since the final NN outputs are created from the internal NN representations at the bottleneck layer , the bottleneck outputs can be viewed as the reduced dimensionality version of the data .This idea was tested using pseudo - random data generated so as to cluster on curved subspaces .", "label": "", "metadata": {}, "score": "57.95104"}
{"text": "We have presented an approach to discovering expressions of gene / protein associations from PubMed based on named entity co - occurrences , shortest dependency paths and an unlexicalized classifier to identify likely statements of gene / protein associations .These paths were then used to rank all words in PubMed by the expected number of times they are predicted to express such associations , and 1200 candidate association - expressing words not appearing in the BioNLP'09 shared task data evaluated manually .", "label": "", "metadata": {}, "score": "58.01083"}
{"text": "Training data .For training data , we could potentially draw from a wealth of corpus resources annotated for some form of association between genes / proteins , such as PPI corpora ( see e.g. [ 41 ] ) .However , as we are in particular interested in event extraction approaches , we chose to use the BioNLP ST 2009 data ( the BioNLP ST 2011 datasets were not available when this work was performed ) .", "label": "", "metadata": {}, "score": "58.02519"}
{"text": "corpus .treebank_raw . sents ( ) .for sent in nltk .corpus .treebank_raw . sents ( ) : . tokens . extend ( sent ) .boundaries . add ( offset - 1 ) .# Create training features . punct_features ( tokens , i ) , ( i in boundaries ) ) .", "label": "", "metadata": {}, "score": "58.028076"}
{"text": "These vectors have 48 dimensions and each vector consists of only one peak value to indicate the category .Note that , in the TIMIT case , other reasonable choices for targets would be 61 ( the number of phone label categories ) , or 39 ( the number of collapses phone categories ) .", "label": "", "metadata": {}, "score": "58.07638"}
{"text": "Here , we will for simplicity assume that systems can eventually achieve satisfactory performance for associations for which annotated data is available .In this study , we seek to characterize the full range of associations of specific genes / proteins described in the literature and estimate what coverage of these associations event extraction systems relying on currently available resources can maximally achieve .", "label": "", "metadata": {}, "score": "58.1537"}
{"text": "Figure 7 shows a plot of the values ranked from high to low E. The result was unexpected : the estimate suggests that even though the newly identified association words are drawn from PubMed without subdomain restrictions and include more than only event expressions , expressions of event - type associations using the previously known words are overall much more prominent in PubMed .", "label": "", "metadata": {}, "score": "58.232"}
{"text": "BMC Bioinformatics .9(Suppl 3 ) .pp .S5 , BioMed Central , Apr 2008 .ISSN 1471 - 2105 .Conferences .Sun , Xu , Louis - Philippe Morency , Daisuke Okanohara and Jun'ichi Tsujii .Modeling Latent - Dynamic in Shallow Parsing : A Latent Conditional Model with Improved Inference .", "label": "", "metadata": {}, "score": "58.372448"}
{"text": "Therefore , an additional experiment was performed , using the state level targets with \" do n't cares , \" as mentioned previously , and a very large neural network for transforming features .The state targets were formed using either a constant length ratio ( ratio for 3 states : 1:4:1 ) or a Viterbi forced alignment approach , as described in Section 4.5 .", "label": "", "metadata": {}, "score": "58.400375"}
{"text": "Log - linear and maximum - margin models are two commonly - used methods in supervised machine learning , and are frequently used in structured prediction problems .Efficient learning of parameters in these models is therefore an important problem , and becomes a key factor when learning from very large data sets .", "label": "", "metadata": {}, "score": "58.51143"}
{"text": "The McClosky - Charniak parser produces constituency ( phrase structure ) analyses in the Penn Treebank scheme , with Penn part - of - speech tags .In addition to the these analyses , dependency analyses in the Stanford Dependency ( SD ) scheme [ 27 ] , created from the constituency analyses by automatic conversion using the using the Stanford parser tools [ 28 ] ( Version 1.6.1 ) are provided in the TPS corpus .", "label": "", "metadata": {}, "score": "58.579777"}
{"text": "Scatter plot of 2-D multivariate Gaussian data and first principal components basis vector .No straight line can be a good fit to this data .Linear Discriminant Analysis ( LDA ) .Linear transforms for the purpose of reducing dimensionality while preserving discriminability between pre - defined categories have also long been known about and used ( Wang & Paliwal , 2003 ) , and are usually referred to as Linear Discriminant Analysis ( LDA ) .", "label": "", "metadata": {}, "score": "58.621452"}
{"text": "# loop over each token tuple , using separator boolean .# to collapse abbreviations into single word tokens .for i , tup in enumerate ( sent ) : . if ( tup [ 0 ] [ 0 ] in string . punctuation and not tup [ 0 ] [ 0 ] in ' .", "label": "", "metadata": {}, "score": "58.62567"}
{"text": "The recognition accuracies were further improved by about 3 % with PCA reduced dimensionality features versus the NLDA features for most cases , showing the effectiveness of PCA in de - correlating the network outputs .The accuracies obtained with the original 78 features , and 3 mixture HMMs , are approximately 58 % ( 1 state models ) and 63 % ( 3 state models ) .", "label": "", "metadata": {}, "score": "58.732166"}
{"text": "The main topics addressed are acoustic - phonetic modeling , lexical representation , language modeling , decoding and model adaptation .After a brief summary of experimental results some directions towards usable systems are given .In moving from laboratory systems towards real - world applications , different constraints arise which influence the system design .", "label": "", "metadata": {}, "score": "58.762695"}
{"text": "2009 , 78 ( 12 ) : e39-e46 .10.1016/j.ijmedinf.2009.04.010 .View Article .Bj\u00f6rne J , Heimonen J , Ginter F , Airola A , Pahikkala T , Salakoski T : Extracting Complex Biological Events with Rich Graph - Based Feature Sets .", "label": "", "metadata": {}, "score": "58.820805"}
{"text": "The availability of discriminative learning techniques for the ranking of candidate analyses output by broad - coverage grammars with rich linguistic representations , orig ... . by Bernd Bohnet , Anders Bj\u00f6rkelund , Jonas Kuhn , Wolfgang Seeker , Sina Zarrie\u00df . \" ...", "label": "", "metadata": {}, "score": "58.837276"}
{"text": "Conclusions .Nonlinear dimensionality reduction methods , based on the general nonlinear mapping abilities of neural networks , can be useful for capturing most of the information from high dimensional spectral / temporal features , using a much smaller number of features .", "label": "", "metadata": {}, "score": "58.89498"}
{"text": "All the training sentences ( 4620 sentences ) were used to extract a total of 31,300 vowel tokens for training .All the test sentences ( 1680 sentences ) were used to extract a total of 11,625 vowel tokens for testing .", "label": "", "metadata": {}, "score": "58.956444"}
{"text": "In contrast , the nonlinear technique NLDA based on minimizing classification error was quite effective for improving accuracy .The general form of the NLDA transformer and its relationship to the HMM recognizer are depicted in Figure 7 .NLDA is based on a multilayer bottleneck neural network and performs a nonlinear feature transformation of the input data .", "label": "", "metadata": {}, "score": "59.014553"}
{"text": "However , ASR accuracies obtained with a combination of LDA and MLLT were nearly as good as those obtained with HDA and MLLT .A detailed summary of HDA and MLLT are beyond the scope of this chapter ; however , these methods , either by themselves , or in conjunction with the nonlinear methods described in this chapter warrant further investigation .", "label": "", "metadata": {}, "score": "59.231777"}
{"text": "The number of DCTCs used was 13 , and number of DCS terms was varied from 4 to 7 , for a total number of features ranging from 52 to 91 .These numbers are given for each experiment .Additionally , as a control , one experiment was conducted with Mel - frequency Cepstral Coefficients ( MFCCs ) ( Davis & Mermelstein , 1980 ) , since these MFCC features are most typically used in ASR experiments .", "label": "", "metadata": {}, "score": "59.24818"}
{"text": "Typical choices include a linear activation function , a unipolar sigmoid function and a bipolar sigmoid function as illustrated in Figure 10 .The activation function should match the characteristic of the input or output data .For example , with training targets assigned the values of \" 0 \" and \" 1 \" , a sigmoid function with the outputs in the range of [ 0 , 1 ] is a good candidate for the output layer .", "label": "", "metadata": {}, "score": "59.41799"}
{"text": "Uppsala , Sweden , pp .325 - 334 , Association for Computational Linguistics , July 2010 .Articles .Miyao , Yusuke , Kenji Sagae , Rune S\u00e6tre , Takuya Matsuzaki and Jun'ichi Tsujii .Evaluating Contributions of Natural Language Parsers to Protein - Protein Interaction Extraction .", "label": "", "metadata": {}, "score": "59.47502"}
{"text": "For both NLDA1 and NLDA2 , the networks were configured with 78 - 500 - 36 - 500 - 144 nodes , going from input to output .Figure 18 .Recognition accuracies of the NLDA dimensionality reduced features using the state level targets . \"", "label": "", "metadata": {}, "score": "59.47777"}
{"text": "As expected this basis vector , represented by a straight line , is oriented along the axis with maximum data variation .Figure 1 .Scatter plot of 2-D multivariate Gaussian data and first principal components basis vector .Line is a good fit to data .", "label": "", "metadata": {}, "score": "59.56221"}
{"text": "Thus NTIMIT is more bandlimited ( approximately 300Hz to 3400 Hz ) , more noisy , but has the identical \" raw \" speech .DCTC / DCSC speech features .The modified DCTC is used for representing speech spectra , and the modified DCSC is used to represent spectral trajectories .", "label": "", "metadata": {}, "score": "59.60373"}
{"text": "Figure 5 .Plot of input and output data for pseudo - random 2-D data .The output data ( red line ) is reconstructed data obtained after passing the input data through the trained neural network .In Figure 6 , NLPCA is illustrated by data which falls on a 2-D surface embedded in a 3-D space .", "label": "", "metadata": {}, "score": "59.628338"}
{"text": "We first review some traditional linear methods for dimensionality reduction before proceeding to the nonlinear transformation , the main subject of this chapter .Principal Components Analysis ( PCA ) .Principal Components Analysis ( PCA ) , also known as the Karhunen - Loeve Transform ( KLT ) , has been known of and in use for nearly a century ( Fodor , 2002 ; Duda et al . , 2001 ) , as a linear method for dimensionality reduction .", "label": "", "metadata": {}, "score": "59.637264"}
{"text": "Compared to the PCA and LDA reduced features , the NLDA1 and NLDA2 features performed considerably better for both the 1-state and 3-state HMMs .For the case of 3-state HMMs , the transformed features reduced to 24 dimensions resulted in the highest accuracy of 69.3 % for NLDA1 .", "label": "", "metadata": {}, "score": "59.700233"}
{"text": "Of the text material in the database , two dialect sentences ( SA sentences ) were designed to expose the specific variants of the speakers and were read by all 630 speakers .There are 450 phonetically - compact sentences ( SX sentences ) which provide a good coverage of pairs of phones .", "label": "", "metadata": {}, "score": "59.702118"}
{"text": "Overall statistics .As expected for a corpus of English , the most frequent words in PubMed are prepositions , determiners , conjunctions , forms of the copula ( \" is \" , \" are \" etc . ) and , if non - word tokens are included , punctuation .", "label": "", "metadata": {}, "score": "59.77403"}
{"text": "The database is further divided into a suggested training set ( 4620 sentences , 462 speakers ) and suggested test set ( 1680 sentences , 168 speakers ) .The training and test sets are balanced in terms of representing dialect regions and male / female speakers .", "label": "", "metadata": {}, "score": "59.841667"}
{"text": "In this paper , we ... . by Michael Collins , Amir Globerson , Terry Koo , Xavier Carreras , Peter L. Bartlett , 2008 . \" ...Log - linear and maximum - margin models are two commonly - used methods in supervised machine learning , and are frequently used in structured prediction problems .", "label": "", "metadata": {}, "score": "59.956585"}
{"text": "For example , the NLDA2 features modeled by 3-state HMMs with 3 mixtures resulted in an accuracy of 69.4 % versus 63.2 % for the original features .Figure 16 .Figure 17 .Accuracies of the NLDA1 and NLDA2 features using 1-state ( top panel ) and 3-state HMMs ( bottom panel ) with various numbers of mixtures .", "label": "", "metadata": {}, "score": "59.9825"}
{"text": "View Article .Ogren PV , Cohen KB , Acquaah - Mensah GK , Eberlein J , Hunter L : The compositional structure of Gene Ontology terms .Proceedings of the PSB'04 .Blaschke C , Leon E , Krallinger M , Valencia A : Evaluation of BioCreAtlvE assessment of task 2 . BMC Bioinformatics .", "label": "", "metadata": {}, "score": "60.20135"}
{"text": "In the framework of phonemic speech recognition using Hidden Markov Models ( HMMs ) together with codebooks trained by Learning Vector Quantization ( LVQ ) , a novel way to model context - dependencies in speech is presented .We use LVQ to map acoustic contextual data into context - independent phonemic form ... \" .", "label": "", "metadata": {}, "score": "60.337814"}
{"text": "The linear time complexity of the stack - based algorithms gives them an advantage with respect to efficiency both in learning and in parsing , but the projective list - based algorithm turns out to be equally efficient in practice .Moreover , when the projective algorithms are used to implement pseudo - projective parsing , they sometimes become less efficient in parsing ( but not in learning ) than the non - projective list - based algorithm .", "label": "", "metadata": {}, "score": "60.496685"}
{"text": "Speech recognition has been a very active area of research over the past twenty years .Despite an evident progress , it is generally agreed by the practitioners of the field that performance of the current speech recognition systems is rather suboptimal and new ap - proaches are needed .", "label": "", "metadata": {}, "score": "60.72749"}
{"text": "We then describe and analyze two families of such algorithms : stack - based and list - based algorithms .In the former family , which is restricted to projective dependency structures , we describe an arc - eager and an arc - standard variant ; in the latter family , we present a projective and a nonprojective variant .", "label": "", "metadata": {}, "score": "60.79818"}
{"text": "pp .337 - 354 , MIT Press , March 2010 .Conferences .Sun , Xu , Hisashi Kashima , Takuya Matsuzaki and Naonori Ueda .Averaged Stochastic Gradient Descent with Feedback : An Accurate , Robust , and Fast Training Method .", "label": "", "metadata": {}, "score": "60.858017"}
{"text": "( 2004 ) ( for English ) , using a different parsing algorithm first presented in Nivre ( 2003 ) . by Joakim Nivre , Ryan Mcdonald - In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics : Human Language Technologies ( ACL-08 : HLT , 2008 . \" ...", "label": "", "metadata": {}, "score": "60.883183"}
{"text": "We find that the HMMs es - timated by EM generally assign a roughly equal number of word tokens to each hid - den state , while the empirical distribution of tokens ... \" .This paper investigates why the HMMs es - timated by Expectation - Maximization ( EM ) produce such poor results as Part - of - Speech ( POS ) taggers .", "label": "", "metadata": {}, "score": "60.94772"}
{"text": "In c ) , two positive pairs , ( Raf-1 , MAP kinase ) and ( Raf-1 , MAPK ) , are extracted due to the equivalence relation .Finally , to make this pair data consistent with the TPS event spans , tokenization and other features , we aligned the entity annotations of the two corpora .", "label": "", "metadata": {}, "score": "61.232944"}
{"text": "In one of these methods , referred to as nonlinear PCA ( NLPCA ) , the goal of the nonlinear transformation is to minimize the mean square error between features estimated from reduced dimensionality features and original features .Thus this method is patterned after PCA .", "label": "", "metadata": {}, "score": "61.250996"}
{"text": "Ninomiya , Takashi , Takuya Matsuzaki , Yoshimasa Tsuruoka , Yusuke Miyao and Jun'ichi Tsujii .Extremely Lexicalized Models for Accurate and Fast HPSG Parsing .In the Proc . of EMNLP 2006 .Sydney , Australia , pp .155 - -163 , July 2006 .", "label": "", "metadata": {}, "score": "61.269985"}
{"text": "Conferences .Okanohara , Daisuke , Kunihiko Sadakane .A Linear - Time Burrows - Wheeler Transform using Induced Sorting .In the Proc . of SPIRE 16th String Processing and Information Retrieval Symposium .pp .90 - -101 , Aug 2009 .", "label": "", "metadata": {}, "score": "61.350086"}
{"text": "Given the high dimensionality of speech feature spaces used for automatic speech recognition , typically 39 or more , it is not feasible to visualize the distribution of data in feature space .It is possible that a reduced dimensionality subspace obtained by linear methods , such as PCA or LDA , forms an effective , or at least adequate subspace for implementing automatic speech recognition systems with a reduced dimensionality feature space .", "label": "", "metadata": {}, "score": "61.452236"}
{"text": "56 - 64 , 2009 .Yao - zhong Zhang , Takuya Matsuzaki , Jun'ichi Tsujii .HPSG Supertagging : A Sequence Labeling View .In the Proceedings of 11th International Conference on Parsing Technology ( IWPT'09 ) .pp .210 - 213 , 2009 .", "label": "", "metadata": {}, "score": "61.682915"}
{"text": "def punct_features2 ( self , tokens , i ) : . isupper ( ) , . ' prevword ' : tokens [ i - 1 ] [ 0 ] . lower ( ) , . ' punct ' : tokens [ i ] [ 0 ] , . '", "label": "", "metadata": {}, "score": "61.798603"}
{"text": "In the The 23rd Pacific Asia Conference on Language , Infermation and Cumputation .December 2009 .[ PDF ] .Articles .Oda , Kanae , Jin - Dong Kim , Tomoko Ohta , Daisuke Okanohara , Takuya Matsuzaki , Yuka Tateisi and Jun'ichi Tsujii .", "label": "", "metadata": {}, "score": "62.108826"}
{"text": "Etzioni O , Banko M , Soderland S , Weld DS : Open information extraction from the web .Commun .ACM .View Article .Banko M , Etzioni O : The Tradeoffs Between Open and Traditional Relation Extraction .Proceedings of ACL - HLT'08 .", "label": "", "metadata": {}, "score": "62.228973"}
{"text": "This paper addresses a data - driven surface realisation model based on a large - scale reversible grammar of German .We investigate the relationship between the surface realisation performance and the character of the input to generation , i.e. its degree of underspecification .", "label": "", "metadata": {}, "score": "62.35233"}
{"text": "This paper addresses a data - driven surface realisation model based on a large - scale reversible grammar of German .We investigate the relationship between the surface realisation performance and the character of the input to generation , i.e. its degree of underspecification .", "label": "", "metadata": {}, "score": "62.35233"}
{"text": "In the max - margin case , O ( 1 \u03b5 ) EG updates are required to reach a given accuracy \u03b5 in the dual ; in contrast , for log - linear models only O(log ( 1/\u03b5 ) ) updates are required .", "label": "", "metadata": {}, "score": "62.478714"}
{"text": "Conclusions .We present a first estimate of the overall coverage of gene / protein associations provided by existing resources for event extraction .Our results suggest that for event - type associations this coverage may be over 90 % .We also identify several biologically significant associations of genes and proteins that are not addressed by these resources , suggesting directions for further extension of extraction coverage .", "label": "", "metadata": {}, "score": "62.77164"}
{"text": "This paper introduces a method for regularization of HMM systems that avoids parameter overfitting caused by insufficient training data .Regularization is done by augmenting the EM training method by a penalty term that favors simple and smooth HMM systems .The penalty term is constructed as a m ... \" .", "label": "", "metadata": {}, "score": "63.01433"}
{"text": "Authors ' Affiliations .Department of Computer Science , University of Tokyo .School of Computer Science , University of Manchester .National Centre for Text Mining , University of Manchester .References .Ananiadou S , Pyysalo S , Tsujii J , Kell DB : Event extraction for systems biology by text mining the literature .", "label": "", "metadata": {}, "score": "63.496994"}
{"text": "Both PCA and LDA are based on linear , i.e. matrix multiplication , transformations .For the case of PCA , the transformation is based on minimizing mean square error between original data vectors and data vectors that can be estimated from the reduced dimensionality data vectors .", "label": "", "metadata": {}, "score": "63.50228"}
{"text": "Efficient HPSG Parsing with Supertagging and CFG - filtering .In the Proceedings of the Twentieth International Joint Conference on Artificial Intelligence .January 2007 .[ gzipped PS ] [ PS ] [ PDF ] [ slide ] .PhD Theses .", "label": "", "metadata": {}, "score": "63.624958"}
{"text": "Ohta T , Pyysalo S , Miwa M , Tsujii J : Event Extraction for DNA Methylation .Proceedings of SMBM'10 .Pyysalo S , Ohta T , Miwa M , Tsujii J : Towards Exhaustive Event Extraction for Protein Modifications .", "label": "", "metadata": {}, "score": "63.643005"}
{"text": "RegexpTokenizer ) : def _ _ init__(self ) : nltk.tokenize.RegexpTokenizer .def _ _ init _ _ ( self ) : . nltk . tokenize . RegexpTokenizer .Note that multiple successive white space characters are treated as one token . ; previous word only one char long ? isupper ( ) , ' prevword ' :", "label": "", "metadata": {}, "score": "63.83485"}
{"text": "24 - S. A. Zahorian , T. Singh , H. Hu , 2007 Dimensionality Reduction of Speech Features using Nonlinear Principal Components Analysis .Proc .INTERSPEECH ' 07 , 1134 1137 , Antwerb , Belgium , Aug. 27 - 31 , 2007 .", "label": "", "metadata": {}, "score": "63.866936"}
{"text": "While in speech recognition the principal concern is ... \" .This paper provides an overview of the state - of - the - art in laboratory speaker - independent , large vocabulary continuous speech recognition ( LVCSR ) systems with a view towards adapting such technology to the requirements of real - world applications .", "label": "", "metadata": {}, "score": "64.1645"}
{"text": "Most frequent words on shortest dependency paths connecting two gene / protein entity mentions in PubMed .Path probabilities .Entities often co - occur in text without any association being stated between them , but some shortest dependency path can be found connecting ( nearly ) all co - occurring entities .", "label": "", "metadata": {}, "score": "64.53021"}
{"text": "Illustration of TPS corpus annotations for an example sentence .Sentence splitting and constituency syntax not shown .All PubMed documents in the TPS corpus were initially processed with the GENIA sentence splitter with simple heuristic post - processing to correct some errors from the machine learning - based splitter [ 19 ] .", "label": "", "metadata": {}, "score": "64.536385"}
{"text": "A total of 1890 phonetically - diverse sentences ( SI sentences ) were selected from existing text sources to add diversity in sentence types and phonetic contexts .Each speaker read 3 of these sentences , with each text being read only by a single speaker .", "label": "", "metadata": {}, "score": "64.972145"}
{"text": "We demonstrate the effectiveness of the approach in a series of dependency parsing experiments on the Penn Treebank and Prague Dependency Treebank , and we show that the cluster - based features yield substantial gains in performance across a wide range of conditions .", "label": "", "metadata": {}, "score": "65.02453"}
{"text": "Author Keywords source - channel key - target resizing , language model , touch model . ... odel predicts that it is very unlikely compared to the key ' s ' .The key - target outlines are shown in heavy lines . \" ...", "label": "", "metadata": {}, "score": "65.14958"}
{"text": "This article has been published as part of Journal of Biomedical Semantics Volume 2 Supplement 5 , 2011 : Proceedings of the Fourth International Symposium on Semantic Mining in Biomedicine ( SMBM ) .Competing interests .The authors declare that they have no competing interests .", "label": "", "metadata": {}, "score": "65.16155"}
{"text": "Bj\u00f6rne J , Ginter F , Pyysalo S , Tsujii J , Salakoski T : Scaling up Biomedical Event Extraction to the Entire PubMed .Proceedings of BioNLP'10 .Gerner M , Nenadic G , Bergman C : LINNAEUS :A species name identification system for biomedical literature .", "label": "", "metadata": {}, "score": "65.36541"}
{"text": "Figure 17 .Accuracies of the NLDA1 and NLDA2 features using 1-state ( top panel ) and 3-state HMMs ( bottom panel ) with various numbers of mixtures .Figure 18 .Recognition accuracies of the NLDA dimensionality reduced features using the state level targets . \"", "label": "", "metadata": {}, "score": "65.37966"}
{"text": "Figure 8 .Use of network outputs in NLDA1 . NLDA2 .Figure 9 illustrates the use of network outputs in NLDA2 .These two versions of NLDA were experimentally tested , with and without PCA following the neural network transformer , with some variations of the nonlinearities in the networks .", "label": "", "metadata": {}, "score": "65.42589"}
{"text": "We further grouped the new event statements into event classes using the Gene Ontology [ 13 ] for reference and identified event classes that were not previously included in the GENIA event ontology .This process suggested 18 event classes that were not previously considered in GENIA resources , shown in Figure 6 with a tentative proposal on how these classes could be organized into the GENIA ontology and examples of identified words expressing each new event type .", "label": "", "metadata": {}, "score": "65.66465"}
{"text": "Airola A , Pyysalo S , Bjorne J , Pahikkala T , Ginter F , Salakoski T : All - paths graph kernel for protein - protein interaction extraction with evaluation of cross - corpus learning .BMC Bioinformatics .2008 , 9 ( Suppl 11 ) : S2 - 10.1186/1471 - 2105 - 9-S11-S2 .", "label": "", "metadata": {}, "score": "65.70342"}
{"text": "We report excellent results for a speaker dependent task for Finnish . \" ...Speech recognition has been a very active area of research over the past twenty years .Despite an evident progress , it is generally agreed by the practitioners of the field that performance of the current speech recognition systems is rather suboptimal and new ap - proaches are needed .", "label": "", "metadata": {}, "score": "65.73909"}
{"text": "This study is based on the 2009 distribution of the full PubMed literature database , encompassing approximately 18 million citations of biomedical domain scientific articles .Figure 1 illustrates these annotations .Note that while the original focus of the corpus is on BioNLP ST events , we ignore the event annotations of the corpus .", "label": "", "metadata": {}, "score": "66.158676"}
{"text": "Various numbers of states and mixtures were evaluated as described in the following experiments .In all cases diagonal covariance matrices were used .For final evaluations of accuracy , some of these 48 monophones were combined to create the \" standard \" set of 39 phone categories .", "label": "", "metadata": {}, "score": "66.163956"}
{"text": "Building on previous work using macroscopic exploration of the parameter space of an ( artificial ) neural microcircuit , we investigate the possibility of using a liquid st ... \" .Abstract - The applicability of complex networks of spiking neurons as a general purpose machine learning technique remains open .", "label": "", "metadata": {}, "score": "66.2293"}
{"text": "View Article .Gerner M , Nenadic G , Bergman CM : An Exploration of Mining Gene Expression Mentions and Their Anatomical Locations from Biomedical Text .Proceedings of BioNLP'10 .The Gene Ontology Consortium : Gene Ontology : tool for the unification of biology .", "label": "", "metadata": {}, "score": "67.17859"}
{"text": "and self .classifier . classify ( self . sents . append ( words [ start : i + 1 ] ) .if start & lt ; len ( words ) : . sents . append ( words [ start : ] ) .", "label": "", "metadata": {}, "score": "67.261215"}
{"text": "In ( Emami and Jelinek , 2005 ) a clustering algorithm is ... . ...w these clusterings are obtained and how much refinement is optimal for each pass .Note that unlikely in the parsing scenario Chapter 2 where the projection state space was obvious and we only needed to estimate the pa ... . by Asela Gunawardana , Tim Paek , Christopher Meek - Proc . IUI & apos;10 .", "label": "", "metadata": {}, "score": "67.28861"}
{"text": "This estimate of coverage is a first attempt and involves many uncertain factors and potential sources of error , calling for more research .Declarations .Acknowledgments .This study is an extension of research first presented at SMBM 2010 , Hinxton , Cambridge , U.K. We would like to thank the anonymous reviewers for their many insightful comments .", "label": "", "metadata": {}, "score": "67.64664"}
{"text": "Most frequent words in sentences containing two or more gene / protein entity mentions in PubMed .Dependency paths .The TPS corpus contains both constituency and dependency analyses of sentence syntax for all sentences with at least one gene / protein mention .", "label": "", "metadata": {}, "score": "68.81746"}
{"text": "The general network configuration is shown in Figure 4 .Figure 4 .Architecture of Bottleneck Neural Network .If data lies along a single curved line in a higher dimensionality space , 1 node in the bottleneck layer should be sufficient .", "label": "", "metadata": {}, "score": "68.89008"}
{"text": "In the Proceedings of the 12th international conference on Computational linguistics and intelligent text processing .Lecture Notes in Computer Sciencepp .( To Appear ) , Springer Verlag , 2011 .Hatori , Jun , Takuya Matsuzaki , Yusuke Miyao and Jun'ichi Tsujii .", "label": "", "metadata": {}, "score": "69.01338"}
{"text": "119 - -126 , 2003 .[PDF ] Named entity recognition of follow - up and time information in 20,000 radiology reports .Yan Xu , Junichi Tsujii , and Eric Chang 28 May 2012 .Abstract .Objective : To develop a system to extract follow - up information from radiology reports .", "label": "", "metadata": {}, "score": "69.43965"}
{"text": "In the Proceedings of International Workshop on Spoken Language Translation ( IWSLT ) .Tokyo , Japan , pp .99 - 106 , December 2009 .Wang , Xiangli , Shunya Iwasawa , Yusuke Miyao , Takuya Matsuzaki and Jun'ichi Tsujii .", "label": "", "metadata": {}, "score": "70.183136"}
{"text": "21 - S. A. Zahorian , D. Qian , A. J. Jagharghi , 1991 Acoustic - phonetic transformations for improved speaker - independent isolated word recognition .Proc .ICASSP'91 , 561 564 .Toronto , Ontario , Canada , May 14 - 17 , 1991 .", "label": "", "metadata": {}, "score": "70.610596"}
{"text": "Kim JD , Ohta T , Pyysalo S , Kano Y , Tsujii J : Overview of BioNLP'09 Shared Task on Event Extraction .Proceedings of BioNLP'09 Shared Task .Kim JD , Pyysalo S , Ohta T , Bossy R , Nguyen N , Tsujii J : Overview of BioNLP Shared Task 2011 .", "label": "", "metadata": {}, "score": "70.83852"}
{"text": "SP and TO conceived of the study .SP designed and implemented the experiments and drafted the manuscript .TO performed the manual evaluation and analysis and helped draft the manuscript .JT participated in the study design and coordination and helped draft the manuscript .", "label": "", "metadata": {}, "score": "71.04337"}
{"text": "The event annotation of the GENIA corpus was originally designed to cover events discussed in publications on a limited subdomain of biomolecular science .It could thus be assumed that the event types and the specific statements annotated in GENIA would have only modest coverage of all gene / protein association types and statements in PubMed .", "label": "", "metadata": {}, "score": "71.572784"}
{"text": "Results : Four experiments conducted using 20 000 radiology reports showed that the CRF recognizer achieved high performance without time - consuming feature engineering and that the LSP classifier further improved the performance of the CRF recognizer .The performance of the current system is P\u00bc0.90 , R\u00bc0.86 , F\u00bc0.88 in the exact matching setting and P\u00bc0.98 , R\u00bc0.93 , F\u00bc0.95 in the inexact matching setting .", "label": "", "metadata": {}, "score": "71.69215"}
{"text": "Figure 14 .Figure 15 .Illustration of the state level training targets with \" do n't cares . \"The -1 values are used to denote \" do n't cares . \"Two approaches are used to determine state boundaries .", "label": "", "metadata": {}, "score": "72.04488"}
{"text": "The state training targets with \" do n't cares \" uses \" do n't care \" states for each phoneme model , so that one neural network trained with the targets can generate state dependent outputs .As illustrated in Figure 15 , the phone - specific training targets in Figure 14 are expanded to 144 dimensions by duplicating the phoneme specific target by the required number of the states .", "label": "", "metadata": {}, "score": "72.9075"}
{"text": "sentence . append ( tup [ 0 ] ) . elif ( tup [ 1 ] ) : . # space character - finish a word token . sentence . append ( tok + tup [ 0 ] ) .# penultimate end of the sentence - break off the punctuation . sentence . append ( tok + tup [ 0 ] ) .", "label": "", "metadata": {}, "score": "73.20091"}
{"text": "Thus the estimation of state boundary information is required .This boundary information may be in error due to the nature of unclear state boundaries and the lack of a reliable estimation approach .Therefore , in the discriminative training process , \" do n't cares \" were used to account for this lack of precision in determining state boundaries .", "label": "", "metadata": {}, "score": "74.17495"}
{"text": "Proc .ICASSP ' 97 , 1011 1014 , Munich , Germany , April 21 - 24 , 1997 .23 - S. A. Zahorian , A. M. Zimmer , F. Meng , 2002 Vowel Classification for Computer - based Visual Feedback for Speech Training for the Hearing Impaired , Proc .", "label": "", "metadata": {}, "score": "75.6042"}
{"text": "Ninomiya , Takashi , Takuya Matsuzaki , Yusuke Miyao and Jun'ichi Tsujii .A log - linear model with an n - gram reference distribution for accurate HPSG parsing .In the Proceedings of IWPT 2007 .June 2007 .Prague , Czech Republic .", "label": "", "metadata": {}, "score": "76.68948"}
{"text": "These sentences contain 25.4 million entity mentions ; approximately 70 % of the corpus total .Table 2 shows the most frequent words in sentences with at least two tagged protein mentions .The list suggests that this simple selection is sufficient to identify a subset of PubMed where biomolecular topics are prominent : both \" protein \" and \" expression \" appear ranked near the top .", "label": "", "metadata": {}, "score": "76.972885"}
{"text": "The targets were chosen as the 48 ( collapsed ) phones in the training data .The number of hidden layers was experimentally determined as well as the number of nodes included in those layers .However , most typically three hidden layers were used .", "label": "", "metadata": {}, "score": "77.15044"}
{"text": "A Tutorial , Institute for Signal and Information Processing , Department of Electrical and Computer Engineering , Mississippi State University .Tools . by Terry Koo , Xavier Carreras , Michael Collins - In Proc .ACL / HLT , 2008 . \" ...", "label": "", "metadata": {}, "score": "77.71998"}
{"text": "if len ( tok ) & gt ; 0 : . sentence . append ( tok ) . sentences . append ( sentence ) .# return the resulting list of sentences . return sentences .The comments should explain most of what is happening here .", "label": "", "metadata": {}, "score": "78.7809"}
{"text": "Pyysalo S , Ohta T , Tsujii J : Overview of the Entity Relations ( REL ) supporting task of BioNLP Shared Task 2011 .Proceedings of BioNLP Shared Task 2011 Workshop .Copyright .\u00a9 Pyysalo et al ; licensee BioMed Central Ltd. 2011 .", "label": "", "metadata": {}, "score": "79.06104"}
{"text": "Soft keyboards offer touch - capable mobile and tabletop devices many advantages such as multiple language support and space for larger graphical displays .On the other hand , because soft keyboards lack haptic feedback , users often produce more typing errors .", "label": "", "metadata": {}, "score": "79.53407"}
{"text": "Soft keyboards offer touch - capable mobile and tabletop devices many advantages such as multiple language support and space for larger graphical displays .On the other hand , because soft keyboards lack haptic feedback , users often produce more typing errors .", "label": "", "metadata": {}, "score": "79.53407"}
{"text": "Jeju Island , Korea , Springer - Verlag , October 2005 .[PDF ] \" ...We describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation .This method requires a source - language dependency parser , target language word segmentation and an unsupervised word alignment compo ... \" .", "label": "", "metadata": {}, "score": "79.83232"}
{"text": "Tools . by Mark Johnson - In : Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ( EMNLP - CoNLL ) .Prague , Czech Republic : Association for Computational Linguistics , 2007 . \" ...", "label": "", "metadata": {}, "score": "82.64076"}
{"text": "Gene / protein mentions .The automatic tagging for mentions of gene / protein entities in the TPS corpus covers a total of 36.4 million gene / protein mentions in 5.4 million documents , approximately 30 % of all PubMed citations .", "label": "", "metadata": {}, "score": "84.54859"}
{"text": "BMC Bioinformatics .11(Suppl 5 ) .pp . P7 , 2010 .DOI:10.1186/1471 - 2105 - 11-S5-P7 .Kemper , Brian , Takuya Matsuzaki , Yukiko Matsuoka , Yoshimasa Tsuruoka , Hiroaki Kitano , Sophia Ananiadou and Jun'ichi Tsujii .", "label": "", "metadata": {}, "score": "84.81741"}
