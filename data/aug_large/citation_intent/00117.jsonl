{"text": "However , this may not have been the central motivation for introducing deep structure .Transformations had been proposed prior to the development of deep structure as a means of increasing the mathematical and descriptive power of context - free grammars .", "label": "", "metadata": {}, "score": "34.61531"}
{"text": "It extracts linguistic information automatically from corpora .The outcome of TBL is an ordered sequence of transformations of the form as shown below .A typical transformation - based learner has an initial state annotator , a set of transformations and an objective function .", "label": "", "metadata": {}, "score": "40.561577"}
{"text": "The system is based on a noisy - channel model and its development requires no linguistic knowledge , but only annotated texts .Therefore , it has ... \" .In this paper we present a system which automatically corrects disfluencies such as repairs and restarts typically occurring in spontaneously spoken speech .", "label": "", "metadata": {}, "score": "40.81489"}
{"text": "Terms such as \" transformation \" can give the impression that theories of transformational generative grammar are intended as a model for the processes through which the human mind constructs and understands sentences .Chomsky is clear that this is not in fact the case : a generative grammar models only the knowledge that underlies the human ability to speak and understand .", "label": "", "metadata": {}, "score": "40.88615"}
{"text": "Transformations actually come in two types : ( i ) the post - Deep structure kind mentioned above , which are string or structure changing , and ( ii ) Generalized Transformations ( GTs ) .Generalized transformations were originally proposed in the earliest forms of generative grammar ( e.g. , Chomsky 1957 ) .", "label": "", "metadata": {}, "score": "43.27773"}
{"text": "In 1998 , Chomsky suggested that derivations proceed in phases .The distinction of Deep Structure vs. Surface Structure is not present in Minimalist theories of syntax , and the most recent phase - based theories also eliminate LF and PF as unitary levels of representation .", "label": "", "metadata": {}, "score": "43.425888"}
{"text": "[ 0091 ] Classes 2 - 4 of atomic paraphrasing transformation are active and passive exchange , reordering of sentence components , and realization in different syntactic categories , respectively .Paraphrasing of classes 2 - 4 mainly involves word re - ordering following a set of syntactic patterns .", "label": "", "metadata": {}, "score": "44.563133"}
{"text": "This phonetic lookup can be used to retrieve a misspelled word in a dictionary or a database , or in a text editor to suggest corrections .Such rules are also necessary to formalize grapheme - phoneme correspondences in speech synthesis architecture .", "label": "", "metadata": {}, "score": "45.150932"}
{"text": "[ need quotation to verify ] Chomsky developed a formal theory of grammar where transformations manipulated not just the surface strings , but the parse tree associated with them , making transformational grammar a system of tree automaton .( For more details see the Transformations section below . )", "label": "", "metadata": {}, "score": "46.780052"}
{"text": "The performance of the measures is evaluated on two different translation tasks : on spontaneously spoken dialogues from the domain of appointment scheduling , and on a collection of technical manuals . \" ...Abstract - Reordering is important problem to be considered when translating between language pairs with different word orders .", "label": "", "metadata": {}, "score": "47.185688"}
{"text": "This algorithm is initiated with a list of pre - defined lexical pairs , and learns atomic paraphrasing patterns based on the lexical pair list .The learned patterns are then used to expand the lexical pair list which makes the learning a recursive procedure .", "label": "", "metadata": {}, "score": "47.19638"}
{"text": "This algorithm is initiated with a list of pre - defined lexical pairs , and learns atomic paraphrasing patterns based on the lexical pair list .The learned patterns are then used to expand the lexical pair list , making the learning a recursive procedure .", "label": "", "metadata": {}, "score": "47.34567"}
{"text": "Language modeling is critical and indispensable for many natural language ap - plications such as automatic speech recognition and machine translation .Due to the complexity of natural language grammars , it is almost impossible to construct language models by a set of linguistic rules ; therefore statistical techniques have been dominant for language modeling over the last few decades .", "label": "", "metadata": {}, "score": "48.04106"}
{"text": "First , the sentence is broken into phrases , that are independently translated as blocks to targ ... \" ...This thesis concerns the problem of unknown or out - of - vocabulary ( 00V ) words in continuous speech recognition .", "label": "", "metadata": {}, "score": "48.04352"}
{"text": "In this paper , we present several confidence measures for ( statistical ) machine translation .We introduce word posterior probabilities for words in the target sentence that can be determined either on a word graph or on an N best list .", "label": "", "metadata": {}, "score": "48.23596"}
{"text": "In this paper , we present several confidence measures for ( statistical ) machine translation .We introduce word posterior probabilities for words in the target sentence that can be determined either on a word graph or on an N best list .", "label": "", "metadata": {}, "score": "48.23596"}
{"text": "A grammar that achieves explanatory adequacy has the additional property that it gives an insight into the underlying linguistic structures in the human mind ; that is , it does not merely describe the grammar of a language , but makes predictions about how linguistic knowledge is mentally represented .", "label": "", "metadata": {}, "score": "48.431786"}
{"text": "The earliest conceptions of transformations were that they were construction - specific devices .For example , there was a transformation that turned active sentences into passive ones .A different transformation raised embedded subjects into main clause subject position in sentences such as \" John seems to have gone \" ; and yet a third reordered arguments in the dative alternation .", "label": "", "metadata": {}, "score": "48.437527"}
{"text": "This will result in both limited precision and high recall rate .Given the importance of automatic paraphrasing , especially in the context of natural language processing , it is desirable to discover new ways that may improve paraphrasing from various aspects .", "label": "", "metadata": {}, "score": "49.30686"}
{"text": "Without reordering capabilities , sentences can be translated correctly only in case when both languages implied in translation have a similar word order .When translating is between language pairs with high disparity in word order , word reordering is extremely desirable for translation accuracy improvement .", "label": "", "metadata": {}, "score": "49.469147"}
{"text": "Semantic paraphrasing refers to non - decomposable combination of lexical substitution and syntactic variation .The present atomic paraphrasing method recognizes multiple major paraphrasing transformation classes in each of these levels .[ 0041 ] FIG .3 is a list of fifteen exemplary paraphrasing transformation classes .", "label": "", "metadata": {}, "score": "49.573166"}
{"text": "The problems associated with the complexity of the model are discussed , and possible solutions are proposed .An implementation of the model , which includes some of these solutions , is d ... \" .The Joint Probability Phrase - based Model of Statical Machine Translation , proposed by Marcu and Wong , is explored .", "label": "", "metadata": {}, "score": "49.668724"}
{"text": "However , they are still present in tree - adjoining grammar as the Substitution and Adjunction operations , and they have recently re - emerged in mainstream generative grammar in Minimalism , as the operations Merge and Move .^ Chomsky , Noam ( 1965 ) .", "label": "", "metadata": {}, "score": "49.78765"}
{"text": "A new feature enforcing morphological constraints has recently been added to this paradigm .We define \" morphs \" to be somewhat like syllable units of a word , but each of them are tagged morphologically , and associated with both an orthographic sequence and a phonemic representation .", "label": "", "metadata": {}, "score": "49.78949"}
{"text": "For example , sub - lexical linguistic information would be very useful in providing linguistic support for previously unseen words , and dynamic reliability modeling may help improve recognition robustness for poorly articulated speech .In this thesis Transformational grammar .In linguistics , a transformational grammar or transformational - generative grammar ( TG , TGG ) is a generative grammar , especially of a natural language , that involves the use of defined operations called transformations to produce new sentences from existing ones .", "label": "", "metadata": {}, "score": "51.14594"}
{"text": "Furthermore , a recognition error due to an OOV word tends to spread errors into neighboring words ; dramatically degrading overall recognition performance . \" ...Letter - to - sound rules , also known as grapheme - to - phoneme rules , are important computational tools and have been used for a variety of purposes including word or name lookups for database searches and speech synthesis .", "label": "", "metadata": {}, "score": "51.439514"}
{"text": "Therefore , it has large potential for rapid deployment and the adaptation to new target languages .The experiments were conducted on spontaneously spoken dialogs from the English VERBMOBIL corpus where a recall of 77.2 % and a precision of 90.2 % was obtained .", "label": "", "metadata": {}, "score": "51.738945"}
{"text": "1 , the process of automatic paraphrasing may use a paraphrasing program which incorporates a paraphrasing model built and trained as described above .In each specific instance of paraphrasing application on an input text , usually some but not all of the above defined feature functions are applicable .", "label": "", "metadata": {}, "score": "52.371666"}
{"text": "The approach is cheap , fast , automatic , large scale , ' ' data driven ' ' and based on real language resources .Treebank grammars typically involve large sets of lexical tags and non - lexical categories as syntactic information tends to be encoded in monadic category symbols .", "label": "", "metadata": {}, "score": "52.562828"}
{"text": "Both notions , as described here , are somewhat vague , and indeed the precise formulation of these principles is controversial .[ 13 ] [ 14 ] An additional aspect of minimalist thought is the idea that the derivation of syntactic structures should be uniform ; that is , rules should not be stipulated as applying at arbitrary points in a derivation , but instead apply throughout derivations .", "label": "", "metadata": {}, "score": "53.104004"}
{"text": "4 Transformations in the Less Inflected Language When translating from English into languages with a highly inflected morphology , the production of the correct fullform often ... . \" ...Language modeling is critical and indispensable for many natural language ap - plications such as automatic speech recognition and machine translation .", "label": "", "metadata": {}, "score": "53.105415"}
{"text": "Natural languages and context - free languages \" .Linguistics and Philosophy 4 ( 4 ) : 471 - 504 .doi : 10.1007/BF00360802 .^ Goldsmith , John A ( 1995 ) . \"Phonological Theory \" .In John A. Goldsmith .", "label": "", "metadata": {}, "score": "53.135387"}
{"text": "The parallel sentence pairs which can not be converted from the one to the other by using the above fifteen atomic paraphrasing classes will be filtered out .The collected sentence pairs are associated with one or more feature functions defined above .", "label": "", "metadata": {}, "score": "53.8135"}
{"text": "On the one hand , the speech recognition component in a conversational interface lives in a rich system environment .Diverse sources of knowledge are available and can potentially be beneficial to its robustness and accuracy .For example , the natural language understanding component can provide linguistic knowledge in syntax and semantics that helps constrain the recognition search space .", "label": "", "metadata": {}, "score": "53.940845"}
{"text": "Reordering is one of the most challenging and important problems in Statistical Machine Translation .Without reordering capabilities , sentences can be translated correctly only in case when both languages implied in translation have a similar word order .When translating is between language pairs wi ... \" .", "label": "", "metadata": {}, "score": "54.25066"}
{"text": "Description : .BACKGROUND .[ 0001 ] Paraphrasing used in a computerized environment is a process of automatically generating a paraphrasing sentence from a reference sentence or an input sentence .The computer - generated paraphrases are alternative ways of conveying the same information .", "label": "", "metadata": {}, "score": "54.653244"}
{"text": "The process may also be incorporated in a search engine , in which the input text is generated by a user as a search query , and the paraphrasing text is used by the search engine as an alternative search query .", "label": "", "metadata": {}, "score": "54.941376"}
{"text": "[ 0113 ]( e ) Learn a language generation model based on a given dependency tree .[0114 ]The steps ( b)-(e ) may only use a relatively small collection of human annotated sentence pairs ( e.g. , 1,000 pairs ) .", "label": "", "metadata": {}, "score": "55.110023"}
{"text": "The algorithm stops when the selected transformations do not add more value or there are no more transforamtions to be selected .This is like painting a wall with background color first , then paint different color in each block as per its shape or so .", "label": "", "metadata": {}, "score": "55.151817"}
{"text": "Consequently , the linguist can study an idealised version of language , greatly simplifying linguistic analysis ( see the \" Grammaticality \" section below ) .The second idea related directly to the evaluation of theories of grammar .Chomsky distinguished between grammars that achieve descriptive adequacy and those that go further and achieved explanatory adequacy .", "label": "", "metadata": {}, "score": "55.392708"}
{"text": "Abstract .Manual , large scale ( computational ) grammar development is time consuming , expensive and requires lots of linguistic expertise .More recently , a number of alternatives based on treebank resources ( such as Penn - II , Susanne , AP treebank ) have been explored .", "label": "", "metadata": {}, "score": "55.78743"}
{"text": "[0117 ] Paraphrasing of classes 11 - 15 involves acquisition of semantically related lexicons .Both the atomic linguistic element and corresponding atomic paraphrasing element are patterns that may be learned .One embodiment proposes a unique mutual induction algorithm to learn atomic paraphrasing patterns and lexical relations of classes 11 - 15 .", "label": "", "metadata": {}, "score": "55.787636"}
{"text": "In one embodiment , the paraphrasing of classes 2 - 4 is modeled as a two step procedure : ( i ) transform dependency tree of the original sentence into a new dependency tree ; and ( ii ) generate paraphrased sentences using the new dependency tree .", "label": "", "metadata": {}, "score": "55.912224"}
{"text": "( 17 ) # # EQU00008 # # .[ 0107 ] Class 8 - 9 : The following describes exemplary methods for acquiring and learning class 8 - 9 atomic paraphrasing transformations .[ 0108 ] Both Classes ( 8) and ( 9 ) involve morphological variations .", "label": "", "metadata": {}, "score": "55.921967"}
{"text": "In previous work we developed methodologies for automatic feature - structure annotation of grammars extracted from treebanks .Automatic annotation of ' ' raw ' ' treebank grammars is difficult as annotation rules often need to identify subsequences in the RHSs of flat treebank rules as they explicitly encode head , complement and modifier relations .", "label": "", "metadata": {}, "score": "56.077732"}
{"text": "[ 12 ] The \" Minimalist Program \" aims at the further development of ideas involving economy of derivation and economy of representation , which had started to become significant in the early 1990s , but were still rather peripheral aspects of Transformational - generative grammar theory .", "label": "", "metadata": {}, "score": "56.473106"}
{"text": "Letter - to - sound rules , also known as grapheme - to - phoneme rules , are important computational tools and have been used for a variety of purposes including word or name lookups for database searches and speech synthesis .", "label": "", "metadata": {}, "score": "56.599945"}
{"text": "For example , the process may be incorporated in a word processor , in which the input text is generated by a user , and the paraphrasing text is output to the user as an alternative to the input text .This may be a useful add - on function in a word processor to assist the user 's writing by suggesting alternative ways of expressing a certain idea .", "label": "", "metadata": {}, "score": "56.740562"}
{"text": "[ citation needed ] .In the 1960s , Chomsky introduced two central ideas relevant to the construction and evaluation of grammatical theories .The first was the distinction between competence and performance .Chomsky noted the obvious fact that people , when speaking in the real world , often make linguistic errors ( e.g. , starting a sentence and then abandoning it midway through ) .", "label": "", "metadata": {}, "score": "56.820225"}
{"text": "Transformation - based learning ( TBL ) is a rule - based algorithm for automatic tagging of parts - of - speech to the given text .TBL transforms one state to another using transformation rules in order to find the suitable tag for each word .", "label": "", "metadata": {}, "score": "56.97319"}
{"text": "In databases , phonetics can help retrieve a word or a proper name without the user needing to know the correct spelling .A phonetic index is built with the vocabulary of the application .This could be an entire dictionary , or a list of proper names .", "label": "", "metadata": {}, "score": "57.119946"}
{"text": "The present system consists of two main parts : ffl an automatic phonetic transcription module which produces an orthophonic transcription of the orthographic input text ffl a speech synthesis module which synthesizes an utterance from its transcription by concatenating and modifying previously recorded speech units .", "label": "", "metadata": {}, "score": "57.158535"}
{"text": "Chomsky emphasizes the importance of modern formal mathematical devices in the development of grammatical theory : .But the fundamental reason for [ the ] inadequacy of traditional grammars is a more technical one .Although it was well understood that linguistic processes are in some sense \" creative , \" the technical devices for expressing a system of recursive processes were simply not available until much more recently .", "label": "", "metadata": {}, "score": "57.4169"}
{"text": "Abstract : .A principled approach to paraphrasing analyzes input text and paraphrases at atomic linguistic level , instead of analyzing the input text and paraphrases as a whole set at one time .The principled approach extracts atomic linguistic elements from the input text and identifies matching atomic paraphrasing elements to form candidate atomic paraphrasing pairs .", "label": "", "metadata": {}, "score": "57.9077"}
{"text": "X NP AUX Y X AUX NP Y .In the 1970s , by the time of the Extended Standard Theory , following the work of Joseph Emonds on structure preservation , transformations came to be viewed as holding over trees .", "label": "", "metadata": {}, "score": "57.926544"}
{"text": "Besides , an unsupervised context clustering has also been proposed to learn paraphrases based on dependency parsing results .[ 0003 ] The existing techniques for paraphrasing regard paraphrases as a whole set , and use unified machine learning frameworks to model the paraphrasing transformations .", "label": "", "metadata": {}, "score": "58.54231"}
{"text": "Valuable application of paraphrasing includes information retrieval , information extraction , question answering and machine translation .For example , in the automatic evaluation of machine translation , paraphrases may help to alleviate problems presented by the fact that there are often alternative and equally valid ways of translating a text .", "label": "", "metadata": {}, "score": "59.16497"}
{"text": "Chomsky argued that , even though linguists were still a long way from constructing descriptively adequate grammars , progress in terms of descriptive adequacy will only come if linguists hold explanatory adequacy as their goal .In other words , real insight into the structure of individual languages can only be gained through comparative study of a wide range of languages , on the assumption that they are all cut from the same cloth .", "label": "", "metadata": {}, "score": "59.25283"}
{"text": "The atomic transformations for candidate atomic paraphrasing pairs may also be defined and recognized by the data source .[ 0019 ]At block 130 , the process obtains a probability value of each candidate atomic paraphrasing pair .In one embodiment , the process obtains the probability value by computing a value of an appropriate feature function describing a probability of the atomic paraphrasing pair .", "label": "", "metadata": {}, "score": "59.26116"}
{"text": "^ Jackendoff , Ray ( 1974 ) .Semantic Interpretation in Generative Grammar .MIT Press .ISBN 0 - 262 - 10013 - 4 .^ May , Robert C. ( 1977 ) .The Grammar of Quantification .MIT Phd Dissertation .", "label": "", "metadata": {}, "score": "59.29681"}
{"text": "Where Should Annotation Stop ?Geoffrey Sampson .A Statistical Account on Word Order Variation in German .Daniela Kurz .Bottom - Up Tagset Design from Maximally Reduced Tagset .Peter Dienes , Csaba Oravecz .The Detection of Inconsistency in Manually Tagged Text .", "label": "", "metadata": {}, "score": "59.946503"}
{"text": "Where Should Annotation Stop ?Geoffrey Sampson .A Statistical Account on Word Order Variation in German .Daniela Kurz .Bottom - Up Tagset Design from Maximally Reduced Tagset .Peter Dienes , Csaba Oravecz .The Detection of Inconsistency in Manually Tagged Text .", "label": "", "metadata": {}, "score": "59.946503"}
{"text": "[0106 ]The paraphrasing transformation of Class 7 involves change into different sentence types .In this class , both the atomic linguistic element and corresponding atomic paraphrasing element are patterns .Class 7 usually involves only close set of patterns , which can either be learned or handled easily by human - crafted rules .", "label": "", "metadata": {}, "score": "60.133152"}
{"text": "Then , the proposed letter sequences are parsed by the TINA parser into possible sequences of morphs .These sequences of morphs are used t .. ...Conversational interfaces have received much attention as a promising natural communication channel between humans and computers .", "label": "", "metadata": {}, "score": "60.165085"}
{"text": "In TBL , accuracy is generally considered as the objective function .So in each training cycle , the tagger finds the transformations that greatly reduce the errors in the training set .This transormation is then added to the transformation list and applied to the training corpus .", "label": "", "metadata": {}, "score": "60.18883"}
{"text": "[ 0104 ] The above feature function F 14 is used to estimate the reliability of the paraphrasing transformation , while feature function F 15 is used to check if the transformation matches the context of the given input sentence .[", "label": "", "metadata": {}, "score": "60.33572"}
{"text": "3 is a list of fifteen exemplary paraphrasing transformation classes .[ 0011 ] FIG .4 is a flowchart of an exemplary process of acquiring semantically related lexicons using the algorithm of mutual induction for paraphrasing patterns and lexical relations .", "label": "", "metadata": {}, "score": "60.793167"}
{"text": "In this paper , proposed function tag and part - of - speech tag reordering rule extraction algorithms are used to generate reordering rule automatically and First Order Markov theory is applied to implement stochastic reordering model . ... rce and target languages .", "label": "", "metadata": {}, "score": "60.89766"}
{"text": "It may be one that assigns tags randomly or a Morkov model tagger .Usually it assigns every word its most likely tag as indicated in the training corpus .For example , walk would be initially labelled as a verb .", "label": "", "metadata": {}, "score": "60.898357"}
{"text": "MIT Press .ISBN 0 - 262 - 53007 - 4 .^ The Port - Royal Grammar of 1660 identified similar principles ; Chomsky , Noam ( 1972 ) .Language and Mind .Harcourt Brace Jovanovich .ISBN 0 - 15 - 147810 - 4 .", "label": "", "metadata": {}, "score": "61.05726"}
{"text": "In one embodiment , the morphological variations are handled by the following exemplary procedure .[ 0110 ] ( b ) Provide a collection of sample parallel sentence pairs involving the above three sets of lexicon pairs .[ 0111 ]( c ) Perform word alignment between parallel sentence pairs .", "label": "", "metadata": {}, "score": "61.59463"}
{"text": "[ 15 ] This idea was formalized by Chomsky in the Chomsky hierarchy .Chomsky argued that it is impossible to describe the structure of natural languages using context - free grammars .[ 16 ] His general position regarding the non - context - freeness of natural language has held up since then , although his specific examples regarding the inadequacy of CFGs in terms of their weak generative capacity were later disproven .", "label": "", "metadata": {}, "score": "61.615612"}
{"text": "When encountering an OOV word , a speech reco ... \" .This thesis concerns the problem of unknown or out - of - vocabulary ( 00V ) words in continuous speech recognition .Most of today 's state - of - the - art speech recognition systems can recognize only words that belong to some predefined finite word vocabulary .", "label": "", "metadata": {}, "score": "61.673588"}
{"text": "Learning Atomic Paraphrasing Transformations and Designing Feature Functions : . [ 0040 ]Sentential paraphrasing may occur at three different levels , which are lexical level , syntactic level , and semantic level .Lexical level paraphrasing refers to synonym substitution , word deletion and insertion .", "label": "", "metadata": {}, "score": "61.71797"}
{"text": "We attempt to combine the information in both the spelling and the pronunciation of a proper name and find ways to let both sources of information improve the recognition accuracies of that name from the accuracies obtained by performing the spelling recognition and pronunciation recognition tasks separately .", "label": "", "metadata": {}, "score": "61.882504"}
{"text": "[ 0016 ] FIG .1 is a flowchart of an exemplary process of automatic paraphrasing using the atomic paraphrases .At block 110 , the process selects a plurality of atomic linguistic elements from an input text .The atomic linguistic elements may be extracted from the input text .", "label": "", "metadata": {}, "score": "62.5311"}
{"text": "The final paraphrasing model is used to decide if an atomic pattern is triggered given a specific context of the input text .[ 0015 ] With the final paraphrasing model built and trained , automatic paraphrasing can be performed using exemplary procedures described below .", "label": "", "metadata": {}, "score": "62.697105"}
{"text": "The major syntactic structures of English .Holt , Rinehart and Winston .ISBN 978 - 0 - 03 - 088042 - 1 .[ page needed ] .^ Emmon Bach , An Introduction to Transformational Grammars , Holt , Rinehart and Winston . Inc. , 1966 , pp .", "label": "", "metadata": {}, "score": "63.16559"}
{"text": "[ 0095 ] ( c ) learn transformation rules between dependency trees ; and .[ 0096 ] ( d ) learn the sentence generation model given a dependency tree .One embodiment implements the tree transformation rule learning algorithm and dependency tree based sentence generation algorithm described in Chris Quirk , Arul Menezes , and Colin Cherry , 2004 ( Dependency Tree Translation : Syntactically Informed Phrasal SMT , Microsoft Research Technical Report : MSR - TR-2004 - 113 ) .", "label": "", "metadata": {}, "score": "63.17655"}
{"text": "[0017 ]At block 120 , for each atomic linguistic element , the process selects one or more atomic paraphrasing elements .The atomic linguistic element relates to the selected atomic paraphrasing element through an atomic transformation to form a candidate atomic paraphrasing pair .", "label": "", "metadata": {}, "score": "63.29842"}
{"text": "Finally , SC ( S OUT , S IN ) is represented as a log linear function of the features being involved , as expressed as follows : .[ 0035 ]The task of building a paraphrasing model is divided into three subtasks : .", "label": "", "metadata": {}, "score": "63.419113"}
{"text": "This completes the building and training of the paraphrasing model .The final paraphrasing model may be then incorporated in a paraphrasing program for application .[ 0129 ]According to one aspect of the present atomic paraphrasing technique , multiple atomic paraphrasing pairs each having atomic linguistic element and a matching atomic paraphrasing element are identified and evaluated using individual feature functions described above that are compatible with the respective atomic paraphrasing pair .", "label": "", "metadata": {}, "score": "63.58068"}
{"text": "[ 1 ] .In 1957 , Noam Chomsky published Syntactic Structures , in which he developed the idea that each sentence in a language has two levels of representation - a deep structure and a surface structure .[ 2 ] [ 3 ] The deep structure represented the core semantic relations of a sentence , and was mapped on to the surface structure ( which followed the phonological form of the sentence very closely ) via transformations .", "label": "", "metadata": {}, "score": "63.72455"}
{"text": "[ 0005 ] In some embodiments , a variety of atomic transformation types are identified to form atomic paraphrasing pairs .The atomic transformations and appropriate feature functions are acquired and trained to build atomic paraphrasing models which are used for selecting and evaluating candidate atomic paraphrasing pairs , and for scoring various combinations of candidate atomic paraphrasing pairs .", "label": "", "metadata": {}, "score": "63.812084"}
{"text": "When translating from languages with hardly any inflectional morphology like English into morphologically rich languages , the English word forms often do not contain enough information for producing the correct fullform in the target language .We investigate methods for improving the quality ... \" .", "label": "", "metadata": {}, "score": "63.938786"}
{"text": "^ Newmeyer , Frederick J. ( 1986 ) .Linguistic Theory in America ( Second Edition ) .Academic Press .[ page needed ] .^ Chomsky , Noam ( 1995 ) .The Minimalist Program .MIT Press .ISBN 0 - 262 - 53128 - 3 .", "label": "", "metadata": {}, "score": "64.250374"}
{"text": "[0002 ] In the last decade , intensive research attention from computation linguistic community has been paid to the field of paraphrase acquisition , including paraphrasing at lexical level , syntactic level and semantic level .Especially , statistical machine translation techniques ( SMT ) have been used to model paraphrasing as a monolingual translation task .", "label": "", "metadata": {}, "score": "64.30419"}
{"text": "The process may compute the composite paraphrasing score by computing a value of a score function .In one embodiment , the score function is a product of the appropriate feature functions of the candidate atomic paraphrasing pairs in the selected combination .", "label": "", "metadata": {}, "score": "64.37584"}
{"text": "[ 10 ] .Chomsky argued that the notions \" grammatical \" and \" ungrammatical \" could be defined in a meaningful and useful way .Although few linguists in the 1950s actually took such an extreme position , Chomsky was at an opposite extreme , defining grammaticality in an unusually mentalistic way ( for the time ) .", "label": "", "metadata": {}, "score": "64.502716"}
{"text": "In such a conversational inter ... \" .Conversational interfaces have received much attention as a promising natural communication channel between humans and computers .A typical conversational interface consists of three major systems : speech understanding , dialog management and spoken language generation .", "label": "", "metadata": {}, "score": "64.51924"}
{"text": "In this thesis , the framework for a proper name recognition system is studied .We attempt to combine the information in both the spelling and the pronunciation of a proper name and find ways to let both sources of information improve the recognition accuracies of that name from the accuracies obta ... \" .", "label": "", "metadata": {}, "score": "64.53142"}
{"text": "This paper describes two related systems which provide frameworks for encoding linguistic knowledge into formal rules within the context of a trainable probabilistic model .The first system , TINA [ 33 ] , drives top - down from sentence level structure , terminating in either words or syllables .", "label": "", "metadata": {}, "score": "64.92986"}
{"text": "This paper describes two related systems which provide frameworks for encoding linguistic knowledge into formal rules within the context of a trainable probabilistic model .The first system , TINA [ 33 ] , drives top - down from sentence level structure , terminating in either words or syllables .", "label": "", "metadata": {}, "score": "64.92986"}
{"text": "In 1986 , Chomsky proposed a distinction between I - Language and E - Language , similar but not identical to the competence / performance distinction .[ 8 ] \" I - language \" refers to Internal language and is contrasted with External Language ( or E - language ) .", "label": "", "metadata": {}, "score": "65.22136"}
{"text": "0120 ] Block 410 extracts sentence pairs from a large monolingual corpus containing lexicon pairs .To be included in the extraction , the similarity of the sentence pairs should meet a preset condition , e.g. , a pre - defined threshold .", "label": "", "metadata": {}, "score": "65.29158"}
{"text": "0092 ] A number of sample paraphrasing instances of classes 2 - 4 may be provided to learn the dependency tree transformation rules and tree - based sentence generation model .An exemplary learning procedure is given as follows : .[ 0093 ] ( a ) perform word alignment between original and paraphrased sentences provided in the sample paraphrasing instances ; .", "label": "", "metadata": {}, "score": "65.3745"}
{"text": "As will be described in detail herein , fifteen major atomic paraphrasing classes are identified based on data exploration and analysis .Different paraphrasing pattern acquisition schemes are designed for different paraphrasing classes .For each class of atomic paraphrasing transformation , paraphrasing patterns are acquired by either machine learning or hand - crafted rules .", "label": "", "metadata": {}, "score": "65.41637"}
{"text": "A typic TBL tagger ( or Brill Tagger ) can easily identify that rabbit is noun if it is given the rule , .Transformation based learning usually starts with some simple solution to the problem .Then it runs through cycles .", "label": "", "metadata": {}, "score": "65.52484"}
{"text": "0115 ]Class 10 : The paraphrasing transformation of Class 10 involves only close set of patterns , and can be handled by human - crafted rules .The following feature function is defined for Class ( 10 ) : .( 20 ) # # EQU00010 # # .", "label": "", "metadata": {}, "score": "65.570404"}
{"text": "[0004 ] This disclosure describes a principled approach to paraphrasing .The principled approach analyzes input text and constructs paraphrases at atomic linguistic level , instead of analyzing the input text and finding paraphrases as a whole set at one time .", "label": "", "metadata": {}, "score": "65.97286"}
{"text": "Although the subject matter has been described in language specific to structural features and/or methodological acts , it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described .", "label": "", "metadata": {}, "score": "66.29634"}
{"text": "In addition , sample parallel sentence pairs which may contain one or more atomic linguistic elements may also be stored in the system to further assist the application of the paraphrasing model .For example , a large number ( e.g. , in millions ) of monolingual parallel sentence pairs may be extracted from comparable news and multiple translations of the same novels .", "label": "", "metadata": {}, "score": "66.32871"}
{"text": "The aim of the workshop is to exchange and propagate research results .in the field of corpus annotation , taking into account various types . of information .The Workshop on Linguistically Interpreted Corpora . focues on . - tools & techniques for syntactic annotation , . - tagging and parsing methods that aim at semi - automatic annotation , . - error detection and correction , . - inter - annotator - agreement , . - representation formats and standards , . - browsing corpora and searching for instances of linguistic phenomena , .", "label": "", "metadata": {}, "score": "66.67742"}
{"text": "The aim of the workshop is to exchange and propagate research results .in the field of corpus annotation , taking into account various types . of information .The Workshop on Linguistically Interpreted Corpora . focues on . - tools & techniques for syntactic annotation , . - tagging and parsing methods that aim at semi - automatic annotation , . - error detection and correction , . - inter - annotator - agreement , . - representation formats and standards , . - browsing corpora and searching for instances of linguistic phenomena , .", "label": "", "metadata": {}, "score": "66.67742"}
{"text": "E - Language encompasses all other notions of what a language is , for example that it is a body of knowledge or behavioural habits shared by a community .Competence , he argues , can only be studied if languages are treated as mental objects .", "label": "", "metadata": {}, "score": "66.71716"}
{"text": "In the present paper we conduct a number of experiments to explore a space of possible grammars based on a small fragment of the AP treebank resource .Starting with the original treebank fragment we automatically extract a CFG G. We then apply an automatic structure preserving grammar compaction step which generalises categories in the original treebank fragment and reduces the number of rules extracted , resulting in a generalised treebank fragment and in a compacted grammar Gc .", "label": "", "metadata": {}, "score": "66.73063"}
{"text": "From the point of view of theoretical linguistics , flat treebank trees and treebank grammars extracted from such trees do not express linguistic generalisations .From the perspective of empirical and corpus linguistics , flat trees are well - motivated as they allow underspecification of subtle and often time consuming attachment decisions .", "label": "", "metadata": {}, "score": "66.77339"}
{"text": "Though transformations continue to be important in Chomsky 's current theories , he has now abandoned the original notion of Deep Structure and Surface Structure .[ citation needed ] .To complicate the understanding of the development of Noam Chomsky 's theories , the precise meanings of Deep Structure and Surface Structure have changed over time - by the 1970s , the two were normally referred to simply as D - Structure and S - Structure by Chomskyan linguists .", "label": "", "metadata": {}, "score": "66.89526"}
{"text": "We present here the methods and results of one such effort , resulting in a relatively compact and fast set of TTP rules that achieves 94.5 % segmental p ... \" .Adopting concepts from statistical language modeling and rulebased transformations can lead to effective and efficient text - tophone ( TTP ) functions .", "label": "", "metadata": {}, "score": "66.895874"}
{"text": "Accordingly , the following feature function is defined : .( 13 ) # # EQU00005 # # .[ 0100 ] Class 6 : The following describes exemplary lexicon acquisition for class 6 .[ 0101 ] The class 6 atomic paraphrasing transformation is pre - positional phrase attachment .", "label": "", "metadata": {}, "score": "67.01821"}
{"text": "..102 9.2 An alignment example between Chinese and English ( Och et al . , 2003 ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "label": "", "metadata": {}, "score": "67.10095"}
{"text": "We have recently been successful in integrating their combined constraint into a recognizer search , achieving considerable improvement in understanding accuracy [ 9 , 23].In this paper , I will look both toward the past and the future , identifying and motivating the decisions that were made in the design of TINA and ANGIE and the associated rule formalisms , and contemplating various remaining open research issues . ...", "label": "", "metadata": {}, "score": "67.533585"}
{"text": "A good example for such a su ... . \" ...This Master 's Thesis concerns research in the automatic analysis of the sub - lexical structure of English words .Sub - lexical structure includes linguistic categories such as syllabification , stress , phonemic representation , phonetics , and spelling .", "label": "", "metadata": {}, "score": "67.67708"}
{"text": "[ 0080 ] The acquisition of the paraphrasing patterns and the design of the feature functions for each class are described in the following .The detailed algorithm description below introduces several notations .[0081 ] Class 1 : Exemplary pattern learning and feature design for class 1 atomic paraphrasing transformation is described below .", "label": "", "metadata": {}, "score": "67.72565"}
{"text": "In general , the process selects those combinations that have the highest composite paraphrasing scores .One or more combinations may be selected .[ 0022 ]At block 160 , the process constructs a paraphrasing text using the atomic paraphrasing elements in the selected combination of candidate atomic paraphrasing pairs .", "label": "", "metadata": {}, "score": "68.31299"}
{"text": "We investigate methods for improving the quality of such translations by making use of part - ofspeech information and maximum entropy modeling .Results for translations from English into Spanish and Catalan are presented on the LC - STAR corpus which consists of spontaneously spoken dialogues in the domain of appointment scheduling and travel planning . .", "label": "", "metadata": {}, "score": "69.45717"}
{"text": "The candidate atomic paraphrasing pairs are evaluated using , for example , feature functions and a trained probability model .The principled approach scores a combination of multiple candidate atomic paraphrasing pairs using a score function which derives its value from the feature functions of the candidate atomic paraphrasing pairs .", "label": "", "metadata": {}, "score": "69.52387"}
{"text": "4 is a flowchart of an exemplary process of acquiring semantically related lexicons using the algorithm of mutual induction for paraphrasing patterns and lexical relations .[ 0119 ] At blocking 401 , for each of the above five paraphrasing classes 11 - 15 , an initial list of lexicon pairs is provided which trigger the following recursive learning procedure .", "label": "", "metadata": {}, "score": "69.74366"}
{"text": "This paper describes a new system for speech analysis , ANGIE , which characterizes word substructure in terms of a trainable grammar .ANGIE capture morpho - phonemic and phonological phenomena through a hierarchical framework .The terminal categories can be alternately letters or phone units , yielding ... \" .", "label": "", "metadata": {}, "score": "69.80134"}
{"text": "We explore regular expression based compaction ( both manual and automatic ) to relate Gc , m to a LFG-82 style grammar design .Finally , we manually recode a subsection of the generalised and manually corrected treebank fragment into ' ' vanilla - flavour ' ' XBar based trees .", "label": "", "metadata": {}, "score": "69.908745"}
{"text": "This Master 's Thesis concerns research in the automatic analysis of the sub - lexical structure of English words .Sub - lexical structure includes linguistic categories such as syllabification , stress , phonemic representation , phonetics , and spelling .This information could be very useful in all sorts of speech applications , including duration modeling and speech recognition .", "label": "", "metadata": {}, "score": "70.02063"}
{"text": "The candidate atomic paraphrasing pairs are evaluated using feature functions and a probability model .The principled approach scores a combination of multiple candidate atomic paraphrasing pairs using a score function which derives its value from the feature functions of the candidate atomic paraphrasing pairs .", "label": "", "metadata": {}, "score": "70.36804"}
{"text": "We evaluate our grammars and methods using standard labelled bracketing measures and according to how well they perform under automatic feature - structure annotation tasks .Tools . by Matthias Honal , Tanja Schultz - in Proceedings of the 8th Eurospeech Conference , 2003 . \" ...", "label": "", "metadata": {}, "score": "70.767395"}
{"text": "Using the collected monolingual parallel corpora , sentence alignment can be performed to extract monolingual parallel sentence pairs .Accordingly , three feature functions are defined as follows : .[ 0089 ] where common BP ( ph 1 , ph 2 ) refers to the common context words when ph 1 and ph 2 are aligned together in the monolingual parallel corpora .", "label": "", "metadata": {}, "score": "70.77472"}
{"text": "The other system , ANGIE [ 36 ] , operates bottom - up from phonetic or orthographic units , characterizing the substructure of syllables / words .It provides a framework for both phonological rule modelling and letter - to - sound / sound - to - letter transformations .", "label": "", "metadata": {}, "score": "70.77867"}
{"text": "[ 0006 ] This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description .This Summary is not intended to identify key features or essential features of the claimed subject matter , nor is it intended to be used as an aid in determining the scope of the claimed subject matter .", "label": "", "metadata": {}, "score": "70.94081"}
{"text": "[ 0077 ] Class 15 : Different semantic role realization [ 0078 ]a. He enjoyed the game .vs. The game pleased him .[0079 ] The above class 1 belongs to lexical level paraphrasing , classes 2 - 7 belong to syntactic level paraphrasing , and class 8 - 15 belong to semantic level paraphrasing .", "label": "", "metadata": {}, "score": "71.20293"}
{"text": "ANGIE capture morpho - phonemic and phonological phenomena through a hierarchical framework .The terminal categories can be alternately letters or phone units , yielding a reversible letter - tosound / sound - to - letter system .In conjunction with a segment network and acoustic phone models , the system can produce phonemicto - phonetic alignments for speech waveforms .", "label": "", "metadata": {}, "score": "71.20799"}
{"text": "[0012 ]The present disclosure proposes a principled approach to sentential paraphrasing .This approach is based on the following observation : there exist many different classes of atomic paraphrasing transformation , and a paraphrase may be created using a combination of atomic paraphrasing transformations .", "label": "", "metadata": {}, "score": "71.65408"}
{"text": "[ 0132 ] The atomic paraphrasing techniques disclosed herein analyze and construct paraphrases using a principled approach based on a multiclass atomic paraphrasing model .The techniques potentially overcome some of the basic problems existing in the conventional paraphrasing techniques .It is , however , appreciated that the potential benefits and advantages discussed herein are not to be construed as a limitation or restriction to the scope of the appended claims .", "label": "", "metadata": {}, "score": "72.44741"}
{"text": "This thesis defines a procedure to se ... . ... nd / sound - to - letter generation , speech recognition , duration modeling , and word spotting .The results of using Angie are described next .The phoneme accuracies on a test set is 91.7 % , with a word accuracy of 69.3 % .", "label": "", "metadata": {}, "score": "72.97926"}
{"text": "[0124 ] The above process may be repeated from block 510 for further learning and expansion .[0125 ]Accordingly , the following feature functions are defined for atomic paraphrasing transformation classes ( 11)-(15 ) : . [0126 ] where n lex ( AT ) is the iteration number in which the involved lexicon pair is learned .", "label": "", "metadata": {}, "score": "73.057106"}
{"text": "( Supervised by Noam Chomsky , this dissertation introduced the idea of \" logical form . \" ) ^ Chomsky , Noam ( 2001 ) . \"Derivation by Phase . \"In other words , in algebraic terms , the I - Language is the actual function , whereas the E - Language is the extension of this function .", "label": "", "metadata": {}, "score": "73.55083"}
{"text": "Text-- to -- speech systems convert orthographic text input into speech output .The present system consists of two main parts : ffl an a ... \" .In this thesis , a diphone -- based text -- to -- speech system for Scottish Gaelic , a language spoken by about 80.000 native speakers in Scotland and Canada , is presented .", "label": "", "metadata": {}, "score": "73.68735"}
{"text": "Duration and intonation are modelled on the basis of simple heuristics .The diphone inventory was designed for the Gaelic of Bayble , Lewis .Scottish Gaelic distinguishes four main phonetic settings : velarised , palatalised , nasalised , and neutral .", "label": "", "metadata": {}, "score": "73.70241"}
{"text": "[0031 ] The above - described atomic paraphrasing method uses an atomic paraphrasing model which can be built and trained before placed into the final application .The following describes the detail of building and training such an atomic paraphrasing model .", "label": "", "metadata": {}, "score": "73.85243"}
{"text": "[0099 ] Class 5 of atomic paraphrasing transformation is head omission .In this class , the atomic linguistic element may be a phrase X of Y ( as in \" group of students \" ) and a corresponding atomic paraphrasing element may be the word Y only ; or vice versa .", "label": "", "metadata": {}, "score": "73.907936"}
{"text": "0008 ] FIG .1 is a flowchart of an exemplary process of automatic paraphrasing using atomic paraphrases .[0009 ] FIG .2 shows an exemplary environment for implementing the atomic paraphrasing method of the present disclosure .[0010 ]", "label": "", "metadata": {}, "score": "73.923035"}
{"text": "[ 0024 ] The above - described process may be implemented with the help of a computing device , such as a server , a personal computer ( PC ) or a portable device having a computing unit .[ 0025 ] FIG .", "label": "", "metadata": {}, "score": "73.949005"}
{"text": "Accordingly , a feature function is defined as follows : .A transformation X i + nounnoun+Y i is then recognized as a valid paraphrasing transformation if E Z \u03b5Z(X i . sub . )max(freq(X i , Z)-C , 0)max(freq(X i , Z)-C , 0 ) is higher than a threshold ( where C is a constant ) .", "label": "", "metadata": {}, "score": "74.76871"}
{"text": "0121 ] Block 420 learns among the similar sentences extracted above paraphrase patterns by replacing common words by a variable .The learned paraphrasing patterns are ranked based on their occurrence frequency which is denoted as supp ( AT ) .Preferably , only the patterns with top supp ( AT ) are kept .", "label": "", "metadata": {}, "score": "74.7993"}
{"text": "Dependency - based Syntactic Annotation of a Chinese Corpus .Tom B. Y. Lai , Huang Changning .The Italian Syntactic - Semantic Treebank : Architecture , Annotation , .Tools and Evaluation .S. Montemagni , F. Barsotti , M. Battista , N. Calzolari , O. Corazzari , . A. Zampolli , F. Fanciulli , M. Massetani , R. Raffaelli , R. Basili , .", "label": "", "metadata": {}, "score": "75.27609"}
{"text": "Dependency - based Syntactic Annotation of a Chinese Corpus .Tom B. Y. Lai , Huang Changning .The Italian Syntactic - Semantic Treebank : Architecture , Annotation , .Tools and Evaluation .S. Montemagni , F. Barsotti , M. Battista , N. Calzolari , O. Corazzari , . A. Zampolli , F. Fanciulli , M. Massetani , R. Raffaelli , R. Basili , .", "label": "", "metadata": {}, "score": "75.27609"}
{"text": "Claims : .The method as recited in claim 1 , wherein selecting the plurality of atomic linguistic elements comprises extracting atomic linguistic elements from the input text .The method as recited in claim 1 , wherein the at least one atomic linguistic element kind has multiple atomic linguistic elements .", "label": "", "metadata": {}, "score": "75.87102"}
{"text": "Each atomic linguistic element kind may be involved with multiple atomic linguistic elements .For example , among the plurality of atomic linguistic elements selected , one or more may be one atomic linguistic element kind , one or more may be another atomic linguistic element kind , and so on .", "label": "", "metadata": {}, "score": "75.883125"}
{"text": "Ken Hale : A Life in Language .MIT Press .Pages 1 - 52 .( See p. 49 fn .2 for comment on E - Language . )^ Isac , Daniela , and Charles Reiss .I - language : An introduction to linguistics as cognitive science .", "label": "", "metadata": {}, "score": "76.05884"}
{"text": "REGISTRATION : . select ' ' Workshops ' ' ( or secure form for workshops ) .The autumn school offers courses and lectures covering different areas . of cognitive science and learning technologies .It is intended for .students and scientists from the fields of psychology , computer .", "label": "", "metadata": {}, "score": "76.12464"}
{"text": "REGISTRATION : . select ' ' Workshops ' ' ( or secure form for workshops ) .The autumn school offers courses and lectures covering different areas . of cognitive science and learning technologies .It is intended for .students and scientists from the fields of psychology , computer .", "label": "", "metadata": {}, "score": "76.12464"}
{"text": "The following three feature functions are defined accordingly .[ 0087 ] where common BP ( ph 1 , ph 2 ) refers to the common context words when phrases ph 1 and ph 2 are translated into the same phrases of a different language .", "label": "", "metadata": {}, "score": "76.21059"}
{"text": "[0007 ] The detailed description is described with reference to the accompanying figures .In the figures , the left - most digit(s ) of a reference number identifies the figure in which the reference number first appears .The use of the same reference numbers in different figures indicates similar or identical items .", "label": "", "metadata": {}, "score": "76.31882"}
{"text": "Treebank vs. xbar - based automatic f - structure annotation .van Genabith , Josef and Frank , Anette and Way , Andy ( 2001 )Treebank vs. xbar - based automatic f - structure annotation .In : LFG01 - 6th International Lexical Functional Grammar Conference , 25 - 27 June 2001 , Hong Kong .", "label": "", "metadata": {}, "score": "76.7025"}
{"text": "The method as recited in claim 1 , wherein the method is incorporated in a search engine , the input text being generated by a user as a search query , and the paraphrasing text being used by the search engine as an alternative search query .", "label": "", "metadata": {}, "score": "76.81119"}
{"text": "Grammar - Based Corpus Annotation .Stefanie Dipper .Automatic Procedures in Tectogrammatical Tagging .Alena Bohmova , Petr Sgall .Considering Automatic Aids to Corpus Annotation .David Day , Benjamin Wellner .CONTACT : .Thorsten Brants .email : thorsten coli.uni-sb .", "label": "", "metadata": {}, "score": "77.17068"}
{"text": "Grammar - Based Corpus Annotation .Stefanie Dipper .Automatic Procedures in Tectogrammatical Tagging .Alena Bohmova , Petr Sgall .Considering Automatic Aids to Corpus Annotation .David Day , Benjamin Wellner .CONTACT : .Thorsten Brants .email : thorsten coli.uni-sb .", "label": "", "metadata": {}, "score": "77.17068"}
{"text": "[0130 ]In practice , the multi - dimensional space defined by all available atomic paraphrasing pairs may result in an exceedingly large number of combinations of atomic paraphrasing pairs , making the computation prohibitively expensive .To overcome this problem , individual atomic paraphrasing pairs may be evaluated first using appropriate feature functions to filter out those paraphrasing pairs that score to low .", "label": "", "metadata": {}, "score": "77.883575"}
{"text": "These syllable - sized units capture both orthographic and phonemic information of the names they represent .Our morphs are arbitrarily categorized into six groups : prefix , onset , rhyme , uroot , dsuf and isuf .Certain combinations of these morph categories , defined by a specific word decomposition rule , are used to represent proper names .", "label": "", "metadata": {}, "score": "78.02942"}
{"text": "Treebank grammars do not in general follow Xbar architectural design principles ( this is not to say that treebank grammars do not have design principles ) .Even though treebank grammars are large , they are still incomplete , exhibiting unabated rule accession rates .", "label": "", "metadata": {}, "score": "78.053505"}
{"text": "One embodiment implements dependency trees and the algorithm for learning tree transformation rules based sentence generation algorithm as disclosed in Chris Quirk , Arul Menezes , and Colin Cherry , 2004 ( Dependency Tree Translation : Syntactically Informed Phrasal SMT , Microsoft Research Technical Report : MSR - TR-2004 - 113 ) .", "label": "", "metadata": {}, "score": "79.01329"}
{"text": "Many methods may be used to learn synonyms and synonymous phrases .The following are three exemplary methods used to learn synonyms .[ 0083 ] ( i ) Word clustering algorithm : Word similarity sim(w 1 , w 2 ) can be estimated between each pair of words , and any word pair with the similarity higher than a pre - defined threshold \u03b8 1 can be regarded as a synonym .", "label": "", "metadata": {}, "score": "79.397675"}
{"text": "Evaluated in the ATIS domain , ANGIE achieveda phone error rate of 36 % , as compared with 40 % achieved with a baseline phone - bigram based recognizer under similar conditions .ANGIE potentially offers many attractive features , including dynamic vocabulary adaptation , as well as a framework for handling unknown words . .", "label": "", "metadata": {}, "score": "79.69859"}
{"text": "An implementation of the model , which includes some of these solutions , is described .The best finding , mixed maximum phrase length , allows for a 25 % reduction in the number of parameters to estimate , along with an improvement in translation quality . iii Acknowledgements First off , I would like to thank my thesis supervisors , Miles Osborne and Chris Callison - Burch , who provided endless assistance and insight .", "label": "", "metadata": {}, "score": "79.82738"}
{"text": "Directory .WORKSHOP PROGRAM .9:00 - 9:30 Opening Session .Anne Abeille , Thorsten Brants , Hans Uszkoreit .9:30 - 10:00 Comparing Linguistic Interpretation Schemes for English Corpora .Eric Atwell , George Demetriou , John Hughes , Amanda Schiffrin .", "label": "", "metadata": {}, "score": "80.51216"}
{"text": "For example , in one embodiment , computer readable medium 230 has stored thereupon a plurality of instructions ( e.g. instructions in application programs 232 ) that , when executed by one or more processors 210 , causes the processor(s ) 210 to : . [ 0026 ] ( a ) select a plurality of atomic linguistic elements from an input text , wherein the plurality of atomic linguistic elements includes at least one atomic linguistic element kind selected from a word , a phrase , a pattern and a lexical dependency tree ; .", "label": "", "metadata": {}, "score": "80.67353"}
{"text": "An example of an interpretable feature is the plural inflection on regular English nouns , e.g. , dog s .The word dogs can only be used to refer to several dogs , not a single dog , and so this inflection contributes to meaning , making it interpretable .", "label": "", "metadata": {}, "score": "81.32685"}
{"text": "A tag may change from X to Y if the previous word is W , the previous tag is ti and the following tag is tj , or the tag two before is ti and the following word is W. Consider the following setence , .", "label": "", "metadata": {}, "score": "81.82594"}
{"text": "Numerous combinations may exist for a given set of atomic paraphrasing pairs .Each combination defines a set of atomic paraphrasing elements which together may be used to construct a paraphrasing text of the input text .The score function SC ( S OUT , S IN ) is used for computing a composite paraphrases score of each candidate combination .", "label": "", "metadata": {}, "score": "82.298325"}
{"text": "Based on observations from the training data , we build statistical models and therefore , the success of a statistical model is crucially dependent on the training data .In other words , if we do n't have enough data for training , or the training data is not matched with the test data , we are not able to build accurate statistical models .", "label": "", "metadata": {}, "score": "83.10004"}
{"text": "[ 0028 ] ( c ) select a combination of candidate atomic paraphrasing pairs ; and .[ 0029 ] ( d ) construct a paraphrasing text of the input text using the atomic paraphrasing elements in the selected combination of candidate atomic paraphrasing pairs .", "label": "", "metadata": {}, "score": "83.10475"}
{"text": "O. Corazzari , A. Zampolli , F. Fanciulli , M. Massetani , .R. Raffaelli , R. Basili , M. T. Pazienza , D. Saracino , . F. Zanzotto , N. Mana , F. Pianesi , R. Delmonte .11:30 - 12:00 Where Should Annotation Stop ?", "label": "", "metadata": {}, "score": "84.31088"}
{"text": "15:00 - 15:30 Grammar - Based Corpus Annotation .Stefanie Dipper .15:30 - 16:00 Coffee Break .16:00 - 16:30 Automatic Procedures in Tectogrammatical Tagging .Alena Bohmova , Petr Sgall .16:30 - 17:00 Considering Automatic Aids to Corpus Annotation .", "label": "", "metadata": {}, "score": "84.44826"}
{"text": "the past to produce such general functions , both hand - crafted and data - driven , simple and complex [ e.g. 1 , 5 , 7 , 8 , 9 , 10 , 11 , 12].GENERAL SCHEME The basic concept of standard SLM work is expressed well by Stolcke [ 13 , p. 270", "label": "", "metadata": {}, "score": "84.550125"}
{"text": "0127 ]Using the above - defined multiple atomic paraphrasing transformations , a paraphrasing model may be built which contains a large number of atomic linguistic elements and potential matching atomic paraphrasing elements .The information of the atomic linguistic elements and atomic paraphrasing elements , together with the statistical data of probabilities of the feature functions , can be stored in the system ( e.g. , stored as data 234 in memory 230 of FIG .", "label": "", "metadata": {}, "score": "84.795616"}
{"text": "But it 's unfair , I think .P.S. Maybe it 's a misprint .Because here is a quote from the WTA rules : The criterion for determining LL statys is determined by the highest ranked players ( in descending order ) who have lost in THE FINAL ROUND OF QUALIFYING .", "label": "", "metadata": {}, "score": "84.92827"}
{"text": "But it 's unfair , I think .P.S. Maybe it 's a misprint .Because here is a quote from the WTA rules : The criterion for determining LL statys is determined by the highest ranked players ( in descending order ) who have lost in THE FINAL ROUND OF QUALIFYING .", "label": "", "metadata": {}, "score": "84.92828"}
{"text": "12:00 - 12:30 A Statistical Account on Word Order Variation in German .Daniela Kurz .12:30 - 14:00 Lunch Break .14:00 - 14:30 Bottom - Up Tagset Design from Maximally Reduced Tagset .Peter Dienes , Csaba Oravecz .14:30 - 15:00 The Detection of Inconsistency in Manually Tagged Text .", "label": "", "metadata": {}, "score": "85.25642"}
{"text": "[ 0084 ] where common ws ( w 1 , w 2 ) refers to the common context words when estimating sim(w 1 , w 2 ) .An exemplary learning procedure is described as follows .It is noted that a word is a special case of a phrase .", "label": "", "metadata": {}, "score": "85.60108"}
{"text": "Hans Uszkoreit ( co - chair ) , Saarbruecken .Jean Veronis , Aix - en - Provence .Atro Voutilainen , Helsinki .Jakub Zavrel , Antwerp .PROGRAM : .Comparing Linguistic Interpretation Schemes for English Corpora .Eric Atwell , George Demetriou , John Hughes , Amanda Schiffrin .", "label": "", "metadata": {}, "score": "86.625854"}
{"text": "Hans Uszkoreit ( co - chair ) , Saarbruecken .Jean Veronis , Aix - en - Provence .Atro Voutilainen , Helsinki .Jakub Zavrel , Antwerp .PROGRAM : .Comparing Linguistic Interpretation Schemes for English Corpora .Eric Atwell , George Demetriou , John Hughes , Amanda Schiffrin .", "label": "", "metadata": {}, "score": "86.625854"}
{"text": "0068 ] Most people died .vs. Few people survived .[ 0069 ] Class 12 : Verb nominalization [ 0070 ] He wrote the book .vs. He was the author of the book .[ 0071 ] Class 13 : Substitution using words with overlapping meanings [ 0072 ] He flew across the ocean . vs. He crossed the ocean by plane .", "label": "", "metadata": {}, "score": "86.86467"}
{"text": "Blackwell Handbooks in Linguistics .Blackwell Publishers .p. 2 .ISBN 1 - 4051 - 5768 - 2 .Can anyone explain why Bohmova , who lost in first round of qualies , was placed in MD as LL , and Katerina Bondarenko , who lost in 3rd round of qualies , was n't placed as LL ?", "label": "", "metadata": {}, "score": "86.91553"}
{"text": "0054 ]Class 7 : Change into different sentence types [ 0055 ] Who drew this picture ?vs. Tell me who drew this picture .[ 0056 ] Class 8 : Morphological derivation [ 0057 ] I was surprised that he destroyed the old house .", "label": "", "metadata": {}, "score": "87.102036"}
{"text": "It is possible for a sentence to be both grammatical and meaningless , as in Chomsky 's famous example \" colorless green ideas sleep furiously .\" The use of such intuitive judgments permitted generative syntacticians to base their research on a methodology in which studying language through a corpus of observed speech became downplayed , since the grammatical properties of constructed sentences were considered to be appropriate data to build a grammatical model on .", "label": "", "metadata": {}, "score": "91.209076"}
{"text": "The input text may be generated by the local user on computing device 202 .The processor(s ) 210 presents the constructed paraphrasing text to the local user at computing device 202 .In other embodiments , the process may be implemented for network searches via network(s ) 290 , in which a user at computing device 202 searches data sources located on networked computing devices ( such as servers ) 241 , 242 and 243 .", "label": "", "metadata": {}, "score": "92.21696"}
{"text": "Tonik .Re : NEW Main Draw .Can anyone explain why Bohmova , who lost in first round of qualies , was placed in MD as LL , and Katerina Bondarenko , who lost in 3rd round of qualies , was n't placed as LL ?", "label": "", "metadata": {}, "score": "92.579834"}
{"text": "10:00 - 10:30 Dependency - based Syntactic Annotation of a Chinese Corpus .Tom B. Y. Lai , Huang Changning .10:30 - 11:00 Coffee Break .11:00 - 11:30 The Italian Syntactic - Semantic Treebank : Architecture , .Annotation , Tools and Evaluation .", "label": "", "metadata": {}, "score": "92.975746"}
{"text": "In order to generate reordering rules ; Myanmar - English parallel tagged aligned corpus is firstly created .Then reordering rules are generated automatically by using the linguistic information from this parallel tagged aligned corpus .In this paper , function tag and part - of - speech tag reordering rule extraction algorithms are proposed to generate reordering rules automatically .", "label": "", "metadata": {}, "score": "93.67907"}
{"text": "In this paper , automatic reordering rule generation and application of generated reordering rules in stochastic reordering model is presented .This work is intended to be incorporated into English - Myanmar Machine Translation system .In order to generate reordering rules ; English - Myanmar parallel tagged aligned corpus is firstly created .", "label": "", "metadata": {}, "score": "94.269554"}
{"text": "Registration is open to all , and is possible electronically through .the Autumn School web page ( see above for the URL ) .Registration fee . is DM 80 ( approximately 39 US$ , as of June 25 , 2000 ) .", "label": "", "metadata": {}, "score": "95.10432"}
{"text": "Registration is open to all , and is possible electronically through .the Autumn School web page ( see above for the URL ) .Registration fee . is DM 80 ( approximately 39 US$ , as of June 25 , 2000 ) .", "label": "", "metadata": {}, "score": "95.10432"}
{"text": "[ 0043 ] Class 2 : Active and passive exchange [ 0044 ] The gangster killed 3 innocent people .vs. 3 innocent people are killed by the gangster .[0045 ] Class 3 : Re - ordering of sentence components [ 0046 ] Tuesday they met .", "label": "", "metadata": {}, "score": "95.96523"}
{"text": "SROOT UCODA ONSET LNUC+ ao l dh !ow+$ a $ l $ th $ ou $ gh Figure 1 : Example parse tree with letter terminals for the word \" although .\" A significantdifference is that we have attempted to reduce the parameterspace , both by decreasing the total number of layers in the hierarchy , and by restricting the context conditions for column 2 ... . \" ...", "label": "", "metadata": {}, "score": "97.60115"}
{"text": "Von Der Fakult\u00e4t F\u00fcr Mathematik , Informatik Und Naturwissenschaften Der , Rheinisch - westf\u00e4lischen Technischen , Hochschule Aachen Erlangung , Bruno Wittmer , Berichter Universit\u00e4tsprofessor , Dr. Stefan Schael , Universit\u00e4tsprofessor Dr , Klaus L\u00fcbelsmeyer . \" ... 1.1The Search for the Higgs Boson ..................... 3 1.2 The LHC Collider ............................. 3 ... \" . \" ...", "label": "", "metadata": {}, "score": "97.84213"}
{"text": "In this paper , automatic r ... \" .Abstract - Reordering is important problem to be considered when translating between language pairs with different word orders .Myanmar is a verb final language and reordering is needed when it is translated into other languages which are different from Myanmar word order .", "label": "", "metadata": {}, "score": "99.900696"}
{"text": "0065 ] Class 11 : Converse word substitution [ 0066 ] John is Mary 's husband .vs. Mary is John 's wife .[0067 ] John sold the house to Mary .vs. Mary bought the house from John .", "label": "", "metadata": {}, "score": "100.59099"}
{"text": "Lecturers : Shaaron Ainsworth , Joost Breuker , Cristiano Castelfranchi , .Richard Cooper , Hector Geffner , Jim Hollan , Dietmar Janetzko , Timothy .Koschmann , Marcia Linn , Deborah McGuinness , Thomas Metzinger , Bernhard .Nebel , Josef Nerb , Werner Nutt , Uwe Oestermeier , Rolf Ploetzner , Lloyd .", "label": "", "metadata": {}, "score": "101.49707"}
{"text": "Lecturers : Shaaron Ainsworth , Joost Breuker , Cristiano Castelfranchi , .Richard Cooper , Hector Geffner , Jim Hollan , Dietmar Janetzko , Timothy .Koschmann , Marcia Linn , Deborah McGuinness , Thomas Metzinger , Bernhard .Nebel , Josef Nerb , Werner Nutt , Uwe Oestermeier , Rolf Ploetzner , Lloyd .", "label": "", "metadata": {}, "score": "101.49707"}
{"text": "vs. The film made an impression on him . [0062 ]His machine operation is very good . vs. He operates the machine very well .[ 0063 ] Class 10 : Comparatives vs. superlatives [ 0064 ] He is smarter than everyone else . vs. He is the smartest one .", "label": "", "metadata": {}, "score": "101.706924"}
{"text": "It 's possible the misprinted , but you also have to sign on as a lucky loser , so Maybe Bondarenko forgot or ?Oct 30th , 2006 02:37 PM .-Makiri- .Re : NEW Main Draw .Good luck to all italians !", "label": "", "metadata": {}, "score": "102.13341"}
{"text": "[ 0047 ] Class 4 : Realization in different syntactic categories [ 0048 ] Palestinian leader Ararat vs. Ararat , Palestinian leader .[ 0049 ] Class 5 : Head omission [ 0050 ] group of students vs. students .[ 0051 ] Class 6 : Prepositional phrase attachment [ 0052 ] the Alabama plant vs. a plant in Alabama [ 0053 ] velvet dresses vs. dresses made of velvet .", "label": "", "metadata": {}, "score": "102.32901"}
{"text": "Anne Abeille ( co - chair ) , Paris .Thorsten Brants ( co - chair ) , Saarbruecken .John Carroll , Sussex .Lionel Clement , Paris .Tomaz Erjavec , Ljubljana .Frank Keller , Edinburgh .Laurent Romary , Nancy .", "label": "", "metadata": {}, "score": "102.58358"}
{"text": "Anne Abeille ( co - chair ) , Paris .Thorsten Brants ( co - chair ) , Saarbruecken .John Carroll , Sussex .Lionel Clement , Paris .Tomaz Erjavec , Ljubljana .Frank Keller , Edinburgh .Laurent Romary , Nancy .", "label": "", "metadata": {}, "score": "102.58358"}
{"text": "17:00 - 17:30 Final Discussion : Current and Future Directions . in Corpus Annotation .Anne Abeille , Thorsten Brants , Hans Uszkoreit .CONTACT : .Thorsten Brants .email : thorsten coli.uni-sb .de .REGISTRATION : . select ' ' Workshops ' ' ( or secure form for workshops )", "label": "", "metadata": {}, "score": "103.196556"}
{"text": "0122 ] Block 430 generalizes the learned paraphrasing patterns by replacing triggering lexicons by variables .The resulting generalized patterns are then used to extract more similar sentence pairs from the monolingual corpora .For example , the following two additional exemplary sentences are extracted because they fit the generalized pattern : Beethoven composed Symphonie No . 9 . vs. The composer of Symphonie No . 9 was Beethoven .", "label": "", "metadata": {}, "score": "107.32733"}
{"text": "The method as recited in claim 11 , wherein the probability value of each candidate atomic paraphrasing pair is obtained using an appropriate feature function of the atomic paraphrasing pair .The method as recited in claim 11 , further comprising : forming a plurality of combinations of candidate atomic paraphrasing pairs from a plurality of candidate atomic paraphrasing pairs ; andcomputing the composite paraphrasing score of each of the plurality of combinations of candidate atomic paraphrasing pairs .", "label": "", "metadata": {}, "score": "107.38675"}
{"text": "[0058 ]He is a good teacher .vs. He teaches well . vs. He is good at teaching .[ 0059 ] The length of Long River is 6,000 kilometers .vs. Long River is as long as 6,000 kilometers .", "label": "", "metadata": {}, "score": "109.2088"}
{"text": "School 2000 in Freiburg .For additional information on lecture and tutorial topics , schedule , . accomodation and travel , please refer to our web pages .Please forward this message to interested colleagues and students .We are looking forward to welcome you in Freiburg , .", "label": "", "metadata": {}, "score": "111.72366"}
{"text": "School 2000 in Freiburg .For additional information on lecture and tutorial topics , schedule , . accomodation and travel , please refer to our web pages .Please forward this message to interested colleagues and students .We are looking forward to welcome you in Freiburg , .", "label": "", "metadata": {}, "score": "111.72366"}
{"text": "0073 ] Bob excels at mathematics .vs. Bob studies mathematics well .[ 0074 ]He is a physicist .vs. He is a scientist trained in physics .[0075 ]Class 14 : Inference [ 0076 ] He was died of cancer .", "label": "", "metadata": {}, "score": "112.350006"}
{"text": "I would like to thank Linear B , for allowing me to run some very computationally expensive processes on their machines at a time when students were scrambling for resources on the school machines .I would also like to thank Linear B for allowing me . by Nicola Ueffing Klaus , Klaus Macherey , Hermann Ney - In Proc .", "label": "", "metadata": {}, "score": "112.83281"}
{"text": "17 ] [ 18 ] .In TGG , Deep structures were generated by a set of phrase structure rules .For example , a typical transformation in TG is the operation of subject - auxiliary inversion ( SAI ) .This rule takes as its input a declarative sentence with an auxiliary : \" John has eaten all the heirloom tomatoes . \" and transforms it into \" Has John eaten all the heirloom tomatoes ? \"", "label": "", "metadata": {}, "score": "112.98397"}
{"text": "This website is unofficial and an independently operated source of news and information not affiliated with any team or organisation .Powered by : vBulletin .Copyright \u00a9 2000 - , Jelsoft Enterprises Ltd. .For the best viewing experience please update your browser to Google Chrome", "label": "", "metadata": {}, "score": "124.783295"}
{"text": "For example , the generalized transformation of embedding would take the kernel \" Dave said X \" and the kernel \" Dan likes smoking \" and combine them into \" Dave said Dan likes smoking . \" GTs are thus structure building rather than structure changing .", "label": "", "metadata": {}, "score": "129.99649"}
{"text": "Computing system 201 is implemented with computing device 202 which includes processor(s ) 210 , I / O devices 220 , computer readable media ( e.g. , memory ) 230 , and network interface ( not shown ) .The computer readable media 230 stores application program modules 232 and data 234 ( such as paraphrasing data ) .", "label": "", "metadata": {}, "score": "130.9526"}
