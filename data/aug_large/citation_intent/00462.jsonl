{"text": "This paper describes a simple yet novel method for constructing sets of 50-best parses based on a co ... \" .Discriminative reranking is one method for constructing high - performance statistical parsers ( Collins , 2000 ) .A discriminative reranker requires a source of candidate parses for each sentence .", "label": "", "metadata": {}, "score": "58.273285"}
{"text": "In this paper , we describe how treebanks for 13 languages were converted into the same dependency format and how parsing performance was measured .We also give an overview of the parsing approaches that participants took and the results that they achieved .", "label": "", "metadata": {}, "score": "61.13327"}
{"text": "They are important for a few reasons .First , at present the best performing parsers on the WSJ treebank ( Ratnaparkhi 1997 ; Charniak 1997 , 1999 ; Collins 1997 , 1999 ) are all cases of history - based mo .. \" ...", "label": "", "metadata": {}, "score": "62.043682"}
{"text": "Various lexical and syntactic features are derived from parse trees and used to derive statistical classifiers from hand - annotated training data . \" ...Discriminative reranking is one method for constructing high - performance statistical parsers ( Collins , 2000 ) .", "label": "", "metadata": {}, "score": "64.52609"}
{"text": "According to an evaluation of unlabeled word - word dependencies , our best model achieves a performance of 89.9 % , comparable to the figures given by Collins ( 1999 ) for a linguistically less expressive grammar .In contrast to Gildea ( 2001 ) , we find a significant improvement from modeling wordword dependencies . \" ...", "label": "", "metadata": {}, "score": "66.01494"}
{"text": "In parsing we would have training examples fs i ; t i g where e .. \" ...This paper introduces new learning algorithms for natural language processing based on the perceptron algorithm .We show how the algorithms can be efficiently applied to exponential sized representations of parse trees , such as the \" all subtrees \" ( DOP ) representation described by ( Bod 9 ... \" .", "label": "", "metadata": {}, "score": "66.32516"}
{"text": "In this paper we investigate two types of chart pruning : a standard beam search , similar to that used in the Collins parser ( Collins , 1999 ) , a .. \" ...We present a systematic comparison and combination of two orthogonal techniques for efficient parsing of Combinatory Categorial Grammar ( CCG ) .", "label": "", "metadata": {}, "score": "66.831024"}
{"text": "We show how the algorithms can be efficiently applied to exponential sized representations of parse trees , such as the \" all subtrees \" ( DOP ) representation described by ( Bod 98 ) , or a representation tracking all sub - fragments of a tagged sentence .", "label": "", "metadata": {}, "score": "67.02414"}
{"text": "The base parser produces a set of candidate parses for each input sentence , with associated probabilities that define an initial ranking of these parses .A second model then attempts to improve upon this initial ranking , using additional features of the tree as evidence .", "label": "", "metadata": {}, "score": "67.75754"}
{"text": "The base parser produces a set of candidate parses for each input sentence , with associated probabilities that define an initial ranking of these parses .A second model then attempts to improve upon this initial ranking , using additional features of the tree as evidence .", "label": "", "metadata": {}, "score": "67.75754"}
{"text": "We also demonstrate that the parser can train from other domains without modification to the modeling framework or the linguistic hints it uses to learn .Furthermore , this paper shows that research into rescoring the top 20 parses returned by the parser might yield accuracies dramatically higher than the state - of - the - art . \" ...", "label": "", "metadata": {}, "score": "68.04785"}
{"text": "A new almost - parsing language model incorporating multiple knowledge sources that is based upon the concept of Constraint Dependency Grammars is presented in this paper .Lexical features and syntactic constraints are tightly integrated into a uniform linguistic structure called a SuperARV that is associated with a word in the lexicon .", "label": "", "metadata": {}, "score": "69.20999"}
{"text": "This article considers approaches which rerank the output of an existing probabilistic parser .The base parser produces a set of candidate parses for each input sentence , with associated probabilities that define an initial ranking of these parses .A second model then attempts to improve upon this initial ranking , using additional features of the tree as evidence .", "label": "", "metadata": {}, "score": "69.22347"}
{"text": "\\n \" \" \\n \" \" The rest of the data consists of a sequence of blocks , one per \\n \" \" sentence .\\n \" \" \\n \" \" Duplicate parses produced by Collins ' parser are deleted , but otherwise \\n \" \" the parses are in alphabetical ( ! ) order .", "label": "", "metadata": {}, "score": "69.26955"}
{"text": "A description of this constraint comes from Collins ' Ph.D. thesis : .X Y ..In training data 96 % of commas follow this rule .The rule also has the benefit of improving efficiency by reducing the number of constituents in the chart .", "label": "", "metadata": {}, "score": "69.61365"}
{"text": "This paper presents a machine learning system for parsing natural language that learns from manually parsed example sentences , and parses unseen data at state - of - the - art accuracies .Its machine learning technology , based on the maximum entropy framework , is highly reusable and not specific to the pa ... \" .", "label": "", "metadata": {}, "score": "69.636215"}
{"text": "This method generates 50-best lists that are of substantially higher quality than previously obtainable . ...m search , keeping some large number of possibilities to extend by adding the next word , and then re - pruning .", "label": "", "metadata": {}, "score": "69.74359"}
{"text": "We also give an overview of the parsing approaches that participants took and the results that they achieved .Finally , we try to draw general conclusions about multi - lingual parsing : What makes a particular language , treebank or annotation scheme easier or harder to parse and which phenomena are challenging for any dependency parser ?", "label": "", "metadata": {}, "score": "70.075264"}
{"text": "This article considers approaches which rerank the output of an existing probabilistic parser .The base parser produces a set of candidate parses for each input sentence , with associated probabilities that define an initial ranking of these parses .A second model then attempts to improve upon this i ... \" .", "label": "", "metadata": {}, "score": "70.757935"}
{"text": "This article considers approaches which rerank the output of an existing probabilistic parser .The base parser produces a set of candidate parses for each input sentence , with associated probabilities that define an initial ranking of these parses .A second model then attempts to improve upon this i ... \" .", "label": "", "metadata": {}, "score": "70.757935"}
{"text": "We perform O(n ) predictions to determine if each word in the input sentence may begin or end a multi - word constituent in chart ... \" .We present methods for reducing the worst - case and typical - case complexity of a context - free parsing pipeline via hard constraints derived from finite - state pre - processing .", "label": "", "metadata": {}, "score": "71.665924"}
{"text": "Parsers based on lexicalised grammar formalisms , such as TAG and CCG , can be made more efficient using supertagging , which for CCG is so effective that every derivation consistent with the supertagger output can be stored in a packed chart .", "label": "", "metadata": {}, "score": "71.70509"}
{"text": "A second model then attempts to improve upon this i ... \" .This article considers approaches which rerank the output of an existing probabilistic parser .The base parser produces a set of candidate parses for each input sentence , with associated probabilities that define an initial ranking of these parses .", "label": "", "metadata": {}, "score": "72.09982"}
{"text": "Creates a new Lingua::CollinsParser object and returns it .For initialization , new ( ) accepts a list of key - value pairs corresponding to the five accessor methods below ( beamsize , punc_flag , distaflag , distvflag , npflag ) - if present , the accessors will be called and the corresponding values will be passed to them .", "label": "", "metadata": {}, "score": "72.81656"}
{"text": "We show how a kernel over trees can be applied to parsing using the voted perceptron algorithm , and we give experimental results on the ATIS corpus of parse trees . ... lems .The method is derived by the transformation from ranking problems to a margin - based classification problem in [ 8].", "label": "", "metadata": {}, "score": "73.413"}
{"text": "In this paper we investigate two forms of chart pruning , and develop a novel method for pruning complete cells in a parse chart .The result is a widecoverage CCG parser that can process almost 100 sentences per second , with little or no loss in accuracy over the baseline with no pruning . ... a packed chart can still be enormous for typical newspaper sentences .", "label": "", "metadata": {}, "score": "73.62053"}
{"text": "The models are \" full \" parsing models in the sense that probabilities are defined for complete parses , rather than for independent events derived by decomposing the parse tree .Dis ... \" .This paper describes a number of log - linear parsing models for an automatically extracted lexicalized grammar .", "label": "", "metadata": {}, "score": "73.63016"}
{"text": "The issues of consistency of argument structure across both polysemous and synonymous verbs are also discussed and we present our actual guidelines for these types of phenomena , along with numerous examples of tagged sentences and verb frames .We conclude with a summary of the current status of annotation process .", "label": "", "metadata": {}, "score": "73.87869"}
{"text": "Dynamic programming over a packed chart , in combination with the parallel implementation , allows us to solve one of the largest - scale estimation problems in the statistical parsing literature in under three hours .A key component of the parsing system , for both training and testing , is a Maximum Entropy supertagger which assigns CCG lexical categories to words in a sentence .", "label": "", "metadata": {}, "score": "75.07245"}
{"text": "Discriminative training is used to estimate the models , which requires incorrect parses for each sentence in the training data as well as the correct parse .The lexicalized grammar formalism used is Combinatory Categorial Grammar ( CCG ) , and the grammar is automatically extracted from CCGbank , a CCG version of the Penn Treebank .", "label": "", "metadata": {}, "score": "75.15821"}
{"text": "The second argument must be an array reference containing those words ' corresponding part - of - speech tags .A Lingua::CollinsParser::Node object is returned , representing a syntax tree for the sentence .It takes a really long time to call load_events ( ) , so this method is provided to \" freeze \" the loaded events hash to a file , so that it can be \" thawed \" out again later with undump_events_hash ( ) .", "label": "", "metadata": {}, "score": "75.455826"}
{"text": "It can be very useful to use the head words when analyzing the tree output .This module , Lingua::CollinsParser , is a Perl wrapper around Collins ' parser .The parser itself is written in C. .Because the internal C code of the parser uses lots of global variables to maintain state , it is currently impossible to create more than one parser instance at the same time .", "label": "", "metadata": {}, "score": "75.63846"}
{"text": "The opposite , generation , starts from the top - level rule and chooses one alternative production wherever there is a choice .A compiler compiler like yacc might be used to convert a grammar into code for the parser of a compiler .", "label": "", "metadata": {}, "score": "75.69028"}
{"text": "This system outperforms previou ... \" .We describe a parsing system based upon a language model for English that is , in turn , based upon assigning probabilities to possible parses for a sentence .This model is used in a parsing system by finding the parse for the sentence with the highest probability .", "label": "", "metadata": {}, "score": "75.7944"}
{"text": "In previous work ( [ Zettlemoyer and Collins , 2007 ] ) , a system has been constructed that uses a small set of mappings between syntactic categories and logical forms in order to learn to convert natural language in to a formal language .", "label": "", "metadata": {}, "score": "76.01832"}
{"text": "In previous work ( [ Zettlemoyer and Collins , 2007 ] ) , a system has been constructed that uses a small set of mappings between syntactic categories and logical forms in order to learn to convert natural language in to a formal language .", "label": "", "metadata": {}, "score": "76.01832"}
{"text": "We present a detailed case study of this learni ... \" .this paper , we will describe a simple rule - based approach to automated learning of linguistic knowledge .This approach has been shown for a number of tasks to capture information in a clearer and more direct fashion without a compromise in performance .", "label": "", "metadata": {}, "score": "76.27768"}
{"text": "The strength of our approach is that it allows a tree to be represented as an arbitrary set of features , without concerns about how these features interact or overlap and without the need to define a derivation or a generative model which takes these features into account .", "label": "", "metadata": {}, "score": "76.479904"}
{"text": "The methods employed allow for the system to be scaled up to larger and more complex domains by extending the set of mappings .This paper describes building a semantic parser around this previously used framework and attempting to learn to convert natural language from a richer source of semantically annotated data .", "label": "", "metadata": {}, "score": "76.78033"}
{"text": "In these results , the generative model performs significantly better than the others , and does about equally well at assigning part - of - speech tags . \" ...Each year the Conference on Computational Natural Language Learning ( CoNLL ) 1 features a shared task , in which participants train and test their systems on exactly the same data sets , in order to better compare systems .", "label": "", "metadata": {}, "score": "76.86623"}
{"text": "The tenth CoNLL ( CoNLL - X ) saw a shared task on Multilingual Dependency Parsing .Each year the Conference on Computational Natural Language Learning ( CoNLL ) 1 features a shared task , in which participants train and test their systems on exactly the same data sets , in order to better compare systems .", "label": "", "metadata": {}, "score": "77.5137"}
{"text": "These bounds on processing are achieved without reducing the parsing accuracy , and in some cases accuracy improves .We demonstrate that our method generalizes across multiple grammars and is complementary to other pruning techniques by presenting empirical results for both exact and approximate inference using the exhaustive CKY algorithm , the Charniak parser , and the Berkeley parser .", "label": "", "metadata": {}, "score": "77.833305"}
{"text": "However , if a cleanup effort is undertaken in the parser 's C code in the future , it may be possible to remove its reliance on global variables , and the new ( ) method could start returning new instances with each call .", "label": "", "metadata": {}, "score": "77.910675"}
{"text": "We examine the treatment of commas in CCGbank , a wide - coverage corpus for Combinatory Categorial Grammar ( CCG ) , reanalysing its comma structures in order to eliminate a class of redundant rules , obtaining a more consistent treebank .", "label": "", "metadata": {}, "score": "77.93503"}
{"text": "Each year the Conference on Computational Natural Language Learning ( CoNLL ) 1 features a shared task , in which participants train and test their systems on exactly the same data sets , in order to better compare systems .The tenth CoNLL ( CoNLL - X ) saw a shared task on Multilingual Dependency Parsing .", "label": "", "metadata": {}, "score": "78.11669"}
{"text": "Intelligence ( Special Issue : Machine Intelligence , 1999 . \" ...Human language acquisition , and in particular the acquisition of grammar , is a partially - canalized , strongly - biased but robust and e cient procedure .For example , children prefer to induce lexically compositional rules ( e.g. Wanner and Gleitman , 1982 ) despite the use , in every attested human languag ... \" .", "label": "", "metadata": {}, "score": "78.229294"}
{"text": "For learning within such frameworks , methods from undirected graphical models are used ; ... .by Wen Wang , Mary P. Harper - in Proceedings of Conference of Empirical Methods in Natural Language Processing , 2002 . \" ...A new almost - parsing language model incorporating multiple knowledge sources that is based upon the concept of Constraint Dependency Grammars is presented in this paper .", "label": "", "metadata": {}, "score": "78.27855"}
{"text": "These pre - processing constraints prune the search space for any chart - based parsing algorithm and significantly decrease decoding time .In many cases cell population is reduced to zero , which we term chart cell \" closing .\" We present methods for closing a sufficient number of chart cells to ensure provably quadratic or even linear worst - case complexity of context - free inference .", "label": "", "metadata": {}, "score": "78.41202"}
{"text": "This model is an extension of PCFG in which non - terminal symbols are augmented with latent variables .Finegrained CFG rules are automatically induced from a parsed corpus by training a PCFG - LA model using an EM - algorithm .", "label": "", "metadata": {}, "score": "78.59468"}
{"text": "Its machine learning technology , based on the maximum entropy framework , is highly reusable and not specific to the parsing problem , while the linguistic hints that it uses to learn can be specified concisely .It therefore requires a minimal amount of human effort and linguistic knowledge for its construction .", "label": "", "metadata": {}, "score": "78.64647"}
{"text": "The Penn Treebank has recently implemented a new syntactic annotation scheme , designed to highlight aspects of predicate - argument structure .This paper discusses the implementation of crucial aspects of this new annotation scheme .It incorporates a more consistent treatment of a wide range of gramma ... \" .", "label": "", "metadata": {}, "score": "78.73236"}
{"text": "We present a systematic comparison and combination of two orthogonal techniques for efficient parsing of Combinatory Categorial Grammar ( CCG ) .First we consider adaptive supertagging , a widely used approximate search technique that prunes most lexical categories from the parser 's search space using a separate sequence model . by Brian Roark , Kristy Hollingshead , Nathan Bodenstab - Computational Linguistics , Early Access:1 - 35 , 2012 . \" ...", "label": "", "metadata": {}, "score": "79.21919"}
{"text": "Surprisingly , .A CCG binary derivation tree is generated top - down , with the probability of generating particular child nodes being conditioned on some limited context from the previously generated structure .Hock ... . by Julia Hockenmaier , Mark Steedman - In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics , 2002 . \" ...", "label": "", "metadata": {}, "score": "79.834564"}
{"text": "Although punctuation is pervasive in written text , their treatment in parsers and corpora is often second - class .We examine the treatment of commas in CCGbank , a wide - coverage corpus for Combinatory Categorial Grammar ( CCG ) , reanalysing its comma structures in order to eliminate a class of redundant ... \" .", "label": "", "metadata": {}, "score": "79.86108"}
{"text": "We present a system for identifying the semantic relationships , or semantic roles , filled by constituents of a sentence within a semantic frame .Various lexical and syntactic features are derived from parse trees and used to derive statistical classifiers from hand - annotated training data .", "label": "", "metadata": {}, "score": "80.9212"}
{"text": "This model is an extension of PCFG in which non - terminal symbols are augmented with latent variables .Finegrained CFG rules are automatically induced from a parsed corpus by training a PCFG - LA model using an E ... \" .", "label": "", "metadata": {}, "score": "81.45245"}
{"text": "These models are trained and tested on a corpus obtained by translating the Penn Treebank trees into CCG normal - form derivations .According to an evaluation of unlabel ... \" .This paper compares a number of generative probability models for a widecoverage Combinatory Categorial Grammar ( CCG ) parser .", "label": "", "metadata": {}, "score": "82.19876"}
{"text": "For instance , if during installation you run the regression tests twice in a row , you 'll notice that the second time is much faster , because it dumped the hash information the first time .The Lingua::CollinsParser perl interface is copyright ( C ) 2004 Thomson Legal & Regulatory , and written by Ken Williams .", "label": "", "metadata": {}, "score": "82.355545"}
{"text": "There are many different ways to do this , resulting in lots of different styles of output and using various amounts of space & time resources .One of the most successful recent methods was developed by Michael Collins as part of his 1999 Ph.D. work at the University of Pennsylvania .", "label": "", "metadata": {}, "score": "82.72864"}
{"text": "This paper presents a new approach to phrase - level sentiment analysis that first determines whether an expression is neutral or polar and then disambiguates the polarity of the polar expressions .With this approach , the system is able to automatically identify the contextual polarity for a large subset of sentiment expressions , achieving results that are significantly better than baseline . ...", "label": "", "metadata": {}, "score": "82.757385"}
{"text": "( 1998 ) .We apply the boosting method to parsing the Wall Street Journal treebank .The method combined the log - likelihood under a baseline model ( that of Collins [ 1999 ] ) with evidence from an additional 500,000 features over parse trees that were not included in the original model .", "label": "", "metadata": {}, "score": "82.86494"}
{"text": "The article also introduces a new algorithm for the boosting approach which takes advantage of the sparsity of the feature space in the parsing data .Experiments show significant efficiency gains for the new algorithm over the obvious implementation of the boosting approach .", "label": "", "metadata": {}, "score": "83.249435"}
{"text": "The article also introduces a new algorithm for the boosting approach which takes advantage of the sparsity of the feature space in the parsing data .Experiments show significant efficiency gains for the new algorithm over the obvious implementation of the boosting approach .", "label": "", "metadata": {}, "score": "83.249435"}
{"text": "The article also introduces a new algorithm for the boosting approach which takes advantage of the sparsity of the feature space in the parsing data .Experiments show significant efficiency gains for the new algorithm over the obvious implementation of the boosting approach .", "label": "", "metadata": {}, "score": "83.249435"}
{"text": "The article also introduces a new algorithm for the boosting approach which takes advantage of the sparsity of the feature space in the parsing data .Experiments show significant efficiency gains for the new algorithm over the obvious implementation of the boosting approach .", "label": "", "metadata": {}, "score": "83.249435"}
{"text": "We propose ( a ) a lexical affinity model where words struggle to modify each other , ( b ) a sense tagging model where words fluctuate randomly in their selectional prefe ... \" .After presenting a novel O(n\u00b3 ) parsing algorithm for dependency grammar , we develop three contrasting ways to stochasticize it .", "label": "", "metadata": {}, "score": "83.2719"}
{"text": "It may produce some kind of abstract syntax tree as output .A parser may be produced automatically from a grammar by a parser generators such as yacc .A parser is normally part of some larger program , like a compiler , which takes the output of the parser and attempts to extract meaning from it in some way , e.g. translating it into another language .", "label": "", "metadata": {}, "score": "83.708206"}
{"text": "We introduce a new method for the reranking task , based on the boosting approach to ranking problems described in Freund et al .( 1998 ) .We apply the boosting method to parsing the Wall Street Journal treebank .The method combined the log - likelihood under a baseline model ( that of Collins [ 1999 ] ) with evidence from an additional 500,000 features over parse trees that were not included in the original model .", "label": "", "metadata": {}, "score": "84.49301"}
{"text": "We introduce a new method for the reranking task , based on the boosting approach to ranking problems described in Freund et al .( 1998 ) .We apply the boosting method to parsing the Wall Street Journal treebank .The method combined the log - likelihood under a baseline model ( that of Collins [ 1999 ] ) with evidence from an additional 500,000 features over parse trees that were not included in the original model .", "label": "", "metadata": {}, "score": "84.49301"}
{"text": "We introduce a new method for the reranking task , based on the boosting approach to ranking problems described in Freund et al .( 1998 ) .We apply the boosting method to parsing the Wall Street Journal treebank .The method combined the log - likelihood under a baseline model ( that of Collins [ 1999 ] ) with evidence from an additional 500,000 features over parse trees that were not included in the original model .", "label": "", "metadata": {}, "score": "84.49301"}
{"text": "One rule is normally designated as the top - level rule which gives the structure for a whole sentence .A parser ( a kind of recogniser ) uses a grammar to parse a sentence , assigning a terminal syntactic category to each input token and a non - terminal category to each appropriate group of tokens , up to the level of the whole sentence .", "label": "", "metadata": {}, "score": "84.69762"}
{"text": "This paper discusses the implementation of crucial aspects of this new annotation scheme .INTRODUCTION During the first phase of the The Penn Treebank project [ 10 ] , ending in December 1992 , 4.5 million words of text were tagged for part - of - speech , with about two - thirds of this material also annotated with a skeletal syntactic bracketing .", "label": "", "metadata": {}, "score": "84.7079"}
{"text": "v. .\" What part of speech ? \"Transferred ( non - grammatical ) use is from 1788 .Pars was a common plural of part ( n. ) in early Middle English .Related : Parsed ; parsing . language An algorithm or program to determine the syntactic structure of ( \" parse \" ) a sentence or string of symbols in some language .", "label": "", "metadata": {}, "score": "84.887344"}
{"text": "We investigate for the first time how factors such as training data size , corpus ( e.g. , Br ... \" .We present an extensive empirical comparison of several smoothing techniques in the domain of language modeling , including those described by Jelinek and Mercer ( 1980 ) , Katz ( 1987 ) , and Church and Gale ( 1991 ) .", "label": "", "metadata": {}, "score": "85.042595"}
{"text": ".. rning deserves further study .There are many different ways one could try to construct a language learner .In [ 65 ] , a selforganizing language learner is proposed to be used for language modelling .In this work we take a different approach , namely starting with a s ..", "label": "", "metadata": {}, "score": "85.42218"}
{"text": "to assign constituent structure to ( a sentence or the words in a sentence ) .( intransitive ) ( of a word or linguistic element ) to play a specified role in the structure of a sentence .( computing ) to analyse the source code of a computer program to make sure that it is structurally correct before it is compiled and turned into machine code .", "label": "", "metadata": {}, "score": "85.447205"}
{"text": "In the extreme case where there is so much tr ... .This represents a 13 % decrease in error rate over the best single - parser results on this corpus [ 9].The major technical innova- tion is the use of a \" maximum - entropy - inspired \" model for conditioning and smoothing that let us successfully to test and combine many different conditioning events .", "label": "", "metadata": {}, "score": "85.62788"}
{"text": "The relative contributions of the various knowledge sources to the strength of our model are also investigated by using constraint relaxation at the level of the knowledge sources .We have found that although each knowledge source contributes to language model quality , lexical features are an outstanding contributor when they are tightly integrated with word identity and syntactic constraints .", "label": "", "metadata": {}, "score": "85.94434"}
{"text": "Published by Houghton Mifflin Company .All rights reserved .Cite This Source . grammar in Technology Expand . language A formal definition of the syntactic structure ( the syntax ) of a language .A grammar is normally represented as a set of production rules which specify the order of constituents and their sub - constituents in a sentence ( a well - formed string in the language ) .", "label": "", "metadata": {}, "score": "85.96494"}
{"text": "This note formally introduces LOHMMs and presents solutions to the three central inference problems for LOHMMs : evaluation , most likely hidden state sequence and parameter estimation .The resulting representation and algorithms are experimentally evaluated on problems from the domain of bioinformatics .", "label": "", "metadata": {}, "score": "86.59433"}
{"text": "Eraall : brill@cs.jhu.edu .Word sense disambiguation , a problem which once seemed out of reach for systems without a great deal of hand cr ... . \" ...We describe a parsing system based upon a language model for English that is , in turn , based upon assigning probabilities to possible parses for a sentence .", "label": "", "metadata": {}, "score": "86.6891"}
{"text": "See also attribute grammar .er with the addition of the Pp and Pcc parameters . ) \" ...The best aspect of a research environment , in my opinion , is the abundance of bright people with whom you argue , discuss , and nurture your ideas .", "label": "", "metadata": {}, "score": "87.44004"}
{"text": "We present a maximum - likelihood approach for automatically constructing maximum entropy models and describe how to implement this approach efficiently , using as examples several problems in natural language processing . \" ... this paper , we will describe a simple rule - based approach to automated learning of linguistic knowledge .", "label": "", "metadata": {}, "score": "87.58856"}
{"text": "The results reveal the requirements for more specialised features in order to control the multitude of powerful rules that such complex semantic descriptions demand .i Acknowledgements I would like to thank those who have given me help , advice and support while completing this project .", "label": "", "metadata": {}, "score": "88.87718"}
{"text": "A fundamental problem in statistical parsing is the choice of criteria and algorithms used to estimate the parameters in a model .The predominant approach in computational linguistics has been to use a parametric model with some variant of maximum - likelihood estimation .", "label": "", "metadata": {}, "score": "89.160965"}
{"text": "A fundamental problem in statistical parsing is the choice of criteria and algorithms used to estimate the parameters in a model .The predominant approach in computational linguistics has been to use a parametric model with some variant of maximum - likelihood estimation .", "label": "", "metadata": {}, "score": "89.160965"}
{"text": "Acknowledgement Many thanks to Amit Dubey and Yuval Krymolowski , the other two organizers of the shared task , for discussions , converting treebanks , writing software and helping with the papers . \" ...This paper presents a new approach to phrase - level sentiment analysis that first determines whether an expression is neutral or polar and then disambiguates the polarity of the polar expressions .", "label": "", "metadata": {}, "score": "89.229485"}
{"text": "A boolean flag indicating whether noun phrases should always include NP and NPB levels , or whether the extra NP level may be omitted when superfluous .The default is to omit , i.e. the flag is true by default .Invokes the parser on the given sentence .", "label": "", "metadata": {}, "score": "89.51019"}
{"text": "This paper discusses the statistical theory underlying various parameter - estimation methods , and gives algorithms which depend on alternatives to ( smoothed ) maximumlikelihood estimation .We first give an overview of results from statistical learning theory .We then show how important concepts from the classification literature -- specifically , generalization results based on margins on training data -- can be derived for parsing models .", "label": "", "metadata": {}, "score": "89.68614"}
{"text": "n. .early 14c . , gramarye ( late 12c .adjective from gramma \" letter , \" from stem of graphein \" to draw or write \" ( see -graphy ) .An Old English word for it was st\u00e6fcr\u00e6ft .", "label": "", "metadata": {}, "score": "90.07704"}
{"text": "Its scoring approach is compatible with a wide variety of probability models .The obvious parsing algorithm for bilexical grammars ( used by most previous authors ) takes time O(n^5 ) .A more efficient O(n\u00b3 ) method is exhibited .The new algorithm has been implemented and used in a large parsing experiment ( Eisner , 1996b ) .", "label": "", "metadata": {}, "score": "90.35019"}
{"text": "For example , children prefer to induce lexically compositional rules ( e.g. Wanner and Gleitman , 1982 ) despite the use , in every attested human language , of constructions , such as morphological negation or non - compositional idioms .But none provide a coherent detailed account of both the emergence and maintenance of a LAD in an evolving population .", "label": "", "metadata": {}, "score": "90.93114"}
{"text": "1992 ) .They are important for a few reasons .Many systems applied to part - ofspeech tagging , speech recognition and other language or speech tasks also fall into this class of model .Second , a partic ... . \" ...", "label": "", "metadata": {}, "score": "91.03321"}
{"text": "Given the increasing need to process massive amounts of textual data , efficiency of NLP tools is becoming a pressing concern .Parsers based on lexicalised grammar formalisms , such as TAG and CCG , can be made more efficient using supertagging , which for CCG is so effective that every derivation consi ... \" .", "label": "", "metadata": {}, "score": "91.46799"}
{"text": "Although the experiments in this article are on natural language parsing ( NLP ) , the approach should be applicable to many other NLP problems which are naturally framed as ranking tasks , for example , speech recognition , machine translation , or natural language generation .", "label": "", "metadata": {}, "score": "92.17685"}
{"text": "Collins English Dictionary - Complete & Unabridged 2012 Digital Edition \u00a9 William Collins Sons & Co. Ltd. 1979 , 1986 \u00a9 HarperCollins Publishers 1998 , 2000 , 2003 , 2005 , 2006 , 2007 , 2009 , 2012 Cite This Source .", "label": "", "metadata": {}, "score": "92.24548"}
{"text": "Although the experiments in this article are on natural language parsing ( NLP ) , the approach should be applicable to many other NLP problems which are naturally framed as ranking tasks , for example , speech recognition , machine translation , or natural language generation . .", "label": "", "metadata": {}, "score": "92.87585"}
{"text": "Although the experiments in this article are on natural language parsing ( NLP ) , the approach should be applicable to many other NLP problems which are naturally framed as ranking tasks , for example , speech recognition , machine translation , or natural language generation . .", "label": "", "metadata": {}, "score": "92.87585"}
{"text": "Although the experiments in this article are on natural language parsing ( NLP ) , the approach should be applicable to many other NLP problems which are naturally framed as ranking tasks , for example , speech recognition , machine translation , or natural language generation . .", "label": "", "metadata": {}, "score": "92.87585"}
{"text": "Introduction We present a statistical parser that induces its grammar and probabilities from a hand - parsed corpus ( a tree - bank ) .Parsers induced from corpora are of interest both as simply exercises in machine learning and also because they are often the best parsers obtainable by any method .", "label": "", "metadata": {}, "score": "93.51373"}
{"text": "( as modifier ): a grammar book .C14 : from Old French gramaire , from Latin grammatica , from Greek grammatik\u0113 ( tekhn\u0113 ) the grammatical ( art ) , from grammatikos concerning letters , from gramma letter .Collins English Dictionary - Complete & Unabridged 2012 Digital Edition \u00a9 William Collins Sons & Co. Ltd. 1979 , 1986 \u00a9 HarperCollins Publishers 1998 , 2000 , 2003 , 2005 , 2006 , 2007 , 2009 , 2012 Cite This Source .", "label": "", "metadata": {}, "score": "93.61211"}
{"text": "This chapter introduces weighted bilexical grammars , a formalism in which individual lexical items , such as verbs and their arguments , can have idiosyncratic selectional influences on each other .Such ' bilexicalism ' has been a theme of much current work in parsing .", "label": "", "metadata": {}, "score": "93.84807"}
{"text": "This chapter introduces weighted bilexical grammars , a formalism in which individual lexical items , such as verbs and their arguments , can have idiosyncratic selectional influences on each other .Such ' bilexicalism ' has been a theme of much current work in parsing .", "label": "", "metadata": {}, "score": "93.84807"}
{"text": "In a dependency representation , every node in the tree structure is a surface word ( i.e. , there are no abstrac ... . by Paul Kingsbury , Martha Palmer - In Language Resources and Evaluation , 2002 . \" ...This paper describes our approach to the development of a Proposition Bank , which involves the addition of semantic information to the Penn English Treebank .", "label": "", "metadata": {}, "score": "94.31825"}
{"text": "Logical hidden Markov models ( LOHMMs ) upgrade traditional hidden Markov models to deal with sequences of structured symbols in the form of logical atoms , rather than flat characters .This note formally introduces LOHMMs and presents solutions to the three central inference problems for LOHMMs : evalu ... \" .", "label": "", "metadata": {}, "score": "95.362915"}
{"text": "Iwould like toacknowledge the following people for their contribution to my education : I thank my advisor Mitch Marcus , who gave me the intellectual freedom to pursue what I believed to be the best way to approach natural language processing , and also gave me direction when necessary .", "label": "", "metadata": {}, "score": "96.76769"}
{"text": "Iwould like toacknowledge the following people for their contribution to my education : I thank my advisor Mitch Marcus , who gave me the intellectual freedom to pursue what I believed to be the best way to approach natural language processing , and also gave me direction when necessary .", "label": "", "metadata": {}, "score": "96.76769"}
{"text": "Iwould like toacknowledge the following people for their contribution to my education : I thank my advisor Mitch Marcus , who gave me the intellectual freedom to pursue what I believed to be the best way to approach natural language processing , and also gave me direction when necessary .", "label": "", "metadata": {}, "score": "96.76769"}
{"text": "That is , whenever a constituent with the same history is generated a second time , it is discarded if its probability is lower than the original version .I .. \" ...This article considers approaches which rerank the output of an existing probabilistic parser .", "label": "", "metadata": {}, "score": "97.559204"}
{"text": "Each symbol may be either a terminal symbol or a non - terminal symbol .A terminal symbol corresponds to one \" lexeme \" - a part of the sentence with no internal syntactic structure ( e.g. an identifier or an operator in a computer language ) .", "label": "", "metadata": {}, "score": "98.68141"}
{"text": "// Licensed under the Apache License , Version 2.0 ( the \" License \" ) ; you may // not use this file except in compliance with the License .See the // License for the specific language governing permissions and limitations // under the License .", "label": "", "metadata": {}, "score": "99.32172"}
{"text": "I hope th ... \" .The best aspect of a research environment , in my opinion , is the abundance of bright people with whom you argue , discuss , and nurture your ideas .I thank all of the people at Penn and elsewhere who have given me the feedback that has helped me to separate the good ideas from the bad ideas .", "label": "", "metadata": {}, "score": "99.77351"}
{"text": "This paper describes our approach to the development of a Proposition Bank , which involves the addition of semantic information to the Penn English Treebank .Our primary goal is the labeling of syntactic nodes with specific argument labels that preserve the similarity of roles such as the window in John broke the window and the window broke .", "label": "", "metadata": {}, "score": "99.77527"}
{"text": "Tools . by Adam L. Berger , Stephen A. Della Pietra , Vincent J. Della Pietra - COMPUTATIONAL LINGUISTICS , 1996 . \" ...The concept of maximum entropy can be traced back along multiple threads to Biblical times .Only recently , however , have computers become powerful enough to permit the widescale application of this concept to real world problems in statistical estimation and pattern recognition .", "label": "", "metadata": {}, "score": "100.00737"}
{"text": "This is explained somewhere in Collins ' Ph.D. thesis , though I could n't quite figure out where .Default is true .A boolean flag indicating whether the \" verb condition \" in the distance measure should be used .This is explained somewhere in Collins ' Ph.D. thesis , though I could n't quite figure out where .", "label": "", "metadata": {}, "score": "100.16971"}
{"text": "The best aspect of a research environment , in my opinion , is the abundance of bright people with whom you argue , discuss , and nurture your ideas .I thank all of the people at Penn and elsewhere who have given me the feedback that has helped me to separate the good ideas from the bad ideas .", "label": "", "metadata": {}, "score": "101.06746"}
{"text": "The best aspect of a research environment , in my opinion , is the abundance of bright people with whom you argue , discuss , and nurture your ideas .I thank all of the people at Penn and elsewhere who have given me the feedback that has helped me to separate the good ideas from the bad ideas .", "label": "", "metadata": {}, "score": "101.06746"}
{"text": "The best aspect of a research environment , in my opinion , is the abundance of bright people with whom you argue , discuss , and nurture your ideas .I thank all of the people at Penn and elsewhere who have given me the feedback that has helped me to separate the good ideas from the bad ideas .", "label": "", "metadata": {}, "score": "101.06746"}
{"text": "The best aspect of a research environment , in my opinion , is the abundance of bright people with whom you argue , discuss , and nurture your ideas .I thank all of the people at Penn and elsewhere who have given me the feedback that has helped me to separate the good ideas from the bad ideas .", "label": "", "metadata": {}, "score": "101.06746"}
{"text": "We describe kernels for various natural ... \" .We describe the application of kernel methods to Natural Language Processing ( NLP ) problems .In many NLP tasks the objects being modeled are strings , trees , graphs or other discrete structures which require some mechanism to convert them into feature vectors .", "label": "", "metadata": {}, "score": "103.67759"}
{"text": "I thank all of my thesis committee members : John La erty from Carnegie Mellon University , Aravind Joshi , Lyle Ungar , and Mark Liberman , for their extremely valuable suggestions and comments about my thesis research .I thank Mike Collins , Jason Eisner , and Dan Melamed , with whom I 've had many stimulating and impromptu discussions in the LINC lab .", "label": "", "metadata": {}, "score": "104.1006"}
{"text": "I thank all of my thesis committee members : John La erty from Carnegie Mellon University , Aravind Joshi , Lyle Ungar , and Mark Liberman , for their extremely valuable suggestions and comments about my thesis research .I thank Mike Collins , Jason Eisner , and Dan Melamed , with whom I 've had many stimulating and impromptu discussions in the LINC lab .", "label": "", "metadata": {}, "score": "104.1006"}
{"text": "I thank all of my thesis committee members : John La erty from Carnegie Mellon University , Aravind Joshi , Lyle Ungar , and Mark Liberman , for their extremely valuable suggestions and comments about my thesis research .I thank Mike Collins , Jason Eisner , and Dan Melamed , with whom I 've had many stimulating and impromptu discussions in the LINC lab .", "label": "", "metadata": {}, "score": "104.1006"}
{"text": "The Collins Parser is copyright ( C ) 1999 by Michael Collins - you will find full copyright and license information in its distribution .The Parser.patch file distributed here is granted under the same license terms as the parser code itself . syntax highlighting : no syntax highlighting acid berries - dark berries - light bipolar blacknblue bright contrast cpan darkblue darkness desert dull easter emacs golden greenlcd ide - anjuta ide - codewarrior ide - devcpp ide - eclipse ide - kdev ide - msvcpp kwrite matlab navy nedit neon night pablo peachpuff print rand01 solarized - dark solarized - light style the typical vampire vim - dark vim whatis whitengrey zellner \" ...", "label": "", "metadata": {}, "score": "104.99143"}
{"text": "In U.S. ( 1842 ) the term was put to use in the graded system for \" a school between primary and secondary where English grammar is taught . \" grammar definition .The rules for standard use of words .A grammar is also a system for classifying and analyzing the elements of language .", "label": "", "metadata": {}, "score": "105.23744"}
{"text": "The concept of maximum entropy can be traced back along multiple threads to Biblical times .Only recently , however , have computers become powerful enough to permit the widescale application of this concept to real world problems in statistical estimation and pattern recognition .", "label": "", "metadata": {}, "score": "105.26517"}
{"text": "The first method we discuss is based on a feature selection me ... . by Michael Collins , Nigel Duffy - Advances in Neural Information Processing Systems 14 , 2001 . \" ...We describe the application of kernel methods to Natural Language Processing ( NLP ) problems .", "label": "", "metadata": {}, "score": "105.40529"}
{"text": "is_punctuation ( ) & & !c_str ( ) ) ; assert ( gold ! c_str ( ) ) ; assert ( parse ! last_parse . clear ( ) ; if ( !parse_logprob . insert ( S_D : : value_type ( parse , logprob ) ) ; if ( itb . size ( ) ; if ( parse_logprob . c_str ( ) ) ; if ( ! a book containing an account of the grammatical facts of a language or recommendations as to rules for the proper use of a language .", "label": "", "metadata": {}, "score": "107.08049"}
{"text": "Restriction to \" rules of language \" is a post - classical development , but as this type of study was until 16c . limited to Latin , Middle English gramarye also came to mean \" learning in general , knowledge peculiar to the learned classes \" ( early 14c . ) , which included astrology and magic ; hence the secondary meaning of \" occult knowledge \" ( late 15c . ) , which evolved in Scottish into glamor ( q.v . ) .", "label": "", "metadata": {}, "score": "117.9458"}
